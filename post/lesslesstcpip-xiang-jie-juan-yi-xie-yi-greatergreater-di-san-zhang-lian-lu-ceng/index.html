<!DOCTYPE html>
<html>

<head>
  <meta charset="UTF-8" />

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
<meta name="keywords" content="Gridea静态个人博客">
<meta name="description" content="温故而知新">
<meta name="theme-color" content="#000">
<title>《TCP/IP 详解 卷一：协议》第三章：链路层 | wenbozhang&#39;s blogs</title>
<link rel="shortcut icon" href="/favicon.ico?v=1663666630346">
<link rel="stylesheet" href="/styles/main.css">
<link rel="stylesheet" href="/media/css/pisces.css">

<link rel="stylesheet" href="/media/fonts/font-awesome.css">
<link
  href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Rosario:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext"
  rel="stylesheet" type="text/css">

<link href="/media/hljs/styles/androidstudio.css"
  rel="stylesheet">

<script src="/media/hljs/highlight.js"></script>
<script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.0/velocity.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.0/velocity.ui.min.js"></script>

<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>



  <meta name="description" content="《TCP/IP 详解 卷一：协议》第三章：链路层" />
  <meta name="keywords" content="TCP/IP" />
</head>

<body>
  <div class="head-top-line"></div>
  <div class="header-box">
    
<div class="pisces">
  <header class="header  ">
    <div class="blog-header box-shadow-wrapper bg-color " id="header">
      <div class="nav-toggle" id="nav_toggle">
        <div class="toggle-box">
          <div class="line line-top"></div>
          <div class="line line-center"></div>
          <div class="line line-bottom"></div>
        </div>
      </div>
      <div class="site-meta">       
        <div class="site-title">
          
            <a href="/" class="brand">
              <span>wenbozhang&#39;s blogs</span>
            </a>  
          
        </div>
        
          <p class="subtitle">随风潜入夜</p>
        
      </div>
      <nav class="site-nav" id="site_nav">
        <ul id="nav_ul">
          
            
            
              
            
            <li class="nav-item ">
              
              
                <a href="/" target="_self">
                  <i class="fa fa-home"></i> 首页
                </a>
              
            </li>
          
            
            
              
            
            <li class="nav-item ">
              
              
                <a href="https://wenbozhangw.github.io/archives/" target="_self">
                  <i class="fa fa-globe"></i> 归档
                </a>
              
            </li>
          
            
            
              
            
            <li class="nav-item ">
              
              
                <a href="https://wenbozhangw.github.io/tags/" target="_self">
                  <i class="fa fa-globe"></i> 标签
                </a>
              
            </li>
          
          
            
              <li class="nav-item ">
                <a href="/friends/" target="_self">
                  
                    <i class="fa fa-address-book"></i> 友情链接
                  
                </a>
              </li>
            
          
        </ul>
      </nav>
    </div>
  </header>
</div>

<script type="text/javascript"> 
 
  let showNav = true;

  let navToggle = document.querySelector('#nav_toggle'),
  siteNav = document.querySelector('#site_nav');
  
  function navClick() {
    let sideBar = document.querySelector('.sidebar');
    let navUl = document.querySelector('#nav_ul');
    navToggle.classList.toggle('nav-toggle-active');
    siteNav.classList.toggle('nav-menu-active');
    if (siteNav.classList.contains('nav-menu-active')) {
      siteNav.style = "height: " + (navUl.children.length * 42) +"px !important";
    } else {
      siteNav.style = "";
    }
  }

  navToggle.addEventListener('click',navClick);  
</script>
  </div>
  <div class="main-continer">
    
    <div
      class="section-layout pisces ">
      <div class="section-layout-wrapper">
        

<div class="sidebar">
  
    <div class="sidebar-box box-shadow-wrapper bg-color right-motion" id="sidebar">
      
        <div class="post-list-sidebar">
          <div class="sidebar-title">
            <span id="tocSideBar" class="sidebar-title-item sidebar-title-active">文章目录</span>
            <span id="metaSideBar" class="sidebar-title-item">站点概览</span>
          </div>
        </div>
      
      <div class="sidebar-body pisces" id="sidebar_body">
        
          
            <div class="post-side-meta" id="post_side_meta">
              
<div class="sidebar-wrapper box-shadow-wrapper bg-color">
  <div class="sidebar-item">
    <img class="site-author-image right-motion" src="/images/avatar.png"/>
    <p class="site-author-name">wenbo zhang</p>
    
  </div>
  <div class="sidebar-item side-item-stat right-motion">
    <div class="sidebar-item-box">
      <a href="/archives/">
        
        <span class="site-item-stat-count">27</span>
        <span class="site-item-stat-name">文章</span>
      </a>
    </div>
    <div class="sidebar-item-box">
      <a href="">
        <span class="site-item-stat-count">10</span>
        <span class="site-item-stat-name">分类</span>
      </a>
    </div>
    <div class="sidebar-item-box">
      <a href="/tags/">
        <span class="site-item-stat-count">10</span>
        <span class="site-item-stat-name">标签</span>
      </a>
    </div>
  </div>
  
    
      <div class="sidebar-item" style="border-top: 1px dotted #ccc; margin-top: 10px;">
      </div>
    
  
  


</div>
            </div>
            <div class="post-toc sidebar-body-active" id="post_toc" style="opacity: 1;">
              <div class="toc-box right-motion">
  <div class="toc-wrapper auto-number auto"
    id="toc_wrapper">
    <ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#31-%E5%BC%95%E8%A8%80">3.1 引言</a></li>
<li><a href="#32-%E4%BB%A5%E5%A4%AA%E7%BD%91%E5%92%8C-ieee-802-%E5%B1%80%E5%9F%9F%E7%BD%91%E5%9F%8E%E5%9F%9F%E7%BD%91%E6%A0%87%E5%87%86">3.2 以太网和 IEEE 802 局域网/城域网标准</a>
<ul>
<li><a href="#321-ieee-802-%E5%B1%80%E5%9F%9F%E7%BD%91%E5%9F%8E%E5%9F%9F%E7%BD%91%E6%A0%87%E5%87%86">3.2.1 IEEE 802 局域网/城域网标准</a></li>
<li><a href="#322-%E4%BB%A5%E5%A4%AA%E7%BD%91%E5%B8%A7%E6%A0%BC%E5%BC%8F">3.2.2 以太网帧格式</a>
<ul>
<li><a href="#3221-%E5%B8%A7%E6%A0%A1%E9%AA%8C%E5%BA%8F%E5%88%97%E5%BE%AA%E7%8E%AF%E5%86%97%E4%BD%99%E6%A0%A1%E9%AA%8C">3.2.2.1 帧校验序列/循环冗余校验</a></li>
<li><a href="#3222-%E5%B8%A7%E5%A4%A7%E5%B0%8F">3.2.2.2 帧大小</a></li>
</ul>
</li>
<li><a href="#323-8021pq%E8%99%9A%E6%8B%9F%E5%B1%80%E5%9F%9F%E7%BD%91%E5%92%8C-qos-%E6%A0%87%E7%AD%BE">3.2.3 802.1p/q：虚拟局域网和 QoS 标签</a></li>
<li><a href="#324-8021ax%E9%93%BE%E8%B7%AF%E8%81%9A%E5%90%88%E4%BB%A5%E5%89%8D%E7%9A%84-8023ad">3.2.4 802.1AX：链路聚合（以前的 802.3ad）</a></li>
</ul>
</li>
<li><a href="#33-%E5%85%A8%E5%8F%8C%E5%B7%A5-%E7%9C%81%E7%94%B5-%E8%87%AA%E5%8A%A8%E5%8D%8F%E5%95%86%E5%92%8C-8021x-%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6">3.3 全双工、省电、自动协商和 802.1X 流量控制</a>
<ul>
<li><a href="#331-%E5%8F%8C%E5%B7%A5%E4%B8%8D%E5%8C%B9%E9%85%8D">3.3.1 双工不匹配</a></li>
<li><a href="#332-%E5%B1%80%E5%9F%9F%E7%BD%91%E5%94%A4%E9%86%92wol-%E7%9C%81%E7%94%B5%E5%92%8C%E9%AD%94%E6%9C%AF%E5%88%86%E7%BB%84">3.3.2 局域网唤醒（WoL）、省电和魔术分组</a></li>
<li><a href="#333-%E9%93%BE%E8%B7%AF%E5%B1%82%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6">3.3.3 链路层流量控制</a></li>
</ul>
</li>
<li><a href="#34-%E7%BD%91%E6%A1%A5%E5%92%8C%E4%BA%A4%E6%8D%A2%E6%9C%BA">3.4 网桥和交换机</a>
<ul>
<li><a href="#341-%E7%94%9F%E6%88%90%E6%A0%91%E5%8D%8F%E8%AE%AE">3.4.1 生成树协议</a>
<ul>
<li><a href="#3411-%E7%AB%AF%E5%8F%A3%E7%8A%B6%E6%80%81%E5%92%8C%E8%A7%92%E8%89%B2">3.4.1.1 端口状态和角色</a></li>
<li><a href="#3412-bpdu-%E7%BB%93%E6%9E%84">3.4.1.2 BPDU 结构</a></li>
<li><a href="#3413-%E5%BB%BA%E7%AB%8B%E7%94%9F%E6%88%90%E6%A0%91">3.4.1.3 建立生成树</a></li>
<li><a href="#3414-%E6%8B%93%E6%89%91%E5%8F%98%E5%8C%96">3.4.1.4 拓扑变化</a></li>
<li><a href="#3415-%E4%BE%8B%E5%AD%90">3.4.1.5 例子</a></li>
<li><a href="#3416-%E5%BF%AB%E9%80%9F%E7%94%9F%E6%88%90%E6%A0%91%E5%8D%8F%E8%AE%AE%E4%BB%A5%E5%89%8D%E7%9A%84-8021w">3.4.1.6 快速生成树协议（以前的 802.1w）</a></li>
</ul>
</li>
<li><a href="#342-8021ak%E5%A4%9A%E6%B3%A8%E5%86%8C%E5%8D%8F%E8%AE%AE">3.4.2 802.1ak：多注册协议</a></li>
</ul>
</li>
<li><a href="#35-%E6%97%A0%E7%BA%BF%E5%B1%80%E5%9F%9F%E7%BD%91ieee-80211wi-fi">3.5 无线局域网——IEEE 802.11（Wi-Fi）</a>
<ul>
<li><a href="#351-80211-%E5%B8%A7">3.5.1 802.11 帧</a>
<ul>
<li><a href="#3511-%E7%AE%A1%E7%90%86%E5%B8%A7">3.5.1.1 管理帧</a></li>
<li><a href="#3512-%E6%8E%A7%E5%88%B6%E5%B8%A7rtscts-%E5%92%8C-ack">3.5.1.2 控制帧：RTS/CTS 和 ACK</a></li>
<li><a href="#3513-%E6%95%B0%E6%8D%AE%E5%B8%A7-%E5%88%86%E7%89%87%E5%92%8C%E8%81%9A%E5%90%88">3.5.1.3 数据帧、分片和聚合</a></li>
</ul>
</li>
<li><a href="#352-%E7%9C%81%E7%94%B5%E6%A8%A1%E5%BC%8F%E5%92%8C%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5%E5%8A%9F%E8%83%BD">3.5.2 省电模式和时间同步功能</a></li>
<li><a href="#353-80211-%E4%BB%8B%E8%B4%A8%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6">3.5.3 802.11 介质访问控制</a>
<ul>
<li><a href="#3531-%E8%99%9A%E6%8B%9F%E8%BD%BD%E6%B3%A2%E4%BE%A6%E5%90%AC-rtscts-%E5%92%8C%E7%BD%91%E7%BB%9C%E5%88%86%E9%85%8D%E5%90%91%E9%87%8F">3.5.3.1 虚拟载波侦听、RTS/CTS 和网络分配向量</a></li>
<li><a href="#3532-%E7%89%A9%E7%90%86%E8%BD%BD%E6%B3%A2%E4%BE%A6%E5%90%ACcca">3.5.3.2 物理载波侦听（CCA）</a></li>
<li><a href="#3533-dcf-%E5%86%B2%E7%AA%81%E9%81%BF%E5%85%8D%E9%80%80%E9%81%BF%E8%BF%87%E7%A8%8B">3.5.3.3 DCF 冲突避免/退避过程</a></li>
<li><a href="#3534-hcf-%E5%92%8C-80211en-%E7%9A%84-qos">3.5.3.4 HCF 和 802.11e/n 的 QoS</a></li>
</ul>
</li>
<li><a href="#354-%E7%89%A9%E7%90%86%E5%B1%82%E7%9A%84%E7%BB%86%E8%8A%82%E9%80%9F%E7%8E%87-%E4%BF%A1%E9%81%93%E5%92%8C%E9%A2%91%E7%8E%87">3.5.4 物理层的细节：速率、信道和频率</a>
<ul>
<li><a href="#3541-%E4%BF%A1%E9%81%93%E5%92%8C%E9%A2%91%E7%8E%87">3.5.4.1 信道和频率</a></li>
<li><a href="#3542-%E6%9B%B4%E9%AB%98%E5%90%9E%E5%90%90%E9%87%8F%E7%9A%84-80211802211n">3.5.4.2 更高吞吐量的 802.11/8022.11n</a></li>
</ul>
</li>
<li><a href="#355-wi-fi-%E5%AE%89%E5%85%A8">3.5.5 Wi-Fi 安全</a></li>
<li><a href="#356-wi-fi-%E7%BD%91%E7%8A%B6%E7%BD%9180211s">3.5.6 Wi-Fi 网状网（802.11s）</a></li>
</ul>
</li>
<li><a href="#36-%E7%82%B9%E5%88%B0%E7%82%B9%E5%8D%8F%E8%AE%AE">3.6 点到点协议</a>
<ul>
<li><a href="#361-%E9%93%BE%E8%B7%AF%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE">3.6.1 链路控制协议</a>
<ul>
<li><a href="#3611-lcp-%E6%93%8D%E4%BD%9C">3.6.1.1 LCP 操作</a></li>
<li><a href="#3612-lcp-%E9%80%89%E9%A1%B9">3.6.1.2 LCP 选项</a></li>
</ul>
</li>
<li><a href="#362-%E5%A4%9A%E9%93%BE%E8%B7%AF-ppp">3.6.2 多链路 PPP</a></li>
<li><a href="#363-%E5%8E%8B%E7%BC%A9%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE">3.6.3 压缩控制协议</a></li>
<li><a href="#364-ppp-%E8%AE%A4%E8%AF%81">3.6.4 PPP 认证</a></li>
<li><a href="#365-%E7%BD%91%E7%BB%9C%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE">3.6.5 网络控制协议</a></li>
<li><a href="#366-%E5%A4%B4%E9%83%A8%E5%8E%8B%E7%BC%A9">3.6.6 头部压缩</a></li>
<li><a href="#367-%E4%BE%8B%E5%AD%90">3.6.7 例子</a></li>
</ul>
</li>
<li><a href="#37-%E7%8E%AF%E5%9B%9E">3.7 环回</a></li>
<li><a href="#38-mtu-%E5%92%8C%E8%B7%AF%E5%BE%84-mtu">3.8 MTU 和路径 MTU</a></li>
<li><a href="#39-%E9%9A%A7%E9%81%93%E5%9F%BA%E7%A1%80">3.9 隧道基础</a>
<ul>
<li><a href="#391-%E5%8D%95%E5%90%91%E9%93%BE%E8%B7%AF">3.9.1 单向链路</a></li>
</ul>
</li>
<li><a href="#310-%E4%B8%8E%E9%93%BE%E8%B7%AF%E5%B1%82%E7%9B%B8%E5%85%B3%E7%9A%84%E6%94%BB%E5%87%BB">3.10 与链路层相关的攻击</a></li>
<li><a href="#311-%E6%80%BB%E7%BB%93">3.11 总结</a></li>
<li><a href="#312-%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE">3.12 参考文献</a></li>
</ul>
</li>
</ul>

  </div>
</div>

<script>

  let lastTop = 0, lList = [], hList = [], postBody, lastIndex = -1;
  let active = 'active-show', activeClass = 'active-current';
  let tocWrapper = document.querySelector('#toc_wrapper');
  let tocContent = tocWrapper.children[0];
  let autoNumber = tocWrapper && tocWrapper.classList.contains('auto-number');

  function addTocNumber(elem, deep) {
    if (!elem) {
      return;
    }
    let prop = elem.__proto__;

    if (prop === HTMLUListElement.prototype) {
      for (let i = 0; i < elem.children.length; i++) {
        addTocNumber(elem.children[i], deep + (i + 1) + '.');
      }
    } else if (prop === HTMLLIElement.prototype) {
      // 保存li元素
      if (elem.children[0].__proto__ === HTMLAnchorElement.prototype) {
        lList.push(elem);
      }
      for (let i = 0; i < elem.children.length; i++) {
        let cur = elem.children[i];
        if (cur.__proto__ === HTMLAnchorElement.prototype) {
          if (autoNumber) {
            cur.text = deep + ' ' + cur.text;
          }
        } else if (cur.__proto__ === HTMLUListElement.prototype) {
          addTocNumber(cur, deep);
        }
      }
    }
  }

  function removeParentActiveClass() {
    let parents = tocContent.querySelectorAll('.' + active)
    parents.forEach(function (elem) {
      elem.classList.remove(active);
    });
  }

  function addActiveClass(index) {
    if (index >= 0 && index < hList.length) {
      lList[index].classList.add(activeClass);
    }
  }

  function removeActiveClass(index) {
    if (index >= 0 && index < hList.length) {
      lList[index].classList.remove(activeClass);
    }
  }

  function addActiveLiElemment(elem, parent) {
    if (!elem || elem === parent) {
      return;
    } else {
      if (elem.__proto__ === HTMLLIElement.prototype) {
        elem.classList.add(active);
      }
      addActiveLiElemment(elem.parentElement, parent);
    }
  }

  function showToc() {
    if (tocWrapper) {
      postBody = document.querySelector('#post_body');
      for (let i = 0; i < postBody.children.length; i++) {
        if (postBody.children[i].__proto__ === HTMLHeadingElement.prototype) {
          hList.push(postBody.children[i]);
        }
      }
      if (tocWrapper.classList.contains('compress')) {
        tocContent.classList.add('closed');
      } else if (tocWrapper.classList.contains('no_compress')) {
        tocContent.classList.add('expanded');
      } else {
        if (hList.length > 10) {
          active = 'active-hidden'
          tocContent.classList.add('closed');
        } else {
          tocContent.classList.add('expanded');
        }
      }
    }
  }

  (function () {
    // 处理不是从#一级标题开始目录
    if (tocContent.children.length === 1 && tocContent.children[0].__proto__ === HTMLLIElement.prototype) {
      let con = tocContent.children[0].children[0];
      tocContent.innerHTML = con.innerHTML;
    }
    let markdownItTOC = document.querySelector('.markdownIt-TOC');
    let innerHeight = window.innerHeight;
    markdownItTOC.style = `max-height: ${innerHeight - 80 > 0 ? innerHeight - 80 : innerHeight}px`
    addTocNumber(tocContent, '');
  })();

  document.addEventListener('scroll', function (e) {
    if (lList.length <= 0) {
      return;
    }
    let scrollTop = document.scrollingElement.scrollTop + 10;
    let dir;

    if (lastTop - scrollTop > 0) {
      dir = 'up';
    } else {
      dir = 'down';
    }

    lastTop = scrollTop;
    if (scrollTop <= 0) {
      if (lastIndex >= 0 && lastIndex < hList.length) {
        lList[lastIndex].classList.remove(activeClass);
      }
      return;
    }

    let current = 0, hasFind = false;
    for (let i = 0; i < hList.length; i++) {
      if (hList[i].offsetTop > scrollTop) {
        current = i;
        hasFind = true;
        break;
      }
    }
    if (!hasFind && scrollTop > lList[lList.length - 1].offsetTop) {
      current = hList.length - 1;
    } else {
      current--;
    }
    if (dir === 'down') {
      if (current > lastIndex) {
        addActiveClass(current);
        removeActiveClass(lastIndex)
        lastIndex = current;
        removeParentActiveClass();
        lList[current] && addActiveLiElemment(lList[current].parentElement, tocContent);
      }
    } else {
      if (current < lastIndex) {
        addActiveClass(current);
        removeActiveClass(lastIndex);
        lastIndex = current;
        removeParentActiveClass();
        lList[current] && addActiveLiElemment(lList[current].parentElement, tocContent);
      }
    }
  });


  window.addEventListener('load', function () {
    showToc();
    document.querySelector('#sidebar').style = 'display: block;';
    tocWrapper.classList.add('toc-active');
    setTimeout(function () {
      if ("createEvent" in document) {
        let evt = document.createEvent("HTMLEvents");
        evt.initEvent("scroll", false, true);
        document.dispatchEvent(evt);
      }
      else {
        document.fireEvent("scroll");
      }
    }, 500)
  })

</script>
            </div>
          
        
      </div>
    </div>
  
</div>
<script>
  const SIDEBAR_TITLE_ACTIVE = 'sidebar-title-active';
  const SIDEBAR_BODY_ACTIVE = 'sidebar-body-active';
  const SLIDE_UP_IN = 'slide-up-in';

  let sidebar = document.querySelector('#sidebar'),
  tocSideBar = document.querySelector('#tocSideBar'),
  metaSideBar = document.querySelector('#metaSideBar'),
  postToc = document.querySelector('#post_toc'),
  postSiteMeta = document.querySelector('#post_side_meta'),
  sidebarTitle = document.querySelector('.sidebar-title'),
  sidebarBody = document.querySelector('#sidebar_body');

  tocSideBar && tocSideBar.addEventListener('click', (e) => {
    toggleSidebar(e);
  });

  metaSideBar && metaSideBar.addEventListener('click', (e) => {
    toggleSidebar(e);
  });

  function toggleSidebar(e) {
    let currentTitle = document.querySelector("."+SIDEBAR_TITLE_ACTIVE);
    if (currentTitle == e.srcElement) {
      return ;
    }
    let current, showElement, hideElement;
    if (e.srcElement == metaSideBar) {
      showElement = postSiteMeta;
      hideElement = postToc;
    } else if (e.srcElement == tocSideBar){
      showElement = postToc;
      hideElement = postSiteMeta;
    }
    currentTitle.classList.remove(SIDEBAR_TITLE_ACTIVE);
    e.srcElement.classList.add(SIDEBAR_TITLE_ACTIVE);

    window.Velocity(hideElement, 'stop');
    window.Velocity(hideElement, 'transition.slideUpOut', {
      display: 'none',
      duration: 200,
      complete: function () {
        window.Velocity(showElement, 'transition.slideDownIn', {
          duration: 200
        });
      }
    })
    hideElement.classList.remove(SIDEBAR_BODY_ACTIVE);
    showElement.classList.add(SIDEBAR_BODY_ACTIVE);
  }

  postToc && postToc.addEventListener('transitionend', function() {
    this.classList.remove(SLIDE_UP_IN);
  });

  if (sidebarBody) {
    if (sidebarBody.classList.contains('pisces') || sidebarBody.classList.contains('gemini')) {
      let hasFix = false;
      let scrollEl = document.querySelector('.main-continer');
      let limitTop = document.querySelector('#nav_ul').children.length * 42 + 162;
      window.addEventListener('scroll', function(e) {
        if (document.scrollingElement.scrollTop >= limitTop) {
          if (!hasFix) {
            sidebar.classList.add('sidebar-fixed');
            hasFix = true;
          }
        } else {
          if (hasFix) {
            sidebar.classList.remove('sidebar-fixed');
            hasFix = false;
          }
        }
      });
    }
  }
  
</script>
        <div class="section-box box-shadow-wrapper">
          <div class="section bg-color post post-page">
            <header class="post-header">
  <h1 class="post-title">
    <a class="post-title-link" href="https://wenbozhangw.github.io/post/lesslesstcpip-xiang-jie-juan-yi-xie-yi-greatergreater-di-san-zhang-lian-lu-ceng/">
      《TCP/IP 详解 卷一：协议》第三章：链路层
    </a>
  </h1>
  <div class="post-meta">
    
    <span class="meta-item pc-show">
      <i class="fa fa-calendar-o"></i>
      <span>发布于</span>
      <span>2022-04-28</span>
      <span class="post-meta-divider pc-show">|</span>
    </span>
    
    <span class="meta-item">
      <i class="fa fa-folder-o"></i>
      <span class="pc-show">分类于</span>
      
      
      <a href="https://wenbozhangw.github.io/tag/NhO-Hr8Eu/">
        <span>TCP/IP</span>
      </a>
      
      
    </span>
    <span class="post-meta-divider">|</span>
    
    <span class="meta-item">
      <i class="fa fa-clock-o"></i>
      <span>189分钟</span>
    </span>
    <span class="meta-item">
      <span class="post-meta-divider">|</span>
      <i class="fa fa-file-word-o"></i>
      <span>48811<span class="pc-show">字数</span></span>
    </span>
    
  </div>
</header>
            <div class="post-body next-md-body" id="post_body">
              <h2 id="31-引言">3.1 引言</h2>
<p>在第 1 章中，我们知道 TCP/IP 协议族中设计链路层的目的是为 IP 模块发送和接收 IP 数据报。它可用于携带一些支持 IP 的辅助性协议，例如 ARP （见第 4 章）。 TCP/IP 支持多种不同的链路层，它依赖于使用的网络硬件类型：有线局域网，例如以太网；<strong>城域网（MAN）</strong>，例如服务供应商提供的有线电视和 DSL 连接；有线语音网络，例如支持调制解调器的电话线；无线网络，例如Wi-Fi （无线局域网）；基于蜂窝技术的各种无线数据服务，例如 HSPA、EV-DO、LTE 和 WiMAX。在本章中，我们将详细讨论以下内容：在以太网和 Wi-Fi 的链路层中，如何使用<strong>点到点协议（PPP）</strong>，如何在其他（链路或更高层）协议中携带链路层协议，以及一种称为隧道的技术等。详细描述当前使用的每种链路技术需要专门一本书才行，因此我们将注意力集中在一些常用的链路层协议，以及 TCP/IP 中如何使用它们。</p>
<p>大多数链路层技术都有一个相关的协议，描述由网络硬件传输的相应 PDU 格式。在描述链路层的 PDU 时，我们通常使用术语<strong>帧</strong>，以区分那些更高层的 PDU 格式，例如描述网络层和传输层 PDU 的分组和段。帧格式通常支持可变的帧长度，范围从几字节到几千字节。这个范围的上限称为<strong>最大传输单元（MTU）</strong>，我们将在后续章节中提到链路层的这一特点。有些网络技术（例如调制解调器和串行线路）不强制规定最大的帧，因此它们可以由用户来配置。</p>
<h2 id="32-以太网和-ieee-802-局域网城域网标准">3.2 以太网和 IEEE 802 局域网/城域网标准</h2>
<p><strong>以太网</strong>这个术语通常指一套标准，由 DEC、 Intel 公司和 Xerox 公司在 1980 年首次发布，并在 1982 年加以修订。第一个常见格式的以太网，目前被称为“10Mb/s 以太网”或“共享以<br>
太网”，它被 IEEE 采纳（轻微修改）为 802.3 标准。这种网络的结构通常如图 3-1 所示。</p>
<figure data-type="image" tabindex="1"><img src="https://wenbozhangw.github.io//post-images/1651118328245.png" alt="图 3-1" loading="lazy"></figure>
<p>图 3-1   基本的共享以太网包含一个或多个站（例如工作站、超级计算机），它们都被连接到一个共享的电缆段上。当介质被确定为空闲状态时，链路层的 PDU（帧）可以从一个站发送到一个或更多其他站。如果多个站同时发送数据，可能因信号传播延迟而发生碰撞。碰撞可以被检测到，它会导致发送站等待一个随机事件，然后重新发送数据。这种常见的方法称为带冲突检测的载波侦听多路访问</p>
<p>由于多个站共享同一网络，该标准需要在每个以太网接口实现一种分布式算法，以控制一个站发送自己的数据。这种特定方法称为<strong>带冲突（或称碰撞）检测的载波侦听多路访问（CSMA/CD）</strong>，它协调哪些计算机可访问共享的介质（电缆），同时不需要其他特殊协议或同步。这种相对简单的方法有助于降低成本和促进以太网投术普及。</p>
<p>采用 CSMA/CD，一个站（例如计算机）首先检测目前网络上正在发送的信号，并在网络空闲时发送自己的帧。这是协议中的“载波侦听”部分。如果其他站碰巧同时发送，发生重叠的电信号被检测为一次碰撞。在这种情况下，每个站等待一个随机时间，然后再次尝试发送。这个时间量的选择依据一个统一的概率分布，随后每个碰撞被检测到的时间长度加倍。最终，每个站会得到机会发送，或者在尝试一定次数（传统以太网为 16）后超时。采用 CSMA/CD，在任何给定的时间内，网络中只能有一个帧传输。如 CSMA/CD 这样的访问方法更正式的名称为<strong>介质访问控制(MAC)协议</strong>。 MAC 协议有很多类型，有些基于每个站尝试独立使用网络（例如 CSMA/CD 的基于竞争的协议），有些基于预先安排的协调（例如依据为每个站分配的时段发送） 。</p>
<p>随着 10Mb/s 以太网的发展，更快的计算机和基础设施使得局域网速度不断提升。由于以太网的普及，已取得以下显著创新和成果：其速度从 10Mb/s 增加到 100Mb/s、 1000Mb/s、10Gb/s，现在甚至更高。 10Gb/s 技术在大型数据中心和大型企业中越来越普遍，并且已被证实可达到 100Gb/s 的速度。最早（研究）的以太网速度为 3Mb/s，但 DIX （Digital、 Intel、 Xerox）标准可达到 10Mb/s，它在一条共享的物理电缆或由电子中继器互联的一组电缆上运行。 20 世纪 90 年代初，共享的电缆已在很大程度上被双绞线（类似电话线，通常称为“10BASE-T”）代替。随着 100Mb/s （也称为“快速以太网”，最流行的版本是“100BASE-TX”）的发展，基于竞争的 MAC 协议已变得不流行。相反，局域网中每个站之间的线路通常不共享，而是提供了一个专用的星形拓扑结构。这可以通过以太网<strong>交换机</strong>来实现，如图 3-2 所示</p>
<figure data-type="image" tabindex="2"><img src="https://wenbozhangw.github.io//post-images/1651120249525.png" alt="图 3-2" loading="lazy"></figure>
<p>图 3-2   一个交换式以太网包含一个或多个站，每个站使用一条专用的线路连接到一个交换机端口。在大多数情况下，交换式以太网以全双工方式运行，并且不需要使用 CSMA/CD 算法。交换机可以通过交换机端口级联形成更大的以太网，该端口有时也称为“上行”端口</p>
<p>目前，交换机为以太网中的每个站提供同时发送和接收数据的能力（称为“全双工以太网”）。虽然 1000Mb/s 以太网（1000BASE-T）仍支持半双工（一次一个方向）操作，但相对于全双工以太网来说，它很少使用。下面我们将详细讨论交换机如何处理 PDU。</p>
<p>当前连接 Internet 的最流行技术之一是无线网络，常见的无线局域网（WLAN） IEEE 标准称为无线保真或 Wi-Fi，有时也称为“无线以太网”或 802.11。虽然这个标准与 802 有线以太网标准不同，但帧格式和通用接口大部分来自 802.3，并且都是 IEEE 802 局域网标准的一部分。因此， TCP/IP 用于以太网的大部分功能，也可用于 Wi-Fi 网络。我们将详细探讨这些功能。首先，我们描绘一个建立家庭和企业网络的所有 IEEE 802 标准的蓝图。这里也包括那些涉及城域网的 IEEE 标准，例如 IEEE 802.16（WiMAX）和蜂窝网络中的异构网络无缝切换标准（IEEE 802.21）。</p>
<h3 id="321-ieee-802-局域网城域网标准">3.2.1 IEEE 802 局域网/城域网标准</h3>
<p>原始的以太网帧格式和工作过程由前面提到的行业协议所描述。这种格式被称为 DIX 格式或 Ethernet II 格式。对这种类型的以太网稍加修改后，由 IEEE 标准化为一种 CSMA/CD 网络，称为 802.3。在 IEEE 标准中，带 802 前缀的标准定义了局域网和城域网的工作过程。当前最流行的 802 标准包括 802.3 （以太网）和 802.11（WLAN/Wi-Fi）。这些标准随着时间推移而演变，经过独立修订后名称发生改变（例如 802.11g），并最终被纳入修订过的标准。表 3-1 显示了一个相当完整的列表，包括截至 2011 年年中支持 TCP/IP 的相关 IEEE 802 局域网和城域网标准。</p>
<center>表 3-1   有关 TCP/IP 协议的局域网和城域网 IEEE 802 标准（2011）</center>
<table>
<thead>
<tr>
<th>名称</th>
<th>描述</th>
<th>官方参考</th>
</tr>
</thead>
<tbody>
<tr>
<td>802.1ak</td>
<td>多注册协议（MRP）</td>
<td>[<a href="#802.1AK-2007">802.1AK-2007</a>]</td>
</tr>
<tr>
<td>802.1AE</td>
<td>MAC 安全（MACSec）</td>
<td>[<a href="#802.AE-2006">802.AE-2006</a>]</td>
</tr>
<tr>
<td>802.1AX</td>
<td>链路聚合（以前的 802.3ad）</td>
<td>[<a href="#802.AX-2008">802.AX-2008</a>]</td>
</tr>
<tr>
<td>802.1d</td>
<td>MAC 网桥</td>
<td>[<a href="#802.1D-2004">802.1D-2004</a>]</td>
</tr>
<tr>
<td>802.1p</td>
<td>流量类/优先级/QoS</td>
<td>[<a href="#802.1D-2004">802.1D-2004</a>]</td>
</tr>
<tr>
<td>802.1q</td>
<td>虚拟往前的局域网/MRP的更正</td>
<td>[<a href="#802.1Q-2005/Corl-2008">802.1Q-2005/Corl-2008</a>]</td>
</tr>
<tr>
<td>802.1s</td>
<td>多生成树协议（MSTP）</td>
<td>[<a href="#802.1Q-2005">802.1Q-2005</a>]</td>
</tr>
<tr>
<td>802.1w</td>
<td>快速生成树协议（RSTP）</td>
<td>[<a href="#802.1D-2004">802.1D-2004</a>]</td>
</tr>
<tr>
<td>802.1X</td>
<td>基于端口的网络控制访问（PNAC）</td>
<td>[<a href="#802.1X-2010">802.1X-2010</a>]</td>
</tr>
<tr>
<td>802.2</td>
<td>逻辑链路控制（LLC）</td>
<td>[<a href="#802.2-1998">802.2-1998</a>]</td>
</tr>
<tr>
<td>802.3</td>
<td>基本以太网和 10 Mb/s 以太网</td>
<td>[<a href="#802.3-2008">802.3-2008</a>] （第 1 节）</td>
</tr>
<tr>
<td>802.3u</td>
<td>100 Mb/s 以太网（“快速以太网”）</td>
<td>[<a href="#802.3-2008">802.3-2008</a>] （第 2 节）</td>
</tr>
<tr>
<td>802.3x</td>
<td>全双工运行和流量控制</td>
<td>[<a href="#802.3-2008">802.3-2008</a>]</td>
</tr>
<tr>
<td>802.3z/802.3ab</td>
<td>1000 Mb/s 以太网（“千兆以太网”）</td>
<td>[<a href="#802.3-2008">802.3-2008</a>] （第 3 节）</td>
</tr>
<tr>
<td>802.3ae</td>
<td>10 Gb/s 以太网</td>
<td>[<a href="#802.3-2008">802.3-2008</a>] （第 4 节）</td>
</tr>
<tr>
<td>802.3ad</td>
<td>链路聚合</td>
<td>[<a href="#802.1AX-2008">802.1AX-2008</a>]</td>
</tr>
<tr>
<td>802.3af</td>
<td>以太网供电（PoE，15.4W）</td>
<td>[<a href="#802.3-2008">802.3-2008</a>] （第2 节）</td>
</tr>
<tr>
<td>802.3ah</td>
<td>以太网接入（第一公里以太网）</td>
<td>[<a href="#802.3-2008">802.3-2008</a>] （第 5 节）</td>
</tr>
<tr>
<td>802.3as</td>
<td>帧格式扩展（2000 字节）</td>
<td>[<a href="#802.3-2008">802.3-2008</a>]</td>
</tr>
<tr>
<td>802.3at</td>
<td>以太网供电增强（“PoE+”，30W）</td>
<td>[<a href="#802.3at-2009">802.3at-2009</a>]</td>
</tr>
<tr>
<td>802.3ba</td>
<td>40/100Gb/s 以太网</td>
<td>[<a href="#802.3ba-2010">802.3ba-2010</a>]</td>
</tr>
<tr>
<td>802.11a</td>
<td>运行在 5GHz 的 54Mb/s 的无线局域网</td>
<td>[<a href="#802.11-2007">802.11-2007</a>]</td>
</tr>
<tr>
<td>802.11b</td>
<td>运行在 2.4GHz 的 11Mb/s 的无线局域网</td>
<td>[<a href="#802.11-2007">802.11-2007</a>]</td>
</tr>
<tr>
<td>802.11e</td>
<td>针对 802.11 的 QoS 增强</td>
<td>[<a href="#802.11-2007">802.11-2007</a>]</td>
</tr>
<tr>
<td>802.11g</td>
<td>运行在 2.4GHz 的 54Mb/s 的无线局域网</td>
<td>[<a href="#802.11-2007">802.11-2007</a>]</td>
</tr>
<tr>
<td>802.11h</td>
<td>频谱/电源管理扩展</td>
<td>[<a href="#802.11-2007">802.11-2007</a>]</td>
</tr>
<tr>
<td>802.11i</td>
<td>安全增强/代替 WEP</td>
<td>[<a href="#802.11-2007">802.11-2007</a>]</td>
</tr>
<tr>
<td>802.11j</td>
<td>运行在 4.9 ~ 5.0GHz（日本）</td>
<td>[<a href="#802.11-2007">802.11-2007</a>]</td>
</tr>
<tr>
<td>802.11n</td>
<td>预先在 2.4GHz 和 5GHz 的 6.5 ~ 600Mb/s 的无线局域网，<br/>使用可选的 MIMO 和 40MHz 管道</td>
<td>[<a href="#802.11n-2009">802.11n-2009</a>]</td>
</tr>
<tr>
<td>802.11s（草案）</td>
<td>网状网，拥塞控制</td>
<td>开发中</td>
</tr>
<tr>
<td>802.11y</td>
<td>运行在 3.7GHz 的 54Mb/s 的无线局域网（许可的）</td>
<td>[<a href="#802.11y-2008">802.11y-2008</a>]</td>
</tr>
<tr>
<td>802.16</td>
<td>微波存取全球互通技术（WiMAX）</td>
<td>[<a href="#802.16-2009">802.16-2009</a>]</td>
</tr>
<tr>
<td>802.16d</td>
<td>固定的无线城域网标准（WiMAX）</td>
<td>[<a href="#802.16-2009">802.16-2009</a>]</td>
</tr>
<tr>
<td>802.16e</td>
<td>固定/移动的无限城域网标准（WiMAX）</td>
<td>[<a href="#802.16-2009">802.16-2009</a>]</td>
</tr>
<tr>
<td>802.16h</td>
<td>改进的共存机制</td>
<td>[<a href="#802.16h-2010">802.16h-2010</a>]</td>
</tr>
<tr>
<td>802.16j</td>
<td>802.16 中的多跳中继</td>
<td>[<a href="#802.16j-2009">802.16j-2009</a>]</td>
</tr>
<tr>
<td>802.16k</td>
<td>802.16 网桥</td>
<td>[<a href="#802.16k-2007">802.16k-2007</a>]</td>
</tr>
<tr>
<td>802.21</td>
<td>介质无关切换</td>
<td>[<a href="#802.21-2008">802.21-2008</a>]</td>
</tr>
</tbody>
</table>
<p>除了 802.3、 802.11、 802.16 标准定义的特定类型的局域网之外，还有一些相关标准适用于所有 IEEE 标准的局域网技术。最常见的是定义**逻辑链路控制（LLC）**的 802.2 标准，其帧头部在 802 网络的帧格式中常见。在 IEEE 的术语中， LLC 和 MAC 是链路层的“子层”，LLC （多数帧格式）对每种网络都是通用的，而 MAC 层可能有所不同。虽然最初的以太网使用 CSMA/CD，但无线局域网常使用  CSMA/CA （CA 是“冲突避免”）。</p>
<p>注意 不幸的是， 802.2 和 802.3 共同定义了与 Ethemet II 不同的帧格式，这个情况直到 802.3x 才最终纠正。它已经被纳入 [<a href="#802.3-2008">802.3-2008</a>] 。在 TCP/IP 世界中，[<a href="#RFC0894">RFC0894</a>] 和 [<a href="#RFC2464">RFC2464</a>] 定义了针对以太网的 IP 数据报封装，但旧的 LLC/SNAP 封装仍发布在 [<a href="#RFC1042">RFC1042</a>] 中。虽然这不再是一个大问题，但它曾经令人关注，并偶尔出现类似问题 [<a href="#RFC4840">RFC4840</a>]。</p>
<p>直到最近，帧格式在本质上还一直相同。为了获得该格式的详细信息，并了解它是如何演变的，我们现在将焦点转向这些细节。</p>
<h3 id="322-以太网帧格式">3.2.2 以太网帧格式</h3>
<p>所有的以太网（802.3）帧都基于一个共同的格式。在原有规范的基础上，帧格式已被改进以支持额外功能。图 3-3 显示了当前的以太网帧格式，以及它与 IEEE 提出的一个相对新的术语 IEEE 分组（一个在其他标准中经常使用的术语）的关系。</p>
<p>以太网帧开始是一个<strong>前导</strong>字段，接收器电路用它确定一个帧的到达时间，并确定编码位（称为<strong>时钟恢复</strong>）之间的时间量。由于以太网是一个异步的局域网（即每个以太网接口卡中不保持精确的时钟同步），从一个接口到另一个接口的编码位之间的间隔可能不同。前导是一个公认的模式（典型值为 <code>0xAA</code>），在发现**帧起始分隔符（SFD）**时，接收器使用它“恢复时钟”。 SFD 的固定值为 <code>0xAB</code>。</p>
<figure data-type="image" tabindex="3"><img src="https://wenbozhangw.github.io//post-images/1651207095547.png" alt="图 3-3" loading="lazy"></figure>
<p>图 3-3   以太网（IEEE802.3）帧格式包含一个源地址和目的地址、一个重载的<strong>长度/类型</strong>字段、一个数据字段和一个帧校验序列（CRC32）。另外，基本帧格式提供了一个标签，其中包含一个 VLAN ID 和优先级信息（802.1p/q），以及一个最近出现的可扩展标签。前导和 SFD 被用于接收器同步。当以太网以半双工模式运行在 100Mb/s 或以上速率时，其他位可能被作为载体扩展添加到短帧中，以确保冲突检测电路的正常运行</p>
<pre><code>注意  最初以太网的位编码使用两个电压等级的曼彻斯特相位编码（MPE）。通过 MPE，
每位被编码为电压变化，而不是绝对值。例如， 0 位被编码为从 -0.85V 到 +0.85V 的变化，
1 位被编码为从 +0.85V 到 -0.85V 的变化（0V 指共享线路处于空闲状态）。 10Mb/s 
以太网规范要求网络硬件使用 20MHz 振荡器，因为 MPE 的每位需要两个时钟周期。
字节 0xAA （二进制为10101010）在以太网的前导中，表示为一个 +0.85 和 -0.85V 之间
的 10MHz 频率的方波。在其他以太网标准中，曼彻斯特编码被替换为不同编码，以提高效率。
</code></pre>
<p>这个基本的帧格式包括 48 位（6 字节）的**目的地址（DST）<strong>和</strong>源地址（SRC）**字段。这些地址有时也采用其他名称，例如“MAC地址”、“链路层地址”、“802 地址”、“硬件地址”或“物理地址”。以太网帧的目的地址也允许寻址到多个站点（称为“广播”或“组播”，见第 9 章）。广播功能用于 ARP 协议（见第 4 章），组播功能用于 ICMPv6 协议（见第 8 章），以实现网络层地址和链路层地址之间的转换。</p>
<p>源地址后面紧跟着一个<strong>类型</strong>字段，或一个<strong>长度</strong>字段。在多数情况下，它用于确定头部后面的数据类型。 TCP/IP 网络使用的常见值包括IPv4 （<code>0x0800</code>）、 IPv6 （<code>0x86DD</code>）和 ARP （<code>0x0806</code>）。 <code>0x8100</code> 表示一个 Q 标签帧（可携带一个“虚拟局域网”或 802.1q 标准的 VLAN ID）。一个以太网帧的基本大小是 1518 字节，但最近的标准将该值扩大到 2000 字节。</p>
<pre><code>注意   最初的 IEEE （802.3）规范将长度/类型字段作为长度字段而不是类型字段使用。
因此，这个字段被重载（可用于多个目的）。关键是看字段值。目前，如果字段值大于
或等于 1536，则该字段表示类型，它是由标准分配的超过 1536 的值。如果字段值等于
或小于 1500，则该字段表示长度。 [ETHERTYPES] 给出了类型的完整列表。
</code></pre>
<p>在上述字段之后， [<a href="#802.3-2008">802.3-2008</a>] 提供了多种标签包含由其他 IEEE 标准定义的各种协议字段。其中，最常见的是那些由 802.1p 和 802.1q 使用的标签，它提供虚拟局域网和一些 **服务质量（Qos）**指示符。这些在 3.2.3 节讨论。</p>
<pre><code>注意   当前的 [802.3-2008] 标准采用修改后的 802.3 帧格式，提供最大为 482 字节的
“标签”，它携带在每个以太网帧中。这些较大的帧称为信封帧，长度最大可能达到
2000 字节。包含 802.1p/q 标签的帧称为 Q 标签帧，也是信封帧。但是，并非所有
信封帧必然是 Q 标签帧。
</code></pre>
<p>在这些讨论过的字段之后，是帧的数据区或<strong>有效载荷</strong>部分。这里是放高层 PDU （例如IP数据报）的地方。传统上，以太网的有效载荷一直是 1500 字节，它代表以太网的 MTU。 目前，大多数系统为以太网使用 1500 字节的 MTU，虽然在必要时它也可设置为一个较小的值。有效载荷有时被<strong>填充</strong>（添加）数个 0，以确保帧总体长度符合最小长度要求，这些我们将在 3.2.2.2 节讨论。</p>
<h4 id="3221-帧校验序列循环冗余校验">3.2.2.1 帧校验序列/循环冗余校验</h4>
<p>在以太网帧格式中，有效载荷区域之后的最后字段提供了对帧完整性的检查。<strong>循环冗余校验（CRC）<strong>字段位于尾部，有 32 位，有时称之为 IEEE/ANSI 标准的 CRC32 [<a href="#802.3-2008">802.3-2008</a>]。要使用一个 n 位 CRC 检测数据传输错误，被检查的消息首先需要追加 n 位 0 形成一个</strong>扩展消息</strong>。然后，扩展消息（使用模 2 除法）除以一个（n + 1）位的值，这个作为除数的值称为<strong>生成多项式</strong>。放置在消息的 CRC 字段中的值是这次除法计算中余数的二进制反码（商被丢弃）。生成多项式已被标准化为一系列不同的 n 值。以太网使用 <code>n=32</code>， CRC32 的生成多项式是 33 位的二进制数<code>100000100110000010001110110110111</code>。为了理解如何使用（mod 2）二进制除法计算<br>
余数，我们看一个 CRC4 的简单例子。国际电信联盟（ITU）将 CRC4 的生成多项式值标准化为<code>10011</code>，这是在 G.704 [<a href="#G704">G704</a>] 标准中规定的。如果我们要发送 16 位的消息<br>
<code>1001111000101111</code>，首先开始进行图 3-4 所示的（mod2）二进制除法。</p>
<figure data-type="image" tabindex="4"><img src="https://wenbozhangw.github.io//post-images/1652281247055.png" alt="图 3-4" loading="lazy"></figure>
<p>图 3-4   长（mod2）二进制除法延时了 CRC4 的计算过程</p>
<p>在该图中，我们看到这个除法的余数是 4 位的值 <code>1111</code>。通常，该余数的反码（0000）将放置在帧的 CRC 或**帧校验序列（FCS）**字段中。在接收到数据之后，接收方执行相同的除法计算出余数，并判断该值与 FCS 字段的值是否匹配。如果两者不匹配，帧可能在传输过程中受损，通常被丢弃。 CRC 功能可用于提示信息受损，因为位模式的任何改变极可能导致余数的改变。</p>
<h4 id="3222-帧大小">3.2.2.2 帧大小</h4>
<p>以太网帧有最小和最大尺寸。最小的帧是 64 字节，要求数据区（有效载荷）长度（无标签）最小为 48 字节。当有效载荷较小时，填充字节（值为0）被添加到有效载荷尾部，以确保达到最小长度。</p>
<pre><code>注意   最小长度对最初的 10Mb/s 以太网的 CSMA/CD 很重要。为了使传输数据的
站能知道哪个帧发生了冲突，将一个以太网的最大长度限制为 2500m（通过4个
中继器连接的 5 个 500m 的电缆段）。根据电子在铜缆中传播速度约为 0.77c （约
2.31×108m/s），可得到 64 字节采用 10Mb/s 时的传输时间为 64×8/10000000=
51.2 μs，最小尺寸的帧能在电缆中传输约 11000m。如果采用一条最长为 2500m 
的电缆，从一个站到另一个站之间的最大往返距离为 5000m。以太网设计者确定最
小帧长度基于安全因素，在完全兼容（和很多不兼容）的情况下，一个输出帧的最
后位在所需时间后仍处于传输过程中，这个时间是信号到达位于最大距离的接收器
并返回的时间。如果这时检测到一个冲突，传输中的站能知道哪个帧发生冲突，即
当前正在传输中的那个帧。在这种情况下，该站发送一个干扰信号（高电压）提醒
其他站，然后启动一个随机的二进制指数退避过程。
</code></pre>
<p>传统以太网的最大帧长度是 1518 字节（包括 4 字节 CRC 和 14 字节头部）。选择这个值出于一种折中：如果一个帧中包括一个错误（接收到不正确的 CRC 校验），只需重发 1.5kB 以修复该问题。另一方面， MTU 大小限制为 1500 字节。为了发送一个更大的消息，则需要多个帧（例如，对于 TCP/IP 网络常用的较大尺寸 64KB，需要至少 44 个帧）。</p>
<p>由多个以太网帧构成一个更大的上层 PDU 的后果是，每个帧都贡献了一个固定开销（14 字节的头部和 4 字节的 CRC）。更糟的是，为了允许以太网硬件接收电路正确恢复来自网络的数据，并为其他站提供将自己的流量与已有流量区分开的机会，以太网帧在网络中不能无缝地压缩在一起。 Ethernet II 规范除了在帧开始处定义了 7 字节前导和 1 字节 SFD 之外，还指定了 12 字节的包间距（IPG）时间（10Mb/s 为9.6μs， 100Mb/s 为 960ns， 1000Mb/s 为 96ns， 10000Mb/s 为 9.6ns）。因此， Ethernet II 的每帧效率最多为 <code>1500/(12 + 8 + 14 + 1500 + 4)=0.975293</code>，约 98%。一种提高效率的方式是，在以太网中传输大量数据时，尽量使帧尺寸更大一些。这可采用以太网<strong>巨型帧</strong> [<a href="#JF">JF</a>] 来实现，它是一种非标准的以太网扩展（主要在 1000Mb/s 以太网交换机中使用），通常允许帧尺寸高达 9000 字节。有些环境使用的帧称为<strong>超级巨型帧</strong>，它们通常超过 9000 字节。在使用巨型帧时要谨慎，这些较大的帧无法与较小的 1518 字节的帧互操作，因为它们无法由大多数传统以太网设备处理。</p>
<h3 id="323-8021pq虚拟局域网和-qos-标签">3.2.3 802.1p/q：虚拟局域网和 QoS 标签</h3>
<p>随着交换式以太网的使用越来越多，位于同一以太网中的每台主机互连已成可能。这样做的好处是，任何主机都可直接与其他主机通信，它们使用 IP 和其他网络层协议，并很少或根本不需要管理员配置。另外，广播和组播流量（见第 9 章）被分发到所有希望接收的主机，而不必建立特殊的组播路由协议。虽然这是很多主机位于同一以太网的优势，但在很多主机使用广播时，广播到每台主机将带来大量网络流量，并出于某些安全因素可能要禁止任意站之间通信。</p>
<p>为了解决大型多用途交换网络运行中的问题， IEEE 采用一种称为**虚拟局域网（VLAN）**的功能扩展 802 LAN 标准，它被定义在 802.1q [<a href="#802.1Q-2005">802.1Q-2005</a>]标准中。兼容的以太网交换机将主机之间的流量分隔为常见的 VLAN。注意，正是由于这种分隔，连在同一交换机但在不同 VLAN 中的两台主机，它们之间的流量需要一台路由器来传递。已研发出交换机/路由器组合设备来满足这种需求，路由器性能最终得到改进以匹配 VLAN 交换性能。因此， VLAN 的吸引力已有所减弱，现代高性能路由器逐渐取代它们。尽管如此，它们仍在使用，在某些环境中仍受欢迎，因此有必要了解它们。</p>
<p>工作站到 VLAN 的映射有几种方法。通过端口分配 VLAN 是一种简单而常见的方法，交换机端口所连接的站被分配在一个特定 VLAN 中，这样连接的任意站就都成为 VLAN 中的成员。其他选择包括基于 MAC 地址的 VLAN，以太网交换机使用表将一个站的 MAC 地址映射到一个 VLAN。如果有些站改变它们的 MAC 地址（由于某些用户行为，有时需要这样做），它们可能变得难以管理。 IP 地址也可用作分配 VLAN 的基础。</p>
<p>当不同 VLAN 中的站连接在同一交换机时，交换机确保流量不在两个 VLAN 之间泄漏，无论这些站使用哪种类型的以太网接口。当多个 VLAN 跨越多个交换机（<strong>中继</strong>）时，在以太网帧发送到另一台交换机之前，需要使用 VLAN 来标记该帧的归属。本功能使用一个称为 <strong>VLAN标签</strong>（或头部）的标记，其中包含 12 位 <strong>VLAN 标识符</strong>（提供 4096 个 VLAN，但保留 VLAN 0 和 VLAN 4095）。它还包含支持 QoS 的 3 位优先级（定义在 802.1p 标准中），如图 3-3 所示。在很多情况下，管理员必须配置交换机端口，以便发送 802.1p/q 帧时能中继到适当的端口。为了使这项工作更加容易，有些交换机通过中继端口支持<strong>本地 VLAN</strong> 选项，这意味着未标记的帧默认与本地 VLAN 相关。中继端口用于互连带 VLAN 功能的交换机，其他端口通常用于直接连接工作站。有些交换机还支持专用的 VLAN 中继方法，例如思科 <strong>内部交换链路（ISL）</strong> 协议。</p>
<p>802.1p 规定了在帧中表示 QoS 标识符的机制。802.1p 头部包括一个 3 位优先级字段，它用于表明一个 QoS 级别。这个标准是 802.1q VLAN 标准的扩展。这两个标准可以一起工作，并在同一头部中共享某些位。它用 3 个有效位定义了 8 个服务级别。 0 级为最低优先级，用于传统的尽力而为的流量。 7 级为最高优先级，可用于关键路由或网管功能。这个标准规定了优先级如何被编码在分组中，但没指定如何控制哪些分组采用哪个级别，以及实现优先级服务的底层机制，这些可由具体的实现者来定义。因此，一个优先级流量相对于另一个的处理方式是由实现或供应商定义的。注意，如果 802.1p/q 头部中的 VLAN ID 字段被设置为 0， 802.1p 可以独立于 VLAN 使用。</p>
<p>控制 802.1p/q 信息的 Linux 命令是 <code>vconfig</code>。它可用来添加和删除虚拟接口，即与物理接口相关联的 VLAN ID。它也可用来设置 802.1p 优先级，更改虚拟接口确定方式，改变由特定 VLAN ID 标记的分组之间的映射，以及协议在操作系统中处理时如何划分优先级。下面的命令为 VLAN ID 为 2 的接口 eth1 添加、删除虚拟接口，修改虚拟接口的命名方式并添加新接口：</p>
<pre><code>Linux# vconfig add eth1 2
Added VLAN with VID == 2 to IF -:eth1:-
Linux# ifconfig eth1.2
ethl.2 Link encap:Ethernet HWaddr 00:04:5A:9F:9E:80
            BROADCAST MULTICAST MTU:1500 Metric:1
            RX packets:0 errors:0 dropped:0 overruns:0 frame:0
            TX packets:0 errors:0 dropped:0 overruns:0 carrier:O
            collisions:0 txqueuelen:0
            RX bytes:0 (0.0 b) TX bytes:0 (0.0 b)
Linux# vconfig rem eth1.2
Removed VLAN -:eth1.2:-
Linux# vconfig set_name_type VLAN_PLUS_VID
Set name-type for VLAN subsystem. Should be visible in
            /proc/net/vlan/config
Linux# vconfig add eth1 2
Added VLAN with VID == 2 to IF -:eth1:-
Linux# ifconfig vlan0002
vlan0002 Link encap:Ethernet HWaddr 00:04:5A:9F:9E:80
            BROADCAST MULTICAST MTU:1500 Metric:1
            RX packets:0 errors:0 dropped:0 overruns:0 frame:0
            TX packets:0 errors:0 dropped:0 overruns:0 carrier:O
            collisions:0 txqueuelen:0
            RX bytes:0 (0.0 b) TX bytes:0 (0.0 b)
</code></pre>
<p>这里，我们可以看到在 Linu x中，虚拟接口命名的默认方法是将相关物理接口与 VLAN ID 串联。例如， VLAN ID 2 与接口 eth1 关联为 eth1.2。这个例子还显示了另一种命名方法，VLAN 被枚举为名称  <code>vlan &lt;n&gt;</code>，其中 <code>&lt;n&gt;</code> 是 VLAN 的标识符。一旦这样设置， VLAN 设备发送帧会如期望的那样被标记为VLAN ID。我们可通过 Wireshark 看到，如图 3-5 所示。</p>
<figure data-type="image" tabindex="5"><img src="https://wenbozhangw.github.io//post-images/1652326011999.png" alt="图 3-5" loading="lazy"></figure>
<p>图 3-5   VLAN ID 标记的帧显示在 Wireshark 中。默认的列和设置已被修改，以显示 VLAN ID 和原始以太网地址</p>
<p>本图显示了一个在 VLAN 2 中传输的 ARP 分组（见第 4 章）。我们可以看到，该帧大小为 60 字节（不包括 CRC）。该帧用 Ethemet II 封装（类型 0x8100），表示一个 VLAN。另外，VLAN 头部表明该帧属于 VLAN 2，优先级为 0，并且是普通帧。其他字段如我们预期的是一个普通 ARP 分组。</p>
<h3 id="324-8021ax链路聚合以前的-8023ad">3.2.4 802.1AX：链路聚合（以前的 802.3ad）</h3>
<p>有些系统配备多个网络接口，具有 <strong>绑定（bonding）</strong> 或 <strong>链路聚合</strong> 能力。通过链路聚合，两个或更多接口被视为一个，通过冗余或将数据分割（分拆）到多个接口，提高性能并获得更好的可靠性。 IEEE修订的 802.1AX [<a href="#802.1AX-2008">802.1AX-2008</a>] 定义了最常用的链路聚合方法，以及可管理这些链路的<strong>链路聚合控制协议（LACP）</strong>。 LACP 使用一种特定格式的 IEEE 802 帧（称为LACPDU）。</p>
<p>以太网交换机支持的链路聚合是一个替代方案，它比支持更高速网络接口的性价比高。如果多个端口聚合能提供足够的带宽，则可能并不需要高速接口。链路聚合不仅可被网络交换机支持，而且可在一台主机上跨越多个<strong>网络接口卡（NIC）</strong>。在通常情况下，聚合的端口必须是同一类型，并工作在同一模式（半双工或全双工）下。</p>
<p>Linux 可实现跨越不同类型设备的链路聚合（绑定），使用以下命令：</p>
<pre><code>Linux# modporbe bonding
Linux# ifconfig bond0 10.0.0.111 netmask 255.255.255.128
Linux# ifenslave bond0 eth0 wlan0
</code></pre>
<p>这组命令中的第一个用于加载绑定驱动，它是一个支持链路聚合的特殊设备驱动程序。第二个命令使用 IPv4 地址来创建 bond0 接口。虽然 IP 相关信息对创建聚合接口不是必需的，但它是典型的。在 <code>ifenslave</code> 命令执行后，绑定设备 bond0 用 MASTER 标志来标记，而设备 eth0 和 wlan0 用 SLAVE 标志来标记：</p>
<pre><code>bond0 Link encap:Ethernet HWaddr 00:11:A3:00:2C:2A
            inet addr:10.0.0.111 Bcast:10.0.0.127 Mask:255.255.255.128
            inet6 addr: fe80::211:a3ff:fe00:2c2a/64 Scope:Link
            UP BROADCAST RUNNING MASTER MULTICAST MTU:1500 Metric:1
            RX packets:2146 errors:0 dropped:0 overruns:0 frame:0
            TX packets:985 errors:0 dropped:0 overruns:0 carrier:O
            collisions:18 txqueuelen:0
            RX bytes:281939 (275.3 Kib) TX bytes:141391 (138.0 Kib)
eth0 Link encap:Ethernet HWaddr 00:11:A3:00:2C:2A
            UP BROADCAST RUNNING SLAVE MULTICAST MTU:1500 Metric:1
            RX packets:1882 errors:0 dropped:0 overruns:0 frame:0
            TX packets:961 errors:0 dropped:0 overruns:0 carrier:O
            collisions:18 txqueuelen:1000
            RX bytes:244231 (238.5 Kib) TX bytes:136561 (133.3 Kib)
            Interrupt:20 Base address:0x6c00
wlan0 Link encap:Ethernet HWaddr 00:11:A3:00:2C:2A
            UP BROADCAST RUNNING SLAVE MULTICAST MTU:1500 Metric:1
            RX packets:269 errors:0 dropped:0 overruns:0 frame:0
            TX packets:24 errors:0 dropped:0 overruns:0 carrier:O
            collisions:18 txqueuelen:1000
            RX bytes:38579 (37.6 Kib) TX bytes:4830 (4.7 Kib)
</code></pre>
<p>在这个例子中，我们将一个有线以太网接口和一个 Wi-Fi 接口绑定在一起。为主设备 bond0 分配了 IPv4 地址信息，通常分配给两个独立接口之一，它默认使用第一个从设备的 MAC 地址。当 IPv4 流量通过 bond0 虚拟接口发送时，很可能使用不同的从设备来发送。在 Linux 中，当绑定的驱动程序被加载时，可使用系统提供的参数选择选项。例如，模式选项决定了能否做以下工作：在接口之间使用循环交付，一个接口作为另一个接口的备份使用，基于对 MAC 源地址和目的地址执行的异或操作选择接口，将帧复制到所有接口，执行 802.3ad 标准的链路聚合，或采用更先进的负载平衡选项。第二种模式用于高可用性系统，当一个链路停止运行时（由 MII 监控来检测；更多细节见 [<a href="#BOND">BOND</a>] ），这种系统将故障部分转移到冗余的网络基础设施上。第三种模式是基于流量的流向选择从接口。如果目的地完全不同，两个站之间的流量被固定到一个接口。在希望尽量少尝试重新排序，并保证多个接口负载平衡的情况下，这种模式可能是有效的。第四种模式针对容错。第五种模式用于支持 802.3ad 的交换机，在同类链路上实现动态聚合能力。</p>
<p>LACP 协议旨在通过避免手工配置，以简化链路聚合的建立工作。在 LACP “主角” （客户端）和“参与者” （服务器）启用后，它们通常每秒都会发送 LACPDU。 LACP 自动确定哪些成员链路可被聚合成一个<strong>链路聚合组（LAG）</strong>，并将它们聚合起来。这个过程的实现需要通过链路发送一系列信息（MAC地址、端口优先级、端口号和密钥）。一个接收站可比较来自其他端口的值，如果匹配就执行聚合。 LACP 协议的细节见[<a href="#802.1AX-2008">802.1AX-2008</a>]。</p>
<hr>
<h2 id="33-全双工-省电-自动协商和-8021x-流量控制">3.3 全双工、省电、自动协商和 802.1X 流量控制</h2>
<p>当以太网最初被开发出来时，它仅工作在半双工模式，并使用一条共享的电缆。也就是说，同一时间内只能在一个方向发送数据，因此在任何时间点只有一个站可发送一个帧。随着交换式以太网的发展，网络不再是单一的共享线路，而代之以很多链路的组合。因此，多个站之间可以同时进行数据交换。另外，以太网被修改为全双工操作，这样可以有效禁用冲突检测电路。这样也可以增加以太网的物理长度，因为半双工操作和冲突检测的相关时间约束被取消。</p>
<p>在 Linux 中， <code>ethtool</code> 程序可用于查询是否支持全双工，以及是否正在执行全双工操作。这个工具也可显示和设置以太网接口的很多属性：</p>
<pre><code>Linux# ethtool eth0
Settings for eth0:
            Supported ports: [ TP MII ]
            supported link modes: 10baseT/Half 10baseT/Full
                                100baseT/Half 100baseT/Full
            Supports auto-negotiation: Yes
            Advertised link modes: 10baseT/Half 10baseT/Full
                                100baseT/Half 100baseT/Full
            Advertised auto-negotiation: Yes
            Speed: 10Mb/s
            Duplex: Half
            Port: MII
            PHYAD: 24
            Transceiver: internal
            Auto-negotiation: on
            Current message level: 0x00000001 (1)
            Link detected: yes
Linux# ethtool eth1
Settings for eth1:
            Supported ports: [ TP ]
            supported link modes: 10baseT/Half 10baseT/Full
                                100baseT/Half 100baseT/Full
                                1000baseT/Full
            Supports auto-negotiation: Yes
            Advertised link modes: 10baseT/Half 10baseT/Full
                                100baseT/Half 100baseT/Full
                                1000baseT/Full
            Advertised auto-negotiation: Yes
            Speed: 100Mb/s
            Duplex: Full
            Port: Twisted Pair
            PHYAD: 0
            Transceiver: internal
            Auto-negotiation: on
            Supports Wake-on: umbg
            Wake-on: g
            Current message level: 0x00000007 (7)
            Link detected: yes
</code></pre>
<p>在这个例子中，第一个以太网接口（eth0）连接到一个半双工的 10Mb/s 网络。我们看到它能够<strong>自动协商</strong>，这是一种来源于 802.3u 的机制，使接口能交换信息（例如速度）和功能（例如半双工或全双工运行）。自动协商信息在物理层通过信号交换，它可在不发送或接收数据时发送。我们可以看到，第二个以太网接口（eth1）也支持自动协商，它的速率为 100Mb/s，工作模式为全双工。其他值（Port、PHYAD、 Transceiver）指出物理端口类型、地址，以及物理层电路在 NIC 内部还是外部。当前消息级别用于配置与接口操作模式相关的日志消息，它的行为由使用的驱动程序指定。我们在下面的例子讨论如何设置这些值。</p>
<p>在 Windows 中，我们可以看到以下细节，首先进入“控制面板”中的“网络连接”，然后在感兴趣的接口上单击鼠标右键并选择“属性”，然后单击“配置”框并选择“高级”选项卡。这时，将打开一个类似图 3-6 （这个例子来自 Windows 7 机器上的以太网接口）所示的对话框。</p>
<figure data-type="image" tabindex="6"><img src="https://wenbozhangw.github.io//post-images/1652338313157.png" alt="图 3-6" loading="lazy"></figure>
<p>图 3-6   Windows (7) 的网络接口属性的“高级”选项卡。该控件允许用户提供网络设备驱动程序的运行参数</p>
<p>在图 3-6 中，我们可看到通过适配器的设备驱动程序来配置的特殊功能。对于这个特殊的适配器和驱动程序， 802.1p/q 标签可启用或禁用，也可提供流量控制和唤醒功能（见 3.3.2 节）。我们可以手工设置速率和双工模式，或使用更典型的自动协商选项。</p>
<h3 id="331-双工不匹配">3.3.1 双工不匹配</h3>
<p>自动协商曾经有一些互操作性问题，特别是一台计算机及其相关的交换机端口使用不同的双工配置时，或者当自动协商只在链路的一端被禁用时。在这些情况下，可能会发生双工不匹配。令人惊讶的是，当这种状况发生时，连接不会完全失败，但可能带来显著的性能下降。当网络中出现中等程度的双向流量繁忙时（例如，在大数据传输期间），一个半双工接口会将输入的流量检测为冲突，从而触发以太网 MAC 的 CSMA/CD 的指数退避功能。同时，导致这个冲突的数据被丢弃，这可能需要更高层协议（例如 TCP）重传。因此，性能下降可能只在半双工接口发送数据，同时又有大量流量需要接收时才是明显的，站处于轻负载时通常不会发生这种情况。一些研究者已试图开发分析工具来检测这种问题 [<a href="#SC05">SC05</a>]。</p>
<h3 id="332-局域网唤醒wol-省电和魔术分组">3.3.2 局域网唤醒（WoL）、省电和魔术分组</h3>
<p>在 Linux 和 Windows 的例子中，我们看到一些电源管理方面的功能。** Windows 唤醒功能**和 <strong>Linux 唤醒</strong> 选项用于使网络接口或主机脱离低功耗（睡眠）状态，这是基于某类分组的传输来实现的。这种分组用来触发可配置的功率状态改变。在 Linux 中，用于唤醒的值可以是零，或者是多个用于低功耗状态唤醒的位，它们可以被以下几种帧所触发：任何物理层（PHY）活动（p）、发往站的单播帧（u）、组播帧（m）、广播帧（b）、 ARP 帧（a）、魔术分组帧（g），以及包括密码的魔术分组帧。这些都可以使用 <code>ethtool</code> 的选项来配置。例如，可以使用以下命令：</p>
<pre><code>Linux# ethtool -s eth0 wol umgb
</code></pre>
<p>当接收到任何 u、 m、 g 或 b 类型的帧时，这个命令将 eth0 设备配置为发送一个唤醒信号。Windows 提供了类似的功能，但标准的用户接口只支持魔术分组帧，以及一个预定义的 u、m、b和a类型帧的子集。魔术分组包含一个字节值 <code>0xFF</code> 的特定重复模式。在通常情况下，这种帧采用 UDP 分组（见第 10 章）形式封装在以太网广播帧中发送。有几个工具可以生成它们，包括 wol [<a href="#WOL">WOL</a>] ：</p>
<pre><code>Linux# wol 00:08:74:93:C8:3C
Waking up 00:08:74:93:C8:3C...
</code></pre>
<p>这个命令的结果是构造一个魔术分组，我们可以使用 Wireshark 查看( 见图 3-7 )。</p>
<figure data-type="image" tabindex="7"><img src="https://wenbozhangw.github.io//post-images/1652346183244.png" alt="图 3-7" loading="lazy"></figure>
<p>图 3-7   Wireshark 中的一个魔术分组帧，开始是 6 字节的 0xFF，然后重复 MAC 地址 16 次</p>
<p>图 3-7 中显示的分组多数是传统的 UDP 分组，但端口号（1126 和 40000）是任意的。分组中最特别的是数据区域。它以一个 6 字节的值 0xFF 开始，其余部分包含重复 16 次的目的 MAC 地址<code>00:08:74:93:C8:3C</code>。该数据的有效载荷模式定义了魔术分组。</p>
<h3 id="333-链路层流量控制">3.3.3 链路层流量控制</h3>
<p>以全双工模式运行扩展的以太网和跨越不同速率的网段时，可能需要由交换机将帧缓存（保存）一段时间。例如，当多个站发送到同一目的地（称为输出端口争用），这种情况可能发生。如果一个站聚合的流量速率超过该站的链路速率，那么帧就开始存储在中间交换机中。如果这种情况持续一段时间，这些帧可能被丢弃。</p>
<p>缓解这种情况的一种方法是在发送方采取<strong>流量控制</strong>（使它慢下来）。一些以太网交换机（和接口）通过在交换机和网卡之间发送特殊信号帧来实现流量控制。流量控制信号被发送到发送方，通知它必须放慢传输速率，但规范将这些细节留给具体实现来完成。以太网使用** PAUSE 消息（也称为PAUSE帧）**实现流量控制，它由 802.3x [<a href="#802.3-2008">802.3-2008</a>] 来定义。</p>
<p>PAUSE 消息包含在 MAC 控制帧中，通过将以太网<strong>长度/类型</strong>字段值设为 <code>0x8808</code>，以及使用 MAC 控制操作码 <code>0x0001</code> 来标识。如果一个站接收到这种帧，表示建议它减缓发送速度。 PAUSE 帧总是被发送到 MAC 地址 <code>01:80:C2:00:00:01</code>，并且只能在全双工链路上使用。它包含一个保持关闭（hold-off）时间值（指定量为 512 比特的时间），表明发送方在继续发送之前需要暂停多长时间。</p>
<p>MAC 控制帧采用如图 3-3 所示的常规封装的帧格式，但紧跟在<strong>长度/类型</strong>字段后的是一个 2 字节的操作码。 PAUSE 帧实际上是唯一一种使用 MAC 控制帧的帧类型。它包括一个 2 字节的保持关闭时间。 “整个” MAC 控制层（基本只是 802.3x 流量控制）的实现是可选的。</p>
<p>以太网层次的流量控制可能有重大负面影响，因此通常并不使用它。当多个站通过一台过载的交换机发送时（见下一节），该交换机通常向所有主机发送 PAUSE 帧。不幸的是，交换机的内存使用可能对发送主机不均衡，因此有些主机可能被惩罚（流量控制），即使它们对交换机流量过载没有多少责任。</p>
<hr>
<h2 id="34-网桥和交换机">3.4 网桥和交换机</h2>
<p>IEEE 802.1d 标准规定了网桥的操作，交换机本质上是高性能的网桥。网桥或交换机用于连接多个物理的链路层网络（例如一对物理的以太网段）或成组的站。最基本的设置涉及连接两个交换机来形成一个扩展的局域网，如图 3-8 所示。</p>
<figure data-type="image" tabindex="8"><img src="https://wenbozhangw.github.io//post-images/1652347179551.png" alt="图 3-8" loading="lazy"></figure>
<p>图 3-8   一个包括两台交换机的扩展以太网。每个交换机端口有一个编号，每个站（包括每个交换机）有自己的 MAC 地址</p>
<p>图中的交换机 A 和 B 互连形成一个扩展的局域网。在这个特定例子中，客户端系统都连接到 A，服务器都连接到 B，端口编号供参考。注意，每个网络单元（包括每个交换机）有自己的 MAC 地址。每个网桥经过一段时间对域外 MAC 地址的“学习”后，最终每个交换机会知道每个站可由哪个端口到达。每个交换机基于每个端口（也可能是每个 VLAN）的列表被存储在一张表（称为<strong>过滤数据库</strong>）中。图 3-9 显示每个交换机了解每个站的位置后，形成的包含这些信息的数据库例子。</p>
<figure data-type="image" tabindex="9"><img src="https://wenbozhangw.github.io//post-images/1652349458178.png" alt="图 3-9" loading="lazy"></figure>
<p>当第一次打开一个交换机（网桥）时，它的数据库是空的，因此它不知道除自己之外的任何站的位置。当它每次接收到一个目的地不是自己的帧时，它为除该帧到达的端口之外的所有端口做一个备份，并向所有端口发送这个帧的备份。如果交换机（网桥）未学习到站的位置，每个帧将会被交付到每个网段，这样会导致不必要的开销。学习能力可以显著降低开销，它是交换机和网桥的一个基本功能。</p>
<p>目前，多数操作系统支持网络接口之间的网桥功能，这意味着具有多个接口的计算机可用作网桥。例如，在 Windows 中，多个接口可被桥接，进入“控制面板”的“网络连接”菜单，选中（突出显示）需要桥接的接口，点击鼠标右键，并选择“网桥连接”。这时，出现一个表示网桥功能的新图标。许多接口相关的正常网络属性消失，取而代之的是网桥设备（见图 3-10）。</p>
<figure data-type="image" tabindex="10"><img src="https://wenbozhangw.github.io//post-images/1652350474031.png" alt="图 3-10" loading="lazy"></figure>
<p>图 3-10   在 Windows 中，通过选中需要桥接的网络接口，鼠标右击并选择桥接网络接口，可创建网桥设备。在网桥建立之后，可进一步修改网桥设备</p>
<p>图 3-10 显示 Windows 7 中的虚拟网桥设备的属性面板。网桥设备的属性包括一个被桥接的相关设备列表，以及在网桥上运行的一组服务（例如， Microsoft网络客户端、文件和打印机共享等）。 Linux 以类似方式工作，它使用命令行参数。在这个例子中，我们使用图 3-11 所示的拓扑结构。</p>
<figure data-type="image" tabindex="11"><img src="https://wenbozhangw.github.io//post-images/1652350584033.png" alt="图 3-11" loading="lazy"></figure>
<p>图 3-11   在这个简单的拓扑中，一台基于 Linux 的 PC 被配置为网桥，它在两个以太网之间实现互联。作为一个处于学习中的网桥，它不断积累并建立一些表，其中包含有关哪个端口可到达扩展局域网中的其他系统的信息</p>
<p>在图 3-11 中，这个简单的网络使用一台基于 Linux、带两个端口的 PC 作为网桥。只有一个站连接到端口 2，网络其他部分都连接到端口 1。以下命令可启用网桥：</p>
<pre><code>Linux# brctl addbr br0
Linux# brctl addif br0 eth0
Linux# brctl addif br0 eth1
Linux# ifconfig eth0 up
Linux# ifconfig eth1 up
Linux# ifconfig br0 up
</code></pre>
<p>以下几个命令可创建一个网桥设备 br0，并为网桥增加接口 eth0 和 eth1。 <code>brctl delif</code> 命令可用于删除接口。在建立接口之后， <code>brctl showmacs</code> 命令可用于检查过滤数据库（称为<strong>转发数据库</strong>，用 Linux 的术语称为 fdbs）：</p>
<pre><code>Linux# brctl show
bridge name  bridge id           STP     enabled     interfaces
br0          8000.0007e914a9cl   no       eth0          eth1
Linux# brctl showmacs br0
port no mac addr is local? ageing timer
1 00:04:5a:9f:9e:80 no 0.79
2 00:07:e9:14:a9:cl yes 0.00
1 00:08:74:93:c8:3c yes 0.00
2 00:14:22:f4:19:5f no 0.81
1 00:17:f2:e7:6d:91 no 2.53
1 00:90:f8:00:90:b7 no 17.13
</code></pre>
<p>这个命令的输出显示关于网桥的其他细节。由于站可能出现移动、网卡更换、 MAC 地址改变或其他情况，所以就算网桥曾发现一个 MAC 地址可通过某个端口访问，这个信息也不能假设永远是正确的。为了解决这个问题，在每次学习一个地址后，网桥启动一个计时器（通常默认为5分钟）。在 Linux 中，每个学习条目使用一个与网桥相关的固定时间。如果在指定的“有效期”内，没有再次看到该条目中的地址，则将这个条目删除，如下所示：</p>
<pre><code>Linux# brctl setageing br0 1
Linux# brctl showmacs br0
port no mac addr is local? ageing timer
1 00:04:5a:9f:9e:80 no 0.79
2 00:07:e9:14:a9:cl yes 0.00
1 00:08:74:93:c8:3c yes 0.00
2 00:14:22:f4:19:5f no 0.78
1 00:17:f2:e7:6d:91 no 0.00
</code></pre>
<p>为了方便演示，我们选择了一个比平时数值低的值作为<strong>有效期</strong>。当一个条目因有效期满而被删除时，后续的帧将被发送到接收端口之外的所有端口（称为<strong>洪泛</strong>），并更新过滤数据库中的这个条目。实际上，过滤数据库的使用和学习有利于优化性能，如果表是空的，网络将花费更多开销，但仍能履行职责。下一步，我们将注意力转移到两个以上的网桥通过冗余链路互联的情况。在这种情况下，帧的洪泛可能导致帧永远循环的洪泛灾难。显然，我们需要一种方法来解决这个问题。</p>
<h3 id="341-生成树协议">3.4.1 生成树协议</h3>
<p>网桥可能单独或与其他网桥共同运行。当两个以上的网桥使用（或交换机端口交叉连接）时，由于存在级联的可能性，因此可能形成很多组的循环帧。我们看如图 3-12 所示的网络。</p>
<figure data-type="image" tabindex="12"><img src="https://wenbozhangw.github.io//post-images/1652351442343.png" alt="图 3-12" loading="lazy"></figure>
<p>图 3-12   一个扩展的以太网包括 4 台交换机和多条冗余链路。如果在这个网络中采用简单的洪泛转发帧，由于多余的倍增流量（所谓的广播风暴），将会导致一场大的灾难。这种情况需要使用 STP</p>
<p>假设图 3-12 中的多个交换机刚被打开，并且它们的过滤数据库为空。当站 S 发送一个帧时，交换机 B 在端口 7、 8 和 9 复制该帧。这时，最初的帧已被“放大” 3 倍。这些帧被交换机 A、 D 和 C 接收。交换机 A 在端口 2 和 3 生成该帧的副本。交换机 D 和 C 分别在端口 20、 22 和 13、 14 生成更多副本。当这些副本在交换机 A、 C 和 D 之间双向传输，这时放大倍数已增大为6。 当这些帧到达时，<br>
转发数据库开始出现震荡，这是由于网桥反复尝试查找通过哪些端口可到达站 S。显然，这种情况是不能容忍的。如果允许这种情况发生，采用这种配置的网桥将无法使用。幸运的是，有一种协议可避免这种情况，这种协议称为<strong>生成树协议（STP）</strong>。我们将介绍 STP 的一些细节，解释网桥和交换机采用哪些方法抑制放大。在当前的标准 [<a href="#802.1D-2004">802.1D-2004</a>] 中，传统的 STP 被**快速生成树协议（RSTP）**代替，我们将在了解传统 STP 的基础上再介绍它。</p>
<p>STP 通过在每个网桥禁用某些端口来工作，这样可避免拓扑环路（即两个网桥之间不允许出现重复路径），但如果拓扑结构未分区，则仍可到达所有站。在数学上，一个生成树是一张图中所有节点和一些线的集合，从任何节点到其他节点（跨越图）有一条路径或路由，但是没有环路（这些线的集合构成一棵树）。一张图可能存在多个生成树。 STP 用于找出这张图的其中一个生成树，该图将网桥作为节点并将链路作为线（或称“边”）。图 3-13 说明了这个想法。</p>
<figure data-type="image" tabindex="13"><img src="https://wenbozhangw.github.io//post-images/1652352139379.png" alt="图 3-13" loading="lazy"></figure>
<p>图 3-13   通过 STP，链路 B-A、 A-C 和 C-D 在生成树中是活跃的。端口 6、7、 1、2、 13、14 和 20 处于转发状态；所有其他端口被阻塞（即不转发）。这样可以防止帧循环，避免广播风暴。如果配置发生变化或某台交换机故障，则将阻塞端口改变为转发状态，并由网桥计算一个新生成树</p>
<p>在本图中，粗线表示网络中被 STP 选择用于转发帧的链路。其他链路没有被使用，端口 8、9、 12、21、22 和 3 被<strong>阻塞</strong>。通过使用 STP，早期的各种问题并没有出现，这些帧只是作为另一个抵达帧的副本而被创建。这里没有出现放大的问题。由于任意两个站之间只有一条路径，因此可以避免循环。生成树的形成和维护由多个网桥完成，在每个网桥上运行一个分布式算法。</p>
<p>用于转发数据库时， STP 必须处理以下情况，例如网桥启用和关闭、接口卡更换或 MAC 地址改变。显然，这种变化可能影响生成树运行，因此 STP 必须适应这些变化。这种适应通过交换一种称为**网桥协议数据单元（BPDU）**的帧来实现。这些帧用来形成和维护生成树。这棵树“生长”自一个网桥——该网桥由其他网桥选举为“根网桥”。</p>
<p>如前所述，一个网络可能存在多个生成树。如何确定哪棵生成树最适于转发帧，这基于每条链路和根网桥位置的相关成本。这个成本是一个与链路速度成反比的整数（建议）。例如，一条 10Mb/s 链路的成本为 100， 100Mb/s 和 1000Mb/s 链路的成本分别为 19 和 4。 STP 计算到根网桥的成本最小的路径。如果必须遍历多条链路，相关成本是这些链路成本之和。</p>
<h4 id="3411-端口状态和角色">3.4.1.1 端口状态和角色</h4>
<p>为了理解 STP 的基本操作，我们需要了解网桥端口的状态机，以及 BPDU 内容。网桥端口可能有 5 个状态：阻塞、侦听、学习、转发和禁用。在图 3-14 所示的状态转换图中，我们可以看出它们之间的关系。</p>
<figure data-type="image" tabindex="14"><img src="https://wenbozhangw.github.io//post-images/1652353538285.png" alt="图 3-14" loading="lazy"></figure>
<p>图 3-14   在正常的 STP 操作中，端口在 4 个主要状态之间转换。在阻塞状态下，帧不被转发，但一次拓扑变化或超时可能导致向侦听状态转换。转发状态是活跃的交换机端口承载数据流量的正常状态。括号中的状态名用于表示 RSTP 相关的端口状态</p>
<p>在图 3-14 显示的生成树中，实线箭头表示端口的正常转换，小的虚线箭头表示由管理配置引起的改变。在初始化后，一个端口进入阻塞状态。在这种状态下，它不进行地址学习、数据转发或 BPDU 发送，但它会监控接收的 BPDU，并在它需要被包含在将到达的根网桥的路径中的情况下，使端口转换到侦听状态。在侦听状态下，该端口允许发送和接收 BPDU，但不进行地址学习或数据转发。经过一个典型的 15 秒的转发延迟，端口进入学习状态。这时，它被允许执行数据转发之外的所有操作。在进入转发状态并开始转发数据之前，需要等待另一个转发延迟。</p>
<p>相对于端口状态机，每个端口都扮演一定的<strong>角色</strong>。由于 RSTP （见 3.4.1.6 节）的出现，这个术语变得越来越重要。端口可能扮演<strong>根端口</strong>、<strong>指定端口</strong>、<strong>备用端口</strong>或<strong>备份端口</strong>等角色。根端口是生成树中位于指向根的线段终点的那些端口。指定端口是指处于转发状态，并与根相连线段中路径成本最小的端口。备用端口是与根相连线段中成本更高的端口。它们不处于转发状态。备份端口是指连接到同一线段中作为同一网桥指定端口使用的端口。因此，备份端口可轻易接管一个失效的指定端口，而不影响生成树拓扑的其余部分，但是它不能在全部网桥失效的情况下提供一条到根的备用路径。</p>
<h4 id="3412-bpdu-结构">3.4.1.2 BPDU 结构</h4>
<p>为了确定生成树中的链路， STP 使用图 3-15 所示的 BPDU。</p>
<figure data-type="image" tabindex="15"><img src="https://wenbozhangw.github.io//post-images/1652354174126.png" alt="图 3-15" loading="lazy"></figure>
<p>图 3-15   BPDU 被放置在 802 帧的有效载荷区，并在网桥之间交换以建立生成树。重要的字段包括源、根节点、到根的成本和拓扑变化提示。在 802.1w 和 [<a href="#802.1D-2004">802.1D-2004</a>] 中（包括快速 ST P或 RSTP），附加字段显示端口状态</p>
<p>图 3-15 所示的格式适用于最初的 STP，以及新的 RSTP （见 3.4.1.6 节）。 BPDU 总被发送到组地址 <code>01:80:C2:00:00:00</code> （链路层组和因特网组播寻址的详细信息见第 9 章），并且不会通过一个未修改的网桥转发。在该图中， DST、 SRC 和 L/T （长度/类型）字段是携带 BPDU 的传统以太网（802.3）帧头部的一部分。 3 字节的 LLC/SNAP 头部由 802.1 定义，并针对 BPDU 被设置为常数 <code>0x424203</code>。并非所有 BPDU 都使用 LLC/SNAP 封装，但这是一个常见的选项。</p>
<p><strong>协议（Prot）</strong> 字段给出协议 ID 号，它被设置为 0。<strong>版本（Vers）</strong> 字段被设置为 0 或 2，取决于使用 STP 还是 RSTP。<strong>类型（rtype）</strong> 字段的分配与版本类似。<strong>标志（Flags）</strong> 字段包含<strong>拓扑变化（TC）</strong> 和 <strong>拓扑变化确认（TCA）</strong> 位，它们由最初的 802.1d 标准定义。附加位被定义为 <strong>建议（P）</strong>、<strong>端口角色（00 为未知， 01 为备用， 10 为根， 11 为指定）</strong>、<strong>学习（L）</strong>、<strong>转发（F）<strong>和</strong>协议（A）</strong>。这些都作为 RSTP 内容在 3.4.1.6 节中讨论。根 ID 字段给出发送方使用的根网桥标识符，即从网桥 ID 字段中获得的 MAC 地址。这些 ID 字段都用一种特殊方式编码，包括 MAC 地址之前的一个 2 字节的优先级字段。优先级的值可通过管理软件来设置，以强制要求生成树采用某个特定网桥作为根（例如， Cisco 在自己的 Catalyst 交换机中使用默认值 <code>0x8000</code>）。</p>
<p>根路径成本是在 <strong>根 ID</strong> 字段中指定的计算出的到达某个网桥的成本。 PID 字段是端口标识符和由发送帧给出的端口号，它被附加在一个可配置的 1 字节的<strong>优先级</strong>字段（默认为 <code>0x80</code>）之后。<strong>消息有效期（MsgA）</strong> 字段指出消息有效期。<strong>最大有效期（MaxA）</strong> 字段指出超时（默认为 20 秒）的最大期限。<strong>欢迎时间（HelloTime）</strong> 字段指出配置帧的传输周期。<strong>转发延迟</strong>字段指出处于学习和侦听状态的时间。所有的有效期和时间字段可在 1/256 秒内获得。</p>
<p><strong>消息有效期</strong>字段不像其他的时间字段那样是固定值。当根网桥发送一个 BPDU 时，它将该字段设置为 0。 网桥转发接收到的不是根端口的帧，并将<strong>消息有效期</strong>字段加1。从本质上来说，该字段是一个跳步计数器，用于记录 BPDU 经过的网桥数量。当一个 BPDU 被一个端口接收时，其包含的信息在内存和 STP 算法参与者中被保存至超时（超时发生在（MaxA-MsgA）时刻）。如果超过这个时间，根端口没有接收到另一个 BPDU，根网桥被宣布“死亡”，并重新开始根网桥选举过程。</p>
<h4 id="3413-建立生成树">3.4.1.3 建立生成树</h4>
<p>STP 的第一个工作是选举根网桥。根网桥是在网络（或 VLAN）中标识符最小（优先级与 MAC 地址结合）的网桥。当一个网桥初始化时，它假设自己是根网桥，并用自己的网桥 ID 作为根 ID 字段的值发送配置 BPDU 消息，如果它检测到一个 ID 更小的网桥，则停止发送自己的帧，并基于接收到的 ID 更小的帧构造下一步发送的 BPDU。发出根 ID 更小的 BPDU 的端口被标记为根端口（即端口在到根网桥的路径上）。剩余端口被设置为阻塞或转发状态。</p>
<h4 id="3414-拓扑变化">3.4.1.4 拓扑变化</h4>
<p>STP 的另一个重要工作是处理拓扑变化。虽然可用前面所述的数据库有效期机制适应拓扑变化，但这是一个比较差的方法，因为有效期计时器需要花费很长时间（5分钟）删除错误条目。相反， STP 采用一种方法检测拓扑变化，并快速通知它们所在的网络。在 STP 中，当一个端口进入阻塞或转发状态时，意味着发生拓扑变化。当网桥检测到一个连接变化（例如一条链路故障），它向根端口之外的端口发送<strong>拓扑变化通知（TCN）</strong> BPDU，通知自己在树中的父网桥，直到根为止。树中通向根的下一个网桥向发送通知的网桥确认 TCN BPDU，并将它们转发到根。当接收到拓扑变化通知时，根网桥在后续的周期性配置消息中设置 TC 位。这种消息被网络中的每个网桥所转发，并被处于阻塞或转发状态的端口接收。设置这个位允许网桥减小转发延时计时器的有效期，将有效期以秒代替推荐的 5 分钟。这样，数据库中已有的错误条目可被快速清除和重新学习，同时允许访问那些被误删除的条目。</p>
<h4 id="3415-例子">3.4.1.5 例子</h4>
<p>在 Linux 中，网桥功能默认禁用 STP。假设在多数情况下拓扑相对简单，一台普通计算机可被用作网桥。可执行以下命令为当前使用的网桥启用 STP：</p>
<pre><code>Linux# brctl stp br0 on
</code></pre>
<p>执行该命令的结果如下：</p>
<pre><code>Linux# brctl stp br0 on
br0
bridge id       8000.0007e914a9c1
designated root     8000.0007e914a9c1
root port       0       path cost       0
max age     19.99       bridge max age      19.99
hello time      1.99        bridge hello time       1.99
forward delay       14.99       bridge forward delay        14.99
ageing time     0.99
hello timer     1.26        tcn timer       0.00
topology change timer       3.37        gc timer        3.26
flags       TOPOLOGY_CHANGE TOPOLOGY_CHANGE_DETECTED

eth0 (0)
port id       0000      state       forwarding
designated root     8000.0007e914a9c1       path cost       100
designated bridge     8000.0007e914a9c1     message age timer       0.00
designated port       8001       forward delay timer 0.00

designated cost       0       hold timer 0.26

flags

eth1 (0)
port id       0000      state       forwarding
designated root     8000.0007e914a9c1       path cost       19
designated bridge     8000.0007e914a9c1     message age timer       0.00
designated port       8002       forward delay timer 0.00
designated cost       0       hold timer 0.26

flags
</code></pre>
<p>我们看到一个简单的桥接网络的 STP 设置。网桥设备 br0 保存网桥的整体信息。这些信息包括网桥 ID （8000.0007e914a9cl），它由图 3-11 中基于 PC 的网桥（端口 1）的最小 MAC 地址生成。可在几秒钟内获得主要的配置参数（例如欢迎时间、拓扑变化计时器等）。标志值表示最近的拓扑变化，用于获得最近的网络连接变化的实际情况。输出的其余部分描述每个端口的信息，即 eth0（网桥端口 1）和 eth1（网桥端口 2）。注意， eth0 的路径成本大约是 eth1 成本的 10 倍。这个结果与 eth0 是一个 10Mb/s 以太网而 eth1 是一个100Mb/s 全双工网络是一致的。</p>
<p>我们可使用 Wireshark 查看一个BPDU。在图 3-16 中，我们看到一个 52 字节的消息内容。消息长度为 52 字节（由于 Linux 捕获功能会拆除填充，因此它小于以太网的 64 字节的最小限制），这个长度是由以太网头部中的<strong>长度/类型</strong>字段加 14 得到的。目的地址是预期的组地址 <code>01:80:C2:00:00:00</code>。有效载荷长度是 38 字节，这个值包含在<strong>长度</strong>字段中。 SNAP/LLC字段包含常数 <code>0x424243</code>，并且封装帧是一个生成树（版本 0）帧。其余协议字段表明站 <code>00:07:e9:14:a9:c1</code> 认为自己是生成树的根，优先级为 32768 （低优先级），并且 BPDU 从端口 2 以优先级 <code>0x80</code> 发送。另外，最大有效期是 20 秒，欢迎时间是 2 秒，转发延迟是 15 秒。</p>
<figure data-type="image" tabindex="16"><img src="https://wenbozhangw.github.io//post-images/1652356336887.png" alt="图 3-16" loading="lazy"></figure>
<p>图 3-16   Wireshark 显示一个 BPDU。以太网帧的目的地址是一个通过网桥（<code>01:80:C2:00:00:00</code>）的组地址</p>
<h4 id="3416-快速生成树协议以前的-8021w">3.4.1.6 快速生成树协议（以前的 802.1w）</h4>
<p>传统 STP 的问题之一是在拓扑变化之后，只能通过一定时间内未接收到 BPDU 来检测。如果这个超时很大，收敛时间（沿着生成树重新建立数据流的时间）可能比预期大。 IEEE 802.1w标准（[<a href="#802.1D-2004">802.1D-2004</a>] 的一部分）改进了传统 STP，它定义了采用新名称的 <strong>快速生成树协议（Rapid Sparming Tree Protocol， RSTP）</strong> 。在 RSTP 中，对 STP 的主要改进是监视每个端口的状态，并在故障时立即发送一个拓扑变化通知。另外， RSTP 使用 BPDU 的标志字段中的全部 6 位来支持网桥之间的协议，以避免由计时器来启动协议操作。它将正常的 STP 端口状态由 5 个减少到 3 个（丢弃、学习和转发，由图 3-14 的括号中的状态名表示）。 RSTP 的丢弃状态代替了传统 STP 的禁止、阻塞和侦听状态。 RSTP 创建了一个称为<strong>备用端口</strong>的新角色，作用是在根端口停止运行时立即代替它。</p>
<p>由于 RSTP 只使用一种类型的 BPDU，因此这里没有专门的拓扑变化 BPDU。正如所说的那样， RSTP 的 BPDU 使用版本和类型号 2 而不是 0。在 RSTP 中，检测到一次拓扑变的交换机会发送一个表示拓扑变化的 BPDU，任何接收到它的交换机立即清除自己的过滤数据库。这个改变可显著影响协议的收敛时间。这时，无须等待拓扑变化传递到根网桥再经过转发延迟后返回，而是立即清除相关条目。总之，在大多数情况下，收敛时间可从几十秒减少到几分之一秒。</p>
<p>RSTP 使<strong>边缘端口</strong>（只连接到端站的端口）和正常的生成树端口之间，以及点到点链路和共享链路之间都有区别。边缘端口和点到点链路上的端口通常不会形成循环，因此允许它们跳过侦听和学习状态，直接进入转发状态。当然，如果假设一个边缘端口可能被入侵，例如两个端口交叉连接，它们可携带任何形式的BPDU （简单的端站通常不处理 BPDU），这时它们将被重新分类为生成树端口。点到点链路可根据接口操作模式来识别。如果这个接口运行在全双工模式下，则这条链路是点到点链路。</p>
<p>在普通的 STP 中， BPDU 通常由一个通知网桥或根网桥来转发。在 RSTP 中， BPDU 为了“保持活跃”而由所有网桥来定期发送，以便确定相连的邻居是否正常运行。大多数高层路由协议也会这样做。注意，在 RSTP 中，拓扑变化没有像普通 STP 那样包括边缘端口连接或断开。当检测到一次拓扑变化时，通知网桥发送 TC 位被设置的 BPDU，不仅到根网桥而且到所有网桥。这样做允许将拓扑变化通知整个网络，并且比传统 STP 更快速。当一个网桥接收到这些消息时，它会更新除边缘端口之外的所有相关条目。</p>
<p>RSTP 的很多功能由 Cisco 和其他公司开发，他们有时需要在自己的产品中为普通 STP做专门的扩展。 IEEE 委员会将这些扩展纳入 802.1d 标准的更新中，该标准涵盖所有类型的 STP，因此扩展局域网可在某些网段中运行传统 STP，同时在其他部分中运行 RSTP （虽然 RSTP 的优势将丧失）。 RSTP 已被扩展到 VLAN [<a href="#802.1Q-2005">802.1Q-2005</a>] 中，它采用一种称为多生成树协议（MSTP）的协议。这个协议保留了RSTP （和 STP）报文格式，因此它有可能做到向后兼容，也支持形成多个生成树（每个 VLAN 一个生成树）。</p>
<h3 id="342-8021ak多注册协议">3.4.2 802.1ak：多注册协议</h3>
<p>**多注册协议（Multiple Registration Protocol， MRP）**提供了在桥接局域网环境中的站之间注册属性的通用方法。 [<a href="#802.1ak-2007">802.1ak-2007</a>]定义了两个特殊的 MRP “应用程序”，称为 MVRP（用于注册 VLAN）和 MMRP （用于注册组 MAC 地址）。 MRP 代替了早期的 GARP 框架;MVRP 和 MMRP 分别代替了旧的 GVRP 和 GMRP 协议。这些协议最初都由 802.1q 定义。</p>
<p>在使用 MVRP 时，当一个站被配置为一个 VLAN 成员时，该信息被传输到它所连接的交换机，并由该交换机将站加入 VLAN 通知其他交换机。这允许交换机根据站的 VLAN ID 添加自己的过滤表，也允许 VLAN 拓扑变化不必通过 STP 而重新计算现有生成树。避免重新计算 STP 是从 GVRP 向 MVRP 迁移的原因之一。</p>
<p>MMRP 是一个站注册其感兴趣的组 MAC 地址（组播地址）的方法。这个信息可能被用于交换机建立端口，组播流量必须通过该端口来交付。如果没有这样的功能，交换机将不得不广播所有的组播流量，这样可能导致不必要的开销。 MMRP 是一个第 2 层协议，它与第 3 层协议 IGMP 和 MLD 相似，并在很多交换机中支持“  IGMP/MLD 探听”能力。我们将在第 9 章讨论 IGMP、MLD 和探听。</p>
<hr>
<h2 id="35-无线局域网ieee-80211wi-fi">3.5 无线局域网——IEEE 802.11（Wi-Fi）</h2>
<p>目前，<strong>无线保真（Wi-Fi）</strong> 是访问 Intemet 的最流行技术之一，其众所周知的 IEEE 标准名称为 802.11，它是一种常用的无线以太网标准。 Wi-Fi 已发展成为一种廉价、高效、便捷的方式，为大多数应用提供可接受的连通性和性能。 Wi-Fi 网络很容易建立。当前多数的便携式电脑和智能手机包含接入 Wi-Fi 基础设施的必要硬件。很多咖啡馆、机场、宾馆和其他公共设施提供了 Wi-Fi “热点”， Wi-Fi 在那些可能难以提供其他基础设施的发展中国家发展甚至更快。图 3-17 显示了 IEEE 802.11 网络体系结构。</p>
<figure data-type="image" tabindex="17"><img src="https://wenbozhangw.github.io//post-images/1652419793689.png" alt="图 3-17" loading="lazy"></figure>
<p>图 3-17   一个无线局域网的 802.11 术语。接入点可采用一种分布式服务（一个无线或有线的主干）来连接，以形成一个扩展的无线局域网（称为一个 ESS）。站（包括 AP 和移动设备）之间的通信构成一个基本服务集。在通常情况下，每个 ESS 有一个指定的 ESSID，它的功能是作为一个网络的名称</p>
<p>图 3-17 中的网络包括多个<strong>站（STA）</strong>。在通常情况下，站和<strong>接入点（AP）<strong>组成一个操作子集。一个 AP 和相关的站被称为一个</strong>基本服务集（BSS）</strong>。 AP 之间通常使用一种有线的<strong>分布式服务</strong>（称为 DS，基本是“主干”）连接，形成一个<strong>扩展服务集（ESS）</strong>。这种方式通常被称为<strong>基础设施模式</strong>。 802.11 标准也提供了一种 Ad hoc （自组织）模式。在这种配置中没有 AP 或 DS，而是直接采用站到站（对等）的通信。在 IEEE 的术语中，加入一个 Ad hoc 网络的 STA 形成一个<strong>独立基本服务集（IBSS）</strong>。由 BSS 或 IBSS 的集合形成的无线局域网称为<strong>服务集</strong>，它由一个**服务集标识符（SSID）**来标识。**扩展服务集标识符（ESSID）**是由 SSID 命名的一个 BSS 集合，它实际上是一个最长 32 个字符的局域网名称。在 WLAN 第一次建立时，该名称通常分配给 AP。</p>
<h3 id="351-80211-帧">3.5.1 802.11 帧</h3>
<p>802.11 网络有一个常见的总体框架，但包括多种类型的帧格式。每种类型的帧不一定包含所有字段。图 3-18 显示了常见帧格式和（最大尺寸的）数据帧。</p>
<figure data-type="image" tabindex="18"><img src="https://wenbozhangw.github.io//post-images/1652420491239.png" alt="图 3-18" loading="lazy"></figure>
<p>图 3-18   802.11 基本数据帧格式（见 [<a href="#802.11n-2009">802.11n-2009</a>]）。 MPDU 格式类似于以太网，但取决于接入点之间使用的 DS 类型：帧是发送到 DS 还是来自它，以及帧是否被聚合。 QoS 控制字段用于特殊功能， HT 控制字段用于控制 802.11n 的“高吞吐量”功能</p>
<p>图 3-18 所示的帧包括一个用于同步的前导码，它取决于正在使用的 802.11 协议类型。接下来，**物理层会聚程序（PLCP）**头部以独立于物理层的方式提供特定的物理层信息。帧的 PLCP 部分的传输速率通常比其余部分低。这样做有两个目的：提高正确交付的概率（较低速度通常具有更好的容错性能），提供对传统设备的兼容性和防止慢速操作的干扰。帧的 MAC PDU（MPDU）与以太网相似，但是有一些额外的字段。</p>
<p>MPDU 以帧控制字开始，其中包括 2 位的<strong>类型</strong>字段，用于识别该帧的类型。这里有三种类型的帧：<strong>管理帧</strong>、<strong>控制帧</strong>和<strong>数据帧</strong>。每种类型有不同的子类型。 [<a href="#802.11n-2009">802.11n-2009，表 7-1</a>]给出了有关类型和子类型的完整列表。剩余字段由帧类型（如果有的话）来决定，后面将单独讨论。</p>
<h4 id="3511-管理帧">3.5.1.1 管理帧</h4>
<p>管理帧用于创建、维持、终止站和接入点之间的连接。它们也被用于确定是否采用加密，传输网络名称（SSID 或 ESSID），支持哪种传输速率，以及采用的时间数据库等。当一个 Wi-Fi 接口“扫描”临近的接入点时，这些帧被用于提供必要的信息。</p>
<p>扫描是一个站发现可用的网络及相关配置信息的过程。这涉及每个可用频率和流量的侦听过程，以确定可用的接入点。一个站可以主动探测网络，在扫描时传输一个特殊的管理帧（“探测请求”）。这些探测请求有一定的限制，以保证 802.11 流量不在非 802.11 （例如医疗服务）频率上传输。下面是在 Linux 系统中手工启动扫描的例子：</p>
<pre><code>Linux# iwlist wlan0 scan
wlan0 Scan completed :
                Cell 01 - Address: 00:02:6F:20:B5:84
                        ESSID: &quot;Grizzly-5354-Aries-802.11b/g&quot;
                        Mode:Master
                        Channel:4
                        Frequency:2.427 GHz (Channel 4)
                        Quality=5/100 Signal level=47/100
                        Encryption key:on
                        IE : WPA Version 1
                            Group Cipher : TKIP
                            Pairwise Ciphers (2) : CCMP TKIP
                            Authentication Suites (1) : PSK
                        Bit Rates:1 Mb/s; 2 Mb/s; 5.5 Mb/s; 11 Mb/s;
                                6 Mb/s; 12 Mb/s; 24 Mb/s; 36 Mb/s; 9 Mb/s;
                                18 Mb/s; 48 Mb/s; 54 Mb/s
                        Extra:tsf=0000009d832ff037
</code></pre>
<p>这里，我们看到在无线接口 wlan0 上手工启动扫描的结果。一个 MAC 地址为 <code>00:02:6F:20:B5:84</code>的 AP 作为主角（即在基础设施模式中作为 AP）工作。它在信道 4 （2.427GHz）上广播 ESSID “Grizzly-5354-Aries-802.11b/g” （更多细节见 3.5.4 节讨论信道和频率时对信道选择的描述）。信号质量和强度决定执行扫描的站从 AP 接收信号的好坏，但相应值的含义可能因设备生产商而不同。 WPA 加密被用于这种链路（见3.5.5节），传输速率从 1Mb/s 到 54Mb/s 不等。 <strong>tsf（时间、同步、功能）</strong> 的值表示 AP 的时间概念，它被用于需要同步的各种功能，例如省电模式（见3.5.2节）。</p>
<p>当一个 AP 广播它的 SSID 时，任何站可尝试与 AP 建立连接。当一个连接建立时，大多数 Wi-Fi 网络会提供必要的配置信息，以便为站提供 Internet 接入（见第 6 章）。但是， AP 的运营商可能希望控制使用网络的站。有些运营商故意使连接变得更困难， AP 不广播其 SSID 被作为一项安全措施。这种方法提供了有限的安全性，这是由于 SSID 可以被猜测。链路加密和密码可提供更可靠的安全性，我们将在 3.5.5 节讨论。</p>
<h4 id="3512-控制帧rtscts-和-ack">3.5.1.2 控制帧：RTS/CTS 和 ACK</h4>
<p>控制帧与帧确认被用于一种流量控制方式。流量控制有助于接收方使一个过快的发送方降低发送速度。帧确认有助于发送方知道哪些帧已正确接收。这些概念也适用于传输层的 TCP 协议（见第15章）。 802.11 网络支持可选的<strong>请求发送/明确发送（RTS/CTS）</strong>，通过放缓传输来进行流量控制。当 RTS/CTS 启用时，一个站在发送数据帧之前发送一个 RTS 帧，当接收方愿意接收额外的流量时，它会响应一个 CTS 帧。在 RTS/CTS 交换之后，这个站开启一个时间窗口（在 CTS 帧中标识），用于向确认接收的站发送数据帧。这种协同传输方法在无线网络中是常见的，模拟流量控制信号多年前已被用于有线的串行线路（有时称为硬件流量控制）。</p>
<p>RTS/CTS 交换有助于避免隐藏终端问题，通过在允许发送时对每个站加以指导，以便发现对方站同时进行的传输。由于 RTS 和 CTS 帧比较短，因此它们不会长期使用信道。如果一个分组的大小足够大， AP 通常为每个分组启动一次 RTS/CTS 交换。在通常情况下， AP 提供一个称为<strong>分组大小阈值</strong>（或类似）的配置选项。超过阈值的帧将会导致一个 RTS 帧优先于数据帧发送。如果需要执行 RTS/CTS 交换，大多数设备生产商设置的默认值为 500 字节。在 Linux 中， RTS/CTS 阈值可通过以下方式设置：</p>
<pre><code>Linux# iwconfig wlan0 rts 250
wlan0 IEEE 802.11g ESSID:&quot;Grizzly-5354-Aries-802.11b/g&quot;
        Mode : Managed
        Frequency:2.427 GH
        Access Point: 00:02:6F:20:B5:84
        Bit Rate=24 Mb/s Tx-Power=0 dBm
        Retry min limit:7 RTs   thr=250 B    Fragment thr=2346 B
        Encryption key:xxxx- ... 一xxxx [3]
        Link Quality=100/100    Signal level=46/100
        Rx invalid nwid:0    Rx invalid crypt:0    Rx invalid frag:0
        Tx excessive retries:0    Invalid misc:0    Missed beacon:0
</code></pre>
<p><code>iwconfig</code> 命令可用于设置多种变量，包括 RTS 和分片阈值（见 3.5.1.3 节）。它也可用于确定统计数据，例如错误的网络 ID （ESSID）或加密密钥而导致的帧出错数量。它也可用于给出过多的重试次数（即重传次数），这是一个用于衡量链路可靠性的粗略指标，在无线网络中常用于指导路由决策 [<a href="#ETX">ETX</a>]。在覆盖范围有限的 WLAN 中，隐藏终端问题通常很少发生，可将站的 RTS 阈值设置为很大（1500 或更大）来禁用 RTS/CTS。这可避免每个分组执行 RTS/CTS 交换带来的开销。</p>
<p>在有线的以太网中，冲突较少意味着正确接收帧的概率较高。在无线网络中，更多的因素导致帧交付可能出错，例如信号不够强或受到干扰。为了帮助解决这些潜在问题， 802.11 采用一种重传/确认（ACK）方法来扩展 802.3 重传机制。确认是对预期在一定时间内接收的一个单播帧（802.11a/b/g）或一组帧（802.11n 或带“块确认”的 802.11e）的响应。组播或广播帧没有相关的确认，以避免出现“ACK爆炸”问题（见第 9 章）。在指定时间内没有接收到对应的 ACK 会导致帧的重传。</p>
<p>重传可能在网络中形成重复的帧。当任何帧是某个帧的一次重传时，<strong>帧控制字</strong>中的 <strong>重试（Retry）</strong> 位需要设置为相应的值。接收站可通过它删除重复的帧。每个站需要保持一个小的缓存条目，以说明最近查看的地址和序列号/分片号。当一个接收帧与一个条目匹配时，则丢弃该帧。</p>
<p>发送一个帧和接收一个 ACK 所需时间与链路距离和<strong>时隙</strong>（802.11 MAC 协议的一个基本时间单位，见 3.5.3 节）相关。在大多数系统中，可配置等待的 ACK 时间（以及时隙），我们可采用不同方法完成配置。在大多数情况下，例如在家庭或办公室中使用，默认值是足够的。在长距离的 Wi-Fi 中，这些值可能需要调整（例如见 [<a href="#MWLD">MWLD</a>] ）。</p>
<h4 id="3513-数据帧-分片和聚合">3.5.1.3 数据帧、分片和聚合</h4>
<p>在一个繁忙的网络中看到的帧大多数是数据帧，它们如大家所期望的那样携带数据。在通常情况下， 802.11 帧和链路层（LLC）帧之间存在一对一关系，它们保证更高层协议（例如 IP）是可用的。但是，802.11 支持帧<strong>分片</strong>，可将一个帧分为多个分片。根据 802.11n 的规定，它也支持帧聚合，可将多个帧合并发送以减少开销。</p>
<p>当使用帧分片时，每个分片有自己的 MAC 头部和尾部的 CRC，并且它们独立于其他分片处理。例如，到不同目的地的分片可以交错。当信道有明显的干扰时，分片有助于提高性能。除非使用块确认功能，否则每个分片将被单独发送，并由接收方为每个分片产生一个 ACK。 由于分片小于全尺寸的帧，如果需要启动一次重传，则只需要重传少量数据。</p>
<p>分片仅用于目的地址为单播（非广播或组播）的帧。为了具备这种能力，顺序控制字段包含一个<strong>分片号</strong>（4 位）和一个<strong>序列号</strong>（12 位）。如果一个帧经过分片，所有分片包含相同的序列号值，而每个相邻的分片的分片号之差为 1。 由于分片号字段长度为 4 位，同一帧最多可能有 15 个分片。<strong>帧控制字</strong>中的<strong>更多标志</strong>字段表示更多分片还没有到达。最后一个分片将这个位设置为 0。接收方将接收到的同一序列号的分片根据分片号重组成原始帧。当所有包含同一序列号的分片被接收，并且最后一个分片将更多标志字段设为 0 时，这个帧被重组并交给更高层协议来处理。</p>
<p>分片并不常使用，因为它需要经过调整。如果不调整就使用，可能导致性能下降。当帧大小更小的情况下，出现位差错的概率（参见下一段）更小。分片大小通常可设为 256 字节至 2048 字节，并作为一个阈值（只有那些超过阈值的帧才被分片）。很多 AP 通常设置更高的阈值（例如 Linksys 品牌 AP 的 2437 字节），这样就会默认不使用分片。</p>
<p>分片有用的原因在于其出错的概率。如果 <strong>误码率（Bit Error Rate， BER）</strong> 为 P， 1 位数据成功交付的概率为 <code>(1-P)</code> ， N 位成功交付的概率为 (1-P)<sup>N</sup> 。随着 N 的增长，这个值逐渐减小。因此，如果我们减小一个帧的大小，理论上可改善错误交付的概率。当然，如果我们将一个 N 位大小的帧分成 K 个分片，我们可发送至少 <code>N/K</code> 个分片。我们给出一个具体的例子，假设要发送一个 1500 字节（12000 位）的帧。如果假设 P= 10<sup>-4</sup> （一个相对较高的误码率），不分片时的成功交付概率为 (1-10<sup>-4</sup>)<sup>12000</sup>=0.301 ，那么只有约 30% 机会将这个帧成功交付，即平均发送三或四次可使它成功接收。</p>
<p>如果我们对同样的例子使用分片，并将分片阈值设置为 500，这时将产生 3 个 4000 位的分片。每个分片成功交付的概率为 (1-10<sup>-4</sup>)<sup>4000</sup> = 0.670。因此，每个分片约有 67% 的机会成功交付。当然，我们必须在交付成功后重组该帧。 3 个分片、 2 个分片、 1 个分片与 0 个分片成功交付的概率分别为 (0.67)<sup>3</sup>= 0.30、 3(0.67)<sup>2</sup>(0.33) = 0.44、 3(0.67)(0.33)<sup>2</sup>= 0.22、 (0.33)<sup>3</sup>=0.04。 因此，虽然所有分片未重传而被成功交付的概率与未分片被成功交付的概率相同，但两个或三个分片被成功交付的机会相对较大。如果发生这种情况，顶多是一个分片需要重传，这比发送 1500 字节的未分片帧显然节省时间（大约三分之一）。当然，每个分片需要花费一些开销，如果误码率实际为 0 ，分片只会因创建更多帧而降低性能。</p>
<p>802.11n 提供的增强功能之一是支持两种形式的帧聚合。一种形式称为<strong>聚合的 MAC 服务数据单元（A-MSDU）</strong>，它可将多个完整的 802.3 （以太网）帧聚合在一个 802.11 帧中。另一种形式称为<strong>聚合的 MAC 协议数据单元（A-MPDU）</strong>，它可将多个具有相同的源、目的和 QoS 的 MPDU 聚合为短帧。图 3-19 描述了两种类型的聚合。</p>
<figure data-type="image" tabindex="19"><img src="https://wenbozhangw.github.io//post-images/1652429598770.png" alt="图 3-19" loading="lazy"></figure>
<p>图 3-19   802.11n 中的帧聚合包括 A-MSDU 和 A-MPDU。 A-MSDU 使用一个 FCS 聚合多个帧。A-MPDU 在聚合的每个 802.11 帧之间使用一个 4 字节的分隔符。每个 A-MPDU 子帧拥有自己的 FCS，并可以分别使用 ACK 确认，以及在必要时重传</p>
<p>对于一次单一的聚合， A-MSDU 方法在技术上更有效率。每个 802.3 头部通常为 14 字节，相对 36 字节的 802.11 MAC 头部更短。因此，仅一个 802.11 MAC 头部对应于多个 802.3 帧，每聚合一个帧最多可节约 22 字节。一个 A-MSDU 可能高达 7935 字节，可容纳 100 多个小（例如 50 字节）的分组，但只能容纳少数（5 个）较大（1500 字节）的数据分组。 A-MSDU 仅对应一个 FCS。更大的 A-MSDU 帧会增大交付出错的概率，由于整个聚合只是针对一个 FCS，因此在出错时将不得不重传整个帧。</p>
<p>A-MPDU 聚合是另一种形式的聚合，多个（最多 64 个） 802.11 帧可聚合起来，每个帧有自己的 802.11 MAC 头部和 FCS，每个帧最多 4095 字节。 A-MPDU 可携带最多 64KB 的数据，足够包含 1000 多个小的分组和大约 40 个较大（1.5KB）的分组。由于每个子帧都携带自己的 FCS，因此可有选择地重传那些出错的子帧。这使得 802.11n （最初在 802.11e）中的块确认功能成为可能，它是一种扩展的确认形式，为发送方提供哪个 A-MPDU 子帧交付成功的反馈信息。这种功能在目的上类似，但在细节上不同，我们将在 TCP （见第 14 章）中介绍选择确认。因此， A-MSDU 提供的聚合类型在无差错网络中传输大量小的分组时可能更有效率，但在实际运行中可能不如 A-MPDU 聚合好 [<a href="#S08">S08</a>] 。</p>
<h3 id="352-省电模式和时间同步功能">3.5.2 省电模式和时间同步功能</h3>
<p>802.11 规范提供一种使站进入有限电源状态的方式，称为<strong>省电模式（PSM）</strong>。 PSM 的设计目标是为了节省电源， STA 可在某个时间关闭无线电收发器电路。在不使用 PSM 时，收发器电路将始终运行，并消耗能量。在使用 PSM 时， STA 的输出帧在帧控制字中设置 1 位。当 AP 发现某些帧的该位被设置时，它会缓冲该帧直到该站需要时为止。 AP 发送信标帧（一种管理帧）提供不同信息，例如 SSID、信道和认证信息。当某个站使用 PSM 时， AP 可向该站提示存在缓冲的帧，只需在发送帧的<strong>帧控制字</strong>中设置一个标识。在某个站执行 PSM 后，它会一直保持这样，直到接收到下一个 AP 信标帧，这时它将苏醒过来，并确定 AP 中是否有为它缓存的帧。</p>
<p>我们应了解和关注 PSM 的使用。虽然它可能延长电池寿命，但是在大多数无线设备中，NIC 不是唯一可节约电源的模块。系统其他部分（例如屏幕和硬盘驱动器）也是电源的主要消耗者，因此总的电池寿命可能不会延长太多。另外， PSM 可能显著影响在帧传输之间空闲期间的吞吐量，时间被过多花费在模式切换上 [<a href="#SHK07">SHK07</a>] 。</p>
<p>在正确的时间（即一个 AP 打算发送一个信标帧时）唤醒 STA 检查等候帧的能力，取决于这个 AP 和它所服务的站对时间的感知。 Wi-Fi 采用<strong>时间同步功能（TSF）</strong>。每个站保持一个 64 位计数器的参考时间（微秒），这个时间与网络中的其他站保持同步。同步保持在 4μs 加 PHY （速率为 1Mb/s 或以上）最大传播延迟之内。这是通过多个站接收一个 TSF 更新（另一个站发送的 64 位计数器副本），并检查其中的值是否比自己的值更大来实现。如果是，接收站将自己的时间更新为更大的值。这种方法可确保时钟总是向前走，但它也会带来一些问题，如果不同站的时钟速率稍有差异，较慢的站就会被最快的站的时钟所同步。</p>
<p>通过将 802.11e （QoS）功能纳入 802.11 中， 802.11 的 PSM 扩展为提供定期批处理缓冲帧功能。这个频率用信标帧的数量来表示。这个功能被称为<strong>自动省电交付模式（APSD）</strong>，它使用 QoS 控制字中的一些子字段。 APSD 对电源有限的设备可能非常有用，因为它们不像传统 802.11 PSM 那样，并不需要在每个信标间隔都被唤醒。相反，它们可选择在自己所选的较长时间内关闭无线电收发器电路。 802.11n 也扩展了 PSM 基本功能，允许一个 STA 装备的多个射频电路（见 3.5.4.2 节 MIMO）共同工作，关闭所有而不是其中一个电路，直到准备好一个帧为止。这被称为<strong>空间复用</strong>省电模式。这个规范还包括称为<strong>省电多重轮询</strong>的增强型 APSD，它提供同时双向（例如，到达 AP 和来自 AP）传输帧的方法。</p>
<h3 id="353-80211-介质访问控制">3.5.3 802.11 介质访问控制</h3>
<p>与有线网络（例如 802.3 局域网）相比，在无线网络中检测“冲突”具有更大挑战性。实际上，介质是相对单一的，无论是集中方式还是分布方式，都需要协同传输，避免多个站同时发送。 802.11 标准采用三种方法控制共享的无线介质，它们分别称为<strong>点协调功能（PCF）</strong>、<strong>分布式协调功能（DCF）<strong>和</strong>混合协调功能（HCF）</strong>。 HCF 被纳入 802.11 规范 [<a href="#802.11-2007">802.11-2007</a>] ，在 802.11e 中增加支持 QoS，它也被用于 802.11n。某些类型的站或 AP 强制实现 DCF，也可选择实现 PCF，但 PCF 使用得并不广泛（因此我们不详细讨论）。相对较新的支持 QoS 的 Wi-Fi 设备通常会实现 HCF，例如 802.11n 的 AP 和更早的 802.11e 的 AP。现在，我们将注意力转移到 DCF 上，并在下面的 QoS 内容中描述 HCF。</p>
<p>DCF 是一种 CSMA/CA 类型，是基于竞争的介质访问方法。它可用于基础设施和 Ad hoc 网络。通过 CSMA/CA，一个站可查看介质是否空闲，如果空闲，它将有机会传输。如果不空闲，它在一段随机的时间内避免发送，直到它再次查看介质是否空闲为止。这个行为与有线局域网中使用的 CSMA/CD 检测方法相似。 802.11 信道仲裁是对 CSMA/CA 的改进，提供优先访问某些站或帧的功能。</p>
<p>802.11 载波侦听能以物理和虚拟方式实现。一个站在准备发送时，通常需要等待一段时间（称为<strong>分布式帧间间隔（DIFS）</strong>），以允许更高优先级的站访问信道。如果信道在 DIFS 期间变得繁忙，该站再次开始一个等待时间。当介质出现空闲时，希望发送数据的站将启动 3.5.3.3 节所述的冲突避免/退避过程。这个过程在一次成功（失败）的传输后，通过一个 ACK 知道数据被接收（或没有接收）后启动。在传输不成功的情况下，经过不同时间（称为<strong>扩展帧间间隔（EIFS）</strong>）启动退避过程。现在，我们将详细地讨论 DCF 实现，包括虚拟和物理载波侦听机制。</p>
<h4 id="3531-虚拟载波侦听-rtscts-和网络分配向量">3.5.3.1 虚拟载波侦听、RTS/CTS 和网络分配向量</h4>
<p>在 802.11 MAC 协议中，虚拟载波侦听机制会检查每个 MAC 帧中的<strong>持续时间</strong>字段。这通过站的侦听而非引导流量来实现。 RTS 和 CTS 帧中都有一个<strong>持续时间</strong>字段，它们像普通帧那样在传输之前可选择是否交换，并估计介质将处于繁忙状态的时间。</p>
<p>发送方基于帧长度、传输速率和 PHY 特性（例如速率等）设置<strong>持续时间</strong>字段。每个站保持一个称为<strong>网络分配向量（NAV）<strong>的本地计数器，它被用于估计介质传输当前帧所需的时间，以及尝试下一次传输之前需等待的时间。当一个站侦听到一个</strong>持续时间</strong>大于自己的 NAV 时，它将自己的 NAV 更新为这个值。由于 RTS 和 CTS 帧中都有<strong>持续时间</strong>字段，如果使用 NAV，在其范围内的任何站（无论是发送方还是接收方）都能看到<strong>持续时间</strong>字段值。 NAV 采用单位时间来维护，并基于本地时钟递减。当本地 NAV 不为 0 时，介质被认为是繁忙的。在接收到一个 ACK 后，本地 NAV 将复位为 0。</p>
<h4 id="3532-物理载波侦听cca">3.5.3.2 物理载波侦听（CCA）</h4>
<p>每个 802.11 PHY 规范（例如，对于不同的频率和无线电技术）需提供一种评估信道是否空闲的功能，它基于能量和波形识别（通常是一个完好的 PLCP）。这个功能称为<strong>空闲信道评估（Clear Channel Assessment， CCA）</strong>，它的实现依赖于 PHY。 CCA 功能是针对 802.11 MAC 的物理载波侦听功能，用于了解介质当前是否繁忙。它通常与 NAV 结合使用，以确定一个站在传输之前是否需要推迟（等待）。</p>
<h4 id="3533-dcf-冲突避免退避过程">3.5.3.3 DCF 冲突避免/退避过程</h4>
<p>在确定某个信道可能空闲时（已到达 NAV 持续时间，并且 CCA 没有提示信道繁忙），一个站在传输之前需推迟访问该信道。由于很多站可能在等待信道变空闲，每个站在发送之前需计算和等待一个<strong>退避时间</strong>。退避时间等于一个随机数和<strong>时隙</strong>的乘积（除非该站已有一个非零的退避时间尝试传输，在这种情况下无须重新计算）。时隙依赖于 PHY，通常是几十微秒。随机数是一个在区间 <code>[0，CW]</code> 中均匀分布的数值，**竞争窗口（CW）**是一个整数，其中包含许多等待时隙，且 <code>aCWmin ≤ CW ≤ aCWmax</code> （该限制由 PHY 定义）。 CW 值的集合从 PHY 指定的常数 aCWmin 开始，以 2 的幂（减 1）增加，直到每个连续传输尝试次数的常数 aCWmax 为止。这样做与以太网中由冲突检测事件引发的退避过程相似。</p>
<p>在无线环境中，冲突检测是不实际的。由于难以发现发送方和接收方同时发送，也难以监听自己之外的传输，因此采用<strong>冲突避免</strong>来代替冲突检测。另外， ACK 是针对单播帧的响应，以确定一个帧是否成功传递。当一个站正确接收一个帧时，在等待一小段时间（称为<strong>短帧间间隔（SIFS）</strong>）后开始传输 ACK，并且不考虑介质的忙碌/空闲状态。这样做不会导致问题，由于 SIFS 的值始终比 DIFS 小，因此该站产生的 ACK 可优先访问信道，以完成接收确认。源站在一定时间内没有接收到 ACK，则意味着一次传输失败。在失败后，源站启动前面讨论的退避过程，并重新尝试发送帧。如果在一定时间（CTStimeout 常数）内没有接收到对较早 RTS 响应的 CTS，则启动同样的过程。</p>
<h4 id="3534-hcf-和-80211en-的-qos">3.5.3.4 HCF 和 802.11e/n 的 QoS</h4>
<p>802.11标准 [<a href="#802.11-2007">802.11-2007</a>] 中的条款 5、 6、 7 和 9 都基于 IEEE 802.11e 工作组的部分工作，常用的术语有 802.11e、Wi-Fi QoS和 WMM（基于Wi-Fi的多媒体）。它们涉及 QoS 功能：修改 802.11 MAC 层和系统接口以支持多媒体应用，例如 IP 语音（VoIP）和流媒体。 QoS 功能实际是否必要，取决于网络层拥塞和应用类型。如果网络利用率较低，可能不必要支持 QoS 的 MAC，虽然其他 802.11e 功能可能有用（例如块确认和 APSD）。在网络利用率和拥塞较高的情况下，需要为 VoIP 等服务提供低抖动交付能力，这时支持 QoS 可能是可取的。这些规范相对较新，支持 QoS 的 Wi-Fi 设备通常比不支持 QoS 的设备更昂贵和更复杂。</p>
<p>QoS 功能引入了新的术语，例如 QoS 站（QSTA）、 QoS 接入点（QAP）和 QoS BSS（QBSS，支持QoS 的 BSS）。在一般情况下，支持 QoS 功能的设备也支持传统的非 QoS 操作。 802.11n “高吞吐量”站（又称为 HTSTA）也是 QSTA。<strong>混合协调功能（HCF）<strong>是一种新的协调功能，支持基于竞争和可控制的信道访问，尽管可控制的信道访问技术很少使用。在 HCF 中，有两种专门的信道访问方法可协同工作：<strong>HFCA 控制信道访问（HCCA）<strong>和更流行的</strong>增强型 DCF 信道访问（EDCA）</strong>，它们分别对应于基于预约和基于竞争的访问。这里也有一些对</strong>准入控制</strong>的支持，它们可在高负载下完全拒绝访问。</p>
<p>EDCA 建立在基本的 DCF 访问之上。通过 EDCA， 8 个<strong>用户优先级（UP）<strong>被映射为 4 个</strong>访问类别（AC）</strong>。用户优先级使用与 802.1d 优先级标记相同的结构，并被编号为 1 至 7 （在 2 和 3 之间还有一个优先级 0），其中 7 为最高优先级。 4 个访问类别分别为背景、尽力而为、视频和音频流量。优先级 1 和 2 用于背景 AC，优先级 0 和 3 用于尽力而为 AC，优先级 4 和 5 用于视频 AC，优先级 6 和 7 用于音频 AC。对于每个 AC， DCF 的一个变种竞争信道访问许可，称为<strong>传输机会（TXOP）</strong>，为较高优先级的流量使用可选的 MAC 参数。在 EDCA 中，很多来自 DCF 的 MAC 参数（例如， DIFS、 aCWmin、 aCWmax）作为配置参数是可调整的。这些值可通过管理帧传输给 QSTA。</p>
<p>HCCA 松散地建立在 PCF 之上，并使用轮询来控制信道访问。它属于同步方式的访问控制，并优先于基于竞争的 EDCA 访问。<strong>混合协调（HC）<strong>位于一个 AP 中，并优先于信道访问分配。在一次传输之前，一个站可为其流量发布一个</strong>流量规范（TSPEC）</strong>，并使用 8 和 15 之间的 UP 值。 HC 可为这种请求分配保留的 TXOP，它被用于基于 EDCA 的帧传输之前的短期控制访问阶段的帧交换。 HC 可拒绝 TXOP 的基于网络管理员设置的管理控制策略的 TSPEC。 HCF 利用前面讨论过的虚拟载波侦听机制和 DCF，以避免基于竞争的站被不基于竞争的访问所干扰。注意，在包括 QSTA 和常规站的网络中，可同时运行 HCF 和 DCF，并在两者之间切换，但 Ad hoc 网络不支持 HC，因此它不处理 TSPEC 和不执行管理控制。这种网络可能仍运行 HCF，但 TXOP 通过基于 EDCA 的竞争来获得。</p>
<h3 id="354-物理层的细节速率-信道和频率">3.5.4 物理层的细节：速率、信道和频率</h3>
<p>目前， [<a href="#802.11-2007">802.11-2007</a>] 标准包括以下较早的修订版：802.11a、 802.11b、 802.11d、 802.11g、802.11h、 802.11i、 802.11j 和 802.11e。 802.11n 标准在 2009 年被采纳为 802.11 的修订版 [<a href="#802.11n-2009">802.11n-2009</a>]。大多数的修订版为 802.11 网络提供额外的调制、编码和工作频率，但 802.11n 还增加了多种数据流和一种聚合多帧方法（见3.5.1.3节）。我们尽量避免详细讨论物理层，这里只是看一下可选的内容。表 3-2 包括 802.11 标准中特别描述的物理层部分。</p>
<center>表 3-2   802.11 标准中描述的物理层部分</center>
<table>
<thead>
<tr>
<th>标准（条款）</th>
<th>速率（Mb/s）</th>
<th>频率范围；调制</th>
<th>信道设置</th>
</tr>
</thead>
<tbody>
<tr>
<td>802.11a（第 17 条）</td>
<td>6、9、12、18、24、36、48、54</td>
<td>5.16GHz ~ 5.35GHz 和 5.725 ~ 5.825GHz；OFDM</td>
<td>37 ~ 168（根据国家不同），20MHz/10MHz/5MHz 信道宽度选项</td>
</tr>
<tr>
<td>802.11b（第 18 条）</td>
<td>1、2 、5.5、11</td>
<td>2.401GHz ~ 2.495GHz；DSSS</td>
<td>1 ~ 14（根据国家不同）</td>
</tr>
<tr>
<td>802.11g（第 19 条）</td>
<td>1、2 、5.5、6、9、11、12、18、24、36、48、54（加 22、23）</td>
<td>2.401GHz ~ 2.495GHz；OFDM</td>
<td>1 ~ 14（根据国家不同）</td>
</tr>
<tr>
<td>802.11n</td>
<td>6.5 ~ 600，很多选项（最多 4 个 MIMO 流）</td>
<td>2.4GHz 和 5GHz 模式，信道宽度 20MHz 或 40MHz；OFDM</td>
<td>1 ~ 13（2.4GHz 频段）；36 ~ 196（5GHz 频段）（根据国家不同）</td>
</tr>
<tr>
<td>802.11y</td>
<td>（与 802.11-2007 相同）</td>
<td>3.650GHz ~ 3.700GHz （需许可）；OFDM</td>
<td>1 ~ 25；36 ~ 64；100 ~ 161（根据国家不同）</td>
</tr>
</tbody>
</table>
<p>第一列给出了标准的原有名称和在 [<a href="#802.11-2007">802.11-2007</a>] 中的当前位置，并增 802.11n 和 802.11y 修订版的细节。在这个表中，需要注意的是， 802.11b/g 工作在 2.4GHz 的**工业、科学和医疗（ISM）<strong>频段， 802.11 仅工作在更高的 5GHz 的</strong>无须许可的国家信息基础设施（U-NII）**频段，而 802.11n 可工作在这两个频段。 802.11y 修订版在美国工作在需要许可的 3.65 ~ 3.70GHz频段。我们应注意的一个重要的实践结论是：802.11b/g 设备与 802.11a 设备不会互操作或干扰，但是如果不认真进行部署， 802.11n 设备可能被任何设备干扰。</p>
<h4 id="3541-信道和频率">3.5.4.1 信道和频率</h4>
<p>监管机构（例如美国联邦通信委员会）将电磁波谱划分为不同频率范围，并分配给世界各地的不同应用。对于每个频率范围及其用途，根据本地政策可能需要或不需要申请许可证。在 802.11 中，多个信道可能以不同方式、不同功率水平工作，这取决于所在地区或国家的监管。 Wi-Fi 信道在某个基本中心频率的基础上以 5MHz 为单位进行编号。例如，信道 36 的基本中心频率为 5.00GHz，则信道 36 的中心频率为 <code>5000 + 36*5 = 5180MHz</code>。虽然信道的中心频率之间以 5MHz 为间隔，但信道宽度可能超过 5MHz（802.11n 高达 40MHz）。因此，信道集中的某些频段内的信道经常重叠。实际上，这意味着一个信道上的传输可能干扰附近信道上的传输。</p>
<p>图 3-20 给出了 802.11b/g 信道在 2.4GHz 的 ISM 频段内的信道与频率映射。每个信道宽度为 22MHz。并非所有信道都可在每个国家合法使用。例如，信道 14 仅被授权在日本使用，信道 12 和 13 被授权在欧洲使用，而美国只能使用信道1 ~ 11。其他国家可能更严格（见 802.11 标准的 Annex J 和修订版）。注意，政策和许可要求可能随时间而改变。</p>
<figure data-type="image" tabindex="20"><img src="https://wenbozhangw.github.io//post-images/1652883012661.png" alt="图 3-20" loading="lazy"></figure>
<p>图 3-20   802.11b 和 802.11g 标准使用 2.4GHz 和 2.5GHz 之间的频段。这个频段被划分为 14 个 22MHz 宽的重叠信道，其中一些子集是否可合法使用取决于所在国家。在同一地区运行多个基站，分配非重叠的信道是可取的做法，例如美国的 1、 6 和 11。只有一个 40MHz 的 802.11n 信道可用于此频段而不会发生重叠</p>
<p>如图 3-20 所示，重叠信道的影响是明显的。例如，一个传输方工作在信道 1 上，它与信道 2、 3、 4 和 5 重叠，但与更高的信道不重叠。在可使用多个接入点的环境中，选择使用哪条信道是很重要的，当同一区域中有多个接入点为多个网络提供服务时，如何选择信道至关重要。在美国，常用方法是同一区域中的 3 个 AP 使用不重叠的信道 1、 6 和 11，信道 11 在美国是无须许可即可使用的最高频率信道。在其他无线局域网也在同一频段运行的情况下，应该由所有受影响的 WLAN 管理员共同规划信道。</p>
<p>如图 3-21 所示， 802.11a/n/y 共享一个有些复杂的信道设置，但提供了更多的不重叠信道（即美国的 12 个无须许可的 20MHz 信道）。</p>
<p>在图 3-21 中，信道以 5MHz 为单位递增，但存在不同的信道宽度：5MHz、 10MHz、20MHz 和 40MHz。 40MHz 信道宽度是 802.11n 的一个选项（见 3.5.4.2 节），可将几个不同所有者的 Wi-Fi 系统聚合为 2 个 20MHz 信道（称为信道绑定）。</p>
<figure data-type="image" tabindex="21"><img src="https://wenbozhangw.github.io//post-images/1652883308062.png" alt="图 3-21" loading="lazy"></figure>
<p>图 3-21   20MHz 信道中的一些可用的 802.11 信道号和中心频率。最常见的无须许可使用的频率范围包括 U-NII 频段，它们均在 5GHz 之上。较低频段被批准可用于大多数国家。 “欧洲”频段被批准用于大多数欧洲国家，高频段被批准用于美国和中国。 802.11a/y 信道的典型宽度为 20MHz，但 802.11n 的信道宽度可能为 40MHz。另外，在日本也可使用窄信道和某些信道（未显示）</p>
<p>对于典型的 Wi-Fi 网络，在 AP 安装过程中需要指定其运行信道，并由用户所在的站修改信道以便连接到 AP。当运行在 Ad hoc 模式时，没有起控制作用的 AP，因此一个站通常需要为 AP 手工配置信道。可用的信道和运行功率可能受限于监管环境、硬件功能，以及所支持的驱动程序软件。</p>
<h4 id="3542-更高吞吐量的-80211802211n">3.5.4.2 更高吞吐量的 802.11/8022.11n</h4>
<p>2009 年年底， IEEE 将 [<a href="#802.11-2007">802.11-2007</a>] 修订为802.11n [<a href="#802.11n-2009">802.11n-2009</a>]。它对 802.11 做了一些重要改变。为了支持更高吞吐量，它采用<strong>多输入多输出（MIMO）<strong>管理</strong>空间流（Spatial Stream）</strong>，即由多个天线同时传输的多个数据流。一个给定信道上最多支持 4 个这种空间流。802.11n 信道宽度可以是 40MHz （使用两个相邻的 20MHz 信道），这是传统 802.11a/b/g/y 信道宽度的两倍。因此，它可将 802.11a/g 的最大传输速率（54Mb/s）提高 8 倍，达到 432Mb/s。802.11n 也提高了单个流的性能，使用一种更高效的调制方案（802.11n采用 MIMO-正交频分复用（OFDM），每个 20MHz 信道最多承载 52 个数据载波，每个 40MHz 信道最多承载 108 个数据载波，代替 802.11a 和 802.11g 中的 48 个），以及一种更有效的转发纠错编码（以编码率 5/6 代替 3/4），将每个流性能提升到 65Mb/s （20MHz 信道）或 135Mb/s （40MHz信道）。通过将<strong>保护间隔</strong>（GI，一个强制的符号之间的空闲时间）从传统的 800ns 减少到 400ns，每个流的最大性能可提高到 72.2Mb/s （20MHz信道）和 150Mb/s （40MHz信道）。通过 4 个空间流的完美协同操作，这样可提供最高 600Mb/s 的传输速率。</p>
<p>802.11n 标准支持大约 77 种调制和编码选项组合，其中包括 8 种对应单个流的选项， 24 种可在所有流中使用的**平等调制（EQM）<strong>选项，以及 43 种可在多个流上使用的</strong>不平等调制（UEQM）<strong>选项。表 3-3 给出了调制和编码方案的一些组合，对应于</strong>调制和编码方案（MCS）**的前 33 个值。更大的值（33 - 76）包括 2 个信道（值 33 - 38）、3 个信道（39 - 52）和 4 个信道（53 - 76）的组合。 MCS 值 32 是一个特殊组合，即 40MHz 信道的两路信号包含相同信息。每行给出了 2 个数据传输速率，一个使用早期的 800ns GI，一个使用较短的 400ns GI 以获得更大传输速率。两个带下划线的值 6Mb/s 和 600Mb/s，分别表示最小和最大吞吐率。</p>
<center>表 3-3   802.11n 的 MCS 值包括平等和不平等调制，不同的 FEC 编码率，使用 20MHz 或 40MHz 信道宽度的 4 个空间流，以及 800ns 或 400ns GI 的组合。77 种组合提供从 6Mb/s 到 600Mb/s 的数据传输速率</center>
<table>
<thead>
<tr>
<th>MCS 值</th>
<th>调制类型</th>
<th>FEC 编码率</th>
<th>空间流</th>
<th>速率（Mb/s）（20MHz）[800/400ns]</th>
<th>速率（Mb/s）（40MHz）[800/400ns]</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>BPSK</td>
<td>1/2</td>
<td>1</td>
<td>6.5/7.2</td>
<td>13.5/15</td>
</tr>
<tr>
<td>1</td>
<td>QPSK</td>
<td>1/2</td>
<td>1</td>
<td>13/14.4</td>
<td>27/30</td>
</tr>
<tr>
<td>2</td>
<td>QPSK</td>
<td>3/4</td>
<td>1</td>
<td>19.4/21.7</td>
<td>40.5/45</td>
</tr>
<tr>
<td>3</td>
<td>16-QAM</td>
<td>1/2</td>
<td>1</td>
<td>26/28.9</td>
<td>54/60</td>
</tr>
<tr>
<td>4</td>
<td>16-QAM</td>
<td>3/4</td>
<td>1</td>
<td>39/43.3</td>
<td>81/90</td>
</tr>
<tr>
<td>5</td>
<td>16-QAM</td>
<td>2/3</td>
<td>1</td>
<td>52/57.8</td>
<td>108/120</td>
</tr>
<tr>
<td>6</td>
<td>16-QAM</td>
<td>3/4</td>
<td>1</td>
<td>58.5/65</td>
<td>121.5/135</td>
</tr>
<tr>
<td>7</td>
<td>16-QAM</td>
<td>5/6</td>
<td>1</td>
<td>65/72.2</td>
<td>135/150</td>
</tr>
<tr>
<td>8</td>
<td>BPSK</td>
<td>1/2</td>
<td>2</td>
<td>13/14.4</td>
<td>27/30</td>
</tr>
<tr>
<td>...</td>
<td>....</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr>
<td>15</td>
<td>64-QAM</td>
<td>5/6</td>
<td>2</td>
<td>130/144.4</td>
<td>270/300</td>
</tr>
<tr>
<td>16</td>
<td>BPSK</td>
<td>1/2</td>
<td>3</td>
<td>19.5/21.7</td>
<td>40.5/45</td>
</tr>
<tr>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr>
<td>31</td>
<td>64-QAM</td>
<td>5/6</td>
<td>4</td>
<td>260/288.9</td>
<td>540/600</td>
</tr>
<tr>
<td>32</td>
<td>BPSK</td>
<td>1/2</td>
<td>1</td>
<td>N/A</td>
<td>6/6.7</td>
</tr>
<tr>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr>
<td>76</td>
<td>64x3/16x1-QAM</td>
<td>3/4</td>
<td>4</td>
<td>214.5/238.3</td>
<td>445.5/495</td>
</tr>
</tbody>
</table>
<p>表 3-3 显示了可用于 802.11n 的各种编码组合，包括<strong>二进制相移键控（BPSK）</strong>、<strong>正交相移键控（QPSK）</strong>，以及各种<strong>正交幅度调制（16-QAM和64-QAM）</strong>。这些调制方案为给定的信道提供更大的传输速率。但是，性能更高和更复杂的调制方案，通常更容易受到噪声干扰。**转发纠错（FEC）**包括一套方法，在发送方引入一些冗余位，用于检测和修改传输过程中的错误。对于 FEC，编码率是可用传输速率与底层信道规定速率之比。例如， 1/2 编码率表示每发送 2 位数据，只有 1 位有效交付。</p>
<p>802.11n 可工作在 3 种模式下。在 802.11n 环境中，可选择所谓的<strong>绿地模式</strong>， PLCP 包含特殊位序列（“训练序列”），它仅被 802.11n 设备获得，不与传统设备进行互操作。为了保持兼容性， 802.11n 提供了 2 种互操作模式。但是，这些模式对纯 802.11n 设备会带来性能损失。一种模式称为<strong>非 HT 模式</strong>，禁止所有 802.11n 功能，但仍与原有设备兼容。这不是一种很有趣的模式，因此我们不再进一步讨论。另一种模式称为 <strong>HT 混合模式</strong>，支持 802.11n 和传统操作，这取决于与哪个站进行通信。 PLCP 给出了向 HT STA 提供 AP 的802.11n 功能和保护传统 STA 所需的信息， PLCP 被修订为包含 HT 和传统信息，并以一个比绿地模式慢的速度传输，以便传统设备来得及处理。在一个传统站使用共享信道时， HT 保护还要求 HTAP 使用自定向 CTS 帧（或 RTS/CTS 帧交换）以传统速率通知传统站。尽管 RTS/CTS 帧是短的，但由于它们是以传统速率（6Mb/s）发送，所以这将显著降低 802.11n WLAN 性能。</p>
<p>在部署一个 802.11n AP 时，应考虑分配适当的信道。在使用 40MHz 信道时， 802.11n AP 应运行在 5GHz 以上的 U-NII 频段， 2.4GHz 的 ISM 频段中根本没有足够的可用频段提供这么宽的信道。一种可选的 BSS 功能称为<strong>分阶段共存操作（PCO）</strong>，允许一个 AP 定期在 20MHz 和 40MHz 信道宽度之间切换，更好地提供 802.11n AP 之间的共存，以一些额外流量代价为附近的传统设备提供服务。最后值得一提的是， 802.11n AP 通常比传统 AP 消耗更多能量。这种比基本的 15W 更高的电源功率，可由 **802.3af 以太网供电（PoE）**系统提供，这意味着需要使用 PoE+ （802.3at 能提供 30W），除非有其他形式的电源（例如一个外接电源）。</p>
<h3 id="355-wi-fi-安全">3.5.5 Wi-Fi 安全</h3>
<p>802.11 网络的安全模型有很大变化。早期， 802.11 采用一种称为**有线等效保密（WEP）**的加密方法。 WEP 后来被证明安全性薄弱，并出现了替换它的需求。工业界通过 <strong>Wi-Fi 保护访问（WPA）<strong>来回应，它使用加密块（见第 18 章的密码学基础知识）代替密钥方式。在 WPA 中，采用一种称为</strong>临时密钥完整性协议（TKIP）<strong>的方案，确保每个帧都用不同密钥加密。它还包括一种称为 Michael 的消息完整性检查，以弥补 WEP 中的主要弱点之一。 WPA 被创建为一个占位符，可通过硬件升级方式使设备支持 WEP 功能。 IEEE 802.11i 工作组制定了一个功能更强的标准，最终被吸收到 [<a href="#802.11-2007">802.11-2007</a>] 的第 8 条，并被工业界称为“WPA2”。WEP 和 WPA 都使用 RC4 加密算法 [<a href="#S96">S96</a>]。 WPA2 使用</strong>高级加密标准</strong>（AES）算法 [<a href="#AES01">AES01</a>]。</p>
<p>我们刚才讨论的加密技术，用于在站和 AP 之间提供隐私保护（假设站拥有访问网络的合法授权）。在使用 WEP、 WPA 或 WPA2 的小规模环境中，授权通常通过预先设置一个共享密钥或密码来实现，它在每个站和 AP 的配置过程中生成。知道这个密钥的用户拥有访问网络的合法授权。这些密钥常用于保护隐私的加密密钥的初始化。这种<strong>预共享密钥（PSK）<strong>具有局限性。例如，管理员为授权用户提供密钥，这可能是相当麻烦的事。如果一个新的用户被授权，必须更换 PSK 并通知所有合法用户。这种方法难以用于有很多用户的环境。因此， WPA 和后期标准支持</strong>基于端口的网络访问控制</strong>标准，称为 802.1x [<a href="#802.1x-2010">802.1x-2010</a>]。它提供了一种在 IEEE 802 局域网（称为 EAPOL，包括 802.3 和 802.11 [<a href="#RFC4017">RFC4017</a>]）中使用<strong>扩展身份验证协议（EAP）</strong>  [<a href="#RFC3748">RFC3748</a>] 的方式。 EAP 可使用多种标准和非标准化的认证协议。它也可用于建立密钥，包括 WEP 密钥。第 18 章将详细讨论这些协议。我们在 3.6 节讨论 PPP 时也会看到 EAP 的使用。</p>
<p>随着 IEEE 802.11i 工作组的工作完成， WPA 和 RC4/TKIP 组合扩展为一个称为 CCMP 的新方案，它被作为 WPA2 的一部分。 CCMP 是基于<strong>计数器模式</strong>（CCM [<a href="#RFC3610">RFC3610</a>]）的 AES ，以确保用于认证和完整性的<strong>密码块链接消息认证码</strong>（CBC-MAC；注意术语MAC在这里的“其他”用途）的安全。 AES 采用 128 位的块和 128 位的密钥。 CCMP 和 TKIP 形成了 Wi-Fi 安全体系结构的基础，称为<strong>强健安全网络（RSN）</strong>，并支持<strong>强健安全网络访问（RSNA）</strong>。早期的一些方法（如 WEP）称为预 RSNA 方法。 RSNA 要求支持 CCMP （TKIP 可选），而 802.11n 标准完全不使用 TKIP。表 3-4 总结了这种复杂情况。</p>
<center>表 3-4   Wi-Fi 安全已从不安全的 WEP 演变到 WPA，再到当前标准的 WPA2 方案</center>
<table>
<thead>
<tr>
<th>名称/标准</th>
<th>密码</th>
<th>密钥流管理</th>
<th>认证</th>
</tr>
</thead>
<tbody>
<tr>
<td>WEP（预 RSNA）</td>
<td>RC4</td>
<td>（WEP）</td>
<td>PSK，（802.1X/EAP）</td>
</tr>
<tr>
<td>WPA</td>
<td>RC4</td>
<td>TKIP</td>
<td>PSK，802.1X/EAP</td>
</tr>
<tr>
<td>WPA2/802.11(i)</td>
<td>CCMP</td>
<td>CCMP，（TKIP）</td>
<td>PSK，802.1X/EAP</td>
</tr>
</tbody>
</table>
<p>在所有情况下，预共享密钥和 802.1X 可用于认证和初始化密钥。 802.1X/EAP 的主要吸引力在于其可管理的认证服务器，它基于 AP 为每个用户提供访问控制决策。出于这个原因，使用 802.1X 的认证有时称为“企业” （例如 WPA 企业）。 EAP 本身可封装各种认证协议，我们将在第 18 章详细讨论这些协议。</p>
<h3 id="356-wi-fi-网状网80211s">3.5.6 Wi-Fi 网状网（802.11s）</h3>
<p>IEEE 正在制定 802.11s 标准，其中包括 Wi-Fi 的<strong>网状网（Mesh）<strong>操作。通过 Mesh 操作，无线站点可用作数据转发代理（像 AP 那样）。在作者编写本书期间（2011 年中期），这个标准仍未完成。 802.11s 草案定义了</strong>混合无线路由协议（HWRP）</strong>，它基于 <strong>Ad hoc 按需距离向量（AODV）<strong>路由 [<a href="#RFC3561">RFC3561</a>] 和</strong>优化链路状态路由（OLSR）<strong>协议 [<a href="#RFC3626">RFC3626</a>] 等 IETF 标准。Mesh 站（Mesh STA）是一种 QoS 站，它可能参与 HWRP 或其他路由协议，但兼容节点必须包括 HWRP 实现和相关</strong>通话时间链路度量</strong>。 Mesh 节点使用 EDCA 来协同工作，或使用一种可选的称为 <strong>Mesh 确定性访问</strong>的协同功能。 Mesh 点（MP）是与邻居形成 Mesh 连接的那些节点。那些包含 AP 功能的 Mesh 点称为 Mesh AP （MAP）。常规 802.11 站可使用 AP 或 MAP 访问无线局域网的其他部分。</p>
<p>802.11s 草案为 RSNA 制定了一种可选的新安全方案，称为基于对等同时认证（SAE）的认证 [<a href="#SAE">SAE</a>]。这种安全协议与其他协议有些区别，它并不需要一个特定的发起者和响应者之间的操作同步。相反，所有站都被平等对待，先发现其他站的任何站可启动一次安全交换（这可能导致两个站同时启动一次交换）。</p>
<hr>
<h2 id="36-点到点协议">3.6 点到点协议</h2>
<p>PPP 表示点到点协议 [<a href="#RFC1661">RFC1661</a>] [<a href="#RFC1662">RFC1662</a>] [<a href="#RFC2153">RFC2153</a>] 。这是一种在串行链路上传输 IP 数据报的流行方法，从低速的拨号调制解调器到高速的光链路 [<a href="#RFC2615">RFC2615</a>]。它被一些 DSL 服务供应商广泛部署，也可分配 Internet 系统的参数（例如，最初的 IP 地址和域名服务器；见第 6 章）。</p>
<p>PPP 实际上是一个协议集合，而不是一个单一的协议。它支持建立链接的基本方法——称为<strong>链路控制协议（Link Control Protocol， LCP）</strong>，以及一系列 NCP 协议，在 LCP 建立了基本链路之后，用于为各种协议（包括 IPv4、 IPv6 和非 IP 协议）建立网络层链路。一些相关标准涉及对 PPP 的压缩和加密控制，以及在链接建立后的一些认证方法。</p>
<h3 id="361-链路控制协议">3.6.1 链路控制协议</h3>
<p>PPP 的 LCP 用于在点到点链路上建立和维护低层的双方通信路径。因此， PPP 操作只需关注一条链路的两端，它不需要像以太网和 Wi-Fi 的 MAC 层协议那样处理共享资源访问的问题。</p>
<p>PPP 通常对底层的点到点链路有最低要求，LCP 更是这样。链路必须支持双向操作（LCP 使用的确认），以及异步或同步操作。通常， LCP 使用简单的位级别帧格式，基于<strong>高级数据链路控制（HDLC）<strong>建立链路协议。在 PPP 设计时， HDLC 就已建立了一种良好的帧格式 [<a href="#ISO3309">ISO3309</a>] [<a href="#ISO4335">ISO4335</a>] 。 IBM 将它修改为</strong>同步数据链路控制（SDLC）</strong>，在其专用的**系统网络体系结构（SNA）**协议族中用作链路层协议。 HDLC 协议还用作 802.2 中 LLC 标准的基础，并最终被用于 PPP。 图 3-22 显示了这种格式。</p>
<figure data-type="image" tabindex="22"><img src="https://wenbozhangw.github.io//post-images/1652887335410.png" alt="图 3-22" loading="lazy"></figure>
<p>图 3-22   PPP 基本帧格式借用了 HDLC 的格式。它包括一个协议标识符、有效载荷区域，以及 2 或 4 字节的 FCS。其他字段是否存在取决于压缩选项</p>
<p>在通常情况下， PPP 帧格式类似于图 3-22 所示的 HDLC 帧，由 2 个 1 字节的包含固定值 <code>0x7E</code> 的<strong>标志</strong>字段“包围” 。点到点链路的两个端点使用这些字段来发现一个帧的开始和结束。如果 <code>0x7E</code> 值出现在帧内部，这时会带来一个小问题。它可通过两种方式来处理，这取决于 PPP 工作在异步还是同步链路上。对于异步链路， PPP 使用<strong>字符填充</strong>（也称为字节填充）。如果标志字符出现在帧中其他地方，则用 2 字节序列 <code>0x7D5E</code> （ <code>0x7D</code> 称为“ppp转义字符”）替换。如果转义字符本身出现在帧中，则用 2 字节序列 <code>0x7D5D</code>  替换。因此，接收方用 <code>0x7E</code> 替换接收的 <code>0x7D5E</code> ，并用 <code>0x7D</code> 替换接收的 <code>0x7D5D</code>。 在同步链路（例如 T1 线路、 T3 线路）上， PPP 使用<strong>位填充</strong>。注意，标志字符的位模式为 <code>01111110</code> （连续 6 个 1 的位序列），在除了标志字符之外的任何地方，位填充在 5 个连续 1 之后填充一个 0。这样做意味着，发送的字节可能超过 8 位，但这通常是正常的，因为低层串行处理硬件能去掉填充的比特流，并将它恢复成未填充时的样子。</p>
<p>在第一个标志字段之后， PPP 采用 HDLC 的<strong>地址</strong>（Addr）和控制字段。在 HDLC 中，地址字段用于指定哪个站正在处理，但是由于 PPP 只关心一个目的地，这个字段总是被设置为 <code>0xFF</code> （所有站）。 HDLC 控制字段用于指示帧序列和重传行为。由于这些链路层的可靠性功能通常不是由 PPP 实现，所以控制字段设置为固定值 <code>0x03</code>。 由于地址和控制字段在 PPP 中都是固定的常数，所以在传输过程中经常通过一个称为**地址和控制字段压缩（ACFC）**的选项来省略它们，该选项实质上是消除了这两个字段。</p>
<pre><code>注意   链路层网络应提供多少可靠性，多年来一直存在相当大的争议。在以太网
中，在放弃之前可尝试重传多达 16 次。通常， PPP 被配置为不重传，尽管确实
有增加重传的规范 [RFC1663]。折中方案是巧妙的，但它依赖于携带的流量类型。
[RFC3366] 详细讨论了要考虑的有关因素。
</code></pre>
<p>PPP 帧的<strong>协议</strong>字段表明携带的数据类型。在一个 PPP 帧中，可携带多种不同类型的协议。正式列表和用于<strong>协议</strong>字段的分配号显示在“点到点协议字段分配”文档中 [<a href="#PPPn">PPPn</a>] 。根据 HDLC 规范，协议号的分配方式为：高位字节的最低有效位为 0，低位字节的最低有效位为1。 <code>0x0000 ~ 0x3FFF</code> （十六进制）范围内的值表示网络层协议， <code>0x8000 ~ 0xBFFF</code> 范围内的值表示 NCP 的相关数据。 <code>0x4000 ~ 0x7FFF</code> 范围内的值用于 NCP 不相关的“很少使用的”协议。 <code>0xC000 ~ 0xEFFF</code> 范围内的值表示控制协议，例如 LCP。在某些情况下，如果**协议字段压缩（PFC）**选项在链路建立时协商成功，<strong>协议</strong>字段可被压缩为 1 字节。 <code>0x0000 ~ 0x00FF</code> 范围内的协议号适用于包括大多数流行的网络层协议在内的协议。注意， LCP 分组总是使用 2 字节的未压缩格式。</p>
<p>PPP 帧的最后部分包含一个 16 位的 FCS（一个 CRC16，生成多项式为 <code>10001000000100001</code>），涵盖除 FCS 字段本身和标志字节之外的整个帧。注意， FCS 的值涵盖任何字节或位被填充之前的帧。 LCP 选项（见 3.6.1.2 节）可将 CRC 从 16 位扩展到 32 位。在这种情况下，可采用与前面提到的以太网相同的 CRC32 多项式。</p>
<h4 id="3611-lcp-操作">3.6.1.1 LCP 操作</h4>
<p>LCP 在基本 PPP 分组之上进行了简单的封装。如图 3-23 所示。</p>
<figure data-type="image" tabindex="23"><img src="https://wenbozhangw.github.io//post-images/1652888191158.png" alt="图 3-23" loading="lazy"></figure>
<p>图 3-23   LCP 分组采用很普通的格式，能识别封装数据的类型和长度。 LCP 帧主要用于建立 PPP 链路，这种格式已成为很多网络控制协议的基础</p>
<p>LCP 的 PPP 协议字段值始终是 <code>0xC021</code>，它不能用 PFC 删除，以免产生歧义。<strong>标识</strong>字段是由 LCP 请求帧的发送方提供的序列号，并随着每个后续消息进行递增。在生成一个回复（ACK、 NACK 或 REJECT 响应）时，这个字段通过复制响应分组请求中包含的值来构造。采用这种方式，请求方可通过匹配标识符来识别相应请求的应答。<strong>代码</strong>字段给出了请求或响应的操作类型：配置请求（<code>0x01</code>）、配置 ACK （<code>0x02</code>）、配置 NACK （<code>0x03</code>）、配置 REJECT（<code>0x04</code>）、终止请求（<code>0x05</code>）、终止 ACK （<code>0x06</code>）、代码 REJECT（<code>0x07</code>）、协议REJECT（<code>0x08</code>）、回送请求（<code>0x09</code>）、回送应答 （<code>0x0A</code>）、放弃请求 （<code>0x0B</code>）、标识（<code>0x0C</code>）和剩余时间（<code>0x0D</code>）。 ACK 消息通常表明接受一组选项， NACK 消息用建议选项表明部分拒绝。 REJECT 消息完全拒绝一个或多个选项。拒绝代码表明前一个分组包含的某些字段值未知。长度字段给出了 LCP 分组的字节长度，它不能超过链路的<strong>最大接收单元（MRU）</strong>，我们稍后讨论一种建议的最大帧限制。注意，长度字段是 LCP 协议的一部分；PPP 协议通常不提供这种字段。</p>
<p>LCP 的主要工作是使一条点到点链路达到最低要求。<strong>配置</strong>消息使链路两端开始基本配置过程，并建立商定的选项。<strong>终止</strong>消息用于在完成后清除一条链路。 LCP 也提供了前面提到的一些附加功能。<strong>回送请求/应答</strong>消息可由 LCP 在一条活跃链路上随时交换，以验证对方的操作。<strong>放弃请求</strong>消息可用于性能测试，指示对方丢弃没有响应的分组。<strong>标识</strong>和<strong>剩余时间</strong>消息用于管理目的：了解对方的系统类型，指出链路保持建立的时间（例如出于管理或安全原因）。</p>
<p>从历史上来看，如果一个远程工作站处于<strong>环回模式</strong>（或者说“回路”），这时点到点链路会出现一个常见问题。电话公司的广域数据线路有时会为了测试而设置成环回模式，由一方发送的数据直接由另一方返回。虽然这可能对线路测试有用，但它对数据通信完全没有帮助，所以 LCP 包括一种发送<strong>魔术数字</strong>（由发送方选择的任意数字）的方式，并查看是否立即返回相同类型的消息。如果是的话，该线路被检测为处于回路，并可能需要进行维护。</p>
<p>为了对 PPP 链路建立和选项协商有一个更好的认识，图 3-24 显示了一个简化的分组交换时间表和一个简化的状态机（在链路两端实现）。</p>
<p>一旦底层协议表明一个关联变为活跃（例如调制解调器检测到载波），则认为这个链路已被建立。链路质量测试包含链路质量报告和确认交换（见 3.6.1.2 节），它也可以在此期间完成。如果链接需要认证（这是常见的），例如当拨号到一个 ISP 时，可能需要一些额外的信息交换，以认证链路上的一方或双方的身份。当底层协议或硬件表明一个关联已停止（例如载波消失），或发送一个链路终止请求，并从对方接收到一个终止响应，则认为这个链路已被终止。</p>
<figure data-type="image" tabindex="24"><img src="https://wenbozhangw.github.io//post-images/1652888802627.png" alt="图 3-24" loading="lazy"></figure>
<p>图 3-24   LCP 用于建立 PPP 链路和各方商定选项。典型的交换过程包括一对包含选项列表的配置请求和配置确认、一个认证交换、数据交换（未画出）和一个终止交换。因为 PPP 是一个包括很多部分的通用协议，所以在一条链路建立和终止之间可能发生很多其他类型的操作</p>
<h4 id="3612-lcp-选项">3.6.1.2 LCP 选项</h4>
<p>当 LCP 建立一条由一个或多个 NCP 使用的链路时，可以对一些选项进行协商。我们将讨论两种或更多的常见情况。**异步控制字符映射（ACCM）**或简称“ asyncmap”选项定义哪些控制字符（即 <code>0x00 ~ 0x1F</code> 范围内的 ASCII 字符）需要被“转义”为 PPP 操作。转义一个字符表示不发送这个字符的真实值，而将 PPP 转义字符（<code>0x7D</code>）放在控制字符原始值和 <code>0x2D</code> 异或形成的值之前。例如， XOFF 字符（<code>0x13</code>）将转换为（<code>0x7D33</code>）发送。 ACCM 用于控制字符可能影响底层硬件操作的情况。例如，如果软件流控制能够使用 XON/XOFF 字符，而 XOFF 字符未经转义就通过链路传输，则硬件直到看到一个 XON 字符才停止数据传输。asyncmap 选项通常是一个 32 位的十六进制数，其中第 n 个最低有效位被设置为 1 ，表示值为 n 的控制字符应被转义。因此， asyncmap 为 <code>0xffffffff</code> 表示转义所有控制字符，为 <code>0x00000000</code>表示不转义任何控制字符，为 <code>0x000A0000</code> 表示转义 XON （<code>0x11</code>）和 XOFF （<code>0x13</code>）。虽然 <code>0xffffffff</code> 是默认值，但当前很多链路可在 asyncmap 被设置为 <code>0x00000000</code> 时安全运行。</p>
<p>由于 PPP 缺少一个长度字段，并且串行线路通常不提供帧封装，所以在理论上对一个 PPP 帧的长度没有硬性限制。实际上，最大帧大小通常由 MRU 指定。当一台主机指定一个 MRU 选项（<code>0x01</code>）时，它要求对方不发送比 MRU 选项提供的值更长的帧。 MRU 值是数据字段的字节长度，它不计算其他 PPP 开销字段（即协议、 FCS、标志字段）。它的典型值是 1500 或 1492，但也可能多达 65535。 1Pv6 操作需要的长度最小为 1280。 PPP 标准要求具体实现能接收最大 1500 字节的帧， MRU 更多的是建议对方选择帧大小，而不是硬性限制帧大小。当小分组和大分组在同一条 PPP 链路上交错传输时，较大分组可能占用一条低带宽链路的大部分带宽，并影响小分组的正常传输。这可能导致抖动（延迟变化），对交互式应用（例如远程登录和 VoIP）产生负面影响。配置较小的 MRU （或 MTU）有助于缓解这个问题，但会产生更大的开销。</p>
<p>PPP 支持一种交换链路质量报告信息的机制。在选项协商期间，可能包括一个包含所请求的特定质量协议的配置信息。选项中的第 16 位被保留给特定协议，但最常见的是一个包括**链路质量报告（LQR）**的 PPP 标准 [<a href="#RFC1989">RFC1989</a>] ，它在 PPP 协议字段中使用值 <code>0xC025</code>。如果启用该选项，则要求对方按某个周期间隔提供 LQR。 LQR 请求之间的最大周期间隔被编码为一个 32 位数字，它被保存在配置选项中，并以 1/100 秒为单位表示。对方可能比这个要求更频繁地生成 LQR。LQR 包括以下信息：一个魔术数字、发送和接收的分组数和字节数、出错的输入分组数和丢弃的分组数，以及交换的 LQR 总数。在一个典型的实现中，允许用户设置对方发送 LQR 的频繁程度。如果链路质量无法满足某些配置阈值，有些实现也提供了终止链路的方法。 LQR 可在 PPP 链路进入建立状态后请求。每个 LQR 被赋予一个序列号，因此它能确定一段时间内的趋势，甚至在 LQR 重新排序时也能确定。</p>
<p>很多 PPP 实现支持一种<strong>回叫</strong>功能。在一次典型的回叫建立过程中， PPP 拨号回叫客户端呼叫 PPP 回叫服务器，并提供认证信息，而服务器断开连接并回叫客户端。在呼叫费用不对称或对于某些安全级别的情况下，这种做法可能是有用的。 LCP 选项针对用于协商回叫的协议，该选项值为 <code>0x0D</code>  [<a href="#RFC1570">RFC1570</a>]。如果许可，**回叫控制协议（CBCP）**完成协商。</p>
<p>PPP 使用的一些压缩和加密算法在处理时需要一定的最小字节数，称为<strong>块大小</strong>。在数据不够长的情况下，通过填充增加数据长度，达到一个甚至多个块的大小。如果存在填充，它通常位于数据区后面，并位于 PPP FCS 字段之前。一种填充方法称为<strong>自描述填充</strong> [<a href="#RFC1570">RFC1570</a>]，它将填充值变为非零值。这时，每个字节获得填充区域的偏移量值。因此，填充的第一个字节值为 <code>0x01</code>，最后一个字节包含填充字节数。最多支持 255 字节的填充。自描述填充选项（类型 10）用于让对方了解填充类型和<strong>最大填充值（MPV）</strong>，它是这个关联允许的最大填充值。由于基本 PPP 帧缺少一个明确的长度字段，因此一个接收方可使用自描述填充，以确定应从接收的数据区删除多少填充字节。</p>
<p>为了减小每个帧包含一个头部的固定开销，提出了一种将多个不同协议的有效载荷聚合成 PPP 帧的方法，称为 PPPMux [<a href="#RFC3153">RFC3153</a>] 方法。主要 PPP 头部的协议字段被设置为聚合帧（<code>0x0059</code>），然后每个有效载荷块被插入帧中。通过在每个有效载荷块之前插入 1 ~ 4 字节的子帧头部来实现。在子帧头部中， 1 位（称为 PFF）说明子帧头部中是否包含协议字段，1 位（称为 LXT）说明后面的长度字段是 1 字节还是 2 字节。除此之外， 1 或 2 字节的协议 ID 使用与外部的 PPP 头部相同的值和压缩方法。在子帧与默认 PID （该 PID 在配置阶段通过 **PPPMux 控制协议（PPPMuxCP）**建立）匹配时， PFF 可以为 0 （意味着不存在 PID 字段）。</p>
<p>PPP 帧格式如图 3-19 所示，普通 PPP/HDLC 的 FCS 可以是 16 或 32 位。默认的 FCS 为 16 位，但 32 位的 FCS 值可通过 32 位的 FCS 选项来启用。其他的 LCP 选项包括使用 PFC 和 ACFC，以及认证算法的选择。</p>
<p>国际化 [<a href="#RFC2484">RFC2484</a>] 提供了一种使用语言和字符集的表示方式。字符集是一个来自“字符集注册表” [<a href="#IANA-CHARSET">IANA-CHARSET</a>] 的标准值，并从 [<a href="#RFC5646">RFC5646</a>] [<a href="#RFC4647">RFC4647</a>] 的列表中选择语言。</p>
<h3 id="362-多链路-ppp">3.6.2 多链路 PPP</h3>
<p>PPP 的一个特殊版本称为<strong>多链路PPP （MP）</strong> [<a href="#RFC1990">RFC1990</a>]，可用于将多条点到点链路聚合为一条链路。这种想法与前面讨论过的链路聚合相似，并被用于多个电路交换信道（例如 ISDNB 信道）的聚合。 MP 包含一个特殊的 LCP 选项，表示支持多链路，以及一个用于多链路上 PPP 帧分片与重组的协商协议。一条聚合链路（称为一个<strong>捆绑</strong>）可作为一条完整的虚拟链路来操作，并包含自己的配置信息。链路捆绑由大量<strong>成员链路</strong>组成。每个成员链路可能有自己的选项集。</p>
<p>实现 MP 的典型方法是使分组轮流经过各个成员链路传输。这种方法称为<strong>银行柜员算法</strong>，它可能导致分组重新排序，可能为其他协议带来不良的性能影响。 （例如，虽然 TCP/IP 可以正确处理重新排序后的分组，但也可能不如没有重新排序处理得好。） MP 在每个分组中添加一个 2 ~ 4 字节的<strong>序列头部</strong>，而远程 MP 接收方的任务是重建正确的顺序。图 3-25 显示了这种数据帧。</p>
<figure data-type="image" tabindex="25"><img src="https://wenbozhangw.github.io//post-images/1652953897257.png" alt="图 3-25" loading="lazy"></figure>
<p>图 3-25   一个 MP 分片包含一个序列头部，允许在一个多链路捆绑的远端对分片重新排序。这个头部支持 2 种格式：短头部（2 字节）和长头部（4 字节）</p>
<p>在图 3-25 中，我们看到一个 MP 分片的开始分片（B）、结束分片（E）位字段和<strong>序列号</strong>字段。这里，需要注意的是长格式（4 字节用于分片信息）和短格式（2 字节用于分片信息）。在选项协商阶段，  LCP 的<strong>短序列号</strong>选项（类型 18）用于选择使用的格式。如果一个帧没有被分片，但使用这种格式传输，则 B 和 E 位都被置位，表明该分片是第一个和最后一个（即它是整个帧）。否则，第一个分片的 B、 E 位组合被设置为 <code>10</code>，最后一个分片的 B、 E位 组合被设置为 <code>01</code> ，它们之间的所有分片被设置为 <code>00</code>。序列号给出相对第一个分片的分组号偏移量。</p>
<p>MP 使用一个称为多链路<strong>最大接收重构单元</strong>（MRRU，类型 18）的 LCP 选项，它可将一系列更大的 MRU 应用于捆绑中。大于成员链路 MRU 的帧仍被允许通过这个 MP 链路，直到达到这个值的上限为止。</p>
<p>由于一个 MP 捆绑可能跨越多条成员链路，因此需要一种方法来确定成员链路属于同一捆绑。同一捆绑中的成员链路由 LCP <strong>端点鉴别</strong>（类型 19）选项识别。端点鉴别可使用电话号码、从 IP 或 MAC 地址中提取的数字，以及其他可管理的字符串。除了每个成员链路的常见内容，对这个选项的格式没有多少限制。</p>
<p>建立 MP 的基本方法定义在 [<a href="#RFC1990">RFC1990</a>] 中，希望各个成员链路可对称使用，相近数量的分片被分配到号码固定的每条链路上。为了实现更复杂的分配， [<a href="#RFC2125">RFC2125</a>] 中规定了<strong>带宽分配协议（BAP）<strong>和</strong>带宽分配控制协议（BACP）</strong>。 BAP 用于为一个捆绑动态添加或删除链路，而 BACP 用于交换如何使用 BAP 添加或删除链路的信息。这种功能有助于实现<strong>按需带宽（BOD）</strong>。在一些需要分配固定资源以满足应用（例如一定数量的电话连接）对带宽需求的网络中， BOD 通常需要监测流量，在应用需求高时创建新的连接，以及在应用需求低时删除连接。在某些开销和连接数量相关的情况下，这种功能是有用的。</p>
<p>BAP/BACP 使用一种新的<strong>链路鉴别</strong> LCP 选项（LCP 选项类型为 23）。这个选项包含一个 16 位的数字值，一个捆绑中的每条成员链路有不同的值。它被 BAP 用于确定需要添加或删除哪些链路。在一条 PPP 链路的网络阶段，每个捆绑都需要使用 BACP 协商。它的主要目的是找出<strong>首选对端</strong>。也就是说，如果在多个对端之间同时建立多个捆绑时，将会优先为首选对端分配成员链路。</p>
<p>BAP 包括 3 种分组类型：请求、响应和标识。请求用于向一个捆绑添加一条链路，或从一个捆绑中删除一条链路。标识用于为原始或被确认的请求返回结果。响应是对这些请求的 ACK 或 NACK。更多细节见 [<a href="#RFC2125">RFC2125</a>] 。</p>
<h3 id="363-压缩控制协议">3.6.3 压缩控制协议</h3>
<p>从历史上来看， PPP 是相对较慢的拨号调制解调器使用的协议。因此，针对 PPP 链路上压缩后发送数据已提出一些方法。压缩类型是不同的，无论是调制解调器硬件支持的压缩类型（例如 V.42bis、 V.44），还是我们以后讨论的协议头部压缩。目前，有几个压缩选项可选。可在一条 PPP 链路的两个方向做出选择， LCP 可协商一个使<strong>压缩控制协议（CCP）</strong> [<a href="#RFC1962">RFC1962</a>] 生效的选项。 CCP 的作用就像 NCP （见 3.6.5 节），只不过在 LCP 链路建立交换阶段指明压缩选项时才开始处理配置压缩细节。</p>
<p>CCP 在行为上很像 NCP，仅在链路进入网络状态时协商。它使用与 LCP 相同的分组交换过程和格式（除协议字段被设置为 <code>0x80FD</code> 之外），另外还有一些特殊选项，并对常见的<strong>代码</strong>字段值（1 ~ 7）定义了 2个 新的操作：复位请求（<code>0x0e</code>）和复位确认（<code>0x0f</code>）。如果在一个压缩帧中检测到一个错误，复位请求可用于要求对方复位压缩状态（例如字典、状态变量、状态机等）。在复位后，对方响应一个复位确认。</p>
<p>一个或多个压缩帧可作为一个 PPP 帧的一部分（即包括 LCP 数据和可能的填充部分）。压缩帧携带的<strong>协议</strong>字段值为 <code>0x00FD</code>，但是如何指明存在多个压缩帧，这依赖于使用的特定压缩算法（见 3.6.6 节）。当 CCP 与 MP 结合使用时，既可用于一个捆绑，也可用于多条成员链路的某些组合。如果只用于成员链路，<strong>协议</strong>字段设置为 <code>0x00FB</code> （单个的链路压缩数据报）。</p>
<p>CCP 可使用十几个压缩算法之一 [<a href="#PPPn">PPPn</a>] 。大多数算法是官方标准的 IETF 文档，虽然它们可能已在 RFC 中加以描述（例如， [<a href="#RFC1977">RFC1977</a>] 描述了 BSD 压缩方案， [<a href="#RFC2118">RFC2118</a>] 描述了 Microsoft <strong>点对点压缩协议</strong>（MPPC））。如果使用压缩， PPP 帧在进一步处理之前需要重构，因此高层的 PPP 操作通常不关心压缩帧的细节。</p>
<h3 id="364-ppp-认证">3.6.4 PPP 认证</h3>
<p>在一条 PPP 链路处于网络状态之前，通常有必要使用某种<strong>认证</strong>（身份验证）机制，以识别建立链路的对方身份。基本的 PPP 规范默认不提供认证，因此图 3-24 中的认证交换在这种情况下不会出现。但是，某种形式的认证在多数时候是需要的，一些经过多年演变的协议被用于应对这种情况。在本章中，我们仅从高层的角度展开讨论，并将细节留给关于安全的章节（第 18 章）。与不提供认证相比，最简单、安全性最低的认证方案是<strong>密码认证协议（PAP）</strong>。这种协议非常简单，一方请求另一方发送一个密码。由于该密码在 PPP 链路上未加密传输，窃听者在线路上可轻易捕获密码并使用它。由于这个重大的漏洞，不建议使用 PAP 进行认证。 PAP 分组像 LCP 分组那样编码，协议字段值设置为 <code>0xC0230</code>。</p>
<p><strong>查询——握手认证协议（CHAP）</strong> [<a href="#RFC1994">RFC1994</a>] 提供了一种更安全的认证方法。在使用 CHAP 时，一个随机值从一方（称为认证方）发送到另一方。响应通过一种特殊的<strong>单向</strong>（即不可逆）功能，将一个随机值和一个共享密钥（通常由密码生成）结合形成响应中的一个数字。在接收到这个响应之后，认证方能更可靠地验证对方密钥是否正确。这个协议在链路上不会以明文（未加密）形式发送密钥或密码，因此窃听者难以了解相关信息。由于每次使用不同的随机值，每个查询/响应的结果会改变，即使一个窃听者有可能捕捉到这个值，也无法通过重新使用（回放）来欺骗对方。</p>
<p>EAP [<a href="#RFC3748">RFC3748</a>] 是一个可用于各种网络的认证框架。它支持很多（约 40 个）不同的认<br>
证方法，从简单密码（例如 PAP 和 CHAP）到更可靠的认证类型（例如智能卡、生物识别）。EAP 定义了一种携带各种认证的消息格式，但需要额外的规范定义 EAP 消息如何在特定的链路上传输。</p>
<p>当 EAP 被用于 PPP 时，前面讨论过的基本认证方法不变。 EAP 不是在链路建立（LCP 建立）阶段协商一种认证方法，认证操作将被推迟到认证状态（网络状态的前一个状态）。这允许更多信息类型用于影响**远程访问服务器（RAS）**的访问控制决策。当某种标准的协议用于执行各种认证机制，网络访问服务器可能无须处理 EAP 消息内容，但可依靠其他基础设施的认证服务器（例如 RADIUS 服务器 [<a href="#RFC2865">RFC2865</a>] ）确定访问控制决策。这是当前的企业网和 ISP 设计中的首选方案。</p>
<h3 id="365-网络控制协议">3.6.5 网络控制协议</h3>
<p>虽然多种 NCP 可用于一条 PPP 链路（甚至同时），但我们将关注支持 IPv4 和 IPv6 的 NCP。 对于 IPv4， NCP 被称为<strong>IP控制协议（IPCP）</strong> [<a href="#RFC1332">RFC1332</a>] 。对于 IPv6， NCP 被称为 IPV6CP [<a href="#RFC5072">RFC5072</a>] 。在 LCP 完成链路建立和认证之后，该链路每端都进入网络状态，并使用一个或多个 NCP （例如典型的是一个 IPCP）进行网络层的相关协商。</p>
<p>IPCP （针对 IPv4 的标准 NCP）可用于在一条链路上建立 IPv4 连接，以及配置 <strong>Van Jacobson 头部压缩（VJ 压缩）</strong> [<a href="#RFC1144">RFC1144</a>] 。 IPCP 分组在 PPP 状态机进入网络状态之后交换。IPCP 分组使用与 LCP 相同的分组交换机制和分组格式，除非协议字段被设置为 <code>0x8021</code>，并且代码字段被限制在范围 0 ~ 7。代码字段的值对应于消息类型：特定供应商（见 [<a href="#RFC2153">RFC2153</a>] ）、配置请求、配置 ACK、配置 REJECT、终止请求、终止 ACK和代码 REJECT。 IPCP 可协商一系列选项，包括 IP 压缩协议（2）、 IPv4 地址（3）和移动 IPv4 （4） [<a href="#RFC2290">RFC2290</a>]。其他选项可用于获得主要和次要的域名服务器（见第 11 章）。</p>
<p>IPV6CP 使用与 LCP 相同的分组交换机制和分组格式，但它有两种不同的选择：接口标识符和 IPv6 压缩协议。接口标识符选项用于传输一个 64 位的 IID 值（见第 2 章），它作为形成一个链路本地 IPv6 地址的基础。由于它仅在本地链路上使用，因此不需要具有全球唯一性。这通过在 IPv6 地址的高位使用标准链路本地前缀，在低位设置某种功能的接口标识符来实现。这里模拟了 IPv6 自动配置过程（见第 6 章）。</p>
<h3 id="366-头部压缩">3.6.6 头部压缩</h3>
<p>PPP 拨号线路的速率一直较慢（54000b/s 或更少），很多小的分组通常使用 TCP/IP （例如 TCP 确认，见第 15 章）。这些分组大部分包含 TCP 和 IP 头部，同一 TCP 连接上的分组之间变化不大。其他高层协议的行为相似。因此，压缩（或消除）高层协议头部是一种有用的方法，这样以来就可在相对较慢的点到点链路上传输更少字节。现代的压缩或消除头部方法一直在随着时间演变。我们将从前面提到的 VJ 压缩开始，按时间顺序讨论它们。</p>
<p>在 VJ 压缩中，部分高层（TCP 和 IP）头部被 1 字节的连接标识符代替。 [<a href="#RFC1144">RFC1144</a>] 讨论了这种方法的起源，它最初来源于一种旧的、称为 CSLIP （压缩串行线路 IP）的点到点协议。一个典型 IPv4 头部的长度是 20 字节，一个没有选项的 TCP 头部的长度也是 20 字节。因此，一个常见的 TCP/IPv4 头部组合是 40 字节，并且很多字段在分组间没有变化。另外，很多字段在分组间只有很小或有限的变化。如果不变的值通过一条链路（或一段时间内）传输并被保存在一张表中，则在后续分组中可用一个小的索引代替该值。变化有限的值可以仅编码差异部分（即仅发送变化的部分）。因此，整个 40 字节头部通常可有效压缩到 3 或 4 字节。这样可显著提高在低速链路上的 TCP/IP 性能。</p>
<p>头部压缩的下一步演化简称为 IP 头部压缩 [<a href="#RFC2507">RFC2507</a>] [<a href="#RFC3544">RFC3544</a>] 。它提供了一种压缩多个分组头部的方式，使用 TCP 或 UDP 传输层协议，以及 IPv4 或 IPv6 网络层协议。这种技术是 VJ 压缩技术的一种逻辑上的扩展，可用于多种协议以及 PPP 链路之外的其他链路。 [<a href="#RFC2507">RFC2507</a>] 指出了底层链路层的一些强大的差错检测机制的必要性，因为，如果压缩头部在运输过程中损坏，出错的分组可在离开链路层时被构造。我们需要认识到，当头部压缩用于链路上时，可能不会像 PPP 的 FCS 计算那样强大。</p>
<p>头部压缩的最新改进方案称为<strong>鲁棒性头部压缩（ROHC）</strong> [<a href="#RFC5225">RFC5225</a>]。它进一步改进了 IP 头部压缩以涵盖更多的传输协议，并允许同时处理多种头部压缩方式。前面提到的 IP 头部压缩可适用于不同类型的链路，包括 PPP。</p>
<h3 id="367-例子">3.6.7 例子</h3>
<p>我们查看一台 PPP 服务器的调试输出，它通过拨号的调制解调器与客户机交互。客户机是一台有 IPv6 功能的运行 Microsoft Windows Vista 的计算机，服务器是一台运行 Linux 的计算机。客户机配置为可在单一链路上协商多链路功能（属性|选项IPPP 设置），出于演示目的，服务器配置为使用 CCP 协商加密协议（见以下代码清单中的 MPPE）：</p>
<p><img src="https://wenbozhangw.github.io//post-images/1652962371471.png" alt="" loading="lazy"><br>
<img src="https://wenbozhangw.github.io//post-images/1652962559431.png" alt="" loading="lazy"></p>
<p>这里，我们可看到一些涉及 PPP 的交换，它是从服务器的角度来看的。 PPP 服务器进程创建的（虚拟）网络接口为 ppp0，它在连接串行端口 ttyS0 的拨号调制解调器上等待连接请求（称为“输入连接”）。当有连接请求到达时，服务器依次发送 <code>0x0</code> 的异步控制字符映射（asyncmap）、 EAP 认证、 PFC 和ACFC 请求。客户拒绝 EAP 认证，并建议使用 MS-CHAP-v2 （ConENak） [<a href="#RFC2759">RFC2759</a>]。服务器再次尝试发送请求，并使用 MS-CHAP-v2，这请求被接受和确认（ConfAck）。接下来，“输入”请求包括 CBCP，一个与 MP 支持相关的 1614 字节的 MRRU，以及一个端点 ID。 服务器拒绝 CBCP 和多链路操作（ConfRej）请求。客户机发送不带 MRRU 的端点鉴别请求，并被接收和确认。下一步，服务器发送一个名为 dialer 的 CHAP 查询。在该查询的响应到达之前，两个标识消息到达，表明对方以字符串 MSRASV5.20 和 MSRAS-0-VISTA 来标识。最后， CHAP 响应到达并验证通过，表明许可访问。这时， PPP 转换为网络状态。</p>
<p>当进入网络状态时， CCP、 IPCP 和 IPV6CP NCP 被交换。 CCP 尝试协商<strong>微软点对点加密（MPPE）</strong> [<a href="#RFC3078">RFC3078</a>] 。MPPE 有些不同之处，因为它是一种加密协议，而不是一种压缩协议，它实际将分组扩大了 4 字节。但是，它提供了一个相对简单的方法，早在协商过程中就完成了加密。选项 <code>+H -M +S +L -D -C</code> 表明 MPPE 是否采用无状态操作（H）、使用哪种加密密钥强度（安全， S；中等， M；低， L）、是否存在过时的 D 位，以及是否需要单独、专用的 MPPC 的压缩协议（C） [<a href="#RFC2118">RFC2118</a>] 。最终，双方同意在有状态模式下使用强大的 128 位密钥（-H， +S）。注意，在这次协商过程中，客户机尝试发送一个 IPCP 请求，但服务器响应的是一个主动的 TermAck （一个 LCP 定义、 ICPC 采纳的消息）。它用于向对方指出服务器“需要重新谈判”         [<a href="#RFC1661">RFC1661</a>]。</p>
<p>在 MPPE 协商成功之后，服务器请求使用 VJ 头部压缩，并提供它的 IPv4 地址和 IPv6 地址，分别为 <code>192.168.0.1</code> 和 <code>fe80::0206:5bff:fedd:c5c3</code>。这个 IPv6 地址是从服务器的以太网 MAC 地址 <code>00:06:5B:DD:C5:C3</code> 而来。客户机最初使用 IPCP 建议的 IPv4 地址和域名服务器<code>0.0.0.0</code>，但被拒绝。客户机请求使用 <code>fe80::0000:0000:dead:beef</code> 作为 IPv6 地址，这个请求被接受和确认。最后，客户机确认服务器的 IPv4 和 IPv6 地址，并且表明自己已建立 IPv6 地址。接着，客户机再次请求 IPv4 和服务器地址 <code>0.0.0.0</code> ，再次被拒绝。 <code>192.168.0.1</code> 被接受和确认。</p>
<p>我们从这次交换中可看到， PPP 协商是既灵活又烦琐的。很多选项可以尝试、拒绝和重新协商。虽然在低延时链路上这可能不是一个大间题，但这种交换中的每个消息都需要花费几秒（或更长）到达目的地。如果在一条卫星链路上，则可能出现很大的超时。对用户来说，链路建立明显是一个太长的过程。</p>
<hr>
<h2 id="37-环回">3.7 环回</h2>
<p>尽管可能看起来很奇怪，但在很多情况下，客户机可能希望使用 Internet 协议（例如 TCP/IP）与同一计算机上的服务器通信。为了实现这个目标，大多数实现支持一种工作在网络层的<strong>环回</strong>（或称“回送”）能力——通常使用一个虚拟的环回网络接口来实现。它就像一个真正的网络接口，但实际上是一个由操作系统提供的专用软件，可通过 TCP/IP 与同一主机的其他部分通信。以 127 开始的 IPv4 地址就是为这个目的而保留， IPv6 地址 <code>::1</code> （见第 2 章的 IPv4 和 IPv6 寻址约定）用于同样目的。传统上，类 UNIX 系统（包括 Linux）为环回接口分配的 IPv4 地址为 <code>127.0.0.1</code> （IPv6 地址为 <code>::1</code>），为它分配的名称为 <code>localhost</code>。发送到环回接口的 IP 数据报不会出现在任何网络中。尽管我们可以想象传输层检测到另一端是一个环回地址，并跳过某些传输层逻辑和所有网络层逻辑，但大多数的实现在传输层和网络层对数据执行完整的处理流程，并仅在数据报离开网络层时将其回送给网络层协议栈。这种处理对于性能测试可能有用，例如在没有任何硬件开销的情况下，测量执行协议栈软件所需的时间。在 Linux 中，环回接口被称为 <code>Io</code>。</p>
<pre><code>lo Link encap:Local Loopback
        inet  addr:127.0.0.1  Mask:255.0.0.0
        inet6 addr:  ::1/128  Scope:Host
        UP LOOPBACK RUNNING MTU:16436 Metric:1
        RX packets:458511 errors:0 dropped:0 overruns:0 frame:0
        TX packets:458511 errors:0 dropped:0 overruns:0 carrier:0
        collisions:0  txqueuelen:0
        RX bytes:266049199 (253.7 MiB)
        TX bytes:266049199 (253.7 MiB)
</code></pre>
<p>这里，我们看到本地环回接口的 IPv4 地址为 <code>127.0.0.1</code>，子网掩码为 <code>255.0.0.0</code>（对应于分级寻址中的 A 类网络号 127）。 IPv6 地址1有一个128位的前缀，它表示只有一个地址。这个接口支持 16KB 的 MTU （可配置为更大尺寸，最大可达 2GB）。从主机在两个月前初始化开始，巨大的流量（接近 50 万个分组）无差错地通过该接口。我们不希望在本地环回设备上看到错误，假设它实际上没有在任何网络上发送分组。</p>
<p>在 Windows 中，默认情况下没安装 Microsoft 环回适配器，尽管这样仍支持 IP 环回功能。这个适配器可用于测试各种网络配置，甚至在一个物理网络接口不可用的情况下。在 Windows XP 下安装该适配器，可选择“开始 | 控制面板 | 添加硬件 | 从列表中选择网络适配器 | 选择 Microsoft 作为制造商 | 选择 Microsoft 环回适配器” 。对于 Windows Vista 或 Windows 7，在命令提示符下运行程序 hdwwiz，并手动添加 Microsoft 环回适配器。在执行上述操作后， ipconfig 命令显示如下（这个例子来自 Windows Vista 环境）：</p>
<pre><code>C:\&gt; ipconfig /all
...
Ethernet adapter Local Area Connection 2:
   Connection-specific DNS Suffix  . . . . . . . :
   Description . . . . . . . . . . . . . . . : Microsoft Loopback Adapter
   Physical Address. . . . . . . . . . . . . : 02-00-4C-4F-4F-50
   DHCP Enabled . . . . . . . . . . . : Yes
   Autoconfiguration Enabled. . . . . . . . . . : Yes
   Link-local IPv6 Address. . . . . . . . : fe80::9c0d:77a:52b8:39f0%18(Preferred)
   Autoconfiguration IPv4 Address . . . . . . . . . . . . : 169.254.57.240(Preferred)
   Subnet Mask  . . . . . . . . . . . . : 255.255.0.0
   Default Gateway. . . . . . . . . . . . . : 
   DHCPv6 IAID . . . . . . . . . . . : 302121036
   DNS Servers  . . . . . . . . . . . : fec0:0:0:ffff::1%1
                                       fec0:0:0:ffff::2%1
                                       fec0:0:0:ffff::3%1
    NetBIOS over Tcpip  . . . . . . . : Enabled
</code></pre>
<p>这里，我们可看到该接口已被创建，分配了 IPv4 和 IPv6 地址，并显示为一系列的虚拟以太网设备。现在，这台计算机具有以下环回地址：</p>
<pre><code>C:\&gt; ping 127.1.2.3
Pinging 127.1.2.3 with 32 bytes of data:
Reply from 127.1.2.3: bytes=32 time&lt;1ms TTL=128
Reply from 127.1.2.3: bytes=32 time&lt;1ms TTL=128
Reply from 127.1.2.3: bytes=32 time&lt;1ms TTL=128
Reply from 127.1.2.3: bytes=32 time&lt;1ms TTL=128

Ping statistics for 127.1.2.3:
    Packets: Sent = Received = Lost = 0 (0% loss)，
Approximate round trip times in milli-seconds:
    Mininum = 0ms，Maximum = 0ms，Average = 0ms

C:\&gt; ping ::1
Pinging ::1 with 32 bytes of data:
Reply from ::1: bytes=32 time&lt;1ms TTL=128
Reply from ::1: bytes=32 time&lt;1ms TTL=128
Reply from ::1: bytes=32 time&lt;1ms TTL=128
Reply from ::1: bytes=32 time&lt;1ms TTL=128

Ping statistics for ::1:
    Packets: Sent = Received = Lost = 0 (0% loss)，
Approximate round trip times in milli-seconds:
    Mininum = 0ms，Maximum = 0ms，Average = 0ms

C:\&gt; ping 169.254.57.240
Pinging 169.254.57.240 with 32 bytes of data:
Reply from 169.254.57.240: bytes=32 time&lt;1ms TTL=128
Reply from 169.254.57.240: bytes=32 time&lt;1ms TTL=128
Reply from 169.254.57.240: bytes=32 time&lt;1ms TTL=128
Reply from 169.254.57.240: bytes=32 time&lt;1ms TTL=128

Ping statistics for 169.254.57.240:
    Packets: Sent = Received = Lost = 0 (0% loss)，
Approximate round trip times in milli-seconds:
    Mininum = 0ms，Maximum = 0ms，Average = 0ms
</code></pre>
<p>我们可以看到， IPv4 中以 127 开始的目的地址被环回。但是，对于 IPv6，只有地址 <code>::1</code> 被定义用于环回操作。我们还可以看到，地址为 <code>169.254.57.240</code> 的环回适配器如何立即返回数据。我们将在第 9 章讨论组播或广播数据报是否被复制并返回给发送主机（通过环回接口）。每个应用程序都可做出这种选择。</p>
<hr>
<h2 id="38-mtu-和路径-mtu">3.8 MTU 和路径 MTU</h2>
<p>我们可以从图 3-3 中看到，在很多链路层网络（例如以太网）中，携带高层协议 PDU 的帧大小是有限制的。以太网有效载荷的字节数通常被限制为 1500， PPP 通常采用相同大小以保持与以太网兼容。链路层的这种特征被称为<strong>最大传输单元（MTU）</strong>。大多数的分组网络（例如以太网）都有固定的上限。大多数的流类型网络（串行链路）提供可设置的上限，它可被帧协议（例如 PPP）所使用。如果 IP 需要发送一个数据报，并且这个数据报比链路层 MTU大，则 IP 通过分片将数据报分解成较小的部分，使每个分片都小于 MTU。我们将在第 5 章和第 10 章讨论 IP 分片。</p>
<p>当同一网络中的两台主机之间通信时，本地链路的 MTU 在会话期间对数据报大小有直接影响。当两台主机之间跨越多个网络通信时，每条链路可能有不同大小的 MTU。在包含所有链路的整个网络路径上，最小的 MTU 称为<strong>路径 MTU</strong>。</p>
<p>任何两台主机之间的路径 MTU 不会永远不变，这取决于当时使用的路径。如果网络中的路由器或链路故障， MTU 可能改变。另外，路径通常不对称（主机 A 到 B 路径可能不是 B 到 A 的反向路径），路径 MTU 不需要在两个方向上相同。</p>
<p>[<a href="#RFC1191">RFC1191</a>] 规定了** IPv4 路径 MTU 发现（PMTUD）**机制， [<a href="#PMTUD">RFC1981</a>] 描述了用于 IPv6 的相应机制。 [<a href="#RFC4821">RFC4821</a>] 描述了一个补充方案，以解决这些机制中的一些问题。 PMTUD 用于确定某个时间的路径 MTU，它在 IPv6 实现中是需要的。在后面的章节中，针对前面描述的 ICMP 和 IP 分片，我们将观察这个机制如何运行。我们在讨论 TCP 和 UDP 时，也会讨论它对传输性能的影响。</p>
<hr>
<h2 id="39-隧道基础">3.9 隧道基础</h2>
<p>在某些情况下，两台计算机通过 Internet 或其他网络建立一条虚拟链路是有用的。虚拟专用网络（VpN）提供这种服务。实现这类服务的最常用方法称为<strong>隧道</strong>。一般来说，隧道是在高层（或同等层）分组中携带低层数据。例如，在一个 IPv4 或 IPv6 分组中携带 IPv4 数据，在一个 UDP、 IPv4 或 IPv6 分组中携带以太网数据。隧道转变了在头部中协议严格分层的思路，并允许形成<strong>覆盖网络</strong>（即这些“链路”实际是其他协议实现的虚拟链路，而不是物理连接的网络）。这是一个非常强大和有用的技术。这里，我们讨论了一些隧道方案的基础。</p>
<p>为某个协议层的分组或另一层的分组建立隧道有多种方法。用于建立隧道的 3 个常见协议包括：<strong>通用路由封装（GRE）</strong> [<a href="#RFC2784">RFC2784</a>] 、<strong>Microsoft 专用的点对点隧道协议（PPTP）</strong> [<a href="#RFC2637">RFC2637</a>] 和 <strong>第 2 层隧道协议（L2TP）</strong>  [<a href="#RFC3931">RFC3931</a>] 。其他协议包括早期非标准的 IP-in-IP 隧道协议 [<a href="#RFC1853">RFC1853</a>]。 GRE 和 IT2P 后来发展为标准，并分别代替了 IP-in-IP 和 PPTP （但这两种协议仍在使用）。我们将重点放在 GRE 和 PPTP，但更关注 PPTP，因为它是个人用户的常用协议，即使它并不是一个 IETF 标准。 L2TP 本身不提供安全保障，它常用于 IP 层安全（IPsec；见第 18 章）。由于 GRE 和 PPTP 有密切关系，我们现在看图 3-26 中的 GRE 头部，它们分别基于原来的标准和修订后的标准。</p>
<figure data-type="image" tabindex="26"><img src="https://wenbozhangw.github.io//post-images/1652968099400.png" alt="图 3-26" loading="lazy"></figure>
<p>图 3-26   基本的 GRE 头部只有 4 字节，包括一个 16 位的校验和选项（很多 Internet 协议中的典型选项）。后来，这个头部被扩展为包括一个标识符（密钥字段），该标识符是同一流中的多个分组共有的，还包括一个序列号（用于顺序混乱的分组重新排序）</p>
<p>从图 3-26 中的头部可以看出，基本 GRE 规范 [<a href="#RFC2784">RFC2784</a>] 是相当简单的，它只提供了对其他分组的最简化的封装。第一个位字段（C）指出是否存在<strong>校验和</strong>。如果是，<strong>校验和</strong>字段中包含相同类型的<strong>校验和</strong>，它在很多 Internet 相关协议中可看到（见 5.2.2 节）。如果<strong>校验和</strong>字段存在，<strong>保留 1 <strong>字段也存在，并被设置为 0。 [<a href="#RFC2890">RFC2890</a>] 扩展了基本格式，包括可选的</strong>密钥</strong>和<strong>序列号</strong>字段，如果有这两个字段的话，图 3-26 中的 K 和 S 位字段分别被设置为1。 密钥字段在多个分组中被分配了一个同样的值，表示它们是属于同一流中的分组。如果分组顺序被打乱（例如通过不同链路），可利用序列号字段对分组重新排序。</p>
<p>虽然 GRE 是 PPTP 的基础，并被 PPTP 使用，但这两个协议的目的不同。 GRE 隧道常用于网络基础设施内的流量传输，例如 ISP 之间或企业内部网与分支机构之间，虽然 GRE 隧道可与 IPsec 结合，但这个流量通常没必要加密。相反， PPTP 常用于用户和 ISP 或企业内部网之间，并需要加密（例如使用 MPPE）。 PPTP 本质上是 GRE 和 PPP 的结合，因此 GRE 可基于 PPP 提供虚拟的点到点链路。 GRE 使用 IPv4 或 IPv6 携带流量，因此它更像是一种第 3 层隧道技术。 PPTP 常用于携带第 2 层帧（例如以太网），因此需要模拟一条直接的局域网（链路层）连接。例如，它可用于对企业网络的远程访问。 PPTP 采用的是对标准 GRE 头部的改进方案（见图 3-27）。</p>
<figure data-type="image" tabindex="27"><img src="https://wenbozhangw.github.io//post-images/1652968427453.png" alt="图 3-27" loading="lazy"></figure>
<p>图 3-27   PPTP 头部基于一个旧的、非标准的 GRE 头部。它包括一个序列号、一个累积的分组确认号和一些标识信息。多数字段在第一次使用时设置为 0</p>
<p>我们可看到图 3-27 与标准 GRE 头部的一些差异，包括额外的 R、 S 和 A 位字段，以及<strong>标志</strong>字段和<strong>回溯（Recur）<strong>字段。它们中的多数设置为 0，并且没有使用（它们的分配是基于一个旧的、非标准的 GRE 版本）。 K、 S 和 A 位字段分别表示</strong>密钥</strong>、<strong>序列号</strong>和<strong>确认号</strong>字段是否存在。如果存在，<strong>序列号</strong>字段保存对方可看到的最大分组数。</p>
<p>我们现在建立一个 PPTP 会话，稍后对 PPTP 的其他功能进行简单讨论。下面的例子类似于前面给出的 PPP 链路建立的例子，区别在于现在不常使用拨号连接， PPTP 为 PPP 提供了一条“原始”链路。第二个客户端使用 Windows Vista 系统，服务器使用 Linux 系统。当调试选项启用时，这个输出保存在/ <code>var/log/messages</code> 文件中：</p>
<pre><code>pptpd: MGR: Manager process started
pptpd: MGR: Maximum of 100 connections available
pptpd: MGR: Launching /usr/sbin/pptpctrl to handle client
pptpd: CTRL: local address = 192.168.0.1
pptpd: CTRL: remote address = 192.168.1.1
pptpd: CTRL: pppd iptions file = /etc/ppp/options.pptpd
pptpd: CTRL: Client 71.141.227.30 control connection started
pptpd: CTRL: Received PPTP Control Message (type : 1)
pptpd: CTRL: Made a START CTRL CONN RPLY packet
pptpd: CTRL: I wrote 156 bytes to the client.
pptpd: CTRL: Sent packet to client
pptpd: CTRL: Received PPPTP Control Message (type : 7)

pptpd: CTRL: Set parameters to 100000000 maxbps， 64 window size
pptpd: CTRL: Made a OUT CALL RPLY packet
pptpd: CTRL: Starting call (launching ppd， opening GRE)
pptpd: CTRL: pty_fd = 6
pptpd: CTRL: tty_fd = 7
pptpd: CTRL (PPPD Launcher) : program binary = /usr/sbin/pppd 
pptpd: CTRL (PPPD Launcher) : local address = 192.168.0.1
pptpd: CTRL (PPPD Launcher) : remote address = 192.168.1.1
pppd: pppd 2.4.4 started by root， uid 0
pppd: using channel 60
pptpd: CTRL: I wrote 32 but4es to the client.
pptpd: CTRL: Sent packet to client
pppd: Using interface ppp0
pppd: Connect: ppp0 &lt;--&gt; /dev/pts/1
pppd:sent [LCP ConfReq id=0x1 &lt;asyncmap 0x0&gt; &lt;auth chap MS-v2&gt;
            &lt;magic 0x4e2ca200&gt; &lt;pcomp&gt; &lt;accomp&gt;]
pptpd: CTRL: Received PPTP Control Message (type : 15)
pptpd: CTRL: Got a SET LINK INFO packet with standard ACCMs
pptpd: GRE: accepting packet #0
pppd: rcvd [LCP ConfReq id=0x0 &lt;mru 1400&gt; &lt;magic 0x5e565505&gt;
            &lt;pcomp&gt; &lt;accomp&gt;]]
pppd: sent [LCP ConfAck id=0x0 &lt;mru 1400&gt; &lt;magic 0x5e565505&gt;
            &lt;pcomp&gt; &lt;accomp&gt;]]
pppd: sent [LCP ConfReq id=0x0 &lt;asyncmap 0x0&gt; &lt;auth chap MS-v2&gt; 
            &lt;magic 0x4e2ca200&gt; &lt;pcomp&gt; &lt;accomp&gt;]]
pptpd: GRE: accepting packet #1
pppd: rcvd [LCP ConfAck id=0x1 &lt;asyncmap 0x0&gt; &lt;auth chap MS-v2&gt;
            &lt;magic 0x4e2ca200&gt; &lt;pcomp&gt; &lt;accomp&gt;]
pppd: sent [CHAP Challenge id=0x3 
            &lt;eb88bfff67dlc239ef73e98ca32646a5&gt;， name = &quot;dialer&quot;]
pptpd: CTRL: Received PPTP Control Message (type = 15)
pptpd: CTRL: Ignored a SET LINK INFO packet with real ACCMs!
pptpd: GRE: accepting packet #2
pppd: rcvd [CHAP Response id=0x3 
            &lt;276f3678fofO3fa57f64b3c367529565000000
            00000000000fa2b2aeoad8db9d986f8e222a0217a620638a24
            3179160900&gt;， name = &quot;dialer&quot;]
pppd: sent [CHAP Success id=0x3
            &quot;S=C551119E0E1AAB68E86DED09A32D0346D7002E05
            M=Accessgranted&quot;]
pppd: sent [CCP ConfReq id=0x1 &lt;mppe +H -M +S +L -D -C&gt;]
pptpd: GRE: accepting packet #3
pppd: rcvd [ IPV6CP ConfReq id=0x1 &lt;addr fe80::1cfc:fddd:8e2c:e118&gt;]
pppd: sent [ IPV6CP TermAck id=0x1 ]
pptpd:GRE: accepting packet #4
pppd: rcvd [CCP confReq id=0x2 &lt;mppe +H -M -S -L -D -C&gt;]
pppd: sent [CCP confNak id=0x2&lt;mppe +H -M +S +L -D -C&gt;]
pptpd: GRE: accepting packet #5
pptpd: GRE: accepting packet #6
pppd: rcvd [ IPCP ConfReq id=0x3 &lt;addr 0.0.0.0&gt;&lt;ms-dns1 0.0.0.0&gt;
&lt;ms-wins 0.0.0.0&gt;&lt;ms-dns3 0.0.0.0&gt;&lt;ms-wins 0.0.0.0&gt;]
pptpd: GRE: accepting packet #7
pppd: sent [ IPCP TermAck id=0x3]
pppd: rcvd [CCP ConfNak id=0x1 &lt;mppe +H -M+S -L -D -C&gt;
pppd: sent [CCP ConfReq id=0x2 &lt;mppe +H -M +S -L -D -C&gt;
pppd: rcvd [CCP confReq id=0x4 &lt;mppe +H -M +S -L -D -C&gt;
pppd: sent [CCP ConfAck id=0x4 &lt;mppe +H -M +S -L -D -C&gt;
pptpd: GRE: accepting packet #8
pppd: rcvd [CCP ConfAck id=0x2 &lt;mppe +H -M +S -L -D -C&gt;
pppd: MPPE 128-bit stateless compression enabled
pppd: sent [ IPCP ConfReq id=0x1 &lt;addr 192.168.0.1&gt;]
pppd: sent [ IPV6CP ConfReq id=0x1 &lt;addr fe80::0206:5bff:fedd:c5c3&gt;]
pptpd: GRE: accepting packet #9
pppd: rcvd [ IPCP ConfAck id=0x1 &lt;addr 192.168.0.1&gt;]
pptpd: GRE: accepting packet #10
pppd: rcvd [ IPV6CP ConfAck id=0x1 &lt;addr fe80::0206:5bff:fedd:c5c3&gt;]
pptpd: GRE:accepting packet #11
pppd: rcvd [ IPCP ConfReq id=0x5 &lt;addr 0.0.0.0&gt;
            &lt;ms-dns1 0.0.0.0&gt;&lt;ms-wins 0.0.0.0&gt;
            &lt;ms-dns3 0.0.0.0&gt;&lt;ms-wins 0.0.0.0&gt;]
pppd: sent [ IPCP ConfRej id=0x5 &lt;ms-wins 0.0.0.0&gt;&lt;ms-wins 0.0.0.0&gt;]
pptpd: GRE: accepting packet #12
pppd: rcvd [ IPV6CP ConfReq id=0x6 &lt;addr fe80::1cfc:fddd:8e2c:e118&gt;]
pppd: sent [ IPV6CP ConfAck id=0x6 &lt;addr fe80::1cfc:fddd:8e2c:e118&gt;]
pppd: local LL address fe80::0206:5bff:fedd:c5c3
pppd: remote LL address fe80::1cfc:fddd:8e2c:e118
pptpd: GRE: accepting packet #13
pppd: rcvd [ IPCP ConfReq id=0x7 &lt;addr 0.0.0.0&gt;
            &lt;ms-dns1 0.0.0.0&gt;&lt;ms-dns3 0.0.0.0&gt;]
pppd: sent [ IPCP ConfNak id=0x7 &lt;addr 192.168.1.1&gt;
            &lt;ms-dns1 192.168.0.1&gt;&lt;ms-dns3 192.168.0.1&gt;]
pptpd: GRE: accepting packet #14
pppd: rcvd [ IPCP ConfReq id=0x8 &lt;addr 192.168.1.1&gt;
            &lt;ms-dns1 192.168.0.1&gt;&lt;ms-dns3 192.168.0.1&gt;]
pppd: sent [ IPCP confAck id=0x8 &lt;addr 192.168.1.1&gt;
            &lt;ms-dns1 192.168.0.1&gt;&lt;ms-dns3 192.168.0.1&gt;]
pppd: local IP address 192.168.0.1
pppd: remote IP address 192.168.1.1
pptpd: GRE:accepting packet #15
pptpd: CTRL: sending ECHO REQ id 1
pptpd: CTRL: Made a ECHO REQ packet
pptpd: CTRL: l wrote 16 bytes to the client.
pptpd: CTRL: sent packet to client
</code></pre>
<p>这个输出类似于前面看过的 PPP 的例子，区别在于一个 pppd 过程和一个 pptpd 过程。这些进程协同工作以建立到服务器的 PPTP 会话。整个建立过程开始于用 pptpd 接收 1 个类型为 1 的控制消息，表示客户机希望建立一个控制连接。 PPTP 使用分离的控制流和数据流，因此首先需要建立一个控制流。在响应这个请求之后，服务器接收到一个类型为 7 的控制消息（表示对方发送的呼叫请求）。最大速度（b/s）设置为一个很大的值 100000000，实际上意味着它是无限制的。<strong>窗口</strong>设置为 64，这是在传输协议例如 TCP （见第 15 章）中经常看到的一个概念。这里，窗口用于流量控制。也就是说， PPTP 使用自己的序列号和确认号来确定多少帧成功到达目的地。如果成功交付的帧太少，发送者需要减小发送速率。为了确定帧确认的等待时间， PPTP 使用一种自适应的超时机制，根据链路的往返时间进行估算。当我们学习 TCP 时将看到这种计算过程。</p>
<p>在设置窗口后不久， pppd 应用开始运行和处理 PPP 数据，就像我们之前在拨号例子中看到的那样。两者之间唯一的区别在于： pptpd 在分组到达和离开时转发给 pppd 过程，以及 pptpd 处理的少量特殊 PPTP 消息（例如 set link info 和 echo request）。这个例子说明了 PPTP 协议如何实际运行，就像一个针对 PPP 分组的 GRE 隧道。由于现有 PPP 实现（这里是 pppd）可处理封装的 PPP 分组，因此它是很方便的。注意，虽然 GRE 本身通常封装在 IPv4 分组中，但类似功能也可使用 IPv6 隧道分组 [<a href="#RFC2473">RFC2473</a>] 。</p>
<h3 id="391-单向链路">3.9.1 单向链路</h3>
<p>当链路仅在一个方向工作时出现一个有趣的问题。这种在一个方向工作的链路称为<strong>单向链路（UDL）</strong>，由于它们需要交换信息（例如 PPP 配置消息），因此前面介绍的很多协议在这种情况下不能正常运行。为了解决这种问题提出了一种标准，可在辅助 Internet 接口上创建隧道，它可与 UDL 操作相结合 [<a href="#RFC3077">RFC3077</a>] 。典型情况是由卫星提供下行流量（流向用户）而形成一条 Intenet 连接，或者是调制解调器提供上行流量而形成一条拨号链路。这在卫星连接的用户主要是下载而不是上传的情况下是有用的，并且通常用于早期的卫星 Internet 连接。它使用 GRE 将链路层的上行流量封装在 IP 分组中。</p>
<p>为了在接收方自动建立和维护隧道， [<a href="#RFC3077">RFC3077</a>] 规定了一种<strong>动态隧道配置协议（DTCP）</strong>。DTCP 涉及在下行链路中发送组播 <strong>Hello 消息</strong>，因此任何有兴趣的接收方都可知道已有 UDL 及其 MAC 和 IP 地址。另外， Hello 消息表示网络中一个隧道端点的接口，它可通过用户端的辅助接口到达。在用户选择隧道端点之后， DTCP 在 GRE 隧道中将同一 MAC 作为 UDL 封装返回流量。服务提供商接收由 GRE 封装的这些第 2 层帧（通常是以太网），将它们从隧道中提取并适当转发。因此，上游（提供商） UDL 需要手工配置隧道，下游（很多用户）自动配置隧道。注意，这种 UDL 处理方法实际上是为上层协议不对称地“隐藏”链路。因此，这条链路“两个”方向上的性能（延迟、带宽）可能非常不对称，并可能对高层协议产生不利影响 [<a href="#RFC3449">RFC3449</a>] 。</p>
<p>这个例子说明，隧道的一个重要问题是配置的工作量，这个工作从前一直由手工完成。在通常情况下，隧道配置涉及选择一个隧道端点，以及用对方的 IP 地址配置位于隧道端点的设备，也许还需要选择协议和提供认证信息。一些相关技术已经出现，以协助自动配置或使用隧道。一种从 IPv4 向 IPv6 的过渡方法称为6to4 [<a href="#RFC3056">RFC3056</a>] 。在 6to4 中， IPv6 分组在一个 IPv4 网络中通过隧道传输， [<a href="#RFC3056">RFC3056</a>] 中规定它采用的封装方式。当相应主机经过了网络地址转换（见第 7 章），采用这种方法就会出现一个问题。这在当前是常见的，特别是对于家庭用户。自动配置隧道的 IPv6 过渡处理方法规定在 Teredo 技术方案中 [<a href="#RFC4380">RFC4380</a>] 。 Teredo 在 UDP/IPv4 分组上形成 IPv6 分组的隧道。理解这种方法需要一些 IPv4、 IPv6 和 UDP 的背景知识，我们将在第 10 章详细讨论这种隧道自动配置选项。</p>
<hr>
<h2 id="310-与链路层相关的攻击">3.10 与链路层相关的攻击</h2>
<p>对 TCP/IP 以下的层进行攻击以影响 TCP/IP 网络运行一直是常见的做法，这是由于大部分链路层信息不被高层共享，因而难以检测。不过，现在大家已知道很多这种攻击，我们在这里提到其中一些，以更好地理解链路层问题如何影响高层运行。</p>
<p>在传统的有线以太网中，接口可被设置为<strong>混杂模式</strong>，这允许它接收目的地不是自己的流量。在早期的以太网中，当介质是名副其实的共享电缆时，该功能允许任何一台连接以太网电缆的计算机“嗅探”别人的帧并检查其内容。当时很多高层协议包含密码等敏感信息，仅通过查看一个分组并解码就能轻易获得密码。两个因素对这种方法的影响很大：交换机部署和高层协议加密部署。在使用交换机后，只有连接到交换机端口的站提供流量，流量的目的地也是其他站（或其他桥接的站），以及广播/组播流量。这种流量很少包含敏感信息（例如密码），可在很大程度上阻止攻击。但是，在更高层使用加密更有效，这在当前是常见的。在这种情况下，嗅探分组难以获得多少好处，因为基本无法直接获取内容。</p>
<p>另一种攻击的目标是交换机。交换机中有一个基于每个端口的站列表。如果这种表能被快速填充（例如被大量伪装的站快速填充），交换机可能被迫放弃合法条目，从而导致中断对合法站的服务。一个相关但可能更严重的攻击是使用 STP。在这种情况下，一个站可伪装成一个到根网桥拥有低成本路径的站，从而吸引流量直接导向它。</p>
<p>随着 Wi-Fi 网络的使用，有线以太网中存在的一些窃听和伪装问题变得更严重，这是由于任何站都可进入监控模式并嗅探分组（802.11 接口置于监控模式通常比以太网接口置于混杂模式更有挑战性，这样做依赖于一个适当的设备）。一些早期“攻击” （可能不是真的被攻击，依据相关的法律框架）涉及扫描中的简单漫游，寻找提供 Internet 连接的接入点（即<strong>驾驶攻击</strong>）。虽然很多接入点使用加密来限制授权用户的访问，但有些人却能打开或使用<strong>捕获门户</strong>技术访问注册网页，然后进行基于 MAC 地址的过滤访问。通过观察站注册以及冒充合法注册用户来“劫持”连接，捕获门户系统已被破坏。</p>
<p>一种更先进的 Wi-Fi 攻击涉及对加密保护的攻击，尤其是很多早期接入点使用的 WEP 加密。针对 WEP [<a href="#BHL06">BHL06</a>] 的攻击有显著的破坏性，它促使 IEEE 修订了自已的标准。新的WPA2 （和 WPA）加密体系明显更强，因此不再推荐使用 WEP。</p>
<p>如果攻击者可访问两个端点之间的信道，它可采用很多方式来攻击 PPP 链路。对于很简单的认证机制（例如 PAP），嗅探可用于捕获密码，以便后续的非法访问。通过 PPP 链路（例如路由流量）上的更高层流量，可导致系统的不可用。</p>
<p>从攻击的角度看，隧道经常是目标，有时也成为攻击工具。作为目标，隧道穿过一个网络（通常是 Internet），它是被截获和分析的目标。隧道端点配置也可被攻击，尝试由端点建立更多隧道（一个 DoS 攻击）或攻击配置自身。如果该配置被攻破，可能打开一个未授权的隧道端点。在这点上，隧道变成工具而不再是目标，有些协议（例如 L2TP）提供一种与协议无关的简便方法，以在链路层访问私有的内部网络。在一种 GRE 相关的攻击中，例如将流量简单地插入一个非加密隧道，它到达隧道端点并被注入“私有”网络，虽然它本来只应被送往端点本地。</p>
<hr>
<h2 id="311-总结">3.11 总结</h2>
<p>在本章中，我们探讨 Internet 协议族的低层，也就是我们关注的链路层。我们首先介绍以太网的演变，速度从 10Mb/s 增加到 10Gb/s 及以上，功能上的变化包括 VLAN、优先级、链路聚合和帧格式等方面。我们介绍了交换机如何通过网桥改善性能，这主要通过在多个独立站的集合之间提供直连电路来实现，以及由全双工操作取代早期半双工操作。我们还介绍了 IEEE 802.11 无线局域网 Wi-Fi 标准的一些细节，并说明它与以太网的相似点和区别。它已成为最流行的 IEEE 标准之一，并通过两个主要频段 2.4GHz 和 5GHz 提供无须许可的网络访问。我们还介绍了 Wi-Fi 安全方法的演变，从较弱的 WEP 到更强的 WPA 和 WPA2 框架。在 IEEE 标准的基础上，我们讨论了点到点链路和 PPP 协议。 PPP 实际上可封装任何类型的分组，可用于 TCP/IP 和非 TCP/IP 网络，采用一种类似 HDLC 的帧格式，并且可用于从低速拨号调制解调器到高速光纤线路。它本身是一整套协议，涉及压缩、加密、认证和链路聚合。它只支持两个参与者之间通信，无法处理对共享介质的访问控制，例如以太网或 Wi-Fi 的 MAC 协议。</p>
<p>大多数实现提供了环回接口。通过特殊的环回地址，通常为 <code>127.0.0.1</code> （IPv6 为 <code>::1</code>），或将 IP 数据报发送到主机自己的 IP 地址，都可访问该接口。环回数据可被传输层处理，并在网络层被 IP 处理。我们描述了链路层的一个重要特点，即 MTU 和路径 MTU 的相关概念。</p>
<p>我们也讨论了隧道的使用，涉及在更高层（或同等层）分组中携带低层协议。这种技术可形成覆盖网络，在 Internet 中将隧道作为网络基础设施的其他层中的链路。这项技术已变得非常流行，包括新功能的实验（例如在一个 IPv4 网络上运行的一个 IPv6 覆盖网络）和实际使用（例如 VPN）。</p>
<p>最后简要讨论了链路层涉及的各种攻击类型，它们既是目标又是工具。很多攻击涉及流量截取与分析（例如查找密码），但很多复杂攻击涉及伪造端点和修改传输中的流量。其他攻击涉及修改控制信息，例如隧道端点或 STP 信息，以将流量导向其他意想不到的位置。链路层访问也提供了一种执行 DoS 攻击的通用方式。这方面最著名的攻击是干扰通信信号，这种攻击几乎从无线电问世以来就有了。</p>
<p>本章仅涵盖了当前 TCP/IP 使用的一些常见链路技术。 TCP/IP 成功的原因之一在于它能工作在几乎任何一种链路技术之上。从本质上来说， IP 只要求发送方和接收方之间存在某条路径，它们可能经过一些级联的中间链路。这是一个相对适中的要求，很多研究的目标甚至延伸得更远，发送方和接收方之间可能永远没有一条端到端路径 [<a href="#RFC4838">RFC4838</a>]。</p>
<hr>
<h2 id="312-参考文献">3.12 参考文献</h2>
<p><span id="802.11-2007">[802.11-2007]</span></span> &quot;IEEE Standard for Local and Metropolitan Area Networks, Part 11: Wireless LAN Medium Access Control (MAC) and Physical Layer (PHY) Specifications,&quot; June 2007.</p>
<p><span id="802.11n-2009">[802.11n-2009]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks, Part 11: Wireless LAN Medium Access Control (MAC) and Physical Layer (PHY) Specifications Amendment 5: Enhancements for Higher Throughput,&quot; Oct. 2009.</p>
<p><span id="802.11y-2008">[802.11y-2008]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks, Part 11: Wireless LAN Medium Access Control (MAC) and Physical Layer (PHY) Specifications Amendment 3: 3650-3700 MHz Operation in USA,&quot; Nov. 2009.</p>
<p><span id="802.16-2009">[802.16-2009]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks, Part 16: Air Interface for Fixed Broadband Wireless Access Systems,&quot; May 2009.</p>
<p><span id="802.16h-2010">[802.16h-2010]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks, Part 16: Air Interface for Fixed Broadband Wireless Access Systems Amendment 2: Improved Coexistence Mechanisms for License-Exempt Operation,&quot; July 2010.</p>
<p><span id="802.16j-2009">[802.16j-2009]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks, Part 16: Air Interface for Fixed Broadband Wireless Access Systems Amendment 1: Multihop Relay Specification,&quot; June 2009.</p>
<p><span id="802.16k-2007">[802.16k-2007]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks, Part 16:Air Interface for Fixed Broadband Wireless Access Systems Amendment 5: Bridging of IEEE 802.16,&quot;Aug. 2010.</p>
<p><span id="802.1AK-2007">[802.1AK-2007]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks, Virtual Bridged Local Area Networks Amendment 7: Multiple RegistrationProtocol,&quot; June 2007.</p>
<p><span id="802.1AE-2006">[802.1AE-2006]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks Media Access Control (MAC) Security,&quot; Aug. 2006.</p>
<p><span id="802.1ak-2007">[802.1ak-2007]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks--—Virtual Bridged Local Area Networks--Amendment 7: Multiple Registration Protocol,&quot; June 2007.</p>
<p><span id="802.1AX-2008">[802.1AX-2008]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks—Link Aggregation,&quot; Nov. 2008.</p>
<p><span id="802.1D-2004">[802.1D-2004]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks Media Access Control (MAC) Bridges,&quot; June 2004.</p>
<p><span id="802.1Q-2005">[802.1Q-2005]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks Virtual Bridged Local Area Networks,&quot; May 2006.</p>
<p><span id="802.1X-2010">[802.1X-2010]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks Port-Based Network Access Control,&quot;Feb. 2010.</p>
<p><span id="802.2-1998">[802.2-1998]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks Logical Link Control&quot;(also ISO/IEC 8802-2:1998), May 1998.</p>
<p><span id="802.21-2008">[802.21-2008]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks, Part 21: Media Independent Handover Services&quot; Jan. 2009.</p>
<p><span id="802.3-2008">[802.3-2008]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks, Part 3:Carrier Sense Multiple Access with Collision Detection (CSMA/CD) Access Method and Physical Layer Specifications,&quot;Dec. 2008.</p>
<p><span id="802.3at-2009">[802.3at-2009]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks—Specific Requirements, Part 3: Carrier Sense Multiple Access with Collision Detection (CSMA/CD) Access Method and Physical Layer Specifications Amendment 3: Date Terminal Equipment (DTE) Power via the Media Dependent Interface (MDI) Enhancements,&quot; Oct. 2009.</p>
<p><span id="802.3ba-2010">[802.3ba-2010]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks, Part 3: Carrier Sense Multiple Access with Collision Detection (CSMA/CD) Access Method and Physical Layer Specifications, Amendment 4: Media Access Control Parameters, Physical Layers, and Management Parameters for 40Gb/s and 100Gb/s Operation,&quot; June 2010.</p>
<p><span id="802.11n-2009">[802.11n-2009]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks, Part 11: Wireless LAN Medium Access Control (MAC) and Physical Layer (PHY) Specifications,Amendment 5: Enhancements for Higher Throughput,&quot; Oct. 2009.</p>
<p><span id="AESO1">[AESO1]</span> U.S. National Institute of Standards and Technology, FIPS PUB 197, &quot;Advanced Encryption Standard,&quot; Nov.2001.</p>
<p><span id="BHLO6">[BHLO6]</span> A.Bittau, M.Handley, and J.Lackey, &quot;The Final Nail in WEP's Coffin, &quot; Proc. IEEE Symposium on Security and Privacy, May 2006.</p>
<p><span id="BOND">[BOND]</span> http://bonding.sourceforge.net</p>
<p><span id="ETHERTYPES">[ETHERTYPES]</span> http://www.iana.org/assignments/ethernet-numbers</p>
<p><span id="ETX">[ETX]</span> D. De Couto, D.Aguayo, J. Bicket, and R. Morris,&quot;A High-Throughput Path Metric for Multi-Hop Wireless Routing,&quot; Proc. Mobicom, Sep. 2003.</p>
<p><span id="G704">[G704]</span> ITU, &quot;General Aspects of Digital Transmission Systems: Synchronous Frame Structures Used at 1544, 6312, 2048k, 8488, and 44736 kbit/s Hierarchical Levels,&quot; ITU-T Recommendation G.704, July 1995.</p>
<p><span id="IANA-CHARSET">[IANA-CHARSET]</span> &quot;Character Sets,&quot; http://www.iana.org/assignments/character-sets</p>
<p><span id="ISO3309">[ISO3309]</span> International Organization for Standardization, &quot;Information Processing Systems--Data Communication High-Level Data Link Control Procedure--Frame Structure,&quot; IS 3309,1984.</p>
<p><span id="ISO4335">[ISO4335]</span> International Organization for Standardization, &quot;Information Processing Systems-Data Communication High-Level Data Link Control Procedure—Elements of Procedure,&quot; IS 4335,1987.</p>
<p><span id="JF">[JF]</span> M.Mathis,&quot;Raising the Internet MTU,&quot; http://www.psc.edu/~mathis/MTU</p>
<p><span id="MWLD">[MWLD]</span> &quot;Long Distance Links with MadWiFi,&quot; http://madwifi-project.org/wiki/UserDocs/LongDistance</p>
<p><span id="PPPn">[PPPn]</span> http://www.iana.org/assignments/ppp-numbers</p>
<p><span id="RFC0894">[RFC0894]</span> C.Hornig, &quot;A Standard for the Transmission of IP Datagrams over Ethernet Networks,&quot; Internet RFC 0894/STD 0041, Apr. 1984.</p>
<p><span id="RFC1042">[RFC1042]</span> J. Postel and J. Reynolds,&quot;Standard for the Transmission of IP Datagrams over IEEE 802 Networks,&quot; Internet RFC 1042/STD 0043, Feb. 1988.</p>
<p><span id="RFC1144">[RFC1144]</span> V.Jacobson, &quot;Compressing TCP/IP Headers for Low-Speed Serial Links&quot; Internet RFC 1144, Feb. 1990.</p>
<p><span id="RFC1191">[RFC1191]</span> J. Mogul and S. Deering,&quot;Path MTU Discovery,&quot; Internet RFC 1191, Nov. 1990.</p>
<p><span id="RFC1332">[RFC1332]</span> G. McGregor, &quot;The PPP Internet Protocol Control Protocol,&quot; Internet RFC 1332, May 1992.</p>
<p><span id="RFC1570">[RFC1570]</span> W.Simpson, ed., &quot;PPP LCP Extensions,&quot; Internet RFC 1570, Jan. 1994.</p>
<p><span id="RFC1661">[RFC1661]</span> W. Simpson, &quot;The Point-to-Point Protocol (PPP),&quot; Internet RFC 1661/STD 0051, July 1994.</p>
<p><span id="RFC1662">[RFC1662]</span> W. Simpson, ed.,&quot;PPP in HDLC-like Framing,&quot; Internet RFC 1662/STD 0051, July 1994.</p>
<p><span id="RFC1663">[RFC1663]</span> D. Rand,&quot;PPP Reliable Transmission,&quot; Internet RFC 1663, July 1994.</p>
<p><span id="RFC1853">[RFC1853]</span> W. Simpson, &quot;IP in IP Tunneling,&quot; Internet RFC 1853 (informational), Oct. 1995.</p>
<p><span id="RFC1962">[RFC1962]</span> D. Rand, &quot;The PPP Compression Protocol (CCP),&quot; Internet RFC 1962, June 1996.</p>
<p><span id="RFC1977">[RFC1977]</span> V.Schryver, &quot;PPP BSD Compression Protocol,&quot; Internet RFC 1977 (informational), Aug. 1996.</p>
<p><span id="RFC1981">[RFC1981]</span> J. McCann and S. Deering ,&quot;Path MTU Discovery for IP Version 6,&quot; Internet RFC 1981,Aug. 1996.</p>
<p><span id="RFC1989">[RFC1989]</span> w. Simpson, &quot;PPP Link Quality Monitoring,&quot; Internet RFC 1989, Aug.1996.</p>
<p><span id="RFC1990">[RFC1990]</span> K. Sklower, B. Lloyd, G. McGregor, D. Carr, and T. Coradetti, &quot;The PPP Multilink Protocol (MP)&quot; Internet RFC 1990, Aug. 1996.</p>
<p><span id="RFC1994">[RFC1994]</span> W. Simpson, &quot;PPP Challenge Handshake Authentication Protocol (CHAP),&quot; Internet RFC 1994, Aug. 1996.</p>
<p><span id="RFC2118">[RFC2118]</span> G.Pall, &quot;Microsoft Point-to-Point (MPPC) Protocol,&quot; Internet RFC 2118 (informational), Mar. 1997.</p>
<p><span id="RFC2125">[RFC2125]</span> C.Richards and K. Smith, &quot;The PPP Bandwidth Allocation Protocol (BAP)/The PPP Bandwidth Allocation Control Protocol (BACP),&quot; Internet RFC 2125, Mar. 1997.</p>
<p><span id="RFC2153">[RFC2153]</span> W. Simpson,&quot;PPP Vendor Extensions,&quot; Internet RFC 2153(informational), May 1997.</p>
<p><span id="RFC2290">[RFC2290]</span> J. Solomon and S.Glass,&quot;Mobile-IPv4 Configuration Option for PPP IPCP,&quot; Internet RFC 2290, Feb. 1998.</p>
<p><span id="RFC2464">[RFC2464]</span> M.Crawford, &quot;Transmission of IPv6 Packets over Ethernet Networks,&quot; Internet RFC 2464, Dec. 1988.</p>
<p><span id="RFC2473">[RFC2473]</span> A.Conta and S. Deering ,&quot;Generic Packet Tuneling in IPv6 Specification,&quot; Internet RFC 2473, Dec. 1998.</p>
<p><span id="RFC2484">[RFC2484]</span> G.Zorn, &quot;PPP LCP Internationalization Configuration Option,&quot; Internet RFC 2484, Jan. 1999.</p>
<p><span id="RFC2507">[RFC2507]</span> M. Degermark, B. Nordgren, and S. Pink, &quot;IP Header Compression,&quot; Internet RFC 2507, Feb. 1999.</p>
<p><span id="RFC2615">[RFC2615]</span> A. Malis and W. Simpson, &quot;PPP over SONET/SDH,&quot; Internet RFC 2615, June 1999.</p>
<p><span id="RFC2637">[RFC2637]</span> K.Hamzeh, G. Pall, W. Verthein, J. Taarud, W. Little, and G.Zorn, &quot;Point-to-Point Tunneling Protocol (PPTP),&quot; Internet RFC 2637 (informational), July 1999.</p>
<p><span id="RFC2759">[RFC2759]</span> G.Zorn, &quot;Microsoft PPP CHAP Extensions, Version 2,&quot; Internet RFC 2759 (informational), Jan. 2000.</p>
<p><span id="RFC2784">[RFC2784]</span> D. Farinacci, T. Li, S. Hanks, D. Meyer, and P. Traina, &quot;Generic Routing Encapsulation (GRE),&quot;Internet RFC 2784, Mar. 2000.</p>
<p><span id="RFC2865">[RFC2865]</span> C.Rigney, S. Willens, A. Rubens, and W. Simpson, &quot;Remote Authentication Dial In User Service (RADIUS),&quot; Internet RFC 2865, June 2000.</p>
<p><span id="RFC2890">[RFC2890]</span> G. Dommety,&quot;Key and Sequence Number Extensions to GRE,&quot; Internet RFC 2890, Sept. 2000.</p>
<p><span id="RFC3056">[RFC3056]</span> B.Carpenter and K. Moore,&quot;Connection of IPv6 Domains via IPv4 Clouds,&quot; Internet RFC 3056, Feb. 2001.</p>
<p><span id="RFC3077">[RFC3077]</span> E. Duros, W. Dabbous, H.Izumiyama, N. Fujii, and Y.Zhang,&quot;A Link-Layer Tunneling Mechanism for Unidirectional Links,&quot; Internet RFC 3077, Mar. 2001.</p>
<p><span id="RFC3078">[RFC3078]</span> G.Pall and G.Zorn, &quot;Microsoft Point-to-Point Encryption (MPPE) Protocol,&quot; Internet RFC 3078 (informational), Mar. 2001.</p>
<p><span id="RFC3153">[RFC3153]</span> R.Pazhyannur, I. Ali, and C. Fox, &quot;PPP Multiplexing,&quot; Internet RFC 3153, Aug. 2001.</p>
<p><span id="RFC3366">[RFC3366]</span> G.Fairhurst and L. Wood,&quot;Advice to Link Designers on Link Automatic Repeat reQuest (ARQ),&quot;Internet RFC 3366/BCP 0062,Aug.2002.</p>
<p><span id="RFC3449">[RFC3449]</span> H. Balakrishnan, V.Padmanabhan, G. Fairhurst, and M. Sooriyabandara, &quot;TCP Performance Implications of Network Path Asymmetry,&quot; Internet RFC 3449/BCP 0069, Dec. 2002.</p>
<p><span id="RFC3544">[RFC3544]</span> T.Koren, S.Casner, and C. Bormann, &quot;IP Header Compression over PPP&quot; Internet RFC 3544, July 2003.</p>
<p><span id="RFC3561">[RFC3561]</span> C.Perkins,E. Belding-Royer, and S. Das,&quot;Ad Hoc On-Demand Distance Vector (AODV) Routing,&quot; Internet RFC 3561 (experimental), July 2003.</p>
<p><span id="RFC3610">[RFC3610]</span> D. Whiting,R.Housley, and N.Ferguson, &quot;Counter with CBC-MAC (CCM),&quot; Internet RFC 3610(informational), Sept. 2003.</p>
<p><span id="RFC3626">[RFC3626]</span> T. Clausen and P. Jacquet, eds.,&quot;Optimized Link State Routing Protocol (OLSR),&quot; Internet RFC 3626 (experimental), Oct. 2003.</p>
<p><span id="RFC3748">[RFC3748]</span> B. Aboba et al., &quot;Extensible Authentication Protocol (EAP),&quot; Internet RFC 3748, June 2004.</p>
<p><span id="RFC3931">[RFC3931]</span> J. Lau, M. Townsley, and L. Goyret, eds,&quot;Layer Two Tunneling Protocol--Version 3 (L2TPv3),&quot; Internet RFC 3931, Mar. 2005.</p>
<p><span id="RFC4017">[RFC4017]</span> D.Stanley, J. Walker, and B. Aboba,&quot;Extensible Authentication Protocol (EAP) Method Requirements for Wireless LANs,&quot; Internet RFC 4017 (informational), Mar. 2005.</p>
<p><span id="RFC4380">[RFC4380]</span>C. Huitema,&quot;Teredo: Tunneling IPv6 over UDP through Network Address Translations (NATs),&quot; Internet RFC 4380,Feb. 2006.</p>
<p><span id="RFC4647">[RFC4647]</span> A. Phillips and M. Davis, &quot;Matching of Language Tags,&quot; Internet RFC 4647/BCP 0047, Sept. 2006.</p>
<p><span id="RFC4821">[RFC4821]</span> M.Mathis and J. Heffner, &quot;Packetization Layer Path MTU Discovery,&quot; Internet RFC 4821, Mar. 2007.</p>
<p><span id="RFC4838">[RFC4838]</span> V.Cerf et al.,&quot;Delay-Tolerant Networking Architecture,&quot; Internet RFC 4838 (informational), Apr. 2007.</p>
<p><span id="RFC4840">[RFC4840]</span> B.Aboba, ed., E. Davies, and D. Thaler, &quot;Multiple Encapsulation Methods Considered Harmful,&quot; Internet RFC 4840 (informational), Apr. 2007.</p>
<p><span id="RFC5072">[RFC5072]</span> S. Varada, ed., D. Haskins, and E.Allen, &quot;IP Version 6 over PPP,&quot; Internet RFC 5072,Sept. 2007.</p>
<p><span id="RFC5225">[RFC5225]</span> G. Pelletier and K.Sandlund, &quot;RObust Header Compression Version 2 (ROHCv2): Profiles for RTP, UDP,IP, ESP, and UDP-Lite,&quot; Internet RFC 5225, Apr. 2008.</p>
<p><span id="RFC5646">[RFC5646]</span> A. Phillips and M. Davis, eds., &quot;Tags for Identifying Languages,&quot; Internet RFC 5646/BCP 0047,Sept. 2009.</p>
<p><span id="S08">[S08]</span> D. Skordoulis et al., &quot;IEEE 802.11n MAC Frame Aggregation Mechanisms for Next-Generation High-Throughput WLANs,” IEEE Wireless Communications, Feb. 2008.</p>
<p><span id="S96">[S96]</span> B. Schneier,Applied Cryptography, Second Edition (John Wiley &amp; Sons, 1996).</p>
<p><span id="SAE">[SAE]</span> D. Harkins, &quot;Simultaneous Authentication of Equals: A Secure, Password-Based Key Exchange for Mesh Networks,&quot; Proc. SENSORCOMM,Aug.2008.</p>
<p><span id="SC05">[SC05]</span> S. Shalunov and R.Carlson, &quot;Detecting Duplex Mismatch on Ethernet,&quot; Proc. Passive and Active Measurement Workshop, Mar. 2005.</p>
<p><span id="SHKO7">[SHKO7]</span> C.Sengul, A.Harris, and R. Kravets,&quot;Reconsidering Power Management,&quot; Invited Paper, Proc. IEEE Broadnets, 2007.</p>
<p><span id="WOL">[WOL]</span> http://wake-on-lan.sourceforge.net</p>

            </div>
            <div class="post-footer">
  <ul class="post-copyright">
    <li class="post-copyright-author">
      <strong>本文作者：</strong>
      wenbo zhang
    </li>
    <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://wenbozhangw.github.io/post/lesslesstcpip-xiang-jie-juan-yi-xie-yi-greatergreater-di-san-zhang-lian-lu-ceng/" title="《TCP/IP 详解 卷一：协议》第三章：链路层">https://wenbozhangw.github.io/post/lesslesstcpip-xiang-jie-juan-yi-xie-yi-greatergreater-di-san-zhang-lian-lu-ceng/</a>
    </li>
    <li class="post-copyright-license">
      <strong>版权声明： </strong>
      本博客所有文章除特别声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i> BY-NC-SA</a> 许可协议。转载请注明出处！
    </li>
  </ul>
  <div class="tags">
    
      <a href="https://wenbozhangw.github.io/tag/NhO-Hr8Eu/"># TCP/IP</a>
    
  </div>
  <div class="nav">
    <div class="nav-prev">
      
        <i class="fa fa-chevron-left"></i>
        <a class="nav-pc-next" title="《TCP/IP 详解 卷一：协议》第四章：地址解析协议" href="https://wenbozhangw.github.io/post/lesslesstcpip-xiang-jie-juan-yi-xie-yi-greatergreater-di-si-zhang-di-zhi-jie-xi-xie-yi/">《TCP/IP 详解 卷一：协议》第四章：地址解析协议</a class="nav-pc-next">
        <a class="nav-mobile-prev" title="《TCP/IP 详解 卷一：协议》第四章：地址解析协议" href="https://wenbozhangw.github.io/post/lesslesstcpip-xiang-jie-juan-yi-xie-yi-greatergreater-di-si-zhang-di-zhi-jie-xi-xie-yi/">上一篇</a>
      
    </div>
    <div class="nav-next">
      
        <a class="nav-pc-next" title="RFC4291: IP Version 6 Addressing Architecture" href="https://wenbozhangw.github.io/post/rfc4291-ip-version-6-addressing-architecture/">RFC4291: IP Version 6 Addressing Architecture</a>
        <a class="nav-mobile-next" title="RFC4291: IP Version 6 Addressing Architecture" href="https://wenbozhangw.github.io/post/rfc4291-ip-version-6-addressing-architecture/">下一篇</a>
        <i class="fa fa-chevron-right"></i>
      
    </div>
  </div>
</div>
            
  
    
      <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>

<div id="gitalk-container"></div>

<script>
  var gitalk = new Gitalk({
    clientID: 'f23d403eec2df8966e70',
    clientSecret: '737d8cc3cc47392fad9a11fa6fe0a5917ac54baa',
    repo: 'wenbozhangw.github.io',
    owner: 'wenbozhangw',
    admin: ['wenbozhangw'],
    id: (location.pathname).substring(0, 49),      // Ensure uniqueness and length less than 50
    distractionFreeMode: false  // Facebook-like distraction free mode
  })
  gitalk.render('gitalk-container')
</script>
    
    
  

          </div>
        </div>
      </div>
    </div>
    <div class="footer-box">
  <footer class="footer">
    <div class="copyright">
      Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a> | © 2019-2020 Theme By <a href="https://github.com/hsxyhao/gridea-theme-next" target="_blank">HsxyHao</a>
    </div>
    <div class="poweredby">
      
    </div>
  </footer>
  
  
  <div class="pisces back-to-top" id="back_to_top">
    <i class="fa fa-arrow-up"></i>
    
    <span class="scrollpercent">
      <span id="back_to_top_text">0</span>%
    </span>
    
  </div>
  
  
    
<link rel="stylesheet" href="/media/live2d/css/live2d.css" />
<div class="box-scale">
  <div id="landlord" style="left: 5px;bottom: px;"
    data-key="">
    <canvas id="live2d" width="500" height="560" class="live2d"></canvas>
    

      <div class="message" style="opacity:0"></div>
      <div class="live_talk_input_body">
        <div class="live_talk_input_name_body">
          <input name="name" type="text" class="live_talk_name white_input" id="AIuserName" autocomplete="off"
            placeholder="你的名字" />
        </div>
        <div class="live_talk_input_text_body">
          <input name="talk" type="text" class="live_talk_talk white_input" id="AIuserText" autocomplete="off"
            placeholder="要和我聊什么呀？" />
          <button type="button" class="live_talk_send_btn" id="talk_send">发送</button>
        </div>
      </div>
      <input name="live_talk" id="live_talk" value="1" type="hidden" />
      <div class="live_ico_box">
        <div class="live_ico_item type_info" id="showInfoBtn"></div>
        <div class="live_ico_item type_talk" id="showTalkBtn"></div>
        
        <div class="live_ico_item type_youdu" id="youduButton"></div>
        <div class="live_ico_item type_quit" id="hideButton"></div>
        <input name="live_statu_val" id="live_statu_val" value="0" type="hidden" />
        <audio src="" style="display:none;" id="live2d_bgm" data-bgm="0" preload="none"></audio>
        <input id="duType" value="douqilai" type="hidden">
        
      </div>
    
  </div>
</div>
<div id="open_live2d">召唤看板娘</div>
<script src="https://libs.baidu.com/jquery/2.0.0/jquery.min.js"></script>
<script>
  var message_Path = 'https://cdn.jsdelivr.net/gh/hsxyhao/live2d.github.io@master/';
  let landlord = document.querySelector('#landlord');
  var apiKey = landlord.dataset.key;
</script>
<script type="text/javascript" src="/media/live2d/js/live2d.js"></script>
<script>
	var home_Path = document.location.protocol + '//' + window.document.location.hostname + ":" + window.document.location.port + '/';
	var userAgent = window.navigator.userAgent.toLowerCase();
	var norunAI = ["android", "iphone", "ipod", "ipad", "windows phone", "mqqbrowser", "msie", "trident/7.0"];
	var norunFlag = false;

	for (var i = 0; i < norunAI.length; i++) {
		if (userAgent.indexOf(norunAI[i]) > -1) {
			norunFlag = true;
			break;
		}
	}

	if (!window.WebGLRenderingContext) {
		norunFlag = true;
	}

	if (!norunFlag) {
		var hitFlag = false;
		var AIFadeFlag = false;
		var liveTlakTimer = null;
		var sleepTimer_ = null;
		var AITalkFlag = false;
		var talkNum = 0;
		(function () {
			function renderTip(template, context) {
				var tokenReg = /(\\)?\{([^\{\}\\]+)(\\)?\}/g;
				return template.replace(tokenReg, function (word, slash1, token, slash2) {
					if (slash1 || slash2) {
						return word.replace('\\', '');
					}
					var variables = token.replace(/\s/g, '').split('.');
					var currentObject = context;
					var i, length, variable;
					for (i = 0, length = variables.length; i < length; ++i) {
						variable = variables[i];
						currentObject = currentObject[variable];
						if (currentObject === undefined || currentObject === null) return '';
					}
					return currentObject;
				});
			}

			String.prototype.renderTip = function (context) {
				return renderTip(this, context);
			};

			var re = /x/;
			re.toString = function () {
				showMessage('哈哈，你打开了控制台，是想要看看我的秘密吗？', 5000);
				return '';
			};

			$(document).on('copy', function () {
				showMessage('你都复制了些什么呀，转载要记得加上出处哦~~', 5000);
			});

			function initTips() {
				$.ajax({
					cache: true,
					url: message_Path + 'message.json',
					dataType: "json",
					success: function (result) {
						$.each(result.mouseover, function (index, tips) {
							$(tips.selector).mouseover(function () {
								var text = tips.text;
								if (Array.isArray(tips.text)) text = tips.text[Math.floor(Math.random() * tips.text.length + 1) - 1];
								text = text.renderTip({ text: $(this).text() });
								showMessage(text, 3000);
								talkValTimer();
								clearInterval(liveTlakTimer);
								liveTlakTimer = null;
							});
							$(tips.selector).mouseout(function () {
								showHitokoto();
								if (liveTlakTimer == null) {
									liveTlakTimer = window.setInterval(function () {
										showHitokoto();
									}, 15000);
								};
							});
						});
						$.each(result.click, function (index, tips) {
							$(tips.selector).click(function () {
								if (hitFlag) {
									return false
								}
								hitFlag = true;
								setTimeout(function () {
									hitFlag = false;
								}, 8000);
								var text = tips.text;
								if (Array.isArray(tips.text)) text = tips.text[Math.floor(Math.random() * tips.text.length + 1) - 1];
								text = text.renderTip({ text: $(this).text() });
								showMessage(text, 3000);
							});
							clearInterval(liveTlakTimer);
							liveTlakTimer = null;
							if (liveTlakTimer == null) {
								liveTlakTimer = window.setInterval(function () {
									showHitokoto();
								}, 15000);
							};
						});
					}
				});
			}
			initTips();

			var text;
			if (document.referrer !== '') {
				var referrer = document.createElement('a');
				referrer.href = document.referrer;
				text = '嗨！来自 <span style="color:#0099cc;">' + referrer.hostname + '</span> 的朋友！';
				var domain = referrer.hostname.split('.')[1];
				if (domain == 'baidu') {
					text = '嗨！ 来自 百度搜索 的朋友！<br>欢迎访问<span style="color:#0099cc;">「 ' + document.title.split(' - ')[0] + ' 」</span>';
				} else if (domain == 'so') {
					text = '嗨！ 来自 360搜索 的朋友！<br>欢迎访问<span style="color:#0099cc;">「 ' + document.title.split(' - ')[0] + ' 」</span>';
				} else if (domain == 'google') {
					text = '嗨！ 来自 谷歌搜索 的朋友！<br>欢迎访问<span style="color:#0099cc;">「 ' + document.title.split(' - ')[0] + ' 」</span>';
				}
			} else {
				if (window.location.href == home_Path) { //主页URL判断，需要斜杠结尾
					var now = (new Date()).getHours();
					if (now > 23 || now <= 5) {
						text = '你是夜猫子呀？这么晚还不睡觉，明天起的来嘛？';
					} else if (now > 5 && now <= 7) {
						text = '早上好！一日之计在于晨，美好的一天就要开始了！';
					} else if (now > 7 && now <= 11) {
						text = '上午好！工作顺利嘛，不要久坐，多起来走动走动哦！';
					} else if (now > 11 && now <= 14) {
						text = '中午了，工作了一个上午，现在是午餐时间！';
					} else if (now > 14 && now <= 17) {
						text = '午后很容易犯困呢，今天的运动目标完成了吗？';
					} else if (now > 17 && now <= 19) {
						text = '傍晚了！窗外夕阳的景色很美丽呢，最美不过夕阳红~~';
					} else if (now > 19 && now <= 21) {
						text = '晚上好，今天过得怎么样？';
					} else if (now > 21 && now <= 23) {
						text = '已经这么晚了呀，早点休息吧，晚安~~';
					} else {
						text = '嗨~ 快来逗我玩吧！';
					}
				} else {
					text = '欢迎阅读<span style="color:#0099cc;">「 ' + document.title.split(' - ')[0] + ' 」</span>';
				}
			}
			showMessage(text, 12000);
		})();

		liveTlakTimer = setInterval(function () {
			showHitokoto();
		}, 15000);

		function showHitokoto() {
			if (sessionStorage.getItem("Sleepy") !== "1") {
				if (!AITalkFlag) {
					$.getJSON('https://v1.hitokoto.cn/', function (result) {
						talkValTimer();
						showMessage(result.hitokoto, 0);
					});
				}
			} else {
				hideMessage(0);
				if (sleepTimer_ == null) {
					sleepTimer_ = setInterval(function () {
						checkSleep();
					}, 200);
				}
			}
		}

		function checkSleep() {
			var sleepStatu = sessionStorage.getItem("Sleepy");
			if (sleepStatu !== '1') {
				talkValTimer();
				showMessage('你回来啦~', 0);
				clearInterval(sleepTimer_);
				sleepTimer_ = null;
			}
		}

		function showMessage(text, timeout) {
			if (Array.isArray(text)) text = text[Math.floor(Math.random() * text.length + 1) - 1];
			$('.message').stop();
			$('.message').html(text);
			$('.message').fadeTo(200, 1);
			//if (timeout === null) timeout = 5000;
			//hideMessage(timeout);
		}
		function talkValTimer() {
			$('#live_talk').val('1');
		}

		function hideMessage(timeout) {
			//$('.message').stop().css('opacity',1);
			if (timeout === null) timeout = 5000;
			$('.message').delay(timeout).fadeTo(200, 0);
		}

		function initLive2d() {
			$('#hideButton').on('click', function () {
				if (AIFadeFlag) {
					return false;
				} else {
					AIFadeFlag = true;
					localStorage.setItem("live2dhidden", "0");
					$('#landlord').fadeOut(200);
					$('#open_live2d').delay(200).fadeIn(200);
					setTimeout(function () {
						AIFadeFlag = false;
					}, 300);
				}
			});
			$('#open_live2d').on('click', function () {
				if (AIFadeFlag) {
					return false;
				} else {
					AIFadeFlag = true;
					localStorage.setItem("live2dhidden", "1");
					$('#open_live2d').fadeOut(200);
					$('#landlord').delay(200).fadeIn(200);
					setTimeout(function () {
						AIFadeFlag = false;
					}, 300);
				}
			});
			$('#youduButton').on('click', function () {
				if ($('#youduButton').hasClass('doudong')) {
					var typeIs = $('#youduButton').attr('data-type');
					$('#youduButton').removeClass('doudong');
					$('body').removeClass(typeIs);
					$('#youduButton').attr('data-type', '');
				} else {
					var duType = $('#duType').val();
					var duArr = duType.split(",");
					var dataType = duArr[Math.floor(Math.random() * duArr.length)];

					$('#youduButton').addClass('doudong');
					$('#youduButton').attr('data-type', dataType);
					$('body').addClass(dataType);
				}
			});
			if (apiKey) {
				$('#showInfoBtn').on('click', function () {
					var live_statu = $('#live_statu_val').val();
					if (live_statu == "0") {
						return
					} else {
						$('#live_statu_val').val("0");
						$('.live_talk_input_body').fadeOut(500);
						AITalkFlag = false;
						showHitokoto();
						$('#showTalkBtn').show();
						$('#showInfoBtn').hide();
					}
				});
				$('#showTalkBtn').on('click', function () {
					var live_statu = $('#live_statu_val').val();
					if (live_statu == "1") {
						return
					} else {
						$('#live_statu_val').val("1");
						$('.live_talk_input_body').fadeIn(500);
						AITalkFlag = true;
						$('#showTalkBtn').hide();
						$('#showInfoBtn').show();

					}
				});
				$('#talk_send').on('click', function () {
					var info_ = $('#AIuserText').val();
					var userid_ = $('#AIuserName').val();
					if (info_ == "") {
						showMessage('写点什么吧！', 0);
						return;
					}
					if (userid_ == "") {
						showMessage('聊之前请告诉我你的名字吧！', 0);
						return;
					}
					showMessage('思考中~', 0);
					let protocol = window.location.protocol.indexOf("s") > 0 ? "https" : "http";
					$.ajax({
						type: "get",
						url: `${protocol}://www.tuling123.com/openapi/api?key=${apiKey}&info=${info_}`,
						dataType: "json",
						success: function (res) {
							talkValTimer();
							showMessage(res.text, 0);
							$('#AIuserText').val("");
							sessionStorage.setItem("live2duser", userid_);
						},
						error: function (e) {
							talkValTimer();
							showMessage('似乎有什么错误，请和站长联系！', 0);
						}
					});
				});
			} else {
				$('#showInfoBtn').hide();
				$('#showTalkBtn').hide();
			}
			//获取音乐信息初始化
			var bgmListInfo = $('input[name=live2dBGM]');
			if (bgmListInfo.length == 0) {
				$('#musicButton').hide();
			} else {
				var bgmPlayNow = parseInt($('#live2d_bgm').attr('data-bgm'));
				var bgmPlayTime = 0;
				var live2dBGM_Num = sessionStorage.getItem("live2dBGM_Num");
				var live2dBGM_PlayTime = sessionStorage.getItem("live2dBGM_PlayTime");
				if (live2dBGM_Num) {
					if (live2dBGM_Num <= $('input[name=live2dBGM]').length - 1) {
						bgmPlayNow = parseInt(live2dBGM_Num);
					}
				}
				if (live2dBGM_PlayTime) {
					bgmPlayTime = parseInt(live2dBGM_PlayTime);
				}
				var live2dBGMSrc = bgmListInfo.eq(bgmPlayNow).val();
				$('#live2d_bgm').attr('data-bgm', bgmPlayNow);
				$('#live2d_bgm').attr('src', live2dBGMSrc);
				$('#live2d_bgm')[0].currentTime = bgmPlayTime;
				$('#live2d_bgm')[0].volume = 0.5;
				var live2dBGM_IsPlay = sessionStorage.getItem("live2dBGM_IsPlay");
				var live2dBGM_WindowClose = sessionStorage.getItem("live2dBGM_WindowClose");
				if (live2dBGM_IsPlay == '0' && live2dBGM_WindowClose == '0') {
					$('#live2d_bgm')[0].play();
					$('#musicButton').addClass('play');
				}
				sessionStorage.setItem("live2dBGM_WindowClose", '1');
				$('#musicButton').on('click', function () {
					if ($('#musicButton').hasClass('play')) {
						$('#live2d_bgm')[0].pause();
						$('#musicButton').removeClass('play');
						sessionStorage.setItem("live2dBGM_IsPlay", '1');
					} else {
						$('#live2d_bgm')[0].play();
						$('#musicButton').addClass('play');
						sessionStorage.setItem("live2dBGM_IsPlay", '0');
					}
				});
				window.onbeforeunload = function () {
					sessionStorage.setItem("live2dBGM_WindowClose", '0');
					if ($('#musicButton').hasClass('play')) {
						sessionStorage.setItem("live2dBGM_IsPlay", '0');
					}
				}
				document.getElementById('live2d_bgm').addEventListener("timeupdate", function () {
					var live2dBgmPlayTimeNow = document.getElementById('live2d_bgm').currentTime;
					sessionStorage.setItem("live2dBGM_PlayTime", live2dBgmPlayTimeNow);
				});
				document.getElementById('live2d_bgm').addEventListener("ended", function () {
					var listNow = parseInt($('#live2d_bgm').attr('data-bgm'));
					listNow++;
					if (listNow > $('input[name=live2dBGM]').length - 1) {
						listNow = 0;
					}
					var listNewSrc = $('input[name=live2dBGM]').eq(listNow).val();
					sessionStorage.setItem("live2dBGM_Num", listNow);
					$('#live2d_bgm').attr('src', listNewSrc);
					$('#live2d_bgm')[0].play();
					$('#live2d_bgm').attr('data-bgm', listNow);
				});
				document.getElementById('live2d_bgm').addEventListener("error", function () {
					$('#live2d_bgm')[0].pause();
					$('#musicButton').removeClass('play');
					showMessage('音乐似乎加载不出来了呢！', 0);
				});
			}
			//获取用户名
			var live2dUser = sessionStorage.getItem("live2duser");
			if (live2dUser !== null) {
				$('#AIuserName').val(live2dUser);
			}
			//获取位置
			var landL = sessionStorage.getItem("historywidth");
			var landB = sessionStorage.getItem("historyheight");
			if (landL == null || landB == null) {
				landL = '5px'
				landB = '0px'
			}
			$('#landlord').css('left', landL + 'px');
			$('#landlord').css('bottom', landB + 'px');
			//移动
			function getEvent() {
				return window.event || arguments.callee.caller.arguments[0];
			}
			var smcc = document.getElementById("landlord");
			var moveX = 0;
			var moveY = 0;
			var moveBottom = 0;
			var moveLeft = 0;
			var moveable = false;
			var docMouseMoveEvent = document.onmousemove;
			var docMouseUpEvent = document.onmouseup;
			smcc.onmousedown = function () {
				var ent = getEvent();
				moveable = true;
				moveX = ent.clientX;
				moveY = ent.clientY;
				var obj = smcc;
				moveBottom = parseInt(obj.style.bottom);
				moveLeft = parseInt(obj.style.left);
				if (isFirefox = navigator.userAgent.indexOf("Firefox") > 0) {
					window.getSelection().removeAllRanges();
				}
				document.onmousemove = function () {
					if (moveable) {
						var ent = getEvent();
						var x = moveLeft + ent.clientX - moveX;
						var y = moveBottom + (moveY - ent.clientY);
						obj.style.left = x + "px";
						obj.style.bottom = y + "px";
					}
				};
				document.onmouseup = function () {
					if (moveable) {
						var historywidth = obj.style.left;
						var historyheight = obj.style.bottom;
						historywidth = historywidth.replace('px', '');
						historyheight = historyheight.replace('px', '');
						sessionStorage.setItem("historywidth", historywidth);
						sessionStorage.setItem("historyheight", historyheight);
						document.onmousemove = docMouseMoveEvent;
						document.onmouseup = docMouseUpEvent;
						moveable = false;
						moveX = 0;
						moveY = 0;
						moveBottom = 0;
						moveLeft = 0;
					}
				};
			};
		}
		$(document).ready(function () {
			var AIimgSrc = [];
			let chooseLive2d = 'histoire'
			if (chooseLive2d === 'histoire') {
				AIimgSrc.push(message_Path + "model/histoire/histoire.1024/texture_00.png");
				AIimgSrc.push(message_Path + "model/histoire/histoire.1024/texture_01.png");
				AIimgSrc.push(message_Path + "model/histoire/histoire.1024/texture_02.png");
				AIimgSrc.push(message_Path + "model/histoire/histoire.1024/texture_03.png");
			} else if (chooseLive2d === 'rem') {
				AIimgSrc.push(message_Path + "model/rem/remu2048/texture_00.png");
			} else if (chooseLive2d === 'Aoba') {
				AIimgSrc.push(message_Path + "model/Aoba/textures/texture_00.png");
			} else if (chooseLive2d === 'hijiki') {
				AIimgSrc.push(message_Path + "model/hijiki/moc/hijiki.2048/texture_00.png");
			} else if (chooseLive2d === 'tororo') {
				AIimgSrc.push(message_Path + "model/tororo/moc/tororo.2048/texture_00.png");
			}
			var images = [];
			var imgLength = AIimgSrc.length;
			var loadingNum = 0;
			for (var i = 0; i < imgLength; i++) {
				images[i] = new Image();
				images[i].src = AIimgSrc[i];
				images[i].onload = function () {
					loadingNum++;
					if (loadingNum === imgLength) {
						var live2dhidden = localStorage.getItem("live2dhidden");
						if (live2dhidden === "0") {
							setTimeout(function () {
								$('#open_live2d').fadeIn(200);
							}, 1300);
						} else {
							setTimeout(function () {
								$('#landlord').fadeIn(200);
							}, 1300);
						}
						let model = '';
						if (chooseLive2d === 'histoire') {
							model = message_Path + "model/histoire/model.json";
						} else if (chooseLive2d === 'rem') {
							model = message_Path + "model/rem/model.json";
						} else if (chooseLive2d === 'Aoba') {
							model = message_Path + "model/Aoba/model.json";
						} else if (chooseLive2d === 'hijiki') {
							model = message_Path + "model/hijiki/hijiki.model.json";
						} else if (chooseLive2d === 'tororo') {
							model = message_Path + "model/tororo/tororo.model.json";
						}
						setTimeout(function () {
							loadlive2d("live2d", model);
						}, 1000);
						initLive2d();
						images = null;
					}
				}
			}
		});
	}
</script>
  
  
</div>
<script>

  let sideBarOpen = 'sidebar-open';
  let body = document.body;
  let back2Top = document.querySelector('#back_to_top'),
  back2TopText = document.querySelector('#back_to_top_text'),
  drawerBox = document.querySelector('#drawer_box'),
  rightSideBar = document.querySelector('.sidebar'),
  viewport = document.querySelector('body');

  function scrollAnimation(currentY, targetY) {
   
    let needScrollTop = targetY - currentY
    let _currentY = currentY
    setTimeout(() => {
      const dist = Math.ceil(needScrollTop / 10)
      _currentY += dist
      window.scrollTo(_currentY, currentY)
      if (needScrollTop > 10 || needScrollTop < -10) {
        scrollAnimation(_currentY, targetY)
      } else {
        window.scrollTo(_currentY, targetY)
      }
    }, 1)
  }

  back2Top.addEventListener("click", function(e) {
    scrollAnimation(document.scrollingElement.scrollTop, 0);
    e.stopPropagation();
    return false;
  });
  
  window.addEventListener('scroll', function(e) {
    let percent = document.scrollingElement.scrollTop / (document.scrollingElement.scrollHeight - document.scrollingElement.clientHeight) * 100;
    if (percent > 1 && !back2Top.classList.contains('back-top-active')) {
      back2Top.classList.add('back-top-active');
    }
    if (percent == 0) {
      back2Top.classList.remove('back-top-active');
    }
    if (back2TopText) {
      back2TopText.textContent = Math.floor(percent);
    }
  });

  
  let hasCacu = false;
  window.onresize = function() {
    if (window.width > 991) {
      calcuHeight();
    } else {
      hasCacu = false;
    }
  }

  function calcuHeight() {
    // 动态调整站点概览高度
    if (!hasCacu && back2Top.classList.contains('pisces') || back2Top.classList.contains('gemini')) {
      let sideBar = document.querySelector('.sidebar');
      let navUl = document.querySelector('#site_nav');
      sideBar.style = 'margin-top:' + (navUl.offsetHeight + navUl.offsetTop + 15) + 'px;';
      hasCacu = true;
    }
  }
  calcuHeight();
  
  let open = false, MOTION_TIME = 300, RIGHT_MOVE_DIS = '320px';

  if (drawerBox) {
    let rightMotions = document.querySelectorAll('.right-motion');
    let right = drawerBox.classList.contains('right');

    let transitionDir = right ? "transition.slideRightIn" : "transition.slideLeftIn";

    let openProp, closeProp;
    if (right) {
      openProp = {
        paddingRight: RIGHT_MOVE_DIS 
      };
      closeProp = {
        paddingRight: '0px'
      };
    } else {
      openProp = {
        paddingLeft: RIGHT_MOVE_DIS 
      };
      closeProp = {
        paddingLeft: '0px'
      };
    }

    drawerBox.onclick = function() {
      open = !open;
      window.Velocity(rightSideBar, 'stop');
      window.Velocity(viewport, 'stop');
      window.Velocity(rightMotions, 'stop');
      if (open) {
        window.Velocity(rightSideBar, {
          width: RIGHT_MOVE_DIS
        }, {
          duration: MOTION_TIME,
          begin: function() {
            window.Velocity(rightMotions, transitionDir,{ });
          }
        })
        window.Velocity(viewport, openProp,{
          duration: MOTION_TIME
        });
      } else {
        window.Velocity(rightSideBar, {
          width: '0px'
        }, {
          duration: MOTION_TIME,
          begin: function() {
            window.Velocity(rightMotions, {
              opacity: 0
            });
          }
        })
        window.Velocity(viewport, closeProp ,{
          duration: MOTION_TIME
        });
      }
      for (let i = 0; i < drawerBox.children.length; i++) {
        drawerBox.children[i].classList.toggle('muse-line');
      }
      drawerBox.classList.toggle(sideBarOpen);
    }
  }

  // 链接跳转
  let newWindow = 'false'
  if (newWindow === 'true') {
    let links = document.querySelectorAll('.post-body a')
    links.forEach(item => {
      if (!item.classList.contains('btn')) {
        item.setAttribute("target","_blank");
      }
    })
  }
  // 代码高亮
  hljs.initHighlightingOnLoad();

</script>
    <div class="light-box" id="light_box"></div>
<script>
  let imgs = document.querySelectorAll('.post-body img');
  let lightBox = document.querySelector('#light_box');
  lightBox.addEventListener('mousedown', (e) => {
    e.preventDefault()
  })
  lightBox.addEventListener('mousewheel', (e) => {
    e.preventDefault()
  })
  let width = window.innerWidth * 0.8;
  lightBox.onclick = () => {
    let img = lightBox.querySelector('img');
    lightBox.style = '';
    img && img.remove();
  }
  imgs.forEach(item => {
    item.onclick = function (e) {
      let lightImg = document.createElement('img');
      lightImg.src = this.src;
      lightBox.style = `height: 100%; opacity: 1; background-color: rgba(0, 0, 0, 0.5);cursor: zoom-out;`;
      lightImg.style = `width: ${width}px; border: 1px solid #fff; border-radius: 2px;`;
      lightImg.onclick = function () {
        lightBox.style = '';
        this.remove();
      }
      lightBox.append(lightImg);
    }
  })
</script>
  </div>
</body>
<input hidden id="copy" />
<script>
  //拿来主义(真香)^_^，Clipboard 实现摘自掘金 https://juejin.im/post/5aefeb6e6fb9a07aa43c20af
  window.Clipboard = (function (window, document, navigator) {
    var textArea,
      copy;

    // 判断是不是ios端
    function isOS() {
      return navigator.userAgent.match(/ipad|iphone/i);
    }
    //创建文本元素
    function createTextArea(text) {
      textArea = document.createElement('textArea');
      textArea.value = text;
      textArea.style.width = 0;
      textArea.style.height = 0;
      textArea.clientHeight = 0;
      textArea.clientWidth = 0;
      document.body.appendChild(textArea);
    }
    //选择内容
    function selectText() {
      var range,
        selection;

      if (isOS()) {
        range = document.createRange();
        range.selectNodeContents(textArea);
        selection = window.getSelection();
        selection.removeAllRanges();
        selection.addRange(range);
        textArea.setSelectionRange(0, 999999);
      } else {
        textArea.select();
      }
    }

    //复制到剪贴板
    function copyToClipboard() {
      try {
        document.execCommand("Copy")
      } catch (err) {
        alert("复制错误！请手动复制！")
      }
      document.body.removeChild(textArea);
    }

    copy = function (text) {
      createTextArea(text);
      selectText();
      copyToClipboard();
    };

    return {
      copy: copy
    };
  })(window, document, navigator);

  function copyCode(e) {
    if (e.srcElement.tagName === 'SPAN' && e.srcElement.classList.contains('copy-code')) {
      let code = e.currentTarget.querySelector('code');
      var text = code.innerText;
      if (e.srcElement.textContent === '复制成功') {
        console.log('复制操作频率过高');
        return;
      }
      e.srcElement.textContent = '复制成功';
      (function (elem) {
        setTimeout(() => {
          if (elem.textContent === '复制成功') {
            elem.textContent = '复制代码'
          }
        }, 1000);
      })(e.srcElement)
      Clipboard.copy(text);
    }
  }

  let pres = document.querySelectorAll('pre');
  pres.forEach(pre => {
    let code = pre.querySelector('code');
    let copyElem = document.createElement('span');
    copyElem.classList.add('copy-code');
    copyElem.textContent = '复制代码';
    pre.appendChild(copyElem);
    pre.onclick = copyCode
  })
</script>
<script src="/media/js/motion.js"></script>

<script src="https://cdn.jsdelivr.net/gh/cferdinandi/smooth-scroll/dist/smooth-scroll.polyfills.min.js"></script>
<script>
  var scroll = new SmoothScroll('a[href*="#"]', {
    speed: 500
  });
</script>

<!-- <div class="search-mask" id="search_mask">
  <div class="search-box">
    <div class="search-title">
      <i class="fa fa-search"></i>
      <div class="input-box">
        <input type="text" placeholder="搜索">
      </div>
      <i class="fa fa-times-circle"></i>
    </div>
    <div class="result">
      
      <div class="item">
        <a class="result-title" href="https://wenbozhangw.github.io/post/li-jie-tong-bu-qi-kuang-jia-abstractqueuedsynchronizer/"" data-c="
          &lt;h2 id=&#34;一-背景&#34;&gt;一、背景&lt;/h2&gt;
&lt;p&gt;Java 在 1.5 版本引入了 &lt;code&gt;java.util.concurrent&lt;/code&gt;包，用以支持并发编程，降低并发编程的复杂性；而其中大部分的同步器（例如 &lt;code&gt;lock&lt;/code&gt;, &lt;code&gt;barriers&lt;/code&gt; 等等）都是基于 &lt;code&gt;AbstractQueuedSynchronizer&lt;/code&gt; 类，一般我们称为&lt;code&gt;AQS&lt;/code&gt;。 &lt;code&gt;java.util.concurrent.locks.AbstractQueuedSynchronizer&lt;/code&gt; 出自 &lt;code&gt;Doug Lea&lt;/code&gt; 带佬，他的 &lt;a href=&#34;https://gee.cs.oswego.edu/&#34;&gt;个人博客&lt;/a&gt; 上有一篇相关论文 &lt;a href=&#34;https://gee.cs.oswego.edu/dl/papers/aqs.pdf&#34;&gt;《The java.util.concurrent Synchronizer Framework》&lt;/a&gt;，在我们深入研究 &lt;code&gt;AQS&lt;/code&gt; 之前，有必要拜读一下该论文，翻译见笔者的另一篇博客&lt;a href=&#34;https://wenbozhangw.github.io/post/lesslessthe-javautilconcurrent-synchronizer-frameworkgreatergreater-yuan-wen-fan-yi/&#34;&gt;《The java.util.concurrent Synchronizer Framework》原文翻译&lt;/a&gt; 之后结合相关源码实现进行分析。&lt;/p&gt;
&lt;!-- more --&gt;
&lt;h2 id=&#34;二-aqs概述&#34;&gt;二、AQS概述&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;AQS&lt;/code&gt; 是 &lt;code&gt;j.u.c&lt;/code&gt; 包中用来构建同步组件（例如 &lt;code&gt;ReentrantLock&lt;/code&gt;、&lt;code&gt;Semaphore&lt;/code&gt;）的基础框架。从实现上来看，&lt;code&gt;AQS&lt;/code&gt; 提供了原子的同步状态管理、线程的阻塞及唤醒以及存储队列管理模型。基于 &lt;code&gt;AQS&lt;/code&gt; 提供的强大功能，我们可以很简单的构建属于自己的同步器组件。同时，&lt;code&gt;AQS&lt;/code&gt; 也提供了任务取消、阻塞超时以及&lt;code&gt;conditionObject&lt;/code&gt;提供的管程风格的 &lt;code&gt;await/signal/signalAll&lt;/code&gt;操作。并且根据所需策略的不同，&lt;code&gt;AQS&lt;/code&gt; 还提供了&lt;code&gt;公平&lt;/code&gt;/&lt;code&gt;非公平&lt;/code&gt;、&lt;code&gt;独占&lt;/code&gt;/&lt;code&gt;共享&lt;/code&gt; 等特性。&lt;/p&gt;
&lt;h2 id=&#34;三-同步器框架原理&#34;&gt;三、同步器框架原理&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;AQS&lt;/code&gt; 框架用来实现加锁和解锁的核心是基于 &lt;code&gt;acquire&lt;/code&gt; 和 &lt;code&gt;release&lt;/code&gt; 方法，通过这两个方法，从而去进行原子操作修改同步器状态变量，从而实现对共享资源的并发访问。在 《The java.util.concurrent Synchronizer Framework》 原文中有提到 &lt;code&gt;AQS&lt;/code&gt; 的这两个核心操作实现的伪代码：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;acquire&lt;/code&gt; 操作如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;while(synchronization state does not allow acquire) {
  enqueue current thread if not already queued;
  possibly block current thread;
}
dequeue current thread if it was queued;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;简单翻译一下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;while(同步器状态获取失败) {
  if (当前线程未进入等待队列) {
    将当前线程入队；
  }
  可能尝试阻塞当前线程;
}
if (如果当前线程已经入队) {
  当前线程出队;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;release&lt;/code&gt; 操作如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;update synchronization state;
if(state may permit a blocked thread to acquire) 
  unblock one or more queued threads;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;简单翻译一下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;更新同步器状态;
if (同步器状态可以允许一个阻塞线程获取) {
  解除一个或多个队列线程的阻塞状态;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到 &lt;code&gt;AQS&lt;/code&gt; 的核心思想是，如果请求资源空闲（即同步器状态修改成功），将共享资源设置为锁定状态；如果共享资源被占用（即同步器状态修改失败），就需要对当前线程进行入队操作，之后通过阻塞等待唤醒机制来保证锁的分配。这个队列机制主要是通过 CLH 队列的变体来实现的。我们会在下文中对 CLH 队列进行讲述。&lt;/p&gt;
&lt;h3 id=&#34;31同步器状态&#34;&gt;3.1同步器状态&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;AQS&lt;/code&gt; 类内部定义了一个&lt;code&gt;volatile&lt;/code&gt;修饰的 &lt;code&gt;32&lt;/code&gt; 位 &lt;code&gt;int&lt;/code&gt; 类型的 &lt;code&gt;state&lt;/code&gt; 变量用于维护同步器的状态：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    /**
     * 同步状态值
     */
    private volatile int state;

    /**
     * 返回同步状态的当前值。
     * 该操作的内存语义为{@code volatile} 读。
     * @return 当前同步状态值
     */
    protected final int getState() {
        return state;
    }

    /**
     * 设置同步状态的值。
     * 该操作具有 {@code volatile} 写的内存语义。
     * @param newState 新状态值
     */
    protected final void setState(int newState) {
        state = newState;
    }

    /**
     * 如果当前状态值等于预期值，则自动将同步状态设置为
     * 给定的更新值。该操作具有 {@code volatile} 读写
     * 的内存语义。
     *
     * @param expect 期望值
     * @param update 新值
     * @return 如果成功，返回{@code true}. 返回 false 表示实际值
     *	       与期望值不相等。
     */
    protected final boolean compareAndSetState(int expect, int update) {
        // 见下面的内部设置来支持这一点
        return unsafe.compareAndSwapInt(this, stateOffset, expect, update);
    }

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;同步器的状态 &lt;code&gt;state&lt;/code&gt; 在不同的实现中会有不同的作用和意义，需要结合具体的使用进行分析（比如说 &lt;code&gt;ReentrantReadWriteLock&lt;/code&gt; 中 &lt;code&gt;state&lt;/code&gt; 的前 16 位记录读锁的数量（共享），后 16 位记录写锁的数量（独占））。另外，我们可以看到，上面关于 &lt;code&gt;state&lt;/code&gt; 的几个方法都是 &lt;code&gt;final&lt;/code&gt; 修饰的，说明子类无法重写它们。我们可以通过修改 &lt;code&gt;state&lt;/code&gt; 字段来表示同步状态加锁的过程。&lt;/p&gt;
&lt;h3 id=&#34;32-clh-队列&#34;&gt;3.2 CLH 队列&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;CLH&lt;/code&gt;队列：&lt;code&gt;Craig、Landin and Hagersten&lt;/code&gt;队列，基础的 CLH 对列是一个单向链表，而 &lt;code&gt;AQS&lt;/code&gt; 中是用的队列是 CLH 队列的变体——虚拟双向队列（FIFO），因此，该框架是不支持基于优先级的同步。使用同步队列的原因是，它是一种不需要使用低级锁来构造非阻塞数据结构。&lt;/p&gt;
&lt;p&gt;CLH 队列实际上并不是很像队列，因为它的入队和出队操作都与其用途（作为锁）紧密相关。他通过两个字段 &lt;code&gt;tail&lt;/code&gt; 和 &lt;code&gt;head&lt;/code&gt; 来存取，同时这两个字段支持原子更新，两者在初始化时都指向的空节点。&lt;/p&gt;
&lt;p&gt;当一个新节点通过原子操作入队：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;do {
  pred = tail;
} while (!tail.compareAndSet(pred, node));
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;同时， 每个节点的 &lt;code&gt;release&lt;/code&gt; 状态都保存在其前驱结点中。因此，当前节点可以通过自旋，直到前驱节点释放锁（但是，从实际上来看，过度的自旋会带来大量的 CPU 性能损耗）：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;while (pred.status != RELEASED); // spin
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;自旋后的出队操作只需将 &lt;code&gt;head&lt;/code&gt; 字段指向刚刚得到锁的节点：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;head = node
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;CLH 的优点是：它的入队和出队操作是快速的、无锁的、无阻塞的（即使在竞争的情况下，也只会有一个线程赢得插入的机会，从而能进行下去）。检测是否有线程在等待也很快（只需要检测 &lt;code&gt;head&lt;/code&gt; 和 &lt;code&gt;tail&lt;/code&gt; 是否相等）；同时，&lt;code&gt;release&lt;/code&gt; 是分散的，避免了一些不必要的内存竞争。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;AQS&lt;/code&gt;中的等待队列是 CLH 锁队列的变体。CLH 锁通常用于自旋锁。但是在 &lt;code&gt;AQS&lt;/code&gt; 中将其作为阻塞同步器，但是根据其基本思想，即在其节点的前驱节点中保存有关线程的控制信息。每个节点的“状态”字段跟踪线程是否应该阻塞。节点在其前驱节点释放时发出 &lt;code&gt;signal&lt;/code&gt; 。否则，队列中的每个节点都是持有单个线程的特定通知器。状态字段不用于控制线程是否持有锁。同时，线程可能会尝试获取队列中的第一个节点，但其并不保证一定成功，所以当前释放的竞争线程可能会重新被阻塞（如果没有获取到锁）。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;AQS&lt;/code&gt;使用的 CLH 变体中的 &amp;quot;prev&amp;quot; 连接（指向前驱节点）主要用于处理取消。如果一个节点被取消，它的后继节点（通常）需要重新连接到一个未取消的前驱节点。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;AQS&lt;/code&gt; 使用 CLH 的 &amp;quot;next&amp;quot; 连接（指向后继节点）来实现阻塞机制。每个节点的线程 id 保存在自身中，因此前驱节点通过遍历 next 连接来确定它是哪个线程来通知下一个节点的唤醒。设置当前节点的 next （后继节点）时，必须避免与新入队的节点竞争。当节点的后继节点为空时，通过从队列的 &lt;code&gt;tail&lt;/code&gt; 向后检查来解决这个问题。（&amp;quot;next&amp;quot; 本来就是一种优化，通常情况下是不需要向后扫描的。）&lt;/p&gt;
&lt;p&gt;CLH 队列需要一个虚拟头节点。但是我们不会在构建时创建它们，因为如果从不存在竞争，那将是浪费精力。相反，在第一次出现竞争时构造节点并设置 &lt;code&gt;head&lt;/code&gt; 和 &lt;code&gt;tail&lt;/code&gt; 指针。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Condition&lt;/code&gt; 等待队列中的阻塞线程使用的是相同的 &lt;code&gt;Node&lt;/code&gt; 结构，但是提供了另一个链表来存放，因此 &lt;code&gt;Condition&lt;/code&gt; 等待队列的实现会更加复杂。&lt;/p&gt;
&lt;p&gt;关于 CLH 队列的实现如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    static final class Node {
        /** 标记节点处于共享模式下的等待 */
        static final Node SHARED = new Node();
        /** 标记节点处于独占模式下的等待 */
        static final Node EXCLUSIVE = null;

        /** waitStatus 值，表示线程已经取消 */
        static final int CANCELLED =  1;
        /** waitStatus 值，表示后继线程需要唤醒 */
        static final int SIGNAL    = -1;
        /** waitStatus 值，表示线程需要等待条件 */
        static final int CONDITION = -2;
        /**
         * waitStatus 值，指示下一个 acquireShared 应该无条件传播
         */
        static final int PROPAGATE = -3;

        /**
         * Status 字段, 仅取以下值:
         *   SIGNAL:     该节点的后继节点被（或即将）阻塞（通过 park），因此当前
         *               节点在释放或取消时必须解除其后继节点的 park。为了避免
         *               竞争，acquire 方法必须首先表明它们需要 signal，然后重试
         *               原子获取，然后在失败时阻塞。
         *   CANCELLED:  由于超时或中断，该节点被取消。节点永远不会离开这个状态。
         *				 特别的是，被取消的节点的线程永远不会再次阻塞。
         *   CONDITION:  此节点当前位于条件队列中。在转换之前不会用作同步队列节点，
         *               此时状态将设置为 0。（此处使用此值与该字段的其他用途无关，但简化的机制）
         *   PROPAGATE:  releaseShared 应该传播到其他节点。这是在 doReleaseShared 中设置 
         *               的（仅针对头结点），以确保传播继续进行，即使其他操作已经介入。
         *   0:          以上都不是
         *
         * 这些值按数字排列以简化使用。非负值意味着节点不需要发出 signal。
         * 因此，大多数代码不需要检查特定值，只需检查 sign 即可。
         *
         * 对于正常同步节点，该字段初始化为 0，对于 CONDITION 节点，该字段初始化为 CONDITION。
         * 它使用 CAS 进行修改（或者在可能的情况下，无条件的 volatile 写入）
         */
        volatile int waitStatus;

        /**
         * 链接到当前节点/线程的前驱节点，用于检查 waitStatus。在入队时分配，
         * 并且仅在出队时设置为 null（为了 GC）。此外，在前驱节点取消时，我们短路，同时
         * 找到一个未取消的前驱节点（该前驱节点不会不存在），因为头结点不会被取消：一个节点
         * 只有在 acquire 成功时才会成为头结点。被取消的线程永远不会获取成功，同时
         * 一个线程只能取消自己，无法取消任何其他节点。
         */
        volatile Node prev;

        /**
         * 链接到当前节点/线程的后继节点，用于在 release 时 unpark 操作。在入队时分配，
         * 前驱节点取消时，会进行绕过调整，在出队时清空（为了 GC）。enq 操作在建立链接之前
         * 不会给前驱节点的 next 字段赋值，因此看到 next 字段为 null，并不一定意味着该节点在
         * 队尾。然而，如果 next 字段看起来是 null，我们可以从 tail 扫描 prev 节点，从而
         * 进行双重检查。取消的节点的 next 字段被设置为指向节点自身，而不是 null，
         * 从而使 isOnSyncQueue 的工作更容易。
         */
        volatile Node next;

        /**
         * 将 thread 放入当前节点。构造时初始化，使用后清空。
         */
        volatile Thread thread;

        /**
         * 链接到等待条件的下一个节点，或特定的 SHARED 值。因为条件队列只有在
         * 独占模式下被访问，所以我们只需要一个简单的链接队列来保存等待条件的节点。
         * 然后，它们被转移到队列中进行重新 acquire。因为条件只能是独占的，所以
         * 我们通过使用特殊值来保存特殊值，以表示共享模式。
         */
        Node nextWaiter;

        /**
         * 如果节点在共享模式下等待，则返回true。
         */
        final boolean isShared() {
            return nextWaiter == SHARED;
        }

        /**
         * 返回上一个节点，如果为空则抛出NullPointerException。
         * 当前驱节点不能为空时使用。null 检查可以省略，但它的存在是为了帮助 VM。
         *
         * @return 当前节点的前驱节点
         */
        final Node predecessor() throws NullPointerException {
            Node p = prev;
            if (p == null)
                throw new NullPointerException();
            else
                return p;
        }

        Node() {    // Used to establish initial head or SHARED marker
        }

        Node(Thread thread, Node mode) {     // Used by addWaiter
            this.nextWaiter = mode;
            this.thread = thread;
        }

        Node(Thread thread, int waitStatus) { // Used by Condition
            this.waitStatus = waitStatus;
            this.thread = thread;
        }
    }

    /**
     * 等待队列的头部，延迟初始化。除此之外，只能通过 setHead 方法进行修改，
     * 注意：如果 head 存在，它的 waitStatus 保证不会被 CANCELLED。
     */
    private transient volatile Node head;

  /**
   * 等待队列的尾部，延迟初始化。仅通过方法 enq 修改以添加新的等待节点。
   */
  private transient volatile Node tail;

  /**
   * 设置以用于支持 compareAndSet. 我们需要在这里本地实现这一点：
   * 为了允许未来的功能增强，我们不能显式地继承 AtomicInteger，不然这将是高效和有用的。
   * 因此，作为少有的弊端，我们本地使用 hotspot 内在的 API 实现。但我们这样做的时候，
   * 我们队其他 CASable 字段做同样的事情（否则可以用原子字段更新器来完成）。
   */
    private static final Unsafe unsafe = Unsafe.getUnsafe();
    private static final long stateOffset;
    private static final long headOffset;
    private static final long tailOffset;
    private static final long waitStatusOffset;
    private static final long nextOffset;

    static {
        try {
            stateOffset = unsafe.objectFieldOffset
                (class.getDeclaredField(&amp;quot;state&amp;quot;));
            headOffset = unsafe.objectFieldOffset
                (class.getDeclaredField(&amp;quot;head&amp;quot;));
            tailOffset = unsafe.objectFieldOffset
                (class.getDeclaredField(&amp;quot;tail&amp;quot;));
            waitStatusOffset = unsafe.objectFieldOffset
                (Node.class.getDeclaredField(&amp;quot;waitStatus&amp;quot;));
            nextOffset = unsafe.objectFieldOffset
                (Node.class.getDeclaredField(&amp;quot;next&amp;quot;));

        } catch (Exception ex) { throw new Error(ex); }
    }

    /**
     * CAS head field. Used only by enq.
     */
    private final boolean compareAndSetHead(Node update) {
        return unsafe.compareAndSwapObject(this, headOffset, null, update);
    }

    /**
     * CAS tail field. Used only by enq.
     */
    private final boolean compareAndSetTail(Node expect, Node update) {
        return unsafe.compareAndSwapObject(this, tailOffset, expect, update);
    }

    /**
     * CAS waitStatus field of a node.
     */
    private static final boolean compareAndSetWaitStatus(Node node,
                                                         int expect,
                                                         int update) {
        return unsafe.compareAndSwapInt(node, waitStatusOffset,
                                        expect, update);
    }

    /**
     * CAS next field of a node.
     */
    private static final boolean compareAndSetNext(Node node,
                                                   Node expect,
                                                   Node update) {
        return unsafe.compareAndSwapObject(node, nextOffset, expect, update);
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;下面介绍一下 &lt;code&gt;Node&lt;/code&gt; 类中的几个属性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;waitStatus&lt;/code&gt;：当前 &lt;code&gt;Node&lt;/code&gt; 的等待状态，共有五个可选值：
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;0&lt;/code&gt;：初始值，当前节点如果没有指定初始值，则默认为 &lt;code&gt;0&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;CANCELLED(1)&lt;/code&gt;：表示当前节点因为超时或线程中断被取消。当节点被取消后，不会再转换为其他状态，被取消的节点的线程实例也不会阻塞。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;SIGNAL(-1)&lt;/code&gt;：表示当前节点的后继节点通过 &lt;code&gt;park()&lt;/code&gt; 被阻塞，当前节点释放或取消时，必须 &lt;code&gt;unpark()&lt;/code&gt; 它的后继节点。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;CONDITION(2)&lt;/code&gt;：表示当前节点是条件队列中的一个节点，当它转换为同步队列中节点时，&lt;code&gt;waitStatus&lt;/code&gt; 会被重新设置为 &lt;code&gt;0&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;PROPAGATE(3)&lt;/code&gt;：当节点为头结点，调用 &lt;code&gt;doReleaseShared()&lt;/code&gt; 时，确保 &lt;code&gt;releaseShared()&lt;/code&gt; 可以传播到其他节点。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;prev&lt;/code&gt;：当前节点的前驱节点，用于检查 &lt;code&gt;waitStatus&lt;/code&gt;。当前驱节点被取消时，通过 &lt;code&gt;prev&lt;/code&gt; 找到一个未取消的前驱节点。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;next&lt;/code&gt;：当前节点的后继节点，当节点被取消或释放时，用于 &lt;code&gt;unpark&lt;/code&gt; 取消后继节点的阻塞（会自动绕过取消的后继节点）。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;thread&lt;/code&gt;：当前节点持有的线程实例引用。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nextWaiter&lt;/code&gt;：下一个等待节点，可能的取值有下面的几种情况：
&lt;ul&gt;
&lt;li&gt;当前实例为独占模式时，取值为 &lt;code&gt;Node.EXCLUSIVE&lt;/code&gt; （即 &lt;code&gt;null&lt;/code&gt;）。&lt;/li&gt;
&lt;li&gt;当前实例为共享模式时，取值为 &lt;code&gt;Node.SHARED&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;非上面两种情况时，代表条件队列中当前节点的下一个等待节点。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;33-阻塞&#34;&gt;3.3 阻塞&lt;/h3&gt;
&lt;p&gt;在 JDK1.5 之前，线程的阻塞和唤醒只能依赖于 &lt;code&gt;Object&lt;/code&gt; 类提供的 &lt;code&gt;wait()&lt;/code&gt; 、&lt;code&gt;notify()&lt;/code&gt;、&lt;code&gt;notifyAll()&lt;/code&gt; 方法，它们都是由 JVM&lt;br&gt;
提供实现，并且使用的时候需要获取监视器锁（即需要在 &lt;code&gt;synchronized&lt;/code&gt; 代码块中），没有 Java API 可以阻塞和唤醒线程。唯一可以选择的是 &lt;code&gt;Thread.suspend&lt;/code&gt; 和 &lt;code&gt;Thread.resume&lt;/code&gt;&lt;br&gt;
，但是他们都有无法解决的竟态问题：当一个非阻塞线程在一个正准备阻塞的线程调用 &lt;code&gt;suspend&lt;/code&gt; 之前调用 &lt;code&gt;resume&lt;/code&gt;，&lt;code&gt;resume&lt;/code&gt;操作将不起作用。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;j.u.c&lt;/code&gt; 包引入了 &lt;code&gt;LockSupport&lt;/code&gt; 类，其底层是基于 &lt;code&gt;Unsafe&lt;/code&gt; 类的 &lt;code&gt;park()&lt;/code&gt; 和 &lt;code&gt;unpark()&lt;/code&gt; 方法，&lt;code&gt;LockSupport.park&lt;/code&gt;&lt;br&gt;
阻塞当前线程，除非或直到发出 &lt;code&gt;LockSupport.unpark&lt;/code&gt;（虚假唤醒是允许的）。&lt;code&gt;park&lt;/code&gt; 方法同样支持可选的相对或绝对的超时设置，以及与&lt;br&gt;
JVM 的 &lt;code&gt;Thread.interrupt&lt;/code&gt; 结合 —— 可通过中断来 &lt;code&gt;unpark&lt;/code&gt; 一个线程。&lt;/p&gt;
&lt;h3 id=&#34;34-条件队列&#34;&gt;3.4 条件队列&lt;/h3&gt;
&lt;p&gt;在 &lt;code&gt;AQS&lt;/code&gt; 中除了同步队列外，还提供了另一种更为复杂的条件队列，而条件队列是基于 &lt;code&gt;Condition&lt;/code&gt;接口实现的，下面我们先浏览一下 &lt;code&gt;Condition&lt;/code&gt; 接口的说明。&lt;/p&gt;
&lt;h4 id=&#34;341-condition-接口&#34;&gt;3.4.1 Condition 接口&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;Condition&lt;/code&gt; 将 &lt;code&gt;Object&lt;/code&gt; 的监视器方法（&lt;code&gt;wait&lt;/code&gt;、&lt;code&gt;notify&lt;/code&gt; 和 &lt;code&gt;notifyAll&lt;/code&gt;） 分解到不同的对象，通过将它们与任意的 &lt;code&gt;Lock&lt;/code&gt;&lt;br&gt;
实现相结合，可以使每个对象具有多个等待集合。&lt;code&gt;Lock&lt;/code&gt; 代替的 &lt;code&gt;synchronized&lt;/code&gt; 方法和语句的使用，&lt;code&gt;Condition&lt;/code&gt; 代替了 &lt;code&gt;Object&lt;/code&gt;&lt;br&gt;
监视器方法的使用。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Condition&lt;/code&gt;（也称为 &lt;em&gt;条件队列(condition queue)&lt;/em&gt; 或 &lt;em&gt;条件变量(condition variable)&lt;/em&gt;）为线程提供了一种暂停执行（“等待”）的方法，直到另外一个线程通知说某个状态条件现在可能为 &lt;code&gt;true&lt;/code&gt;&lt;br&gt;
。由于对这种共享状态信息的访问会发生在多个不同线程中，所以它必须受到保护，因此需要某种形式的锁与条件相关联。等待条件提供的关键属性是它以 *&lt;br&gt;
原子* 方式释放关联的锁并挂起当前线程，就像 &lt;code&gt;Object.wait&lt;/code&gt; 一样。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Condition&lt;/code&gt; 实例本质上是需要绑定到锁。需要获取特定 &lt;code&gt;Lock&lt;/code&gt; 实例的 &lt;code&gt;Condition&lt;/code&gt; 实例，请使用其 &lt;code&gt;newCondition()&lt;/code&gt; 方法。&lt;/p&gt;
&lt;p&gt;例如，假设我们有一个支持 put 和 take 方法的有界缓冲区。如果 take 在空缓冲区上尝试获取，则线程将阻塞，知道缓冲区变得可用；如果在一个满的缓冲区上调用 &lt;code&gt;put&lt;/code&gt;，则线程将阻塞，直到有空间可用。我们希望&lt;br&gt;
put 线程继续等待，并且与 take线程隔开在另一个等待集合中，以便当我们的缓冲区可用或有空间发生变化时通知对应的单个线程。这可以使用量 &lt;code&gt;Condition&lt;/code&gt; 实例来实现。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;class BoundedBuffer {
    final Lock lock = new ReentrantLock();
    final Condition notFull = lock.newCondition();
    final Condition notEmpty = lock.newCondition();
    
    final Object[] items = new Object[100];
    int putptr, takeptr, count;
    
    public void put(Object x) throws InterruptedException {
        lock.lock();
        try {
            while (count == items.length) 
                notFull.await();
            items[putptr] = x;
            if (++putptr == items.length) putptr = 0;
            ++count;
            notEmpty.signal();
        } finally {
            lock.unlock();
        }
    }
    
    public Object take() throws InterrputedException {
        lock.lock();
        try {
            while (count == 0) 
                notEmpty.await();
            Object x = items[takeptr];
            if (++takeptr == items.length) takeptr = 0;
            --count;
            notFull.signal();
            return x;
        } finally {
            lock.unlock;
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(&lt;code&gt;java.util.concurrent.ArrayBlockingQueue&lt;/code&gt; 类提供了这个功能，所以没有理由使用这个实例类。)&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Condition&lt;/code&gt; 的实现可以提供与 &lt;code&gt;object&lt;/code&gt; 监视器方法不同的行为和语义，例如保证通知的顺序，或者在执行通知时不需要持有锁。如果实现提供了这种专门的语义，那么实现必须记录这些语义。&lt;/p&gt;
&lt;p&gt;请注意，&lt;code&gt;Condition&lt;/code&gt; 实例只是普通对象，它们本身可以用作 &lt;code&gt;synchronized&lt;/code&gt; 语句中的目标，并且可以调用它们自己的监视器 &lt;code&gt;wait&lt;/code&gt; 和 &lt;code&gt;notification&lt;/code&gt; 方法。获取 &lt;code&gt;Condition&lt;/code&gt; 实例的监视器锁，或使用其监视器方法，与获取和该 &lt;code&gt;Condition&lt;/code&gt; 关联的 &lt;code&gt;Lock&lt;/code&gt; 或使用其 &lt;code&gt;wait()&lt;/code&gt; 和 &lt;code&gt;signal()&lt;/code&gt; 方法没有指定关系。为避免混淆，建议不要以这种方式使用 &lt;code&gt;Condition&lt;/code&gt; 实例，除非在它们自己的实现中。&lt;/p&gt;
&lt;p&gt;除非另有说明，否则为任何参数传递 &lt;code&gt;null&lt;/code&gt; 值将导致 &lt;code&gt;NullPointerException&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;实现注意事项：&lt;/p&gt;
&lt;p&gt;在等待 &lt;code&gt;Condition &lt;/code&gt; 时，通常允许发生 &lt;em&gt;”虚假唤醒“&lt;/em&gt;&lt;br&gt;
，作为对底层平台语义的让步。这对大多数应用程序几乎没有实际影响，因为应该始终在循环中等待 &lt;code&gt;Condition&lt;/code&gt;&lt;br&gt;
，测试正在等待的状态谓词是否为 &lt;code&gt;true&lt;/code&gt;。一个实现可以自由地消除虚假唤醒的可能性，但建议应用程序的程序员总是假设它们可以发生，因此总是在循环中等待条件唤醒。&lt;/p&gt;
&lt;p&gt;条件等待的三种形式（可中断、不可中断和定时）在某些平台上实现的难易程度和性能特征可能不同。特别是，可能难以提供这些功能并维护特定的语义，例如排序保证。此外，中断线程的实际挂起能力可能并不总是适用所有平台。&lt;/p&gt;
&lt;p&gt;因次，实现不需要为所有三种等待形式定义完全相同的保证或语义，也不需要支持线程实际挂起的中断。&lt;/p&gt;
&lt;p&gt;实现需要清楚地记录每个等待方法提供的语义和保证，并且当实现确实支持线程挂起的中断时，它必须遵守此接口中定义的中断语义。&lt;/p&gt;
&lt;p&gt;由于中断通常意味着取消，并且对中断的检查通常不常见，因此实现可以倾向于响应中断而不是正常的方法返回。即使可以证明中断发生在另一个可能已经解除阻塞线程的操作之后也是如此。一个实现应该记录这个行为。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public interface Condition {

  /**
   * 使当前线程等待，直到它被 signal 或中断。
   *
   * 直到以下四种情况之一发生时，与此 Condition 关联的锁会被自动释放，并且当前线程
   * 由于线程调度会被禁用并处于休眠状态：
   * - 其他某个线程为此 Condition 调用了 signal() 方法，而当前线程恰好被选为要被唤醒的线程；
   * - 其他一些线程为此 Condition 调用了 signalAll() 方法；
   * - 其他一些线程中断当前线程，支持中断线程挂起；
   * - 发生“虚假唤醒”。
   *
   * 在所有情况下，在此方法可以返回之前，当前线程必须重新获取获取与此 Condition 关联的锁。
   * 当前线程返回时，它保证持有这个锁。
   *
   * 如果当前线程：
   * - 在进入此方法时设置其中断状态；或者，
   * - 等待过程中被中断，支持线程挂起的中断。
   *
   * 然后抛出 InterruptedException 并清除当前线程的中断状态。在第一种情况下，没有规定是否
   * 在释放锁之前进行中断判断。
   *
   * 实现注意事项：
   *
   * 调用此方法时，假定当前线程持有与此 Condition 关联的锁。由实现决定是否是这种情况，
   * 如果不是，如何响应。通常，将抛出异常（例如，IllegalMonitorStateException）并且
   * 实现必须记录该事实。
   *
   * 与响应 signal 的正常方法返回相比，实现更倾向于响应中断。在这种情况下，实现必须确保将
   * 信号量重定向到另一个等待线程（如果有的话）。
   *
   * @throws InterruptedException - 如果当前线程被中断（并且支持线程挂起的中断）
   */
  void await() throws InterruptedException;

  /**
   * 使当前线程等待，直到它被 signal。
   *
   * 直到以下三种情况之一发生时，与此 Condition 关联的锁会被自动释放，并且当前线程
   * 由于线程调度会被禁用并处于休眠状态：
   * - 其他某个线程为此 Condition 调用了 signal() 方法，而当前线程恰好被选为要被唤醒的线程；
   * - 其他一些线程为此 Condition 调用了 signalAll() 方法；
   * - 发生“虚假唤醒”。
   *
   * 在所有情况下，在此方法可以返回之前，当前线程必须重新获取获取与此 Condition 关联的锁。
   * 当前线程返回时，它保证持有这个锁。
   *
   * 如果当现场进入该方法时设置了中断状态，或者在等待过程中被中断，则继续等待直到被 signal 唤醒。
   * 当它最终从这个方法返回时，它的中断状态会依旧存在。
   *
   *
   * 实现注意事项：
   *
   * 调用此方法时，假定当前线程持有与此 Condition 关联的锁。由实现决定是否是这种情况，
   * 如果不是，如何响应。通常，将抛出异常（例如，IllegalMonitorStateException）并且
   * 实现必须记录该事实。
   *
   */
  void awaitUninterruptibly();

  /**
   * 使当前线程等待，直到它被 signal 或 中断，或者达到指定的等待时间。
   *
   * 直到以下五种情况之一发生时，与此 Condition 关联的锁会被自动释放，并且当前线程
   * 由于线程调度会被禁用并处于休眠状态：
   * - 其他某个线程为此 Condition 调用了 signal() 方法，而当前线程恰好被选为要被唤醒的线程；
   * - 其他一些线程为此 Condition 调用了 signalAll() 方法；
   * - 其他一些线程中断当前线程，支持中断线程挂起；
   * - 到达指定的等待时间；
   * - 发生“虚假唤醒”。
   *
   * 在所有情况下，在此方法可以返回之前，当前线程必须重新获取获取与此 Condition 关联的锁。
   * 当前线程返回时，它保证持有这个锁。
   *
   * 如果当前线程：
   * - 在进入此方法时设置其中断状态；或者，
   * - 等待过程中被中断，支持线程挂起的中断。
   *
   * 然后抛出 InterruptedException 并清除当前线程的中断状态。在第一种情况下，没有规定是否
   * 在释放锁之前进行中断判断。
   *
   * 在返回时提供给定的 nanosTimeout 值，该方法返回对剩余等待纳秒数的预估，如果超时，则返回
   * 小于或等于零的值。在等待返回但是等待的条件仍不成立的情况下，此值可用于确定是否重新等待以及
   * 重新等待多长时间。此方法的典型用途如以下形式：
   *
   * boolean aMethod(long timeout, TimeUnit unit) {
   *     long nanos = unit.toNanos(timeout);
   *     lock.lock();
   *     try {
   *         while (!conditionBeingWaitedFor()) {
   *             if (nanos &amp;lt;= 0L) 
   *                 return false;
   *             nanos = theCondition.awaitNanos(nanos);
   *         }
   *         // ...
   *     } finally {
   *         lock.unlock();
   *     }
   * }
   *
   * 设计说明：此方法需要纳秒参数，以避免报告剩余时间时出现截断错误。这种精度损失将使程序员
   * 难以确保总等待时间不会系统地短于重新等待发生时指定的时间。
   *
   * 实现注意事项：
   *
   * 调用此方法时，假定当前线程持有与此 Condition 关联的锁。由实现决定是否是这种情况，
   * 如果不是，如何响应。通常，将抛出异常（例如，IllegalMonitorStateException）并且
   * 实现必须记录该事实。
   *
   * 与响应 signal 的正常方法返回相比，实现更倾向于响应中断。在这种情况下，实现必须确保将
   * 信号量重定向到另一个等待线程（如果有的话）。
   *
   * 参数： nanosTimeout - 等待的最长时间，以纳秒为单位。
   * 返回： nanosTimeout值减去从该方法返回时等待的时间的估计值。正值表示可以用作对该方法的
   *       后续调用以完成等待所需时间的参数。小于或等于零表示没有剩余的时间。
   * @throws InterruptedException - 如果当前线程被中断（并且支持线程挂起的中断）
   */
  long awaitNanos(long nanosTimeout) throws InterruptedException;

  /**
   * 使当前线程等待，直到它被 signal 或 中断，或者达到指定的等待时间。此方法在行为上等效于：
   *     awaitNanos(unit.toNanos(time)) &amp;gt; 0 
   *
   * 参数： time - 等待的最长时间
   *       unit - time 参数的时间单位
   * 返回： 如果从方法返回之前已经到达指定时间，则为 false，否则为 true。
   * @throws InterruptedException - 如果当前线程被中断（并且支持线程挂起的中断）
   */
  boolean await(long time, TimeUnit unit) throws InterruptedException;

  /**
   * 使当前线程等待，直到它被 signal 或 中断，或者达到指定的等待时间。
   *
   * 直到以下五种情况之一发生时，与此 Condition 关联的锁会被自动释放，并且当前线程
   * 由于线程调度会被禁用并处于休眠状态：
   * - 其他某个线程为此 Condition 调用了 signal() 方法，而当前线程恰好被选为要被唤醒的线程；
   * - 其他一些线程为此 Condition 调用了 signalAll() 方法；
   * - 其他一些线程中断当前线程，支持中断线程挂起；
   * - 到达指定的等待时间；
   * - 发生“虚假唤醒”。
   *
   * 在所有情况下，在此方法可以返回之前，当前线程必须重新获取获取与此 Condition 关联的锁。
   * 当前线程返回时，它保证持有这个锁。
   *
   * 如果当前线程：
   * - 在进入此方法时设置其中断状态；或者，
   * - 等待过程中被中断，支持线程挂起的中断。
   *
   * 然后抛出 InterruptedException 并清除当前线程的中断状态。在第一种情况下，没有规定是否
   * 在释放锁之前进行中断判断。
   *
   * 返回值表示是否已经过了 deadline，可以如下使用：
   *
   * 实现注意事项：
   *
   * 调用此方法时，假定当前线程持有与此 Condition 关联的锁。由实现决定是否是这种情况，
   * 如果不是，如何响应。通常，将抛出异常（例如，IllegalMonitorStateException）并且
   * 实现必须记录该事实。
   *
   * 与响应 signal 的正常方法返回相比，实现更倾向于响应中断。在这种情况下，实现必须确保将
   * 信号量重定向到另一个等待线程（如果有的话）。
   * boolean aMethod(Date deadline) {
   *     boolean stillWaiting = true;
   *     lock.lock();
   *     try {
   *         while(!conditionBeingWaitedFor()) {
   *             if (!stillWaiting)
   *                 return false;
   *             stillWaiting = theCondition.awaitUntil(deadline);
   *         }
   *         // ...
   *     } finally {
   *         lock.unlock();
   *     }
   * }
   *
   * 参数： deadline - 等待的绝对时间。
   * 返回： 如果返回时已经超过最后期限，则为 false，否则为 true。
   * @throws InterruptedException - 如果当前线程被中断（并且支持线程挂起的中断）
   */
  boolean awaitUntil(Date deadline) throws InterruptedException;

  /**
   * 唤醒一个等待线程。
   *
   * 如果有任何线程在此 Condition 下等待，则选择一个用于唤醒。然后，该线程必须在从
   * await 返回之前重新获取锁。
   *
   * 实现注意事项
   *
   * 在调用此方法时，实现可能（并且通常确实）要求当前线程持有与此 Condition 关联的锁。
   * 实现必须记录此前提条件以及未持有锁时采取的任何操作。通常，会抛出 IllegalMonitorStateException。
   */
  void signal();

  /**
   * 唤醒所有等待线程。
   *
   * 如果有任何线程在此 Condition 下等待，则它们全部都会被唤醒。然后，每个线程必须在从
   * await 返回之前重新获取锁。
   *
   * 实现注意事项
   *
   * 在调用此方法时，实现可能（并且通常确实）要求当前线程持有与此 Condition 关联的锁。
   * 实现必须记录此前提条件以及未持有锁时采取的任何操作。通常，会抛出 IllegalMonitorStateException。
   */
  void signalAll();
}

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;Condition&lt;/code&gt; 接口提供了与 JAVA 原生的监视器相同风格的 API，但是其并不依赖于 JVM 的实现，用户可以自定义实现 &lt;code&gt;Condition&lt;/code&gt;&lt;br&gt;
接口，提供更加强大和更加灵活的功能，&lt;code&gt;Condition&lt;/code&gt; 在说明中建议和 &lt;code&gt;Lock&lt;/code&gt;&lt;br&gt;
共同使用，可以使每个对象具有多个等待集合，我们下面了解一下 &lt;code&gt;Lock&lt;/code&gt; 接口 。&lt;/p&gt;
&lt;h4 id=&#34;342-lock-接口&#34;&gt;3.4.2 Lock 接口&lt;/h4&gt;
&lt;p&gt;与使用 &lt;code&gt;synchronized&lt;/code&gt; 方法和语句相比，&lt;code&gt;Lock&lt;/code&gt;&lt;br&gt;
实现提供了更广泛的锁定操作。它们允许更灵活的结构，可能具有完全不同的属性，并且可能支持多个关联的 &lt;code&gt;Condition&lt;/code&gt; 对象。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Lock&lt;/code&gt; 是一种控制多线程访问共享资源的工具。通常，&lt;code&gt;Lock&lt;/code&gt;&lt;br&gt;
提供对共享资源的独占访问：一次只有一个线程可以获得锁，并且堆共享资源的所有访问都需要首先获取锁。但是，某些锁可能允许并发访问共享资源，例如 &lt;code&gt;ReadWriteLock&lt;/code&gt;&lt;br&gt;
的读锁。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;synchronized&lt;/code&gt; 方法或语句的使用提供了对于每个对象关键的隐式监视器锁的访问，但强制所有锁的获取和释放必须在块结构内发生：当获取多个锁时，它们必须以相反的顺序释放，并且所有锁必须在获得它们的相同词法范围内释放。&lt;/p&gt;
&lt;p&gt;虽然 &lt;code&gt;synchronized&lt;/code&gt;&lt;br&gt;
方法和语句的作用域机制让使用监视器锁编程变得更加容易，并且有助于避免许多设计锁的常见编程错误，但在某些情况下，您需要以更加灵活的方式使用锁。例如，一些遍历并发访问的数据结构的算法需要使用 &lt;code&gt;hand-over-hand&lt;/code&gt;&lt;br&gt;
或 &lt;code&gt;chain locking&lt;/code&gt;：你获取节点 A 的锁，然后获取节点 B 的锁，然后释放 A 并获取 C，然后释放 B 并获取 D 等等。&lt;code&gt;Lock&lt;/code&gt;&lt;br&gt;
接口的实现通过允许在不同范围内获取和释放锁以及允许以任意顺序获取和释放多个锁，来启用此类技术。&lt;/p&gt;
&lt;p&gt;随着这种灵活性的增加，额外的责任也随之而来。块结构锁定的缺失消除了 &lt;code&gt;synchronized&lt;/code&gt; 方法和语句发生的锁定和自动释放。在大多数情况下，应使用以下语句：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Lock l=...;
l.lock();
try{
    // access the resource protected by this lock
}finally{
    l.unlock;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;当锁定和解锁发生在不同范围内时，必须注意确保所有在持有锁时执行的代码都受到 &lt;code&gt;try-finally&lt;/code&gt; 或 &lt;code&gt;try-catch&lt;/code&gt; 的保护，以确保在必要时释放锁。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Lock&lt;/code&gt; 实现通过提供非阻塞获取锁定方式（&lt;code&gt;tryLock()&lt;/code&gt;）、获取可中断锁的尝试（&lt;code&gt;lockInterruptibly()&lt;/code&gt;&lt;br&gt;
，以及获取锁的尝试）、还提供了超过使用 &lt;code&gt;synchronized&lt;/code&gt; 方法和语句的附加功能 —— 可以超时（&lt;code&gt;tryLock(long, Timeunit)&lt;/code&gt;）。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Lock&lt;/code&gt; 类还可以提供与隐式监视器锁完全不同的行为和语义，例如保证排序、不可重入使用或死锁检测。如果实现提供了这种专门的语义，那么实现必须用文档记录这些语义。&lt;/p&gt;
&lt;p&gt;请注意，&lt;code&gt;Lock&lt;/code&gt; 实例只是普通对象，它们本身可以用作 &lt;code&gt;synchronized&lt;/code&gt; 语句中的目标。获取 &lt;code&gt;Lock&lt;/code&gt;&lt;br&gt;
实例的监视器锁与调用该实例的任何 &lt;code&gt;lock() &lt;/code&gt;&lt;br&gt;
方法没有指定关系。建议为避免混淆，除非在它们自己的实现中，否则不要以这种方式使用 &lt;code&gt;Lock&lt;/code&gt; 实例。&lt;/p&gt;
&lt;p&gt;除非另有说明，否则任何参数传递 &lt;code&gt;null&lt;/code&gt; 将导致 &lt;code&gt;NullPointerException&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;内存同步&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;所有 &lt;code&gt;Lock&lt;/code&gt; 实现&lt;em&gt;必须&lt;/em&gt;&lt;br&gt;
强制执行与内置监视器锁提供的相同的内存同步语义。如 &lt;a href=&#34;https://docs.oracle.com/javase/specs/jls/se7/html/jls-17.html#jls-17.4&#34;&gt;《The Java Language Specification (17.4 Memory Model) 》&lt;/a&gt;&lt;br&gt;
中所述：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;成功的 &lt;em&gt;Lock&lt;/em&gt; 动作与成功的 &lt;code&gt;lock()&lt;/code&gt; 操作具有相同的内存同步效果。&lt;/li&gt;
&lt;li&gt;成功的 &lt;em&gt;Unlock&lt;/em&gt; 动作与成功的 &lt;code&gt;unlock()&lt;/code&gt; 操作具有相同的内存同步效果。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;不成功的 lock 和 unlock 操作，以及重入 lock/unlock 操作，不需要任何内存同步效果。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;实现注意事项&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;三种形式的锁获取（可中断、不可中断和超时）可能在它们的性能特征、顺序保证或其他实现质量方面有所不同。此外，中断 &lt;em&gt;正在进行&lt;/em&gt;&lt;br&gt;
的锁获取的能力在给定的 &lt;code&gt;Lock&lt;/code&gt;&lt;br&gt;
类中可能不可用。因此，实现不需要为所有的三种形式的锁获取给定完全相同的保证或语义，也不需要支持正在进行的锁获取的中断。实现需要清楚地记录每个锁定方法提供的语义和保证。它们必须遵守此接口中定义的中断语义，一直吃获取锁的中断：完全或仅在方法入口上。&lt;/p&gt;
&lt;p&gt;由于中断通常意味着取消，并且对中断的检查通常不常见，因此实现可以倾向于响应中断而不是正常的方法返回。即使可以证明在另一个操作可能已解除阻塞线程之后发生中断也是如此。实现应该用文档记录这个行为。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public interface Lock {

  /**
   * 获取锁。
   *
   * 如果锁不可用，则当前线程处于线程调度的目的，将被禁用并处于休眠状态，直到获得锁为止。
   *
   * 实现注意事项
   *
   * Lock 实现可能能够检测到锁的错误使用，例如会导致死锁的调用，并且在这种情况下可能会抛出
   * （未经检查）的异常。该 Lock 实现必须描述和记录情况以及异常类型。
   */
  void lock();

  /**
   * 除非当前线程被中断，否则获取锁。
   *
   * 如果可用，则获取锁并立即返回。
   *
   * 如果锁不可用，则当前线程处于线程调度的目的，将被禁用并处于休眠状态，直到发生以下两种情况之一：
   * - 锁被当前线程获取；
   * - 其他一些线程中断当前线程，当前线程支持获取锁的中断。
   *
   * 如果当前线程：
   * - 在进入此方法时设置其中断状态；
   * - 获取锁时中断，并支持获取锁中断。
   *
   * 然后会抛出 InterruptedException 并清除当前线程的中断状态。
   *
   *
   * 实现注意事项
   *
   * 在某些实现中中断锁获取的能力可能是无法实现的，并且如果可能的话会是一个非常昂贵的操作。
   * 程序员应该意识到可能是这种情况，并详细记录和描述这种情况。。
   *
   * 与正常方法返回相比，实现更倾向于响应中断。
   *
   * Lock 实现可能能够检测到锁的错误使用，例如会导致死锁的调用，并且在这种情况下可能会抛出
   * （未经检查的）异常。该 Lock 实现必须详细记录情况和异常类型。
   *
   * @throws InterruptedException - 如果当前线程在获取锁时被中断（并且支持获取锁的中断）
   */
  void lockInterruptibly() throws InterruptedException;

  /**
   * 仅当调用时是空闲的，才获取到锁。
   *
   * 如果锁可用，则获取锁并立即返回 true。如果锁不可用，则此方法立即返回 false。
   *
   * 该方法的典型用法是：
   *
   * Lock lock = ...;
   * if (lock.tryLock()) {
   *     try {
   *         // manipulate protected state
   *     } finally {
   *         lock.unlock();
   *     }
   * } else {
   *     // perform alternative actions
   * }
   *
   * 这种方法确保锁在获得的情况下才解锁，并且在未获得的时候不进行解锁操作。
   *
   * 返回： 如果获得了锁返回 true，否则为 false。
   */
  boolean tryLock();

  /**
   * 如果在给定的等待时间内锁空闲并且当前线程没有被中断，则获取锁。
   *
   * 如果锁可用，则获取锁并立即返回 true。如果锁不可用，则当前线程处于线程调度的目的，
   * 将被禁用并处于休眠状态，直到发生以下三种情况之一：
   * - 锁被当前线程获取；
   * - 其他一些线程中断当前线程，当前线程支持获取锁的中断；
   * - 指定的等待时间已过。
   *
   * 如果获得锁，则返回 true。
   *
   * 如果当前线程：
   * - 在进入此方法时设置其为中断状态；或
   * - 获取锁时中断，并支持获取锁中断。
   *
   * 然后会抛出 InterruptedException 并清除当前线程的中断状态。
   *
   * 如果经过了指定的等待时间，则返回 false。如果时间小于或等于 0，则该方法不会等待。
   *
   * 实现注意事项
   *
   * 在某些实现中中断锁获取的能力可能是无法实现的，并且如果可能的话会是一个非常昂贵的操作。
   * 程序员应该意识到可能是这种情况，并详细记录和描述这种情况。。
   *
   * 与正常方法返回相比，实现更倾向于响应中断。
   *
   * Lock 实现可能能够检测到锁的错误使用，例如会导致死锁的调用，并且在这种情况下可能会抛出
   * （未经检查的）异常。该 Lock 实现必须详细记录情况和异常类型。
   *
   * 参数： time - 等待锁的最长时间
   *       unit - time 参数的时间单位
   * 返回： 如果获得了锁，返回 true；如果在获得锁之前超过了等待时间，返回 false
   * @throws InterruptedException - 如果当前线程在获取锁时被中断（并且支持获取锁的中断）
   */
  boolean tryLock(long time, TimeUnit unit) throws InterruptedException;

  /**
   * 释放锁。
   *
   * 实现注意事项
   *
   * Lock 实现通常会对哪个线程可以释放锁施加限制（通常只有锁的持有者可以释放它），
   * 并且如果违反限制可能会抛出（未经检查的）异常。该 Lock 实现必须详细记录情况和异常类型。
   */
  void unlock();

  /**
   * 返回绑定到此 Lock 实例的新 Condition 实例。
   *
   * 在等待条件之前，锁必须由当前线程持有。调用 Condition.await() 将在等待之前自动释放
   * 锁，并在等待返回之前重新获取锁。
   *
   * 实现注意事项
   *
   * Condition 实例的确切操作取决于 Lock 实现，并且必须由该实现描述。
   *
   *
   * 返回：此 Lock 实例的新 Condition 实例
   * @throws UnsupportedOperationException - 如果 Lock 实现不支持 Condition
   */
  Condition newCondition();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;四-aqs-的独占与共享&#34;&gt;四、AQS 的独占与共享&lt;/h2&gt;
&lt;p&gt;在 &lt;code&gt;AQS&lt;/code&gt; 的设计中，为我们保留的扩展的能力，我们可以使用 &lt;code&gt;ConditionObject&lt;/code&gt; 和 &lt;code&gt;AQS&lt;/code&gt;&lt;br&gt;
去实现共享资源的独占和共享，就和 &lt;code&gt;ReadWriteLock&lt;/code&gt; 一样，下面我们根据 &lt;code&gt;AQS&lt;/code&gt; 的源码来解析这两种模式是如何实现的。&lt;/p&gt;
&lt;h3 id=&#34;41-独占模式&#34;&gt;4.1 独占模式&lt;/h3&gt;
&lt;p&gt;独占模式：意味着同一时刻，共享资源只有唯一的单个节点可以获取访问，此时获取到锁的节点的线程是独享的，获取到锁的线程也就从阻塞状态可以继续运行，而同步队列的其他节点则需要继续阻塞。&lt;/p&gt;
&lt;p&gt;独占模式的实现主要由 &lt;code&gt;AQS&lt;/code&gt; 在初始化时， &lt;code&gt;status&lt;/code&gt; 值来确定允许申请资源的数量上限，而对共享资源的获取和释放主要由以下方法进行操作：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;acquire(int)&lt;/code&gt; ：获取 int 数量的资源，也就是原子修改 &lt;code&gt;status&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;acquireInterruptibly(int)&lt;/code&gt;：获取 int 数量的资源，可以响应线程中断。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tryAcquireNanos(int, long)&lt;/code&gt; ：在指定 long 时间内，获取 int 数量的资源。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;release(int)&lt;/code&gt; ：释放 int 数量的资源。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;411-acquire&#34;&gt;4.1.1 acquire&lt;/h4&gt;
&lt;p&gt;下面我们根据源码，了解一下独占模式是如何运行的，首先是 &lt;code&gt;acquire&lt;/code&gt;：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * 以独占模式获取锁，忽略中断。  通过调用至少一次 tryAcquire() 方法来实现，成功就返回。
 * 否则线程排队，调用 tryAcquire() 成功之前，可能重复阻塞和解除阻塞。此方法可用于实现
 * Lock.lock()。
 *
 * 参数：arg - acquire 参数。这个值被传递给 tryAcquire，你可以用此代表你喜欢的任何东西。
 */
public final void acquire(int arg){
    // 只有当加锁成功或以独占类型节点入队（同步队列，非条件队列）成功时返回，
    if(!tryAcquire(arg) &amp;amp;&amp;amp;
       // 加锁失败，则进行入队操作
       acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
         // 加锁失败，入队失败，则中断线程
         selfInterrupt();
}

/**
 * 尝试以独占模式 acquire。此方法应查询对象的状态，判断是否允许以独占模式获取它。
 *
 * 此方法始终由执行 acquire 的线程调用。如果此方法报告失败，且该线程尚未入队，
 * 则 acquire 方法可以将该线程排队，知道某个其他线程 release 并 signal。这
 * 可用于实现 Lock.tryLock 方法。
 *
 * 默认实现抛出 UnsupportedOperationException 。
 *
 * 参数：arg - acquire 参数.。该值始终是传递给 acquire 方法的值，或者是在进入条件等待时
 保存的值。该值可以表示你喜欢的任何东西。
 * 返回：如果成功，返回 true。成功后，该对象已 acquire。
 * @throws IllegalMonitorStateException  如果获取会将此同步器置于非法状态。
 *                                       必须以一致的方式抛出此异常，同步才能正常工作。
 * @throws UnsupportedOperationException 如果不支持独占模式
 */
protected boolean tryAcquire(int arg){
    throw new UnsupportedOperationException();
}


/**
 * 为当前线程和给定模式创建节点并入队节点。
 *
 * 参数：mode - Node.EXCLUSIVE 用于独占，Node.SHARED 用于共享
 * 返回：新节点
 */
private Node addWaiter(Node mode){
    // 创建当前线程和模式的新节点，此时 waitStatus 为 0
    Node node = new Node(Thread.currentThread(), mode);
    // 先尝试直接入队，当且仅当 tail 不为空时，直接将当前节点追加到 tail 后面
    Node pred = tail;
    if(pred != null){
        // 当前节点的前驱节点为 pred
        node.prev = pred;
        // 原子修改 tail 为当前节点
        if(compareAndSetTail(pred, node)){
            // pred 的后继节点指向当前节点
            pred.next = node;
            return node;
        }
    }
    // tail 为空，或入队失败，则进行自旋 enq 入队
    enq(node);
    return node;
}

/**
 * 将节点插入队列，必要时进行初始化。
 * 参数： node - 插入的节点
 * 返回： 节点的前驱节点
 */
private Node enq(final Node node){
    // 自旋进行插入操作
    for(;;){
        // 获取队列的 tail
        Node t = tail;
        // t 为空，说明队尾没有节点，说明还没有初始化
        if(t == null){ // Must initialize
            // 初始化操作，创建 head 节点
            if(compareAndSetHead(new Node()))
                // 将 tail 也指向 head
            tail = head;
        } else {
            // 将队尾指向当前节点的前驱节点
            node.prev = t;
            // 设置当前节点为队尾
            if(compareAndSetTail(t, node)){
                // 设置 t 的后继节点为当前节点
                t.next = node;
                return t;
            }
        }
    }
}


/**
 * 以独占模式且不中断，acquire 队列中的线程。由 condition 的 wait 和 acquire 方法使用。
 *
 * 参数：node - 节点
 *      arg - acquire 参数
 * 返回：如果在等待时被中断，返回 true
 */
final boolean acquireQueued(final Node node,int arg){
    // acquire 是否失败
    boolean failed = true;
    try {
        // 是否中断
        boolean interrupted = false;
        // 自旋尝试获取资源，每次自旋都会调用 tryAcquire 尝试获取资源，获取资源失败，则进入阻塞状态
        // 成功则跳出自旋
        for(;;){
            // 当前新入队节点的前驱节点
            final Node p = node.predecessor();
            // 前驱节点为头节点时，尝试获取资源。
            if(p == head &amp;amp;&amp;amp; tryAcquire(arg)){
                // 获取资源成功，将当前节点设置为头结点
                setHead(node);
                // 断开前一个节点的链接，帮助 GC
                p.next = null; // help GC
                // 获取成功
                failed = false;
                // 返回是否中断
                return interrupted;
            }
            // 判断在 acquire 失败后是否需要阻塞当前节点中的线程
            if(shouldParkAfterFailedAcquire(p,node)&amp;amp;&amp;amp;
                parkAndCheckInterrupt())
                interrupted =true;
            }
    } finally {
        if(failed)
            cancelAcquire(node);
    }
}

/**
 * 检查并更新 acquire 失败的节点的状态。如果线程应该阻塞，则返回 true。
 * 这是所有循环 acquire 获取资源的主要 signal 控制方法。要求 pred == node.prev。
 *
 * 参数：pred - 节点的前驱节点持有的状态
 *      node - 当前节点
 * 返回：如果线程应该阻塞，返回 true。
 */
private static boolean shouldParkAfterFailedAcquire(Node pred,Node node){
    // 前驱节点的等待状态
    int ws=pred.waitStatus;
    // 前驱结点状态为 SIGNAL，说明当前节点可以阻塞，pred 在完成后需要调用 release
    if(ws == Node.SIGNAL)
        /*
         * 前驱节点状态设置为 Node.SIGNAL，等待被 release 调用释放，后继节点可以安全地进入阻塞。
         */
        return true;
    if(ws &amp;gt; 0) {
        /*
         * 前驱节点为 CANCELLED，尝试把所有 CANCELLED 的前驱节点移除，找到一个
         * 非取消的前驱节点。
         */
        do {
            node.prev = pred = pred.prev;
        } while (pred.waitStatus &amp;gt; 0);
        pred.next=node;
    } else {
        /*
         * waitStatus 为 0 或 PROPAGATE.  表示我们需要一个 signal，
         * 而不是阻塞。调用者需要重试以确保在阻塞前无法 acquire。
         */
        compareAndSetWaitStatus(pred,ws,Node.SIGNAL);
    }
    return false;
}

/**
 * park 后检查是否中断的便捷方法
 *
 * 返回：如果中断，返回true
 */
private final boolean parkAndCheckInterrupt(){
    // park 当前线程
    LockSupport.park(this);
    // 判断是否中断
    return Thread.interrupted();
}


/**
 * 将队列 head 设置为 node，从而使之前的节点出队。仅由 acquire 方法调用。
 * 为了 GC 和抑制不必要的 signal 和遍历，同时也清空无用的字段。
 *
 * 参数：node - 节点
 */
private void setHead(Node node){
    head=node;
    node.thread=null;
    node.prev=null;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;依旧使用上面的例子，当 &lt;code&gt;thread-1&lt;/code&gt; 入队时，此时队列为空，需要初始化一个空节点，之后将调用 &lt;code&gt;addWaiter()&lt;/code&gt; 将  &lt;code&gt;thread-1&lt;/code&gt; 入队：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;/Users/wenbo.zhang/Desktop/images/AQS-thread-1-enq.png&#34; alt=&#34;aqs-thread-1-enq&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;此时，在 &lt;code&gt;thread-1&lt;/code&gt; 等待过程中，将 &lt;code&gt;thread-2&lt;/code&gt; 进行入队操作：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;/Users/wenbo.zhang/Desktop/images/AQS-thread-2-enq.png&#34; alt=&#34;aqs-thread-2-enq&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;以上就是 &lt;code&gt;tryAcquire&lt;/code&gt; 失败后的入队逻辑，可以看到，在节点进行入队时，会修改前驱节点的 waitStatus，当前驱节点 &lt;code&gt;release&lt;/code&gt;&lt;br&gt;
时，会进行哪些操作呢？下面我们对 &lt;code&gt;release&lt;/code&gt; 操作进行解析。&lt;/p&gt;
&lt;h4 id=&#34;412-release&#34;&gt;4.1.2 release&lt;/h4&gt;
&lt;p&gt;在独占模式中，&lt;code&gt;release()&lt;/code&gt; 用来释放资源，下面我们根据源码来解读 &lt;code&gt;AQS&lt;/code&gt; 如何进行释放操作。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * 释放独占模式。如果 tryRelease 返回 true，则通过解锁一个或多个线程实现。此方法可以
 * 用来实现方法 Lock.unlock.
 *
 * 参数：arg - release 参数。这个值被传递给 tryRelease，你可以用它表示任何你喜欢的东西。
 * 返回：tryRelease 返回的值
 */
public final boolean release(int arg){
    // 尝试释放资源
    if(tryRelease(arg)){
        Node h=head;
        // head 不为空，且 waitStatus 不为 0 的情况下，唤醒后继节点
        if(h!=null&amp;amp;&amp;amp;h.waitStatus!=0)
        // 后继节点解除阻塞
        unparkSuccessor(h);
        return true;
    }
    return false;
}

/**
 * 尝试设置状态，以体现独占模式下的 release。
 *
 * 该方法总是由执行 release 的线程调用。
 *
 * 默认实现抛出 UnsupportedOperationException。
 *
 * 参数：arg - release 参数。此值始终是传递给 release 方法的值，或者是进入条件等待时的
 *            当前状态值。该值是未解释的，可以表示任何你想要的内容。
 * 返回：如果当前对象现在完全释放，则返回 true，以便任何等待的线程都可以尝试 acquire；否则 false。
 * @throws IllegalMonitorStateException - 如果 release 会将此同步器置于非法状态。
 *                                        必须以一致的方式抛出此异常，同步器才能正常工作。
 * @throws UnsupportedOperationException - 如果不支持独占模式
 */
protected boolean tryRelease(int arg){
    throw new UnsupportedOperationException();
}

/**
 * 如果节点存在后继节点，则唤醒后继节点。
 *
 * 参数：node - 节点
 */
private void unparkSuccessor(Node node){
    /*
     * 如果状态为负数（即可能需要 signal），尝试 clear 以等待 signal。
     * 允许失败或等待线程更改状态。
     */
    int ws = node.waitStatus;
    if(ws &amp;lt; 0)
        // 将当前节点的 waitStatus 置为 0
        compareAndSetWaitStatus(node, ws, 0);

    /*
     * 当前线程的后继节点 unpark ，通常只是下一个节点。但如果下个节点为空或
     * 已经取消，则从 tail 向后遍历以找到实际未取消的后继节点。
     */
    Node s=node.next;
    // 后继节点为空，或后继节点是 CANCELLED
    if(s == null || s.waitStatus &amp;gt; 0){
        s = null;
    // 从 tail 开始，向 head 遍历，找到最接近 当前节点的不为空且未取消的节点
    for(Node t = tail;t != null &amp;amp;&amp;amp; t != node; t = t.prev)
        if(t.waitStatus &amp;lt;= 0)
            s = t;
    }
    // 找到之后，unpark 节点线程阻塞状态
    if(s != null)
        LockSupport.unpark(s.thread);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;当 &lt;code&gt;release&lt;/code&gt; 操作成功 &lt;code&gt;unpark&lt;/code&gt; 一个线程后，该线程在通过 &lt;code&gt;acquireQueued&lt;/code&gt; 进行 &lt;code&gt;tryAcquire&lt;/code&gt;&lt;br&gt;
成功后，就会将头结点设置为当前节点，并将之前的头结点以及线程字段置空，以方便 GC 回收，&lt;code&gt;thread-1&lt;/code&gt; 获取到锁在执行过程中，状态如下：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;/Users/wenbo.zhang/Desktop/images/AQS-thread-1-release.png&#34; alt=&#34;aqs-thread-1-release&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;thread-1&lt;/code&gt; 执行完成后，对 &lt;code&gt;thread-2&lt;/code&gt; 进行 unpark 后，状态如下：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;/Users/wenbo.zhang/Desktop/images/AQS-thread-2-release.png&#34; alt=&#34;aqs-thread-2-release&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;413-acquireinterruptibly&#34;&gt;4.1.3 acquireInterruptibly&lt;/h4&gt;
&lt;p&gt;下面我们对 &lt;code&gt;acquire&lt;/code&gt; 的变体，即带有响应中断版本的 &lt;code&gt;acquireInterruptibly&lt;/code&gt; 方法进行解析：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * 以独占模式 acquire，如果线程中断则终止操作。通过首先检查中断状态，然后
 * 至少调用一次 tryAcquire，成功则直接返回。否则线程排队，可能会在 tryAcquire
 * 成功或线程被中断之前，多次重复阻塞和解除阻塞。该方法可用于实现 
 * Lock.lockInterruptibly 方法。
 *
 * 参数：arg - acquire 参数。这个值被传递给 tryAcquire，但并没有进行解释，
 *            你可以将其表示为任何你想要的值。  
 * @throws InterruptedException - 如果当前线程被中断
 */
public final void acquireInterruptibly(int arg)
        throws InterruptedException{
     // 判断当前线程是否中断，并清空线程中断标记位，中断直接抛出异常
    if(Thread.interrupted())
        throw new InterruptedException();
    // 尝试加锁，加锁失败则进行自旋阻塞 acquire
    if(!tryAcquire(arg))
        doAcquireInterruptibly(arg);
}

/**
 * 以独占且可中断模式 acquire。
 * 参数：arg - acquire 参数
 */
private void doAcquireInterruptibly(long arg)
        throws InterruptedException {
    // 新增当前线程节点并入队
    final Node node = addWaiter(Node.EXCLUSIVE);
    boolean failed = true;
    try {
        for (;;) {
            // 前驱节点
            final Node p = node.predecessor();
            // 前驱节点为头节点，且 acquire 成功，则将当前节点置为头节点
            if (p == head &amp;amp;&amp;amp; tryAcquire(arg)) {
                setHead(node);
                p.next = null; // help GC
                failed = false;
                return;
            }
            // 获取资源失败则进入阻塞状态
            if (shouldParkAfterFailedAcquire(p, node) &amp;amp;&amp;amp;
                    // park 当前线程，并判断是否中断
                    parkAndCheckInterrupt())
                throw new InterruptedException();
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到，&lt;code&gt;acquireInterruptibly&lt;/code&gt; 方法与 &lt;code&gt;acquire&lt;/code&gt; 方法基本一致，区别在于在线程中断时是否抛出 &lt;code&gt;InterruptedException&lt;/code&gt;。&lt;/p&gt;
&lt;h4 id=&#34;414-tryacquirenanos&#34;&gt;4.1.4  tryAcquireNanos&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * 尝试以独占模式进行 acquire, 如果线程中断则终止操作, 如果超过给定的超时时间
 * 则返回 false。通过首先检查线程中断状态，然后至少调用一次 tryAcquire 方法，
 * 成功则返回 true。否则，线程排队，在调用 tryAcquire 直到成功、或线程被中断、
 * 或到达超时时间，可能重复多次阻塞和解除阻塞。此方法可用于实现 Lock.tryLock(long, TimeUnit)。
 *
 * 参数：arg - release 参数。此值始终是传递给 release 方法的值，或者是进入条件等待时的
 *            当前状态值。该值是未解释的，可以表示任何你想要的内容。
 *      nanosTimeout - 等待的最大纳秒数
 * 返回：如果成功 acquire，则返回 true；如果超时则返回 false
 * @throws InterruptedException 如果线程被中断
 */
public final boolean tryAcquireNanos(long arg, long nanosTimeout)
        throws InterruptedException {
    // 如果当前线程中断，清除中断状态，并抛出异常
    if (Thread.interrupted())
        throw new InterruptedException();
    // 首次先尝试获取资源，失败后以指定超时时间阻塞获取
    return tryAcquire(arg) ||
            doAcquireNanos(arg, nanosTimeout);
}

/**
 * 以独占且支持超时模式进行 acquire。
 *
 * 参数：arg - acquire 参数
 *      nanosTimeout - 最大等待时间
 * 返回：如果 acquire 成功，返回 true
 */
private boolean doAcquireNanos(long arg, long nanosTimeout)
        throws InterruptedException {
    // 如果超时时间小于等于 0，则直接加锁失败返回
    if (nanosTimeout &amp;lt;= 0L)
        return false;
    // 最终超时时间线 = 当前系统时间的纳秒数 + 指定的超时纳秒数
    final long deadline = System.nanoTime() + nanosTimeout;
    // 以独占模式添加新节点并入队
    final Node node = addWaiter(Node.EXCLUSIVE);
    boolean failed = true;
    try {
        // 自旋进行 acquire 操作
        for (;;) {
            // 当前节点的前驱节点
            final Node p = node.predecessor();
            // 前驱节点为 head，尝试 acquire 操作，成功后，将当前节点设为 head，并清空节点无用字段
            if (p == head &amp;amp;&amp;amp; tryAcquire(arg)) {
                setHead(node);
                p.next = null; // help GC
                failed = false;
                return true;
            }
            // 获取本次循环的超时时间
            nanosTimeout = deadline - System.nanoTime();
            // 本次自旋超时到达，直接返回
            if (nanosTimeout &amp;lt;= 0L)
                return false;
            // 当前节点在 acquire 失败后如果需要阻塞，且
            if (shouldParkAfterFailedAcquire(p, node) &amp;amp;&amp;amp;
                    // 当前超时时间大于 1000 纳秒，小于等于 1000 纳秒将会进入下一轮自旋获取锁
                    nanosTimeout &amp;gt; spinForTimeoutThreshold)
                // 指定超时时间并 park
                LockSupport.parkNanos(this, nanosTimeout);
            // 如果线程中断，则抛出异常
            if (Thread.interrupted())
                throw new InterruptedException();
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;tryAcquireNanos&lt;/code&gt; 方法与 &lt;code&gt;doAcquireInterruptibly&lt;/code&gt; 方法在对超时中断处理上是保持一致的，都会在线程中断后抛出 &lt;code&gt;InterruptedException&lt;/code&gt;。&lt;code&gt;tryAcquireNanos&lt;/code&gt; 在每轮的自旋加锁失败后，都会重新计算超时时间，当超时时间小于 &lt;code&gt;spinForTimeoutThreshold&lt;/code&gt; 后，则会进入自旋进行 &lt;code&gt;acquire&lt;/code&gt; 操作。&lt;/p&gt;
&lt;h4 id=&#34;415-独占模式的实现&#34;&gt;4.1.5 独占模式的实现&lt;/h4&gt;
&lt;p&gt;基于上述对独占模式的源码的解析，在 &lt;code&gt;j.u.c&lt;/code&gt;  包中提供的独占模式的同步器有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ReentrantLock&lt;/code&gt;可重入锁；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ReentrantReadWriteLock&lt;/code&gt; 中的 &lt;code&gt;WriteLock&lt;/code&gt;；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ThreadPoolExecutor&lt;/code&gt; 中的 &lt;code&gt;Worker&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;42-共享模式&#34;&gt;4.2 共享模式&lt;/h3&gt;
&lt;p&gt;共享模式：即同一时刻，共享资源可以被多个线程获取，&lt;code&gt;status&lt;/code&gt; 的状态大于或等于 0。共享模式在 &lt;code&gt;AQS&lt;/code&gt; 中的体现为，如果有一个节点持有的线程 &lt;code&gt;acquire&lt;/code&gt; 操作 &lt;code&gt;status&lt;/code&gt; 成功，那么它会被解除阻塞，并且会把解除阻塞状态 &lt;code&gt;PROPAGATE&lt;/code&gt; 给所有有效的后继节点。&lt;/p&gt;
&lt;p&gt;共享模式的功能主要由以下四个方法提供，与独占模式相比，在方法命名上由 &lt;code&gt;Shared&lt;/code&gt; 区分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;acquireShared(int)&lt;/code&gt; ：获取 int 数量的资源，也就是原子修改 &lt;code&gt;status&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;acquireSharedInterruptibly(int)&lt;/code&gt;：获取 int 数量的资源，可以响应线程中断。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tryAcquireSharedNanos(int, long)&lt;/code&gt; ：在指定 long 时间内，获取 int 数量的资源。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;releaseShared(int)&lt;/code&gt; ：释放 int 数量的资源。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;421-acquireshared&#34;&gt;4.2.1 acquireShared&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * 以共享模式 acquire，并忽略线程中断。通过首先最少调用一次 tryAcquireShared 实现，
 * 成功则直接返回。否则线程排队，在调用 tryAcquireShared 成功之前，可能会多次重复
 * 阻塞和解除阻塞。
 *
 * 参数：arg - acquire 参数。该值被传递给 tryAcquireShared，但并没有进行解释，
 *            你可以将其表示为任何你想要的值。  
 */
public final void acquireShared(long arg) {
    // 获取失败，返回负值；此时需要加入同步等待队列
    if (tryAcquireShared(arg) &amp;lt; 0)
        doAcquireShared(arg);
}

/**
 * 尝试以共享模式 acquire。此方法应查询对象的状态是否允许以共享模式获取它，
 * 如果允许，则可以获取。
 *
 * 此方法始终由执行 acquire 的线程调用。如果此方法返回失败，且该线程尚未排队，
 * 则 acquire 方法可以将该线程入队，直到某个其他线程释放发出 signal。
 *
 * 默认实现抛出 UnsupportedOperationException。
 *
 * 参数：arg - acquire 参数。该值始终是传递给 acquire 方法的值，或者是在进入条件等待
 *            时保存的值。该值并没有进行解释，你可以将其表示为任何你想要的值。  
 * 返回：失败返回负值；如果以共享模式获取成功但后续的共享模式 acquire 不能成功，则为 0；
 *      如果在共享模式下获取成功并且后续共享模式也可能成功，则为正值，在这种情况下，后续等待
 *      线程必须检查可用性。（对于三种不同返回值的支持使此方法可以仅在 acquire 可用时的独占上下文中使用。）
 *      成功后，此对象已被获取。
 * @throws IllegalMonitorStateException - 如果 acquire 会将此同步器置于非法状态。
 *                                        必须以一致的方式抛出此异常，同步器才能正常工作。
 * @throws UnsupportedOperationException - 如果不支持共享模式
 */
protected long tryAcquireShared(long arg) {
    throw new UnsupportedOperationException();
}

/**
 * 以共享且不中断模式进行 acquire。
 * 参数：arg - acquire 的参数
 */
private void doAcquireShared(long arg) {
    // 为当前线程创建一个新的共享节点并入队
    final Node node = addWaiter(Node.SHARED);
    boolean failed = true;
    try {
        boolean interrupted = false;
        for (;;) {
            // 该节点的前驱节点
            final Node p = node.predecessor();
            // 如果前驱节点为 head
            if (p == head) {
                // 调用 tryAcquireShared 获取资源，只有在大于等于 0 时，才获取到资源，此时唤醒其他节点 
                long r = tryAcquireShared(arg);
                if (r &amp;gt;= 0) {
                    // 设置头结点，并设置 `PROPAGATE 状态，确保唤醒传播到可用的后继节点
                    // 当任意等待节点晋升为 head，也会进行此操作，以此来进行链式唤醒
                    setHeadAndPropagate(node, r);
                    p.next = null; // help GC
                    if (interrupted)
                        selfInterrupt();
                    failed = false;
                    return;
                }
            }
            // acquire 失败判断是否需要 park，并校验线程中断
            if (shouldParkAfterFailedAcquire(p, node) &amp;amp;&amp;amp;
                    parkAndCheckInterrupt())
                interrupted = true;
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}

/**
 * 设置队列的 head，并检查后继节点是否可能在共享模式下等待，如果是这样，且设置了
 * propagate &amp;gt; 0，则进行传播。
 *
 * 参数：node - 节点
 *      propagate - tryAcquireShared 的返回值
 *
 * 如果是共享模式下，在设置头结点后，会判断 propagate &amp;gt; 0 || head.waiteStatus &amp;lt; 0 情况下，
 * 进行共享模式下的资源释放操作。
 */
private void setHeadAndPropagate(Node node, long propagate) {
    Node h = head; // 记录旧 head 以供检查
    // 设置当前处理节点为 head
    setHead(node);
    /*
     * 如果出现以下情况，请尝试 signal 下一个排队节点：
     *  - 调用着指定了传播；
     *  - or 有先前的操作记录（在 setHead 之前或之后作为 h.waitStatus）（注意：这是用了 waitStatus 的符号检查，因为 PROPAGATE 状态可能会转换为 SIGNAL）。
     * and
     *  - 下一个节点在共享模式中等待，或者我们并不清楚，因为它显示为 null
     * 
     *
     * 这两种检查的保守性可能会导致不必要的唤醒，但只有在多个竞争的 acquires 和 releases 时才会这样，
     * 所以大多数节点无论如何都需要现在或很快得到 signal。
     */
    // 入参 propagate &amp;gt; 0 || head 为 null || head 的状态为非 CANCELLED 和 0 || 再次校验 head 为空 || 再次校验 head 状态不为 CANCELLED 和 0
    if (propagate &amp;gt; 0 || h == null || h.waitStatus &amp;lt; 0 ||
            (h = head) == null || h.waitStatus &amp;lt; 0) {
        Node s = node.next;
        // 当前节点（已经是头节点）的后继节点为 null，且为共享模式
        if (s == null || s.isShared())
            doReleaseShared();
    }
}

/**
 * 共享模式的 release 操作 -- signal 后继节点并保证 propagation。
 * （在独占模式下，如果需要 signal，release 就相当于调用 head 的 unparkSuccessor）。
 */
private void doReleaseShared() {
    /*
     * 确保 release 可以传播，即使还有其他正在进行的 acquire/release。
     * 如果需要 signal，这会以常用的方式尝试对 head 进行 unparkSuccessor。
     * 但如果没没有，则将状态设置为 &amp;quot;PROPAGATE&amp;quot; 确保在 release 时继续传播。
     * 此外，我们必须在循环中进行，以防止在我们执行此操作时，链表中添加新节点。
     * 此外，与 unparkSuccessor 的其他用法不同，我们需要知道 CAS 重置状态
     * 是否失败，如果是则重新检查。
     */
    for (;;) {
        Node h = head;
        // 头节点不为空，且头节点同时不是尾结点
        if (h != null &amp;amp;&amp;amp; h != tail) {
            // 头节点的 waitStatus
            int ws = h.waitStatus;
            // 如果为 SIGNAL，则 CAS 将其更新为 0，更新成功后唤醒其后继节点的阻塞
            if (ws == Node.SIGNAL) {
                // 更新失败，是因为会有并发情况，唤醒的线程也会调用 doReleaseShared
                // 如果更新失败，则跳过进行重新检查
                if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))
                    continue;            // loop to recheck cases
                unparkSuccessor(h);
            }
            // 头节点 waitStatus 已经为 0，则 CAS 将其更新为 -3
            // 此时可以分析 waitStatus 值为 0 的情况如下：
            // 1. 如果 head 节点没有及时被更新，另一个线程被唤醒后获得锁，此时另一个线程已经执行了
            // setHead，将头节点更新为了自己，（因为如果在下面的 h == head 判断中，头节点没有变化，
            // 会直接跳出循环）；此时，通过 unparkSuccessor 将 waitStatus 更新为 0。
            else if (ws == 0 &amp;amp;&amp;amp;
                    !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))
                continue;                // loop on failed CAS
        }
        // 1. head 没有变更，说明被唤醒的线程还没有执行完 setHead 操作，跳出循环。
        // 等新的节点执行 setHeadAndPropagate 操作后，也会调用 doReleaseShared
        // 2. 如果 head  变更了，那就可能会有多个线程（在当前循环被唤醒）都来执行
        // doReleaseShared，此时这个方法的 compareAndSetWaitStatus 就可能
        // 修改失败（当然，也可能会因为其他线程的 acquire/release 的竞争），那此时会
        // 自旋做重新检查。
        if (h == head)                   // loop if head changed
            break;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们对 &lt;code&gt;doReleaseShared&lt;/code&gt; 进行一个说明：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;首先，该方法是一个死循环，每次循环中都会重新获取 &lt;code&gt;head&lt;/code&gt;，只有当 &lt;code&gt;h == head&lt;/code&gt; 时，才会&lt;strong&gt;跳出&lt;/strong&gt;循环。而 &lt;code&gt;head&lt;/code&gt; 发生变化一定是由于队列中的节点在 &lt;code&gt;acquire&lt;/code&gt; 阻塞过程中被唤醒，之后成功获得锁资源，然后在调用 &lt;code&gt;setHeadAndPropagate&lt;/code&gt; 方法中的 &lt;code&gt;setHead&lt;/code&gt; 方法修改 &lt;code&gt;head&lt;/code&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;判断 &lt;code&gt;h != null &amp;amp;&amp;amp; h != tail&lt;/code&gt; 说明队列中至少要存在两个节点，如果队列并没有因为竞争而初始化为 &lt;code&gt;head&lt;/code&gt; 设置过值（&lt;code&gt;head&lt;/code&gt; 为 &lt;code&gt;null&lt;/code&gt;），或队列仅有一个节点（&lt;code&gt;head&lt;/code&gt; 和 &lt;code&gt;tail&lt;/code&gt; 指向同一个节点），那么将不进行操作，直接到最后去判断 &lt;code&gt;head&lt;/code&gt; 是否发生了变化。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果步骤 2 中的条件满足，说明队列有两个及以上节点，那么此时会根据 &lt;code&gt;h&lt;/code&gt; 的 &lt;code&gt;waitStatus&lt;/code&gt; 字段判断：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;如果状态为 &lt;code&gt;signal&lt;/code&gt;，说明 &lt;code&gt;h&lt;/code&gt; 节点的后继节点需要被通知，此时进行 CAS 操作 &lt;code&gt;compareAndSetWaitStatus(h, Node.SIGNAL, 0)&lt;/code&gt;:
&lt;ol&gt;
&lt;li&gt;如果 CAS 操作成功，即将 &lt;code&gt;h&lt;/code&gt; 的状态由 &lt;code&gt;SIGNAL&lt;/code&gt; 改为 &lt;code&gt;0&lt;/code&gt;，此时通过 &lt;code&gt;unparkSuccessor&lt;/code&gt; 方法唤醒后继节点。&lt;/li&gt;
&lt;li&gt;如果 CAS 操作失败，说明当前线程在修改时存在竞争（可能其他线程也在进行 &lt;code&gt;release/acquire&lt;/code&gt; 操作，或者同样在进行 &lt;code&gt;doReleaseShared&lt;/code&gt;），此时我们进行重新检查。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;如果状态为 &lt;code&gt;0&lt;/code&gt; ，说明 &lt;code&gt;h&lt;/code&gt; 节点的后继节点已经被唤醒或在唤醒的过程中了，因为当前为共享模式的释放，所以我们使用 CAS 操作将状态更新为 &lt;code&gt;PROPAGATE&lt;/code&gt;传播唤醒其他节点。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;下面我们分析一下 &lt;code&gt;h&lt;/code&gt; 的 &lt;code&gt;waitStatus&lt;/code&gt; 为 &lt;code&gt;0&lt;/code&gt; 的情况：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果队列中只有一个节点，那么它的状态肯定为 0，此时 &lt;code&gt;head&lt;/code&gt; 和 &lt;code&gt;tail&lt;/code&gt; 都指向这个节点。&lt;/li&gt;
&lt;li&gt;如果队列中有一个节点（它的状态为 0），此时另外一个线程由于 &lt;code&gt;acquire&lt;/code&gt; 失败，那么失败线程会调用 &lt;code&gt;addWaiter&lt;/code&gt; 方法将自己入队，此时队列中有两个节点，此时还没有来得及执行 &lt;code&gt;shouldParkAfterFailedAcquire&lt;/code&gt; 中的 &lt;code&gt;compareAndSetWaitStatus(pred, ws, Node.SIGNAL);&lt;/code&gt; 将第一个节点的状态改为 &lt;code&gt;signal&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;队列中有多个节点，此时，刚好有线程释放了锁，调用了 &lt;code&gt;releaseShared() -&amp;gt; doReleaseShared() -&amp;gt; unparkSuccessor() &lt;/code&gt;  方法的 &lt;code&gt;compareAndSetWaitStatus(node, ws, 0)&lt;/code&gt; 一行，将节点状态设置为了 0，之后唤醒 &lt;code&gt;head&lt;/code&gt; 节点的后继节点，&lt;code&gt;head&lt;/code&gt; 的后继节点将自己设置为队列的 &lt;code&gt;head&lt;/code&gt; 的过程中（还没有设置为 &lt;code&gt;head&lt;/code&gt;），当前 &lt;code&gt;head&lt;/code&gt; 节点的状态为 0。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;综上，如果在释放共享锁的过程中，会执行 &lt;code&gt;doReleaseShared&lt;/code&gt; 方法，而此时会对 &lt;code&gt;PROPAGATE&lt;/code&gt; 状态进行传播，唤醒其后继节点，而后继节点唤醒后，也会执行相同的步骤，如果在 &lt;code&gt;if(h == head)&lt;/code&gt; 判断前后继节点调用 &lt;code&gt;setHeadAndPropagte&lt;/code&gt; 方法将 &lt;code&gt;head&lt;/code&gt; 修改为自己，那就会可能有多个线程同时并发执行 &lt;code&gt;doReleaseShared&lt;/code&gt; 方法，以此达到传播的目的，当 &lt;code&gt;head&lt;/code&gt; 不发生变化时，唤醒的后继节点也会对后续的各个节点进行唤醒，直到全部唤醒完成或无共享资源可用（此时 &lt;code&gt;head&lt;/code&gt; 节点不再发生变化）。&lt;/p&gt;
&lt;p&gt;与独占模式的 &lt;code&gt;acquire&lt;/code&gt; 方法相比，共享模式在当前节点获取资源成功后，除了会将自身设置为 &lt;code&gt;head&lt;/code&gt; 之外，还会通过 CAS 将自身的 &lt;code&gt;waitStatus&lt;/code&gt; 设置为 &lt;code&gt;PROPAGATE&lt;/code&gt;，从而传播去唤醒其他等待节点。&lt;/p&gt;
&lt;h4 id=&#34;422-releaseshared&#34;&gt;4.2.2 releaseShared&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * 以共享模式进行 release 操作。如果 tryReleaseShared 返回 true，则通过解锁一个或
 * 多个线程来实现。
 *
 * 参数：arg - release 参数。该值被传递给 tryReleaseShared，但并没有进行解释，
 *            你可以将其表示为任何你想要的值。 
 * 返回：tryReleaseShared 的返回值
 */
public final boolean releaseShared(int arg) {
    // 尝试释放资源
    if (tryReleaseShared(arg)) {
        // 进行 doReleaseShared 以传播方式唤醒其他节点
        doReleaseShared();
        return true;
    }
    return false;
}

/**
 * 尝试设置状态，以体现共享模式下的 release。
 *
 * 该方法总是由执行 release 的线程调用。
 *
 * 默认实现抛出 UnsupportedOperationException。
 *
 * 参数：arg - release 参数。此值始终是传递给 release 方法的值，或者是进入条件等待时的
 *            当前状态值。该值是未解释的，可以表示任何你想要的内容。
 * 返回：如果此共享模式的 release 可能允许等待 acquire 的其他线程成功（共享或独占）；否则 false。
 * @throws IllegalMonitorStateException - 如果 release 会将此同步器置于非法状态。
 *                                        必须以一致的方式抛出此异常，同步器才能正常工作。
 * @throws UnsupportedOperationException - 如果不支持独占模式
 */
protected boolean tryReleaseShared(int arg) {
    throw new UnsupportedOperationException();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到，&lt;code&gt;releaseShared&lt;/code&gt; 其实就是在 &lt;code&gt;tryReleaseShared&lt;/code&gt; 返回 &lt;code&gt;true&lt;/code&gt; 后，去调用 &lt;code&gt;doReleaseShared&lt;/code&gt; 传播唤醒状态。&lt;/p&gt;
&lt;h4 id=&#34;423-acquiresharedinterruptibly&#34;&gt;4.2.3 acquireSharedInterruptibly&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * 以共享模式 acquire，如果线程中断则终止操作。通过首先检查中断状态，然后
 * 至少调用一次 tryAcquireShared，成功则直接返回。否则线程排队，可能会在 
 * tryAcquireShared 成功或线程被中断之前，多次重复阻塞和解除阻塞。
 *
 * 参数：arg - acquire 参数。这个值被传递给 tryAcquire，但并没有进行解释，
 *            你可以将其表示为任何你想要的值。  
 * @throws InterruptedException - 如果当前线程被中断
 */
public final void acquireSharedInterruptibly(int arg)
        throws InterruptedException {
    // 判断线程中断并清除中断标志，如果中断，直接抛出异常终止
    if (Thread.interrupted())
        throw new InterruptedException();
    // 尝试加锁，小于 0 说明加锁失败，需要入队操作
    if (tryAcquireShared(arg) &amp;lt; 0)
        doAcquireSharedInterruptibly(arg);
}

/**
 * 以共享且可中断模式 acquire。
 * 参数：arg - acquire 参数
 */
private void doAcquireSharedInterruptibly(int arg)
        throws InterruptedException {
    // 创建共享模式节点并入队
    final Node node = addWaiter(Node.SHARED);
    boolean failed = true;
    try {
        for (;;) {
            // 当前节点的前驱节点
            final Node p = node.predecessor();
            if (p == head) {
                // 加锁操作
                int r = tryAcquireShared(arg);
                if (r &amp;gt;= 0) {
                    // 设置头结点并传播状态
                    setHeadAndPropagate(node, r);
                    p.next = null; // help GC
                    failed = false;
                    return;
                }
            }
            // 加锁失败后进行阻塞操作，如果线程中断，则抛出异常
            if (shouldParkAfterFailedAcquire(p, node) &amp;amp;&amp;amp;
                    parkAndCheckInterrupt())
                throw new InterruptedException();
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;424-tryacquiresharednanos&#34;&gt;4.2.4 tryAcquireSharedNanos&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * 尝试以共享模式进行 acquire, 如果线程中断则终止操作, 如果超过给定的超时时间
 * 则返回 false。通过首先检查线程中断状态，然后至少调用一次 tryAcquireShared 方法，
 * 成功则返回 true。否则，线程排队，在调用 tryAcquireShared 直到成功、或线程被中断、
 * 或到达超时时间，可能重复多次阻塞和解除阻塞。
 *
 * 参数：arg - release 参数。此值始终是传递给 release 方法的值，或者是进入条件等待时的
 *            当前状态值。该值是未解释的，可以表示任何你想要的内容。
 *      nanosTimeout - 等待的最大纳秒数
 * 返回：如果成功 acquire，则返回 true；如果超时则返回 false
 * @throws InterruptedException 如果线程被中断
 */
public final boolean tryAcquireSharedNanos(int arg, long nanosTimeout)
        throws InterruptedException {
    if (Thread.interrupted())
        throw new InterruptedException();
    // 首次尝试，如果 tryAcquireShared &amp;gt;= 0 说明加锁成功，可以直接返回
    return tryAcquireShared(arg) &amp;gt;= 0 ||
            // 需要入队操作
            doAcquireSharedNanos(arg, nanosTimeout);
}

/**
 * 以共享且支持超时模式进行 acquire。
 *
 * 参数：arg - acquire 参数
 *      nanosTimeout - 最大等待时间
 * 返回：如果 acquire 成功，返回 true
 */
private boolean doAcquireSharedNanos(int arg, long nanosTimeout)
        throws InterruptedException {
    // 小于零不需要阻塞了，直接返回
    if (nanosTimeout &amp;lt;= 0L)
        return false;
    // 计算当前线程的超时线
    final long deadline = System.nanoTime() + nanosTimeout;
    // 新增共享节点并入队
    final Node node = addWaiter(Node.SHARED);
    boolean failed = true;
    try {
        // 自旋并休眠，这段代码和 doAcquireShared 一致
        for (;;) {
            final Node p = node.predecessor();
            if (p == head) {
                int r = tryAcquireShared(arg);
                if (r &amp;gt;= 0) {
                    setHeadAndPropagate(node, r);
                    p.next = null; // help GC
                    failed = false;
                    return true;
                }
            }
            // 自旋过程中，每次都重新计算新的超时时间
            nanosTimeout = deadline - System.nanoTime();
            // 超时则直接跳出，返回 false
            if (nanosTimeout &amp;lt;= 0L)
                return false;
             // 当前节点在 acquire 失败后如果需要阻塞，且
            if (shouldParkAfterFailedAcquire(p, node) &amp;amp;&amp;amp;
                    // 当前超时时间大于 1000 纳秒，小于等于 1000 纳秒将会进入下一轮自旋获取锁
                    nanosTimeout &amp;gt; spinForTimeoutThreshold)
                // 以自旋过程中计算的 nanosTimeout 阻塞
                LockSupport.parkNanos(this, nanosTimeout);
            // 线程中断直接退出
            if (Thread.interrupted())
                throw new InterruptedException();
        }
    } finally {
        if (failed)
            // 加锁失败，退出节点
            cancelAcquire(node);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;425-共享模式的实现&#34;&gt;4.2.5 共享模式的实现&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ReentrantReadWriteLock&lt;/code&gt; 中的 &lt;code&gt;ReadLock&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;信号量 &lt;code&gt;Semaphore&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;闭锁 &lt;code&gt;CountDownLatch&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;五-条件队列之-conditionobject&#34;&gt;五、条件队列之 ConditionObject&lt;/h2&gt;
&lt;p&gt;在 &lt;code&gt;AQS&lt;/code&gt; 内部也存在这 &lt;code&gt;Condition&lt;/code&gt; 接口的实现类，即 &lt;code&gt;ConditionObject&lt;/code&gt;，它是 &lt;code&gt;AQS&lt;/code&gt;的共有内部类，并且它是 &lt;code&gt;Lock&lt;/code&gt;&lt;br&gt;
实现的基础。&lt;code&gt;ConditionObject&lt;/code&gt; 提供的条件队列的入队的方法如下。&lt;/p&gt;
&lt;h3 id=&#34;51-条件队列的入队和出队&#34;&gt;5.1 条件队列的入队和出队&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class ConditionObject implements Condition, java.io.Serializable {
    private static final long serialVersionUID = 1173984872572414699L;
    /**
     * 条件队列的第一个节点
     */
    private transient Node firstWaiter;
    /**
     * 条件队列的最后一个节点
     */
    private transient Node lastWaiter;

    /**
     * Creates a new {@code ConditionObject} instance.
     */
    public ConditionObject() {
    }

    /**
     * 为等待队列添加一个新的等待节点
     *
     * @return 新的等待节点
     */
    private Node addConditionWaiter() {
        // 本地变量保存 lastWaiter
        Node t = lastWaiter;
        // 如果 lastWaiter 不为条件等待状态，则说明 lastWaiter 是取消状态，清理
        if (t != null &amp;amp;&amp;amp; t.waitStatus != Node.CONDITION) {
            // 解除所有取消的等待节点的连接
            unlinkCancelledWaiters();
            t = lastWaiter;
        }
        // 创建当前线程的新节点，类型为 CONDITION
        Node node = new Node(Thread.currentThread(), Node.CONDITION);
        // 在首次创建 Condition 时，lastWaiter 为 null，则把当前节点设置为 firstWaiter 
        if (t == null)
            firstWaiter = node;
        else
            // lastWaiter 不为空，则连接新节点
            t.nextWaiter = node;
        // 当前新增节点为 lastWaiter
        lastWaiter = node;
        return node;
    }

    /**
     * 从条件队列中取消连接已取消的等待节点。仅在持有锁时调用。当前方法会在条件等待期间
     * 发生取消时被调用，并且在 lastWaiter 已被取消时插入新的等待节点时调用。需要这种
     * 方法来避免在没有 signal 的情况下保留垃圾。因此，即使它可能需要完全遍历，它也只有
     * 在没有被 signal 的情况下发生超时或取消时才发挥作用。它遍历所有节点，而不是在特定
     * 目标处停止以取消连接到垃圾节点的所有指针，因此不会在取消风暴期间进行多次重新遍历。
     * &amp;lt;p&amp;gt;
     * 简单来说，此方法就是更新队列，移除所有 CANCELLED 的节点，期间会 firstWaiter 和
     * lastWaiter 的引用
     */
    private void unlinkCancelledWaiters() {
        // 保存当前的 firstWaiter 
        Node t = firstWaiter;
        // 跟踪节点，用于最后找到 lastWaiter
        Node trail = null;
        while (t != null) {
            // 从 firstWaiter 开始往后遍历
            Node next = t.nextWaiter;
            // 当前节点不是 CONDITION，那么就是 CANCELLED
            if (t.waitStatus != Node.CONDITION) {
                // 取消当前节点的引用
                t.nextWaiter = null;
                // trail 为空，说明当前还未遇到第一个 CONDITION 状态的节点
                if (trail == null)
                    // 将 firstWaiter 暂时设置为 下个节点
                    firstWaiter = next;
                else
                    // 将 next 链接到追踪节点
                    trail.nextWaiter = next;
                // 遍历结束
                if (next == null)
                    // lastWaiter 即 trail 的最后一个节点
                    lastWaiter = trail;
            } else
                // CONDITION 节点，记录当前节点
                trail = t;
            // 更新当前节点为 next
            t = next;
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们在观察 &lt;code&gt;ConditionObject&lt;/code&gt; 类后可以发现，所有的 &lt;code&gt;await&lt;/code&gt; 方法及其变体都会调用 &lt;code&gt;addConditionWaiter()&lt;/code&gt;&lt;br&gt;
方法，将阻塞线程添加到添加队列中。我们下面演示一下条件队列入队的情况下，假设存在两个线程 &lt;code&gt;thread-1&lt;/code&gt; 和 &lt;code&gt;thread-2&lt;/code&gt;&lt;br&gt;
需要阻塞入队，首先是 &lt;code&gt;thread-1&lt;/code&gt; 入队：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;/Users/wenbo.zhang/Desktop/images/condition-queue-thread-1-enq.png&#34; alt=&#34;thread-1-enq&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;在 &lt;code&gt;thread-1&lt;/code&gt; 入队后等待过程中，&lt;code&gt;thread-2&lt;/code&gt; 入队：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;img src=&#34;/Users/wenbo.zhang/Desktop/images/condition-queue-thread-2-enq.png&#34; alt=&#34;thread-2-enq&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;之后线程入队就如上面操作一样，只需修改 lastWaiter 和 nextWaiter 指向新节点即可。&lt;/p&gt;
&lt;h3 id=&#34;52-condition-之-await&#34;&gt;5.2 Condition 之 await&lt;/h3&gt;
&lt;p&gt;实现 &lt;code&gt;Condition&lt;/code&gt; 接口的 &lt;code&gt;await&lt;/code&gt; 方法，主要用于条件等待操作。下面是关于接口中方法的说明：&lt;/p&gt;
&lt;p&gt;使当前线程等待，直到它被 signal 或中断。&lt;/p&gt;
&lt;p&gt;直到以下四种情况之一发生时，与此 Condition 关联的锁会被自动释放，并且当前线程由于线程调度会被禁用并处于休眠状态：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;其他某个线程为此 Condition 调用了 signal() 方法，而当前线程恰好被选为要被唤醒的线程；&lt;/li&gt;
&lt;li&gt;其他一些线程为此 Condition 调用了 signalAll() 方法；&lt;/li&gt;
&lt;li&gt;其他一些线程中断当前线程，支持中断线程挂起；&lt;/li&gt;
&lt;li&gt;发生“虚假唤醒”。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在所有情况下，在此方法可以返回之前，当前线程必须重新获取获取与此 Condition 关联的锁。当前线程返回时，它保证持有这个锁。&lt;/p&gt;
&lt;p&gt;如果当前线程：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在进入此方法时设置其中断状态；或者，&lt;/li&gt;
&lt;li&gt;等待过程中被中断，支持线程挂起的中断。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;然后抛出 InterruptedException 并清除当前线程的中断状态。在第一种情况下，没有规定是否在释放锁之前进行中断判断。&lt;/p&gt;
&lt;p&gt;实现注意事项：&lt;/p&gt;
&lt;p&gt;调用此方法时，假定当前线程持有与此 Condition 关联的锁。由实现决定是否是这种情况，如果不是，如何响应。通常，将抛出异常（例如，IllegalMonitorStateException）并且实现必须记录该事实。&lt;/p&gt;
&lt;p&gt;与响应 signal 的正常方法返回相比，实现更倾向于响应中断。在这种情况下，实现必须确保将信号量重定向到另一个等待线程（如果有的话）。&lt;/p&gt;
&lt;p&gt;throws InterruptedException - 如果当前线程被中断（并且支持线程挂起的中断）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/** 该模式意味着退出等待时重新中断 */
private static final int REINTERRUPT =  1;
/** 该模式意味着在退出等待时抛出 InterruptedException */
private static final int THROW_IE    = -1;


/**
 * 实现支持中断的条件等待。
 * 1. 如果当前线程被中断，抛出 InterruptedException。
 * 2. 保存 getState 返回的锁状态。
 * 3. 使用保存状态作为参数调用 release，如果失败抛出 IllegalMonitorStateException。
 * 4. 线程入队阻塞，直到 signal 或 线程中断
 * 5. 通过使用保存状态作为参数调用特定的 acquire 方法来重新加锁。
 * 6. 如果在步骤 4 中被阻塞过程中被其他线程中断，则抛出 IntrrputedException。
 */
public final void await() throws InterruptedException {
    // 判断线程中断，清理中断标志
    if (Thread.interrupted())
        throw new InterruptedException();
    // 新增条件等待节点并进入条件等待队列
    Node node = addConditionWaiter();
    // 释放当前 AQS 的所有资源，并返回资源的 state
    int savedState = fullyRelease(node);
    // 中断模式
    int interruptMode = 0;
    // 如果新增节点不在同步队列，对当前节点线程进行阻塞。
    // 这里是个循环判断，当前节点被唤醒后，会将节点从条件队列转换到同步队列，
    // 所以在节点被唤醒后，如果加锁成功，将会被放入同步队列跳出循环
    while (!isOnSyncQueue(node)) {
        LockSupport.park(this);
        // 线程中断，转移当前节点
        if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)
            break;
    }
    // 节点进入同步队列后，如果此时线程没有中断，则以独占方式进入同步队列阻塞
    // 这里在 acquireQueued 中进行 tryAcquire 时使用的参数为 savedState
    if (acquireQueued(node, savedState) &amp;amp;&amp;amp; interruptMode != THROW_IE)
        interruptMode = REINTERRUPT;
    // 当前节点的 nextWaiter 不为空，则从等待队列中移除所有 CANCELLED 节点
    if (node.nextWaiter != null) // clean up if cancelled
        unlinkCancelledWaiters();
    // 根据 interruptMode 对中断进行对应处置
    if (interruptMode != 0)
        reportInterruptAfterWait(interruptMode);
}

/**
 * 使用当前的状态值调用 release；返回保存的状态值。
 * 失败则取消节点，并抛出异常。
 * 
 * 参数：node - 当前等待的条件节点
 * 返回：之前的同步状态
 */
final int fullyRelease(Node node) {
    boolean failed = true;
    try {
        int savedState = getState();
        // 释放资源，也就是解锁
        if (release(savedState)) {
            failed = false;
            return savedState;
        } else {
            throw new IllegalMonitorStateException();
        }
    } finally {
        if (failed)
            // 失败则取消节点
            node.waitStatus = Node.CANCELLED;
    }
}

/**
 * 如果一个节点（从最初就是放在条件队列中的节点）现在正在同步队列中等待 acquire 操作，
 * 则返回 true。
 * 
 * 参数：node - 节点
 * 返回：如果在同步队列中 acquire，返回 true
 */
final boolean isOnSyncQueue(Node node) {
    // 在同步队列，则说明当前节点肯定不是条件等待节点
    // 如果不是条件等待节点，但是节点的 prev 为空，说明节点可能在同步队列已出队
    if (node.waitStatus == Node.CONDITION || node.prev == null)
        return false;
    // 节点不是等待节点，且存在后继节点，说明一定在同步队列上
    if (node.next != null) // If has successor, it must be on queue
        return true;
    /*
     * node.prev 可以是非空的，但尚未在队列中，因为将其放入队列的 CAS 可能会失败。
     * 所以我们必须从队列 tail 遍历，以确保它确实成功了。在调用这个方法时，它总是在
     * tail 附近，除非 CAS 失败（这不太可能），所以我们几乎不会有太多的遍历。
     */
    // 从同步队列往前遍历查找节点
    return findNodeFromTail(node);
}

/**
 * 如果节点通过从 tail 向前搜索，出现在了同步队列上，则返回 true。
 * 仅在 isOnSyncQueue 需要调用。
 * 
 * 返回：如果存在，返回 true
 */
private boolean findNodeFromTail(Node node) {
    Node t = tail;
    for (;;) {
        if (t == node)
            return true;
        if (t == null)
            return false;
        t = t.prev;
    }
}

/**
 * 检查线程中断，如果在 signal 之前中断，则返回 THROW_IE，
 * 如果在 signal 之后中断，返回 REINTERRUPT，如果没有中断，
 * 返回 0。
 */
private int checkInterruptWhileWaiting(Node node) {
    return Thread.interrupted() ?
            // 如果是当前入队成功了，当前线程抛出异常
            (transferAfterCancelledWait(node) ? THROW_IE : REINTERRUPT) :
            // 线程未中断
            0;
}

/**
 * 如果有必要，在取消等待后将节点转移到同步队列。如果是在 signal 之前被
 * 取消等待，则返回 true。
 *
 * 参数：node - 节点。
 * 返回：如果在 signal 之前取消等待，返回 true。
 */
final boolean transferAfterCancelledWait(Node node) {
    // CAS 尝试将当前节点状态修改为 0
    if (compareAndSetWaitStatus(node, Node.CONDITION, 0)) {
        // 修改成功，转移到同步队列
        enq(node);
        return true;
    }
    /*
     * 如果我们由于竞争 CAS 修改失败，那在它完成 enq() 入队之前，我们不能继续。
     * 在传输未完成之前取消，这个很少见也很短暂，所以我们只需要自旋。
     */
    // 等待其他线程将节点加入同步队列
    while (!isOnSyncQueue(node))
        // 让出 CPU
        Thread.yield();
    return false;
}

/**
 * 根据 interruptMode 选择抛出 InterruptedException、重新中断、或不执行任何操作。
 */
private void reportInterruptAfterWait(int interruptMode)
        throws InterruptedException {
    // 抛出异常
    if (interruptMode == THROW_IE)
        throw new InterruptedException();
    else if (interruptMode == REINTERRUPT)
        selfInterrupt();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到，当一个节点加入条件队列时，如果当前节点是同步队列的节点，首先会释放 &lt;code&gt;AQS&lt;/code&gt; 同步队列的资源（此时线程是独占模式，因此不存在竞争），只有持有锁的线程可以进行 &lt;code&gt;fullyRelease&lt;/code&gt;，此时这个节点就从同步队列转移到了条件队列（其实本质是将节点从同步队列移除，然后在条件队列新增一个节点）。之后，该节点就会在条件队列上阻塞，直到有其他线程调用 &lt;code&gt;signal&lt;/code&gt; 或 &lt;code&gt;signal&lt;/code&gt; 唤醒当前线程，当前线程就会从条件队列转移到同步队列中，当 &lt;code&gt;await&lt;/code&gt; 方法被唤醒，并且当前节点成功转移到同步队列中，之后的操作就属于 &lt;code&gt;AQS&lt;/code&gt; 中的同步队列阻塞及唤醒操作。&lt;/p&gt;
&lt;h3 id=&#34;53-condtion-之-signalsignalall&#34;&gt;5.3 Condtion 之 signal/signalAll&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Condition&lt;/code&gt; 接口的 &lt;code&gt;signal&lt;/code&gt; 方法，主要用来唤醒阻塞的条件队列中的线程，其方法说明如下：&lt;/p&gt;
&lt;p&gt;唤醒一个等待线程。&lt;/p&gt;
&lt;p&gt;如果有任何线程在此 Condition 下等待，则选择一个用于唤醒。然后，该线程必须在从await 返回之前重新获取锁。&lt;/p&gt;
&lt;p&gt;实现注意事项：&lt;/p&gt;
&lt;p&gt;在调用此方法时，实现可能（并且通常确实）要求当前线程持有与此 Condition 关联的锁。实现必须记录此前提条件以及未持有锁时采取的任何操作。通常，会抛出 IllegalMonitorStateException。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/*
 * 将等待时间最长的线程（如果存在）从该条件队列转换到拥有锁的等待队列。
 *
 * @throws IllegalMonitorStateException 如果 isHeldExclusively 返回 false
 */
public final void signal() {
  // 当前同步器持有的线程是否是当前线程
  if (!isHeldExclusively())
    throw new IllegalMonitorStateException();
  // 等待时间最长的就是第一个入队的 fistWaiter
  Node first = firstWaiter;
  if (first != null)
    // 唤醒节点
    doSignal(first);
}

/**
 * 删除并转换节点，直到命中未取消的节点或 null。从 signal 中分离出来部分是为了
 * 编译器内联没有等待节点的情况。
 *
 * 参数：first - (非空) 条件队列中的第一个节点
 */
// 该方法目的就是唤醒成功一个节点，或条件队列为空时，执行结束
private void doSignal(Node first) {
  do {
    // 第一个节点的 nextWaiter 为空，说明目前只有一个等待节点
    if ((firstWaiter = first.nextWaiter) == null)
      lastWaiter = null;
    // 将当前处理节点从条件队列移除
    first.nextWaiter = null;
    // 转换当前节点
  } while (!transferForSignal(first) &amp;amp;&amp;amp;
          // 转换失败，此时的 firstWaiter 是 first 的 nextWaiter 节点
          (first = firstWaiter) != null);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;下面是 &lt;code&gt;signalAll&lt;/code&gt; 方法，与 &lt;code&gt;signal&lt;/code&gt; 不同的是，&lt;code&gt;signalAll&lt;/code&gt; 方法会唤醒所有等待节点：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * 将所有线程从该条件等待队列转换到拥有锁的等待队列。
 *
 * @throws IllegalMonitorStateException 如果 isHeldExclusively 返回 false
 */
public final void signalAll() {
  // // 当前同步器持有的线程是否是当前线程
    if (!isHeldExclusively())
      throw new IllegalMonitorStateException();
    Node first = firstWaiter;
    if (first != null)
        // 唤醒所有节点
        doSignalAll(first);
}

/**
 * 移除并转换所有节点
 * @param first (非空) 条件队列中的第一个节点
 */
private void doSignalAll(Node first) {
    // 全部转换，则将 lastWaiter 和 firstWaiter 置空
    lastWaiter = firstWaiter = null;
    do {
        // 获取下一个等待节点
        Node next = first.nextWaiter;
        // 下一个等待节点移除
        first.nextWaiter = null;
        // 处理当前节点
        transferForSignal(first);
        // 更新下个节点为处理节点
        first = next;
    } while (first != null);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到，&lt;code&gt;signal&lt;/code&gt; 和 &lt;code&gt;signalAll&lt;/code&gt; 方法会将节点转换到同步队列，并将节点的状态修改为 &lt;code&gt;SINGAL&lt;/code&gt;，之后解除节点线程阻塞状态。唯一不同的地方是，&lt;code&gt;signal&lt;/code&gt; 方法只唤醒单个节点，而 &lt;code&gt;signalAll&lt;/code&gt; 方法会唤醒全部节点。&lt;/p&gt;
&lt;h3 id=&#34;54-await-方法的几种变体&#34;&gt;5.4 await 方法的几种变体&lt;/h3&gt;
&lt;p&gt;下面我们简单看一下 &lt;code&gt;await&lt;/code&gt; 方法的几种变体。&lt;/p&gt;
&lt;h4 id=&#34;541-awaituninterruptibly&#34;&gt;5.4.1 awaitUninterruptibly&lt;/h4&gt;
&lt;p&gt;使当前线程等待，直到它被 &lt;code&gt;signal&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;直到以下三种情况之一发生时，与此 &lt;code&gt;Condition&lt;/code&gt; 关联的锁会被自动释放，并且当前线程由于线程调度会被禁用并处于休眠状态：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;其他某个线程为此 &lt;code&gt;Condition&lt;/code&gt; 调用了 &lt;code&gt;signal()&lt;/code&gt; 方法，而当前线程恰好被选为要被唤醒的线程；&lt;/li&gt;
&lt;li&gt;其他一些线程为此 &lt;code&gt;Condition&lt;/code&gt; 调用了 &lt;code&gt;signalAll()&lt;/code&gt; 方法；&lt;/li&gt;
&lt;li&gt;发生“虚假唤醒”。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在所有情况下，在此方法可以返回之前，当前线程必须重新获取获取与此 &lt;code&gt;Condition&lt;/code&gt; 关联的锁。当前线程返回时，它保证持有这个锁。&lt;/p&gt;
&lt;p&gt;如果当现场进入该方法时设置了中断状态，或者在等待过程中被中断，则继续等待直到被 &lt;code&gt;signal&lt;/code&gt; 唤醒。当它最终从这个方法返回时，它的中断状态会依旧存在。&lt;/p&gt;
&lt;p&gt;实现注意事项：&lt;/p&gt;
&lt;p&gt;调用此方法时，假定当前线程持有与此 &lt;code&gt;Condition&lt;/code&gt; 关联的锁。由实现决定是否是这种情况，如果不是，如何响应。通常，将抛出异常（例如，IllegalMonitorStateException）并且实现必须记录该事实。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * 实现非中断的条件等待。
 *
 * 1. 保存 getStatus() 返回的锁定状态。
 * 2. 使用保存的状态作为参数调用 release()，如果失败抛出 IllegalMonitorStateException。
 * 3. 阻塞直到 signal。
 * 4. 将保存的状态作为参数调用特定版本的 acquire() 来重新获取锁。
 */
public final void awaitUninterruptibly() {
    // 添加新的等待节点
    Node node = addConditionWaiter();
    // release 当前 AQS 的所有资源，并返回资源的 state
    int savedState = fullyRelease(node);
    // 是否中断
    boolean interrupted = false;
    // 判断当前节点是否是同步队列节点，理论上新增的应当是不在同步队列，当被唤醒时，如果加锁成功则会在同步队列
    while (!isOnSyncQueue(node)) {
        // 阻塞当前节点
        LockSupport.park(this);
        // 判断当前线程是否中断
        if (Thread.interrupted())
            interrupted = true;
    }
    // 如果当前线程被中断，或在加锁过程中中断，则对当前线程进行中断操作
    if (acquireQueued(node, savedState) || interrupted)
        selfInterrupt();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;542-awaitnanos&#34;&gt;5.4.2 awaitNanos&lt;/h4&gt;
&lt;p&gt;使当前线程等待，直到它被 signal 或 中断，或者达到指定的等待时间。&lt;/p&gt;
&lt;p&gt;直到以下五种情况之一发生时，与此 Condition 关联的锁会被自动释放，并且当前线程由于线程调度会被禁用并处于休眠状态：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;其他某个线程为此 Condition 调用了 signal() 方法，而当前线程恰好被选为要被唤醒的线程；&lt;/li&gt;
&lt;li&gt;其他一些线程为此 Condition 调用了 signalAll() 方法；&lt;/li&gt;
&lt;li&gt;其他一些线程中断当前线程，支持中断线程挂起；&lt;/li&gt;
&lt;li&gt;到达指定的等待时间；&lt;/li&gt;
&lt;li&gt;发生“虚假唤醒”。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在所有情况下，在此方法可以返回之前，当前线程必须重新获取获取与此 Condition 关联的锁。当前线程返回时，它保证持有这个锁。&lt;/p&gt;
&lt;p&gt;如果当前线程：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在进入此方法时设置其中断状态；或者，&lt;/li&gt;
&lt;li&gt;等待过程中被中断，支持线程挂起的中断。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;然后抛出 InterruptedException 并清除当前线程的中断状态。在第一种情况下，没有规定是否在释放锁之前进行中断判断。&lt;/p&gt;
&lt;p&gt;在返回时提供给定的 nanosTimeout 值，该方法返回对剩余等待纳秒数的预估，如果超时，则返回小于或等于零的值。在等待返回但是等待的条件仍不成立的情况下，此值可用于确定是否重新等待以及重新等待多长时间。此方法的典型用途如以下形式：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;boolean aMethod(long timeout, TimeUnit unit) {
    long nanos = unit.toNanos(timeout);
    lock.lock();
    try {
        while (!conditionBeingWaitedFor()) {
            if (nanos &amp;lt;= 0L)
                return false;
            nanos = theCondition.awaitNanos(nanos);
        }
        // ...
    } finally {
        lock.unlock();
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;设计说明：此方法需要纳秒参数，以避免报告剩余时间时出现截断错误。这种精度损失将使程序员难以确保总等待时间不会系统地短于重新等待发生时指定的时间。&lt;/p&gt;
&lt;p&gt;实现注意事项：&lt;/p&gt;
&lt;p&gt;调用此方法时，假定当前线程持有与此 Condition 关联的锁。由实现决定是否是这种情况，如果不是，如何响应。通常，将抛出异常（例如，IllegalMonitorStateException）并且实现必须记录该事实。&lt;/p&gt;
&lt;p&gt;与响应 signal 的正常方法返回相比，实现更倾向于响应中断。在这种情况下，实现必须确保将信号量重定向到另一个等待线程（如果有的话）。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * 实现超时条件等待。
 * 1. 如果当前线程被中断，抛出 InterruptedException。
 * 2. 保存 getState 返回的锁状态。
 * 3. 使用保存状态作为参数调用 release，如果失败抛出 IllegalMonitorStateException。
 * 4. 线程入队阻塞，直到 signal、线程中断或超时。
 * 5. 通过使用保存状态作为参数调用特定的 acquire 方法来重新加锁。
 * 6. 如果在步骤 4 中被阻塞过程中被其他线程中断，则抛出 IntrrputedException。
 */
public final long awaitNanos(long nanosTimeout)
        throws InterruptedException {
    if (Thread.interrupted())
        throw new InterruptedException();
    // 增加条件等待节点，并加入条件等待队列
    Node node = addConditionWaiter();
    // 是否 AQS 中的全部资源
    int savedState = fullyRelease(node);
    // 计算超时的时间线
    final long deadline = System.nanoTime() + nanosTimeout;
    int interruptMode = 0;
    // 阻塞直到超时，或中断抛出异常、或同步入队成功
    while (!isOnSyncQueue(node)) {
        // 节点超时
        if (nanosTimeout &amp;lt;= 0L) {
            // 移除条件等待队列，放入同步队列中
            transferAfterCancelledWait(node);
            break;
        }
        // 如果当前实现剩余比较多，这里是 1000 纳秒，那么阻塞
        if (nanosTimeout &amp;gt;= spinForTimeoutThreshold)
            LockSupport.parkNanos(this, nanosTimeout);
        // 中断则跳出循环
        if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)
            break;
        // 重新计算剩余时间
        nanosTimeout = deadline - System.nanoTime();
    }
    // 节点在超时、中断、或 signal 出队后，会加入同步队列，这里在同步队列操作
    if (acquireQueued(node, savedState) &amp;amp;&amp;amp; interruptMode != THROW_IE)
        interruptMode = REINTERRUPT;
    // 下个节点不为空，则断开取消的节点
    if (node.nextWaiter != null)
        unlinkCancelledWaiters();
    // 根据中断模式进行中断处理
    if (interruptMode != 0)
        reportInterruptAfterWait(interruptMode);
    // 返回剩余时间
    return deadline - System.nanoTime();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;543-awaituntil&#34;&gt;5.4.3 awaitUntil&lt;/h4&gt;
&lt;p&gt;使当前线程等待，直到它被 signal 或 中断，或者达到指定的等待时间。&lt;/p&gt;
&lt;p&gt;直到以下五种情况之一发生时，与此 Condition 关联的锁会被自动释放，并且当前线程由于线程调度会被禁用并处于休眠状态：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;其他某个线程为此 Condition 调用了 signal() 方法，而当前线程恰好被选为要被唤醒的线程；&lt;/li&gt;
&lt;li&gt;其他一些线程为此 Condition 调用了 signalAll() 方法；&lt;/li&gt;
&lt;li&gt;其他一些线程中断当前线程，支持中断线程挂起；&lt;/li&gt;
&lt;li&gt;到达指定的等待时间；&lt;/li&gt;
&lt;li&gt;发生“虚假唤醒”。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在所有情况下，在此方法可以返回之前，当前线程必须重新获取获取与此 Condition 关联的锁。当前线程返回时，它保证持有这个锁。&lt;/p&gt;
&lt;p&gt;如果当前线程：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在进入此方法时设置其中断状态；或者，&lt;/li&gt;
&lt;li&gt;等待过程中被中断，支持线程挂起的中断。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;然后抛出 InterruptedException 并清除当前线程的中断状态。在第一种情况下，没有规定是否在释放锁之前进行中断判断。&lt;/p&gt;
&lt;p&gt;返回值表示是否已经过了 deadline，可以如下使用：&lt;/p&gt;
&lt;p&gt;实现注意事项：&lt;/p&gt;
&lt;p&gt;调用此方法时，假定当前线程持有与此 Condition 关联的锁。由实现决定是否是这种情况，如果不是，如何响应。通常，将抛出异常（例如，IllegalMonitorStateException）并且实现必须记录该事实。&lt;/p&gt;
&lt;p&gt;与响应 signal 的正常方法返回相比，实现更倾向于响应中断。在这种情况下，实现必须确保将信号量重定向到另一个等待线程（如果有的话）。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;boolean aMethod(Date deadline) {
    boolean stillWaiting = true;
    lock.lock();
    try {
        while(!conditionBeingWaitedFor()) {
            if (!stillWaiting)
                return false;
            stillWaiting = theCondition.awaitUntil(deadline);
        }
        // ...
    } finally {
        lock.unlock();
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;参数： deadline - 等待的绝对时间。&lt;/p&gt;
&lt;p&gt;返回： 如果返回时已经超过最后期限，则为 false，否则为 true。&lt;/p&gt;
&lt;p&gt;@throws InterruptedException - 如果当前线程被中断（并且支持线程挂起的中断）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * 实现绝对超时时间的条件等待。
 * 1. 如果当前线程被中断，抛出 InterruptedException。
 * 2. 保存 getState 返回的锁状态。
 * 3. 使用保存状态作为参数调用 release，如果失败抛出 IllegalMonitorStateException。
 * 4. 线程入队阻塞，直到 signal、线程中断或超时。
 * 5. 通过使用保存状态作为参数调用特定的 acquire 方法来重新加锁。
 * 6. 如果在步骤 4 中被阻塞过程中被其他线程中断，则抛出 IntrrputedException。
 * 7. 如果在步骤 4 中被阻塞过程中超时，则返回 false，否则返回 true。
 */
public final boolean awaitUntil(Date deadline)
        throws InterruptedException {
    // 获取绝对时间的时间戳
    long abstime = deadline.getTime();
    if (Thread.interrupted())
        throw new InterruptedException();
    // 当前线程加入添加条件队列
    Node node = addConditionWaiter();
    // 释放 AQS 的全部资源
    int savedState = fullyRelease(node);
    boolean timedout = false;
    int interruptMode = 0;
    // 阻塞直到超时，或中断抛出异常、或同步入队成功
    while (!isOnSyncQueue(node)) {
        // 判断当前循环是否超时
        if (System.currentTimeMillis() &amp;gt; abstime) {
            // 取消条件等待，跳出循环
            timedout = transferAfterCancelledWait(node);
            break;
        }
        // 阻塞
        LockSupport.parkUntil(this, abstime);
        // 中断则跳出循环
        if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)
            break;
    }
    // 节点在超时、中断、或 signal 出队后，会加入同步队列，这里在同步队列操作
    if (acquireQueued(node, savedState) &amp;amp;&amp;amp; interruptMode != THROW_IE)
        interruptMode = REINTERRUPT;
    if (node.nextWaiter != null)
        unlinkCancelledWaiters();
    if (interruptMode != 0)
        reportInterruptAfterWait(interruptMode);
    return !timedout;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;544-awaitlong-time-timeunit-unit&#34;&gt;5.4.4 await(long time, TimeUnit unit)&lt;/h4&gt;
&lt;p&gt;使当前线程等待，直到它被 signal 或 中断，或者达到指定的等待时间。此方法在行为上等效于：&lt;code&gt;awaitNanos(unit.toNanos(time)) &amp;gt; 0 &lt;/code&gt;。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * 实现超时条件等待。
 * 1. 如果当前线程被中断，抛出 InterruptedException。
 * 2. 保存 getState 返回的锁状态。
 * 3. 使用保存状态作为参数调用 release，如果失败抛出 IllegalMonitorStateException。
 * 4. 线程入队阻塞，直到 signal、线程中断或超时。
 * 5. 通过使用保存状态作为参数调用特定的 acquire 方法来重新加锁。
 * 6. 如果在步骤 4 中被阻塞过程中被其他线程中断，则抛出 IntrrputedException。
 * 7. 如果在步骤 4 中被阻塞过程中超时，则返回 false，否则返回 true。
 */
public final boolean await(long time, TimeUnit unit)
        throws InterruptedException {
    // 转为纳秒书剑
    long nanosTimeout = unit.toNanos(time);
    // 判断线程中断，并清空状态，中断则抛出异常
    if (Thread.interrupted())
        throw new InterruptedException();
    // 当前线程加入添加条件队列
    Node node = addConditionWaiter();
    // 释放所有 AQS 资源
    int savedState = fullyRelease(node);
    // 计算超时时间先
    final long deadline = System.nanoTime() + nanosTimeout;
    boolean timedout = false;
    int interruptMode = 0;
    while (!isOnSyncQueue(node)) {
        if (nanosTimeout &amp;lt;= 0L) {
            timedout = transferAfterCancelledWait(node);
            break;
        }
        if (nanosTimeout &amp;gt;= spinForTimeoutThreshold)
            LockSupport.parkNanos(this, nanosTimeout);
        if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)
            break;
        nanosTimeout = deadline - System.nanoTime();
    }
    if (acquireQueued(node, savedState) &amp;amp;&amp;amp; interruptMode != THROW_IE)
        interruptMode = REINTERRUPT;
    if (node.nextWaiter != null)
        unlinkCancelledWaiters();
    if (interruptMode != 0)
        reportInterruptAfterWait(interruptMode);
    return !timedout;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;七-aqs-中的-cancelacquire&#34;&gt;七、AQS 中的 cancelAcquire&lt;/h2&gt;
&lt;p&gt;当节点在下列几种状态时，会触发 &lt;code&gt;AQS&lt;/code&gt; 进行 &lt;code&gt;cancelAcquire&lt;/code&gt; 操作，具体如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;节点在队列自旋 &lt;code&gt;acquire&lt;/code&gt;  过程中触发异常，如 &lt;code&gt;acquireQueue&lt;/code&gt;、&lt;code&gt;doAcquireShared&lt;/code&gt; 等方法；&lt;/li&gt;
&lt;li&gt;节点在队列自旋 &lt;code&gt;acquire&lt;/code&gt; 过程中触发线程中断，如 &lt;code&gt;doAcquireInterruptibly&lt;/code&gt;、&lt;code&gt;doAcquireNanos&lt;/code&gt; 、&lt;code&gt;doAcquireSharedInterruptibly&lt;/code&gt;、&lt;code&gt;doAcquireSharedNanos&lt;/code&gt; 等方法&lt;/li&gt;
&lt;li&gt;节点在带有超时参数的 &lt;code&gt;acquire&lt;/code&gt; 变体方法调用中，到达超时时间，且未成功 &lt;code&gt;acquire&lt;/code&gt;，如 &lt;code&gt;doAcquireNanos&lt;/code&gt; 、&lt;code&gt;doAcquireSharedNanos&lt;/code&gt; 等方法。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;总的来说，当线程在 acquire 过程中触发各种异常，或带超时的接口调用触发超时时，就会在 &lt;code&gt;finally&lt;/code&gt; 中调用 &lt;code&gt;cancelAcquire&lt;/code&gt; 方法，用于取消该节点，将该节点从队列中移除。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
* 取消正在进行尝试的 acquire。
*
* 参数：node - 节点
*/
private void cancelAcquire(Node node) {
    // 当前节点不存在，直接忽略
    if (node == null)
        return;
	// 将当前节点持有的线程置空，释放资源
    node.thread = null;

    // 跳过取消的前驱节点，将当前节点的前驱节点和 pred 指向一个未被 CANCELLED 的节点
    Node pred = node.prev;
    // 从当前节点到找到节点之前，都为 CANCELLED 节点，全部需要断开
    // 此后，当前节点的前驱节点为非 CANCELLED 节点
    while (pred.waitStatus &amp;gt; 0)
        node.prev = pred = pred.prev;

    // 很明显 predNext 是要断开链接的节点。如果不是，下面 CAS 将失败，
    // 在这种情况下，我们可能在竞争中输给了另一个 cancel 或 signal，
    // 我们不需要采取其他行动。
    Node predNext = pred.next;

    // 可以在这里使用无条件写入，而不是 CAS 操作。
    // 在这个原子步骤之后，其他节点可以跳过我们。
    // 在此之前，我们不受其他线程影响。
    // 将当前节点状态设置为 CANCELLED
    node.waitStatus = Node.CANCELLED;

    // 如果当前节点为 tail，直接移除当前节点，将 tail 置为 pred（当前节点的前驱节点，非CANCELLED）
    if (node == tail &amp;amp;&amp;amp; compareAndSetTail(node, pred)) {
        compareAndSetNext(pred, predNext, null);
    } else {
        // 当前节点的前驱节点非 head，需要将当前节点从同步队列中移除
        int ws;
        if (pred != head &amp;amp;&amp;amp;
                // 前驱节点状态为 SIGNAL
                ((ws = pred.waitStatus) == Node.SIGNAL ||
                        // 前驱节点状态为 0，将其置为 SIGNAL
                        (ws &amp;lt;= 0 &amp;amp;&amp;amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;amp;&amp;amp;
                pred.thread != null) {
            Node next = node.next;
            // 将当前节点从队列移除，即将 pred 节点（当前节点的前驱节点）的 next 指向当前节点的后继节点
            if (next != null &amp;amp;&amp;amp; next.waitStatus &amp;lt;= 0)
                compareAndSetNext(pred, predNext, next);
        } else {
            // 当前节点的前驱节点为 head，则说明从 head 到 当前节点之间全部为 CANCELLED 节点，
            // 直接唤醒当前节点的后继节点
            unparkSuccessor(node);
        }

        // 断开当前节点引用
        node.next = node; // help GC
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;八-aqs-的锁实现&#34;&gt;八、AQS 的锁实现&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;AQS&lt;/code&gt; 作为同步器框架，其提供的基础的功能给并发组件，下面我们将根据 &lt;code&gt;j.u.c&lt;/code&gt; 包内置的同步组件，来了解 &lt;code&gt;AQS&lt;/code&gt; 的使用。&lt;/p&gt;
&lt;h3 id=&#34;81-reentrantlock&#34;&gt;8.1 ReentrantLock&lt;/h3&gt;
&lt;p&gt;一种可重入的互斥 &lt;code&gt;Lock&lt;/code&gt;，其基本行为和语义与使用 &lt;code&gt;synchronized&lt;/code&gt; 方法和语句访问的隐式监视器锁相同，但具有扩展功能。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ReentrantLock&lt;/code&gt; 被上次成功锁定但尚未解锁的线程 &lt;em&gt;持有&lt;/em&gt;。当锁不被另一个线程持有时，调用 &lt;code&gt;lock&lt;/code&gt; 的线程将返回，并成功获取锁。如果当前线程已经持有锁，该方法将立即返回。这可以使用方&lt;code&gt;isHeldByCurrentThread&lt;/code&gt; 和 &lt;code&gt;getHoldCount&lt;/code&gt; 方法来检查。&lt;/p&gt;
&lt;p&gt;此类的构造函数接受一个可选的 &lt;em&gt;fair&lt;/em&gt; 番薯。当设置为 &lt;code&gt;true&lt;/code&gt; 时，在竞争情况下，锁会优先授予给等待时间最长的线程的访问。否则，锁将无法保证获得顺序。如果在多线程情况下使用公平锁，可能会比非公平锁的吞吐量低（即，会更慢；通常情况下会慢得多），但在获得锁和确保不会出现线程饥饿的情况会有更好的效果。但是请注意，锁的公平性并不能保证线程调度的公平性。因此，使用公平锁的多线程中，可能会有单个线程连续多次获得它，而其他活动线程无法获得锁，因此也无法执行。另请注意，没有超时参数的 &lt;code&gt;tryLock()&lt;/code&gt; 方法不遵守公平设置。如果锁可用，即使其他线程正在等待，他也会成功。&lt;/p&gt;
&lt;p&gt;推荐的做法是在 &lt;code&gt;lock&lt;/code&gt; 加锁之后立即调用&lt;code&gt;try&lt;/code&gt; 块，最常见的用法如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;class X {
    private final ReentrantLock lock = new ReentrantLock();
    // ...
    
    public void m() {
        lock.lock(); // block until condition holds
        try {
            // ... method body
        } finally {
            lock.unlock();
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;除了实现 &lt;code&gt;Lock&lt;/code&gt; 接口之外，该类还定义了许多 &lt;code&gt;public&lt;/code&gt; 和 &lt;code&gt;protected&lt;/code&gt; 的方法来检查锁的状态。其中一些方法仅对 instrumentation 和 monitoring 有用。&lt;/p&gt;
&lt;p&gt;此类的序列化与内置锁的行为方式相同：反序列化锁处于未锁定状态，无论其在序列化时的状态如何。&lt;/p&gt;
&lt;p&gt;此锁最多支持同一线程的 2147483647 个递归锁。尝试超过此限制会导致锁定方法抛出 &lt;code&gt;Error&lt;/code&gt; 。&lt;/p&gt;
&lt;h4 id=&#34;811-sync&#34;&gt;8.1.1 Sync&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;ReentratLock&lt;/code&gt; 的抽象类 &lt;code&gt;Sync&lt;/code&gt; 作为 &lt;code&gt;AQS&lt;/code&gt;框架实现类，用于同步控制的基础。可用于实现公平锁和非公平锁。主要通过使用 &lt;code&gt;AQS&lt;/code&gt; 的状态来表示持有锁的次数，当 &lt;code&gt;AQS&lt;/code&gt; 状态为 &lt;code&gt;0&lt;/code&gt;，说明当前可能没有其他线程持有锁，&lt;code&gt;ReentrantLock&lt;/code&gt;的每次获取锁都会讲 &lt;code&gt;AQS&lt;/code&gt; 状态加一。下面是 &lt;code&gt;Sync&lt;/code&gt; 的源码：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * 此锁的同步控制的基础。下面分为公平和非公平版本。使用 AQS 状态来表示
 * 持有锁的次数。
 */
abstract static class Sync extends AbstractQueuedSynchronizer {
    private static final long serialVersionUID = -5179523762034025860L;

    /**
     * 执行 Lock.lock。抽象方法的原因主要是非公平版本提供快速路径。
     */
    abstract void lock();

    /**
     * 执行非公平的 tryLock。tryAcquire 在子类中实现，但两者都需要对
     * tryLock 方法进行非公平尝试。
     */
    final boolean nonfairTryAcquire(int acquires) {
        // 获取当前执行线程
        final Thread current = Thread.currentThread();
        // 获取 AQS 当前状态
        int c = getState();
        // 当前状态为 0，说明锁可能没有被其他线程获取
        if (c == 0) {
            // cas 尝试加锁，将 AQS 状态修改为 acquires，成功后直接返回
            if (compareAndSetState(0, acquires)) {
                // 设置当前线程为独占
                setExclusiveOwnerThread(current);
                return true;
            }
        }
        // 如果当前线程已经持有了锁，即当前线程就是独占锁的线程
        else if (current == getExclusiveOwnerThread()) {
            // 将状态直接加上 acquires
            int nextc = c + acquires;
            // 状态溢出
            if (nextc &amp;lt; 0) // overflow
                throw new Error(&amp;quot;Maximum lock count exceeded&amp;quot;);
            // 当前线程就是持有锁的线程，所以直接设置 AQS 状态
            setState(nextc);
            return true;
        }
        // 既不是独占线程，状态也不为 0，说明当前锁被其他线程持有
        return false;
    }

    /**
     * 释放资源操作
     */
    protected final boolean tryRelease(int releases) {
        // 计算释放后的状态值
        int c = getState() - releases;
        // 当前线程不是锁的持有者，抛出异常
        if (Thread.currentThread() != getExclusiveOwnerThread())
            throw new IllegalMonitorStateException();
        // 是否完全释放
        boolean free = false;
        // 释放后状态值为 0，说明当前线程已经完全释放资源
        // 如果不为 0，说明当前线程是重入操作的释放，还需要等执行完再次释放
        if (c == 0) {
            // 设置释放 flag
            free = true;
            // 取消当前线程的独占
            setExclusiveOwnerThread(null);
        }
        // 设置 AQS 状态值
        setState(c);
        return free;
    }

    /**
     * 当前线程是否是该独占锁的持有者
     */
    protected final boolean isHeldExclusively() {
        // 虽然我们通常必须在拥有锁之前读取状态值，但是我们不需要
        // 检查这样检查当前线程是否是持有者
        return getExclusiveOwnerThread() == Thread.currentThread();
    }

    /**
     * Condition 实例，用于和 Lock 一起使用
     */
    final ConditionObject newCondition() {
        return new ConditionObject();
    }

// 从外部类中集成的方法

    // 获取当前锁的独占线程
    final Thread getOwner() {
        return getState() == 0 ? null : getExclusiveOwnerThread();
    }

    // 获取当前 AQS 的状态值
    final int getHoldCount() {
        return isHeldExclusively() ? getState() : 0;
    }

    // 是否被锁定
    final boolean isLocked() {
        return getState() != 0;
    }

    /**
     * 从流中重构实例（即反序列化）。
     * 返回的实例为非锁定状态
     */
    private void readObject(java.io.ObjectInputStream s)
            throws java.io.IOException, ClassNotFoundException {
        s.defaultReadObject();
        setState(0); // reset to unlocked state
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;812-公平锁和非公平锁&#34;&gt;8.1.2 公平锁和非公平锁&lt;/h4&gt;
&lt;p&gt;公平锁和非公平锁在源码的实现中，差异很小，唯一的区别是公平锁会在加锁时，判断在自己之前是否有其他线程在等待，只有当自己是头结点（等待时间最长），之后才会尝试加锁。下面我们通过源码来了解一下，以下是非公平锁的实现：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * Sync 对象的非公平锁
 */
static final class NonfairSync extends Sync {
    private static final long serialVersionUID = 7316153563782823691L;

    /**
     * 执行锁定操作。尝试直接修改 AQS 状态加锁（快速路径），失败时恢复正常 acquire。
     */
    final void lock() {
        // CAS 尝试直接加锁，成功后将当前线程设置为独占线程
        if (compareAndSetState(0, 1))
            setExclusiveOwnerThread(Thread.currentThread());
        else
            // CAS 操作失败，正常进行 acquire 操作 
            acquire(1);
    }

    /**
     * tryAcquire 进行加锁操作，实现自 AQS，调用 Sync 进行非公平 tryAcquire
     */
    protected final boolean tryAcquire(int acquires) {
        return nonfairTryAcquire(acquires);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;下面是公平锁的实现：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * Sync 对象的公平锁
 */
static final class FairSync extends Sync {
    private static final long serialVersionUID = -3000897897090466540L;

    // 公平锁，直接 acquire，不尝试快速路径
    final void lock() {
        acquire(1);
    }

    /**
     * tryAcquire 的公平锁版本。除非递归调用，或者在没有等待节点时是第一个，否则不应该具有访问锁权限。
     */
    protected final boolean tryAcquire(int acquires) {
        // 获取当前线程
        final Thread current = Thread.currentThread();
        // 获取 AQS 状态
        int c = getState();
        // 可能没有加锁
        if (c == 0) {
            // 先判断队列中是否有在自己之前的节点
            if (!hasQueuedPredecessors() &amp;amp;&amp;amp;
                    // 自己就是第一个节点，CAS 尝试加锁
                    compareAndSetState(0, acquires)) {
                // 设置独占
                setExclusiveOwnerThread(current);
                return true;
            }
        }
        else if (current == getExclusiveOwnerThread()) {
            int nextc = c + acquires;
            if (nextc &amp;lt; 0)
                throw new Error(&amp;quot;Maximum lock count exceeded&amp;quot;);
            setState(nextc);
            return true;
        }
        return false;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到，在 &lt;code&gt;tryAcquire&lt;/code&gt; 时，公平锁会调用 &lt;code&gt;hasQueuedPredecessors()&lt;/code&gt; 方法，先判断自己是否是头结点（头结点没有前驱节点），我们看下这个方法的源码：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * 查询是否有任何线程其他线程在队列中的等待时间大于当前线程。
 *
 * 调用此方法等效于（但是可能有更高效）：
 * getFirstQueuedThread() != Thread.currentThread() &amp;amp;&amp;amp;
 * hasQueuedThreads()
 *
 * 请注意，由于中断和超时可能随时会发生，从而导致节点取消，因此返回 true 并不代表着
 * 某些其他线程会在当前线程之获取到锁。同样，由于队列为空，在此方法返回 false 时，
 * 另一个线程可能会在竞争中先入队成功。
 *
 * 本方法目的在于供公平同步器的使用，从而避免”闯入“。如果一个同步器的 tryAcquire 
 * 方法应该返回 false，并且他的 tryAcquireShared 方法应该返回一个负值，这个方法
 * 返回 true（除非是可重入的获取）。
 *
 * protected boolean tryAcquire(int arg) {
 *   if (isHeldExclusively()) {
 *     // A reentrant acquire; increment hold count
 *     return true;
 *   } else if (hasQueuedPredecessors()) {
 *     return false;
 *   } else {
 *     // try to acquire normally
 *   }
 * }
 *
 * @return 如果当前线程之前有一个排队线程，则为true ，如果当前线程位于队列的头部或队列为空，则为false
 * @since 1.7
 */
public final boolean hasQueuedPredecessors() {
    // 之所以这么做是因为 head 在 tail 之前被初始化，
    // 先 tail 后 head，h.next 操作一定能获取到值。
    // 如果按照先 h 再 t 的方式取值，可能会发生这样的情况：
    // 此时队列为空 head 为 null，在 h 赋值完成后，其他线程
    // 入队，此时 head 和 tail 都不为空，就造成了 h 不存在，
    // 但是 t 却存在的情况。这种情况 h.next 就会抛出空指针了
    Node t = tail; // 以相反的顺序读取字段
    Node h = head;
    Node s;
    return h != t &amp;amp;&amp;amp;
            ((s = h.next) == null || s.thread != Thread.currentThread());
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;813-reentrantlock-类的其他方法&#34;&gt;8.1.3 ReentrantLock 类的其他方法&lt;/h4&gt;
&lt;p&gt;除了核心的加锁和解锁方法外，&lt;code&gt;ReentrantLock&lt;/code&gt; 还提供了其他的一些监控手段的方法，如下说明：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class ReentrantLock implements Lock, java.io.Serializable {
    private static final long serialVersionUID = 7373984872572414699L;
    /** 提供实现所有机制的同步器 */
    private final Sync sync;

    /**
     * 创建 ReentrantLock 的实例。这相当于 ReentrantLock(false)。
     */
    public ReentrantLock() {
        sync = new NonfairSync();
    }

    /**
     * 使用给定的公平策略创建 ReentrantLock 实例。
     *
     * 参数：fair - 如果当前锁应该使用公平排序策略，则为 true
     */
    public ReentrantLock(boolean fair) {
        sync = fair ? new FairSync() : new NonfairSync();
    }

    /**
     * 获取锁。
     *
     * 如果没有被另一个线程持有，则获取锁并立即返回，将锁持有计数设置为 1。
     *
     * 如果当前线程已经持有锁，则持有次数加 1 并立即返回。
     *
     * 如果锁被另一个线程持有，那么当前线程出于线程调度的目的，将会被禁用并处于休眠状态，
     * 直到当前线程获得锁为止，此时锁持有计数设置为 1.
     */
     public void lock() {
         sync.lock();
     }

    /**
     * 除非当前线程被中断，否则一直 acquire 直到获取锁。
     *
     * 如果没有被另一个线程持有，则获取锁并立即返回，将锁持有计数设置为 1。
     *
     * 如果当前线程已经持有锁，则持有次数加 1 并立即返回。
     *
     * 如果锁被另一个线程持有，那么当前线程出于线程调度的目的，将会被禁用并处于休眠状态，
     * 直到发生以下两种情况之一：
     * - 当前线程获取锁成功；或者
     * - 其他线程中断当前线程。
     *
     * 如果当前线程获取到了锁，则锁持有计数设置为 1。
     *
     * 如果当前线程：
     * - 在进入此方法时设置其中断状态；或者
     * - 在获取锁过程中被中断，
     * 然后会抛出 InterruptedException 并清除当前线程的中断状态。
     *
     * 在此实现中，由于此方法明显表示出中断能力，因此优先响应中断而不是
     * 正常执行或可重入获取锁。
     *
     * @throws InterruptedException - 如果当前线程被中断
     */
    public void lockInterruptibly() throws InterruptedException {
        sync.acquireInterruptibly(1);
    }

    /**
     * 仅当调用时没有另一个线程持有时才获取锁。
     *
     * 如果锁没有被另一个线程持有，则获取锁，并立即返回 true，将锁持有计数设置为 1。
     * 即使此锁已设置为使用公平排队策略，调用 tryLock() 也会立即获取锁（如果可用），
     * 无论其他线程当前是否正在等待该锁。这种 “闯入” 行为在某些情况下可能很有用，
     * 即使它破坏了公平性。如果您想完全遵循公平设置，请使用几乎等效的 tryLock(9, TimeUnit.SECONDS)
     * （它也检测中断）。
     *
     * 如果当前线程已经持有了锁，那么持有计数加 1 并返回 true。
     * 
     * 如果锁被其他线程持有，则此方法立即返回 false。
     *
     * 返回：如果锁空闲并被当前线程获取成功，或锁已经被当前线程持有，则返回 true，否则返回 false。
     */
    public boolean tryLock() {
        return sync.nonfairTryAcquire(1);
    }

    /**
     * 如果在给定的等待时间内没有被其他线程持有锁，且当前线程没有被中断，则获取锁。
     *
     * 如果锁没有被另一个线程持有，则获取锁，并立即返回 true，且会将锁持有的计数设置为 1。如果
     * 此锁已设置为使用公平排序策略，则在该线程之前排队任何其他线程正在等待该锁，则不会获取到锁。
     * 这与 tryLock() 方法形成对比。如果你想要一个允许 “闯入” 公平锁的可超时 tryLock，则可以
     * 将超时和非超时方法相结合使用：
     *
     * if (lock.tryLock() ||
     *     lock.tryLock(timeout, unit)) {
     *     ...
     * }
     *
     *
     * 如果没有被另一个线程持有，则获取锁并立即返回，将锁持有计数设置为 1。
     *
     * 如果当前线程已经持有锁，则持有次数加 1 并立即返回。
     *
     * 如果锁被另一个线程持有，那么当前线程出于线程调度的目的，将会被禁用并处于休眠状态，
     * 直到发生以下三种情况之一：
     * - 当前线程获取锁成功；或者
     * - 其他线程中断当前线程；或者
     * - 达到了指定的超时等待时间。
     *
     * 如果当前线程获取到了锁，则锁持有计数设置为 1。
     *
     * 如果当前线程：
     * - 在进入此方法时设置其中断状态；或者
     * - 在获取锁过程中被中断，
     * 然后会抛出 InterruptedException 并清除当前线程的中断状态。
     *
     * 如果到达了指定的超时时间，则返回 false。如果时间小于或等于零，则该方法不会等待。
     *
     * 在此实现中，由于此方法明显表示出中断能力，因此优先响应中断而不是
     * 正常执行或可重入获取锁，同时也优先于报告超过等待时间。
     *
     *
     * 参数：timeout - 等待锁的时间
     *      unit - timeout 参数的时间单位
     * 返回：如果锁是空闲的并被当前线程获取到，或者锁已经被当前线程持有，则返回true；
     *      如果在获得锁之前达到了超时时间，则返回 false
     * @throws InterruptedException - 如果当前线程被中断
     * @throws NullPointerException - 如果时间单位为空
     */
    public boolean tryLock(long timeout, TimeUnit unit)
            throws InterruptedException {
        return sync.tryAcquireNanos(1, unit.toNanos(timeout));
    }

    /**
     * 尝试释放此锁。
     *
     * 如果当前线程是这个锁的持有者，那么持有计数就会递减。如果持有计数现在为 0，则直接释放锁。
     * 如果当前线程不是该锁的持有者，则抛出 IllegalMonitorStateException。
     *
     * @throws IllegalMonitorStateException - 如果当前线程没有持有这个锁。
     */
    public void unlock() {
        sync.release(1);
    }

    /**
     * 返回与当前 Lock 实例一起使用的 Condition 实例。
     *
     * 当与内置的监视器锁一起使用时，返回的 Condition 实例支持与 Object 监视器方法
     * （wait、notify 和 notifyAll） 相同的用法。
     *
     * - 如果在调用任何 Condition 的 await 和 signal 方法时，未持有锁，则会引发 
     *   IllegalMonitorStateException。
     * - 当 Condition 的 await 方法被调用时，锁被释放，在该线程返回前，锁会被其他线程
     *   重新获得，锁持有计数会恢复到调用方法时的状态。
     * - 如果线程在等待过程中被中断，则等待终止，并抛出 InterruptedException，并清除
     *   线程的中断状态。
     * - 以 FIFO 顺序 signal 等待线程。
     * - 从 await 方法返回的线程重新获取锁的顺序与最初获取锁的线程顺序相同，在默认情况下，
     *   非公平锁，未指定顺序；但对于公平锁，优先考虑那些等待时间长的线程。
     *
     * 返回：Condition 对象
     */
    public Condition newCondition() {
        return sync.newCondition();
    }

    /**
     * 查询当前线程持有该锁的次数。
     *
     * 如果解锁的次数和加锁的次数不匹配，那么该线程会持有该锁。
     *
     * 持有计数信息通常仅用于测试和调试目的。例如，如果某段代码不应该在已经持有锁的情况下输入，
     * 那么我们可以断言这个事实：
     * 
     * class X {
     *     ReentrantLock lock = new ReentrantLock();
     *     // ...
     *     public void m() {
     *         assert lock.getHoldCount() == 0;
     *         lock.lock();
     *         try {
     *             // ... method body
     *         } finally {
     *             lock.unlock();
     *         }
     *     }
     * }
     *
     * 返回：当前线程持有锁的次数，如果当前线程未持有锁，则为零
     */
    public int getHoldCount() {
        return sync.getHoldCount();
    }

    /**
     * 查询当前线程是否持有该锁。
     *
     * 类似于内置监视器锁的 Thread.holdsLock(Object) 方法，此方法通常用于调试和测试。
     * 例如，如果一个线程只有在持有锁时，才调用该方法，可以这样断言：
     *
     * class X{
     *     ReentrantLock lock = new ReentrantLock();
     *     // ...
     *     
     *     public void m(){
     *         assert lock.isHeldByCurrentThread();
     *         // ... method body
     *     }
     * }
     *
     * 它还可以用于确保以不可重入方式使用可重入锁，例如：
     *
     * class X{
     *     ReentrantLock lock = new ReentrantLock();
     *     // ...
     *     
     *     public void m(){
     *         assert !lock.isHeldByCurrentThread();
     *         lock.lock();
     *         try {
     *             // ... method body
     *         } finally {
     *             lock.unlock;
     *         }
     *     }
     * }
     *
     * 返回：如果当前线程持有该锁，返回 true；否则返回 false
     */
    public boolean isHeldByCurrentThread() {
        return sync.isHeldExclusively();
    }

    /**
     * 查询当前锁是否被持有。此方法设计用于监控系统状态，而不用于同步控制。
     *
     * 返回：任何线程持有此锁，返回 true；否则返回 false。
     */
    public boolean isLocked() {
        return sync.isLocked();
    }

    /**
     * 如果此锁的公平性设置为 true，则返回 true。
     *
     * 返回：如果此锁的公平性设置为 true，则返回 true。
     */
    public final boolean isFair() {
        return sync instanceof FairSync;
    }

    /**
     * 返回拥有此锁的线程，如果锁没有被持有，返回 null。如果当前线程不是锁的持有者，
     * 调用此方法会返回当前锁定状态的近似值。例如，即使有线程在尝试获取锁，但还没有
     * 获取成功，所有者也可能暂时为 null。此方法主要目的在于促进提供更广泛的锁监视
     * 设施的子类的构建。
     *
     * 返回：锁的持有者，如果没有，返回 null。
     */
    protected Thread getOwner() {
        return sync.getOwner();
    }

    /**
     * 查询是否有线程正在等待获取此锁。请注意，由于取消可能随时发生，因此返回 true，
     * 并不意味着其他线程就会获取锁。此方法主要设计用于监控系统状态。
     *
     * 返回：如果可能有其他线程等待获取锁，则为true。
     */
    public final boolean hasQueuedThreads() {
        return sync.hasQueuedThreads();
    }

    /**
     * 查询给定线程是否正在等待获取此锁。请注意，由于取消可能随时发生，因此返回 true，
     * 并不意味着该线程就会获取锁。此方法主要设计用于监控系统状态。
     *
     * 参数：thread - 线程
     * 返回：如果给定线程可能等待获取锁，则为true。
     * @throws NullPointerException thread 为 null
     */
    public final boolean hasQueuedThread(Thread thread) {
        return sync.isQueued(thread);
    }

    /**
     * 返回等待获取该锁的线程数的近似值。该值为一个预估值，因为在该方法遍历内部
     * 数据结构时，线程数可能会动态发生变化。此方法主要设计用于监控系统状态，而不
     * 是用于同步控制。
     *
     * 返回：等待此锁的预估线程数
     */
    public final int getQueueLength() {
        return sync.getQueueLength();
    }

    /**
     * 返回一个集合，其中包含正在等待获取此锁的线程。因为在构造这个结果时，实际的
     * 线程集合可能会动态变化，所以返回的集合只是预估值。返回集合的元素没有特定顺序。
     * 此方法主要目的在于促进提供更广泛的锁监视设施的子类的构建。
     *
     * 返回：线程集合。
     */
    protected Collection&amp;lt;Thread&amp;gt; getQueuedThreads() {
        return sync.getQueuedThreads();
    }

    /**
     * 查询是否有线程正在等待与当前锁关联的 Condition。请注意，
     * 由于超时和中断可能随时发生，因此返回 true，并不意味着将来 signal 无法唤醒等待线程。
     * 此方法主要设计用于监控系统状态。
     * 
     * 参数：condition - condition
     * 返回：如果有任何等待线程，返回 true
     * @throws IllegalMonitorStateException - 如果没有持有这个锁
     * @throws IllegalArgumentException - 如果给定条件与此锁没有关联
     * @throws NullPointerException - condition 为 null
     */
    public boolean hasWaiters(Condition condition) {
        if (condition == null)
            throw new NullPointerException();
        if (!(condition instanceof AbstractQueuedSynchronizer.ConditionObject))
            throw new IllegalArgumentException(&amp;quot;not owner&amp;quot;);
        // 判断当前 condition 是否存在等待节点
        return sync.hasWaiters((AbstractQueuedSynchronizer.ConditionObject)condition);
    }

    /**
     * 返回等待与当前锁关联的给定 condtion 的线程数的估计值。请注意，
     * 由于超时和中断可能随时发生，因此此值进作为实际等待节点的上限。
     * 此方法主要设计用于监控系统状态，不用来做同步控制。
     * 
     * 参数：condition - condition
     * 返回：预估的等待线程数
     * @throws IllegalMonitorStateException - 如果没有持有这个锁
     * @throws IllegalArgumentException - 如果给定条件与此锁没有关联
     * @throws NullPointerException - condition 为 null
     */
    public int getWaitQueueLength(Condition condition) {
        if (condition == null)
            throw new NullPointerException();
        if (!(condition instanceof AbstractQueuedSynchronizer.ConditionObject))
            throw new IllegalArgumentException(&amp;quot;not owner&amp;quot;);
        return sync.getWaitQueueLength((AbstractQueuedSynchronizer.ConditionObject)condition);
    }

    /**
     * 返回线程集合，其中包含可能正在等待与此锁相关联的指定 condition 的线程。因为在
     * 构造这个结果时，实际的线程集合可能会动态变化，所以该集合返回的只是一个近似值。
     * 返回集合的元素没有特定顺序。此方法主要目的在于促进提供更广泛的锁监视设施的子类的构建。
     *
     * 参数：condition - condition
     * 返回：线程集合
     * @throws IllegalMonitorStateException - 如果没有持有这个锁
     * @throws IllegalArgumentException - 如果给定条件与此锁没有关联
     * @throws NullPointerException - condition 为 null
     */
    protected Collection&amp;lt;Thread&amp;gt; getWaitingThreads(Condition condition) {
        if (condition == null)
            throw new NullPointerException();
        if (!(condition instanceof AbstractQueuedSynchronizer.ConditionObject))
            throw new IllegalArgumentException(&amp;quot;not owner&amp;quot;);
        return sync.getWaitingThreads((AbstractQueuedSynchronizer.ConditionObject)condition);
    }

    /**
     * 返回标识此锁的字符串及其锁状态。。括号中的状态包括字符串 &amp;quot;Unlocked&amp;quot; 或字符串
     * &amp;quot;Locked by&amp;quot; 后跟拥有锁的线程的名称。
     *
     * 返回：一个标识这个锁的字符串，以及它的锁状态
     */
    public String toString() {
        Thread o = sync.getOwner();
        return super.toString() + ((o == null) ?
                                   &amp;quot;[Unlocked]&amp;quot; :
                                   &amp;quot;[Locked by thread &amp;quot; + o.getName() + &amp;quot;]&amp;quot;);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;82-reentantreadwritelock&#34;&gt;8.2 ReentantReadWriteLock&lt;/h3&gt;
&lt;p&gt;该锁实现了 &lt;code&gt;ReadWriteLock&lt;/code&gt; 接口，并支持和 &lt;code&gt;ReentrantLock&lt;/code&gt; 相似的语义。&lt;/p&gt;
&lt;p&gt;此类具有以下属性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;顺序加锁&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;此类不会为读锁和写锁的访问强加优先级顺序。但是，它支持可选的 &lt;em&gt;公平&lt;/em&gt; 策略。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;非公平模式（默认）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当构造非公平（默认）锁时，进入读写锁的顺序是未指定的，并受到重入的约束。一直存在竞争的非公平锁可能会无限期地推迟一个或多个读锁或写锁线程，但通常比公平锁具有更高的吞吐量。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;公平模式&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当构造为公平锁时，线程使用近似到达顺序策略竞争入队。如果当前持有的锁被释放，要么为等待时间最长的单个写入线程分配写锁，要么如果有一组读取线程等待时间比写入线程长，则为读取线程分配读锁。&lt;/p&gt;
&lt;p&gt;如果持有写锁或存在等待写入线程，则尝试获取公平锁（不可重入）的线程将阻塞。直到当前等待时间最长的写入线程获得写锁并释放之后，该线程才会获得读锁。当然，在没有线程获取写锁的情况下，如果一个等待的写入线程放弃等待，剩下的一个或多个读取线程将作为队列中等待时间最长的，被分配读锁。&lt;/p&gt;
&lt;p&gt;除非读锁和写锁都空闲（这意味着没有等待的线程），否则试图获取公平写锁（不可重入）的线程将阻塞。（请注意，非阻塞 &lt;code&gt;ReentrantReadWriteLock.ReadLock.tryLock()&lt;/code&gt; 和 &lt;code&gt;ReentrantReadWriteLock.WriteLock.tryLock()&lt;/code&gt; 方法不遵守此公平设置，如果可能，将立即获取锁，而不管等待线程。）&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;重入&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;此锁允许读取线程和写入线程以 &lt;code&gt;ReentrantLock&lt;/code&gt; 一样的方式重新获取读锁或写锁。在写入线程持有的所有写锁都被释放之前，不允许非重入的读取线程。&lt;/p&gt;
&lt;p&gt;此外，写入线程可以获取读锁，但反之则不行。在其他应用程序中，当对在读锁下执行读取操作的方法在调用或回调期间持有写锁时，可重入性可能很有用。如果一个读取线程试图获得写锁，它将永远不会成功。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;锁降级&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;重入还允许从写锁降级为读锁，方法是获取写锁，然后获取读锁，然后释放写锁。但是，&lt;strong&gt;无法&lt;/strong&gt; 从读锁升级为写锁。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;锁获取中断&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;读锁和写锁都支持获取锁过程中的中断。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Condition 支持&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;写锁提供了一个 &lt;code&gt;Condition&lt;/code&gt; 实现，就写锁而言，它的行为方式与 &lt;code&gt;ReentrantLock.newCondition&lt;/code&gt; 提供的实现的行为方式相同。当然，这个 &lt;code&gt;Condition&lt;/code&gt; 只能与写锁一起使用。读锁不支持 &lt;code&gt;Condition&lt;/code&gt; 并且 &lt;code&gt;readLock().newCondition()&lt;/code&gt; 抛出 &lt;code&gt;UnsupportedOperationException&lt;/code&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Instrumentation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;此类支持确定锁是否被持有或竞争的方法。这些方法是为监控系统状态而设计的，而不是为同步控制而设计的。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;此类的序列化与内置锁的行为方式相同：反序列化锁将处于未锁定状态，无论其在序列化时的状态如何。&lt;/p&gt;
&lt;p&gt;示例用法。这是一个代码草图，展示了如果在更新缓存后执行锁降级（以非嵌套方式处理多个锁时，异常处理特别棘手）：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;class CachedData {
    Object data;
    volatile boolean cacheVaild;
    final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();

    void processCachedData() {
        rwl.readLock().lock();
        if (!cacheVaild) {
            // Must release read lock before acquiring write lock
            rwl.readLock().unlock();
            rwl.writeLock().lock();
            try {
                // Recheck state because another thread might have
                // acquired write lock and changed state before we did.
                if (!cacheVaild) {
                    data = ...
                    cacheVaild = true;
                }
                // Downgrade by acquiring read lock before releasing write lock
                rwl.readLock().lock();
            } finally {
                rwl.writeLock().unlock(); // Unlock write, still hold read
            }
        }
        
        try {
            use(data);
        } finally {
            rwl.readLock().unlock();
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;ReentrantReadWriteLock&lt;/code&gt; 可以用于在某些集合的某些用途中提高并发性能。通常，只有当集合预计很大、被很多线程读取，但对写入很少时，并且开销要超过同步开销的操作时，才值得这么做。例如，这里有一个使用 &lt;code&gt;TreeMap&lt;/code&gt; 的类，该类预计会很大，并且可以并发访问。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;class RWDictionary {
    private final Map&amp;lt;String, Data&amp;gt; m = new TreeMap&amp;lt;String, Data&amp;gt;();
    private final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();
    private final Lock r = rwl.readLock();
    private final Lock w = rwl.writeLock();

    public Data get(String key) {
        r.lock();
        try {
            return m.get(key);
        } finally {
            r.unlock();
        }
    }

    public String[] allKeys() {
        r.lock();
        try {
            return m.keySet().toArray();
        } finally {
            r.unlock();
        }
    }

    public Data put(String key, Data value) {
        w.lock();
        try {
            return m.put(key, value);
        } finally {
            w.unlock();
        }
    }

    public void clear() {
        w.lock();
        try {
            m.clear();
        } finally {
            w.unlock();
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;实现注意事项&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;该锁最多支持 65535 个重入写锁和 65535 个读锁。如果超出这些限制会导致 &lt;code&gt;lock&lt;/code&gt; 方法引发 &lt;code&gt;Error&lt;/code&gt;。&lt;/p&gt;
&lt;h4 id=&#34;821-sync&#34;&gt;8.2.1  Sync&lt;/h4&gt;
&lt;p&gt;和 &lt;code&gt;ReentrantLock&lt;/code&gt; 相似，在 &lt;code&gt;ReentrantReadWriteLock&lt;/code&gt; 类中同样有基于 &lt;code&gt;AQS&lt;/code&gt; 框架实现的内部类 &lt;code&gt;Sync&lt;/code&gt;。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * ReentrantReadWriteLock 的同步实现。
 * 分为公平和非公平版本。
 */
abstract static class Sync extends AbstractQueuedSynchronizer {
    private static final long serialVersionUID = 6317671515068378041L;

    /*
     * 读锁和写锁计数提取常量和函数。
     * 锁的状态在逻辑上分为两个无符号 short：
     * 较低的表示独占（写锁）锁持有计数，
     * 较高的表示共享（读锁）锁持有计数。
     */

    // 共享锁（读锁）的偏移量
    static final int SHARED_SHIFT   = 16;
    /**
     * 我们每次在进行读锁数量增加 +1 时，只需直接将 SHARED_UNIT 加上 state 即可。
     * 举个例子，在十进制中，如果我们只有四位，读锁只能操作高位的2个数字，写锁只能操作
     * 低位的两个数字，那么如果想要让读锁加一，那我们就需要加上 100，此时数字就是 01 | 00。
     * 如果我们还想要再次加一，此时同样是加上 100，就是 02 | 00，这样就实现了读锁加一的效果，
     * 而写锁，只需要直接加一即可。而这个 100 其实就是我们位数的偏移量，100 就是 1 左移 2 位即可，
     * 因为写锁占了低位，所以我们要偏移后，这个 SHARED_UNIT 就是我们每次增减的值。
     */
    static final int SHARED_UNIT    = (1 &amp;lt;&amp;lt; SHARED_SHIFT);
    // 读/写锁的最大数量，为什么减一，以上面的例子来说，两位只能是 00 ~ 99，
    // 也就是 1 &amp;lt;&amp;lt; SJARED_SHIFT - 1，因为再加的话，就溢出到高位了
    static final int MAX_COUNT      = (1 &amp;lt;&amp;lt; SHARED_SHIFT) - 1;
    // 低 16 位全部为 1，高 16 位全部是 0，当我们想要计算独占锁（读锁，占低 16 位）
    // 的数量时（因为可能会有重入），将 state &amp;amp; EXCLUSIVE_MARK，进行 &amp;amp; 操作，
    // （都为 1 才保留，其余全部为 0），高位数字会被清掉，所以就计算出了低 16 位.
    // 也就是写锁的数量
    static final int EXCLUSIVE_MASK = (1 &amp;lt;&amp;lt; SHARED_SHIFT) - 1;

    /** 返回读锁的数量  */
    static int sharedCount(int c)    { return c &amp;gt;&amp;gt;&amp;gt; SHARED_SHIFT; }
    /** 返回写锁的数量  */
    static int exclusiveCount(int c) { return c &amp;amp; EXCLUSIVE_MASK; }

    /**
     * 每个线程的读锁持有数量，维护为 ThreadLocal，缓存在 cachedHoldCounter
     */
    static final class HoldCounter {
        int count = 0;
        // 使用线程 id，而不是引用，避免垃圾滞留
        final long tid = getThreadId(Thread.currentThread());
    }

    /**
     * ThreadLocal 子类，为了反序列化，使用最简单明确的定义。
     */
    static final class ThreadLocalHoldCounter
        extends ThreadLocal&amp;lt;HoldCounter&amp;gt; {
        public HoldCounter initialValue() {
            return new HoldCounter();
        }
    }

    /**
     * 当前线程持有的可重入读锁数量。仅在构造函数和 readObject 中初始化。
     * 每当线程的读取计数减为 0 时删除。
     */
    private transient ThreadLocalHoldCounter readHolds;

    /**
     * 最后一个线程成功获取 readLock 的持有计数。这节省了 ThreadLocal
     * 查找，在通常情况下，下一个要 release 的线程是最后一个 acquire 的线程。
     * 这是非 volatile 的，因为它只是作为一种试探，对线程进行缓存有利。
     *
     * 该读取计数缓存的生命周期可能比线程更长，因为内部使用线程 id，而不是
     * 线程引用，来避免垃圾回收保留。
     *
     * 通过良性数据竞争访问；依赖于内存模型的 final 字段和 out-of-thin-air 的保证。
     */
    private transient HoldCounter cachedHoldCounter;

    /**
     * firstReader 是第一个获得读锁的线程。firstReaderHoldCount 是 first
     * 的持有计数。
     *
     * 更准确的说，firstReader 是最后一次将共享计数从 0 改为 1 的唯一线程，
     * 此后一直没有释放读锁；如果没有这样的线程，则为 null。
     *
     * 除非线程在没有放弃读锁的情况下终止，否则不会导致垃圾保留，因为 tryReleaseShared
     * 会将其设置为 null。
     *
     * 通过良性数据竞争访问；依赖于内存模型对引用的 out-of-thin-air 保证。
     *
     * 这使得对非竞争读锁的持有计数保存跟踪非常简单。
     */
    private transient Thread firstReader = null;
    private transient int firstReaderHoldCount;

    Sync() {
        // 初始化读锁的持有计数 ThreadLocal
        readHolds = new ThreadLocalHoldCounter();
        setState(getState()); // 确保 readHolds 的内存可见性
    }

    /*
     * 公平锁和非公平锁使用相同的 acquires 和 releases 代码，但在队列非空时，
     * 它们在是否允许插入方面会有所不同。
     */

    /**
     * 该方法返回当前线程请求获得读锁是否应该被阻塞，在公平和非公平策略下实现不同。
     * 在公平锁中，如果队列中当前线程之前 有 其他线程排队，则返回 true，当在队列头部
     * 或者队列为空则返回 false。
     * 在非公平锁中，如果队列头部的等待节点是写入线程，则返回 true，避免写入线程无限等待；
     * 如果写入线程不在队头，则返回 false，不影响其他线程进行读取。
     */
    abstract boolean readerShouldBlock();

    /**
     * 返回当前线程请求获得写锁是否应该被阻塞，在公平锁中，行为和 reader 一样，都会检查在
     * 自己之前是否有其他线程排队；在非公平锁中，总是返回 false，不阻塞。
     */
    abstract boolean writerShouldBlock();

    /*
     * 注意 tryRelease 和 tryAcquire 可以被 Condition 调用。因此，
     * 它们的参数可能会是包含所有的读锁计数和写锁计数，在条件等待期间全部释放并
     * tryAcquire 重新建立读锁和写锁持有计数。
     */
    // 读锁释放
    protected final boolean tryRelease(int releases) {
        // 判断当前线程是否是独占线程
        if (!isHeldExclusively())
            throw new IllegalMonitorStateException();
        // 读锁模式下是单线程，计算释放后的值
        int nextc = getState() - releases;
        // 判断是否全部释放
        boolean free = exclusiveCount(nextc) == 0;
        if (free)
            // 清空独占线程
            setExclusiveOwnerThread(null);
        // 写入新的 state
        setState(nextc);
        return free;
    }

    // 读锁获取
    protected final boolean tryAcquire(int acquires) {
        /*
         * 步骤：
         * 1. 如果读锁计数不为 0 或写锁计数不为 0，且当前线程不是锁持有者，失败。
         * 2. 如果计数饱和（溢出），失败（只有在计数不为 0 时才会出现）。
         * 3. 否则，如果该线程是可重入加锁或队列策略允许（非公平锁可以抢占，
         * 即 writerShouldBlock 返回 false），则该线程有资格获取锁。如果是这样，
         * CAS更新状态并设置独占线程。
         */
        Thread current = Thread.currentThread();
        int c = getState();
        // 独占（写）锁数量
        int w = exclusiveCount(c);
        // c 不为零，即存在读锁或写锁被持有（也可能是自己）
        if (c != 0) {
            // (注意: 如果 c != 0 且 w == 0 那么共享（读）锁数量不为 0)
            // 如果 w == 0 说明读锁不为零，读锁有则加锁失败。
            // 如果 w == 0 没有满足，说明现在写锁不为零，判断当前线程是不是
            // 独占线程，如果是，则尝试重入，如果不是则失败
            if (w == 0 || current != getExclusiveOwnerThread())
                return false;
            // 独占线程重入，检查是否超过最大重入数量
            if (w + exclusiveCount(acquires) &amp;gt; MAX_COUNT)
                throw new Error(&amp;quot;Maximum lock count exceeded&amp;quot;);
            // 重入计数
            setState(c + acquires);
            return true;
        }
        // 判断当前写锁是否需要阻塞，如果需要阻塞，失败
        // 如果不需要阻塞，则 CAS 修改持有计数，加锁并设置独占线程
        if (writerShouldBlock() ||
                !compareAndSetState(c, c + acquires))
            return false;
        setExclusiveOwnerThread(current);
        return true;
    }

    // 共享（写）锁释放
    protected final boolean tryReleaseShared(int unused) {
        Thread current = Thread.currentThread();
        // 当前线程是否是 firstReader，在没有竞争的情况下，这个变量可以帮助我们
        // 更加简单快速的去确认读取所的持有数量
        if (firstReader == current) {
            // assert firstReaderHoldCount &amp;gt; 0;
            // 如果只有一个读取锁持有数量，直接释放锁，并将 firstReader 置空
            if (firstReaderHoldCount == 1)
                firstReader = null;
            else
                // 将持有数量 -1
                firstReaderHoldCount--;
        } else {
            // 如果不是当前线程，说明现在有多个线程持有读锁
            // 如果缓存是 null 或者 缓存线程不是当前线程，说明当前线程不是最后一次获取
            // 持有读锁的线程，则从 threadLocal 读取
            HoldCounter rh = cachedHoldCounter;
            if (rh == null || rh.tid != getThreadId(current))
                rh = readHolds.get();
            // 当前的读锁计数
            int count = rh.count;
            // 如果当前持有的读锁计数小于等于 1，直接删除 ThreadLocal 值
            if (count &amp;lt;= 1) {
                readHolds.remove();
                // 如果还没开始释放就 &amp;lt;= 0，这说明有逻辑问题，抛出异常
                if (count &amp;lt;= 0)
                    throw unmatchedUnlockException();
            }
            // 计数器减一
            --rh.count;
        }
        // 自旋 CAS 修改共享锁计数
        for (;;) {
            int c = getState();
            // c - SHARED_UNIT(共享锁的一个单元)，也就是对高 16 位进行减一操作
            int nextc = c - SHARED_UNIT;
            if (compareAndSetState(c, nextc))
                // 释放读锁对写锁没有影响，但如果读锁和写锁都空闲（nextc 为 0），
                // 则表示可以唤醒后面等待的线程
                return nextc == 0;
        }
    }

    private IllegalMonitorStateException unmatchedUnlockException() {
        return new IllegalMonitorStateException(
                &amp;quot;attempt to unlock read lock, not locked by current thread&amp;quot;);
    }

    // 共享（写）锁的获取
    protected final int tryAcquireShared(int unused) {
        /*
         * 步骤：
         * 1. 如果写锁被另一个线程持有，则失败。
         * 2. 否则，该线程有资格获得锁定状态，因此请询问它是否应该
         *    因为队列策略而阻塞。如果没有，请尝试通过 CAS 更新 state
         *    并更新计数。注意，该步骤不检查可重入 acquire，它被推迟
         *    在 fullTryAcquireShared 中，从而避免在更典型的
         *    不可重入的场景下，检查持有计数。
         * 3. 如果由于线程不符合条件或 CAS 失败或计数已经饱和，
         *    则步骤 2 失败，然后将会进行 fullTryAcquireShared 方法。
         */
        Thread current = Thread.currentThread();
        int c = getState();
        // 写锁数量不为 0，并且当前线程不为独占线程
        // 这一步就是我们进行锁降级时，持有写锁然后去获取读锁的基础
        if (exclusiveCount(c) != 0 &amp;amp;&amp;amp;
                getExclusiveOwnerThread() != current)
            return -1;
        // 获取读锁数量
        int r = sharedCount(c);
        // 判断读锁是否应该阻塞
        if (!readerShouldBlock() &amp;amp;&amp;amp;
                // 判断当前是否溢出
                r &amp;lt; MAX_COUNT &amp;amp;&amp;amp;
                // CAS 尝试加锁
                compareAndSetState(c, c + SHARED_UNIT)) {
            // 加锁成功后，判断是否是首个获取读锁的线程
            if (r == 0) {
                // 将 firstReader 和 firstReaderHoldCount 赋值
                firstReader = current;
                firstReaderHoldCount = 1;
              // 当前线程是否是首个获取读锁的线程重入了
            } else if (firstReader == current) {
                // 持有计数递增
                firstReaderHoldCount++;
            } else {
                // 非首个线程，判断自己是否是上次来访问 AQS 加锁的线程
                HoldCounter rh = cachedHoldCounter;
                // 当自己也不是上次加锁的线程，那只能从 threadLocal 中读取
                if (rh == null || rh.tid != getThreadId(current))
                    // 更新 rh 和 cachedHoldCounter，因为自己是最后一次获取
                    // 读锁成功的线程
                    cachedHoldCounter = rh = readHolds.get();
                else if (rh.count == 0)
                    // 读锁数量为零，说明是同一个线程之前全部释放后，再次加锁
                    // 由于当线程释放完后，会清空 threadLocal，但是并不会清理
                    // cachedHoldCounter，所以，当同一个线程释放完，再次过来
                    // 获取（中间没有其他线程过来加锁），那 cachedHoldCounter 持有的
                    // 计数是仍然存在的，所以只需要将计数重新放回 threadLocal 即可
                    readHolds.set(rh);
                // 持有计数递增
                rh.count++;
            }
            return 1;
        }
        // 需要阻塞，或读锁移除，或 CAS 失败
        return fullTryAcquireShared(current);
    }

    /**
     * 读锁进行 acquire 的完整版本，它处理 CAS 失败和在 tryAcquireShared
     * 中未处理的重入获取
     */
    final int fullTryAcquireShared(Thread current) {
        /*
         * 此代码与 tryAcquireShared 中的代码部分冗余，但总体上更简单，
         * 因为不会使 tryAcquireShared 与重试和延迟读取持有计数之间的交互
         * 复杂化。
         */
        HoldCounter rh = null;
        // 自旋加锁
        for (;;) {
            int c = getState();
            // 独占锁数量不为零，则判断当前线程是否是独占线程，非独占则失败
            if (exclusiveCount(c) != 0) {
                if (getExclusiveOwnerThread() != current)
                    return -1;
                // 否则我们持有独占锁；如果我们在持有写锁的情况下，在这里阻塞会导致死锁。
                // 所以我们直接放行
              
              // 下面判断没有线程持有写锁，排队的情况
            } else if (readerShouldBlock()) {
                // 在这里面说明我们获取 readLock 需要阻塞的，说明在我们之前可能有其他排队线程
                // 确保我们没有以可重入的方式获取读锁
                // 如果当前线程是已经获取过读锁，再次重入的，直接放行
                if (firstReader == current) {
                    // assert firstReaderHoldCount &amp;gt; 0;
                } else {
                    // 到这里，我们不是首次获取读锁的
                    // 首次自旋 rh 是 null，那需要给 rh 赋值
                    if (rh == null) {
                        // 先给 rh 赋为 cachedHoldCounter，即假设我们是最后一个获取的
                        rh = cachedHoldCounter;
                        // 如果 rh 为空，或者 rh 的线程并不是自己，则从 threadLocal 查找
                        if (rh == null || rh.tid != getThreadId(current)) {
                            // 查找获取 threadLocal 的值，如果我们没有持有锁，是首次获取
                            // 那这一步会导致 threadLocal 实例化 HoldCounter，实例化后
                            // 的 count 为 0，由于我们需要阻塞，所以肯定是失败的，目的就是
                            // 检查我们是不是重入，重入的话就成功，失败需要把 threadLocal
                            // 值清理掉
                            rh = readHolds.get();
                            // threadLocal 中的持有计数，如果为空，则移除 threadLocal
                            if (rh.count == 0)
                                readHolds.remove();
                        }
                    }
                    // 如果我们没有持有锁，并且需要阻塞，则失败
                    if (rh.count == 0)
                        return -1;
                }
            }
            // 如果限制持有锁数量达到最大，则失败
            if (sharedCount(c) == MAX_COUNT)
                throw new Error(&amp;quot;Maximum lock count exceeded&amp;quot;);
            // CAS 尝试加写锁
            if (compareAndSetState(c, c + SHARED_UNIT)) {
                // 加锁成功，判断加锁前读锁数量是不是为 0，为 0 说明自己是第一个加锁的
                if (sharedCount(c) == 0) {
                    // 设置 firstReader 和 firstReaderHoldCount 主要为了提高性能
                    firstReader = current;
                    firstReaderHoldCount = 1;
                // 不为零，判断当前线是否是 firstReader 重入
                } else if (firstReader == current) {
                    // 持有计数增加
                    firstReaderHoldCount++;
                } else {
                    // 如果非 firstReader，则获取 threadLocal 值
                    if (rh == null)
                        // 先假设我们是最后一个加锁的
                        rh = cachedHoldCounter;
                    // 如果我们不是最后一个加锁的，则从 threadLocal 查找
                    if (rh == null || rh.tid != getThreadId(current))
                        rh = readHolds.get();
                    // 我们是最后一个加锁的，则设置一下 threadLocal，因为
                    // 随时会有其他线程在加锁成功后将 cachedHoldCounter 更新掉，
                    // 这时候我们的计数就丢失了
                    else if (rh.count == 0)
                        readHolds.set(rh);
                    // 增加持有读锁计数
                    rh.count++;
                    // 将自己更新为最后一个获取读锁的线程，缓存下来，提高性能
                    cachedHoldCounter = rh; // cache for release
                }
                return 1;
            }
        }
    }

    /**
     * 对写锁执行 tryLock，在两种策略（公平和非公平）下都会“闯入”。
     * 这在效果上与 tryAcquire 相同，只是缺少对 writeShouldBlock
     * 的调用。
     */
    final boolean tryWriteLock() {
        Thread current = Thread.currentThread();
        int c = getState();
        // 说明有线程持有读/写锁
        if (c != 0) {
            // 判断读锁数量是否为 0，为 0 说明有其他线程持有写锁，那我们肯定失败
            // 不为 0，则判断当前线程是否是重入，非重入，则直接失败
            int w = exclusiveCount(c);
            if (w == 0 || current != getExclusiveOwnerThread())
                return false;
            if (w == MAX_COUNT)
                throw new Error(&amp;quot;Maximum lock count exceeded&amp;quot;);
        }
        // CAS 加锁
        if (!compareAndSetState(c, c + 1))
            return false;
        // 成功后更新独占线程
        setExclusiveOwnerThread(current);
        return true;
    }

    /**
     * 对读锁执行 tryLock，在两种策略下都会“闯入”。这在效果上与 
     * tryAcquireShared 相同，只是缺少对 readerShouldBlock 的调用。
     */
    final boolean tryReadLock() {
        Thread current = Thread.currentThread();
        // 自旋尝试获取读锁
        for (;;) {
            int c = getState();
            // 独占锁数量不为空，并且当前线程不是独占线程，则直接失败
            if (exclusiveCount(c) != 0 &amp;amp;&amp;amp;
                    getExclusiveOwnerThread() != current)
                return false;
            // 获取写锁数量
            int r = sharedCount(c);
            // 判断写锁数量是否已满
            if (r == MAX_COUNT)
                throw new Error(&amp;quot;Maximum lock count exceeded&amp;quot;);
            // CAS 尝试加锁
            if (compareAndSetState(c, c + SHARED_UNIT)) {
                // 加锁成功，判断当前线程是不是首个获得读锁的
                if (r == 0) {
                    // 设置 firstReader 和 firstReaderCount
                    firstReader = current;
                    firstReaderHoldCount = 1;
                // 读锁不为空，看看当前线程是否是 firstReader 重入，是的话直接增加计数
                } else if (firstReader == current) {
                    firstReaderHoldCount++;
                } else {
                    // 先从缓存中找，如果不是，则从 threadLocal 找
                    HoldCounter rh = cachedHoldCounter;
                    if (rh == null || rh.tid != getThreadId(current))
                        cachedHoldCounter = rh = readHolds.get();
                    else if (rh.count == 0)
                        readHolds.set(rh);
                    // 计数
                    rh.count++;
                }
                return true;
            }
        }
    }

    // 是否是独占线程
    protected final boolean isHeldExclusively() {
        // While we must in general read state before owner,
        // we don&#39;t need to do so to check if current thread is owner
        return getExclusiveOwnerThread() == Thread.currentThread();
    }

    // Methods relayed to outer class

    // 获取 condition
    final ConditionObject newCondition() {
        return new ConditionObject();
    }

    // 获取独占线程
    final Thread getOwner() {
        // Must read state before owner to ensure memory consistency
        return ((exclusiveCount(getState()) == 0) ?
                null :
                getExclusiveOwnerThread());
    }

    // 获取读锁数量
    final int getReadLockCount() {
        return sharedCount(getState());
    }

    // 写锁是否被占有
    final boolean isWriteLocked() {
        return exclusiveCount(getState()) != 0;
    }

    // 获取当前线程持有的写锁数量
    final int getWriteHoldCount() {
        return isHeldExclusively() ? exclusiveCount(getState()) : 0;
    }

    // 获取当前线程持有读锁数量
    final int getReadHoldCount() {
        if (getReadLockCount() == 0)
            return 0;

        // 先从 firstReader 里面找
        Thread current = Thread.currentThread();
        if (firstReader == current)
            return firstReaderHoldCount;

        // 再从 cachedHoldCounter 找，没有则从 threadLocal 找
        HoldCounter rh = cachedHoldCounter;
        if (rh != null &amp;amp;&amp;amp; rh.tid == getThreadId(current))
            return rh.count;

        int count = readHolds.get().count;
        if (count == 0) readHolds.remove();
        return count;
    }

    /**
     * 从流中读取对象（即反序列化）
     */
    private void readObject(java.io.ObjectInputStream s)
            throws java.io.IOException, ClassNotFoundException {
        s.defaultReadObject();
        readHolds = new ThreadLocalHoldCounter();
        setState(0); // reset to unlocked state
    }

    // 获取全部计数
    final int getCount() { return getState(); }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;822-公平锁和非公平锁&#34;&gt;8.2.2 公平锁和非公平锁&lt;/h4&gt;
&lt;p&gt;非公平锁：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;static final class NonfairSync extends Sync {
    private static final long serialVersionUID = -8159625535654395037L;
    final boolean writerShouldBlock() {
        return false; // 非公平锁写入不需要阻塞
    }
    // 
    final boolean readerShouldBlock() {
        /* 作为避免写入线程饿死的启发式方法，如果队列头部暂时显示为写入线程，则阻塞。
         * 这只是一种概率效应，引入如果在写入线程之前有其他读取线程没有超时，则
         * 读取线程不会阻塞。
         */
        // 判断队列头部线程是否是独占线程
        return apparentlyFirstQueuedIsExclusive();
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;公平锁：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;static final class FairSync extends Sync {
    private static final long serialVersionUID = -2274990926593161451L;
    final boolean writerShouldBlock() {
        return hasQueuedPredecessors();
    }
    final boolean readerShouldBlock() {
        return hasQueuedPredecessors();
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;823-读锁和写锁&#34;&gt;8.2.3 读锁和写锁&lt;/h4&gt;
&lt;h5 id=&#34;8231-readlock&#34;&gt;8.2.3.1  ReadLock&lt;/h5&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public static class ReadLock implements Lock, java.io.Serializable {
    private static final long serialVersionUID = -5992448646407690164L;
    private final Sync sync;

    /**
     * 子类使用的构造器
     *
     * 参数：lock - 外部锁对象
     * 参数：NullPointerException - 如果 lock 为空
     */
    protected ReadLock(ReentrantReadWriteLock lock) {
        sync = lock.sync;
    }

    /**
     * 获取读锁。
     *
     * 如果写锁没有被另一个线程持有，则获取读锁并立即返回。
     *
     * 如果写锁被另一个线程持有，那么当前线程处于调度目的将被禁用并处于休眠状态，
     * 直到获得读锁为止。
     */
    public void lock() {
        sync.acquireShared(1);
    }

    /**
     * 获取读锁，线程中断则终止。
     *
     * 如果写锁没有被另一个线程持有，则获取读锁并立即返回。
     *
     * 如果写锁被另一个线程持有，那么出于调度的目的，该线程将被禁用并
     * 进入休眠状态，直到发生以下两种状态之一：
     * - 该线程获取到读锁；或者
     * - 其他一些线程中断当前线程。
     *
     * 如果当前线程：
     * - 进入此方法时设置中断状态；或者
     * - 在线程获取读锁时被中断。
     *
     * 然后抛出InterruptedException并清除当前线程的中断状态。
     *
     * 在此实现中，由于此方法明显表示出中断能力，因此优先响应中断而不是
     * 正常执行或可重入获取锁。
     *
     * @throws InterruptedException - 如果当前线程被中断
     */
    public void lockInterruptibly() throws InterruptedException {
        sync.acquireSharedInterruptibly(1);
    }

    /**
     * 仅当调用时另一个线程未持有写锁时才获取锁。
     *
     * 如果写锁没有被另一个线程持有，则获取读锁，并返回 true。即使此锁已设置为
     * 使用公平排序策略，调用 tryLock() 将立即获取读锁（如果可用），无论其他
     * 线程当前是否正在等待。这种“闯入”行为在某些情况下可能很有用，即便它会破坏
     * 公平性。如果您想要要求此锁保证公平性设置，请使用与此几乎等效的 
     * tryLock(0, TimeUnit.SECONDS)（它也会检测线程中断）。
     *
     * 如果写锁被另一个线程持有，则此方法立即返回 false。
     *
     * 返回：如果获得了锁，则返回 true
     */
    public boolean tryLock() {
        return sync.tryReadLock();
    }

    /**
     * 如果在给定的等待时间内获取写锁没有超时、或当前线程没有中断，则获取读锁。
     *
     * 如果写锁没有被另一个线程持有，则获取读锁，并返回 true。如果此锁已设置为
     * 使用公平排序策略，则在此线程之前有任何其他线程等待锁，则不会获取锁。这与
     * tryLock() 方法形成对比。如果你想要一个允许 “闯入” 公平锁的可超时 tryLock
     * ，则可以将超时和非超时方法相结合使用：
     *
     * if (lock.tryLock() ||
     *     lock.tryLock(timeout, unit)) {
     *   ...
     * }
     *
     * 如果写锁被另一个线程持有，那么出于调度的目的，该线程将被禁用并
     * 进入休眠状态，直到发生以下三种状态之一：
     * - 该线程获取到读锁；或者
     * - 其他一些线程中断当前线程；或者
     * - 超过指定的等待时间。
     *
     * 如果当前线程：
     * - 进入此方法时设置中断状态；或者
     * - 在线程获取读锁时被中断。
     *
     * 然后抛出InterruptedException并清除当前线程的中断状态。
     *
     * 在此实现中，由于此方法明显表示出中断能力，因此优先响应中断而不是
     * 正常执行或可重入获取锁，以及报告等待超时。
     *
     * 参数：timeout - 等待读锁的时间
     *      unit - timeout 参数的时间单位
     * 返回：如果获得了读锁，则为 true
     * @throws InterruptedException - 如果当前线程被中断
     * @throws NullPointerException - 如果时间单位为空
     */
    public boolean tryLock(long timeout, TimeUnit unit)
            throws InterruptedException {
        return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout));
    }

    /**
     * 尝试释放此锁。
     *
     * 如果读锁的数量为零，则写锁可以尝试获取。
     */
    public void unlock() {
        sync.releaseShared(1);
    }

    /**
     * 抛出 UnsupportedOperationException，因为 ReadLock 不支持 Cindition。
     *
     * @throws UnsupportedOperationException 总是
     */
    public Condition newCondition() {
        throw new UnsupportedOperationException();
    }

    /**
     * 返回标识此锁的字符串及其锁状态。括号中的状态包括字符串&amp;quot;Read locks =&amp;quot; ，后跟持有的读锁数。
     *
     * 返回：一个标识这个锁的字符串，以及它的锁状态
     */
    public String toString() {
        int r = sync.getReadLockCount();
        return super.toString() +
                &amp;quot;[Read locks = &amp;quot; + r + &amp;quot;]&amp;quot;;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;8232-writelock&#34;&gt;8.2.3.2 WriteLock&lt;/h5&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public static class WriteLock implements Lock, java.io.Serializable {
    private static final long serialVersionUID = -4992448646407690164L;
    private final Sync sync;

    /**
     * 子类使用的构造器
     *
     * 参数：lock - 外部锁对象
     * 参数：NullPointerException - 如果 lock 为空
     */
    protected WriteLock(ReentrantReadWriteLock lock) {
        sync = lock.sync;
    }

    /**
     * 获取写锁。
     * 
     * 如果其他线程既没有持有读锁也没有持有写锁，则获取写锁并立即返回，将写锁持有
     * 计数设置为 1。
     * 
     * 如果当前线程已经持有写锁，则持有计数加一并立即返回。
     *
     * 如果锁被另一个线程持有，那么当前线程处于调度目的将被禁用并处于休眠状态，
     * 直到获得写锁为止，此时写锁持有计数设置为 1。
     */
    public void lock() {
        sync.acquire(1);
    }

    /**
     * 获取写锁，线程中断则终止。
     *
     * 如果其他线程既没有持有读锁也没有持有写锁，则获取写锁并立即返回，
     * 将写锁持有计数设置为 1。
     *
     * 如果当前线程已经持有写锁，则持有计数加一并立即返回。
     *
     * 如果锁被另一个线程持有，那么出于调度的目的，该线程将被禁用并
     * 进入休眠状态，直到发生以下两种情况之一：
     * - 该线程获取到写锁；或者
     * - 其他一些线程中断当前线程。
     *
     * 如果当前线程获取到了写锁，则锁持有计数设置为 1。
     *
     * 如果当前线程：
     * - 进入此方法时设置中断状态；或者
     * - 在线程获取读锁时被中断。
     *
     * 然后抛出InterruptedException并清除当前线程的中断状态。
     *
     * 在此实现中，由于此方法明显表示出中断能力，因此优先响应中断而不是
     * 正常执行或可重入获取锁。
     *
     * @throws InterruptedException - 如果当前线程被中断
     */
    public void lockInterruptibly() throws InterruptedException {
        sync.acquireInterruptibly(1);
    }

    /**
     * 仅当调用时没有其他线程未持有锁时才获取写锁。
     *
     * 如果其他线程既没有持有读锁也没有持有写锁，则获取写锁并立即返回，将写锁持有
     * 计数设置为 1。即使此锁已设置为使用公平排序策略，调用 tryLock() 将立即获
     * 取该锁（如果可用），无论其他线程当前是否正在等待。这种“闯入”行为在某些情况
     * 下可能很有用，即便它会破坏公平性。如果您想要要求此锁保证公平性设置，请使用
     * 与此几乎等效的  tryLock(0, TimeUnit.SECONDS)（它也会检测线程中断）。
     *
     * 如果当前线程已经持有写锁，则持有计数加一并立即返回。
     * 
     * 如果锁被另一个线程持有，则此方法立即返回 false。
     *
     * 返回：如果获得了锁，则返回 true
     */
    public boolean tryLock( ) {
        return sync.tryWriteLock();
    }

    /**
     *
     * 如果在给定的等待时间内获取锁没有超时、或当前线程没有中断，则获取读锁。
     *
     * 如果其他线程既没有持有读锁也没有持有写锁，则获取写锁并立即返回，将写锁持有
     * 计数设置为 1。如果此锁已设置为使用公平排序策略，则在此线程之前有任何其他
     * 线程等待锁，则不会获取锁。这与 tryLock() 方法形成对比。如果你想要一个
     * 允许 “闯入” 公平锁的可超时 tryLock，则可以将超时和非超时方法相结合使用：
     *
     * if (lock.tryLock() ||
     *     lock.tryLock(timeout, unit)) {
     *   ...
     * }
     *
     * 如果当前线程已经持有写锁，则持有计数加一并立即返回。
     * 
     * 如果锁被另一个线程持有，那么出于调度的目的，该线程将被禁用并
     * 进入休眠状态，直到发生以下三种状态之一：
     * - 该线程获取到读锁；或者
     * - 其他一些线程中断当前线程；或者
     * - 超过指定的等待时间。
     *
     * 如果当前线程获取到了写锁，则锁持有计数设置为 1。
     *
     * 如果当前线程：
     * - 进入此方法时设置中断状态；或者
     * - 在线程获取读锁时被中断。
     *
     * 然后抛出InterruptedException并清除当前线程的中断状态。
     *
     * 在此实现中，由于此方法明显表示出中断能力，因此优先响应中断而不是
     * 正常执行或可重入获取锁，以及报告等待超时。
     *
     * 参数：timeout - 等待读锁的时间
     *      unit - timeout 参数的时间单位
     * 返回：如果获得了读锁，则为 true
     * @throws InterruptedException - 如果当前线程被中断
     * @throws NullPointerException - 如果时间单位为空
     */
    public boolean tryLock(long timeout, TimeUnit unit)
            throws InterruptedException {
        return sync.tryAcquireNanos(1, unit.toNanos(timeout));
    }

    /**
     * 尝试释放此锁。
     *
     * 如果当前线程是这个锁的持有者，那么持有计数就会递减。如果持有计数为零，
     * 则释放锁。如果当前线不是该锁的持有者，则抛出 IllegalMonitorStateException。
     *
     * @throws IllegalMonitorStateException - 如果当前线程没有持有该锁
     */
    public void unlock() {
        sync.release(1);
    }

    /**
     * 返回与此 Lock 实例一起使用的 Condition 实例。
     *
     * 当与内置监视器锁一起使用时，返回的 Condition 实例支持与 Object 监视器
     * 方法（wait、notify 和 notifyAll）相同的用法。
     *
     * - 如果在调用任何 Condition 方法时未持有此锁的写锁，则会抛出 
     *   IllegalMonitorStateException。（写锁和读锁持有是独立的，因此不会被
     *   检查或影响。但是，当前线程在持有写锁时，又获取读锁，同时调用条件等待方法本质上
     *   是错误的，因为其他可以解除阻塞的线程无法获取写锁。）
     * - 当 condition await 方法被调用时，写锁将被释放，在它们返回之前，写锁
     *   将被重新获得，所持有计数恢复到调用方法时的状态。
     * - 如果线程在等待过程中被中断，则等待将终止，将抛出 InterruptedException，
     *   并清除线程的中断状态。
     * - 等待线程以 FIFO 顺序 signal。
     * - 从 await 方法返回的线程重新获取锁的顺序与最初获取锁的线程顺序相同，在默认情况下
     *   未指定，但对于公平锁，会优先考虑哪些等待时间最长的线程。
     *
     * 返回：condition 对象
     */
    public Condition newCondition() {
        return sync.newCondition();
    }

    /**
     * 返回标识此锁的字符串及其锁状态。括号中的状态包括字符串&amp;quot;Unlocked&amp;quot;或
     * 字符串&amp;quot;Locked by&amp;quot;后跟拥有线程的名称。
     *
     * 返回：一个标识这个锁的字符串，以及它的锁状态
     */
    public String toString() {
        Thread o = sync.getOwner();
        return super.toString() + ((o == null) ?
                &amp;quot;[Unlocked]&amp;quot; :
                &amp;quot;[Locked by thread &amp;quot; + o.getName() + &amp;quot;]&amp;quot;);
    }

    /**
     * 查询当前线程是否持有该写锁。与 ReentrantReadWriteLock#isWriteLockedByCurrentThread 
     * 效果相同。
     *
     * 返回：如果当前线程持有此锁，则为true；否则为 false。
     * @since 1.6
     */
    public boolean isHeldByCurrentThread() {
        return sync.isHeldExclusively();
    }

    /**
     * 查询当前线程持有该写锁的次数。对于解锁操作不匹配的每个锁定操作，
     * 线程都持有一个锁。与 ReentrantReadWriteLock#getWriteHoldCount 的效果相同。
     *
     * 返回：当前线程持有此锁的次数，如果当前线程未持有此锁，则为零
     * @since 1.6
     */
    public int getHoldCount() {
        return sync.getWriteHoldCount();
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;823-其他方法&#34;&gt;8.2.3 其他方法&lt;/h4&gt;
&lt;p&gt;下面我们看一下 &lt;code&gt;ReentrantReadWriteLock&lt;/code&gt; 中使用的线程 id 如何获取：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * 返回给定线程的 thread ID。我们必须直接访问它，因为通过方法 Thread.getId() 返回的
 * 并不是最终的，并且已知会以不保留唯一映射的方式被覆盖。
 */
static final long getThreadId(Thread thread) {
    return UNSAFE.getLongVolatile(thread, TID_OFFSET);
}

// Unsafe mechanics
private static final sun.misc.Unsafe UNSAFE;
private static final long TID_OFFSET;
static {
    try {
        UNSAFE = sun.misc.Unsafe.getUnsafe();
        Class&amp;lt;?&amp;gt; tk = Thread.class;
        TID_OFFSET = UNSAFE.objectFieldOffset
                (tk.getDeclaredField(&amp;quot;tid&amp;quot;));
    } catch (Exception e) {
        throw new Error(e);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其他一些关于 ReentrantReadWriteLock 的基础监控方法，这里不在做描述。&lt;/p&gt;
&lt;h3 id=&#34;83-samphora&#34;&gt;8.3 Samphora&lt;/h3&gt;
&lt;p&gt;计数信号量。从概念上讲，信号量维护一组 permit（许可）。如果需要，每个 &lt;code&gt;acquire&lt;/code&gt; 都会阻塞，直到 permit 可用，然后获得它。每个 &lt;code&gt;release&lt;/code&gt; 都会添加一个 permit，可能会释放一个阻塞的获取者。但是，没有使用实际的 permit 对象；&lt;code&gt;Semaphore&lt;/code&gt; 只是对可用数量进行计数并采取相应的措施。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Semaphore&lt;/code&gt; 通常用于限制可以访问某些（物理或逻辑）资源的线程数。例如，这是一个使用 &lt;code&gt;Semaphore&lt;/code&gt; 来控制对资源池访问的类：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;class Pool {
  private static final int MAX_AVAILABLE = 100;
  private final Semaphore available = new Semaphore(MAX_AVAILABLE, true);
  
  public Object getItem() throws InterruptedException {
    available.acquire();
    return getNextAvailableItem();
  }
  
  public void putItem(Object x) {
    if (markAsUnused(x)) {
      available.release();
    }
  }
  
  // Not a particularly efficient data structure; just for demo
  
  protected Object[] items = ... whatever kinds of items being managed
  protected boolean[] used = new boolean[MAX_AVAILABLE];
  
  protected synchronized Object getNextAvailableItem(){
    for (int i = 0; i &amp;lt; MAX_AVAILABLE; ++i) {
      if (!used[i]) {
        used[i] = true;
        return items[i];
      }
    }
    return null;// not reached
  }
  
  protected synchronized boolean markAsUnused(Object item) {
    for (int i = 0; i &amp;lt; MAX_AVAILABLE; ++i) {
      if (item == items[i]) {
        if (used[i]) {
          used[i] = false;
          return true;
        } else {
          return false;
        }
      }
    }
    return false;
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在获取一个 item 之前，每个线程必须从 &lt;code&gt;Semaphore&lt;/code&gt; 中获得一个 permit，保证一个 item 可供使用。当线程处理完该 tiem 时，它被返回到池中，一个 permit 返回给 &lt;code&gt;Semaphore&lt;/code&gt;，允许另一个线程获取该 item。请注意，当调用 &lt;code&gt;acquire&lt;/code&gt; 时，不会持有同步锁，因为这将阻塞 item 返回池中。&lt;code&gt;Semaphore&lt;/code&gt; 封装了限制对池的访问所需的同步，与维护池本身的一致性所需的同步是分开的。&lt;/p&gt;
&lt;p&gt;初始化为 1 的 &lt;code&gt;Semaphore&lt;/code&gt;，使用时最多只有一个 permit 可用，可以作为互斥锁。这通常称为二进制信号量（binary semaphore），因为它只有两种状态：1 个 permit 可用，或 0 个 permit 可用。当以这种方式使用时，二进制信号量具有这样的属性（与许多 &lt;code&gt;java.util.concurrent.locks.Lock&lt;/code&gt; 实现不同），即 “锁” 可以由所有者以外的线程释放（因为信号量没有所有权的概念）。这在一些专门的上下文中很有用，比如死锁恢复。&lt;/p&gt;
&lt;p&gt;此类的构造函数可以选择接受一个 &lt;em&gt;公平&lt;/em&gt; 参数。当设置为 false 时，此类不保证线程获取 permit 的顺序。特别是，允许“闯入”，也就是说，调用 &lt;code&gt;acquire&lt;/code&gt; 的线程可以在一个一直等待的线程之前被允许分配一个 permit —— 从逻辑上来说，就是新线程将自己置于等待队列的头部。当 &lt;code&gt;fairness&lt;/code&gt; 设置为 true时，信号量保证调用任何 &lt;code&gt;acquire&lt;/code&gt; 方法的线程会按照这些线程被 &lt;code&gt;acquire&lt;/code&gt; 方法处理的顺序获得 permit（先进先出；FIFO）。请注意，FIFO 排序必然适用于这些方法中的特定内部执行点。因此，一个线程可以在另一个线程之前调用 &lt;code&gt;acquire&lt;/code&gt;，但在另一个线程之后到达排序点，并且从方法返回时类似。另外请注意，没有超时参数的 &lt;code&gt;tryAcquire&lt;/code&gt; 方法不遵循公平设置，会直接获取任何可用的 permit。&lt;/p&gt;
&lt;p&gt;通常，用于控制资源访问的信号量应该被初始化公平的，以确保没有线程因访问资源而被饿死。当使用信号量进行其他类型的同步控制时，非公平排序的吞吐量优势通常超过公平性考虑。&lt;/p&gt;
&lt;p&gt;该类还提供了一次获取和释放多个 permit 的方便方法。当使用这些方法且不设置公平性时，要注意线程有无限延迟被饿死的风险会增加。&lt;/p&gt;
&lt;p&gt;内存一致性影响：线程中调用“释放”方法（比如 &lt;code&gt;release()&lt;/code&gt;）之前的操作 happen-before 另一线程中紧跟在成功的“获取”方法（比如 acquire()）之后的操作。&lt;/p&gt;
&lt;h4 id=&#34;831-sync&#34;&gt;8.3.1 Sync&lt;/h4&gt;
&lt;p&gt;信号量的同步实现。使用 &lt;code&gt;AQS&lt;/code&gt; 的 &lt;code&gt;state&lt;/code&gt; 来表示 permit。分为公平和非公平版本。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;abstract static class Sync extends AbstractQueuedSynchronizer {
    private static final long serialVersionUID = 1192457210091910933L;

    Sync(int permits) {
        setState(permits);
    }

    final int getPermits() {
        return getState();
    }

    // 非公平尝试获取资源，注意此方法会自旋直到获取成功，或可用资源不够用，直接返回相减后的数量
    final int nonfairTryAcquireShared(int acquires) {
        // 自旋获取 permit
        for (;;) {
            // 获取当前可用的 permit 数量
            int available = getState();
            // 获取后的剩余数量
            int remaining = available - acquires;
            // remaining 大于等于 0 时，尝试 CAS 获取，成功则直接返回
            if (remaining &amp;lt; 0 ||
                    compareAndSetState(available, remaining))
                return remaining;
        }
    }

    // 归还资源，同样，此方法会自旋直至成功
    protected final boolean tryReleaseShared(int releases) {
        // 自旋释放 permit
        for (;;) {
            // 获取当前的 permit 数量
            int current = getState();
            // 归还 permit
            int next = current + releases;
            // 判断归还后是否溢出
            if (next &amp;lt; current) // overflow
                throw new Error(&amp;quot;Maximum permit count exceeded&amp;quot;);
            // CAS 归还
            if (compareAndSetState(current, next))
                return true;
        }
    }

    // 获取资源，注意此方法在 CAS 修改后直接返回。
    // 此方法在使用信号量来跟踪那些变为不可用资源的子类中很有用。
    // 此方法与 acquire 的不同之处在于它不会阻塞，等待 permit 可用。
    final void reducePermits(int reductions) {
        // 自旋减少 permit 
        for (;;) {
            int current = getState();
            int next = current - reductions;
            if (next &amp;gt; current) // underflow
                throw new Error(&amp;quot;Permit count underflow&amp;quot;);
            if (compareAndSetState(current, next))
                return;
        }
    }

    // 获取全部可用资源
    final int drainPermits() {
        for (;;) {
            int current = getState();
            if (current == 0 || compareAndSetState(current, 0))
                return current;
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;832-公平和非公平&#34;&gt;8.3.2 公平和非公平&lt;/h4&gt;
&lt;p&gt;非公平版：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;static final class NonfairSync extends Semaphore.Sync {
    private static final long serialVersionUID = -2694183684443567898L;

    NonfairSync(int permits) {
        super(permits);
    }

    protected int tryAcquireShared(int acquires) {
        return nonfairTryAcquireShared(acquires);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;公平版：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;static final class FairSync extends Sync {
    private static final long serialVersionUID = 2014338818796000944L;

    FairSync(int permits) {
        super(permits);
    }

    // 返回负数说明资源不够用
    protected int tryAcquireShared(int acquires) {
        // 自旋获取资源
        for (;;) {
            // 先判断队列中是否有等待阻塞的前驱节点
            if (hasQueuedPredecessors())
                return -1;
            int available = getState();
            int remaining = available - acquires;
            if (remaining &amp;lt; 0 ||
                    compareAndSetState(available, remaining))
                return remaining;
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;833-acquire-release&#34;&gt;8.3.3 acquire &amp;amp; release&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class Semaphore implements java.io.Serializable {
    private static final long serialVersionUID = -3222578661600680210L;
    /** All mechanics via AbstractQueuedSynchronizer subclass */
    private final Sync sync;

    /**
     * 使用给定数量的 permit 创建信号量，并设置为非公平。
     *
     * 参数：permits - 可用的 permit 的初始数量。该值可能为负数，在
     *                这种情况下，必须在任何 acquire 之前进行 release。
     */
    public Semaphore(int permits) {
        sync = new NonfairSync(permits);
    }

    /**
     * 创建具有给定 permit 数量和给定公平设置的 Semaphore 。
     *
     * 参数：permits - 可用的 permit 的初始数量。该值可能为负数，在
     *                这种情况下，必须在任何 acquire 之前进行 release。
     *      fair - 此信号量保证竞争 permit 的 acquire 为先进先出，则为 true；否则为 false
     */
    public Semaphore(int permits, boolean fair) {
        sync = fair ? new FairSync(permits) : new NonfairSync(permits);
    }

    /**
     * 从信号量获取一个 permit，阻塞直到获取一个可用，线程被中断则终止。
     * 
     * 获得一个 permit，如果有可用则立即返回，并将可用 permit 数量减一。
     *
     * 如果没有可用的 permit，则处于线程调度目的，当前线程将被禁用并处于休眠状态，直到
     * 发生以下两种情况下之一：
     * - 其他一些线程调用此信号量的 release 方法，并且当前线接下来获得一个 permit；或者
     * - 其他线程中断当前线程。
     *
     * 如果当前线程：
     * - 在进入此方法时设置其中断状态；或者
     * - 在等待过程中被中断。
     *
     * 然后抛出InterruptedException并清除当前线程的中断状态。
     *
     * @throws InterruptedException - 如果当前线程被中断。
     */
    public void acquire() throws InterruptedException {
        sync.acquireSharedInterruptibly(1);
    }

    /**
     * 从信号量获取一个 permit，阻塞直至获取一个可用。
     *
     * 获取一个 permit，如果存在可用会立即返回，并将可用 permit 减一。
     *
     * 如果没有可用的 permit，则处于线程调度目的，当前线程将被禁用并处于休眠状态，直到
     * 某个其他线程调用此信号量的 release 方法并且当前线程被分配到可用的 permit。
     *
     * 如果当前线程在等待 permit 时发生中断，那么它将继续等待，但线程被分配 permit 的
     * 时间与它在没有中断发生时收到 permit 的时间相比可能会发生变化。当线程从此方法返回
     * 时，将设置其中断状态。
     */
    public void acquireUninterruptibly() {
        sync.acquireShared(1);
    }

    /**
     * 仅当在调用时有可用的 permit 时，才从此信号量获取 permit。
     *
     * 获取一个 permit，如果存在一个可用则立即返回 true，并将可用 permit 的数量减一。
     *
     * 如果没有可用的 permit，则此方法将立即返回 false。
     *
     * 即使次信号量已设置为公平排序策略，对于 tryAcquire() 的调用也会立即获得
     * permit（如果可用），无论其他线程当前是否正在等待。这种“闯入”行为在某些情况下
     * 可能很有用，即使它破坏了公平性。如果要尊重公平设置，请使用几乎等效的
     * tryAcquire(0, TimeUnit.SECONDS)（它也会检测中断）。
     *
     * 返回：如果获得了 permit，则为 true；否则为 false。
     */
    public boolean tryAcquire() {
        return sync.nonfairTryAcquireShared(1) &amp;gt;= 0;
    }

    /**
     * 如果在给定超时时间内没有中断，且 permit 可用，则从信号量中获取一个 permit。
     *
     * 获取一个 permit，如果存在一个可用则立即返回 true，并将可用 permit 的数量减一。
     *
     * 如果没有可用的 permit，则处于线程调度目的，当前线程将被禁用并处于休眠状态，直到
     * 发生以下三种情况下之一：
     * - 其他一些线程调用此信号量的 release 方法，并且当前线接下来获得一个 permit；或者
     * - 其他线程中断当前线程；或者
     * - 超过指定的超时时间。
     *
     * 如果获得 permit，则返回 true。
     *
     * 如果当前线程：
     * - 在进入此方法时设置其中断状态；或者
     * - 在等待过程中被中断。
     *
     * 然后抛出InterruptedException并清除当前线程的中断状态。
     *
     * 如果经过指定的等待时间，则返回 false。如果时间小于等于零，则该方法不会等待。
     * 参数：timeout - 等待 permit 的最大时间
     *      unit - timeout 参数的时间单位
     * 返回：如果已经获得 permit，则为 true；如果获得之前超过等待时间，则为 false。
     * @throws InterruptedException - 如果当前线程被中断
     */
    public boolean tryAcquire(long timeout, TimeUnit unit)
            throws InterruptedException {
        return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout));
    }

    /**
     * 释放 permit，将其返回给信号量。
     *
     * 释放 permit，将可用 permit 数量加一。如果任何线程试图获取 permit，则选择一个
     * 线程给予刚释放的 permit。出于线程调度目的，该线程（重新）启用。
     *
     * 不要求线程必须先调用 acquire 获得 permit，之后才能 release 释放 permit。
     * 信号量的正确使用是通过应用程序中的编程约定建立的。
     */
    public void release() {
        sync.releaseShared(1);
    }

    /**
     * 从信号量中获取给定数量的 permits，阻塞直到有足够数量的 permits 可用，线程中断
     * 则终止。
     *
     * 获取给定数量的 permits，如果可用则立即返回 true，并将可用 permits 的数量减去
     * 给定的数量。
     *
     * 如果没有可用的 permits，或可用 permits 数量不足，则处于线程调度目的，当前线程将
     * 被禁用并处于休眠状态，直到发生以下量种情况下之一：
     * - 其他一些线程调用此信号量的 release 方法，并且当前线接下来获得足够数量的 permits；或者
     * - 其他线程中断当前线程。
     *
     * 如果当前线程：
     * - 在进入此方法时设置其中断状态；或者
     * - 在等待过程中被中断。
     *
     * 然后抛出InterruptedException并清除当前线程的中断状态。将分配给当前线程的 permits
     * 改为分配给尝试获取 permit 的其他线程，就好像通过调用 release() 使 permits 可用
     * 一样。
     *
     * 参数：permits - 获得的 permits 数量
     * @throws InterruptedException - 如果当前线程被中断
     * @throws IllegalArgumentException – 如果permits是负数
     */
    public void acquire(int permits) throws InterruptedException {
        if (permits &amp;lt; 0) throw new IllegalArgumentException();
        sync.acquireSharedInterruptibly(permits);
    }

    /**
     * 从信号量获取给定数量的 permits，阻塞直至所有的 permits 可用。
     *
     * 获取给定数量的 permits，如果存在可用会立即返回，并将可用 permits 减去给定数量。
     *
     * 如果没有可用的 permits，或可用的 permits 不足则处于线程调度目的，当前线程将被禁
     * 用并处于休眠状态，直到某个其他线程调用此信号量的 release 方法并且当前线程被分配
     * 到足够数量可用的 permits。
     *
     * 如果当前线程在等待 permits 时发生中断，那么它将继续等待，并且它在队列中的位置不受
     * 影响。当线程确实从此方法返回时，将设置其中断状态。
     *
     * 参数：permits - permits 数量
     * @throws IllegalArgumentException - 如果 permits 为负数
     */
    public void acquireUninterruptibly(int permits) {
        if (permits &amp;lt; 0) throw new IllegalArgumentException();
        sync.acquireShared(permits);
    }

    /**
     * 仅当调用时有给定数量的 permits 可用时，才从此信号量中获取到给定数量的 permits。
     *
     * 获取给定数量的 permits，如果存在可用会立即返回，并将可用 permit 减去给定数量。
     * 
     * 如果可用的 permits 不足，则此方法立即返回 false，并且可用 permits 数量不变。
     *
     * 即使次信号量已设置为公平排序策略，对于 tryAcquire() 的调用也会立即获得
     * permit（如果可用），无论其他线程当前是否正在等待。这种“闯入”行为在某些情况下
     * 可能很有用，即使它破坏了公平性。如果要尊重公平设置，请使用几乎等效的
     * tryAcquire(permits, 0, TimeUnit.SECONDS)（它也会检测中断）。
     *
     * 参数：permits - 获取的 permits 数量
     * 返回：如果获得了 permit，则为 true，否则为 false
     * @throws IllegalArgumentException - 如果 permits 为负数
     */
    public boolean tryAcquire(int permits) {
        if (permits &amp;lt; 0) throw new IllegalArgumentException();
        return sync.nonfairTryAcquireShared(permits) &amp;gt;= 0;
    }

    /**
     * 如果在给定超时时间内没有中断，且有足够的 permits 可用，则从信号量中获取 permits。
     *
     * 获取给定数量的 permits，如果存在足够数量可用则立即返回 true，并将可用 permits 的
     * 数量减去给定数值。
     *
     * 如果没有足够可用的 permits，则处于线程调度目的，当前线程将被禁用并处于休眠状态，直到
     * 发生以下三种情况下之一：
     * - 其他一些线程调用此信号量的 release 方法，并且当前线接下来获得足够数量 permits；或者
     * - 其他线程中断当前线程；或者
     * - 超过指定的超时时间。
     *
     * 如果获得 permits，则返回 true。
     *
     * 如果当前线程：
     * - 在进入此方法时设置其中断状态；或者
     * - 在等待过程中被中断。
     *
     * 然后抛出InterruptedException并清除当前线程的中断状态。将分配给当前线程的 permits
     * 改为分配给尝试获取 permit 的其他线程，就好像通过调用 release() 使 permits 可用
     * 一样。
     *
     * 如果经过指定的等待时间，则返回 false。如果时间小于等于零，则该方法不会等待。
     * 参数：permits - 获得的 permits 数量
     *      timeout - 等待 permit 的最大时间
     *      unit - timeout 参数的时间单位
     * 返回：如果已经获得 permits，则为 true；如果获得之前超过等待时间，则为 false。
     * @throws InterruptedException - 如果当前线程被中断
     * @throws IllegalArgumentException - 如果 permits 为负数
     */
    public boolean tryAcquire(int permits, long timeout, TimeUnit unit)
            throws InterruptedException {
        if (permits &amp;lt; 0) throw new IllegalArgumentException();
        return sync.tryAcquireSharedNanos(permits, unit.toNanos(timeout));
    }

    /**
     * 释放给定数量的 permits，将其返回给信号量。
     *
     * 释放给定数量的 permits，将可用 permits 数量加上改数量。如果任何线程试图获取
     * permit，则选择一个线程给予刚释放的 permits。如果可用 permits 的数量满足该
     * 线程的要求，处于线程调度目的，该线程（重新）启用；否则线程将等待直到有足够的
     * permits 可用。如果在满足该线程的请求后仍然有可用的 permits，则这些 permits
     * 将依次分配给试图获取 permits 的线程。
     *
     * 不要求线程必须先调用 acquire 获得 permits 之后才能 release 释放 permits。
     * 信号量的正确使用是通过应用程序中的编程约定建立的。
     *
     * 参数：permits - 释放的 permits 数量
     * @throws IllegalArgumentException - permits 为负数
     */
    public void release(int permits) {
        if (permits &amp;lt; 0) throw new IllegalArgumentException();
        sync.releaseShared(permits);
    }

    /**
     * 返回此信号量当前可用的 permits 数量。
     *
     * 此方法通常用于调试和测试。
     *
     * 返回：此信号量中可用的 permit 数量
     */
    public int availablePermits() {
        return sync.getPermits();
    }

    /**
     * 获取并返回当前所有的 permits。
     *
     * 返回：获得的 permits 数量
     */
    public int drainPermits() {
        return sync.drainPermits();
    }

    /**
     * 按照指定的 reduction 减少可用 permits 数量。此方法在使用信号量来跟踪
     * 子类中资源变得不可用情况会很有用。此方法与 acquire 的不同之处在于它不会
     * 阻塞等待 permits 可用。
     *
     * 参数：reduction - 移除的 permits 数量
     * @throws IllegalArgumentException - 如果 reduction 为负数
     */
    protected void reducePermits(int reduction) {
        if (reduction &amp;lt; 0) throw new IllegalArgumentException();
        sync.reducePermits(reduction);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其他一些用于监控的非核心方法不再展示。&lt;/p&gt;
&lt;h3 id=&#34;84-countdownlatch&#34;&gt;8.4 CountDownLatch&lt;/h3&gt;
&lt;p&gt;一种同步辅助工具，允许一个或多个线程等待，知道在其他线程中执行的一组操作完成。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;CountDownLatch&lt;/code&gt; 使用给定的 &lt;em&gt;计数（count）&lt;/em&gt; 进行初始化。调用 &lt;code&gt;await&lt;/code&gt; 方法将会一直阻塞，直到调用 &lt;code&gt;countDown&lt;/code&gt; 方法将当前计数减少到零，只有所有等待的线程都被释放，任何后续的 &lt;code&gt;await&lt;/code&gt; 方法调用将会立即返回。这是一次性使用的现象——计数是无法重置的。如果你需要能够重置计数的版本，请考虑使用 &lt;code&gt;CyclicBarrier&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;CountDownLatch&lt;/code&gt; 是一种多功能同步工具，可用于多种用途。使用计数 1 初始化的 &lt;code&gt;CountDownLatch&lt;/code&gt; 可以用作简单的开/关闩锁：所有调用 &lt;code&gt;await&lt;/code&gt; 方法的线程都将在门处等待，直到它被调用 &lt;code&gt;countDown&lt;/code&gt; 方法线程打开门。初始化为 N 的 &lt;code&gt;CountDownLatch&lt;/code&gt;  可用于使一个线程等待，直到 N 个线程完成某个动作，或某个动作完成 N 次。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;CountDownLatch&lt;/code&gt; 的一个有用属性是它不需要调用 &lt;code&gt;countDown&lt;/code&gt; 的线程等待计数变为零才能继续，它只是阻塞调用 &lt;code&gt;await&lt;/code&gt; 方法的线程，直到所有线程都可以通过。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;示例用法：&lt;/strong&gt; 这是一对类，其中一组工作线程使用两个 &lt;code&gt;CountDownLatch&lt;/code&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第一个是启动信号，它阻塞任何 worker 继续前进，直到 driver 准备好让他们继续。&lt;/li&gt;
&lt;li&gt;第二个是完成信号，允许 driver 程序等待所有 worker 完成。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;class Driver {
  void main() throws InterruptedException {
    CountDownLatch startSignal = new CountDownLatch(1);
    CountDownLatch doneSignal = new CountDownLatch(N);
    
    for (int i = 0; i &amp;lt; N; ++i) { // create and start threads
      new Thread(new Worker(startSignal, doneSignal)).start();
    }
    
    doSomethingElse(); // don&#39;t let run yet
    startSignal.countDown(); // let all threads proceed
    doSomethingElse(); 
    doSignal.await(); // wait for all to finish
  }
}

class Worker implements Runnable {
  private final CountDownLatch startSignal;
  private final CountDownLatch doneSignal;
  Worker(CountDownLatch startSignal, CountDownLatch doneSignal) {
    this.startSignal = startSignal;
    this.doneSignal = doneSignal;
  }
  
  public void run() {
    try {
      startSignal.await();
      doWork();
      doneSignal.countDown();
    } catch (InterruptedException ex) {} //return;
  }
  
  void doWork() { ... }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;另一个典型的用法是将一个问题分成 N 个部分，用一个 &lt;code&gt;Runnable&lt;/code&gt; 描述每个部分，该 &lt;code&gt;Runnable&lt;/code&gt; 执行该部分并在完成后进行 &lt;code&gt;countDown&lt;/code&gt; 操作，并将所有 &lt;code&gt;Runnables&lt;/code&gt; 排队到一个 &lt;code&gt;Executor&lt;/code&gt;。当所有的子任务执行完成后，协调线程就可以在 &lt;code&gt;await&lt;/code&gt; 状态中被释放。（当线程必须以这种方式重复使用 &lt;code&gt;countDown&lt;/code&gt; 时，请改用 &lt;code&gt;CyclicBarrier&lt;/code&gt;）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;class Driver2 { // ...
  void main() throws InterruptedException {
    CountDownLatch doneSignal = new CountDownLatch(N);
    Executor e = ...
    
    for (int i = 0; i &amp;lt; N; ++i) { // create and start threads
      e.execute(new WorkerRunnable(doneSignal, i));
    }
    
    doneSignal.await(); // wait for all to finish
  }
}

class WorkRunnable implements Runnable {
  private final CountDownLatch doneSignal;
  private final int i;
  WorkerRunnable(CountDownLatch doneSignal, int i) {
    this.doneSignal = doneSignal;
    this.i = i;
  }
  
  public void run() {
    try {
      doWork(i);
      doneSignal.countDown();
    } catch (InterruptedException ex) {} // return;
  }
  
  void doWork() { ... }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;内存一致性影响：直到计数到达零，调用 &lt;code&gt;countDown()&lt;/code&gt; 之前的线程中的动作 &lt;code&gt;happen-before&lt;/code&gt; 在另一个线程中从相应的 &lt;code&gt;await()&lt;/code&gt; 成功返回之后的动作。&lt;/p&gt;
&lt;h4 id=&#34;841-sync&#34;&gt;8.4.1 Sync&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;CountDownLatch&lt;/code&gt; 的同步控制。使用 &lt;code&gt;AQS&lt;/code&gt; 状态来表示计数&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;private static final class Sync extends AbstractQueuedSynchronizer {
    private static final long serialVersionUID = 4982264981922014374L;

    Sync(int count) {
        setState(count);
    }

    int getCount() {
        return getState();
    }

    protected int tryAcquireShared(int acquires) {
        return (getState() == 0) ? 1 : -1;
    }

    protected boolean tryReleaseShared(int releases) {
        // Decrement count; signal when transition to zero
        for (;;) {
            int c = getState();
            if (c == 0)
                return false;
            int nextc = c-1;
            // CAS 递减，为零返回 true
            if (compareAndSetState(c, nextc))
                return nextc == 0;
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;842-await-countdown&#34;&gt;8.4.2 await &amp;amp; countDown&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class CountDownLatch {
    private final Sync sync;

    /**
     * 使用给定的计数初始化 CountDownLatch。
     *
     * 参数：count - 在线程可以通过 await 之前必须调用 countDown 的次数
     * @throws IllegalArgumentException - 如果 count 为负数
     */
    public CountDownLatch(int count) {
        if (count &amp;lt; 0) throw new IllegalArgumentException(&amp;quot;count &amp;lt; 0&amp;quot;);
        this.sync = new Sync(count);
    }

    /**
     * 阻塞当前线程，使其等待，直到 CountDownLatch 计数器为零，线程中断则终止。
     *
     * 如果当前计数为零，则此方法立即返回。
     *
     * 如果当前计数大于零，出于线程调度目的，当前线程将被禁用并处于休眠状态，直到以下
     * 两种情况下之一发生：
     * - 由于调用了 countDown 方法，计数达到零；或者
     * - 其他一些线程中断当前线程。
     *
     * 如果当前线程：
     * - 在进入此方法时设置其中断状态；或者
     * - 等待过程中被中断。
     *
     * 然后抛出InterruptedException并清除当前线程的中断状态。
     *
     * @throws InterruptedException - 如果当前线程在等待中被中断
     */
    public void await() throws InterruptedException {
        sync.acquireSharedInterruptibly(1);
    }

    /**
     *
     * 阻塞当前线程，使其等待，直到 CountDownLatch 计数器为零，或到达指定的等待时间，
     * 线程中断则终止。
     *
     * 如果当前计数为零，则此方法立即返回 true。
     *
     * 如果当前计数大于零，出于线程调度目的，当前线程将被禁用并处于休眠状态，直到以下
     * 三种情况下之一发生：
     * - 由于调用了 countDown 方法，计数达到零；或者
     * - 其他一些线程中断当前线程；或者
     * - 达到指定的等待时间。
     * 
     * 如果计数到达零，则该方法返回 true。
     *
     * 如果当前线程：
     * - 在进入此方法时设置其中断状态；或者
     * - 等待过程中被中断。
     *
     * 然后抛出InterruptedException并清除当前线程的中断状态。
     * 
     * 如果经过了指定的等待时间，则返回 false。如果时间小于或等于零，则该方法不会等待。
     * 
     * 
     * 参数：timeout - 等待的最长时间
     *      unit - timeout参数的单位
     * 返回：如果计数到达零，则返回 true；如果在计数到达零之前超过的等待时间，则返回 false
     * @throws InterruptedException - 如果当前线程在等待中被中断
     */
    public boolean await(long timeout, TimeUnit unit)
            throws InterruptedException {
        return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout));
    }

    /**
     * 减少 CountDownLatch 的计数，如果计数达到零，则释放所有等待线程。
     *
     * 如果当前计数大于零，则递减。如果新计数为零，出于线程调度重启所有等待线程。
     *
     * 如果当前计数为零，则不会发生任何事情。
     */
    public void countDown() {
        sync.releaseShared(1);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;85-cyclicbarrier&#34;&gt;8.5 CyclicBarrier&lt;/h3&gt;
&lt;p&gt;一种同步辅助工具，它允许一组线程相互等待以达到共同的障碍点。&lt;code&gt;CyclicBarriers&lt;/code&gt; 在涉及固定大小的线程组的程序中很有用，这些线程组必须偶尔相互等待。屏障被称为 &lt;code&gt;循环（Cyclic）&lt;/code&gt; 的，因为它们可以在等待线程被释放后重新使用。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;CyclicBarrier&lt;/code&gt; 支持一个可选的 &lt;code&gt;Runnable&lt;/code&gt; 命令，该命令在每个屏障点运行一次，在最后一个线程到达之后，但是在任何线程被释放之前。此屏障操作对于在任何一方继续执行之前更新共享状态很有用。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;示例用法：&lt;/strong&gt; 以下是在并行分解设计中使用屏障的示例：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;class Solver {
  final int N;
  final float[][] data;
  final CyclicBarrier barrier;
  
  class Worker implements Runnable {
    int myRow;
    Worker(int row) { myRow = row; }
    public void run() {
      while (!done()) {
        processRow(myRow);
        
        try {
          barrier.await();
        } catch (InterruptedException ex) {
          return;
        } catch (BrokenBarrierException ex) {
          return;
        }
      }
    }
  }
  
  public Solver(float[][] matrix) {
    data = matrix;
    N = matrix.length;
    Runnable barrierAction = new Runnable() {
      public void run() {
        margeRows(...);
      }
    };
    barrier = new CyclicBarrier(N, barrierAction);
    
    List&amp;lt;Thread&amp;gt; threads = new ArrayList&amp;lt;Thread&amp;gt;(N);
    for (int i = 0; i &amp;lt; N; i++) {
      Thread thread = new Thread(new Worker(i));
      threads.add(thread);
      thread.start();
    }
    
    // wait until done
    for (Thread thread : threads) {
      thread.join();
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在这里，每个工作线程处理矩阵的一行，然后在屏障处等待，直到处理完所有行。处理完所有行后，将执行提供的 &lt;code&gt;Runnable&lt;/code&gt; 屏障操作，合并矩阵行。如果合并已经确定完成，那 &lt;code&gt;done()&lt;/code&gt; 方法会返回 true ，每个工作线程将会终止。&lt;/p&gt;
&lt;p&gt;如果 barrier action 在执行时不依赖于被挂起的各个线程，那么该方法中的任何线程都可以在它被释放时执行该动作。为了方便起见，每次调用 &lt;code&gt;await&lt;/code&gt; 都会返回该线程在屏障处到达的索引。然后，您可以选择那个线程应该执行 barrier action，例如：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;if (barrier.await() == 0) {
  // log the completion of this iteration
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;CyclicBarrier&lt;/code&gt; 对失败的同步尝试使用 &lt;code&gt;all-or-none&lt;/code&gt; 模型：如果线程由于中断、故障或超时而过早地离开屏障点，则在该屏障点等待的所有其他线程也会通过 &lt;code&gt;BrokenBarrierException&lt;/code&gt;（或者如果它们也在同时被中断，抛出&lt;code&gt;InterruptedException&lt;/code&gt; ）。&lt;/p&gt;
&lt;p&gt;内存一致性效果：在调用 &lt;code&gt;await()&lt;/code&gt; 之前线程中的操作 happen-before 作为 barrier action 的一部分的操作，而这些操作又 happen-before 从其他线程中的相应 &lt;code&gt;await()&lt;/code&gt; 成功返回之后的操作。&lt;/p&gt;
&lt;h4 id=&#34;851-generation&#34;&gt;8.5.1 Generation&lt;/h4&gt;
&lt;p&gt;屏障的每次使用都会表现为 &lt;code&gt;generation&lt;/code&gt; 实例。每当屏障被触发或重置时，&lt;code&gt;generation&lt;/code&gt; 就会发生变化。可能有许多 &lt;code&gt;generation&lt;/code&gt; 与使用屏障的线程相关联 —— 由于锁定可能会以不确定的方式分配给等待线程 —— 但一次只能使其中一个 &lt;code&gt;generation&lt;/code&gt; 处于活动状态（count 使用的那个）并且所有其余的线程要么 broken，要么 trip（可能是指阻塞？）。如果有中断带没有后续重置，则不需要活动的 &lt;code&gt;generation&lt;/code&gt;。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;private static class Generation {
    boolean broken = false;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;852-实现详解&#34;&gt;8.5.2 实现详解&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class CyclicBarrier {

    // 忽略 Generation Class

    /** 用户保护屏障入口的锁 */
    private final ReentrantLock lock = new ReentrantLock();
    /** 等待直到 triped 的 condition */
    private final Condition trip = lock.newCondition();
    /** 分片数量 */
    private final int parties;
    /* tripped 时执行的命令 */
    private final Runnable barrierCommand;
    /** 当前 generation */
    private Generation generation = new Generation();

    /**
     * 仍在等待的 parties 数量。每个 generation 都会讲 parties 减少到 0。
     * 每次生成新的 generation 或 broken 时会重置。
     */
    private int count;

    /**
     * 更新屏障 trip 状态，并唤醒全部。只有当持有锁才可以调用。
     */
    private void nextGeneration() {
        // signal completion of last generation
        trip.signalAll();
        // set up next generation
        count = parties;
        generation = new Generation();
    }

    /**
     * 设置当前的 generation 为 broken，并唤醒全部。只有当持有锁才可以调用。
     */
    private void breakBarrier() {
        generation.broken = true;
        count = parties;
        trip.signalAll();
    }

    /**
     * 屏障的主要代码，涵盖各种策略。
     */
    private int dowait(boolean timed, long nanos)
        throws InterruptedException, BrokenBarrierException,
               TimeoutException {
        // 屏障入口，先获得锁
        final ReentrantLock lock = this.lock;
        lock.lock();
        try {
            // 获取当前的 generation
            final Generation g = generation;

            // 判断当前是否 broken，抛出异常
            if (g.broken)
                throw new BrokenBarrierException();

            // 判断线程是否中断
            if (Thread.interrupted()) {
                breakBarrier();
                throw new InterruptedException();
            }

            // 获取当前索引
            int index = --count;
            // 当最后一个任务到达 await 屏障点时，则执行 command
            if (index == 0) {  // tripped
                // 是否执行命令，执行失败（抛出异常）则跳出等待
                boolean ranAction = false;
                try {
                    final Runnable command = barrierCommand;
                    if (command != null)
                        command.run();
                    ranAction = true;
                    // 下一个 generation，也就是重置屏障
                    nextGeneration();
                    return 0;
                } finally {
                    if (!ranAction)
                        breakBarrier();
                }
            }

            // 说明不是最后一个到达屏障的任务，需要阻塞
            // loop until tripped, broken, interrupted, or timed out
            for (;;) {
                try {
                    // 如果没有超时，则直接阻塞；存在超时时间使用超时阻塞
                    // condition 的 await 会进行 fullyRelease，释放持有的锁
                    if (!timed)
                        trip.await();
                    else if (nanos &amp;gt; 0L)
                        nanos = trip.awaitNanos(nanos);
                } catch (InterruptedException ie) {
                    // 如果当前 generation 没有被其他线程改变，且中断
                    if (g == generation &amp;amp;&amp;amp; ! g.broken) {
                        // 中断屏障
                        breakBarrier();
                        throw ie;
                    } else {
                        // 即使我们没有被中断，我们也即将完成等待，所以这个中断
                        // 被认为是 “属于” 后续执行的。
                        Thread.currentThread().interrupt();
                    }
                }

                if (g.broken)
                    throw new BrokenBarrierException();

                // generation 已经更换
                if (g != generation)
                    return index;

                // 超时则中断屏障
                if (timed &amp;amp;&amp;amp; nanos &amp;lt;= 0L) {
                    breakBarrier();
                    throw new TimeoutException();
                }
            }
        } finally {
            lock.unlock();
        }
    }

    /**
     * 创建一个新的 CyclicBarrier，当给定数量的 parties （线程）正在等待它时，
     * 它将触发继续执行，他将执行给定的 barrierAction，由最后一个进入屏障的线程
     * 执行。
     *
     * 参数：parties - 在屏障被触发之前必须调用 await 的线程数
     *      barrierAction - 当屏障被触发时执行的命令，如果没有动作则为 null
     * @throws IllegalArgumentException - 如果 parties 小于 1
     */
    public CyclicBarrier(int parties, Runnable barrierAction) {
        if (parties &amp;lt;= 0) throw new IllegalArgumentException();
        this.parties = parties;
        this.count = parties;
        this.barrierCommand = barrierAction;
    }

    /**
     * 创建一个新的 CyclicBarrier，当给定数量的 parties （线程）正在等待它时，
     * 它将触发继续执行，在触发屏障继续执行时不执行预定义操作。
     *
     * 参数：parties - 在屏障被触发之前必须调用 await 的线程数
     *      barrierAction - 当屏障被触发时执行的命令，如果没有动作则为 null
     * @throws IllegalArgumentException - 如果 parties 小于 1
     */
    public CyclicBarrier(int parties) {
        this(parties, null);
    }

    /**
     * 返回触发次屏障所需的 parties 数量。
     *
     * 返回：打破此屏障需要的 parties 数量。
     */
    public int getParties() {
        return parties;
    }

    /**
     * 等到所有 parties 都在此屏障上调用 await。
     *
     * 如果当前线程不是最后到达的，处于线程调度目的，将其禁用并处于休眠状态，
     * 直到发生以下情况之一：
     * - 最后一个线程到达；或者
     * - 其他线程中断当前线程；或者
     * = 其他线程中断了任意等待线程；或者
     * - 其他线程在等待屏障时超时；或者
     * - 其他一些线程调用此屏障的 reset 方法。
     *
     * 如果当前线程：
     * - 在进入此方法时设置其中断状态；或者
     * - 等待过程中被中断
     *
     * 然后抛出 InterruptedException 并清除当前线程的中断状态。
     *
     * 如果在任何线程等待时调用屏障的 reset 方法，或者在调用 await 或在任何线程
     * 在等待时屏障时，isBroken() 为 true，则抛出 BrokenBarrierException。
     *
     * 如果任何线程在等待时被中断，那么所有其他等待的线程都会抛出 BrokenBarrierException
     * 并将屏障的 generation 的 broken 状态设置为 true。
     *
     * 如果当前线程是最后到达的线程，并且在构造函数中提供了非空的 barrierAction，则允许当前
     * 在继续之前先执行 barrierAction 操作。如果在屏障操作期间发生了异常，则该异常将在当前
     * 线程中传播，并且屏障处于 broken 状态。
     *
     * 返回：当前线程的到达索引，其中索引 getParties - 1 表示第一个到达，0表示最后一个到达
     * @throws InterruptedException - 如果当前线程在等待时被中断
     * @throws BrokenBarrierException - 如果另一个线程在当前线程等待时中断或超时，或者
     *                                  屏障被重置，或者在调用 await 时屏障被破坏，或者
     *                                  barrierAction （如果存在） 由于异常失败
     */
    public int await() throws InterruptedException, BrokenBarrierException {
        try {
            return dowait(false, 0L);
        } catch (TimeoutException toe) {
            throw new Error(toe); // cannot happen
        }
    }

    /**
     * 等到所有 parties 都在此屏障上调用 await，或达到指定的超时时间。
     *
     * 如果当前线程不是最后到达的，处于线程调度目的，将其禁用并处于休眠状态，
     * 直到发生以下情况之一：
     * - 最后一个线程到达；或者
     * - 到达指定的超时时间；或者
     * - 其他线程中断当前线程；或者
     * = 其他线程中断了任意等待线程；或者
     * - 其他线程在等待屏障时超时；或者
     * - 其他一些线程调用此屏障的 reset 方法。
     *
     * 如果当前线程：
     * - 在进入此方法时设置其中断状态；或者
     * - 等待过程中被中断
     *
     * 然后抛出 InterruptedException 并清除当前线程的中断状态。
     *
     * 如果到达指定的超时时间，则抛出 TimeoutException。如果时间小于或等于零，则
     * 该方法不会等待。
     *
     * 如果在任何线程等待时调用屏障的 reset 方法，或者在调用 await 或在任何线程
     * 在等待时屏障时，isBroken() 为 true，则抛出 BrokenBarrierException。
     *
     * 如果任何线程在等待时被中断，那么所有其他等待的线程都会抛出 BrokenBarrierException
     * 并将屏障的 generation 的 broken 状态设置为 true。
     *
     * 如果当前线程是最后到达的线程，并且在构造函数中提供了非空的 barrierAction，则允许当前
     * 在继续之前先执行 barrierAction 操作。如果在屏障操作期间发生了异常，则该异常将在当前
     * 线程中传播，并且屏障处于 broken 状态。
     *
     * 参数：timeout - 等待屏障的时间
     *       unit - timeout 的单位
     * 返回：当前线程的到达索引，其中索引 getParties - 1 表示第一个到达，0表示最后一个到达
     * @throws InterruptedException - 如果当前线程在等待时被中断
     * @throws TimeoutException - 如果到达指定的超时时间。在这种情况下，屏障将被 broken。
     * @throws BrokenBarrierException - 如果另一个线程在当前线程等待时中断或超时，或者
     *                                  屏障被重置，或者在调用 await 时屏障被破坏，或者
     *                                  barrierAction （如果存在） 由于异常失败
     */
    public int await(long timeout, TimeUnit unit)
        throws InterruptedException,
               BrokenBarrierException,
               TimeoutException {
        return dowait(true, unit.toNanos(timeout));
    }

    /**
     * 查询当前屏障是否处于 broken 状态。
     *
     * 返回：一个或多个 parties 在上次屏障重置后，由于超时或中断而使此屏障 broken，
     *      或者由于异常而导致 barrierAction 失败，则为 true；否则为 false。
     */
    public boolean isBroken() {
        final ReentrantLock lock = this.lock;
        lock.lock();
        try {
            return generation.broken;
        } finally {
            lock.unlock();
        }
    }

    /**
     * 将屏障重置为初始状态。如果任何 parties 在当前屏障处等待，他们将返回 BrokenBarrierException。
     * 请注意，由于其他原因发生 broken 后的重置可能会很复杂；线程需要以其他方式重新同步，并选择一个
     * 线程执行 reset 操作。相反，最好为后续使用创建一个新的屏障。
     */
    public void reset() {
        final ReentrantLock lock = this.lock;
        lock.lock();
        try {
            breakBarrier();   // break the current generation
            nextGeneration(); // start a new generation
        } finally {
            lock.unlock();
        }
    }

    /**
     * 返回当前在屏障处等待的 parties 数量。此方法主要用于调试和断言。
     *
     * 返回，当前在 await 中被阻塞的 parties 数量
     */
    public int getNumberWaiting() {
        final ReentrantLock lock = this.lock;
        lock.lock();
        try {
            return parties - count;
        } finally {
            lock.unlock();
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
">理解同步器框架AbstractQueuedSynchronizer</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://wenbozhangw.github.io/post/lesslessthe-javautilconcurrent-synchronizer-frameworkgreatergreater-yuan-wen-fan-yi/"" data-c="
          &lt;h2 id=&#34;摘要&#34;&gt;摘要&lt;/h2&gt;
&lt;p&gt;在 J2SE1.5 的 &lt;code&gt;java.util.concurrent&lt;/code&gt;包（下面简称为 &lt;code&gt;j.u.c&lt;/code&gt; 包 ）中，大多数的同步器（例如锁、栅栏等。）都是使用基于 &lt;code&gt;AbstractQueuedSynchronizer&lt;/code&gt;类（下面简称为 &lt;code&gt;AQS&lt;/code&gt; 类），这个简单的小型框架构建的。这个框架提供了原子管理同步状态、线程的阻塞和解除阻塞、以及排队的通用机制。本文描述了该框架的基本原理、设计、实现、使用和性能。&lt;/p&gt;
&lt;!-- more --&gt;
&lt;h2 id=&#34;类别和主题描述符&#34;&gt;类别和主题描述符&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;D.1.3 [编程技术]&lt;/strong&gt;：并发编程 —— 并行编程&lt;/p&gt;
&lt;h2 id=&#34;一般术语&#34;&gt;一般术语&lt;/h2&gt;
&lt;p&gt;算法、策略、性能、设计。&lt;/p&gt;
&lt;h2 id=&#34;关键字&#34;&gt;关键字&lt;/h2&gt;
&lt;p&gt;同步，Java&lt;/p&gt;
&lt;h2 id=&#34;1-介绍&#34;&gt;1. 介绍&lt;/h2&gt;
&lt;p&gt;Java&lt;sup&gt;TM&lt;/sup&gt; 发布版本 J2SE-1.5 引入了 &lt;code&gt;j.u.c&lt;/code&gt; 包，这是通过 JCP （Java社区进程）的 JSR（Java规范请求）166 规范创建的，这个包提供了支持中等并发成都的并发类合集。这些组件包括一组&lt;em&gt;同步器&lt;/em&gt;——维护内部&lt;em&gt;同步状态&lt;/em&gt;（例如，表示锁的状态是获取还是释放）的抽象数据类型（ADT）类、更新和检查该状态的操作。以及至少会有一个方法会导致调用现存在同步状态被获取时阻塞，并在其他线程更改同步状态时解除阻塞。实例包括各种形式的互斥锁、读写锁、信号量、屏障、Future、时间指示器和传送队列等（exclusion locks, read-write locks, semaphores, barriers, futures, event indicators, and handoff queues）。&lt;/p&gt;
&lt;p&gt;众所周知，几乎任何同步器都可以用于实现其他形式的同步器。例如，可以用可重入锁实现信号量，反之亦然。然而，这样做通常会增加复杂性、开销和不灵活性，使其至多只能是个二流工程。且缺乏吸引力。此外，它在概念上没有吸引力。如果任何这样的构造方式不能在本质上比其他形式更简洁，那么开发者就不应该随意地选择其中的某个来作为基础构建另一个同步器。取而代之，JSR166 建立了一个以 &lt;code&gt;AQS&lt;/code&gt; 类为中心的小型框架，它为用户自定构造器以及&lt;code&gt;j.u.c&lt;/code&gt; 包中大多数提供的同步器提供了一种通用的机制。&lt;/p&gt;
&lt;p&gt;本文的其余部分将讨论该框架的需求、设计和实现背后的主要思想、示例用法以及一些性能指标的测量。&lt;/p&gt;
&lt;h2 id=&#34;2-需求&#34;&gt;2 需求&lt;/h2&gt;
&lt;h3 id=&#34;21-功能&#34;&gt;2.1 功能&lt;/h3&gt;
&lt;p&gt;同步器有一般包含两种方法：一种是 &lt;code&gt;acquire&lt;/code&gt; 操作 ，用于阻塞调用的线程，除非/直到同步状态允许它继续；另一种是 &lt;code&gt;release&lt;/code&gt; 操作，用于通过某种方式改变同步状态，以允许一个或多个被 &lt;code&gt;acquire&lt;/code&gt; 的线程解除阻塞。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;j.u.c&lt;/code&gt; 包没有为同步器定义一个统一的 API。有些是通过公共接口定义的（例如，Lock），而另外一些则定义了其特有的版本。因此，在不同的类中，&lt;code&gt;acquire&lt;/code&gt; 和 &lt;code&gt;release&lt;/code&gt; 操作的名字和形式会有不同。例如：&lt;code&gt;Lock.lock&lt;/code&gt;、&lt;code&gt;Semaphore.acquire&lt;/code&gt;、&lt;code&gt;CountDownLatch.await&lt;/code&gt; 和 &lt;code&gt;FutureTask.get&lt;/code&gt;，在这个框架里，这些方法都是 &lt;code&gt;acquire&lt;/code&gt; 操作。但是，&lt;code&gt;j.u.c&lt;/code&gt;包确实保持了跨类的一致约定，以支持一系列常见的使用选项。如果有意义，每个同步器都支持以下操作：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;非阻塞同步尝试（例如，&lt;code&gt;tryLock&lt;/code&gt;）以及阻塞版本。&lt;/li&gt;
&lt;li&gt;可选超时，因此应用程序可以放弃等待。&lt;/li&gt;
&lt;li&gt;通过中断实现任务取消，通常分为可取消的 &lt;code&gt;acquire&lt;/code&gt; 版本和不可取消的 &lt;code&gt;acquire&lt;/code&gt; 版本。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;同步器可能根据它们是否管理  &lt;em&gt;exclusive&lt;/em&gt; 状态 （一次只有一个线程可以通过阻塞点）和可能的 &lt;em&gt;shared&lt;/em&gt; 状态（多个线程至少在某些情况下可以继续）而有所不同。当然，常规的锁类往往只维护 &lt;em&gt;exclusive&lt;/em&gt; 状态，但是计数信号量在数量许可的情况下，允许多个线程同时执行。为了使框架使用能够更加广泛，这两种模式都要支持。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;j.u.c&lt;/code&gt; 包还定义了 &lt;code&gt;Condition&lt;/code&gt; 接口，用于支持监控形式的 await/singal 操作，这些操作可能与独占的 &lt;code&gt;Lock&lt;/code&gt; 类相关联，并且其本质上与其相关 &lt;code&gt;Lock&lt;/code&gt; 类交织在一起。&lt;/p&gt;
&lt;h3 id=&#34;22-性能目标&#34;&gt;2.2 性能目标&lt;/h3&gt;
&lt;p&gt;Java 内置锁（使用 &lt;code&gt;synchronized&lt;/code&gt; 的方法或代码块）的性能问题长期以来一直被人们关注，有关它们的构造有相当多的文献（例如，[&lt;a href=&#34;#1&#34;&gt;1&lt;/a&gt;]、[&lt;a href=&#34;#3&#34;&gt;3&lt;/a&gt;] ）。然而，大部分的研究主要关注的是在单核处理器上，大部分时间使用与单线程上下文环境中，如何尽量降低其空间（因为任何 Java 对象都可以充当锁）和时间的开销。对于同步器来说，这两个都不是特别重要的问题：程序员仅在需要的时候才会使用同步器，因此并不需要压缩空间来避免浪费，并且同步器几乎只用于多线程设计（特别是在多核处理器上），在这种设计下，偶尔的竞争是在意料之中的。因此，常规的 JVM 锁优化策略主要是针对零竞争的场景，而其他场景则使用缺乏可预测的”慢速路径（slow paths）“[&lt;a href=&#34;#12&#34;&gt;12&lt;/a&gt;]，对于严重依赖 &lt;code&gt;j.u.c&lt;/code&gt; 的典型多线程服务器应用程序来说，这不是正确的策略选择。&lt;/p&gt;
&lt;p&gt;相反，这里的主要性能目标是可伸缩性：即使在同步器发生竞争的情况下，也要可预测地保持效率。理想情况下，不管有多少线程试图通过同步点，通过同步点所需的开销应该是恒定的。其中一个主要目标是，在某一线程被允许通过同步点但还没有通过的情况下，使其耗费的总时间最少。但是，者必须与资源考虑相平衡，包括总的 CPU 时间需求、内存流量和线程调度开销。例如，自旋锁通常比阻塞锁所需要的时间更短，但是通常也会浪费 CPU 时钟周期，并且造成内存竞争，因此通常不适用。&lt;/p&gt;
&lt;p&gt;实现同步器的这些目标包含了两种不同的使用类型。大多数应用程序应该最大限度地提高总吞吐量和容错性，并且最好保证尽量减少接的情况。然而，对于那些控制资源分配的程序来说，更重要的是去维持多线程读取的公平性，可以接受较差的总吞吐量。没有框架能够代表用户在这些冲突的目标之前做出决定；相反，必须适应不同的公平策略。&lt;/p&gt;
&lt;p&gt;无论同步器内部设计得多么好，在某些应用程序中都会产生性能瓶颈。因此，框架必须能够监控和检查基本操作，以允许用户发现和缓解瓶颈。这至少（也是最有用的）需要提供一种方法来确定有多少线程被阻塞。&lt;/p&gt;
&lt;h2 id=&#34;3-设计和实现&#34;&gt;3. 设计和实现&lt;/h2&gt;
&lt;p&gt;同步器背后的基本思想非常简单。&lt;code&gt;acquire&lt;/code&gt; 操作如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;while(synchronization state does not allow acquire) {
  enqueue current thread if not already queued;
  possibly block current thread;
}
dequeue current thread if it was queued;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;release&lt;/code&gt; 操作如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;update synchronization state;
if(state may permit a blocked thread to acquire) 
  unblock one or more queued threads;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;为了支持上述操作，需要下面三个基本组件相互协作：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;同步状态的原子性原理；&lt;/li&gt;
&lt;li&gt;线程的阻塞与解除阻塞；&lt;/li&gt;
&lt;li&gt;队列的管理；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;也许可以创建一个框架，允许这三个部分各自独立变化。然而，这既不高效也不实用。例如，保存在队列节点中的信息必须与解除阻塞所需要的信息一致，而暴露出的方法签名必须依赖于同步状态的特性。&lt;/p&gt;
&lt;p&gt;同步器框架中的核心设计决策是这三个组件选择一个具体实现，同时在使用方式上仍然有大量的选择可用。这有意地限制了其适用范围，但是提供了足够的效率，是的实际上没有理由在合适的情况下不用这个框架而去重新造一个。&lt;/p&gt;
&lt;h3 id=&#34;31-同步状态&#34;&gt;3.1 同步状态&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;AQS&lt;/code&gt;类仅使用单个 &lt;code&gt;int&lt;/code&gt;（32 bit）来保存同步状态，并暴露出 &lt;code&gt;getState&lt;/code&gt;、&lt;code&gt;setState&lt;/code&gt; 以及 &lt;code&gt;compareAndSet&lt;/code&gt; 操作来读取和更新这个状态。这些方法都依赖于 &lt;code&gt;java.util.concurrent.atomic&lt;/code&gt; 支持，这个包提供了兼容 JSR133 中 &lt;code&gt;volatile&lt;/code&gt; 在读和写上的语义，并且通过使用本地的 compare-and-swap 或 load-linked/store-conditional 指令来实现 &lt;code&gt;compareAndSetState&lt;/code&gt;，只有当它持有给定的期望值时，才会自动将状态设置为给定的新值。&lt;/p&gt;
&lt;p&gt;将同步状态限定为 32 位 &lt;code&gt;int&lt;/code&gt; 是出于实践上的考量。虽然 JSR166 也提供了 64 位 &lt;code&gt;long&lt;/code&gt; 字段的原子操作，但是这些操作在很多平台上还是使用内部锁的方式来模拟实现的，以至于会使同步器的性能不佳。将来，很可能会添加第二个基类，专门用于 64 位状态（使用 &lt;code&gt;long&lt;/code&gt; 控制参数）。然而，现在还没有一个令人信服的理由将其纳入计划。目前，32 位足以满足大多数应用，只有一个 &lt;code&gt;j.u.c&lt;/code&gt; 同步器类 &lt;code&gt;CyclicBarrier&lt;/code&gt; 需要更多的位来维护状态，所以它使用了锁（该包中大多数更高层次的 工具也是如此）。&lt;/p&gt;
&lt;p&gt;基于 &lt;code&gt;AQS&lt;/code&gt; 的具体类必须根据这些暴露出的状态相关的方法定义 &lt;code&gt;tryAcquire&lt;/code&gt; 和 &lt;code&gt;tryRelease&lt;/code&gt; 方法，以控制 &lt;code&gt;acquire&lt;/code&gt; 和 &lt;code&gt;release&lt;/code&gt; 操作。当同步状态满足时，&lt;code&gt;tryAcquire&lt;/code&gt; 方法必须返回 &lt;code&gt;true&lt;/code&gt;，而当新的同步状态允许后续 &lt;code&gt;acquire&lt;/code&gt; 时，&lt;code&gt;tryRelease&lt;/code&gt; 方法也必须返回 &lt;code&gt;true&lt;/code&gt;。这些方法都接受一个 &lt;code&gt;int&lt;/code&gt; 类型的参数，该参数可用于传递想要的状态。例如：可重入锁，当某个线程从条件等待中返回，然后重新获取锁时，为了重新建立循环计数的场景。很多同步器并不需要这样的参数，因此忽略它即可。&lt;/p&gt;
&lt;h3 id=&#34;32-阻塞&#34;&gt;3.2 阻塞&lt;/h3&gt;
&lt;p&gt;在 JSR166 之前，除了创建基于内置监视器的同步器，没有 Java API 可以阻塞和解锁线程。唯一可以选择的是 &lt;code&gt;Thread.suspend&lt;/code&gt; 和 &lt;code&gt;Thread.resume&lt;/code&gt;，但是它们都有无法解决的竟态问题，所以也没办法使用：当一个非阻塞线程在一个正准备阻塞的线程调用 &lt;code&gt;suspend&lt;/code&gt; 之前调用 &lt;code&gt;resume&lt;/code&gt;，&lt;code&gt;resume&lt;/code&gt;操作将不起作用。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;java.util.concurrent.locks&lt;/code&gt; 包包含一个 &lt;code&gt;LockSupport&lt;/code&gt; 类，其中包含解决这个问题的方法。方法 &lt;code&gt;LockSupport.park&lt;/code&gt; 阻塞当前线程，除非或直到发出 &lt;code&gt;LockSupport.unpark&lt;/code&gt;（虚假唤醒也是允许的） 。对 &lt;code&gt;unpark&lt;/code&gt; 的调用是不 ”计数“的，所以一个 &lt;code&gt;park&lt;/code&gt; 之前的多个 &lt;code&gt;unpark&lt;/code&gt; 只会解除一个 &lt;code&gt;park&lt;/code&gt; 操作。此外，这适用于每个线程，而不是每个同步器。一个线程在一个新的同步器上调用 &lt;code&gt;park&lt;/code&gt; 操作可能会立即返回，因为在此之前可能有“剩余的” &lt;code&gt;unpark&lt;/code&gt; 操作。但是，在缺少一个 &lt;code&gt;unpark&lt;/code&gt; 操作时，下一次调用 &lt;code&gt;park&lt;/code&gt; 就会阻塞。虽然可以显式地消除这个状态，但并不值得这样做。在需要的时候多次调用 &lt;code&gt;park&lt;/code&gt; 会更高效。&lt;/p&gt;
&lt;p&gt;这个简单的机制在某种程度上类似于 Solaris-9 的线程库 [&lt;a href=&#34;#11&#34;&gt;11&lt;/a&gt;]，WIN32的 “可消费事件”，以及 Linux 中的 NPTL 线程库，因此最常见的运行 Java 的平台上都有相对应的有效实现，（但目前 Solaris 和 Linux 上的 Sun Hotspot JVM 参考实现实际上是使用一个 pthread 的 condvar 来适应目前的运行时设计的）。&lt;code&gt;park&lt;/code&gt; 方法同样支持可选的相对或绝对的超时设置，以及与 JVM 的 &lt;code&gt;Thread.interrupt&lt;/code&gt; 结合 —— 可通过中断来 &lt;code&gt;unpark&lt;/code&gt; 一个线程。&lt;/p&gt;
&lt;h3 id=&#34;33-队列&#34;&gt;3.3 队列&lt;/h3&gt;
&lt;p&gt;整个框架的核心是维护阻塞线程的队列，这里仅限于 FIFO 队列。因此，该框架不支持基于优先级的同步。&lt;/p&gt;
&lt;p&gt;如今，对于同步队列最合适的选择是不需要使用低级锁来构造的非阻塞数据结构，这一点几乎没有争议。其中，有两个主要的候选：一个是 Mellor-Crummey 和 Scott锁（MCS锁）[&lt;a href=&#34;#9&#34;&gt;9&lt;/a&gt;] 的变体，另一个是Craig，Landin 和 Hagersten锁（CLH锁）[&lt;a href=&#34;#5&#34;&gt;5&lt;/a&gt;] [&lt;a href=&#34;#8&#34;&gt;8&lt;/a&gt;] [&lt;a href=&#34;#10&#34;&gt;10&lt;/a&gt;]的变体。一直以来，CLH 锁只用于旋转锁。然而，它们似乎比 MCS 更适合在同步框架器中使用，因为它们更容易处理取消和超时，所以作为实现的基础。最终的设计与最初的 CLH 结构相差甚远，因此下文将对此做出解释。&lt;/p&gt;
&lt;p&gt;CLH 队列实际上并不是很像队列，因为它的入队和出队操作都与它的用途（即用作锁）紧密相关。他是一个链表队列，通过两个字段 &lt;code&gt;head&lt;/code&gt; 和 &lt;code&gt;tail&lt;/code&gt; 来存取，这两个字段支持原子更新，两者在初始化时都指向了空节点。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1662043146964.png&#34; alt=&#34;CLHNode&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;一个新节点，&lt;code&gt;node&lt;/code&gt;，通过一个原子操作入队：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;do {
    pred = tail;
} while (!tail.compareAndSet(pred, node));
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;每一个节点的 &lt;code&gt;release&lt;/code&gt; 状态都保存在其前驱节点中。因此，自旋锁的“自旋”操作如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;while (pred.status != RELEASED); // spin
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;自旋后的出队操作只需将 &lt;code&gt;head&lt;/code&gt; 字段指向刚刚得到锁的节点：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;head = node
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;CLH 锁的优点之一是：其入队和出队操作是快速的、无锁的、无阻塞的（即使在竞争情况下，也只会有一个线程赢得插入机会，从而能继续进行）；检测是否有线程在等待也很快（只需要检测 &lt;code&gt;head&lt;/code&gt; 和 &lt;code&gt;tail&lt;/code&gt; 是否相等）；同时，&lt;code&gt;release&lt;/code&gt; 是分散的，避免了一些不必要的内存竞争。&lt;/p&gt;
&lt;p&gt;在 CLH 锁的原始版本中，节点之间甚至都没有链接。在自旋锁中，&lt;code&gt;pred&lt;/code&gt; 变量可以作为局部变量保存。然而，Scott 和 Scherer [&lt;a href=&#34;#10&#34;&gt;10&lt;/a&gt;] 证明，通过在节点中显式的维护 &lt;code&gt;pred&lt;/code&gt; 字段，CLH 锁可以处理超时和各种形式的取消：如果节点的前驱结点取消，节点可以滑动去使用前一个节点的状态字段。&lt;/p&gt;
&lt;p&gt;使用 CLH 队列阻塞同步器，需要做的主要修改是提供一种高效的方式定位某个节点的后继节点。在自旋锁中，一个节点只需要改变其状态，下一次自旋中其后继节点就能注意到这个改变，所有节点间的链接操作并不是必须的。但是在阻塞同步器中，一个节点需要显式地唤醒（&lt;code&gt;unpark&lt;/code&gt;）其后继节点。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;AQS&lt;/code&gt; 队列的节点包含一个 &lt;code&gt;next&lt;/code&gt; 链接到它的后继节点。但是，由于没有针对双向链表节点的类似 &lt;code&gt;compareAndSet&lt;/code&gt; 的原子性无锁插入指令，因此这个 &lt;code&gt;next&lt;/code&gt; 链接的设置并非作为原子性插入操作的一部分，而仅是在节点被插入后简单赋值：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;pred.next = node;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这反映在所有的用法中。&lt;code&gt;next&lt;/code&gt; 链接仅是一种优化。如果一个节点的后继节点通过它的 &lt;code&gt;next&lt;/code&gt; 字段看起来不存在（或看起来被取消了），总是可以从尾部开始，使用 &lt;code&gt;pred&lt;/code&gt; 字段向前遍历来检查是否真的有后继节点。&lt;/p&gt;
&lt;p&gt;第二组修改是使用保存在每个节点中的状态字段来控制阻塞，而非自旋。在同步器框架中，仅在线程调用具体子类的 &lt;code&gt;tryAcquire&lt;/code&gt; 方法返回 &lt;code&gt;true&lt;/code&gt; 时，队列中的线程才能从 &lt;code&gt;acquire&lt;/code&gt; 操作中返回；而单个 &lt;code&gt;release&lt;/code&gt; 位是不够的。但是仍然需要控制，以确保活动线程只允许在队列的头部调用 &lt;code&gt;tryAcquire&lt;/code&gt;；在这种情况下，&lt;code&gt;acquire&lt;/code&gt; 可能会失败，然后（重新）阻塞。这种情况不需要读取状态标识，因为可以通过检查当前节点的前驱是否为 &lt;code&gt;head&lt;/code&gt; 来确定权限。与自旋锁不同，这里会读取 &lt;code&gt;head&lt;/code&gt;  的副本以保证不会有太多的内存竞争。但是，取消状态必须仍然存在于状态字段中。&lt;/p&gt;
&lt;p&gt;队列节点的状态字段还用于避免不必要的 &lt;code&gt;park&lt;/code&gt; 和 &lt;code&gt;unpark&lt;/code&gt; 调用。虽然这些方法相对于阻塞原语来说比较快，但是它们在跨 Java 和 JVM 运行时和/或操作系统边界时仍有可避免的开销。在调用 &lt;code&gt;park&lt;/code&gt; 之前，线程设置一个 “唤醒（signal me）” 位，然后再次检查同步和节点状态。一个释放的线程会清空其自身状态。这样线程就不必频繁地尝试阻塞，尤其对于锁类，在这些锁类中，等待下一个合格线程获取锁的时间会加重其他竞争。除非后继线程已经设置了 &lt;code&gt;signal&lt;/code&gt; 位，否则这也可以避免正在 &lt;code&gt;release&lt;/code&gt; 的线程去判断其后继节点。这也消除了除非 &lt;code&gt;signal&lt;/code&gt; 和 &lt;code&gt;cancel&lt;/code&gt; 一起发生，否则必须遍历多个节点来处理明显为空的 &lt;code&gt;next&lt;/code&gt; 字段的情况。&lt;/p&gt;
&lt;p&gt;同步器框架中使用的 CLH 锁的变体与其他语言中使用的变体之间的主要区别可能是，依靠垃圾收集来挂你节点的存储回收，这避免了复杂性和开销。然而，即使依赖 GC，也仍然需要在确定链接字段永远不会被需要时，将其置为 null。这往往可以与出队操作一起完成。否则，无用的节点仍然可达，就导致它们不可回收。&lt;/p&gt;
&lt;p&gt;J2SE1.5 版本的源代码文档中描述了一些更进一步的微调，包括 CLH 队列在第一次争用时所需的初始空节点的延迟初始化等。&lt;/p&gt;
&lt;p&gt;抛开这些细节，基本的 &lt;code&gt;acquire&lt;/code&gt; 操作的最终实现的一般形式如下（互斥，非中断，无超时）：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;if (!tryAcquire(arg)) {
    node = create and enqueue new node;
    pred = node&#39;s effective predecessor;
    while (pred is not head node || !tryAcquire(arg)) {
        if (pred&#39;s signal bit is set)
            park()
        else 
            compareAndSet pred&#39;s signal bit to true;
        pred = node&#39;s effective predecessor;
    }
    head = node;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;release&lt;/code&gt; 操作：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;if (tryRelease(arg) &amp;amp;&amp;amp; head node&#39;s signal bit is set) {
	compareAndSet head&#39;s signal bit to false;
    unpark head&#39;s successor, if one exists
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;acquire&lt;/code&gt; 操作的主循环次数依赖于具体实现类中 &lt;code&gt;tryAcquire&lt;/code&gt; 的实现方式。另一方面，在没有 &lt;code&gt;cancel&lt;/code&gt; 操作的情况下，每一个组件的 &lt;code&gt;acquire&lt;/code&gt; 和 &lt;code&gt;cancel&lt;/code&gt; 都是在一个 O(1) 常数时间内操作，不考虑 &lt;code&gt;park&lt;/code&gt; 中发生的所有操作系统线程调度。&lt;/p&gt;
&lt;p&gt;支持 &lt;code&gt;cancel&lt;/code&gt; 操作主要是要在 &lt;code&gt;acquire&lt;/code&gt; 循环里的 &lt;code&gt;park&lt;/code&gt; 返回时检查中断或超时。由于超时或中断而被取消等待的线程会设置其节点状态，然后 &lt;code&gt;unpark&lt;/code&gt; 其后继节点。在有 &lt;code&gt;cancel&lt;/code&gt; 的情况下，判断其前驱结点和后继节点以及重置状态可能需要 O(n) 的遍历（n 是队列的长度）。由于 &lt;code&gt;cancel&lt;/code&gt; 操作，该线程再也不会被阻塞，节点的连接和状态字段可以被快速重建。&lt;/p&gt;
&lt;h3 id=&#34;34-条件队列&#34;&gt;3.4 条件队列&lt;/h3&gt;
&lt;p&gt;同步器框架提供了一个 &lt;code&gt;ConditionObject&lt;/code&gt; 类，给维护独占同步的类以及实现 &lt;code&gt;Lock&lt;/code&gt; 接口的类使用。一个锁对象可以管理任意数量的 &lt;code&gt;ConditionObject&lt;/code&gt;，可以提供典型的监视器风格的 &lt;code&gt;await&lt;/code&gt;、&lt;code&gt;signal&lt;/code&gt; 和 &lt;code&gt;singalAll&lt;/code&gt; 操作，包括那些带有超时的操作，以及一些检测和监控的方法。&lt;/p&gt;
&lt;p&gt;同样是通过修正一些设计决策，&lt;code&gt;ConditionObject&lt;/code&gt; 类使条件能够与其他同步操作有效地集成。该类仅支持 Java 风格的监视器访问规则，在这些规则中，只有当拥有条件的锁被当前线程持有时，条件操作才是合法的（参见 [&lt;a href=&#34;#4&#34;&gt;4&lt;/a&gt;] 对替代方法的讨论）。因此，一个 &lt;code&gt;ConditionObject&lt;/code&gt; 关联到一个 &lt;code&gt;ReentrantLock&lt;/code&gt; 上就表现的跟内置监视器的行为方式相同（通过 &lt;code&gt;Object.await&lt;/code&gt; 等），不同之处仅在与方法名、额外的功能以及用户可以为每个锁声明多个条件。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ConditionObject&lt;/code&gt; 使用与同步器相同的内部队列节点，但在单独的条件队列中维护它们。&lt;code&gt;signal&lt;/code&gt;操作是通过将节点从条件队列转移到锁队列中来实现的，而没有必要在需要唤醒的线程重新获取到锁之前将其唤醒。&lt;/p&gt;
&lt;p&gt;基本的 &lt;code&gt;await&lt;/code&gt; 操作如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;create and add new node to condition queue;
release lock;
block until node is on lock queue;
re-acquire lock;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;signal&lt;/code&gt; 操作如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;transfer the first node from condition queue to lock queue;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;因为这些操作仅在持有锁时执行，所以它们可以使用顺序链表队列操作（在节点中使用 &lt;code&gt;nextWaiter&lt;/code&gt; 字段）来维护条件队列。转移操作仅仅把第一个节点从条件队列中的链接移除，然后通过 CLH 插入操作将其插入到锁队列上。&lt;/p&gt;
&lt;p&gt;实现这些操作的主要复杂性是处理由于超时或 &lt;code&gt;Thread.interrupt&lt;/code&gt; 而导致的条件等待的取消。&lt;code&gt;cancel&lt;/code&gt; 和 &lt;code&gt;signal&lt;/code&gt;几乎同时发生就会有竞争问题，最终的结果遵照内置监视器的规范。JSR133 修订后，就要求如果中断发生在 &lt;code&gt;signal&lt;/code&gt; 操作之前，&lt;code&gt;await&lt;/code&gt; 方法必须在重新获取到锁后，抛出 &lt;code&gt;InterruptedException&lt;/code&gt;。但是，如果中断发生在 &lt;code&gt;signal&lt;/code&gt; 后，&lt;code&gt;await&lt;/code&gt; 必须返回且不抛异常，同时设置线程的中断状态。&lt;/p&gt;
&lt;p&gt;为了保持正确的顺序，队列节点状态变量中的一个位记录了该节点是否已经（或正在）被转移。&lt;code&gt;cancel&lt;/code&gt; 和 &lt;code&gt;signal&lt;/code&gt; 相关的代码都会尝试用 &lt;code&gt;compareAndSet&lt;/code&gt; 修改这个状态。如果某次 &lt;code&gt;signal&lt;/code&gt; 操作修改失败，就会转移队列中的下一个节点（如果存在的话）。如果某次 &lt;code&gt;cancel&lt;/code&gt; 操作修改失败，就必须终止此次转移，然后等待重新获得锁。后面的情况采用了一个潜在的无限的自旋等待。在节点成功的被插入到锁队列之前，被 &lt;code&gt;cancel&lt;/code&gt; 的等待不能重新获得锁，所以必须自旋等待 CLH 队列插入（即 &lt;code&gt;compareAndSet&lt;/code&gt; ）成功，被 &lt;code&gt;signal&lt;/code&gt; 线程成功执行。这里很少需要自旋，并且使用 &lt;code&gt;Thread.yield&lt;/code&gt; 来提供一个调度提示其他线程（理想情况下是发出 &lt;code&gt;signal&lt;/code&gt; 的线程）应该运行。虽然在这里可以为 &lt;code&gt;cancel&lt;/code&gt; 实现一个帮助策略来插入节点，但是这种情况非常罕见，以至于无法证明这样做所带来的额外开销是合理的。在所有其他情况下，这里和其他地方的基本机制不使用自旋或&lt;code&gt;yield&lt;/code&gt;，在因此在但处理器上保持了合理的性能。&lt;/p&gt;
&lt;h2 id=&#34;4-用例&#34;&gt;4. 用例&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;AQS&lt;/code&gt; 类将上述功能组合在一起，并作为同步器的“模板方法模式”[&lt;a href=&#34;#6&#34;&gt;6&lt;/a&gt;]基类。子类只需定义状态的检查和更新的相关方法，实现控制 &lt;code&gt;acquire&lt;/code&gt; 和 &lt;code&gt;release&lt;/code&gt;  操作。然而，&lt;code&gt;AQS&lt;/code&gt; 的子类本身用作同步器 ADT 并不合适，因为该类必须暴露出内部内部控制 &lt;code&gt;acquire&lt;/code&gt; 和 &lt;code&gt;release&lt;/code&gt; 的规则，这些都不应该对用户可见。所有 &lt;code&gt;j.u.c&lt;/code&gt; 包中的同步器类都声明了一个 &lt;code&gt;private&lt;/code&gt; 且继承 &lt;code&gt;AQS&lt;/code&gt;的内部类，并且把所有同步方法都委托给这个内部类。这样，各个同步器类的公开方法就可以使用适合自己的名称。&lt;/p&gt;
&lt;p&gt;例如，这里有一个最简单的 &lt;code&gt;Mutex&lt;/code&gt; 类，它使用同步状态 &lt;code&gt;0&lt;/code&gt; 表示未锁定，使用同步状态 &lt;code&gt;1&lt;/code&gt; 表示锁定。这个类不需要同步方法中的参数，因此这里在调用的时候使用 &lt;code&gt;0&lt;/code&gt; 作为实参，方法实现里将其忽略。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;class Mutex {
  class Sync extends AbstractQueuedSynchronizer {
    public boolean tryAcquire(int ingore) {
      return compareAndSetState(0, 1);
    }
    public boolean tryRelease(int ignore) {
      setState(0);
      return true;
    }
  }
  
  private final Sync sync = new Sync();
  
  public void lock(){
    sync.acquire(0);
  }
  public void unlock(){
    sync.release(0);
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这个例子的完整版本，以及其他使用指南可以在 J2SE 文档中找到。还有可以有一些其他变体。例如，&lt;code&gt;tryAcquire&lt;/code&gt; 可以使用 “test-and-test-and-set” 策略，即在改变状态值之前先对状态进行校验。&lt;/p&gt;
&lt;p&gt;令人诧异的是，像互斥锁这样对性能敏感的东西，也打算通过委托和虚方法结合的方式来定义。然而，这正是现代动态编译器长期关注的面向对象设计结构。它们往往擅长优化掉这种开销，起码会优化频繁调用同步器的哪些代码。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;AQS&lt;/code&gt; 类还提供了许多方法来帮助同步器类进行策略控制。例如，基础的 &lt;code&gt;acquire&lt;/code&gt; 方法有可超时和可中断的版本。虽然到目前为止的讨论都集中在独占模式的同步器上（如锁），但 &lt;code&gt;AQS&lt;/code&gt; 类也包含一组并行的方法（如&lt;code&gt;acquireShared&lt;/code&gt;），不同之处在于 &lt;code&gt;tryAcquireShared&lt;/code&gt; 和 &lt;code&gt;tryReleaseShared&lt;/code&gt; 方法可以通知框架（同步它们的返回值）可以接受更多的请求，最终框架会通过级联的 &lt;code&gt;signal&lt;/code&gt; 唤醒多个线程。&lt;/p&gt;
&lt;p&gt;虽然序列化（持久存储或传输）同步器通常来说没有太大意义，但这些类经常被用来构造其他类，如线程安全的集合，它们通常是可序列化的。&lt;code&gt;AQS&lt;/code&gt; 和 &lt;code&gt;ConditionObject&lt;/code&gt; 类提供了序列化同步状态的方法，但不会序列化潜在的被阻塞的线程，也不会序列化其他内部暂时性的 bookkeeping。即使如此，在反序列化时，大部分同步器类也只是仅将同步状态重置为初始值，这与内置锁的隐式策略一直 —— 总是反序列化到一个解锁状态。这相当于一个空操作，但仍必须显式地支持以便 ·&lt;code&gt;final&lt;/code&gt; 字段能够反序列化。&lt;/p&gt;
&lt;h3 id=&#34;41-公平调度的控制&#34;&gt;4.1 公平调度的控制&lt;/h3&gt;
&lt;p&gt;即使它们基于 FIFO 队列，同步器也不一定是公平的。请注意，在基础的 &lt;code&gt;acquire&lt;/code&gt; 算法（第 3.3 节）中，&lt;code&gt;tryAcquire&lt;/code&gt; 检查是在排队之前执行的。因此，新的 &lt;code&gt;acquire&lt;/code&gt; 线程可以“窃取”本该属于队列头部第一个线程通过同步器的机会。&lt;/p&gt;
&lt;p&gt;可 &lt;em&gt;闯入的FIFO&lt;/em&gt; 策略通常比其他技术提供更高的总吞吐量。当一个存在竞争的锁已经空闲，而下一个准备获取锁的线程正在解除阻塞的过程中，此时没有线程可以获取到这个锁，如果使用&lt;em&gt;闯入策略&lt;/em&gt;，则可以减少这之间的时间。与此同时，这种策略还可以避免过多的、无效的竞争（只允许一个（第一个）排队的线程被唤醒，然后尝试 &lt;code&gt;acquire&lt;/code&gt; 操作导致）。如果是短时间持有同步器的场景，创建同步器的开发人员在可以通过定义 &lt;code&gt;tryAcquire&lt;/code&gt; ，在控制权返回之前重复调用自己若干次，来进一步凸显&lt;em&gt;闯入&lt;/em&gt;效果。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1662043201211.png&#34; alt=&#34;fifo&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;可闯入的 FIFO 同步器只有概率性的公平属性。在锁队列的头部一个解除了阻塞的线程拥有一次无偏向的机会来赢得与闯入线程之间的竞争，如果竞争失败，那么要么重新阻塞，要么进行重试。然而，如果闯入的线程到达的速度比队头的线程解除阻塞更快，俺么在队列中的第一个线程将会很难赢得竞争，以及于几乎总是要重新阻塞，并且它的后继节点也会一直保持阻塞。对于短暂持有的同步器来说，在队列中第一个线程被解除阻塞的期间，多处理器上很可能发生过多次闯入和 &lt;code&gt;release&lt;/code&gt;。如下文所述，最终结果就是保持一个或多个线程的高速进展的同时，在一定概率是避免了饥饿的发生。&lt;/p&gt;
&lt;p&gt;当需要更高的公平性需求时，实现起来也很简单。如果需要严格的公平性，程序员可以定义 &lt;code&gt;tryAcquire&lt;/code&gt; 为：如果当前线程不是队列的头结点（可以通过 &lt;code&gt;getFirstQueuedThread&lt;/code&gt;方法检查这一点，这是框架提供的为数不多的几个检测方法之一），则立即返回失败（返回 &lt;code&gt;false&lt;/code&gt;）。&lt;/p&gt;
&lt;p&gt;一种更快、不太严格的方法是，如果队列（暂时）为空，也允许 &lt;code&gt;tryAcquire&lt;/code&gt; 成功。在这种情况下，遇到空队列的多个线程可能会争取第一个获得锁，这样，通常至少有一个线程是不需要放入队列的。所有支持 &lt;code&gt;fair&lt;/code&gt; 模式的 &lt;code&gt;j.u.c&lt;/code&gt; 同步器都采用这种策略。&lt;/p&gt;
&lt;p&gt;尽管公平性设置在实践中很有用，当时它们并没有保障，因为 Java Language Specification 没有提供这样的调度保证。例如：即使是严格公平的同步器，如果一组线程永远不需要阻塞来达到相互等待，那么 JVM 也可以决定完全按照顺序方式运行它们。实际上，在单处理上，在抢占式上下文切换之前，这样的线程有可能是各自运行了一段时间。如果这样的线程正持有某个互斥锁，它将很快被切换回来，仅仅是为了释放其持有的锁，然后会继续阻塞，因为它知道有另一个线程需要这把锁，这更增加了同步器可用但没有线程能来获取直接的间隔。同步器公平性设置在多处理器上的影响可能会更大，因为在这种环境中会产生更多的交错，因此一个线程就会有更多的机会发现锁被另一个线程请求。&lt;/p&gt;
&lt;p&gt;在高度竞争的情况下，当保护短暂持有的代码体时，尽管可能性能不佳，但公平锁仍然能有效地工作。例如，当公平锁保护的是相对长的代码体和/或具有相对较长的锁间（inter-lock）间隔时，在这种情况下，闯入只能带来很小的性能优势，但却可能会大大增加无限等待的风险。同步器框架将这些工程决策留给用户来确定。&lt;/p&gt;
&lt;h3 id=&#34;42-同步器&#34;&gt;4.2 同步器&lt;/h3&gt;
&lt;p&gt;下面是 &lt;code&gt;j.u.c&lt;/code&gt; 包中同步器定义方式的概述：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ReentrantLock&lt;/code&gt; 类使用同步状态来保存锁（重复）持有的次数。当锁被一个线程获取时，&lt;code&gt;ReentrantLock&lt;/code&gt; 也会记录下当前获得锁的线程标识，以便检查是否是重复获取，以及当前错误的线程试图进行解锁操作时检测是否存在非法状态异常。&lt;code&gt;ReentrantLock&lt;/code&gt; 还是用了 &lt;code&gt;AQS&lt;/code&gt; 提供的 &lt;code&gt;ConditionObject&lt;/code&gt;，并向外暴露了其他监控和检查的方法。&lt;code&gt;ReentrantLock&lt;/code&gt; 通过在内部声明的两个不同的 &lt;code&gt;AQS&lt;/code&gt; 实现类（提供公平模式的那个回禁用 &lt;em&gt;闯入&lt;/em&gt; 策略 ）来实现可选的公平模式，在创建 &lt;code&gt;ReentrantLock&lt;/code&gt; 实例的时候根据配置使用相应的 &lt;code&gt;AQS&lt;/code&gt; 实现类。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ReentrantReadWriteLock&lt;/code&gt; 类使用同步状态的 16 位来保存写锁计数，剩余的 16 位保存读锁计数。&lt;code&gt;WriteLock&lt;/code&gt; 在其他方面的结构与 &lt;code&gt;ReentrantLock&lt;/code&gt; 相同。&lt;code&gt;ReadLock&lt;/code&gt; 使用 &lt;code&gt;acquireShared&lt;/code&gt; 方法来启用多个读线程。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Semaphore&lt;/code&gt; 类（计数信号量）使用同步状态来保存当前计数。它里面定义的 &lt;code&gt;acquireShared&lt;/code&gt; 方法会减少计数，或当计数为非正值时阻塞线程；&lt;code&gt;tryRelease&lt;/code&gt; 方法会增加计数，如果计数现在是正数，可能还要解除线程的阻塞。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;CountDownLatch&lt;/code&gt; 类使用同步状态来表示计数。当它达到零时，所有 &lt;code&gt;acquire&lt;/code&gt; 都通过。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;FutureTask&lt;/code&gt; 类使用同步状态来表示未来的运行状态（初始化、运行、取消、完成）。设置或取消一个 &lt;code&gt;FutureTask&lt;/code&gt; 时，会调用 &lt;code&gt;AQS&lt;/code&gt; 的 &lt;code&gt;release&lt;/code&gt; 操作；等待计算结果的线程解除阻塞是通过 &lt;code&gt;AQS&lt;/code&gt; 的 &lt;code&gt;acquire&lt;/code&gt; 操作。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;SynchronousQueue&lt;/code&gt; 类（一种 CSP（Communication Sequential Processes）形式的传递）使用了内部的等待节点，这些节点可以用于协调生产者和消费者。同时，它使用 &lt;code&gt;AQS&lt;/code&gt;  同步状态来控制当某个消费者消费前一项时，允许一个生产者继续生产，反之亦然。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;j.u.c&lt;/code&gt; 包的用户当然可以为自定义的应用定义自己的同步器。例如，那些曾考虑到过的，但没有采纳进这个包的同步器包括提供 WIN32 事件风格的语义类，binary latches、集中管理的锁以及基于树的屏障。&lt;/p&gt;
&lt;h2 id=&#34;5-性能&#34;&gt;5. 性能&lt;/h2&gt;
&lt;p&gt;尽管同步器框架除了互斥锁之外，还支持许多其他类型的同步方式，但锁的性能是最容易测量和比较的。即便如此，仍由许多不同的测量方法。这里的实验主要目的在于展示开销和吞吐量。&lt;/p&gt;
&lt;p&gt;在每个测试中，所有线程都重复的更新一个伪随机数，该随机数由 &lt;code&gt;nextRandom(int seed)&lt;/code&gt; 方法计算：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;int t = (seed % 127773) * 16807 - (seed / 127773) * 2836;
return (t &amp;gt; 0) ? t : t + 0x7fffffff;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在每次迭代中，线程以概率 S 在一个互斥锁下更新共享的生成器，否则更新其自己局部的生成器，此时是不需要锁的。因此，锁的占用是短暂的，这就会导致线程在持有锁期间被抢占时的外界干扰降到了最小。这个函数的随机性主要为了两个目的：确定是否需要使用锁（这个生成器足以应付这里的需求），以及使用循环中的代码不可能被轻易的优化掉。&lt;/p&gt;
&lt;p&gt;这里比较了四种锁：内置的，用的是 &lt;code&gt;synchronized&lt;/code&gt; 块；互斥锁，使用一个简单的 &lt;code&gt;Mutex&lt;/code&gt; 类，如第四节所示；可重入锁，用的是 &lt;code&gt;ReentrantLock&lt;/code&gt;；以及公平锁，用的是 &lt;code&gt;ReentrantLock&lt;/code&gt; 的公平模式。所有测试都运行在 J2SE1.5 JDK build46（大致与beta2相同）的 server 模式下。在收集测试数据之前，测试程序执行了 20 次无竞争运行，以消除预热效应。除了公平模式测试只运行了一百万次迭代，其他每个线程测试运行一千万次迭代。&lt;/p&gt;
&lt;p&gt;该测试运行在四台 X86 机器和四台 UltraSparc 机器上。所有 X86 机器都运行的是 RedHat 基于 NPTL 2.4 内核和库的 Linux 系统。所有的 UltraSparc 机器都运行的是 Solaris-9。测试时所有系统的负载都很轻。根据该测试的特征，并不要求操作系统完全空闲。“4P” 这个名字反映出双核超线程的 Xeon 更像是 4 路处理器，而不是 2 路处理器。这里没有将测试数据规范化。如下所示，同步的相对开销与处理器的数量、类型、速度之间不具备简单的关系。&lt;/p&gt;
&lt;center&gt;&lt;b&gt;表1 测试的平台&lt;/b&gt;&lt;/center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;名字&lt;/th&gt;
&lt;th&gt;处理器数量&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;速度（Mhz）&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1P&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;Pentium3&lt;/td&gt;
&lt;td&gt;900&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2P&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;Pentium3&lt;/td&gt;
&lt;td&gt;1400&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2A&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;Athlon&lt;/td&gt;
&lt;td&gt;2000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4P&lt;/td&gt;
&lt;td&gt;2HT&lt;/td&gt;
&lt;td&gt;Pentium4/Xeon&lt;/td&gt;
&lt;td&gt;2400&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1U&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;UltraSparc2&lt;/td&gt;
&lt;td&gt;650&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4U&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;UltraSparc2&lt;/td&gt;
&lt;td&gt;450&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8U&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;UltraSparc3&lt;/td&gt;
&lt;td&gt;750&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;24U&lt;/td&gt;
&lt;td&gt;24&lt;/td&gt;
&lt;td&gt;UltraSparc3&lt;/td&gt;
&lt;td&gt;750&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;51-开销&#34;&gt;5.1 开销&lt;/h3&gt;
&lt;p&gt;通过只只运行一个线程，从 S=1 时的每次迭代时间减去 S=0 （访问共享内存的概率为零）时的每次迭代时间得到的。表 2 显示了在非竞争的场景下每次锁操作的开销（以纳秒为单位）。&lt;code&gt;Metux&lt;/code&gt; 类最接近于框架的基本耗时，可重入锁的额外开销是记录当前所有者线程和错误检查时的耗时，对于公平锁来说还会包含开始时检查队列是否为空的耗时。&lt;/p&gt;
&lt;p&gt;表 2 还显示了 &lt;code&gt;tryAcquire&lt;/code&gt; 与内置锁的“快速路径（fast path）”的耗时对比。这里的差异主要反映了各种锁和机器中使用的不同的原子指令以及内存屏障的耗时。在多处理器上，这些指令常常是完全优于所有其他指令的。内置锁和同步器类之间的主要差别，显然是由于 Hotspot 锁使用 &lt;code&gt;compareAndSet&lt;/code&gt; 锁定和解锁，而同步器的 &lt;code&gt;acquire&lt;/code&gt; 操作使用了一次 &lt;code&gt;compareAndSet&lt;/code&gt;，但 &lt;code&gt;release&lt;/code&gt; 操作用的是一次 &lt;code&gt;volatile&lt;/code&gt; 写（即，多处理器上的一次内存屏障以及所有处理器上的重排序限制）。每个锁的绝对和相对耗时因机器的不同而不同。&lt;/p&gt;
&lt;center&gt;&lt;b&gt;表2 无竞争时的单锁开销（单位：纳秒）&lt;/b&gt;&lt;/center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;机器&lt;/th&gt;
&lt;th&gt;内置&lt;/th&gt;
&lt;th&gt;互斥&lt;/th&gt;
&lt;th&gt;可重入&lt;/th&gt;
&lt;th&gt;公平可重入&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1P&lt;/td&gt;
&lt;td&gt;18&lt;/td&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;31&lt;/td&gt;
&lt;td&gt;37&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2P&lt;/td&gt;
&lt;td&gt;58&lt;/td&gt;
&lt;td&gt;71&lt;/td&gt;
&lt;td&gt;77&lt;/td&gt;
&lt;td&gt;81&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2A&lt;/td&gt;
&lt;td&gt;13&lt;/td&gt;
&lt;td&gt;21&lt;/td&gt;
&lt;td&gt;31&lt;/td&gt;
&lt;td&gt;30&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4P&lt;/td&gt;
&lt;td&gt;116&lt;/td&gt;
&lt;td&gt;95&lt;/td&gt;
&lt;td&gt;109&lt;/td&gt;
&lt;td&gt;117&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1U&lt;/td&gt;
&lt;td&gt;90&lt;/td&gt;
&lt;td&gt;40&lt;/td&gt;
&lt;td&gt;58&lt;/td&gt;
&lt;td&gt;67&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4U&lt;/td&gt;
&lt;td&gt;122&lt;/td&gt;
&lt;td&gt;82&lt;/td&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;td&gt;115&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8U&lt;/td&gt;
&lt;td&gt;160&lt;/td&gt;
&lt;td&gt;83&lt;/td&gt;
&lt;td&gt;103&lt;/td&gt;
&lt;td&gt;123&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;24U&lt;/td&gt;
&lt;td&gt;161&lt;/td&gt;
&lt;td&gt;84&lt;/td&gt;
&lt;td&gt;108&lt;/td&gt;
&lt;td&gt;119&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;在另一个极端，表 3 显示了在 S=1 的情况下，运行 256 个并发线程时产生了大规模的锁竞争下每个锁的开销。在完全饱和的情况下，可闯入的 FIFO 锁比内置锁的开销少了一个数量级（相当于更大的吞吐量），比公平锁少了两个数量级。这证明了即使在极端争用的情况下，可闯入FIFO策略在保持线程进度方面的有效性。&lt;/p&gt;
&lt;p&gt;表 3 也说明了即使在内部开销比较低的情况下，公平锁的性能也完全是由上下文切换的时间所决定的。列出的时间大致上都与各平台上线程阻塞和解除线程阻塞的时间成比例。&lt;/p&gt;
&lt;p&gt;此外，后续增加的一个实验（仅使用机器 4P）显示，对于这里使用的非常短暂的锁，公平性设置对总体方差只有很小的影响。这里将线程终止时间的差异被记录为可变性的粗粒度度量。在机器 4P 上，公平锁的时间度量的标准差平均为 0.7%，可重入锁平均为 6.0%。作为对比，为模拟一个产时间持有锁的场景，测试中使每个线程在持有锁的情况下计算了 16K 次随机数。这时，总运行时间几乎是相同的（公平锁：9.79s，可重入锁：9.72s）。公平模式下的差异依然很小，标准差平均为 0.1%，而可重入锁上升到了平均 29.5%。&lt;/p&gt;
&lt;center&gt;&lt;b&gt;表格3 饱和时的单锁开销（单位：纳秒）&lt;/b&gt;&lt;/center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;机器&lt;/th&gt;
&lt;th&gt;内置&lt;/th&gt;
&lt;th&gt;互斥&lt;/th&gt;
&lt;th&gt;可重入&lt;/th&gt;
&lt;th&gt;公平可重入&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1P&lt;/td&gt;
&lt;td&gt;521&lt;/td&gt;
&lt;td&gt;46&lt;/td&gt;
&lt;td&gt;67&lt;/td&gt;
&lt;td&gt;8327&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2P&lt;/td&gt;
&lt;td&gt;930&lt;/td&gt;
&lt;td&gt;108&lt;/td&gt;
&lt;td&gt;132&lt;/td&gt;
&lt;td&gt;14967&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2A&lt;/td&gt;
&lt;td&gt;748&lt;/td&gt;
&lt;td&gt;79&lt;/td&gt;
&lt;td&gt;84&lt;/td&gt;
&lt;td&gt;33910&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4P&lt;/td&gt;
&lt;td&gt;1146&lt;/td&gt;
&lt;td&gt;188&lt;/td&gt;
&lt;td&gt;247&lt;/td&gt;
&lt;td&gt;15328&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1U&lt;/td&gt;
&lt;td&gt;879&lt;/td&gt;
&lt;td&gt;153&lt;/td&gt;
&lt;td&gt;177&lt;/td&gt;
&lt;td&gt;41394&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4U&lt;/td&gt;
&lt;td&gt;2590&lt;/td&gt;
&lt;td&gt;347&lt;/td&gt;
&lt;td&gt;368&lt;/td&gt;
&lt;td&gt;30004&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8U&lt;/td&gt;
&lt;td&gt;1274&lt;/td&gt;
&lt;td&gt;157&lt;/td&gt;
&lt;td&gt;174&lt;/td&gt;
&lt;td&gt;31084&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;24U&lt;/td&gt;
&lt;td&gt;1983&lt;/td&gt;
&lt;td&gt;160&lt;/td&gt;
&lt;td&gt;182&lt;/td&gt;
&lt;td&gt;32291&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;52-吞吐量&#34;&gt;5.2 吞吐量&lt;/h3&gt;
&lt;p&gt;大多数同步器的使用范围在无竞争和饱和竞争这两个极端之间。这可以用实验在两个方面进行检查，通过修改固定数量线程的竞争概率，和/或通过向一组具有固定竞争概率的线程添加更多的线程。为了说明这些影响，测试运行在不同的竞争概率和不同的线程数目下，都用的是可重入锁。附图使用了一个 &lt;em&gt;slowdown&lt;/em&gt; 度量标准：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1662043242519.jpg&#34; alt=&#34;formula&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;这里，t 是总运行时间，b 是一个线程在没有竞争或同步的情况下的基线时间，n 是线程的数量，p 是处理器的数量，S 是共享访问的比例。计算结果是实际执行时间与理想执行时间（通常是无法达到的）的比率，理想执行时间是通过使用 Amdahl&#39;s 定律对顺序和并行任务的混合计算得到。理想的时间模型是在没有任何同步开销的情况下，没有线程因为与其他线程冲突而阻塞。即便如此，在竞争非常少的情况下，一些测试结果显示，与理想情况相比，有些测试结果表现出了很小的速度增长，大概是由于基线和测试之间的优化、流水线等方面有着轻微的差别。&lt;/p&gt;
&lt;p&gt;图中用以 2 为底的对数为比例进行了缩放。例如，值为 1 表示实际时间是理想时间的两倍，4 表示慢 16 倍。使用对数就不需要依赖一个随意的基线时间（这里是计算随机数的时间），因此，基于不同底数的计算结果表现出的趋势应该是类似的。这些测试使用的竞争概率从 1/128（标识为 “0.008”）到 1，以 2 的幂为步长，线程的数量从 1 到 1024，以 2 的幂的一半为步长。&lt;/p&gt;
&lt;p&gt;在单处理器上（1P 和 1U），性能会随着竞争的增加而降低，但通常不会随着线程数量的增加而降低。多处理器在竞争的情况下，通常会遇到更糟糕的性能下降。根据多处理器相关的图表显示，开始出现的峰值处虽然只有几个线程的竞争，但相对性能通常却最差。这反映出了一个性能的 &lt;em&gt;过渡区域&lt;/em&gt;，在这里闯入的线程和被唤醒的线程都准备获取锁，这会让它们频繁的迫使对方阻塞。在大部分时候，过渡区域后面会紧接着一个 &lt;em&gt;平滑区域&lt;/em&gt;，因为此时几乎没有空闲的锁，所以会与单处理器上的顺序执行模式差不多；在多处理器上会较早进入平滑区域。例如，请注意，在处理器数量较少的机器上，满竞争（标记为 “1.000”）表现出相对较差的速度下降。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1662043305229.jpg&#34; alt=&#34;slowndown-1&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1662043318498.jpg&#34; alt=&#34;slowndown-2&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1662043328452.jpg&#34; alt=&#34;slowndown-3&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1662043337590.jpg&#34; alt=&#34;slowndown-4&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;基于这些结果，进一步调整阻塞（&lt;code&gt;park/unpark&lt;/code&gt;）以减少上下文切换和相关的开销，这会给本框架带来小但显著的提升。此外，在多处理上为短时间持有的但高竞争的锁采用某种形式的适应性自旋，可以避免这里看到的一些波动，这对同步器类有很大好处。虽然在跨不同上下文时适应性自旋很难很好的工作，但可以使用本框架为遇到这类使用配置的特定应用构建一个自定义形式的锁。&lt;/p&gt;
&lt;h2 id=&#34;6-结论&#34;&gt;6. 结论&lt;/h2&gt;
&lt;p&gt;在撰写本文时，&lt;code&gt;j.u.c&lt;/code&gt;同步器框架还太新，无法在实践中进行使用。因此在 J2SE 1.5 最终发布之前，它不太可能被广泛使用，而且他的设计、API 实现以及性能肯定还有无法预料的后果。但是，此时，这个框架明显能胜任其基本目标，即为创建新的同步器提供一个高效的基础。&lt;/p&gt;
&lt;h2 id=&#34;7-致谢&#34;&gt;7. 致谢&lt;/h2&gt;
&lt;p&gt;Thanks to Dave Dice for countless ideas and advice during the development of this framework, to Mark Moir and Michael Scott for urging consideration of CLH queues, to David Holmes for critiquing early versions of the code and API, to Victor Luchangco and Bill Scherer for reviewing previous incarnations of the source code, and to the other members of the JSR166 Expert Group (Joe Bowbeer, Josh Bloch, Brian Goetz, David Holmes, and Tim Peierls) as well as Bill Pugh, for helping with design and specifications and commenting on drafts of this paper. Portions of this work were made possible by a DARPA PCES grant, NSF grant EIA-0080206 (for access to the 24way Sparc) and a Sun Collaborative Research Grant.&lt;/p&gt;
&lt;h2 id=&#34;8-引用&#34;&gt;8. 引用&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span id=&#34;1&#34;&gt;[1]&lt;/span&gt; Agesen, O., D. Detlefs, A. Garthwaite, R. Knippel, Y. S.Ramakrishna, and D. White. An Efficient Meta-lock for Implementing Ubiquitous Synchronization. ACM OOPSLA Proceedings, 1999.&lt;/li&gt;
&lt;li&gt;&lt;span id=&#34;2&#34;&gt;[2]&lt;/span&gt; Andrews, G. Concurrent Programming. Wiley, 1991.&lt;/li&gt;
&lt;li&gt;&lt;span id=&#34;3&#34;&gt;[3]&lt;/span&gt; Bacon, D. Thin Locks: Featherweight Synchronization for Java. ACM PLDI Proceedings, 1998.&lt;/li&gt;
&lt;li&gt;&lt;span id=&#34;4&#34;&gt;[4]&lt;/span&gt; Buhr, P. M. Fortier, and M. Coffin. Monitor Classification,ACM Computing Surveys, March 1995.&lt;/li&gt;
&lt;li&gt;&lt;span id=&#34;5&#34;&gt;[5]&lt;/span&gt; Craig, T. S. Building FIFO and priority-queueing spin locks from atomic swap. Technical Report TR 93-02-02,Department of Computer Science, University of Washington, Feb. 1993.&lt;/li&gt;
&lt;li&gt;&lt;span id=&#34;6&#34;&gt;[6]&lt;/span&gt; Gamma, E., R. Helm, R. Johnson, and J. Vlissides. Design Patterns, Addison Wesley, 1996.&lt;/li&gt;
&lt;li&gt;&lt;span id=&#34;7&#34;&gt;[7]&lt;/span&gt; Holmes, D. Synchronisation Rings, PhD Thesis, Macquarie University, 1999.&lt;/li&gt;
&lt;li&gt;&lt;span id=&#34;8&#34;&gt;[8]&lt;/span&gt; Magnussen, P., A. Landin, and E. Hagersten. Queue locks on cache coherent multiprocessors. 8th Intl. Parallel Processing Symposium, Cancun, Mexico, Apr. 1994.&lt;/li&gt;
&lt;li&gt;&lt;span id=&#34;9&#34;&gt;[9]&lt;/span&gt; Mellor-Crummey, J.M., and M. L. Scott. Algorithms for Scalable Synchronization on Shared-Memory Multiprocessors. ACM Trans. on Computer Systems,February 1991&lt;/li&gt;
&lt;li&gt;&lt;span id=&#34;10&#34;&gt;[10]&lt;/span&gt; M. L. Scott and W N. Scherer III. Scalable Queue-Based Spin Locks with Timeout. 8th ACM Symp. on Principles and Practice of Parallel Programming, Snowbird, UT, June 2001.&lt;/li&gt;
&lt;li&gt;&lt;span id=&#34;11&#34;&gt;[11]&lt;/span&gt; Sun Microsystems. Multithreading in the Solaris Operating Environment. White paper available at http://wwws.sun.com/software/solaris/whitepapers.html 2002.&lt;/li&gt;
&lt;li&gt;&lt;span id=&#34;12&#34;&gt;[12]&lt;/span&gt; Zhang, H., S. Liang, and L. Bak. Monitor Conversion in a Multithreaded Computer System. United States Patent 6,691,304. 2004.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;9-参考&#34;&gt;9. 参考&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://gee.cs.oswego.edu/dl/papers/aqs.pdf&#34;&gt;《The java.util.concurrent Synchronizer Framework》&lt;/a&gt;&lt;/p&gt;
">《The java.util.concurrent Synchronizer Framework》原文翻译</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://wenbozhangw.github.io/post/chapter-2-grammars/"" data-c="
          &lt;p&gt;本章描述了本规范中用于定义程序词法和语法结构的上下文无关语法（context-free grammars）。&lt;/p&gt;
&lt;!-- more --&gt;
&lt;h2 id=&#34;21-context-free-grammars&#34;&gt;2.1 Context-Free Grammars&lt;/h2&gt;
&lt;p&gt;一个上下文无关的语法由许多 &lt;em&gt;productions&lt;/em&gt; 组成。每一个 productions 都有一个称为 &lt;em&gt;nonterminal&lt;/em&gt; 的抽象符号在它 &lt;em&gt;left-hand side&lt;/em&gt;，一个或多个 nonterminal 和 &lt;em&gt;terminal&lt;/em&gt; 符号的序列在他的 &lt;em&gt;right-hand side&lt;/em&gt;。对于每种语法，终止符号都是从指定的 &lt;em&gt;alphabet&lt;/em&gt; 中抽取的。&lt;/p&gt;
&lt;p&gt;从由单个可识别的非终结符（称为 &lt;em&gt;goal symbol&lt;/em&gt;）组成的句子开始，给定的与上下文无关的语法指定了一种语言，即，通过将序列中的任何非终止符重复替换为以非终止符为左边的 productions 的右手边而产生的可能的终止符序列集。&lt;/p&gt;
">Chapter 2. Grammars</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://wenbozhangw.github.io/post/chapter-1-interduction/"" data-c="
          &lt;p&gt;Java® 编程语言是一种通用的、并发的、基于类的、面向对象的语言。它被设计得足够简单，以至于许多程序员都能熟练使用该语言。Java 编程语言与 C 和 C++ 有关，但其组织方式却截然不同，它省略了 C 和 C++ 的许多方面，并包含了其他语言的一些思想。它是一种生产语言，而不是一种研究语言，因此，正如 C. A. R. Hoare 在他关于语言设计的经典论文中建议的那样，设计避免包含新的和未经测试的功能。&lt;/p&gt;
&lt;!-- more --&gt;
&lt;p&gt;Java 编程语言是强类型和静态类型的。该规范清楚地区分了编译时错误（可以且必须在编译时检测到）和运行时发生的错误、编译时通常包括将程序装换为与机器无关的字节码表示形式。运行时活动包括加载和链接执行程序所需的类、可选的机器底阿妈生成和程序的动态优化、以及实际的程序执行。&lt;/p&gt;
&lt;p&gt;Java 编程语言是一种相对高级的语言，因为通过该语言无法获得机器表示的细节。它包括自动存储管理，通常使用垃圾收集器以避免显式释放的安全问题（如 C 的 &lt;code&gt;free&lt;/code&gt; 或 C++ 的 &lt;code&gt;delete&lt;/code&gt; ）。高性能的垃圾收集实现可以有有限的暂停，以支持系统编程和实施应用程序。该语言不包括任何不安全的结构，例如不进行索引检查的数组访问，因为这种不安全的结构将导致程序以未指定的方式运行。&lt;/p&gt;
&lt;p&gt;Java 编程语言通常被编译成* Java 虚拟机规范 Java SE 8 版* 定义的字节码指令集和二进制格式。&lt;/p&gt;
&lt;h2 id=&#34;11-organization-of-the-specification&#34;&gt;1.1 Organization of the Specification&lt;/h2&gt;
&lt;p&gt;第 2 章描述了语法和用来表示语言的词汇语法和句法语法的符号。&lt;/p&gt;
&lt;p&gt;第 3 章描述了基于 C 和 C++ 的 Java 编程语言的词法结构。该语言是用 Unicode 字符集编写的、它支持在只支持 ASCII 的系统上编写 Unicode 字符。&lt;/p&gt;
&lt;p&gt;第 4 章描述了类型、值和变量、类型被细分为基本类型（primitive types）和引用类型（reference types）。&lt;/p&gt;
&lt;p&gt;基本类型被定义为在所有机器和所有实现中是相同的，并且是各种大小的二进制补码整数、单精度和双精度 IEEE 754 标准浮点数、布尔类型和 Unicode 字符 char 类型。基本类型的值不共享状态。&lt;/p&gt;
&lt;p&gt;引用类型是类（class）类型、接口（interface）类型和数组（array）类型。引用类型由动态创建的对象实现，这些对象可以是类或数组的实例。可以存在对每个对象的许多引用。所有对象（包括数组）都支持类对象的方法，类对象是类层次结构的（单一）根。预定义的字符串（&lt;code&gt;String&lt;/code&gt;）类支持 Unicode 字符串。存在用于在对象内部包装原始值的类。在许多情况下，包装和解包是由编译器自动执行的（在这种情况想，包装称为装箱（boxing），解包成为拆箱（unboxing））。类和接口声明可以是泛型的，也就是说，它们可以被其他引用类型参数化。然后可以用特定的类型参数来调用这样的声明。&lt;/p&gt;
&lt;p&gt;变量是类型化的存储位置。一个原始类型的变量保存该原始类型的值。一个类类型的变量可以包含一个空引用或一个对象的引用，该对象的类型是该类类型或该类类型的任何子类。接口类型的变量可以包含一个空引用或对实现该接口的任何类的实例的引用。数组类型的变量可以包含空引用或对数组的引用。&lt;code&gt;Object&lt;/code&gt; 类类型的变量可以包含一个空引用或对任何对象的引用，无论是类实例还是数组。&lt;/p&gt;
&lt;p&gt;第 5 章描述了转换和数字提升（numeric promotions）。转换会改变编译时类型，有时还会改变表达式的值。这些转换包括基本类型和引用类型之间的装箱和拆箱转换。数值提升用于将数值运算符的操作数转换为可执行运算的通用类型。语言上没有漏洞；在运行时检查引用类型的强制转换，以确保类型安全。&lt;/p&gt;
&lt;p&gt;第 6 章描述了声明和命名，以及如何确定名字的含义。语言不要求在使用类型或其成员变量之前声明它们。声明顺序只对局部变量、局部类以及类或接口中字段的初始值设定项的顺序有意义。&lt;/p&gt;
&lt;p&gt;Java 编程语言提供了对命名作用域的控制，并支持对包、类和接口成员的外部访问的限制。这对于大型项目中区分类型的用户和谁能扩展类型提供了很大的帮助。同时这里也给出了更加具有可读性程序的命名习惯。&lt;/p&gt;
&lt;p&gt;第 7 章描述了程序的结构，程序的结构被组织成了各种包，这就像模块化概念中的各种模块。包的成员是类、接口和子包。每个包都是一个编译单元。每个编译单元包含类型声明的短名称和从其他包里导入的类型的短名称。包是以一个层次性命名空间进行命名的，因特网域名系统通常被用来组成唯一的包名。&lt;/p&gt;
&lt;p&gt;第 8 章描述了类。类的成员包括类、接口、字段（变量）和方法。类方法的调用可以不使用对象的引用。实例变量是在作为类实例的对象中动态创建的。实例方法在类的实例上被调用；在方法执行期间实例就成为当前对象 this，以此支持面向对象的编程风格。&lt;/p&gt;
&lt;p&gt;类支持单个实现继承，其中每个实现类派生于单个父类，最终都派生于类 &lt;code&gt;Object&lt;/code&gt;。类类型的遍历可以引用该类或该类的任何子类的实例，允许新类型以多种形式与现有方法一起使用。&lt;/p&gt;
&lt;p&gt;类支持使用同步方法进行并发编程。方法声明了在执行过程中可能出现的检查异常，这允许编译时检查以确保异常情况得到处理。对象可以声明一个 &lt;code&gt;finalize&lt;/code&gt; 方法，该对象将在对象被垃圾收集器丢弃之前被调用，从而允许对象清理它们的状态。&lt;/p&gt;
&lt;p&gt;为了简单起见，Java 语言没有将声明头文件（C 和 C++ 用头文件提前声明类名，函数名）和类的实现分开，也没有分开的类型和类层次结构。&lt;/p&gt;
&lt;p&gt;一种特殊形式的类，枚举，支持小型值集的定义，以及以类型安全的方式对它们进行操作。与其他语言中的枚举不同，枚举是对象，可能有自己的方法。&lt;/p&gt;
&lt;p&gt;第 9 章描述了接口类型，它声明了一组抽象方法、成员类型和常量。在其他方面不相关的类可以实现相同的接口类型。接口类型的变量可以包含对实现该接口的任何对象的引用。支持多接口继承。&lt;/p&gt;
&lt;p&gt;注解类型属于特殊接口用来做注解声明。Java 程序语言中这种注解任何方面都不会影响程序的语义。然而，注解给各种工具提供了非常有用的输入。&lt;/p&gt;
&lt;p&gt;第 10 章描述了数组。数组访问包括边界检查。数组是动态创建的对象，可以赋值给 &lt;code&gt;Object&lt;/code&gt; 类型的变量。Java 语言支持数组的数组，而不是多维数组。&lt;/p&gt;
&lt;p&gt;第 11 章描述了异常，它是不可恢复的，并与语言的语义和并发机制完全集成。Java 语言提供了三种类型的异常：收件异常（checked exception）、运行时异常（run-time exception）、错误（error）。编译器只保证方法和构造器上具有受检异常声明的哪些异常会被合适的处理。者提供了编译使其检查异常处理器的存在，极大的保证了程序正常。大多数用户定义的异常都应该是受检异常。Java 虚拟机检测到的程序中的无效操作会导致运行时异常，例如 &lt;code&gt;NullPointerException&lt;/code&gt;。错误是由 Java 虚拟机检测到的错误导致的，比如 &lt;code&gt;OutOfMemoryError&lt;/code&gt;。大多数简单的程序不会去处理错误异常。&lt;/p&gt;
&lt;p&gt;第 12 章描述了在程序执行过程中发生的活动。程序通常存储为已编译类和接口的二进制文件。这些二进制文件可以加载到 Java 虚拟机中，链接到其他类和接口，并进行初始化。&lt;/p&gt;
&lt;p&gt;在初始化后，可以使用类方法和类变量。可以实例化一些类以创建类类型的新对象。作为类实例的对象还包含类的每个父类的一个实例，对象的创建涉及到这些父类实例的递归创建。&lt;/p&gt;
&lt;p&gt;当一个对象不再被引用时，他可能会被垃圾收集器回收。如果对象声明了终结器（finalizer），则在对象被回收之前会执行终结器，以给对象最后一次机会来清理，否则那些资源无法被释放。当不再需要某个类时，可以将其卸载。&lt;/p&gt;
&lt;p&gt;第 13 章描述了二进制兼容性，说明了对于那些还没有重新编译，但是引用了修改类的类的影响。这些考虑因素是开发人员感兴趣的，开发人员通常会通过 Internet 在一系列连续的版本中广泛分发这些类型的产品。好的程序开发环境会在类型改变时自动重新编译相关代码，所以大多数程序员不需要关心这些细节。&lt;/p&gt;
&lt;p&gt;第 14 章描述了基于 C 和 C++ 的块（block）和语句（statements）。该语言没有 &lt;code&gt;goto&lt;/code&gt; 语句，但是有带标签的 &lt;code&gt;break&lt;/code&gt; 和 &lt;code&gt;continue&lt;/code&gt; 语句。与 C 不同，Java 编程语言要求在控制流语句中使用布尔（或布尔）表达式，并且不隐式地将类型转换为布尔（除了通过拆箱），希望在编译时捕捉更多的错误。&lt;code&gt;synchronized&lt;/code&gt; 语句提供基本的对象级监视器锁定。&lt;code&gt;try&lt;/code&gt; 语句可以包含 &lt;code&gt;catch&lt;/code&gt; 和 &lt;code&gt;finally&lt;/code&gt; 子句，以防止非本地控制转移（内部 Exception 会直接打断当前代码执行的流程）。&lt;/p&gt;
&lt;p&gt;第 15 章描述了表达式。为了增加确定性和可移植性，这个文档明确了表达式求值的（明显的）顺序。重载的方法和构造函数会在编译时被解析到合适的而且最具体的方法和构造函数上。&lt;/p&gt;
&lt;p&gt;第 16 章描述了语言确保局部变量在使用前被明确设置的精确方式。虽然所有其他变量都自动初始化为默认值，但 Java 编程语言不会自动初始化局部变量，以避免掩盖程序错误。&lt;/p&gt;
&lt;p&gt;第 17 章描述了线程和锁的语义，这些都是基于源自 Mesa 程序语言提出的 monitor-based 并发性。Java 编程语言为支持高性能实现的共享内存多处理器指定了内存模型。&lt;/p&gt;
&lt;p&gt;第 18 章描述了各种类型推断算法，用于测试泛型方法的实用性和推断泛型方法调用中的类型。&lt;/p&gt;
&lt;p&gt;第 19 张介绍了 Java 语言的语法。&lt;/p&gt;
&lt;h2 id=&#34;12-example-programs&#34;&gt;1.2 Example Programs&lt;/h2&gt;
&lt;p&gt;正文中给出的大多数示例程序都可以执行，并且在形式上类似于：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;class Test {
    public static void main(String[] args) {
        for (int i = 0; i &amp;lt; args.length; i++)
            System.out.print(i == 0 ? args[i] : &amp;quot; &amp;quot; + args[i]);
        System.out.println();
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在安装了 Oracle JDK 的机器上，可以通过给出以下命令来编译和执行这个存储在文件 &lt;code&gt;Test.java&lt;/code&gt; 中的类：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;javac Test.java
java Test Hello, world.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;产生输出：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Hello, world.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;13-notation&#34;&gt;1.3 Notation&lt;/h2&gt;
&lt;p&gt;在本规范中，我们只的是来自 Java SE 平台 API 的类和接口。每当我们使用单个标识符 &lt;code&gt;N&lt;/code&gt; 引用一个类或接口（除了在实例中声明的那些）时，意图引用的是 &lt;code&gt;java.lang&lt;/code&gt; 包中名为 &lt;code&gt;N&lt;/code&gt; 的类或接口。对于 &lt;code&gt;java.lang&lt;/code&gt; 之外的包中的类或接口，我们使用规范名称（canonical name，&lt;a href=&#34;https://docs.oracle.com/javase/specs/jls/se8/html/jls-6.html#jls-6.7&#34;&gt;§6.7&lt;/a&gt; ）。&lt;/p&gt;
&lt;p&gt;旨在阐明规范的非规范性信息以较小的缩进文本给出。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;这是非规范性信息。它提供直觉、基本原理、建议、例子等。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Java 编程语言的类型系统有时依赖于&lt;em&gt;替换&lt;/em&gt;的概念。符号 [F&lt;sub&gt;1&lt;/sub&gt;:=T&lt;sub&gt;1&lt;/sub&gt;, ..., F&lt;sub&gt;n&lt;/sub&gt;:=T&lt;sub&gt;n&lt;/sub&gt;] 表示 1 ≤ i ≤ n 是 T&lt;sub&gt;i&lt;/sub&gt; 对 F&lt;sub&gt;i&lt;/sub&gt; 的替换。&lt;/p&gt;
&lt;h2 id=&#34;14-relationship-to-predefined-classes-and-interfaces&#34;&gt;1.4 Relationship to Predefined Classes and Interfaces&lt;/h2&gt;
&lt;p&gt;如上所述，该规范经常引用 Java SE 平台 API 的类。特别是，有些类与 Java 编程语言有着特殊的关系。例如 &lt;code&gt;Object&lt;/code&gt;、&lt;code&gt;Class&lt;/code&gt;、&lt;code&gt;ClassLoader&lt;/code&gt;、&lt;code&gt;String&lt;/code&gt;、&lt;code&gt;Thread&lt;/code&gt; 等类，以及 &lt;code&gt;java.lang.reflect&lt;/code&gt; 包中的类和接口等。改规范约束了这些类和接口的行为，但没有为它们提供完整的规范。读者可以参考 Java SE 平台 API 文档。&lt;/p&gt;
&lt;p&gt;因此，本规范没有详细描述反射。许多语言结构在核心反射 API（&lt;code&gt;java.lang.reflect&lt;/code&gt;）和语言模型 API（&lt;code&gt;javax.lang.model&lt;/code&gt;）中都有类似的内容，但这里一般不讨论这些内容。例如，当我们列出创建一个对象的方法时，我们通常不包括核心反射 API 完成这个任务的方法。读者应该知道这些额外的机制，即使它们在正文中没有提到。&lt;/p&gt;
&lt;h2 id=&#34;15-feedback&#34;&gt;1.5 Feedback&lt;/h2&gt;
&lt;p&gt;欢迎读者向 jls-jvms-spec-comments@openjdk.java.net 报告 Java 语言规范中的技术错误和歧义。&lt;/p&gt;
&lt;p&gt;有关 &lt;code&gt;javac&lt;/code&gt; （Java 编程语言的参考编译器） 的行为，特别是它是否符合本规范的问题，可以发送给 compiler-dev@openjdk.java.net。&lt;/p&gt;
&lt;h2 id=&#34;16-references&#34;&gt;1.6 References&lt;/h2&gt;
&lt;h3 id=&#34;bibliography&#34;&gt;Bibliography&lt;/h3&gt;
&lt;p&gt;Apple Computer. &lt;em&gt;Dylan Reference Manual.&lt;/em&gt; Apple Computer Inc., Cupertino, California. September 29, 1995.&lt;/p&gt;
&lt;p&gt;Bobrow, Daniel G., Linda G. DeMichiel, Richard P. Gabriel, Sonya E. Keene, Gregor Kiczales, and David A. Moon.* Common Lisp Object System Specification*, X3J13 Document 88-002R, June 1988; appears as Chapter 28 of Steele, Guy. &lt;em&gt;Common Lisp: The Language&lt;/em&gt;, 2nd ed. Digital Press, 1990, ISBN 1-55558-041-6, 770-864.&lt;/p&gt;
&lt;p&gt;Ellis, Margaret A., and Bjarne Stroustrup. &lt;em&gt;The Annotated C++ Reference Manual&lt;/em&gt;. Addison-Wesley, Reading, Massachusetts, 1990, reprinted with corrections October 1992, ISBN 0-201-51459-1.&lt;/p&gt;
&lt;p&gt;Goldberg, Adele and Robson, David. &lt;em&gt;Smalltalk-80: The Language&lt;/em&gt;. Addison-Wesley, Reading, Massachusetts, 1989, ISBN 0-201-13688-0.&lt;/p&gt;
&lt;p&gt;Harbison, Samuel. &lt;em&gt;Modula-3&lt;/em&gt;. Prentice Hall, Englewood Cliffs, New Jersey, 1992, ISBN 0-13-596396.&lt;/p&gt;
&lt;p&gt;Hoare, C. A. R. &lt;em&gt;Hints on Programming Language Design&lt;/em&gt;. Stanford University Computer Science Department Technical Report No. CS-73-403, December 1973. Reprinted in SIGACT/SIGPLAN Symposium on Principles of Programming Languages. Association for Computing Machinery, New York, October 1973.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;IEEE Standard for Binary Floating-Point Arithmetic&lt;/em&gt;. ANSI/IEEE Std. 754-1985. Available from Global Engineering Documents, 15 Inverness Way East, Englewood, Colorado 80112-5704 USA; 800-854-7179.&lt;/p&gt;
&lt;p&gt;Kernighan, Brian W., and Dennis M. Ritchie. &lt;em&gt;The C Programming Language&lt;/em&gt;, 2nd ed. Prentice Hall, Englewood Cliffs, New Jersey, 1988, ISBN 0-13-110362-8.&lt;/p&gt;
&lt;p&gt;Madsen, Ole Lehrmann, Birger Møller-Pedersen, and Kristen Nygaard. &lt;em&gt;Object-Oriented Programming in the Beta Programming Language&lt;/em&gt;. Addison-Wesley, Reading, Massachusetts, 1993, ISBN 0-201-62430-3.&lt;/p&gt;
&lt;p&gt;Mitchell, James G., William Maybury, and Richard Sweet. &lt;em&gt;The Mesa Programming Language, Version 5.0&lt;/em&gt;. Xerox PARC, Palo Alto, California, CSL 79-3, April 1979.&lt;/p&gt;
&lt;p&gt;Stroustrup, Bjarne. &lt;em&gt;The C++ Progamming Language&lt;/em&gt;, 2nd ed. Addison-Wesley, Reading, Massachusetts, 1991, reprinted with corrections January 1994, ISBN 0-201-53992-6.&lt;/p&gt;
&lt;p&gt;Unicode Consortium, The. &lt;em&gt;The Unicode Standard, Version 6.2.0&lt;/em&gt;. Mountain View, California, 2012, ISBN 978-1-936213-07-8.&lt;/p&gt;
">Chapter 1. Interduction</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://wenbozhangw.github.io/post/preface-to-the-java-se-8-edition/"" data-c="
          &lt;p&gt;&lt;strong&gt;Alex Buckley&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1996 年，James Gosling、Bill Joy 和 Guy Steele 为 &lt;em&gt;Java® 语言规范&lt;/em&gt; 的第一版写了：&lt;br&gt;
“我们相信 Java 编程语言是一种成熟的语言，可以广泛使用。尽管如此，我们预计未来几年该语言会发生一些演变。我们打算以与现在应用程序完全兼容的方式管理这种演变。”&lt;/p&gt;
&lt;p&gt;Java SE 8 代表了 Java 语言历史上最大的一次金华。相对较少的特性 —— lambda 表达式、方法引用和函数式接口 —— 结合起来提供了一个融合面向对象和函数式风格的编程模型。在 Brian Goetz 的领导下，这种融合以一种鼓励最佳实践的方式完成 —— 不变性、无状态、组合性 —— 同时保留“Java的感觉” —— 可读性、简单性、通用性。&lt;/p&gt;
&lt;p&gt;至关重要的是，Java SE 平台的库与 Java 语言共同发展。这意味着使用 lambda 表达式和方法引用来表示行为 —— 例如，应用于列表中每个元素的操作 —— 是 &amp;quot;开箱即用&amp;quot; 的高效和高性能。以类似的方式，Java 虚拟机与 Java 语言共同进化，以确保在独立编译的约束条件下， default 方法在编译时和运行时尽可能一致地支持库的发展。&lt;/p&gt;
&lt;p&gt;自 20 世纪 90 年代以来，向 Java 语言添加一级函数的计划就已经出现了。2007 年左右的 BGGA 和 CICE 提案为这个话题带来了新的活力，而 2009 年左右在 OpenJDK 中创建的项目 Lambda 吸引了前所未有的兴趣。Java SE 7 中向 JVM 添加的方法句柄为新的实现技术打开了大门，同时保留了“一次编写，随处运行”的原则。随着时间的过去，语言的变化由 JSR 335 —— Java编程语言的Lambda表达式 —— 监督，其专家组包括 Joshua Bloch、Kevin Bourrillion、Andrey Breslav、Rémi Forax、Dan Heidinga、Doug Lea、Bob Lee、David Lloyd、Sam Pullara、Srikanth Sankaran 和 Vladimir Zakharov。&lt;/p&gt;
&lt;p&gt;编程语言设计通常涉及处理完全不为语言用户所知的复杂程度。（因此，它经常被比作冰山：它 90% 的部分是看不见的。）在 JSR 335 中，最大的复杂性隐藏在隐式类型 lambda 表达式与重载解析的交互中。在这一领域和许多其他领域，Oracle 的 Dan Smith 做了一项出色的工作，彻底地指定了所需的行为。他的话可以在整个规范中找到，包括一个关于类型推断的全新章节。&lt;/p&gt;
&lt;p&gt;Java SE 8 中的另一个举措是增强注解的实用性，这是 Java 语言最流行的特性之一。首先，Java 语法已经扩展到允许在许多语言结构中对类型进行注解，从而形成了新的静态分析工具（如 Checker 框架）的基础。这个特性由 JSR 308 “Java类型注解” 指定，由 Michael Ernst 和我自己、Doug Lea 和 Srikanth Sankaran 组成的专家组负责。该规范中涉及的变化是广泛的，Michael Ernst 和 Werner Dietl 多年来的不懈努力得到了热烈的认可。其次，注解可以在语言构造上“重复”，这对用注解类型建模特定领域配置的 api 有很大的好处。Java EE 的 Michael Keith 和 Bill Shannon 发起并指导了这个特性。&lt;/p&gt;
&lt;p&gt;Oracle Java 平台组的许多同事已经为该规范提供了宝贵的支持：Leonid Arbouzov, Mandy Chung, Joe Darcy, Robert Field, Joel Borggrén-Franck, Sonali Goel, Jon Gibbons, Jeannette Hung, Stuart Marks, Eric McCorkle, Matherey Nunez, Mark Reinhold, Vicente Romero, John Rose, Georges Saab, Steve Sides, Bernard Traversat和Michel Trudeau。&lt;/p&gt;
&lt;p&gt;也许最应该感谢的是编译器工程师，他们把规范变成了真正的软件。Oracle 的 Maurizio Cimadamore 从最早开始就英勇地致力于 lambda 表达式的设计和在 javac 中的实现。Eclipse 中对 Java SE 8 特性的支持由 Jayaprakash Arthanareeswaran、Shankha Banerjee、Anirban Chakraborty、Andrew Clement、Stephan Herrmann、Markus Keller、Jesper Møller、Manoj Palat、Srikanth Sankaran 和 Olivier Thomann 贡献；Anna Kozlova, Alexey Kudravtsev 和 Roman Shevchenko 合著的 IntelliJ 。他们值得整个 Java 社区的感谢。&lt;/p&gt;
&lt;p&gt;Java SE 8 是 Java 语言的复兴。虽然有些人在寻找“下一个伟大的语言”，但我们相信，用 Java 编程比以往任何时候都更令人兴奋和高效。我们希望它继续适合你。&lt;/p&gt;
">Preface to the Java SE 8 Edition</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://wenbozhangw.github.io/post/httpclient-lian-jie-wu-fa-shi-fang-wen-ti/"" data-c="
          &lt;p&gt;在中银消金三方服务平台，数据源配置中可以配置数据源调用的&lt;strong&gt;超时时间&lt;/strong&gt;，代码中使用这个用户配置的&lt;strong&gt;超时时间&lt;/strong&gt;作为 &lt;code&gt;connectionRequestTimeout&lt;/code&gt;、&lt;code&gt;connectionTimeout&lt;/code&gt; 和 &lt;code&gt;socketTimeout&lt;/code&gt; 参数。在数据源调用明细中，明显可以看出数据源的调用时长有远大于配置的&lt;strong&gt;超时时间&lt;/strong&gt;，客户提出不符合预期，要求数据源的调用时间在超过配置的&lt;strong&gt;超时时间&lt;/strong&gt;后能够终止。&lt;/p&gt;
&lt;!-- more --&gt;
&lt;h2 id=&#34;httpclient-超时参数&#34;&gt;httpclient 超时参数&lt;/h2&gt;
&lt;p&gt;上面提到，代码中使用配置的超时时间作为 httpclient 的 &lt;code&gt;connectionRequestTimeout&lt;/code&gt;、&lt;code&gt;connectionTimeout&lt;/code&gt; 和 &lt;code&gt;socketTimeout&lt;/code&gt; 参数，下面简单介绍一下这三个参数的含义。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;connectionRequestTimeout&lt;/code&gt;：指从连接池获取连接的超时时间（当请求并发数量大于连接池中的连接数量时，则获取不到连接的请求会被放入 pending 队列等待，如果超过设定的时间，则抛出超时异常）。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;connectionTimeout&lt;/code&gt;：指客户端和服务器建立连接的超时时间。（当客户端和服务器在建立链接时，如果在指定时间内无法成功建立链接，则抛出 &lt;code&gt;ConnectionTimeoutException&lt;/code&gt;）。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;socketTimeout&lt;/code&gt;：指客户端从服务器读取数据的超时时间，即客户端和服务器 socket 通信的超时时间，其实这个时间是客户端两次读取数据的最长时间，如果客户端在网络抖动的情况下，每次返回部分数据，两次数据包的时间在设定时间之内，也是不会超时的。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;问题背景&#34;&gt;问题背景&lt;/h2&gt;
&lt;p&gt;为了保证计时的准确性，我们采用异步提交线程池，用 &lt;code&gt;Future.get(timeout)&lt;/code&gt; 的方式保证任务可以在超过设定时间后，计时的准确性，大致代码如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class Main {

    private static final Logger logger = LoggerFactory.getLogger(Main.class);

    private static final ThreadPoolExecutor executor = new ThreadPoolExecutor(10, 10, 60,
            java.util.concurrent.TimeUnit.SECONDS, new java.util.concurrent.LinkedBlockingQueue&amp;lt;&amp;gt;(10), new ThreadPoolExecutor.CallerRunsPolicy());

    public static void main(String[] args) throws IOException, InterruptedException {

        for (int i = 0; i &amp;lt; 10; i++) {
            // 请求一个阻塞接口，不会返回数据，必定超时
            HttpGet httpGet = new HttpGet(&amp;quot;*****&amp;quot;);
            CloseableHttpResponse response = null;
            Future&amp;lt;CloseableHttpResponse&amp;gt; future = null;
            try {
                future = executor.submit(() -&amp;gt; {
                    try {
                        return HttpClientUtil.execute(httpGet);
                    } catch (Exception e) {
                        logger.error(&amp;quot;&amp;quot;, e);
                        return null;
                    }
                });
                response = future.get(5, TimeUnit.SECONDS);
                System.out.println(&amp;quot;response = &amp;quot; + response);
            } catch (Exception e) {
                if (e instanceof TimeoutException &amp;amp;&amp;amp; future != null) {
                    logger.info(Thread.currentThread().getName() + &amp;quot; start cancel future&amp;quot;);
                    logger.error(&amp;quot;&amp;quot;, e);
                }
            } finally {
                httpGet.abort();
                httpGet.releaseConnection();
                if (null != response) {
                    EntityUtils.consume(response.getEntity());
                }
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在功能上线的两周后，现场反馈说有大量超时，导致大量调用返回超时异常，出现异常&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;org.apache.http.conn.ConnectionPoolTimeoutException: Timeout waiting for connection from pool
        at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.leaseConnection(PoolingHttpClientConnectionManager.java:313)
        at org.apache.http.impl.conn.PoolingHttpClientConnectionManager$1.get(PoolingHttpClientConnectionManager.java:279)
        at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:191)
        at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:185)
        at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
        at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:110)
        at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
        at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
        at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108)
        at cn.tongdun.freyr.http.SimpleGetRequestExecutor.lambda$execute$0(SimpleGetRequestExecutor.java:56)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;出现大量异常后，服务就无法使用了，即任何接口的调用都是超时状态。此时通过 debug 发现，即使没有调用，连接也依旧处于 &lt;code&gt;lease&lt;/code&gt; 状态。&lt;/p&gt;
&lt;h3 id=&#34;问题排查&#34;&gt;问题排查&lt;/h3&gt;
&lt;p&gt;首先，出现 &lt;code&gt;Timeout waiting for connection from pool&lt;/code&gt; 是由于 httpclient 在从连接池获取连接时，在 &lt;code&gt;connectionRequectTimeout&lt;/code&gt; 时间内没有获取到连接，而抛出的异常信息，从连接池获取连接的流程如下。&lt;/p&gt;
&lt;h4 id=&#34;httpclient-从连接池获取连接&#34;&gt;httpclient 从连接池获取连接&lt;/h4&gt;
&lt;p&gt;首先，根据请求的路由和 token 构建 &lt;code&gt;ConnectionRequest&lt;/code&gt; 对象，此对象保存了获取从连接池获取连接的 &lt;code&gt;get&lt;/code&gt; 方法，代码如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Override
    public CloseableHttpResponse execute(
            final HttpRoute route,
            final HttpRequestWrapper request,
            final HttpClientContext context,
            final HttpExecutionAware execAware) throws IOException, HttpException {
        // ......
        Object userToken = context.getUserToken();

        final ConnectionRequest connRequest = connManager.requestConnection(route, userToken);
        if (execAware != null) {
            if (execAware.isAborted()) {
                connRequest.cancel();
                throw new RequestAbortedException(&amp;quot;Request aborted&amp;quot;);
            } else {
                execAware.setCancellable(connRequest);
            }
        }

        // .....
}        
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们可以看到，此时使用的超时时间就是我们传入配置的 &lt;code&gt;connectionRequestTimeout&lt;/code&gt;，下面我们看下 &lt;code&gt;ConnectionRequest&lt;/code&gt; 对象的构建。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    @Override
    public ConnectionRequest requestConnection(
            final HttpRoute route,
            final Object state) {
        Args.notNull(route, &amp;quot;HTTP route&amp;quot;);
        if (this.log.isDebugEnabled()) {
            this.log.debug(&amp;quot;Connection request: &amp;quot; + format(route, state) + formatStats(route));
        }
        final Future&amp;lt;CPoolEntry&amp;gt; future = this.pool.lease(route, state, null);
        return new ConnectionRequest() {

            @Override
            public boolean cancel() {
                return future.cancel(true);
            }

            @Override
            public HttpClientConnection get(
                    final long timeout,
                    final TimeUnit tunit) throws InterruptedException, ExecutionException, ConnectionPoolTimeoutException {
                final HttpClientConnection conn = leaseConnection(future, timeout, tunit);
                if (conn.isOpen()) {
                    final HttpHost host;
                    if (route.getProxyHost() != null) {
                        host = route.getProxyHost();
                    } else {
                        host = route.getTargetHost();
                    }
                    final SocketConfig socketConfig = resolveSocketConfig(host);
                    conn.setSocketTimeout(socketConfig.getSoTimeout());
                }
                return conn;
            }

        };

    }

    protected HttpClientConnection leaseConnection(
            final Future&amp;lt;CPoolEntry&amp;gt; future,
            final long timeout,
            final TimeUnit tunit) throws InterruptedException, ExecutionException, ConnectionPoolTimeoutException {
        final CPoolEntry entry;
        try {
            entry = future.get(timeout, tunit);
            if (entry == null || future.isCancelled()) {
                throw new InterruptedException();
            }
            Asserts.check(entry.getConnection() != null, &amp;quot;Pool entry with no connection&amp;quot;);
            if (this.log.isDebugEnabled()) {
                this.log.debug(&amp;quot;Connection leased: &amp;quot; + format(entry) + formatStats(entry.getRoute()));
            }
            return CPoolProxy.newProxy(entry);
        } catch (final TimeoutException ex) {
            throw new ConnectionPoolTimeoutException(&amp;quot;Timeout waiting for connection from pool&amp;quot;);
        }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们可以看到，代码中捕获了 &lt;code&gt;TimeoutException&lt;/code&gt;，并重新构建 &lt;code&gt;ConnectionPoolTimeoutException&lt;/code&gt;，也就是说，&lt;code&gt;future.get&lt;/code&gt; 会在超时的时候抛出 &lt;code&gt;TimeoutException&lt;/code&gt;，然后被外层的 &lt;code&gt;catch&lt;/code&gt; 捕获，下面我们看 &lt;code&gt;final Future&amp;lt;CPoolEntry&amp;gt; future = this.pool.lease(route, state, null);&lt;/code&gt; 中的 &lt;code&gt;Future&lt;/code&gt; 是如何实现的：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    /**
     * {@inheritDoc}
     * &amp;lt;p&amp;gt;
     * Please note that this class does not maintain its own pool of execution
     * {@link Thread}s. Therefore, one &amp;lt;b&amp;gt;must&amp;lt;/b&amp;gt; call {@link Future#get()}
     * or {@link Future#get(long, TimeUnit)} method on the {@link Future}
     * returned by this method in order for the lease operation to complete.
     */
    @Override
    public Future&amp;lt;E&amp;gt; lease(final T route, final Object state, final FutureCallback&amp;lt;E&amp;gt; callback) {
        Args.notNull(route, &amp;quot;Route&amp;quot;);
        Asserts.check(!this.isShutDown, &amp;quot;Connection pool shut down&amp;quot;);

        return new Future&amp;lt;E&amp;gt;() {

            private final AtomicBoolean cancelled = new AtomicBoolean(false);
            private final AtomicBoolean done = new AtomicBoolean(false);
            private final AtomicReference&amp;lt;E&amp;gt; entryRef = new AtomicReference&amp;lt;E&amp;gt;(null);

            @Override
            public boolean cancel(final boolean mayInterruptIfRunning) {
                if (cancelled.compareAndSet(false, true)) {
                    done.set(true);
                    lock.lock();
                    try {
                        condition.signalAll();
                    } finally {
                        lock.unlock();
                    }
                    if (callback != null) {
                        callback.cancelled();
                    }
                    return true;
                } else {
                    return false;
                }
            }

            @Override
            public boolean isCancelled() {
                return cancelled.get();
            }

            @Override
            public boolean isDone() {
                return done.get();
            }

            @Override
            public E get() throws InterruptedException, ExecutionException {
                try {
                    return get(0L, TimeUnit.MILLISECONDS);
                } catch (final TimeoutException ex) {
                    throw new ExecutionException(ex);
                }
            }

            @Override
            public E get(final long timeout, final TimeUnit tunit) throws InterruptedException, ExecutionException, TimeoutException {
                final E entry = entryRef.get();
                if (entry != null) {
                    return entry;
                }
                synchronized (this) {
                    try {
                        for (;;) {
                            final E leasedEntry = getPoolEntryBlocking(route, state, timeout, tunit, this);
                            if (validateAfterInactivity &amp;gt; 0)  {
                                if (leasedEntry.getUpdated() + validateAfterInactivity &amp;lt;= System.currentTimeMillis()) {
                                    if (!validate(leasedEntry)) {
                                        leasedEntry.close();
                                        release(leasedEntry, false);
                                        continue;
                                    }
                                }
                            }
                            entryRef.set(leasedEntry);
                            done.set(true);
                            onLease(leasedEntry);
                            if (callback != null) {
                                callback.completed(leasedEntry);
                            }
                            return leasedEntry;
                        }
                    } catch (final IOException ex) {
                        done.set(true);
                        if (callback != null) {
                            callback.failed(ex);
                        }
                        throw new ExecutionException(ex);
                    }
                }
            }

        };
    }

 private E getPoolEntryBlocking(
            final T route, final Object state,
            final long timeout, final TimeUnit tunit,
            final Future&amp;lt;E&amp;gt; future) throws IOException, InterruptedException, TimeoutException {

        Date deadline = null;
        if (timeout &amp;gt; 0) {
            deadline = new Date (System.currentTimeMillis() + tunit.toMillis(timeout));
        }
        this.lock.lock();
        try {
            final RouteSpecificPool&amp;lt;T, C, E&amp;gt; pool = getPool(route);
            E entry;
            for (;;) {
                Asserts.check(!this.isShutDown, &amp;quot;Connection pool shut down&amp;quot;);
                for (;;) {
                    entry = pool.getFree(state);
                    if (entry == null) {
                        break;
                    }
                    if (entry.isExpired(System.currentTimeMillis())) {
                        entry.close();
                    }
                    if (entry.isClosed()) {
                        this.available.remove(entry);
                        pool.free(entry, false);
                    } else {
                        break;
                    }
                }
                if (entry != null) {
                    this.available.remove(entry);
                    this.leased.add(entry);
                    onReuse(entry);
                    return entry;
                }

                // New connection is needed
                final int maxPerRoute = getMax(route);
                // Shrink the pool prior to allocating a new connection
                final int excess = Math.max(0, pool.getAllocatedCount() + 1 - maxPerRoute);
                if (excess &amp;gt; 0) {
                    for (int i = 0; i &amp;lt; excess; i++) {
                        final E lastUsed = pool.getLastUsed();
                        if (lastUsed == null) {
                            break;
                        }
                        lastUsed.close();
                        this.available.remove(lastUsed);
                        pool.remove(lastUsed);
                    }
                }

                if (pool.getAllocatedCount() &amp;lt; maxPerRoute) {
                    final int totalUsed = this.leased.size();
                    final int freeCapacity = Math.max(this.maxTotal - totalUsed, 0);
                    if (freeCapacity &amp;gt; 0) {
                        final int totalAvailable = this.available.size();
                        if (totalAvailable &amp;gt; freeCapacity - 1) {
                            if (!this.available.isEmpty()) {
                                final E lastUsed = this.available.removeLast();
                                lastUsed.close();
                                final RouteSpecificPool&amp;lt;T, C, E&amp;gt; otherpool = getPool(lastUsed.getRoute());
                                otherpool.remove(lastUsed);
                            }
                        }
                        final C conn = this.connFactory.create(route);
                        entry = pool.add(conn);
                        this.leased.add(entry);
                        return entry;
                    }
                }

                boolean success = false;
                try {
                    if (future.isCancelled()) {
                        throw new InterruptedException(&amp;quot;Operation interrupted&amp;quot;);
                    }
                    pool.queue(future);
                    this.pending.add(future);
                    if (deadline != null) {
                        success = this.condition.awaitUntil(deadline);
                    } else {
                        this.condition.await();
                        success = true;
                    }
                    if (future.isCancelled()) {
                        throw new InterruptedException(&amp;quot;Operation interrupted&amp;quot;);
                    }
                } finally {
                    // In case of &#39;success&#39;, we were woken up by the
                    // connection pool and should now have a connection
                    // waiting for us, or else we&#39;re shutting down.
                    // Just continue in the loop, both cases are checked.
                    pool.unqueue(future);
                    this.pending.remove(future);
                }
                // check for spurious wakeup vs. timeout
                if (!success &amp;amp;&amp;amp; (deadline != null &amp;amp;&amp;amp; deadline.getTime() &amp;lt;= System.currentTimeMillis())) {
                    break;
                }
            }
            throw new TimeoutException(&amp;quot;Timeout waiting for connection&amp;quot;);
        } finally {
            this.lock.unlock();
        }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;通过代码，我们可以看到 lease 方法返回了 &lt;code&gt;Future&lt;/code&gt; 接口的匿名内部类实现，其中 &lt;code&gt;get(final long timeout, final TimeUnit tunit)&lt;/code&gt; 方法会在同步代码块下循环从连接池获取连接，即 &lt;code&gt;getPoolEntryBlocking&lt;/code&gt; 方法。&lt;/p&gt;
&lt;p&gt;在 &lt;code&gt;getPoolEntryBlocking&lt;/code&gt; 方法中，会在加锁情况下，循环获取连接，当获取连接为空时（即连接池中没有 &lt;code&gt;available&lt;/code&gt; 的连接），会执行 &lt;code&gt;success = this.condition.awaitUntil(deadline)&lt;/code&gt;，即阻塞到超时的死亡时间线，如果在阻塞过程中，有其他连接释放（释放的代码后面我们会看到），则会把 &lt;code&gt;success&lt;/code&gt; 置为 &lt;code&gt;true&lt;/code&gt;，如果没有在死亡线达到之前获取到连接，则 &lt;code&gt;success&lt;/code&gt; 为 &lt;code&gt;false&lt;/code&gt;，在最后，&lt;code&gt;(!success &amp;amp;&amp;amp; (deadline != null &amp;amp;&amp;amp; deadline.getTime() &amp;lt;= System.currentTimeMillis())&lt;/code&gt; 会跳出循环，抛出 &lt;code&gt; throw new TimeoutException(&amp;quot;Timeout waiting for connection&amp;quot;)&lt;/code&gt;，被外层捕获。&lt;/p&gt;
&lt;p&gt;这就是 httpclient 从连接池获取连接的过程，以及在超时情况下抛出的异常信息。&lt;/p&gt;
&lt;h4 id=&#34;httpclient-归还连接&#34;&gt;httpclient 归还连接&lt;/h4&gt;
&lt;p&gt;我们看到在使用 httpclient 的时候，在 &lt;code&gt;finally&lt;/code&gt; 代码块中，我们调用了 &lt;code&gt;abort&lt;/code&gt; 和 &lt;code&gt;releaseConnection&lt;/code&gt; 方法，用来释放 httpclient 连接，下面我们分析下如何释放连接归还连接池。&lt;/p&gt;
&lt;h5 id=&#34;abort-释放连接&#34;&gt;abort 释放连接&lt;/h5&gt;
&lt;p&gt;首先看 &lt;code&gt;abort&lt;/code&gt; 方法：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    @Override
    public void abort() {
        if (this.aborted.compareAndSet(false, true)) {
            final Cancellable cancellable = this.cancellableRef.getAndSet(null);
            if (cancellable != null) {
                cancellable.cancel();
            }
        }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;代码中，将 &lt;code&gt;abort&lt;/code&gt; 变量从 &lt;code&gt;false&lt;/code&gt; 置为 &lt;code&gt;true&lt;/code&gt;，之后获取 &lt;code&gt;Cancellable&lt;/code&gt;，并将其置空，调用 &lt;code&gt;cancel&lt;/code&gt; 方法，我们看下在何处会放入 &lt;code&gt;Cancellable&lt;/code&gt;：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    @Override
    public CloseableHttpResponse execute(
            final HttpRoute route,
            final HttpRequestWrapper request,
            final HttpClientContext context,
            final HttpExecutionAware execAware) throws IOException, HttpException {
       //  ......
        Object userToken = context.getUserToken();

        final ConnectionRequest connRequest = connManager.requestConnection(route, userToken);
        if (execAware != null) {
            if (execAware.isAborted()) {
                connRequest.cancel();
                throw new RequestAbortedException(&amp;quot;Request aborted&amp;quot;);
            } else {
                // ① 将 ConnectionRequest 放入 Cancellable
                execAware.setCancellable(connRequest);
            }
        }

        final RequestConfig config = context.getRequestConfig();

        final HttpClientConnection managedConn;
        try {
            final int timeout = config.getConnectionRequestTimeout();
            managedConn = connRequest.get(timeout &amp;gt; 0 ? timeout : 0, TimeUnit.MILLISECONDS);
        } catch(final InterruptedException interrupted) {
            Thread.currentThread().interrupt();
            throw new RequestAbortedException(&amp;quot;Request aborted&amp;quot;, interrupted);
        } catch(final ExecutionException ex) {
            Throwable cause = ex.getCause();
            if (cause == null) {
                cause = ex;
            }
            throw new RequestAbortedException(&amp;quot;Request execution failed&amp;quot;, cause);
        }

        context.setAttribute(HttpCoreContext.HTTP_CONNECTION, managedConn);

        if (config.isStaleConnectionCheckEnabled()) {
            // validate connection
            if (managedConn.isOpen()) {
                this.log.debug(&amp;quot;Stale connection check&amp;quot;);
                if (managedConn.isStale()) {
                    this.log.debug(&amp;quot;Stale connection detected&amp;quot;);
                    managedConn.close();
                }
            }
        }

        final ConnectionHolder connHolder = new ConnectionHolder(this.log, this.connManager, managedConn);
        try {
            if (execAware != null) {
                // ② 将 ConnectionHolder 放入 Cancellable
                execAware.setCancellable(connHolder);
            }
    // .....
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;第一处，将 &lt;code&gt;ConnectionRequest&lt;/code&gt; 放入。也就是说，如果此时是在执行从连接池获取连接之前调用了 &lt;code&gt;Cancellable.cancel&lt;/code&gt;，则会在构建好请求后，直接释放请求，抛出 &lt;code&gt;throw new RequestAbortedException(&amp;quot;Request aborted&amp;quot;);&lt;/code&gt; 异常；如果此时在连接获取过程中，在 &lt;code&gt;getPoolEntryBlocking&lt;/code&gt; 中调用 &lt;code&gt;Cancellable.cancel&lt;/code&gt;，在循环中会调用 &lt;code&gt;future.isCancelled()&lt;/code&gt; 判断是否取消任务，抛出 &lt;code&gt;throw new InterruptedException(&amp;quot;Operation interrupted&amp;quot;)&lt;/code&gt; 。&lt;/p&gt;
&lt;p&gt;第二处，即获取到连接后，将 &lt;code&gt;HttpClientConnection&lt;/code&gt; 的持有者 &lt;code&gt;ConnectionHolder&lt;/code&gt; 放入。此时，我们看 &lt;code&gt;ConnectionHolder&lt;/code&gt; 的 &lt;code&gt;cancel&lt;/code&gt; 方法的实现：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    @Override
    public boolean cancel() {
        final boolean alreadyReleased = this.released.get();
        log.debug(&amp;quot;Cancelling request execution&amp;quot;);
        abortConnection();
        return !alreadyReleased;
    }

    @Override
    public void abortConnection() {
        if (this.released.compareAndSet(false, true)) {
            synchronized (this.managedConn) {
                try {
                    this.managedConn.shutdown();
                    log.debug(&amp;quot;Connection discarded&amp;quot;);
                } catch (final IOException ex) {
                    if (this.log.isDebugEnabled()) {
                        this.log.debug(ex.getMessage(), ex);
                    }
                } finally {
                    this.manager.releaseConnection(
                            this.managedConn, null, 0, TimeUnit.MILLISECONDS);
                }
            }
        }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;ConnectionHolder&lt;/code&gt; 的 &lt;code&gt;cancel&lt;/code&gt; 方法调用了 &lt;code&gt;abortConnection&lt;/code&gt; 方法，在此方法中，首先将 &lt;code&gt;release&lt;/code&gt; 置为 &lt;code&gt;true&lt;/code&gt;，之后在同步代码块情况下，先调用 &lt;code&gt;this.managedConn.shutdown()&lt;/code&gt; 以下是该方法的源码：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    @Override
    public void shutdown() throws IOException {
        final Socket socket = this.socketHolder.getAndSet(null);
        if (socket != null) {
            // force abortive close (RST)
            try {
                socket.setSoLinger(true, 0);
            } catch (final IOException ex) {
            } finally {
                socket.close();
            }
        }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;主要功能是为了将 &lt;code&gt;Connection&lt;/code&gt; 的 Socket 对象置空，之后将 &lt;code&gt;socket&lt;/code&gt; 关闭。&lt;/p&gt;
&lt;p&gt;之后，在 &lt;code&gt;finally&lt;/code&gt; 中，调用 &lt;code&gt;manager.releaseConnection&lt;/code&gt; 方法，源码如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    @Override
    public void releaseConnection(
            final HttpClientConnection managedConn,
            final Object state,
            final long keepalive, final TimeUnit tunit) {
        Args.notNull(managedConn, &amp;quot;Managed connection&amp;quot;);
        synchronized (managedConn) {
            final CPoolEntry entry = CPoolProxy.detach(managedConn);
            if (entry == null) {
                return;
            }
            final ManagedHttpClientConnection conn = entry.getConnection();
            try {
                if (conn.isOpen()) {
                    final TimeUnit effectiveUnit = tunit != null ? tunit : TimeUnit.MILLISECONDS;
                    entry.setState(state);
                    entry.updateExpiry(keepalive, effectiveUnit);
                    if (this.log.isDebugEnabled()) {
                        final String s;
                        if (keepalive &amp;gt; 0) {
                            s = &amp;quot;for &amp;quot; + (double) effectiveUnit.toMillis(keepalive) / 1000 + &amp;quot; seconds&amp;quot;;
                        } else {
                            s = &amp;quot;indefinitely&amp;quot;;
                        }
                        this.log.debug(&amp;quot;Connection &amp;quot; + format(entry) + &amp;quot; can be kept alive &amp;quot; + s);
                    }
                    conn.setSocketTimeout(0);
                }
            } finally {
                this.pool.release(entry, conn.isOpen() &amp;amp;&amp;amp; entry.isRouteComplete());
                if (this.log.isDebugEnabled()) {
                    this.log.debug(&amp;quot;Connection released: &amp;quot; + format(entry) + formatStats(entry.getRoute()));
                }
            }
        }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在 &lt;code&gt;finally&lt;/code&gt; 中的 &lt;code&gt;pool.release&lt;/code&gt; 方法中：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    @Override
    public void release(final E entry, final boolean reusable) {
        this.lock.lock();
        try {
            if (this.leased.remove(entry)) {
                final RouteSpecificPool&amp;lt;T, C, E&amp;gt; pool = getPool(entry.getRoute());
                pool.free(entry, reusable);
                if (reusable &amp;amp;&amp;amp; !this.isShutDown) {
                    this.available.addFirst(entry);
                } else {
                    entry.close();
                }
                onRelease(entry);
                Future&amp;lt;E&amp;gt; future = pool.nextPending();
                if (future != null) {
                    this.pending.remove(future);
                } else {
                    future = this.pending.poll();
                }
                if (future != null) {
                    this.condition.signalAll();
                }
            }
        } finally {
            this.lock.unlock();
        }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们可以看到，连接对象从 &lt;code&gt;lease&lt;/code&gt; 队列移除，并调用 &lt;code&gt;pool.free&lt;/code&gt; 方法，将连接重新放回 &lt;code&gt;available&lt;/code&gt; 队列的第一个：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    public void free(final E entry, final boolean reusable) {
        Args.notNull(entry, &amp;quot;Pool entry&amp;quot;);
        final boolean found = this.leased.remove(entry);
        Asserts.check(found, &amp;quot;Entry %s has not been leased from this pool&amp;quot;, entry);
        if (reusable) {
            this.available.addFirst(entry);
        }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;注意，此处分别是 &lt;code&gt;ConnectionPool&lt;/code&gt; 和 &lt;code&gt;RouteSpecificPool&lt;/code&gt;，&lt;code&gt;ConnectionPool&lt;/code&gt; 包含了 &lt;code&gt;RouteSpecificPool&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;在将连接放回 &lt;code&gt;available&lt;/code&gt; 队列后，&lt;code&gt;pool.nexPending&lt;/code&gt; 获取待获取连接的挂起队列，移除一个获取连接，之后 &lt;code&gt;condition.signalAll()&lt;/code&gt; 通知所有的等待的 &lt;code&gt;future&lt;/code&gt; 获取连接。&lt;/p&gt;
&lt;h5 id=&#34;releaseconnection-释放连接&#34;&gt;releaseConnection 释放连接&lt;/h5&gt;
&lt;p&gt;我们来看 &lt;code&gt;releaseConnection&lt;/code&gt; 的代码：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    /**
     * A convenience method to simplify migration from HttpClient 3.1 API. This method is
     * equivalent to {@link #reset()}.
     *
     * @since 4.2
     */
    public void releaseConnection() {
        reset();
    }

    /**
     * Resets internal state of the request making it reusable.
     *
     * @since 4.2
     */
    public void reset() {
        final Cancellable cancellable = this.cancellableRef.getAndSet(null);
        if (cancellable != null) {
            cancellable.cancel();
        }
        this.aborted.set(false);
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们可以看到，此处也是使用和 &lt;code&gt;abort&lt;/code&gt; 一样的方式调用 &lt;code&gt;Cancellable.cancel&lt;/code&gt; 方法，但是，在方法最后，将 &lt;code&gt;aborted&lt;/code&gt; 设置为了 &lt;code&gt;false&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;简单翻一下方法注释，&lt;code&gt;Resets internal state of the request making it reusable.&lt;/code&gt;，即重置请求的内部状态，使其可以重新使用。 我们发现，&lt;code&gt;releaseConnection&lt;/code&gt; 的作用是使请求可以重用，所以将 &lt;code&gt;aborted&lt;/code&gt; 重新置为了 &lt;code&gt;false&lt;/code&gt;。&lt;/p&gt;
&lt;h2 id=&#34;问题处理&#34;&gt;问题处理&lt;/h2&gt;
&lt;p&gt;通过上面分析，我们发现，调用 &lt;code&gt;abort&lt;/code&gt; 方法时，将请求的 &lt;code&gt;aborted&lt;/code&gt; 标志设为了 &lt;code&gt;true&lt;/code&gt;，而调用 &lt;code&gt;releaseConnection&lt;/code&gt; 后，请求的 &lt;code&gt;aborted&lt;/code&gt; 标志被重置为了 &lt;code&gt;false&lt;/code&gt;。而在代码中，会通过 &lt;code&gt;aborted&lt;/code&gt; 标志判断当前请求是否可用：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    @Override
    public CloseableHttpResponse execute(
            final HttpRoute route,
            final HttpRequestWrapper request,
            final HttpClientContext context,
            final HttpExecutionAware execAware) throws IOException, HttpException {
        // 使用 aborted 判断是否需要取消 ConnectionRequest
        final ConnectionRequest connRequest = connManager.requestConnection(route, userToken);
        if (execAware != null) {
            if (execAware.isAborted()) {
                connRequest.cancel();
                throw new RequestAbortedException(&amp;quot;Request aborted&amp;quot;);
            } else {
                execAware.setCancellable(connRequest);
            }
        }

        // ......
      
        final ConnectionHolder connHolder = new ConnectionHolder(this.log, this.connManager, managedConn);
        try {
            if (execAware != null) {
                execAware.setCancellable(connHolder);
            }

            HttpResponse response;
            for (int execCount = 1;; execCount++) {

                if (execCount &amp;gt; 1 &amp;amp;&amp;amp; !RequestEntityProxy.isRepeatable(request)) {
                    throw new NonRepeatableRequestException(&amp;quot;Cannot retry request &amp;quot; +
                            &amp;quot;with a non-repeatable request entity.&amp;quot;);
                }

        // 使用 aborted 判断请求是否丢弃
                if (execAware != null &amp;amp;&amp;amp; execAware.isAborted()) {
                    throw new RequestAbortedException(&amp;quot;Request aborted&amp;quot;);
                }

                // ......

                final int timeout = config.getSocketTimeout();
                if (timeout &amp;gt;= 0) {
                    managedConn.setSocketTimeout(timeout);
                }

                // 使用 aborted 判断请求是否丢弃
                if (execAware != null &amp;amp;&amp;amp; execAware.isAborted()) {
                    throw new RequestAbortedException(&amp;quot;Request aborted&amp;quot;);
                }

                if (this.log.isDebugEnabled()) {
                    this.log.debug(&amp;quot;Executing request &amp;quot; + request.getRequestLine());
                }

                if (this.log.isDebugEnabled()) {
                    this.log.debug(&amp;quot;Executing request &amp;quot; + request.getRequestLine());
                }

                if (!request.containsHeader(AUTH.WWW_AUTH_RESP)) {
                    if (this.log.isDebugEnabled()) {
                        this.log.debug(&amp;quot;Target auth state: &amp;quot; + targetAuthState.getState());
                    }
                    this.authenticator.generateAuthResponse(request, targetAuthState, context);
                }
                if (!request.containsHeader(AUTH.PROXY_AUTH_RESP) &amp;amp;&amp;amp; !route.isTunnelled()) {
                    if (this.log.isDebugEnabled()) {
                        this.log.debug(&amp;quot;Proxy auth state: &amp;quot; + proxyAuthState.getState());
                    }
                    this.authenticator.generateAuthResponse(request, proxyAuthState, context);
                }

                response = requestExecutor.execute(request, managedConn, context);

                // The connection is in or can be brought to a re-usable state.
                if (reuseStrategy.keepAlive(response, context)) {
                    // Set the idle duration of this connection
                    final long duration = keepAliveStrategy.getKeepAliveDuration(response, context);
                    if (this.log.isDebugEnabled()) {
                        final String s;
                        if (duration &amp;gt; 0) {
                            s = &amp;quot;for &amp;quot; + duration + &amp;quot; &amp;quot; + TimeUnit.MILLISECONDS;
                        } else {
                            s = &amp;quot;indefinitely&amp;quot;;
                        }
                        this.log.debug(&amp;quot;Connection can be kept alive &amp;quot; + s);
                    }
                    connHolder.setValidFor(duration, TimeUnit.MILLISECONDS);
                    connHolder.markReusable();
                } else {
                    connHolder.markNonReusable();
                }

                if (needAuthentication(
                        targetAuthState, proxyAuthState, route, response, context)) {
                    // Make sure the response body is fully consumed, if present
                    final HttpEntity entity = response.getEntity();
                    if (connHolder.isReusable()) {
                        EntityUtils.consume(entity);
                    } else {
                        managedConn.close();
                        if (proxyAuthState.getState() == AuthProtocolState.SUCCESS
                                &amp;amp;&amp;amp; proxyAuthState.isConnectionBased()) {
                            this.log.debug(&amp;quot;Resetting proxy auth state&amp;quot;);
                            proxyAuthState.reset();
                        }
                        if (targetAuthState.getState() == AuthProtocolState.SUCCESS
                                &amp;amp;&amp;amp; targetAuthState.isConnectionBased()) {
                            this.log.debug(&amp;quot;Resetting target auth state&amp;quot;);
                            targetAuthState.reset();
                        }
                    }
                    // discard previous auth headers
                    final HttpRequest original = request.getOriginal();
                    if (!original.containsHeader(AUTH.WWW_AUTH_RESP)) {
                        request.removeHeaders(AUTH.WWW_AUTH_RESP);
                    }
                    if (!original.containsHeader(AUTH.PROXY_AUTH_RESP)) {
                        request.removeHeaders(AUTH.PROXY_AUTH_RESP);
                    }
                } else {
                    break;
                }
            }

            if (userToken == null) {
                userToken = userTokenHandler.getUserToken(context);
                context.setAttribute(HttpClientContext.USER_TOKEN, userToken);
            }
            if (userToken != null) {
                connHolder.setState(userToken);
            }

            // check for entity, release connection if possible
            final HttpEntity entity = response.getEntity();
            if (entity == null || !entity.isStreaming()) {
                // connection not needed and (assumed to be) in re-usable state
                connHolder.releaseConnection();
                return new HttpResponseProxy(response, null);
            } else {
                return new HttpResponseProxy(response, connHolder);
            }
        } catch (final ConnectionShutdownException ex) {
            final InterruptedIOException ioex = new InterruptedIOException(
                    &amp;quot;Connection has been shut down&amp;quot;);
            ioex.initCause(ex);
            throw ioex;
        } catch (final HttpException ex) {
            connHolder.abortConnection();
            throw ex;
        } catch (final IOException ex) {
            connHolder.abortConnection();
            if (proxyAuthState.isConnectionBased()) {
                proxyAuthState.reset();
            }
            if (targetAuthState.isConnectionBased()) {
                targetAuthState.reset();
            }
            throw ex;
        } catch (final RuntimeException ex) {
            connHolder.abortConnection();
            if (proxyAuthState.isConnectionBased()) {
                proxyAuthState.reset();
            }
            if (targetAuthState.isConnectionBased()) {
                targetAuthState.reset();
            }
            throw ex;
        } catch (final Error error) {
            connManager.shutdown();
            throw error;
        }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在同步状态下，由于调用 &lt;code&gt;abort&lt;/code&gt; 和 &lt;code&gt;releaseConnection&lt;/code&gt; 时，此时客户端请求已经结束，所以修改状态不会造成问题（由于项目中每次都是重新构建请求，所以也没有重用请求）。但是当请求在异步执行时，在执行请求的同时如果丢弃连接（执行 &lt;code&gt;finally&lt;/code&gt; 的 &lt;code&gt;abort&lt;/code&gt; 和 &lt;code&gt;releaseConnection&lt;/code&gt;），此时可能在连接获取的阻塞阶段，&lt;code&gt;cancel&lt;/code&gt; 可能取消的是 &lt;code&gt;future&lt;/code&gt;，而如果此时 &lt;code&gt;future&lt;/code&gt; 已经获取并返回连接，由于后面调用 &lt;code&gt;releaseConnection&lt;/code&gt; 将请求的 &lt;code&gt;aborted&lt;/code&gt; 置为 &lt;code&gt;false&lt;/code&gt;，判断中断失效，不会抛出异常，那么已获取的连接就不会被释放。&lt;/p&gt;
&lt;h3 id=&#34;修复方法&#34;&gt;修复方法&lt;/h3&gt;
&lt;h4 id=&#34;删除-releaseconnection&#34;&gt;删除 releaseConnection&lt;/h4&gt;
&lt;p&gt;如果在使用中不会复用请求，那么我们可以不再调用 &lt;code&gt;releaseConnection&lt;/code&gt;，因为 &lt;code&gt;abort&lt;/code&gt; 已经调用了 &lt;code&gt;Cancellable&lt;/code&gt; 的 &lt;code&gt;cancel&lt;/code&gt; 方法，因此，相当于 &lt;code&gt;releaseConnection&lt;/code&gt; 只会执行 &lt;code&gt;this.aborted.set(false)&lt;/code&gt;，而这会导致执行请求的线程在判断时不抛出异常，也就不会被捕获然后释放连接。&lt;/p&gt;
&lt;h4 id=&#34;将-abort-和-releaseconnection-放入异步方法的-finally-执行&#34;&gt;将 abort 和 releaseConnection 放入异步方法的 finally 执行&lt;/h4&gt;
&lt;p&gt;当我们想要复用连接时，我们可以将外面的释放连接方法放入异步方法的 &lt;code&gt;finally&lt;/code&gt; 中执行，如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;            try {
                future = executor.submit(() -&amp;gt; {
                    try {
                        return HttpClientUtil.execute(httpGet);
                    } catch (Exception e) {
                        logger.error(&amp;quot;&amp;quot;, e);
                        return null;
                    } finally {
                        httpGet.abort();
                        httpGet.releaseConnection();
                    }
                });
                response = future.get(5, TimeUnit.SECONDS);
                System.out.println(&amp;quot;response = &amp;quot; + response);
            } catch (Exception e) {
                if (e instanceof TimeoutException &amp;amp;&amp;amp; future != null) {
                    logger.info(Thread.currentThread().getName() + &amp;quot; start cancel future&amp;quot;);
                    logger.error(&amp;quot;&amp;quot;, e);
                    }
                }
            } finally {
                if (null != response) {
                    EntityUtils.consume(response.getEntity());
                }
            }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;注意，在 &lt;code&gt;Future.get&lt;/code&gt; 方法超时后，不会终止任务，而是丢弃任务执行的结果，因此，当调用结束时，方法依旧会执行 &lt;code&gt;finally&lt;/code&gt; 释放连接，但是要通过 &lt;code&gt;Futrue.isDone&lt;/code&gt; 判断 &lt;code&gt;Future&lt;/code&gt; 是否执行结束，才能重新复用请求对象。&lt;/p&gt;
">HttpClient连接无法释放问题</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://wenbozhangw.github.io/post/chapter-12-execution/"" data-c="
          &lt;p&gt;此章节规定了程序执行期间发生的活动。他围绕 Java 虚拟机以及构成程序的类、接口和对象的声明周期进行组织编写。&lt;/p&gt;
&lt;p&gt;Java 虚拟机通过加载指定的类然后调用该类中的 &lt;code&gt;main&lt;/code&gt; 方法来启动。第 &lt;a href=&#34;#121-java-virtual-machine-startup&#34;&gt;12.1&lt;/a&gt; 节概述了执行 main 所涉及的加载、链接和初始化步骤，作为本章节的概念的介绍。下一个部分讲述了加载 &lt;a href=&#34;#122-loading-of-classes-and-interfaces&#34;&gt;12.2&lt;/a&gt; 、链接  &lt;a href=&#34;#123-linking-of-classes-and-interfaces&#34;&gt;12.3&lt;/a&gt; 和初始化  &lt;a href=&#34;#124-initialization-of-classes-and-interfaces&#34;&gt;12.4&lt;/a&gt;  的细节。&lt;/p&gt;
&lt;p&gt;本章后续部分说明创建新类实例的过程（第 &lt;a href=&#34;#125-creation-of-new-class-instances&#34;&gt;12.5&lt;/a&gt; 节 ）；和类实例的最终确定（ &lt;a href=&#34;#126-finalization-of-class-instances&#34;&gt;12.6&lt;/a&gt; ）。它通过描述类的卸载（第 &lt;a href=&#34;#127-unloading-of-classes-and-interfaces&#34;&gt;12.7&lt;/a&gt; 节 ）和程序退出时遵循的过程（第 &lt;a href=&#34;#128-program-exit&#34;&gt;12.8&lt;/a&gt; 节 ）来结束。&lt;/p&gt;
&lt;!-- more --&gt;
&lt;h2 id=&#34;121-java-virtual-machine-startup&#34;&gt;12.1 Java Virtual Machine Startup&lt;/h2&gt;
&lt;p&gt;Java 虚拟机通过调用某个指定类的 &lt;code&gt;main&lt;/code&gt; 方法开始执行，并传递给它一个参数，该参数是一个字符串数组。在本规范的示例中，这个特定类通常称为 &lt;code&gt;Test&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;Java 虚拟机启动的精确语义在 &lt;em&gt;Java Virtual Machine Specification, Java SE 8 Edition&lt;/em&gt;  的第 5 章中给出。在这里，我们从 Java 编程语言的角度概述了该过程。&lt;/p&gt;
&lt;p&gt;将初始类指定给 Java 虚拟的方式超出了本规范的范围，但在使用命令行的主机环境中，这是典型的，对于作为命令行参数指定的类的全限定名，以及将后面的命令参数作为字符串提供给方法 &lt;code&gt;main&lt;/code&gt; 。&lt;/p&gt;
&lt;p&gt;例如，在 UNIX 实现中，命令行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;java Test reboot Bob Dot Enzo
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;通常会通过调用类 &lt;code&gt;Test&lt;/code&gt;（未命名包中的类）的方法 &lt;code&gt;main&lt;/code&gt; 类启动 Java 虚拟机，并向其传递包含四个字符串 &amp;quot;reboot&amp;quot;、&amp;quot;Bob&amp;quot;、&amp;quot;Dot&amp;quot; 和 &amp;quot;Enzo&amp;quot; 的数组。&lt;/p&gt;
&lt;p&gt;我们现在概述 Java 虚拟机执行 &lt;code&gt;Test&lt;/code&gt; 可能采取的步骤，作为加载、连接和初始化过程的例子，这些过程将在后面的部分中进一步描述。&lt;/p&gt;
&lt;h3 id=&#34;1211-load-the-class-test&#34;&gt;12.1.1 Load the Class Test&lt;/h3&gt;
&lt;p&gt;最初尝试执行类 &lt;code&gt;Test&lt;/code&gt; 和 &lt;code&gt;main&lt;/code&gt; 方法时，发现没有加载类 &lt;code&gt;Test&lt;/code&gt; —— 也就是说，Java 虚拟机当前不包含这个类的二进制表示。然后，Java 虚拟机使用类加载器来尝试找到这样的二进制表示。如果这个过程失败，就会抛出一个错误。该加载张将在 &lt;a href=&#34;#122-loading-of-classes-and-interfaces&#34;&gt;12.2&lt;/a&gt; 中进一步描述。&lt;/p&gt;
&lt;h3 id=&#34;1212-link-test-verify-prepare-optionally-resolve&#34;&gt;12.1.2 Link Test: Verify, Prepare, (Optionally) Resolve&lt;/h3&gt;
&lt;p&gt;加载 &lt;code&gt;Test&lt;/code&gt; 后，必须调用 &lt;code&gt;main&lt;/code&gt; 之前对其进行初始化。和所有（类或接口）类型一样，&lt;code&gt;Test&lt;/code&gt; 在初始化之前必须被连接。连接包括&lt;strong&gt;验证&lt;/strong&gt;、&lt;strong&gt;准备&lt;/strong&gt; 和 &lt;strong&gt;（可选）解析&lt;/strong&gt; 。链接将在 &lt;a href=&#34;#123-linking-of-classes-and-interfaces&#34;&gt;12.3&lt;/a&gt; 中进一步描述。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;验证&lt;/strong&gt;会检查 &lt;code&gt;Test&lt;/code&gt; 的加载表示是否格式良好，是否有正确的符号表。验证还检查实现 &lt;code&gt;Test&lt;/code&gt; 的代码是否符合 Java 编程语言和 Java 虚拟机的语义要求。如果在验证过程中检测到问题，就会抛出一个错误。&lt;a href=&#34;#1231-verification-of-the-binary-representation&#34;&gt;12.3.1&lt;/a&gt; 中进一步描述了验证。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;准备&lt;/strong&gt;包括静态存储和 Java 虚拟机实现内部使用的任何数据结构的分配，比如方法表。&lt;a href=&#34;#1232-preparation-of-a-class-or-interface-type&#34;&gt;12.3.2&lt;/a&gt; 中进一步描述了准备工作。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解析&lt;/strong&gt;是检查从 &lt;code&gt;Test&lt;/code&gt; 到其他类和接口的符号引用的过程，通过加载提到的其他类和接口并检查引用使用正常。&lt;/p&gt;
&lt;p&gt;在初始化连接时，解析步骤是可选的。一种实现可以从很早就被链接的类或接口中解析符号引用，甚至可以从被引用的类和接口中进一步递归解析所有符号引用。（该解决方案可能会导致这些进一步加载和链接步骤的错误。）这种实现选择代表了一个极端，类似于在 C 语言的简单实现中已经做了多年的这种“静态”链接。。（在这些实现中，编译后的程序通常被表示为 “a.out” 文件，改文件包含该程序的完全链接版本，包括到该程序所使用的程序例程的完全解析的连接。这些库例程的副本包含在 “a.out” 文件中。）&lt;/p&gt;
&lt;p&gt;一种实现可以选择仅在符号引用被主动使用时解析它；对所有符号引用一致使用这种策略将代表的是“最懒惰”的解决方式。在这种情况下，如果 Test 有几个对另一个类的符号引用，那么这些引用可能会在使用时一次解析一个，或者如果这些引用的程序执行期间从未使用过，则可能根本不解析。&lt;/p&gt;
&lt;p&gt;对何时执行解析的唯一要求是，在解析过程中检测到的任何错误都必须在程序中的某个点抛出，在该点上，程序将采用一些可能直接或间接地采取一些操作，这些操作可能需要链接到设计错误的类或接口。使用上面描述的 “静态” 示例实现选择，如果加载和链接错误涉及类 Test 或任何进一步递归引用的类和接口中提到的类和接口，那么它们可能在程序执行之前发生。在实现“最懒惰”解析的系统中，只有在积极使用不正确的符号引用时才会抛出这些错误。&lt;/p&gt;
&lt;p&gt;解析过程在第 &lt;a href=&#34;#1233-resolution-of-symbolic-references&#34;&gt;12.3.3&lt;/a&gt; 节中进一步描述。&lt;/p&gt;
&lt;h3 id=&#34;1213-initialize-test-execute-initializers&#34;&gt;12.1.3 Initialize Test: Execute Initializers&lt;/h3&gt;
&lt;p&gt;在我们接下来的示例中，Java 虚拟机仍在尝试执行 &lt;code&gt;Test&lt;/code&gt; 类的 &lt;code&gt;main&lt;/code&gt; 方法。仅当类已初始化时才允许这样做（第 &lt;a href=&#34;#1241-when-initialization-occurs&#34;&gt;12.4.1&lt;/a&gt; 节 ）。&lt;/p&gt;
&lt;p&gt;初始化包括按文本顺序执行类 &lt;code&gt;Test&lt;/code&gt; 的任何类变量初始化程序和静态初始化程序。但是在初始化 &lt;code&gt;Test&lt;/code&gt; 之前，它的直接超类必须被初始化，以及它的直接超类的直接超类，以此递归类推。在最简单的情况下，&lt;code&gt;Test&lt;/code&gt; 将 &lt;code&gt;Object&lt;/code&gt; 作为其隐式直接超类；如果类 &lt;code&gt;Object&lt;/code&gt; 尚未初始化，则必须初始化 &lt;code&gt;Test&lt;/code&gt; 之前对齐进行初始化。类 &lt;code&gt;Object&lt;/code&gt; 没有超类，所以递归在这里终止。&lt;/p&gt;
&lt;p&gt;如果类 &lt;code&gt;Test&lt;/code&gt; 有另一个类 &lt;code&gt;Super&lt;/code&gt; 作为它的父类，那么 &lt;code&gt;Super&lt;/code&gt; 必须在 &lt;code&gt;Test&lt;/code&gt; 之前初始化。这需要加载、验证和准备 &lt;code&gt;Super&lt;/code&gt; （如果还没有这样做的话），根据实现的不同，可能涉及递归地解析来自 &lt;code&gt;Super&lt;/code&gt; 的符号引用等等。&lt;/p&gt;
&lt;p&gt;因此，初始化可能会导致加载、连接和初始化错误，包括涉及其他类型的此类错误。&lt;/p&gt;
&lt;p&gt;初始化过程在第 &lt;a href=&#34;#124-initialization-of-classes-and-interfaces&#34;&gt;12.4&lt;/a&gt; 节中进一步描述。&lt;/p&gt;
&lt;h3 id=&#34;1214-invoke-testmain&#34;&gt;12.1.4 Invoke Test.main&lt;/h3&gt;
&lt;p&gt;最后，在 &lt;code&gt;Test&lt;/code&gt; 类的初始化完成后（在此期间可能发生了其他相应的加载、连接和初始化），调用 &lt;code&gt;Test&lt;/code&gt; 的 &lt;code&gt;main&lt;/code&gt; 方法。&lt;/p&gt;
&lt;p&gt;方法 &lt;code&gt;main&lt;/code&gt; 必须声明为 &lt;code&gt;public&lt;/code&gt;、&lt;code&gt;static&lt;/code&gt; 和 &lt;code&gt;void&lt;/code&gt;。它必须指定一个声明类型为字符串数组 的形式参数（第 8.4.1 节）。因此，可以接受以下任一声明：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public static void main(String[] args)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public static void main(String... args)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;122-loading-of-classes-and-interfaces&#34;&gt;12.2 Loading of Classes and Interfaces&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;加载&lt;/strong&gt; 指的是找到具有特定名称的类和接口类型的二进制形式的过程，可能是通过即时计算，但更常见的是通过检索 Java 编译器先前从源代码计算的二进制表示，并根据该二进制形式构造表示类或接口的 &lt;code&gt;Class&lt;/code&gt; 对象。&lt;/p&gt;
&lt;p&gt;*Java Virtual Machine Specification, Java SE 8 Edition * 的第 5 章给出了加载的精确语义。在这里，我们从 Java 编程语言的角度概述了该过程。&lt;/p&gt;
&lt;p&gt;类或接口的二进制格式通常是上面引用的 *Java Virtual Machine Specification, Java SE 8 Edition *  中描述的类文件格式，但是其他格式也是可能的，只要它们满足 13.1 中指定的要求。&lt;code&gt;ClassLoader&lt;/code&gt; 类的 &lt;code&gt;defineClass&lt;/code&gt; 方法可用于从 &lt;code&gt;class&lt;/code&gt; 文件格式的二进制表示中构造 &lt;code&gt;Class&lt;/code&gt; 对象。&lt;/p&gt;
&lt;p&gt;行为良好的类加载器维护以下属性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;给定相同的名称，一个好的类加载器总是返回相同的类对象。&lt;/li&gt;
&lt;li&gt;如果一个类加载器 &lt;code&gt;L1&lt;/code&gt; 将类 &lt;code&gt;C&lt;/code&gt; 的加载委托给另一个加载器 &lt;code&gt;L2&lt;/code&gt;，那么对于 &lt;code&gt;C&lt;/code&gt; 的直接超类或直接超接口，或者作为 &lt;code&gt;C&lt;/code&gt; 中的字段类型，或者作为 &lt;code&gt;C&lt;/code&gt; 中的方法或构造函数的形参类型，或者作为 &lt;code&gt;C&lt;/code&gt; 中方法的返回类型出现的任何 &lt;code&gt;T&lt;/code&gt; 类型，&lt;code&gt;L1&lt;/code&gt; 和 &lt;code&gt;L2&lt;/code&gt; 应该返回相同的 &lt;code&gt;Class&lt;/code&gt; 对象。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;恶意的类加载器可能会破坏这些属性。然而，它不能破坏类型系统的安全性，因为 Java 虚拟机防止了这一点。&lt;/p&gt;
&lt;p&gt;进一步讨论这些问题，请参阅 &lt;em&gt;Java Virtual Machine Specification, Java SE 8 Edition and the paper Dynamic Class Loading in the Java Virtual Machine, by Sheng Liang and Gilad Bracha, in Proceedings of OOPSLA &#39;98, published as ACM SIGPLAN Notices, Volume 33, Number 10, October 1998, pages 36-44&lt;/em&gt; 。Java 编程语言设计的一个基本原则是，运行时类型系统不能被用 Java 编程语言编写的代码破坏，甚至不能被诸如 &lt;code&gt;ClassLoader&lt;/code&gt; 和 &lt;code&gt;SecurityManager&lt;/code&gt; 之类的敏感系统类的实现破坏。&lt;/p&gt;
&lt;h3 id=&#34;1221-the-loading-process&#34;&gt;12.2.1 The Loading Process&lt;/h3&gt;
&lt;p&gt;加载过程由 &lt;code&gt;ClassLoader&lt;/code&gt; 类及其子类实现。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ClassLoader&lt;/code&gt; 的不同子类可以实现不同的加载策略。特别是，类加载器可以缓存类和接口的二进制表示，根据预期的使用情况预读取它们，或者一起加载一组相关的类。这些活动对于正在运行的应用程序可能不是完全透明的，例如，如果因为类加载器缓存了旧版本而找不到类的新编译版本。然而，类加载器的责任是旨在程序中没有预读取或分组加载的地方反映加载错误。&lt;/p&gt;
&lt;p&gt;如果在类加载过程中出现错误，则在程序中（直接或间接）使用该类型的任何点都会引发 &lt;code&gt;LinkageError&lt;/code&gt; 类的子类之一的实例：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ClassCircularityError&lt;/code&gt;：无法加载类或接口，因为它将是其自己的超类或超接口（第 8.1.4 节、第 9.1.3 节、第 13.4.4 节）。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ClassFormatError&lt;/code&gt;：声明指定所请求的编译类或接口的二进制数据格式不正确。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;NoClassDefFoundError&lt;/code&gt;：相关的类加载器找不到请求的类或接口的定义。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因为加载涉及新数据结构的分配，所以它可能会因 &lt;code&gt;OutOfMemoryError&lt;/code&gt; 而失败。&lt;/p&gt;
&lt;h2 id=&#34;123-linking-of-classes-and-interfaces&#34;&gt;12.3 Linking of Classes and Interfaces&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;链接&lt;/strong&gt; 是获取类或接口类型的二进制形式，并将其组合到 Java 虚拟机的运行时状态中，以便可以执行的过程。类或接口类型总是在连接之前加载。&lt;/p&gt;
&lt;p&gt;链接设计三种不同的活动：验证、准备和解析符号引用。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Java Virtual Machine Specification, Java SE 8 Edition&lt;/em&gt; 的第 5 章中给出了链接的精确语义。在这里，我们从 Java 编程语言的角度概述了这个过程。&lt;/p&gt;
&lt;p&gt;如果考虑到 Java 编程语言的语义，类或接口在初始化之前就被完全验证和准备，并且在链接期间检测到的错误在程序中的某个点被抛出，在该点处程序采取了可能需要链接到错误中涉及的类或接口的一些动作，则该规范允许关于链接活动（以及由于递归，加载）何时发生的实现灵活性。&lt;/p&gt;
&lt;p&gt;例如，一个实现可以选择仅当一个类或接口被使用时（惰性或延迟解析），单独解析它当的每个符号引用，或者在类被验证时一次性解析它们（静态解析）。这意味着，在一些实现中，在类或接口被初始化之后，解析过程可以继续。&lt;/p&gt;
&lt;p&gt;因为链接涉及新数据结构的分配，所以它可能会因 &lt;code&gt;OutOfMemoryError&lt;/code&gt; 而失败。&lt;/p&gt;
&lt;h3 id=&#34;1231-verification-of-the-binary-representation&#34;&gt;12.3.1 Verification of the Binary Representation&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;验证&lt;/strong&gt;确保类或接口的二进制表示在接口上是正确的。例如，它检查每条指令都有一个有效的操作码；每个分支指令都分支到其他指令的开始，而不是一条指令的中间；每个方法都具有结构正确的签名；并且每条指令都遵守 Java 虚拟机语言的类型规则。&lt;/p&gt;
&lt;p&gt;如果在验证过程中出现错误，那么将在程序中导致该类在被验证的点处抛出 &lt;code&gt;LinkageError&lt;/code&gt; 类的以下子类的实例：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;VerifyError&lt;/code&gt;：类或接口的二进制定义未能通过一组必须的检查，以验证它符合 Java 虚拟机语言的语义，并且不会破坏 Java 虚拟机的完整性。（一些示例见 13.4.2、13.4.4、13.4.9 和 13.4.17。 ）&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;1232-preparation-of-a-class-or-interface-type&#34;&gt;12.3.2 Preparation of a Class or Interface Type&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;准备&lt;/strong&gt;工作包括为类或接口创建 &lt;code&gt;static&lt;/code&gt; 字段（类变量和常量），并将这些字段初始化为默认值（4.12.5）。这不需要执行任何源代码；静态字段的显式初始化器作为初始化（12.4）的一部分执行，而不是准备。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Java 虚拟机的实现可以在准备时预先计算额外的数据结构，以便使以后对类或接口的操作更有效。一种特别有用的数据结构是“方法表”或其他数据结构，它允许在一个类的实例上调用任何方法，而不需要在调用时搜索超类。&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;1233-resolution-of-symbolic-references&#34;&gt;12.3.3 Resolution of Symbolic References&lt;/h3&gt;
&lt;p&gt;类或接口的二进制表示引用其他类和接口（13.1）的二进制名称（13.1），象征性地引用其他类和接口及其字段、方法和构造函数。对于字段和方法，这些符号引用包括字段或方法所属的类或接口类型的名称，以及字段或方法本身的名称，以及适当的类型信息。&lt;/p&gt;
&lt;p&gt;在符号引用可以被使用之前，它必须经过解析，其中符号引用被检查为正确的，并且通常被替换为直接引用，如果引用被重复使用，则直接引用可以被更有效地处理。&lt;/p&gt;
&lt;p&gt;如果在解析过程中出现错误，那么将会抛出一个错误。最典型的情况是，这将是 &lt;code&gt;IncompatibleClassChangeError&lt;/code&gt; 类的下列子类之一的实例，但也可能是 &lt;code&gt;IncompatibleClassChangeError&lt;/code&gt; 的其他子类的实例，甚至是 &lt;code&gt;IncompatibleClassChangeError&lt;/code&gt; 类本身的实例。此错误可能在程序中直接或间接使用对该类型的符号引用的任何位置引发：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;IllegalAccessError&lt;/code&gt;：遇到了指定字段的使用或赋值、方法的调用或类实例的创建的符号引用，而包含该引用的代码无权访问这些引用，因为该字段 &lt;code&gt;private&lt;/code&gt; 、&lt;code&gt;protected&lt;/code&gt; 或 &lt;code&gt;package&lt;/code&gt; 访问权限（非 &lt;code&gt;public&lt;/code&gt;）声明的，或者因为该类未声明为 &lt;code&gt;public&lt;/code&gt;。&lt;br&gt;
例如，如果一个最初声明为 &lt;code&gt;public&lt;/code&gt; 的字段在另一个引用该字段的类被编译后被更改为 &lt;code&gt;private&lt;/code&gt;，就会发生这种情况（13.4.7）。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;InstantiationError&lt;/code&gt;：遇到了在类创建表达式中使用的符号引用，但无法创建实例，因为该引用引用了接口或抽象类。&lt;br&gt;
例如，如果一个原本不是抽象的类在另一个引用该类的类被编译后变成了抽象的，就会发生这种情况（13.4.1）。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;NoSuchFieldError&lt;/code&gt;：遇到了引用特定类或接口的特定字段的符号引用，但该类或接口不包含该名称的字段。&lt;br&gt;
例如，如果在编译了引用某个字段的另一个类之后，从该类中删除了该字段声明，就会出现这种情况(13.4.8)。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;NoSuchMethodError&lt;/code&gt;：遇到了引用特定类或接口的特定方法的符号引用，但该类或接口不包含该签名的方法。&lt;br&gt;
例如，如果在编译了引用某个方法的另一个类之后，从该类中删除了该方法声明，就会出现这种情况(13.4.12)。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;此外，如果某个类声明了一个无法找到实现的 &lt;code&gt;native&lt;/code&gt; 方法，则可能会引发 &lt;code&gt;UnsatisfiedLinkError&lt;/code&gt;，&lt;code&gt;LinkageError&lt;/code&gt;的子类。根据 Java 虚拟机（12.3）的实现所使用的解析策略的类型，如果使用了方法，或者更早，就会出现错误。&lt;/p&gt;
&lt;h2 id=&#34;124-initialization-of-classes-and-interfaces&#34;&gt;12.4 Initialization of Classes and Interfaces&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;初始化&lt;/strong&gt;类包括执行它的静态初始化器和在类中声明的 &lt;code&gt;static&lt;/code&gt; 字段（类变量）的初始化器。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;初始化&lt;/strong&gt;接口包括为接口中声明的字段（常量）执行初始化器。&lt;/p&gt;
&lt;h3 id=&#34;1241-when-initialization-occurs&#34;&gt;12.4.1 When Initialization Occurs&lt;/h3&gt;
&lt;p&gt;类或接口类型 T 将在第一次出现以下任何一种情况之前立即初始化：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;T 是一个类并且创建了 T 的一个实例。&lt;/li&gt;
&lt;li&gt;调用由 T 声明的 &lt;code&gt;static&lt;/code&gt; 方法。&lt;/li&gt;
&lt;li&gt;分配一个由 T 声明的 &lt;code&gt;static&lt;/code&gt; 字段。&lt;/li&gt;
&lt;li&gt;使用由 T 声明的 &lt;code&gt;static&lt;/code&gt; 字段，并且该字段不是常量变量（4.12.4）。&lt;/li&gt;
&lt;li&gt;T 是顶级类（7.6），并且执行了断言语句（14.10），它在词法上嵌套在 T （8.1.3）中。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当一个类被初始化时，它的超类（如果它们之前没有被初始化），以及声明任何默认方法的超接口（8.1.5）（如果它们之前没有被初始化）也会被初始化。接口的初始化本身不会导致它的任何超接口的初始化。&lt;/p&gt;
&lt;p&gt;引用 &lt;code&gt;static&lt;/code&gt; 字段（8.3.1.1）只会初始化实际声明静态字段的类或接口，即使它可能通过子类，子接口或实现接口的类的名称被引用。&lt;/p&gt;
&lt;p&gt;在类 &lt;code&gt;Class&lt;/code&gt; 和包 &lt;code&gt;java.lang.reflect&lt;/code&gt; 中调用某些反射方法也会导致类或接口初始化。&lt;/p&gt;
&lt;p&gt;类或接口在任何其他情况下都不会初始化。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;注意，编译器可以在接口中生成合成的默认方法，也就是说，既没有显示声明也没有隐式声明的默认方法（13.1）。这些方法将触发接口的初始化，尽管源代码没有给出应该初始化接口的指示。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;目的是一个类或接口类型有一组初始化器，使它处于一致的状态，并且这个状态是其他类观察到的第一个状态。静态初始值设定项和类变量初始值设定项是按文本顺序执行的，可能不会引用在勒种声明的类变量，这些类变量的声明在使用后以文本形式出现，即使这些类变量在作用域内（8.3.3）。这种限制旨在编译时检测大多数循环或错误的初始化。&lt;/p&gt;
&lt;p&gt;初始化代码是不受限制的，这一事实允许构造这样的例子，其中在评估初始化表达式之前，当类变量仍然具有其初始默认值时，可以观察到类变量的值，但是这样的例子在实践中很少。（这样的例子也可以构造为变量初始化（&lt;a href=&#34;#125-creation-of-new-class-instances&#34;&gt;12.5&lt;/a&gt;）。）Java 编程语言的全部功能都可以在这些初始化器中获得；程序员必须小心谨慎。这种能力给代码生成器带来了额外的负担，但是这种负担在任何情况下都会出现，因为 Java 编程语言是并发的（&lt;a href=&#34;#1242-detailed-initialization-procedure&#34;&gt;12.4.2&lt;/a&gt;）。&lt;/p&gt;
&lt;p&gt;例子 12.4.1-1，超类在子类之前初始化：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;class Super {
    static { System.out.print(&amp;quot;Super &amp;quot;); }
}
class One {
    static { System.out.print(&amp;quot;One &amp;quot;); }
}
class Two extends Super {
    static { System.out.print(&amp;quot;Two &amp;quot;); }
}
class Test {
    public static void main(String[] args) {
        One o = null;
        Two t = new Two();
        System.out.println((Object)o == (Object)t);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;此程序输出：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Super Two false
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;类 &lt;code&gt;One&lt;/code&gt; 永远不会被初始化，因为它没有被主动使用，因此永远不会被链接到。类 &lt;code&gt;Two&lt;/code&gt; 仅在其超类 &lt;code&gt;Super&lt;/code&gt; 被初始化后才被初始化。&lt;/p&gt;
&lt;p&gt;例子 12.4.1-2，只有声明 &lt;code&gt;static&lt;/code&gt; 字段的类被初始化：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;class Super {
    static int taxi = 1729;
}
class Sub extends Super {
    static { System.out.print(&amp;quot;Sub &amp;quot;); }
}
class Test {
    public static void main(String[] args) {
        System.out.println(Sub.taxi);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;此程序输出：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;1729
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;因为 &lt;code&gt;Sub&lt;/code&gt; 类从未初始化；对 &lt;code&gt;Sub.taxi&lt;/code&gt; 的引用是对 &lt;code&gt;Super&lt;/code&gt; 类中实际声明的字段的引用，不会触发 &lt;code&gt;Sub&lt;/code&gt; 类的初始化。&lt;/p&gt;
&lt;p&gt;例子 12.4.1-3，接口初始化不初始化超接口：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;interface I {
    int i = 1, ii = Test.out(&amp;quot;ii&amp;quot;, 2);
}
interface J extends I {
    int j = Test.out(&amp;quot;j&amp;quot;, 3), jj = Test.out(&amp;quot;jj&amp;quot;, 4);
}
interface K extends J {
    int k = Test.out(&amp;quot;k&amp;quot;, 5);
}
class Test {
    public static void main(String[] args) {
        System.out.println(J.i);
        System.out.println(K.j);
    }
    static int out(String s, int i) {
        System.out.println(s + &amp;quot;=&amp;quot; + i);
        return i;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;该程序产生输出：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;1
j=3
jj=4
3
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;对 &lt;code&gt;J.i&lt;/code&gt; 的引用是对作为常量变量的字段引用（4.12.4）；因此，他不会导致 &lt;code&gt;I&lt;/code&gt; 被初始化（13.4.9）。&lt;/p&gt;
&lt;p&gt;对 &lt;code&gt;K.j&lt;/code&gt; 的引用是对接口 &lt;code&gt;J&lt;/code&gt;  中实际声明的不是常量变量的字段的引用；这导致接口 &lt;code&gt;J&lt;/code&gt; 的字段初始化，但不初始化其超接口 &lt;code&gt;I&lt;/code&gt; 的字段，也不初始化接口 &lt;code&gt;K&lt;/code&gt; 的字段。&lt;/p&gt;
&lt;p&gt;尽管名称 &lt;code&gt;K&lt;/code&gt; 用于引用接口 &lt;code&gt;J&lt;/code&gt; 的字段 &lt;code&gt;j&lt;/code&gt;，但接口 &lt;code&gt;K&lt;/code&gt; 并未初始化。&lt;/p&gt;
&lt;h3 id=&#34;1242-detailed-initialization-procedure&#34;&gt;12.4.2 Detailed Initialization Procedure&lt;/h3&gt;
&lt;p&gt;因为 Java 编程语言是多线程的，所以类或接口的初始化需要小心的同步，因为其他一些线程可能同时视图初始化相同的类或接口。还存在这样的可能性，即类或接口的初始化可以作为该类或接口初始化的一部分被递归地请求；例如，类 A 中的变量初始化器可能会调用不相关的类 B 的方法，这有可能会调用类 A 的方法。&lt;/p&gt;
&lt;p&gt;该过程假设 &lt;code&gt;Class&lt;/code&gt; 对象已经被验证和准备，并且该对象包含指示四种情况之一的状态：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;该 &lt;code&gt;Class&lt;/code&gt; 对象已经过验证和准备，但尚未初始化。&lt;/li&gt;
&lt;li&gt;该 &lt;code&gt;Class&lt;/code&gt; 对象正在被某个特定的线程 &lt;code&gt;T&lt;/code&gt; 初始化。&lt;/li&gt;
&lt;li&gt;该 &lt;code&gt;Class&lt;/code&gt; 对象已经完全初始化，可以使用了。&lt;/li&gt;
&lt;li&gt;该 &lt;code&gt;Class&lt;/code&gt; 对象处于错误状态，可能是因为初始化尝试失败。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于每个类或接口 &lt;code&gt;C&lt;/code&gt;，都有一个唯一的初始化锁 &lt;code&gt;LC&lt;/code&gt;。从 &lt;code&gt;C&lt;/code&gt; 到 &lt;code&gt;LC&lt;/code&gt; 的映射由 Java 虚拟机实现决定。初始化 &lt;code&gt;C&lt;/code&gt; 的过程如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;对 &lt;code&gt;C&lt;/code&gt; 的初始化锁 &lt;code&gt;LC&lt;/code&gt; 进行同步，这包括等待，直到当前线程可以获取 &lt;code&gt;LC&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;如果 &lt;code&gt;C&lt;/code&gt; 的 &lt;code&gt;Class&lt;/code&gt; 对象指示某个其他线程正在对 &lt;code&gt;C&lt;/code&gt; 进行初始化，那么释放 &lt;code&gt;LC&lt;/code&gt; 并阻塞当前线程，直到通知正在进行的初始化已经完成，此时重复该步骤。&lt;/li&gt;
&lt;li&gt;如果 &lt;code&gt;C&lt;/code&gt; 的 &lt;code&gt;Class&lt;/code&gt; 对象指示当前线程正在对 &lt;code&gt;C&lt;/code&gt; 进行初始化，那么这一定是一个递归的初始化请求。释放 &lt;code&gt;LC&lt;/code&gt; 并正常完成。&lt;/li&gt;
&lt;li&gt;如果 &lt;code&gt;C&lt;/code&gt; 的 &lt;code&gt;Class&lt;/code&gt; 对象指示 &lt;code&gt;C&lt;/code&gt; 已经被初始化，那么不需要进一步的动作。释放 &lt;code&gt;LC&lt;/code&gt; 并正常完成。&lt;/li&gt;
&lt;li&gt;如果 &lt;code&gt;C&lt;/code&gt; 的 &lt;code&gt;Class&lt;/code&gt; 对象处于错误状态，那么初始化是不可能的。释放 &lt;code&gt;LC&lt;/code&gt; 并抛出一个 &lt;code&gt;NoClassDefFoundError&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;否则，记录当前线程正在初始化 &lt;code&gt;C&lt;/code&gt; 的 &lt;code&gt;Class&lt;/code&gt; 对象，并释放 &lt;code&gt;LC&lt;/code&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;然后，初始化 &lt;code&gt;C&lt;/code&gt; 的 &lt;code&gt;static&lt;/code&gt; 字段，它们是常量变量（4.12.4，8.3.2，9.3.1）。&lt;/p&gt;
&lt;ol start=&#34;7&#34;&gt;
&lt;li&gt;接下来，如果 &lt;code&gt;C&lt;/code&gt; 是一个类而不是一个接口，它的超类还没有初始化，那么设 &lt;code&gt;SC&lt;/code&gt; 是它的超类，设 SI&lt;sub&gt;1&lt;/sub&gt;，... ...，SI&lt;sub&gt;n&lt;/sub&gt;是声明了至少一个默认方法的 &lt;code&gt;C&lt;/code&gt; 的所有超接口。超接口的顺序由 C 直接实现的每个接口的超接口层次结构上的递归枚举给出（按照 &lt;code&gt;C&lt;/code&gt; 的 &lt;code&gt;implements&lt;/code&gt; 子句从左到右的顺序 ）。对于 &lt;code&gt;C&lt;/code&gt; 直接实现的每个接口 &lt;code&gt;I&lt;/code&gt; ，枚举在返回 &lt;code&gt;I&lt;/code&gt; 之前在 &lt;code&gt;I&lt;/code&gt; 的超接口上递归（按照 &lt;code&gt;I&lt;/code&gt; 的 &lt;code&gt;extends&lt;/code&gt; 子句从左到右的顺序）。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;对于列表 [SC，SI&lt;sub&gt;1&lt;/sub&gt;，... ...，SI&lt;sub&gt;n&lt;/sub&gt;]，递归地对 &lt;code&gt;S&lt;/code&gt; 执行整个过程，如有必要，首先验证并准备 &lt;code&gt;S&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;如果 &lt;code&gt;S&lt;/code&gt; 的初始化因为一个抛出的异常而突然完成，那么获取 &lt;code&gt;LC&lt;/code&gt;，将 &lt;code&gt;C&lt;/code&gt; 的类对象标记为错误，通知所有等待的线程，释放 &lt;code&gt;LC&lt;/code&gt;，然后突然完成，抛出与初始化 &lt;code&gt;S&lt;/code&gt; 相同的异常。&lt;/p&gt;
&lt;ol start=&#34;8&#34;&gt;
&lt;li&gt;接下来，通过查询 &lt;code&gt;C&lt;/code&gt; 的定义类加载器来确定 &lt;code&gt;C&lt;/code&gt; 是否启用了断言（14.10）。&lt;/li&gt;
&lt;li&gt;接下来，按照文本顺序执行类的类变量初始值设定项和静态初始值设定项，或者接口的字段初始值设定项，就好像它们是单个块一样。&lt;/li&gt;
&lt;li&gt;如果初始化器的执行正常完成，那么获取 &lt;code&gt;LC&lt;/code&gt;， 将 &lt;code&gt;C&lt;/code&gt; 的 &lt;code&gt;Class&lt;/code&gt; 对象标记为完全初始化，通知所有等待的线程，释放 &lt;code&gt;LC&lt;/code&gt;，然后正常完成这个过程。&lt;/li&gt;
&lt;li&gt;否则，初始值设定项一定是通过抛出某个异常 &lt;code&gt;E&lt;/code&gt; 而突然完成的，如果 &lt;code&gt;E&lt;/code&gt; 的类不是 &lt;code&gt;Error&lt;/code&gt; 或它的某个子类，则创建 &lt;code&gt;ExceptionInInitializerError&lt;/code&gt; 类的新实例，使用 &lt;code&gt;E&lt;/code&gt; 作为参数，并在下面的步骤中使用此对象代替 &lt;code&gt;E&lt;/code&gt;。如果由于发生 &lt;code&gt;OutOfMemoryError&lt;/code&gt; 而无法创建 &lt;code&gt;ExceptionInInitializerError&lt;/code&gt; 的新实例，则在下面的步骤中使用 &lt;code&gt;OutOfMemoryError&lt;/code&gt; 对象代替 &lt;code&gt;E&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;获取 &lt;code&gt;LC&lt;/code&gt;，将 &lt;code&gt;C&lt;/code&gt; 的 &lt;code&gt;Class&lt;/code&gt; 对象标记为错误，通知所有等待的线程，释放 &lt;code&gt;LC&lt;/code&gt;，并突然完成此过程，原因为 &lt;code&gt;E&lt;/code&gt; 或其替换，如前一步骤中所确定的。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;em&gt;当实现可以确定类的初始化已经完成时，它可以通过取消步骤 1 中的锁获取（以及步骤 4/5 中的释放）来优化该过程，前提是，就存储器模型而言，如果锁被获取，则所有的 happens-before 排序在执行优化时仍然存在。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;代码生成器需要保留类或接口的可能初始化点，插入刚才描述的初始化过程的调用。如果这个初始化过程正常完成，并且 * &lt;code&gt;Class&lt;/code&gt; * 对象被完全初始化并准备好使用，那么初始化过程的调用不再是必要的，并且它可以从代码中消除——例如，通过修补它或以其他方式重新生成代码。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;在某些情况下，如果可以确定一组相关类型的初始化顺序，编译时分析可能能够从生成代码中消除许多类型已初始化的检查。然而，这种分析必须充分考虑到并发性和初始化代码不受限制的事实。&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;125-creation-of-new-class-instances&#34;&gt;12.5 Creation of New Class Instances&lt;/h2&gt;
&lt;p&gt;当对一个类实例创建表达式求值（15.9）导致一个类被实例化时，一个新的类实例被显示地创建。&lt;/p&gt;
&lt;p&gt;在以下情况下可以隐式创建一个新的类实例：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;加载一个包含 &lt;code&gt;String&lt;/code&gt; 字面量（3.10.5）的类或接口可能会创建一个新的 &lt;code&gt;String&lt;/code&gt; 对象来表示该字面量。（如果同一个 &lt;code&gt;String&lt;/code&gt; 之前已经被保留，这可能不会发生（3.10.5）。）&lt;/li&gt;
&lt;li&gt;导致装箱转换的操作的执行（5.1.7）。装箱转换可以创建于原语类型之一相关联的包装类的新对象。&lt;/li&gt;
&lt;li&gt;执行不属于常量表达式（15.28）的字符串连接运算符 &lt;code&gt;+&lt;/code&gt; （15.18.1）时，总是会创建一个新的字符串来表示结果。字符串串联运算也可以为原始类型的值创建临时包装对象。&lt;/li&gt;
&lt;li&gt;评估方法引入表达式（15.13.3）或 lambda 表达式（15.27.4）可能需要创建实现函数式接口类型的类的新实例。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;作为类实例创建过程的一部分，这些情况中的每一种都标识了一个特定的构造函数（8.8），改构造函数将使用指定的参数（可能没有）来调用。&lt;/p&gt;
&lt;p&gt;每当一个新的类实例被创建时，内存空间被分配给它，其中包括在类类型中声明所有实例变量，以及在类类型的每个超类中声明的所有实例变量，包括所有可能隐藏的实例变量（8.3）。&lt;/p&gt;
&lt;p&gt;如果没有足够的可用空间分配内存，那么类实例的创建就会突然结束，并发出 &lt;code&gt;OutOfMemoryError&lt;/code&gt;。否则，新对象中的所有实例变量，包括在超类中声明的实例变量，都被初始位它们的默认值（4.12.5）。&lt;/p&gt;
&lt;p&gt;就在返回新创建对象的引用作为结果之前，处理指定的构造函数，使用以下过程初始化新对象：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;将构造函数的参数赋给为这个构造函数调用新创建的参数变量。&lt;/li&gt;
&lt;li&gt;如果这个构造函数是从同一个类中的另一个构造函数的显式构造函数调用（8.8.7.1）开始的（使用 &lt;code&gt;this&lt;/code&gt;），那么使用这五个步骤计算参数并递归地处理构造函数调用。如果构造函数调用突然完成，那么这个过程也会因为同样的原因而突然完成；否则，继续执行步骤 5。&lt;/li&gt;
&lt;li&gt;此构造函数不以同一个类中的另一个构造函数的显式构造函数调用开始（使用 &lt;code&gt;this&lt;/code&gt;）。如果这个构造函数是针对 &lt;code&gt;Object&lt;/code&gt; 之外的类，那么这个构造函数将以一个超类构造函数的显式或隐式调用开始（使用 &lt;code&gt;super&lt;/code&gt;）。使用相同的五个步骤评估参数并递归处理超类构造函数调用。如果构造函数调用突然完成，那么这个过程也会因同样的原因而突然完成。否则，继续执行步骤 4。&lt;/li&gt;
&lt;li&gt;执行该类的实例初始值设定项和实例变量初始值设定项，将实例变量初始值设定项的值分配给相应的实例变量，按照它们在该类的源代码中以文本形式出现的从左到右的顺序。如果这些初始化器中的任何一个执行导致了异常，俺么就不再处理进一步的初始化器，并且这个过程以同样的异常突然结束。否则，继续执行步骤 5。&lt;/li&gt;
&lt;li&gt;执行该构造函数体的其余部分。如果该执行突然完成，那么该过程也由于同样的原因而突然完成。否则，此过程正常完成。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;与 C++ 不同，Java 编程语言在创建新的类实例期间没有为方法分派指定更改规则。如果调用的方法在被初始化的对象的子类中被重写，那么这些重写的方法将被使用，甚至在新对象被完全初始化之前。&lt;/p&gt;
&lt;p&gt;例子 12.5-1，实例创建评估：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;class Point {
    int x, y;
    Point() { x = 1; y = 1; }
}
class ColoredPoint extends Point {
    int color = 0xFF00FF;
}
class Test {
    public static void main(String[] args) {
        ColoredPoint cp = new ColoredPoint();
        System.out.println(cp.color);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里，创建了一个新的 &lt;code&gt;ColoredPoint&lt;/code&gt; 实例。首先，为新的 &lt;code&gt;ColoredPoint&lt;/code&gt; 分配空间，以保存字段 &lt;code&gt;x&lt;/code&gt;、&lt;code&gt;y&lt;/code&gt; 和 &lt;code&gt;color&lt;/code&gt;。然后将所有这些字段初始化为它们的默认值（在本例中，每个字段为 0）。接下来，首先调用没有参数的 &lt;code&gt;ColoredPoint&lt;/code&gt; 构造函数。由于 &lt;code&gt;ColoredPoint&lt;/code&gt; 没有声明构造函数，因此隐式声明了一下形势的默认构造函数：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;ColoredPoint() { super(); }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;然后，这个构造函数调用不带参数的 &lt;code&gt;Point&lt;/code&gt; 构造函数。&lt;code&gt;Point&lt;/code&gt; 构造函数并不以调用构造函数开始，因此 Java 编译器提供了对其超类构造函数的隐式调用，不带参数，就像已经编写的那样：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Point() { super(); x = 1; y = 1; }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;因此，将调用不带参数的 &lt;code&gt;Object&lt;/code&gt; 构造函数。&lt;/p&gt;
&lt;p&gt;类 &lt;code&gt;Object&lt;/code&gt; 没有父类，因此递归到此结束。接下来，调用 &lt;code&gt;Object&lt;/code&gt; 的任何实例初始化器和实例变量的初始化器。接下来，执行不带参数的 &lt;code&gt;Object&lt;/code&gt; 构造函数体。&lt;code&gt;Object&lt;/code&gt; 中没有声明这样的构造函数，所以 Java 编译器提供了一个默认构造函数，在这个特殊情况下是：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Object() { }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;此构造函数执行无效并返回。&lt;/p&gt;
&lt;p&gt;接下来，执行类 &lt;code&gt;Point&lt;/code&gt; 的实例变量的所有初始化器。当它发送时，&lt;code&gt;x&lt;/code&gt; 和 &lt;code&gt;y&lt;/code&gt; 的声明不提供任何初始化值，因此示例的这一步不需要任何操作。然后执行 &lt;code&gt;Point&lt;/code&gt; 构造函数体，将 &lt;code&gt;x&lt;/code&gt; 设为 &lt;code&gt;1&lt;/code&gt;，将 &lt;code&gt;y&lt;/code&gt; 设为 &lt;code&gt;1&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;接下来，执行 &lt;code&gt;ColoredPoint&lt;/code&gt; 类的实例变量和初始化器。这一步将值 &lt;code&gt;0xFF00FF&lt;/code&gt; 分配给 &lt;code&gt;color&lt;/code&gt;。最后，执行 &lt;code&gt;ColoredPoint&lt;/code&gt; 构造函数体的其余部分（调用 &lt;code&gt;super&lt;/code&gt; 之后的部分）；在主题的其他部分中碰巧没有语句，因此不需要进一步操作，初始化完成。&lt;/p&gt;
&lt;p&gt;例子 12.5-2，实例创建期间的动态调度：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;class Super {
    Super() { printThree(); }
    void printThree() { System.out.println(&amp;quot;three&amp;quot;); }
}
class Test extends Super {
    int three = (int)Math.PI;  // That is, 3
    void printThree() { System.out.println(three); }

    public static void main(String[] args) {
        Test t = new Test();
        t.printThree();
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;该程序产生输出：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;0
3
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这表明在类 &lt;code&gt;Super&lt;/code&gt; 的构造函数中调用 &lt;code&gt;printThree&lt;/code&gt; 并没有调用类 &lt;code&gt;Super&lt;/code&gt; 中 &lt;code&gt;printThree&lt;/code&gt; 的定义，而是调用了类 &lt;code&gt;Test&lt;/code&gt; 中 &lt;code&gt;printThree&lt;/code&gt; 的覆盖定义。因此，该方法在 &lt;code&gt;Test&lt;/code&gt; 的字段初始化器执行之前允许，这就是为什么第一个输出值是 0，&lt;code&gt;Test&lt;/code&gt; 的字段 &lt;code&gt;three&lt;/code&gt; 初始化的默认值。之后在方法 &lt;code&gt;main&lt;/code&gt; 中对 &lt;code&gt;printThree&lt;/code&gt; 的调用，调用了 &lt;code&gt;printThree&lt;/code&gt; 的相同的定义，但此时已经执行了实例变量 &lt;code&gt;three&lt;/code&gt; 的初始化器，因此输出了值 &lt;code&gt;3&lt;/code&gt;。&lt;/p&gt;
&lt;h2 id=&#34;126-finalization-of-class-instances&#34;&gt;12.6 Finalization of Class Instances&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;Object&lt;/code&gt; 类有一个 &lt;code&gt;protected&lt;/code&gt; 的方法 &lt;code&gt;finalize&lt;/code&gt;；这个方法可以被其他类重写。可为对象调用的 &lt;code&gt;finalize&lt;/code&gt; 的特定定义成为该对象的&lt;em&gt;终结器(finalizer)&lt;/em&gt;。在垃圾收集器回收对象的存储之前，Java 虚拟机将调用该对象的 finalizer 。&lt;/p&gt;
&lt;p&gt;finalizer 提供了释放自动存储管理器无法自动释放的资源的机会。在这种情况下，仅仅回收对象使用的内存并不能保证回收对象所持有的资源。&lt;/p&gt;
&lt;p&gt;Java 编程语言没有指定调用 finalizer 的时间，只是说将在重用对象的存储志强调用 finalizer。&lt;/p&gt;
&lt;p&gt;Java 编程语言没有指定哪个线程将为任何给定对象调用 finalizer。&lt;/p&gt;
&lt;p&gt;*重要的是 要注意，许多 finalizer 线程可能是活动的（在大型共享内存多处理器上有时需要这样），如果一个大型连接的数据结构变成垃圾，那么该数据结构中每个对象的所有 *  &lt;code&gt;finalize&lt;/code&gt; &lt;em&gt;方法都可能同时被调用，每个 finalizer 调用在不同的线程中运行。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Java 编程语言没有对 &lt;code&gt;finalize&lt;/code&gt; 方法调用进行排序。finalizer 可以按任何顺序调用，甚至可以并发调用。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;例如，如果循环链接的未终结对象组变得不可达（或 finalizer 可达），则所有对象可以一起变得可终结。最终，这些对象的 finalizer 可以以任何顺序调用，甚至可以使用多线程并发调用。如果自动存储管理器来发现对象不可达，那么它们的存储可以被回收。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;实现一个类是很简单的，当所有对象都变得不可访问时，它将导致一组类似 finalizer 的方法以指定的顺序为一组对象调用。定义这样一个类留给读者作为练习。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;保证在调用 finalizer 时，调用该 finalizer 的线程不会持有任何用户可见的同步锁。&lt;/p&gt;
&lt;p&gt;如果在终结期间引发了未捕获异常，则该异常将被忽略，该对象的终结将终止。&lt;/p&gt;
&lt;p&gt;一个对象的构造函数的完成发生在（17.4.5）它的 &lt;code&gt;finalize&lt;/code&gt; 方法的执行之前（在 happens-before 的正式意义上）。&lt;/p&gt;
&lt;p&gt;在类对象中声明的 &lt;code&gt;finalize&lt;/code&gt; 方法不执行任何操作。&lt;code&gt;Object&lt;/code&gt; 类声明 &lt;code&gt;finalize&lt;/code&gt; 方法的事实意味着任何类的 &lt;code&gt;finalize&lt;/code&gt; 方法都可以调用其超类的 &lt;code&gt;finalize&lt;/code&gt; 方法。除非程序员有意使超类中 finalizer 的动作无效，否则应该总是这样做。（与构造函数不同，finalizer 不会自动调用超类的 finalizer；这种调用必须显式编码。）&lt;/p&gt;
&lt;p&gt;&lt;em&gt;为了提高效率，实现可以跟踪哪些不覆盖&lt;/em&gt;  &lt;code&gt;Object&lt;/code&gt;&lt;em&gt;类的&lt;/em&gt; &lt;code&gt;finalize&lt;/code&gt; &lt;em&gt;方法的类对象，或者以一种简单 方式覆盖它。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;protected void finalize() throws Throwable {
    super.finalize();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如 &lt;a href=&#34;#1261-implementing-finalization&#34;&gt;12.6.1&lt;/a&gt; 所述，我们鼓励实现将这一的对象视为具有未被覆盖的 finalizer，并更有效的终结它们。&lt;/p&gt;
&lt;p&gt;可以显示调用 finalizer，就像任何其他方法一样。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;java.lang.ref&lt;/code&gt; 包描述了弱引用，它与垃圾收集和终结进行交互。与任何与 Java 编程语言有特殊交互的 API 一样，实现者必须了解 &lt;code&gt;java.lang.ref&lt;/code&gt; API 提出的任何要求。本规范不以任何方式讨论弱引用。读者可以参考 API 文档了解详细信息。&lt;/p&gt;
&lt;h3 id=&#34;1261-implementing-finalization&#34;&gt;12.6.1 Implementing Finalization&lt;/h3&gt;
&lt;p&gt;每个对象都可以用两个属性来描述：它可以是 &lt;em&gt;可到达的（reachable）&lt;/em&gt;，&lt;em&gt;终结器可到达的（finalizer-reachable）&lt;/em&gt; 或 &lt;em&gt;不可到达的（unreachable）&lt;/em&gt;，也可以是 &lt;em&gt;未终结的（unfinalized）&lt;/em&gt;，&lt;em&gt;可终结的（finalizable）&lt;/em&gt; 或 &lt;em&gt;终结的（finalized）&lt;/em&gt;。&lt;/p&gt;
&lt;p&gt;**可达（reachable）**对象是可以在任何潜在的持续计算中从任何活动线程访问的任何对象。&lt;/p&gt;
&lt;p&gt;**终结器可访问（finalizer-reachable）**的对象可以通过某个引用链从某个可终结的对象访问，但不能从任何活动线程访问。&lt;/p&gt;
&lt;p&gt;**不可达（unreachable）**对象无论用哪种方法都不可达。&lt;/p&gt;
&lt;p&gt;**未终结（unfinalized）**对象从未自动调用其 finalizer。&lt;/p&gt;
&lt;p&gt;**终结（finalized）**对象已经自动调用了它的 finalizer。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;可终结（finalizable）&lt;/strong&gt; 对象从未自动调用其终结器，但 Java 虚拟机最终可能会自动调用其终结器。&lt;/p&gt;
&lt;p&gt;直到对象 &lt;code&gt;o&lt;/code&gt; 的构造函数调用了 &lt;code&gt;o&lt;/code&gt; 上层的 &lt;code&gt;Object&lt;/code&gt; 的构造函数，并且该调用成功完成（即没有引发异常），对象 &lt;code&gt;o&lt;/code&gt; 才是 &lt;strong&gt;可终结的（finaliable）&lt;/strong&gt;。对一个对象的字段的每一个预终结（pre-finalization）写入必须对该对象的终结（finalization）可见。此外，对该对象的字段的预终结（pre-finalization）读取都会看到在该对象的终结被启动之后发生的写入。&lt;/p&gt;
&lt;p&gt;程序的优化转换可以设计成减少可到达对象的数量，使之少于那些天真地认为可到达的对象的数量。例如，Java 编译器或代码生成器可能会选择将一个不再使用的变量或参数设置为 &lt;code&gt;null&lt;/code&gt;，从而使此类对象的存储可能更快速地被回收。&lt;/p&gt;
&lt;p&gt;另一个例子是对象字段中的值存储在寄存器中。然后程序可以访问寄存器而不是对象，并且不在访问该对象。这意味着该对象是垃圾。注意，只有当引用在栈上，而不是存储在堆中时，才允许这种优化。&lt;/p&gt;
&lt;p&gt;例如，考虑 Finalizer Guardian 模式：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;class Foo {
    private final Object finalizerGuardian = new Object() {
        protected void finalize() throws Throwable {
            /* finalize outer Foo object */
        }
    }
} 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果子类重写 &lt;code&gt;finalize&lt;/code&gt; 并且没有显示调用 &lt;code&gt;super.finalize&lt;/code&gt;，finalizer guardian 会强制调用 &lt;code&gt;super.finalize&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;如果允许对存储在堆上的引用进行这些优化，那么 Java 编译器可以检测到 &lt;code&gt;finalizerGuardian&lt;/code&gt; 字段从未被读取，将其清空，理解回收对象，并提前调用 finalizer。这与初衷背道而驰：当 &lt;code&gt;Foo&lt;/code&gt; 实例变得不可访问时，程序员可能想调用 &lt;code&gt;Foo&lt;/code&gt; 的 finalizer。因此，这种转换是不合法的：只要外部类对象是可达的，内部类对象就应该是可达的。&lt;/p&gt;
&lt;p&gt;这种类型的转换可能会导致 &lt;code&gt;finalizer&lt;/code&gt; 方法的调用比预期的要早。为了允许用户防止这种情况，我们强调了同步可以保持对象存活的概念。如果一个对象的 finalizer 可以导致该对象上的同步，那么该对象必须是活动的，并且在它被锁定时被认为是可访问的。&lt;/p&gt;
&lt;p&gt;请注意，这并不妨碍同步消除：只有当 finalizer 可能对一个对象进行同步时，同步才会使该对象保持活动状态。由于终结器出现在另一个线程中，因此许多情况下，无论如何都无法移除同步。&lt;/p&gt;
&lt;h3 id=&#34;1262-interaction-with-the-memory-model&#34;&gt;12.6.2 Interaction with the Memory Model&lt;/h3&gt;
&lt;p&gt;内存模型（17.4）必须能够决定何时提交发生在 finalizer 中的操作。本节描述 finalization 与内存模型的交互。&lt;/p&gt;
&lt;p&gt;每个执行都与许多可达性决策点，标记为 &lt;code&gt;di&lt;/code&gt;。每个动作要么发生在 &lt;code&gt;di&lt;/code&gt;之前，要么发生在 &lt;code&gt;di&lt;/code&gt; 之后。除了明确提到的以外，本节中描述的先来后到排序与内存模型中的所有其他排序无关。&lt;/p&gt;
&lt;p&gt;如果 &lt;code&gt;r&lt;/code&gt; 是看到写 &lt;code&gt;w&lt;/code&gt; 的读，并且 &lt;code&gt;r&lt;/code&gt; 在 &lt;code&gt;di&lt;/code&gt; 之前，那么 &lt;code&gt;w&lt;/code&gt; 必须在 &lt;code&gt;di&lt;/code&gt; 之前。&lt;/p&gt;
&lt;p&gt;如果 &lt;code&gt;x&lt;/code&gt; 和 &lt;code&gt;y&lt;/code&gt; 是对同一变量或监视器的同步操作，使得 &lt;code&gt;so(x, y)&lt;/code&gt; （17.4.4）和 &lt;code&gt;y&lt;/code&gt; 在 &lt;code&gt;di&lt;/code&gt; 之前，那么 &lt;code&gt;x&lt;/code&gt; 必须在 &lt;code&gt;di&lt;/code&gt; 之前。&lt;/p&gt;
&lt;p&gt;在每个可达性决策点，一些对象集被标记为不可达，而这些对象的一些子集被标记为可终结。这些可达性决策点也是根据 &lt;code&gt;java.lang.ref&lt;/code&gt; 包的 API 文件中提供的规则检查、加入队列和清除引用的点。&lt;/p&gt;
&lt;p&gt;唯一被认为在 &lt;code&gt;di&lt;/code&gt; 点绝对可达的对象是那些可以通过应用这些规则证明可达的对象：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果存在对类 &lt;code&gt;C&lt;/code&gt; 的 &lt;code&gt;static&lt;/code&gt; 字段 &lt;code&gt;v&lt;/code&gt; 的写入 &lt;code&gt;w1&lt;/code&gt;，使得 &lt;code&gt;w1&lt;/code&gt; 写入的值是对 &lt;code&gt;B&lt;/code&gt; 的引用，类 &lt;code&gt;C&lt;/code&gt; 有可到达的类加载器加载，并且不存在对 &lt;code&gt;v&lt;/code&gt; 的写入 &lt;code&gt;w2&lt;/code&gt;，使得 &lt;code&gt;hb(w2, w1)&lt;/code&gt; 不为 true，并且 &lt;code&gt;w1&lt;/code&gt; 和 &lt;code&gt;w2&lt;/code&gt; 都在 &lt;code&gt;di&lt;/code&gt; 之前，则对象 &lt;code&gt;B&lt;/code&gt; 在 &lt;code&gt;di&lt;/code&gt; 处肯定是可达的。&lt;/li&gt;
&lt;li&gt;如果存在对 &lt;code&gt;A&lt;/code&gt; 的元素 &lt;code&gt;v&lt;/code&gt; 的写 &lt;code&gt;w1&lt;/code&gt;，使得由 &lt;code&gt;w1&lt;/code&gt; 写的值是对 &lt;code&gt;B&lt;/code&gt; 的引用，并且不存在对 &lt;code&gt;v&lt;/code&gt; 的写 &lt;code&gt;w2&lt;/code&gt; ，使得 &lt;code&gt;hb(w2, w1)&lt;/code&gt; 不为 true，并且 &lt;code&gt;w1&lt;/code&gt; 和 &lt;code&gt;w2&lt;/code&gt; 都在 &lt;code&gt;di&lt;/code&gt; 之前，则对象 &lt;code&gt;B&lt;/code&gt; 在 &lt;code&gt;di&lt;/code&gt; 处肯定是从 &lt;code&gt;A&lt;/code&gt; 可达的。&lt;/li&gt;
&lt;li&gt;如果一个对象 &lt;code&gt;C&lt;/code&gt; 从一个对象 &lt;code&gt;B&lt;/code&gt; 肯定是可达的，并且对象 &lt;code&gt;B&lt;/code&gt; 从一个对象 &lt;code&gt;A&lt;/code&gt; 肯定是可达的，那么 &lt;code&gt;C&lt;/code&gt; 从 &lt;code&gt;A&lt;/code&gt; 肯定是可达的。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果对象 &lt;code&gt;X&lt;/code&gt; 在 &lt;code&gt;di&lt;/code&gt; 被标记位不可达，则：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;从 &lt;code&gt;static&lt;/code&gt; 字段到 &lt;code&gt;di&lt;/code&gt;， &lt;code&gt;X&lt;/code&gt; 一定不可达；以及&lt;/li&gt;
&lt;li&gt;线程 &lt;code&gt;t&lt;/code&gt; 中所有在 &lt;code&gt;di&lt;/code&gt; 之后对 &lt;code&gt;X&lt;/code&gt; 的所有活动使用必须发生在 &lt;code&gt;X&lt;/code&gt; 的 finalizer 调用中，或者线程 &lt;code&gt;t&lt;/code&gt; 在 &lt;code&gt;di&lt;/code&gt; 之后执行对 &lt;code&gt;X&lt;/code&gt; 的引用的读取的结果；以及&lt;/li&gt;
&lt;li&gt;所有在 &lt;code&gt;di&lt;/code&gt; 之后的读操作，如果看到对 &lt;code&gt;X&lt;/code&gt; 的引用，就必须看到在 &lt;code&gt;di&lt;/code&gt; 处不可达的对象元素的写操作，或者在 &lt;code&gt;di&lt;/code&gt; 之后看到对象的写操作。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;动作 &lt;code&gt;a&lt;/code&gt; 是对 &lt;code&gt;X&lt;/code&gt; 的主动使用，当且仅当以下至少有一个为 true：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;读取或写入 &lt;code&gt;X&lt;/code&gt; 的元素&lt;/li&gt;
&lt;li&gt;&lt;code&gt;a&lt;/code&gt; 锁定或解锁 &lt;code&gt;X&lt;/code&gt;，并且在调用 &lt;code&gt;X&lt;/code&gt; 的 finalizer 之后，会在 &lt;code&gt;X&lt;/code&gt; 上发生一个锁定操作&lt;/li&gt;
&lt;li&gt;&lt;code&gt;a&lt;/code&gt; 写入一个对 &lt;code&gt;X&lt;/code&gt; 的引用&lt;/li&gt;
&lt;li&gt;&lt;code&gt;a&lt;/code&gt; 是一个对象 &lt;code&gt;Y&lt;/code&gt; 的主动使用，&lt;code&gt;X&lt;/code&gt; 从 &lt;code&gt;Y&lt;/code&gt; 肯定是可达的&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果对象 &lt;code&gt;X&lt;/code&gt; 在 &lt;code&gt;di&lt;/code&gt; 被标记为可终结，则：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;X&lt;/code&gt; 必须在 &lt;code&gt;di&lt;/code&gt; 处被标记为不可达；以及&lt;/li&gt;
&lt;li&gt;&lt;code&gt;di&lt;/code&gt; 必须是 &lt;code&gt;X&lt;/code&gt; 被标记为可终结的唯一位置；以及&lt;/li&gt;
&lt;li&gt;在 finalizer 调用之后发生的动作必须在 &lt;code&gt;di&lt;/code&gt; 之后。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;127-unloading-of-classes-and-interfaces&#34;&gt;12.7 Unloading of Classes and Interfaces&lt;/h2&gt;
&lt;p&gt;Java 编程语言的实现可以&lt;strong&gt;卸载&lt;/strong&gt;类。&lt;/p&gt;
&lt;p&gt;当前仅当类或接口的定义类加载可以被垃圾回收期回收时，类或接口才可以被卸载，如 &lt;a href=&#34;#126-finalization-of-class-instances&#34;&gt;12.6&lt;/a&gt; 中所讨论的。&lt;/p&gt;
&lt;p&gt;Bootstrap loader 加载的类和接口不能被卸载。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;类卸载是一种优化，有助于减少内存使用。显然，程序的语义不应该依赖于系统是否以及如何选择实现优化，比如类卸载。否则会损害程序的可移植性。因此，一个类或接口是否被卸载对程序来说应该是透明的。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;然而，如果一个类或接口&lt;/em&gt; &lt;code&gt;C&lt;/code&gt; &lt;em&gt;在它的定义加载器潜在地可达时被卸载，那么&lt;/em&gt; &lt;code&gt;C&lt;/code&gt; &lt;em&gt;可能被重新装载。谁也不能保证这不会发生。即使该类没有被任何其他当前加载的类引用，他也可能被尚未加载的某个类或接口&lt;/em&gt; &lt;code&gt;D&lt;/code&gt; &lt;em&gt;引用。当&lt;/em&gt; &lt;code&gt;D&lt;/code&gt; &lt;em&gt;被&lt;/em&gt; &lt;code&gt;C&lt;/code&gt; &lt;em&gt;的定义加载器加载时，它的执行可能会导致&lt;/em&gt; &lt;code&gt;C&lt;/code&gt; &lt;em&gt;的重新加载。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;例如，如果类有&lt;/em&gt;  &lt;code&gt;static&lt;/code&gt; &lt;em&gt;变量（其状态会丢失），静态初始值设定项（可能有副作用）或&lt;/em&gt; &lt;code&gt;native&lt;/code&gt; &lt;em&gt;方法（可能保留静态状态），则重新加载可能不透明。此外，类对象的哈希值依赖它的身份。因此，一般来说，以完全透明的方式重新加载一个类或接口是不可能的。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;因为我们永远不能保证卸载一个类或接口（其加载器是潜在可达的）不会导致重新加载，重新加载从来都不是透明的，但是卸载必须是透明的，所以当一个类或接口加载器是潜在可达的时候，我们不能卸载它。类似的推理可以用来推断由 Bootstrap loader 装载的类和加快永远不能被卸载。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;人们还必须讨论为什么卸载一个类&lt;/em&gt; &lt;code&gt;C&lt;/code&gt; &lt;em&gt;是安全的，如果它的定义类加载器可以被回收的话。如果定义类加载器可以被回收，那么永远不会有对它的任何活动引用（这包括不活动的引用，但可能被 finalizer 复活）。反过来，只有当加载器定义的任何类（包括）&lt;/em&gt; &lt;code&gt;C&lt;/code&gt; &lt;em&gt;都不能有任何活动引用时，这种情况才会发送，无论是从它们的实例还是从代码。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;类卸载是一种优化，它仅在对加载大量类并在一段时间后停止使用这些类的应用程序有意义。这种应用程序的一个主要例子是 web 浏览器，但还有其他应用程序。这种应用程序的一个特点是，它们通过显式使用类加载器来管理类。因此，上述政策对他们来说非常有效。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;严格来说，本规范并没有讨论类卸载的问题，因为类卸载仅仅是一种优化。然而，这个问题非常精妙，因此在此作为澄清提及。&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;128-program-exit&#34;&gt;12.8 Program Exit&lt;/h2&gt;
&lt;p&gt;当发生以下两种情况之一时，程序终止其所有活动并退出：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;所有不是守护线程的线程都会终止。&lt;/li&gt;
&lt;li&gt;某线程调用类 &lt;code&gt;Runtime&lt;/code&gt; 或类 &lt;code&gt;System&lt;/code&gt; 的 &lt;code&gt;exit&lt;/code&gt; 方法，安全管理器不禁止 &lt;code&gt;exit&lt;/code&gt; 操作。&lt;/li&gt;
&lt;/ul&gt;
">Chapter 12. Execution</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://wenbozhangw.github.io/post/lesslesstcpip-xiang-jie-juan-yi-xie-yi-greatergreater-di-wu-zhang-internet-xie-yi/"" data-c="
          &lt;h2 id=&#34;51-引言&#34;&gt;5.1 引言&lt;/h2&gt;
&lt;p&gt;IP是 TCP/IP 协议族中的核心协议。所有 TCP、 UDP、 ICMP 和 IGMP 数据都通过 IP 数据报传输。 IP 提供了一种尽力而为、无连接的数据报交付服务。 “尽力而为”的含义是不保证 IP 数据报能成功到达目的地。虽然 IP 不是简单丢弃所有不必要流量，但它也不对自己尝试交付的数据报提供保证。当某些错误发生时，例如一台路由器临时用尽缓冲区， IP 提供一个简单的错误处理方法： 丢弃一些数据（通常是最后到达的数据报）。任何可靠性必须由上层（例如 TCP）提供。 IPv4 和 IPv6 都使用这种尽力而为的基本交付模式。&lt;/p&gt;
&lt;p&gt;“&lt;strong&gt;无连接&lt;/strong&gt;”意味着 IP 不维护网络单元（即路由器）中数据报相关的任何链接状态信息，每个数据报独立于其他数据报来处理。这也意味着 IP 数据报可不按顺序交付。如果一个源主机向同一目的地发送两个连续的数据报（第一个为 A，第二个为 B），每个数据报可以独立路由，通过不同路径，并且 B 可能在 A 之前到达。 IP 数据报也可能发生其他问题：它们可能在传输过程中被复制，可能改变内容从而导致错误。此外， IP 之上的一些协议（通常是 TCP）需要处理这些潜在问题，以便为应用提供无差错的交付。&lt;/p&gt;
&lt;!-- more --&gt;
&lt;p&gt;本章我们首先看一下 IPv4 （见图 5-1）和 IPv6 （见图 5-2）头部中的字段，然后描述 IP 如何转发。[&lt;a href=&#34;#RFC0791&#34;&gt;RFC0791&lt;/a&gt;] 是针对 IPv4 的正式规范。描述 IPv6 的一系列 RFC 从 [&lt;a href=&#34;#RFC2460&#34;&gt;RFC2460&lt;/a&gt;] 开始。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1653556210920.png&#34; alt=&#34;图 5-1&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 5-1   IPv4 数据报。头部大小可变， 4 位的 IHL 字段被限制为 15 个 32 位字（60字节）。一个典型的 IPv4 头部包含 20 字节（没有选项）。源地址和目的地址的长度为 32 位。第二个 32 位字的大部分用于 IPv4 分片功能。头部校验和有助于确保头部字段被正确发送到目的地，但不保护数据内容&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1653556327941.png&#34; alt=&#34;图 5-2&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 5-2    IPv6 头部大小固定（40 字节），并包含 128 位源地址和目的地址。下一个头部字段用于说明 IPv6 头部之后其他扩展头部的存在和类型，它们形成一条包括特殊扩展或处理指令的头部链。应用数据跟在这条头部链之后，通常紧跟着是一个传输层头部&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;52-ipv4-头部和-ipv6-头部&#34;&gt;5.2 IPv4 头部和 IPv6 头部&lt;/h2&gt;
&lt;p&gt;图 5-1 显示了 IPv4 数据报格式。正常的 IPv4 头部大小为 20 字节，除非存在选项（这种情况很少见）。 IPv6 头部长度是它的两倍，但没有任何选项。它可以有扩展头部，可提供类似的功能，我们将在后面看到。在关于 IP 头部和数据报的印象中，最高有效位在左侧且编号为 0，一个 32 位值的最低有效位在右侧且编号为 31。&lt;/p&gt;
&lt;p&gt;一个 32 位值的 4 字节按以下顺序传输：首先是 0 ~ 7 位，然后是 8 ~ 15 位，接着是 16 ~ 23 位，最后是 24 ~ 31 位。这就是所谓的&lt;strong&gt;高位优先&lt;/strong&gt;字节序，它是 TCP/IP 头部中所有二进制整数在网络中传输时所需的字节顺序。它也被称为网络字节序。计算机的 CPU 使用其他格式存储二进制整数，例如大多数 PC 使用低位优先字节序，在传输时必须将头部值转换为网络字节序，并在接收时再转换回来。&lt;/p&gt;
&lt;h3 id=&#34;521-ip-头部字段&#34;&gt;5.2.1 IP 头部字段&lt;/h3&gt;
&lt;p&gt;第一个字段（只有 4 位或半个字节）是版本字段。它包含 IP 数据报的版本号：IPv4 为 4， IPv6 为 6。IPv4 头部和 IPv6 头部除版本字段位置相同外再无其他是一样的。因此，这两个协议不能直接互操作，主机或路由器必须分别处理 IPv4 或 IPv6 （或两者，称为&lt;strong&gt;双栈&lt;/strong&gt;）。虽然也提出并发展了其他 IP 版本，但只有版本 4 和 6 经常使用。 IANA 负责保存这些版本号的正式注册信息 [&lt;a href=&#34;#IV&#34;&gt;IV&lt;/a&gt;]。&lt;/p&gt;
&lt;p&gt;**Internet 头部长度（IHL）**字段保存 IPv4 头部中 32 位字的数量，包括任何选项。由于它是一个 4 位的字段，所以 IPv4 头部被限制为最多 15 个 32 位字，即 60 字节。后面，我们将看到，这种限制使一些选项（例如“记录路由”选项）当前几乎无法使用。这个字段的正常值（当没有选项时）是 5。 IPv6 中不存在这个字段，其头部长度固定为 40 字节。&lt;/p&gt;
&lt;p&gt;在头部长度之后， IPv4 [&lt;a href=&#34;#RFC0791&#34;&gt;RFC0791&lt;/a&gt;] 的最初规范指定了一个&lt;strong&gt;服务类型（ToS）&lt;strong&gt;字段，IPv6 [&lt;a href=&#34;#RFC2460&#34;&gt;RFC2460&lt;/a&gt;] 指定了一个等效的&lt;/strong&gt;通信类型&lt;/strong&gt;字段。由于它们从来没被广泛使用，因此最终这个 8 位长的字段被分为两个部分，并由一组 RFC（ [&lt;a href=&#34;#RFC3260&#34;&gt;RFC3260&lt;/a&gt;] [&lt;a href=&#34;#RFC3168&#34;&gt;RFC3168&lt;/a&gt;] [&lt;a href=&#34;#RFC2474&#34;&gt;RFC2474&lt;/a&gt;] 和其他 RFC）重新定义。目前，前 6 位被称为&lt;strong&gt;区分服务&lt;/strong&gt;字段（DS字段），后 2 位是**显式拥塞通知（ECN）**字段或指示位。现在，这些 RFC 适用于 IPv4 和 IPv6。这些字段被用于数据报转发时的特殊处理。我们将在 5.2.3 节中详细讨论它们。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;总长度&lt;/strong&gt;字段是 IPv4 数据报的总长度（以字节为单位）。通过这个字段和 IHL 字段，我们知道数据报的数据部分从哪里开始，以及它的长度。由于它是一个 16 位的字段，所以 IPv4 数据报的最大长度（包括头部）为 65535 字节。由于一些携带 IPv4 数据报的低层协议不能（精确）表达自己封装的数据报大小，所以需要在头部中给出总长度字段。例如，以太网会将短帧填充到最小长度（64 字节）。虽然以太网最小有效载荷为 46 字节（见第 3 章），但一个 IPv4 数据报也可能会更小（20 字节）。如果没有提供总长度字段， IPv4 实现将无法知道一个 46 字节的以太网帧是一个 IP 数据报，还是经过填充的 IP 数据报，这样可能会导致混淆。&lt;/p&gt;
&lt;p&gt;尽管可发送一个 65535 字节的IP数据报，但大多数链路层（例如以太网）不能携带这么大的数据，除非将它分（拆）成更小的片。另外，主机不需要接收大于 576 字节的 IPv4 数据报。 （在 IPv6 中，主机需要能处理所连接链路 MTU 大小的数据报，而最小链路 MTU 为 1280 字节。）很多使用 UDP 协议（见第 10 章）传输数据（例如 DNS、DHCP 等）的应用程序，限制为使用 512 字节大小的数据，以避免 576 字节的 IPv4 限制。 TCP 根据额外信息（见第 15 章）选择自己的数据报大小。&lt;/p&gt;
&lt;p&gt;当一个 IPv4 数据报被分为多个更小的分片时，每个分片自身仍是一个独立的 IP 数据报，总长度字段反映具体的分片长度。第 10 章中将详细介绍分片和 UDP。IPv6 头部不支持分片，其长度可由&lt;strong&gt;负载长度&lt;/strong&gt;字段获得。这个字段提供 IPv6 数据报长度，不包括头部长度，但扩展头部包括在&lt;strong&gt;负载长度&lt;/strong&gt;中。对于 IPv4，这个 16 位的字段限制其最大值为 65535。对于 IPv6，&lt;strong&gt;负载长度&lt;/strong&gt;被限制为 64KB，而不是整个数据报。另外， IPv6 还支持一个超长数据报选项（见 5.3.1.2 节），它至少在理论上提供了可能性，即单个分组的有效载荷可达到 4GB （4294967295 字节）!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;标识&lt;/strong&gt;字段帮助标识由 IPv4 主机发送的数据报。为了避免将一个数据报分片和其他数据报分片混淆，发送主机通常在每次（从它的一个 IP 地址）发送数据报时都将一个内部计数器加 1，并将该计数器值复制到 &lt;strong&gt;IPv4 标识&lt;/strong&gt; 字段。这个字段对实现分片很重要，因此我们将在第 10 章中进一步讨论，另外还会讨论标志和分片偏移字段。在 IPv6 中，这个字段显示在分片扩展头部中，我们将在 5.3.3 节中讨论。&lt;/p&gt;
&lt;p&gt;**生存期（TTL）**字段用于设置一个数据报可经过的路由器数量的上限。发送方将它初始化为某个值（[&lt;a href=&#34;#RFC1122&#34;&gt;RFC1122&lt;/a&gt;] 建议为 64，但 128 或 255 也不少见），每台路由器在转发数据报时将该值减 1。当这个字段值达到 0 时，该数据报被丢弃，并使用一个 ICMP 消息通知发送方（见第 8 章）。.这可以防止由于出现不希望的路由环路而导致数据报在网络中永远循环。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;注意    TTL 字段最初指定 IP 数据报的最大生存期在几秒钟内，但路由器总需要将
这个值至少减 1。 实际上，当前路由器在正常操作下通常不会持有数据报超过 1 秒
钟，因此较早的规则现在已被忽略或遗忘，这个字段在 IPv6 中根据实际用途已被
重新命名为跳数限制。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;IPv4 头部中的&lt;strong&gt;协议&lt;/strong&gt;字段包含一个数字，表示数据报有效载荷部分的数据类型。最常用的值为 17 （UDP）和 6 （TCP）。这提供了多路分解的功能，以便 IP 协议可用于携带多种协议类型的有效载荷。虽然该字段最初仅用于指定数据报封装的传输层协议，但它现在用于识别其中封装的协议是否为一种传输层协议。其他封装也是可能的，例如 IPv4-in-IPv4 （值为 4）。数字分配页面 [&lt;a href=&#34;#AN&#34;&gt;AN&lt;/a&gt;] 给出了可能的协议字段值的正式列表。 IPv6 头部中的下一个&lt;strong&gt;头部&lt;/strong&gt;字段给出了 IPv4 中的协议字段。它用于指出 IPv6 头部之后的头部类型。这个字段可能包含由 IPv4 协议字段定义的任何值，或 5.3 节中描述的 IPv6 扩展头部的相关值。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;头部校验和&lt;/strong&gt;字段仅计算 IPv4 头部。理解这一点很重要，因为这意味着 IP 协议不检查 IPv4 数据报有效载荷（例如 TCP 或 UDP 数据）的正确性。为了确保 IP 数据报的有效载荷部分已正确传输，其他协议必须通过自己的数据完整性检验机制来检查重要数据。我们看到，封装在 IP 中的几乎所有协议（ICMP、 IGMP、 UDP 和 TCP）在自己头部中都有一个涵盖其头部和数据的校验和，也涵盖它们认为重要的 IP 头部的某些部分（一种“违反分层”的形式）。令人惊讶的是， IPv6 头部没有任何校验和字段。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;注意    IPv6 头部省略校验和字段是一个有争议的决定。这个行动背后的理由大致
如下：在 IP 头部中，更高层协议为确定正确性，必须计算它们自己的校验和，这
需要涵盖它们认为重要的数据。 IP 头部中的错误带来的后果是：数据被投递到错误
的目的地、指示数据来源错误，或在交付过程中错位。由于位错误比较少见（受益
于 Internet 流量的光纤传输），而且其他字段提供了更有力的确保正确性的机制（更
高层次的校验和或其他检查），因此决定从 IPv6 头部中删除这个字段。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;大多数使用校验和的其他 Internet 相关协议也使用该校验和计算算法，因此有时称之为 &lt;strong&gt;Internet 校验和&lt;/strong&gt;。注意，当一个 IPv4 数据报经过一台路由器时， TTL 字段减 1 带来的结果是其头部校验和必须改变。找们将在 5.2.2 节详细讨论校验和计算方法。&lt;/p&gt;
&lt;p&gt;每个 IP 数据报包含发送者的&lt;strong&gt;源 IP 地址&lt;/strong&gt;和接收者的&lt;strong&gt;目的 IP 地址&lt;/strong&gt;。这些针对 IPv4 的 32 位地址和针对 IPv6 的 128 位地址，通常标识一台计算机的一个接口，但组播地址和广播地址（见第 2 章）不符合本规则。虽然一个 32 位地址可容纳看似很多 Internet 实体（2&lt;sup&gt;32&lt;/sup&gt; 个），但一个广泛的共识是这个数字仍不够，这是向 IPv6 迁移的一个主要动机。 IPv6 的 128 位地址可容纳数量庞大的 Internet 实体。 [&lt;a href=&#34;#H05&#34;&gt;H05&lt;/a&gt;] 进行了重新统计， IPv6 拥有 3.4 × 10&lt;sup&gt;38&lt;/sup&gt; 个地址。引用 [&lt;a href=&#34;#H05&#34;&gt;H05&lt;/a&gt;]  和其他人的话：“乐观估计将使地球上每平方米表面拥有 3 911 873 538 269 506 102 个地址。”这确实看起来可持续很长一段时间。&lt;/p&gt;
&lt;h3 id=&#34;522-internet-校验和&#34;&gt;5.2.2 Internet 校验和&lt;/h3&gt;
&lt;p&gt;Internet 校验和是一个 16 位的数字和，它能以相当高的概率确定接收的消息或其中的部分内容是否与发送的相匹配。注意，Internet 校验和算法与常见的&lt;strong&gt;循环冗余校验（CRC）&lt;/strong&gt;[&lt;a href=&#34;#PB61&#34;&gt;PB61&lt;/a&gt;] 不同，后者提供了更强的保护功能。&lt;/p&gt;
&lt;p&gt;为了给输出的数据报计算 IPv4 头部校验和，首先将数据报的校验和字段值设置为 0。然后，对头部（整个头部被认为是一个 16 位字的序列）计算 16 位二进制反码和。这个 16 位二进制反码和被存储在&lt;strong&gt;校验和&lt;/strong&gt;字段中。二进制反码加法可通过“循环进位（end-round-carry）加法”实现：当使用传统（二进制补码）加法产生一个进位时，这个进位以二进制值 1 加在高位。图 5-3 显示了这个例子，消息内容使用十六进制表示。&lt;/p&gt;
&lt;p&gt;图 5-3    Internet 校验和是一个被校验数据（如果被计算的字节数为奇数，用 0 填充）的 16 位反码和的反码。如果被计算数据包括一个校验和字段，该字段在计算校验和运算之前被设置为 0，然后将计算出的校验和填充到该字段。为了检查一个包含校验和字段（头部、有效载荷等）的数据输入是否有效，需要对整个数据块（包含校验和字段）同样计算校验和。由于校验和字段本质上是其余数据校验和的反码，对正确接收的数据计算校验和应产生一个值 0&lt;/p&gt;
&lt;p&gt;当一个 IPv4 数据报被接收时，对整个头部计算出一个校验和，包括校验和字段自身的值。假设这里没有错误，计算出的校验和值为 0 （值 FFFF 的反码）。注意，对于任何不正常的分组或头部，分组中的校验和字段值不为 FFFF。如果是这样，这个和（在发送方的最后一次反码运算之前）将为 0。通过反码加法得到的和不能永远为 0，除非所有字节都是 0，这在任何合法 IPv4 头部中都不可能出现。当发现一个头部出错（计算的校验和不为 0）时， IPv4 实现将丢弃接收到的数据报。但是，不会生成差错信息。更高层以某种方式检测丢失的数据报，并在必要时重新传输。&lt;/p&gt;
&lt;h4 id=&#34;5221-internet-校验和数学性质&#34;&gt;5.2.2.1 Internet 校验和数学性质&lt;/h4&gt;
&lt;p&gt;在数学上， 16 位的十六进制值集合 V = {0001， …， FFFF} 与其反码和运算“+”共同形成一个阿贝尔群。将一个集合和一个运算符组合到一组时，必须符合以下性质：闭包、结合性、存在一个恒等元素，以及存在可逆。要形成一个阿贝尔（可交换的）群，还必须满足交换性。如果我们仔细观察，可看到所有特性实际上都服从：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于 V 中的任何 X、Y、（X + Y） 在 V 中  [闭包]&lt;/li&gt;
&lt;li&gt;对于 V 中的任何 X、Y、Z，X +（Y + Z） = （X + Y） + Z                 [结合性]&lt;/li&gt;
&lt;li&gt;对于 V 中的任何 X，e + X = X + e = X，其中 e = FFFF                 [恒等]&lt;/li&gt;
&lt;li&gt;对于 V 中的任何 X，有一个 X&#39; 在 V 中，使得 X + X&#39; = e                  [可逆]&lt;/li&gt;
&lt;li&gt;对于 V 中的任何 X、Y，（X + Y）=（Y +X）                      [交换性]&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;关于集合 V 和组 &amp;lt;V， +&amp;gt;，有趣的是我们已删除 0000。如果我们将数字 0000 放入集合 V，这时 &amp;lt;V， +&amp;gt; 不再是一个组。为了看清这点，我们首先观察 0000 和 FFFF 作为 0 （加性恒等）出现在使用“+”的运算中的情况。例如，AB12 + 0000= AB1 2= AB12+FFFF。但是，在一个组中只能有一个恒等元素。如果我们包含元素 12AB，并假设恒等元素为 0000，那么我们就需要某个可逆数 X′ 使得 （12AB  + X′）= 0000，但我们发现，在 V 中没有满足此条件的 X&#39; 存在。因此，我们需要排除 0000 作为&amp;lt;V， +&amp;gt; 中的恒等元素，通过将它从集合 V 中删除，使得这种结构成为一个满足要求的组。这里仅对抽象代数做一个简单介绍，读者若希望详细阅读这方面内容，可参考 Pinter [&lt;a href=&#34;#P90&#34;&gt;P90&lt;/a&gt;] 的畅销书。&lt;/p&gt;
&lt;h3 id=&#34;523-ds-字段和-ecn-以前称为-tos-字节或-ipv6-流量类别&#34;&gt;5.2.3 DS 字段和 ECN （以前称为 ToS 字节或 IPv6 流量类别）&lt;/h3&gt;
&lt;p&gt;IPv4 头部的第 3 和第 4 字段（IPv6 头部的第 2 和第 3 字段）分别是&lt;strong&gt;区分服务（称为 DS 字段）&lt;strong&gt;和 &lt;strong&gt;ECN 字段&lt;/strong&gt;。区分服务（称为 DiffServ）是一个框架和一组标准，用于支持 Internet [&lt;a href=&#34;#RFC2474&#34;&gt;RFC2474&lt;/a&gt;] [&lt;a href=&#34;#RFC2475&#34;&gt;RFC2475&lt;/a&gt;] [&lt;a href=&#34;#RFC3260&#34;&gt;RFC3260&lt;/a&gt;] 上不同类型的服务（即不只是尽力而为服务）。 IP 数据报以某种方式（通过预定义模式设置某些位）被标记，使它们的转发不同于（例如以更高的优先级）其他数据报。这样做可能导致网络中排队延时的增加或减少，以及出现其他特殊效果（可能与 ISP 收取的特殊费用相关）。 &lt;strong&gt;DS 字段&lt;/strong&gt;中的数字称为&lt;/strong&gt;区分服务代码点（DSCP）&lt;/strong&gt;。 “代码点”指的是预定义的具有特定含义的位。在通常情况下，如果数据报拥有一个分配的 DSCP，它在通过网络基础设施交付过程中会保持不变。但是，某些策略（例如在一段时间内可发送多少个高优先级的分组）可能导致一个数据报中的 DSCP 在交付过程中改变。&lt;/p&gt;
&lt;p&gt;当通过一台具有内部排队流量的路由器时，头部中的 2 位 ECN 位用于为数据报标记&lt;strong&gt;拥塞标识符&lt;/strong&gt;。一台持续拥塞的具有 ECN 感知能力的路由器在转发分组时会设置这两位。这种功能的设计思路是，当一个被标记的分组被目的节点接收时，有些协议（例如 TCP）会发现分组被标记并将这种情况通知发送方，发送方随后会降低发送速度，这样可在路由器因过载而被迫丢弃流量之前缓解拥塞。这种机制是避免或处理网络拥塞的方法之一，我们将在第 16 章中详细探讨。虽然 &lt;strong&gt;DS 字段&lt;/strong&gt;和 &lt;strong&gt;ECN 字段&lt;/strong&gt;并不密切相关，但它们被用作代替以前定义的** IPv4 服务类型&lt;strong&gt;和&lt;/strong&gt; IPv6 流量类别**字段。因此，它们经常被放在一起讨论，术语“ToS 字节”和“流量类别字节”仍在广泛使用。&lt;/p&gt;
&lt;p&gt;尽管原来的 ToS 和流量类别字节没得到广泛支持，但 DS 字段结构仍提供了一些对它们的兼容能力。为了对其如何工作有更清楚的了解，我们首先回顾服务类型字段 [&lt;a href=&#34;#RFC0791&#34;&gt;RFC0791&lt;/a&gt;] 的原始结构，如图 5-4 所示。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1653567934848.png&#34; alt=&#34;图 5-4&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 5-4    原来的 &lt;strong&gt;IPv4 服务类型&lt;/strong&gt; 和 &lt;strong&gt;IPv6 流量类别&lt;/strong&gt; 字段结构。&lt;strong&gt;优先级&lt;/strong&gt;子字段用于表示哪些分组具有更高优先级（较大的值意味着更高的优先级）。D、T 和 R 子字段分别用于表示延时、吞吐量和可靠性。如果这些字段值为 1，分别对应于低延时、高吞吐量和高可靠性&lt;/p&gt;
&lt;p&gt;D、 T 和 R 子字段表示数据报在延时、吞吐量和可靠性方面得到良好的处理。相应值为 1 表示更好的处理（分别为低延时、高吞吐量和高可靠性）。优先级取值范围是从 000 （常规）到 111 （网络控制），表示优先级依次递增（见表 5-1）。它们都基于一个称为**多级优先与抢占（MLPP）**的方案，该方案可追溯到美国国防部的 AUTOVON 电话系统 [&lt;a href=&#34;#A92&#34;&gt;A92&lt;/a&gt;]，其中较低优先级的呼叫可被更高优先级的呼叫抢占。这些术语仍在使用，并被纳入 VoIP 系统中。&lt;/p&gt;
&lt;center&gt; 表 5-1    原来的 IPv4 服务类型和 IPv6 流量类别 的优先级子字段值 &lt;/center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;值&lt;/th&gt;
&lt;th&gt;优先级名称&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;000&lt;/td&gt;
&lt;td&gt;常规&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;001&lt;/td&gt;
&lt;td&gt;优先级&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;010&lt;/td&gt;
&lt;td&gt;立即&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;011&lt;/td&gt;
&lt;td&gt;瞬间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;td&gt;瞬间覆盖&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;101&lt;/td&gt;
&lt;td&gt;严重&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;110&lt;/td&gt;
&lt;td&gt;网间控制&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;111&lt;/td&gt;
&lt;td&gt;网络控制&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;在定义 &lt;strong&gt;DS 字段&lt;/strong&gt;时，优先级的值已定义在 [&lt;a href=&#34;#RFC2474&#34;&gt;RFC2474&lt;/a&gt;] 中，以提供有限的兼容性。在图 5-5 中， 6 位 &lt;strong&gt;DS 字段&lt;/strong&gt;用于保存 DSCP，提供对 64 个代码点的支持。特定 DSCP 值可通知路由器对接收的数据报进行转发或特殊处理。不同类型的转发处理表示为&lt;strong&gt;每跳行为（PHB）&lt;/strong&gt;，因此 DSCP 值可有效通知路由器哪种 PHB 被应用于数据报。 DSCP 的默认值通常为 0，对应于常规的尽力而为的 Internet 流量。 64 个可能的 DSCP 值分为不同用途，它们可从 [&lt;a href=&#34;#DSCPREG&#34;&gt;DSCPREG&lt;/a&gt;] 中获得，如表 5-2 所示。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1653568463910.png&#34; alt=&#34;图 5-5&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 5-5    &lt;strong&gt;DS 字段&lt;/strong&gt;包含 6 位（其中 5 位当前是标准的，表示当前接收的数据报应转发时，可由一台兼容的路由器转发）。后面 2 位用作 ECN，当数据报通过持续拥塞的路由器时设置。当这些数据报到达目的地时，稍后发送一个包含拥塞指示的数据报给发送方，通知该数据报经过一台或多台拥塞的路由器&lt;/p&gt;
&lt;center&gt; 表 5-2    DSCP 值被分成 3 个池：标准的、实验/本地用途的（EXP/LU）和最终打算标准化的实验/本地用途的（*） &lt;/center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;池&lt;/th&gt;
&lt;th&gt;代码店前缀&lt;/th&gt;
&lt;th&gt;策略&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;xxxxx0&lt;/td&gt;
&lt;td&gt;标准的&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;xxxx11&lt;/td&gt;
&lt;td&gt;EXP/LU&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;xxxx01&lt;/td&gt;
&lt;td&gt;EXP/LU（*）&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;这个方案供研究人员和操作人员用于实验或本地用途。以 0 作为结尾的 DSCP 用于标准用途，以 1 作为结尾的 DSCP 用于实验或本地用途。以 01 作为结尾的 DSCP 最初打算用于实验或本地用途，但最终会走向标准化。&lt;/p&gt;
&lt;p&gt;在图 5-5 中， &lt;strong&gt;DS 字段&lt;/strong&gt;中的类别部分包含前 3 位，并基于较早定义的&lt;strong&gt;服务类型&lt;/strong&gt;的优先级子字段。路由器通常先将流量分为不同类别。常见类别的流量可能有不同的丢弃概率，如果路由器被迫丢弃流量，允许路由器确定首先丢弃哪些流量。 3 位的类别选择器提供了 8 个定义的代码点（称为&lt;strong&gt;类别选择代码点&lt;/strong&gt;），它们对应于一个指定最小功能集的 PHB，提供与早期的 IP 优先级相似的功能。它们称为&lt;strong&gt;类别选择兼容的 PHB&lt;/strong&gt;，目的是支持部分兼容的最初定义的 IP 优先级子字段 [&lt;a href=&#34;#RFC0791&#34;&gt;RFC0791&lt;/a&gt;] 。 &lt;code&gt;xxx000&lt;/code&gt; 形式的代码点总被映射为这种 PHB，但是其他值也可映射到相同 PHB。&lt;/p&gt;
&lt;p&gt;表 5-3 给出了类别选择器的 DSCP 值，以及 [&lt;a href=&#34;#RFC0791&#34;&gt;RFC0791&lt;/a&gt;] 定义的 IP 优先级字段的相应术语。&lt;strong&gt;保证转发（AF）&lt;strong&gt;组对固定数量的独立 AF 类别的 IP 分组提供转发，它有效地概括了优先级的概念。某个类别的流量与其他类别的流量分别转发。在一个流量类别中，数据报被分配一个&lt;/strong&gt;丢弃优先级&lt;/strong&gt;。在一个类别中，较高丢弃优先级的数据报优先于那些较低丢弃优先级的数据报处理（即以较高优先级转发）。结合流量类别和丢弃优先级，名称 AFij 对应于保证转发类别 i 的丢弃优先级 j。例如，一个标记为 AF32 的数据报的流量类别为 3，丢弃优先级为 2。&lt;/p&gt;
&lt;center&gt;表 5-3 DS 字段值设计为兼容服务类型和 IPv6 流量类别字段中指定的 IP 优先级字段。 AF 和 EF 提供比简单的“尽力而为”更好的服务&lt;/center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;名称&lt;/th&gt;
&lt;th&gt;值&lt;/th&gt;
&lt;th&gt;参考文献&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;CS0&lt;/td&gt;
&lt;td&gt;000000&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2474&#34;&gt;RFC2474&lt;/a&gt;]&lt;/td&gt;
&lt;td&gt;类别选择（尽力而为/常规）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CS1&lt;/td&gt;
&lt;td&gt;001000&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2474&#34;&gt;RFC2474&lt;/a&gt;]&lt;/td&gt;
&lt;td&gt;类别选择（优先）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CS2&lt;/td&gt;
&lt;td&gt;010000&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2474&#34;&gt;RFC2474&lt;/a&gt;]&lt;/td&gt;
&lt;td&gt;类别选择（立即）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CS3&lt;/td&gt;
&lt;td&gt;011000&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2474&#34;&gt;RFC2474&lt;/a&gt;]&lt;/td&gt;
&lt;td&gt;类别选择（瞬间）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CS4&lt;/td&gt;
&lt;td&gt;100000&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2474&#34;&gt;RFC2474&lt;/a&gt;]&lt;/td&gt;
&lt;td&gt;类别选择（瞬间覆盖）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CS5&lt;/td&gt;
&lt;td&gt;101000&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2474&#34;&gt;RFC2474&lt;/a&gt;]&lt;/td&gt;
&lt;td&gt;类别选择（CRITIC/ECP）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CS6&lt;/td&gt;
&lt;td&gt;110000&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2474&#34;&gt;RFC2474&lt;/a&gt;]&lt;/td&gt;
&lt;td&gt;类别选择（网间控制）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CS7&lt;/td&gt;
&lt;td&gt;111000&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2474&#34;&gt;RFC2474&lt;/a&gt;]&lt;/td&gt;
&lt;td&gt;类别选择（控制）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AF11&lt;/td&gt;
&lt;td&gt;001010&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2597&#34;&gt;RFC2597&lt;/a&gt;]&lt;/td&gt;
&lt;td&gt;保证转发（1，1）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AF12&lt;/td&gt;
&lt;td&gt;001100&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2597&#34;&gt;RFC2597&lt;/a&gt;]&lt;/td&gt;
&lt;td&gt;保证转发（1，2）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AF13&lt;/td&gt;
&lt;td&gt;001110&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2597&#34;&gt;RFC2597&lt;/a&gt;]&lt;/td&gt;
&lt;td&gt;保证转发（1，3）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AF21&lt;/td&gt;
&lt;td&gt;010010&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2597&#34;&gt;RFC2597&lt;/a&gt;]&lt;/td&gt;
&lt;td&gt;保证转发（2，1）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AF22&lt;/td&gt;
&lt;td&gt;010100&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2597&#34;&gt;RFC2597&lt;/a&gt;]&lt;/td&gt;
&lt;td&gt;保证转发（2，2）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AF23&lt;/td&gt;
&lt;td&gt;010110&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2597&#34;&gt;RFC2597&lt;/a&gt;]&lt;/td&gt;
&lt;td&gt;保证转发（2，3）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AF31&lt;/td&gt;
&lt;td&gt;011010&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2597&#34;&gt;RFC2597&lt;/a&gt;]&lt;/td&gt;
&lt;td&gt;保证转发（3，1）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AF32&lt;/td&gt;
&lt;td&gt;011100&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2597&#34;&gt;RFC2597&lt;/a&gt;]&lt;/td&gt;
&lt;td&gt;保证转发（3，2）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AF33&lt;/td&gt;
&lt;td&gt;011110&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2597&#34;&gt;RFC2597&lt;/a&gt;]&lt;/td&gt;
&lt;td&gt;保证转发（3，3）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AF41&lt;/td&gt;
&lt;td&gt;100010&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2597&#34;&gt;RFC2597&lt;/a&gt;]&lt;/td&gt;
&lt;td&gt;保证转发（4，1）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AF42&lt;/td&gt;
&lt;td&gt;100100&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2597&#34;&gt;RFC2597&lt;/a&gt;]&lt;/td&gt;
&lt;td&gt;保证转发（4，2）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AF43&lt;/td&gt;
&lt;td&gt;100110&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2597&#34;&gt;RFC2597&lt;/a&gt;]&lt;/td&gt;
&lt;td&gt;保证转发（4，3）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;EF PHB&lt;/td&gt;
&lt;td&gt;101110&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC3246&#34;&gt;RFC3246&lt;/a&gt;]&lt;/td&gt;
&lt;td&gt;加速转发&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;VOICE-ADMIT&lt;/td&gt;
&lt;td&gt;101100&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC5865&#34;&gt;RFC5865&lt;/a&gt;]&lt;/td&gt;
&lt;td&gt;容量许可的流量&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;**加速转发（EF）**提供了非拥塞的网络服务，也就是说， EF 流量应享受较低的延时、抖动和丢包率。直观地说， EF 流量要求路由器的输出速率至少比输入速率大。因此，在一台路由器的队列中， EF 流量仅排在其他 EF 流量之后。&lt;/p&gt;
&lt;p&gt;为了在 Internet 中提供差异化服务，目前已持续进行十多年的努力。虽然大部分机制的标准化开始于 20 世纪 90 年代末，但其中有些功能直到 21 世纪才被实现。 [&lt;a href=&#34;#RFC4594&#34;&gt;RFC4594&lt;/a&gt;] 给出了一些关于如何配置系统以利用该功能的指导。差异化服务的复杂性在于：差异化服务和假设的差异化定价结构之间的联系，以及由此产生的公平问题。这种经济关系是复杂的，并且不在我们讨论的范围内。关于这个问题和相关主题的更多信息，详见 [&lt;a href=&#34;#MB97&#34;&gt;MB97&lt;/a&gt;] 和 [&lt;a href=&#34;#W03&#34;&gt;W03&lt;/a&gt;] 。&lt;/p&gt;
&lt;h3 id=&#34;524-ip-选项&#34;&gt;5.2.4 IP 选项&lt;/h3&gt;
&lt;p&gt;IP 支持一些可供数据报选择的选项。 [&lt;a href=&#34;#RFC0791&#34;&gt;RFC0791&lt;/a&gt;] 介绍了大多数的选项，当时处于 IPv4 设计阶段， Internet 的规模相当小，对来自恶意用户的威胁关注较少。由于 IPv4 头部大小的限制以及相关的安全问题，因此很多选项不再是实用或可取的。在 IPv6 中，大部分选项已被删除或改变，不再是 IPv6 基本头部的一部分，而被放在 IPv6 头部之后的一个或多个扩展头部中。 IP 路由器接收到一个包含选项的数据报，通常需要对该数据报进行特殊处理。在某些情况下，尽管 IPv6 路由器可以处理扩展头部，但很多头部被设计为仅由终端主机处理。在有些路由器中，带选项或扩展的数据报不会像普通数据报那样被快速转发。作为相关的背景知识，我们简要讨论 IPv4 选项，以及 IPv6 如何实现扩展头部和选项。表 5-4 显示了经过多年标准化的 IPv4 选项。&lt;/p&gt;
&lt;p&gt;表 5-4 给出了保留的 IPv4 选项，它们可在描述性的 RFC 中找到。这个完整的列表会定期更新，并可在 [&lt;a href=&#34;#IPPARAM&#34;&gt;IPPARAM&lt;/a&gt;] 中在线查看。选项的范围总是以 32 位为界。如果有必要，数值 0 作为填充字节被添加。这确保 IPv4 头部始终是 32 位的倍数（IHL 字段的要求）。表 5-4 中的“编号”列是选项编号。 “值”列给出了放在&lt;strong&gt;类型&lt;/strong&gt;字段中的编号，以表示该选项的存在。由于&lt;strong&gt;类型&lt;/strong&gt;字段有另外的结构，所以这两列中的相应值不必相同。特别指出的是，第 1 （高序）位表示如果相关数据报被分片，该选项是否被复制到分片中。后面 2 位表示该选项的类别。目前，除了“时间戳”和“跟踪”使用类别 2 （调试和测量）外，表 5-4 中的所有选项使用类别 0 （控制）。类别 1 和 3 被保留。&lt;/p&gt;
&lt;center&gt;表 5-4    如果选项存在，它在 IPv4 分组中紧跟在基本 IPv4 头部之后。选项由一个 8 位的类型字段标识。这个字段被细分为 3 个子字段：复制（1 位）、类别（2 位）和编号（5 位）。选项 0 和 1 的长度是 1 字节，多数的其他选项长度可变。可变选项包括 1 字节的类型标识符、1 字节的长度以及选项自身&lt;/center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;名称&lt;/th&gt;
&lt;th&gt;编号&lt;/th&gt;
&lt;th&gt;值&lt;/th&gt;
&lt;th&gt;长度&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;th&gt;参考文献&lt;/th&gt;
&lt;th&gt;注释&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;列表结尾&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;表示没有更多选项&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC0791&#34;&gt;RFC0791&lt;/a&gt;]&lt;/td&gt;
&lt;td&gt;如果需要&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;没有操作&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;表示没有操作执行（用于填充）&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC0791&#34;&gt;RFC0791&lt;/a&gt;]&lt;/td&gt;
&lt;td&gt;如果需要&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;源路由&lt;/td&gt;
&lt;td&gt;3 &lt;br/&gt;9&lt;/td&gt;
&lt;td&gt;131 &lt;br/&gt;137&lt;/td&gt;
&lt;td&gt;可变&lt;/td&gt;
&lt;td&gt;发送方列出分组转发时遍历的路由器“航点”。松散意味着其他路由器可以包含在航点（3，131）中。严格意味着（9，137）中的所有航点都有按顺序遍历&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC1108&#34;&gt;RFC1108&lt;/a&gt;]&lt;/td&gt;
&lt;td&gt;很少，经常被过滤&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;安全和处理标签&lt;/td&gt;
&lt;td&gt;2 &lt;br/&gt;5&lt;/td&gt;
&lt;td&gt;130 &lt;br/&gt;133&lt;/td&gt;
&lt;td&gt;11&lt;/td&gt;
&lt;td&gt;在美国军事环境下如何为 IP 数据包指定安全标签和处理闲置&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC0791&#34;&gt;RFC0791&lt;/a&gt;]&lt;/td&gt;
&lt;td&gt;很少&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;记录路由&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;可变&lt;/td&gt;
&lt;td&gt;在分组的头部中记录经过的路由器&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC0791&#34;&gt;RFC0791&lt;/a&gt;]&lt;/td&gt;
&lt;td&gt;很少&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;时间戳&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;68&lt;/td&gt;
&lt;td&gt;可变&lt;/td&gt;
&lt;td&gt;在分组的源和目的地记录日期和时间&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC0791&#34;&gt;RFC0791&lt;/a&gt;]&lt;/td&gt;
&lt;td&gt;很少&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;流 ID&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;136&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;携带 16 位的 SATNET 流标识符&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC0791&#34;&gt;RFC0791&lt;/a&gt;]&lt;/td&gt;
&lt;td&gt;历史的&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;EIP&lt;/td&gt;
&lt;td&gt;17&lt;/td&gt;
&lt;td&gt;145&lt;/td&gt;
&lt;td&gt;可变&lt;/td&gt;
&lt;td&gt;扩展 Internet 协议（20 世纪 90 年代早期的一个实验）&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC1385&#34;&gt;RFC1385&lt;/a&gt;]&lt;/td&gt;
&lt;td&gt;历史的&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;跟踪&lt;/td&gt;
&lt;td&gt;18&lt;/td&gt;
&lt;td&gt;82&lt;/td&gt;
&lt;td&gt;可变&lt;/td&gt;
&lt;td&gt;增加一个路由跟踪选项和 ICMP 报文（20 世纪 90 年代早期的一个实验）&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC1393&#34;&gt;RFC1393&lt;/a&gt;]&lt;/td&gt;
&lt;td&gt;历史的&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;路由器警告&lt;/td&gt;
&lt;td&gt;20&lt;/td&gt;
&lt;td&gt;148&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;表示一个路由器需要解释数据报的内容&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2113&#34;&gt;RFC2113&lt;/a&gt;] [&lt;a href=&#34;#RFC5350&#34;&gt;RFC5350&lt;/a&gt;]&lt;/td&gt;
&lt;td&gt;偶然&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;快速启动&lt;/td&gt;
&lt;td&gt;25&lt;/td&gt;
&lt;td&gt;25&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;表示启动快速传输协议（实验性的）&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC4782&#34;&gt;RFC4782&lt;/a&gt;]&lt;/td&gt;
&lt;td&gt;很少&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;目前，多数标准化选项在 Internet 中很少或从未使用。例如，源路由和记录路由选项需要将 IPv4 地址放在 IPv4 头部中。由于头部（总计 60 字节，其中 20 字节是基本 IPv4 头部）空间有限，这些选项在当前基于 IPv4 的 Internet 中用处不大，其中一条 Internet 路径的平均路由器跳步数约为 15 [&lt;a href=&#34;#LFS07&#34;&gt;LFS07&lt;/a&gt;]。另外，这些选项主要用于诊断目的，它们为防火墙的构建带来麻烦和风险。因此， IPv4 选项通常在企业网络边界处被防火墙拒绝或剥离（见第 7 章）。&lt;/p&gt;
&lt;p&gt;在企业网络内部，路径的平均长度更小，对恶意用户的防护可能考虑得更少，这些选项仍然可以使用。另外，&lt;strong&gt;路由器警告&lt;/strong&gt;选项提示可能由于在 Internet 上使用其他选项而有异常问题。由于它的设计目标主要是优化性能，并不会改变路由器的基本行为，所以该选项通常比其他选项更常用。正如前面所提到的，有些路由器会实现高度优化的内部路径，用于那些不包含选项的 IP 流量转发。路由器警告选项用于通知路由器，一个分组需使用超出常规的转发算法来处理。在表 5-4 的结尾处，实验性的“快速启动”选项适用于 IPv4 和 IPv6 ，我们将在下一节讨论 IPv6 扩展头部和选项时介绍它。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;53-ipv6-扩展头部&#34;&gt;5.3 IPv6 扩展头部&lt;/h2&gt;
&lt;p&gt;在 IPv6 中，那些由 IPv4 选项提供的特殊功能，通过在 IPv6 头部之后增加扩展头部实现。IPv4 路由和时间戳功能都采用这种方式，其他功能（例如分片和超大分组）很少在 IPv6 中使用（但仍需要），因此没有为它们在 IPv6 头部分配相应的位。基于这种设计， IPv6 头部固定为 40 字节，扩展头部仅在需要时添加。在选择 IPv6 头部为固定大小时，要求扩展头部仅由终端主机（仅有一个例外）处理， IPv6 设计者简化了高性能路由器的设计和实现，这是因为 IPv6 路由器处理分组所需的命令比 IPv4 简单。实际上，分组处理性能受很多因素影响，包括协议复杂性、路由器硬件和软件功能，以及流量负载等。&lt;/p&gt;
&lt;p&gt;扩展头部和更高层协议（例如 TCP 或 UDP）头部与 IPv6 头部链接起来构成级联的头部（见图 5-6）。每个头部中的下一个头部字段表示紧跟着的头部的类型，它可能是一个 IPv6 扩展头部或其他类型。值 59 表示这个头部链的结尾。下一个头部字段的可能值定义在 [&lt;a href=&#34;#IP6PARAM&#34;&gt;IP6PARAM&lt;/a&gt;] 中，并在表 5-5 中列出了其中的大多数。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1653631363785.png&#34; alt=&#34;图 5-6&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 5-6    IPv6 头部使用下一个头部字段形成一个链。链中的头部可以是 IPv6 扩展头部或传输层头部。 IPv6 头部出现在数据报的开头，并且长度始终为 40 字节&lt;/p&gt;
&lt;center&gt;表 5-5    IPv6 下一个头部字段值可能表示扩展头部或其他协议头部。在适当情况下，它与 IPv4 协议字段使用相同值&lt;/center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;头部类型&lt;/th&gt;
&lt;th&gt;顺序&lt;/th&gt;
&lt;th&gt;值&lt;/th&gt;
&lt;th&gt;参考文献&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;IPv6 头部&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;41&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2460&#34;&gt;RFC2460&lt;/a&gt;] [&lt;a href=&#34;#RFC2473&#34;&gt;RFC2473&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;逐跳选项（HOPOPT）&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2460&#34;&gt;RFC2460&lt;/a&gt;]，紧跟在 IPv6 头部之后&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;目的地选项&lt;/td&gt;
&lt;td&gt;3，8&lt;/td&gt;
&lt;td&gt;60&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2460&#34;&gt;RFC2460&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;路由&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;43&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2460&#34;&gt;RFC2460&lt;/a&gt;] [&lt;a href=&#34;#RFC5095&#34;&gt;RFC5095&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;分片&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;44&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2460&#34;&gt;RFC2460&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;封装安全载荷（ESP）&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;50&lt;/td&gt;
&lt;td&gt;（见第 18 章）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;认证（AH）&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;51&lt;/td&gt;
&lt;td&gt;（见第 18 章）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;移动（MIPv6）&lt;/td&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;135&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC6275&#34;&gt;RFC6275&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;（无——没有下一个头部）&lt;/td&gt;
&lt;td&gt;最后&lt;/td&gt;
&lt;td&gt;59&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2460&#34;&gt;RFC2460&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ICMPv6&lt;/td&gt;
&lt;td&gt;最后&lt;/td&gt;
&lt;td&gt;58&lt;/td&gt;
&lt;td&gt;（见第 8 章）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;UDP&lt;/td&gt;
&lt;td&gt;最后&lt;/td&gt;
&lt;td&gt;17&lt;/td&gt;
&lt;td&gt;（见第 10 章）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;TCP&lt;/td&gt;
&lt;td&gt;最后&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;（见第 13 ~ 17 章）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;各种其他高层协议&lt;/td&gt;
&lt;td&gt;最后&lt;/td&gt;
&lt;td&gt;——&lt;/td&gt;
&lt;td&gt;见 [&lt;a href=&#34;#AN&#34;&gt;AN&lt;/a&gt;] 中的完整列表&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;我们从表 5-5 中可以看到， IPv6 扩展头部机制将一些功能（例如路由和分片）与选项加以区分。除了“逐跳选项”的位置之外（它是强制性的），扩展头部的顺序是建议性的，因此一个 IPv6 实现必须按接收的顺序处理扩展头部。只有“目的地选项”头部可以使用两次，第一次是指出包含在 IPv6 头部中的目的 IPv6 地址，第二次（位置 8）是关于数据报的最终目的地。在某些情况下（例如使用路由头部），当数据报被转发到最终目的地时， IPv6 头部中的&lt;strong&gt;目的 IP 地址&lt;/strong&gt;字段将会改变。&lt;/p&gt;
&lt;h3 id=&#34;531-ipv6-选项&#34;&gt;5.3.1 IPv6 选项&lt;/h3&gt;
&lt;p&gt;我们已经看到，相对于 IPv4， IPv6 提供了一种更灵活和可扩展的方式，将扩展和选项相结合。由于 IPv4 头部空间的限制，那些来自 IPv4 的选项已停止使用，而 IPv6 可变长度的扩展头部或编码在特殊扩展头部中的选项可适应当前更大的 Internet。如果选项存在，可放入&lt;strong&gt;逐跳选项&lt;/strong&gt;（与一个数据报传输路径上的每个路由器相关）或&lt;strong&gt;目的地选项&lt;/strong&gt;（仅与接收方相关）。逐跳选项（称为HOPOPT）是唯一由分组经过的每个路由器处理的选项。逐跳选项和目的地选项的编码格式一样。&lt;/p&gt;
&lt;p&gt;逐跳选项和目的地选项头部的出现可以超过一次。这些选项均被编码为 &lt;strong&gt;类型 - 长度 - 值（TLV）&lt;/strong&gt; 集合，对应于 图5-7 中所示格式。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1653638926599.png&#34; alt=&#34;图 5-7&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 5-7    逐跳选项和目的地选项编码为 TLV 集合。第一字节给出了选项类型，包括一些子字段，在选项没被识别时指示一个 IPv6 节点如何动作，以及在数据报转发时选项数据是否改变。&lt;strong&gt;选项数据长度&lt;/strong&gt;字段给出了选项数据的字节长度&lt;/p&gt;
&lt;p&gt;TLV 结构如图 5-7 所示，它的长度为 2 字节，后面是可变长度的数据字节。第一字节表示选项类型，其中包括 3 个子字段。当 5 位的&lt;strong&gt;类型子字段&lt;/strong&gt;无法由选项识别时，第一个子字段给出了一个 IPv6 节点尝试执行的动作。表 5-6 显示了所有可能的值。&lt;/p&gt;
&lt;center&gt;表 5-6    一个 IPv6 的 TLV 选项类型的 2 个高序位，表示如果这个选项没有被识别，一个 IPv6 节点是转发还是丢弃该数据报，以及是否向发送方返回一个消息，提示这个数据报的处理结果&lt;/center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;值&lt;/th&gt;
&lt;th&gt;动作&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;00&lt;/td&gt;
&lt;td&gt;跳过选项，继续处理&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;01&lt;/td&gt;
&lt;td&gt;丢弃这个数据报（沉默）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;丢弃这个数据报，并向原地址发送一个“ICMPv6 参数问题”消息&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;11&lt;/td&gt;
&lt;td&gt;与 10 相同，但仅在分组的目的地不是组播时，发送这个 ICMPv6 消息&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;如果一个发往组播目的地的数据报中包括一个未知选项，那么大量节点将生成返回源节点的流量。这可通过将&lt;strong&gt;动作子字段&lt;/strong&gt;设置为 11 来避免。&lt;strong&gt;动作子字段&lt;/strong&gt;的灵活性在开发新的选项时是有用的。一个新的选项可携带在一个数据报中，并被那些无法理解它的路由器所忽略，这样有助于促进新选项的增量部署。当选项数据可能在数据报转发过程改变时，&lt;strong&gt;改变&lt;/strong&gt;位字段（图 5-7 中的 Chg）设置为 1。表 5-7 中所示的选项已被 IPv6 定义。&lt;/p&gt;
&lt;center&gt;表 5-7    IPv6 选项携带在逐跳（H）选项或目的地（D）选项扩展头部中。选项类型字段包含来自“类型”列以及动作和改变子字段中的二进制值。“长度”列包含来自图 5-7 的选项数据长度字节中的值。填充 1 是唯一没有该字节的选项&lt;/center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;选项名&lt;/th&gt;
&lt;th&gt;头部&lt;/th&gt;
&lt;th&gt;动作&lt;/th&gt;
&lt;th&gt;改变&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;长度&lt;/th&gt;
&lt;th&gt;参考文献&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;填充 1&lt;/td&gt;
&lt;td&gt;HD&lt;/td&gt;
&lt;td&gt;00&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2460&#34;&gt;RFC2460&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;填充 N&lt;/td&gt;
&lt;td&gt;HD&lt;/td&gt;
&lt;td&gt;00&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;可变&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2460&#34;&gt;RFC2460&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;超大有效载荷&lt;/td&gt;
&lt;td&gt;H&lt;/td&gt;
&lt;td&gt;11&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;194&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2675&#34;&gt;RFC2675&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;隧道封装限制&lt;/td&gt;
&lt;td&gt;D&lt;/td&gt;
&lt;td&gt;00&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2473&#34;&gt;RFC2473&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;路由器警告&lt;/td&gt;
&lt;td&gt;H&lt;/td&gt;
&lt;td&gt;00&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2711&#34;&gt;RFC2711&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;快速启动&lt;/td&gt;
&lt;td&gt;H&lt;/td&gt;
&lt;td&gt;00&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC4782&#34;&gt;RFC4782&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CALIPSO&lt;/td&gt;
&lt;td&gt;H&lt;/td&gt;
&lt;td&gt;00&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;8+&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC5570&#34;&gt;RFC5570&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;家乡地址&lt;/td&gt;
&lt;td&gt;D&lt;/td&gt;
&lt;td&gt;11&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;201&lt;/td&gt;
&lt;td&gt;16&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC6275&#34;&gt;RFC6275&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;5311-填充-1-和填充-n&#34;&gt;5.3.1.1 填充 1 和填充 N&lt;/h4&gt;
&lt;p&gt;由于 IPv6 选项需要与 8 字节的偏移量对齐，因此较小的选项用 0 填充到长度为 8 字节。这里有两个填充选项，分别称为填充 1 和填充 N。填充 1 选项（类型 0）是唯一缺少&lt;strong&gt;长度&lt;/strong&gt;字段和&lt;strong&gt;值&lt;/strong&gt;字段的选项。它仅有 1 字节长，取值为 0。填充 N 选项（类型 1）向头部的选项区域填充 2 字节或更多字节，它使用图 5-7 所示格式。对于″个填充字节，&lt;strong&gt;选项数据长度&lt;/strong&gt;字段包含的值为（n - 2）。&lt;/p&gt;
&lt;h4 id=&#34;5312-ipv6-超大有效载荷&#34;&gt;5.3.1.2 IPv6 超大有效载荷&lt;/h4&gt;
&lt;p&gt;在某些 TCP/IP 网络中，例如那些用于互连超级计算机的网络，由于正常的 64KB 的 IP 数据报大小限制，在传输大量数据时会导致不必要的开销。 IPv6 超大有效载荷选项指定了一种有效载荷大于 65535 字节的 IPv6 数据报，称为&lt;strong&gt;超大报文&lt;/strong&gt;。这个选项无法由 MTU 小于 64KB 的链路连接的节点来实现。超大有效载荷选项提供了一个 32 位的字段，用于携带有效载荷在 65535 ~ 4294967295 字节之间的数据报。&lt;/p&gt;
&lt;p&gt;当一个用于传输的超大报文形成时，其正常&lt;strong&gt;负载长度&lt;/strong&gt;字段被设置为 0。我们将在后面看到， TCP 协议使用&lt;strong&gt;负载长度&lt;/strong&gt;字段，计算由前面所述的 Internet 校验和算法得到的校验和。当使用超大有效载荷选项时， TCP 必须使用来自选项的长度值，而不是基本头部中的长度字段值。虽然这个过程并不困难，但更大有效载荷使得未检测出错误的可能性增大 [&lt;a href=&#34;#RFC2675&#34;&gt;RFC2675&lt;/a&gt;]。&lt;/p&gt;
&lt;h4 id=&#34;5313-隧道封装限制&#34;&gt;5.3.1.3 隧道封装限制&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;隧道&lt;/strong&gt;是指将一个协议封装在另一个协议中（见第 1 章和第 3 章）。例如， IP 数据报可能被封装在另一个 IP 数据报的有效载荷部分。隧道可用于形成虚拟的覆盖网络，在覆盖网络中，一个网络（例如 Internet）可作为另一个 IP 的链路层使用 [&lt;a href=&#34;#TWEF03&#34;&gt;TWEF03&lt;/a&gt;]。隧道可以嵌套，从这个意义上来说，一条隧道中的数据报本身也可采用递归方式封装在另一条隧道中。&lt;/p&gt;
&lt;p&gt;在发送一个 IP 数据报时，发送者通常无法控制最终用于封装的隧道层次。发送者可使用这个选项设置一个限制。一台路由器打算将一个 IPv6 数据报封装在一条隧道中，它首先检查&lt;strong&gt;隧道封装限制&lt;/strong&gt;选项是否存在并置位。如果这个限制选项的值为 0，该数据报被丢弃，并将一个“ICMPv6 参数间题”消息（见第 8 章）发送到数据报源端（即之前的隧道入口点）。如果这个限制选项的值不为 0，该数据报可进行隧道封装，但新形成（封装）的 IPv6 数据报必须包括一个&lt;strong&gt;隧道封装限制&lt;/strong&gt;选项，其值比封装之前的数据报中的封装限制选项值减 1。实际上，封装限制行动类似于 IPv4 的 TTL 和 IPv6 的&lt;strong&gt;跳数限制&lt;/strong&gt;字段，只不过采用隧道封装层次代替转发跳步。&lt;/p&gt;
&lt;h4 id=&#34;5314-路由器警告&#34;&gt;5.3.1.4 路由器警告&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;路由器警告&lt;/strong&gt;选项指出数据报包含需要路由器处理的信息。它与 IPv4 的路由器警告选项的目的相同。 [&lt;a href=&#34;#RAOPTS&#34;&gt;RAOPTS&lt;/a&gt;] 给出了这个选项的当前设置值。&lt;/p&gt;
&lt;h4 id=&#34;5315-快速启动&#34;&gt;5.3.1.5 快速启动&lt;/h4&gt;
&lt;p&gt;**快速启动（QS）**选项和 [&lt;a href=&#34;#RFC4782&#34;&gt;RFC4782&lt;/a&gt;] 定义的 TCP/IP 实验性“快速启动”程序配合使用。它适用于 IPv4 和 IPv6，但目前建议仅用于专用网络，而不是全球性的 Internet。选项包括发送者需要的以比特/秒为单位的传输速率的编码值、 QS TTL 值和一些额外信息。如果沿途的路由器认为可以接受所需的速率，在这种情况下它们将递减 QS TTL，并在转发数据报时保持所需的速率不变。如果路由器不同意（即其支持的速率较低），它将该速率减小到一个可接受的速率。如果路由器不能识别 QS 选项，它将不递减 QS TTL。接收方将向发送方提供反馈，包括接收到的数据报的 IPv4 TTL 或 &lt;strong&gt;IPv6 跳数限制&lt;/strong&gt;字段和自己的 QS TTL 之间的差异，以及获得的速率可能被沿途的路由器所调整。这个信息被发送方用于确定发送速率（否则可能超出 TCP 使用的速率）。对 TTL 值进行比较的目的是确保沿途每台路由器参与 QS 谈判。如果发现任何路由器递减 IPv4 TTL （或 &lt;strong&gt;IPv6 跳数限制&lt;/strong&gt;）字段，但没有修改 QS TTL 值，则说明它没有启用 QS。&lt;/p&gt;
&lt;h4 id=&#34;5316-calipso&#34;&gt;5.3.16 CALIPSO&lt;/h4&gt;
&lt;p&gt;这个选项用于在某些专用网络中支持&lt;strong&gt;通用体系结构标签 IPv6 安全选项（CALIPSO）&lt;/strong&gt; [&lt;a href=&#34;#RFC5570&#34;&gt;RFC5570&lt;/a&gt;]。它提供了一种为数据报做标记的方法，包括一个安全级别标识符和一些额外的信息。需要注意的是，它用于多级安全网络环境（例如，政府、军队和银行），其中所有数据的安全级别必须以某种形式的标签注明。&lt;/p&gt;
&lt;h4 id=&#34;5317-家乡地址&#34;&gt;5.3.1.7 家乡地址&lt;/h4&gt;
&lt;p&gt;当使用 IPv6 移动选项时，这个选项保存发送数据报的 IPv6 节点的“家乡”地址。移动 IP （见 5.5 节）规定了 IP 节点的一系列处理过程，这些节点可能改变自已的网络接入点，同时不会断开自已的高层网络连接。这里存在一个节点的“家乡”的概念，它来自其典型位置的地址前缀。当远离家乡漫游时，通常为该节点分配一个不同的 IP 地址。该选项允许这个节点提供自己正常的家乡地址，以及它在漫游时的新地址（通常是临时分配）。当其他 IPv6 节点需要与移动节点通信时，它可以使用该节点的家乡地址。如果&lt;strong&gt;家乡地址&lt;/strong&gt;选项存在，包含它的&lt;strong&gt;目的地选项头部&lt;/strong&gt;必须出现在路由头部之后，并且在&lt;strong&gt;分片、认证&lt;/strong&gt;和 &lt;strong&gt;ESP 头部&lt;/strong&gt;（见第 18 章）之前（如果这些头部也存在）。我们将在移动 IP 中详细讨论这个选项。&lt;/p&gt;
&lt;h3 id=&#34;532-路由头部&#34;&gt;5.3.2 路由头部&lt;/h3&gt;
&lt;p&gt;IPv6 路由头部为发送方提供了一种 IPv6 数据报控制机制，以控制（至少部分控制）数据报通过网络的路径。目前，路由扩展头部有两个不同版本，分别称为类型 0 （RH0）和类型 2 （RH2）。 RH0 出于安全方面的考虑已被否决 [&lt;a href=&#34;#RFC5095&#34;&gt;RFC5095&lt;/a&gt;]， RH2 被定义为与移动 IP 共同使用。为了更好地理解路由头部，我们首先讨论 RH0，然后研究它为什么被放弃，以及它和 RH2 的不同之处。 RH0 规定了数据报转发时可“访问”的一个或多个 IPv6 节点。图 5-8 显示了这个头部。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1653651957371.png&#34; alt=&#34;图 5-8&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 5-8    目前已废弃的路由头部类型 0（RH0）涵盖了 IPv4 的宽松和严格的&lt;strong&gt;源路由&lt;/strong&gt;和&lt;strong&gt;记录路由&lt;/strong&gt;选项。它在数据报转发时由发送方构造，其中包括转发路径上的 IPv6 节点地址。每个地址可指定为一个宽松或严格的地址。一个严格的地址必须经过一个 IPv6 跳步到达，而一个松散的地址可能经过一个或多个其他跳步到达。在 IPv6 基本头部中，&lt;strong&gt;目的 IP 地址&lt;/strong&gt;字段修改为包含数据报转发的下一个转发地址&lt;/p&gt;
&lt;p&gt;图 5-8 所示的 IPv6 路由头部涵盖了来自 IPv4 的&lt;strong&gt;宽松源路由&lt;/strong&gt;和&lt;strong&gt;记录路由&lt;/strong&gt;选项。它还支持采用 IPv6 地址之外的其他标识符路由的可能性，这个功能是不规范的，这里没有进一步讨论。对于标准化的 IPv6 地址的路由， RH0 允许发送方指定一个指向目的地址的向量。&lt;/p&gt;
&lt;p&gt;这个头部包含一个 8 位的&lt;strong&gt;路由类型&lt;/strong&gt;标识符和一个 8 位的&lt;strong&gt;剩余部分&lt;/strong&gt;字段。对于 RH0， IPv6 地址类型标识符为 0 ；对于 RH2，该标识符为 2。&lt;strong&gt;剩余部分&lt;/strong&gt;字段指出还有多少段路由需要处理，也就是说，在到达最终目的地之前仍需访问的中间节点数。它是一个 32 位的从保留字段开始的地址块，由发送方设置为 0，并由接收方忽略。在数据报转发时，这些地址并非可访问的组播 IPv6 地址。&lt;/p&gt;
">《TCP/IP 详解 卷一：协议》第五章：Internet 协议</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://wenbozhangw.github.io/post/lesslesstcpip-xiang-jie-juan-yi-xie-yi-greatergreater-di-si-zhang-di-zhi-jie-xi-xie-yi/"" data-c="
          &lt;h2 id=&#34;41-引言&#34;&gt;4.1 引言&lt;/h2&gt;
&lt;p&gt;IP 协议的设计目标是为跨越不同类型物理网络的分组交换提供互操作。这需要网络层软件使用的地址和底层网络硬件使用的地址之间进行转换。网络接口硬件通常有一个主要的硬件地址（例如以太网或 802.11 无线接口的 48 位地址）。由硬件交换的帧需要使用正确的硬件地址定位到正确的接口；否则，无法传输数据。但是，一个传统 IPv4 网络需要使用自己的地址：32 位的 IPv4 地址。如果一台主机要将一个帧发送到另一台主机，仅知道这台主机的 IP 地址是不够的，还需要知道主机在网络中的有效硬件地址。操作系统软件（即以太网驱动程序）必须知道目的主机的硬件地址，以便直接向它发送数据。对于 TCP/IP 网络，&lt;strong&gt;地址解析协议（ARP）&lt;/strong&gt; [&lt;a href=&#34;#RFC0826&#34;&gt;RFC0826&lt;/a&gt;] 提供了一种在 IPv4 地址和各种网络技术使用的硬件地址之间的映射。 ARP 仅用于 IPv4， IPv6 使用邻居发现协议，它被合并入 ICMPv6 （见第 8 章）。&lt;/p&gt;
&lt;!-- more --&gt;
&lt;p&gt;这里需要注意的是，网络层地址和链路层地址是由不同部门分配的。对于网络硬件，主地址是由设备制造商定义的，并存储在设备的永久性内存中，所以它不会改变。因此，工作在特定硬件技术上的任意协议族，必须利用特定类型的地址。这允许不同协议族中的网络层协议&lt;strong&gt;同时运行&lt;/strong&gt;。另一方面，网络接口的 IP 地址是由用户或网络管理员分配的，并且可以接需选择。为便携设备分配的 IP 地址可能改变，例如设备移动时。 IP 地址通常从维护附近网络连接点的地址池中获得，它在系统启用或配置时分配（见第 6 章）。当两个局域网的主机之间传输的以太网帧包含 IP 数据报时，由 48 位以太网地址确定该帧的目的接口。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;地址解析&lt;/strong&gt;是发现两个地址之间的映射关系的过程。对于使用 IPv4 的 TCP/IP 协议族，这是由运行的 ARP 来实现的。 ARP 是一个通用的协议，从这个意义上来看，它被设计为支持多种地址之间的映射。实际上， ARP 几乎总是用于 32 位 IPv4 地址和以太网的 48 位 MAC 地址之间的映射。这种情况在 [&lt;a href=&#34;#RFC0826&#34;&gt;RFC0826&lt;/a&gt;] 中进行描述，它也是我们感兴趣的。在本章中，我们将互换使用以太网地址和 MAC 地址。&lt;/p&gt;
&lt;p&gt;ARP 提供从网络层地址到相关硬件地址的动态映射。我们使用动态这个术语是因为它会自动执行和随时间变化，而不需要系统管理员重新配置。也就是说，如果一台主机改变它的网络接口卡，从而改变了它的硬件地址（但保留其分配的 IP 地址）， ARP 可以在一定延时后继续正常运作。 ARP 操作通常与用户或系统管理员无关。&lt;/p&gt;
&lt;p&gt;注意    提供 ARP 反向映射的协议称为 RARP，它用于缺少磁盘驱动器（通常是无盘工作站或 X 终端）的系统。它在当前已很少使用，而且需要系统管理员手功配置。详情见 [&lt;a href=&#34;#RFC0903&#34;&gt;RFC0903&lt;/a&gt;] 。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;42-一个例子&#34;&gt;4.2 一个例子&lt;/h2&gt;
&lt;p&gt;当我们使用 Internet 服务时，例如在浏览器中打开一个网页，本地计算机必须确定如何与相关的服务器联系。它首先是判断该服务位于本地（同一 IP 子网的一部分）还是远程。如果是远程的，需要一台可到达目的地的路由器。仅在到达位于同一 IP 子网的系统时，ARP 才能工作。那么对于这个例子，我们假设使用 Web 浏览器打开以下网址：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;http://10.0.0.1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;注意，这个 URL 包含一个 IPv4 地址，而不是更常见的域名或主机名。这里使用地址的原因是要强调一个事实，例子中是共享相同 IPv4 前缀的相关系统（见第 2 章）。这里，我们使用包含地址的 URL，以确定一个本地的 Web 服务器，并探索 &lt;strong&gt;直接交付&lt;/strong&gt; 的运行原理。随着嵌入式设备（例如打印机和 VoIP 适配器）使用内置 Web 服务器进行配置，这种本地服务器越来越常见。&lt;/p&gt;
&lt;h3 id=&#34;421-直接交付和-arp&#34;&gt;4.2.1 直接交付和 ARP&lt;/h3&gt;
&lt;p&gt;在本节中，我们列出了直接交付的步骤，重点集中在 ARP 的运行上。直接交付发生在一个 IP 数据报被发送到一个 IP 地址，而该地址与发送方具有相同 IP 前缀的情况下。在 IP 数据报转发（见第 5 章）的常见方式中，它扮演着一个重要角色。下面用前面的例子列出 IPv4 直接交付的基本操作：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在这种情况下，应用程序是一个 Web 浏览器，调用一个特殊函数来解析 URL，看它是否包含主机名。这里不是，应用程序使用 32 位 IPv4 地址 &lt;code&gt;10.0.0.1&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;应用程序要求 TCP 协议建立一条到 &lt;code&gt;10.0.0.1&lt;/code&gt; 的连接。&lt;/li&gt;
&lt;li&gt;通过向 &lt;code&gt;10.0.0.1&lt;/code&gt; 发送一个 IPv4 数据报，TCP 尝试向远程主机发送一个连接请求（第 15 章将介绍细节）。&lt;/li&gt;
&lt;li&gt;我们假设地址 &lt;code&gt;10.0.0.1&lt;/code&gt; 使用与发送主机相同的网络前缀，数据报可被直接发送到这个地址而不经过任何路由器。&lt;/li&gt;
&lt;li&gt;假设以太网兼容地址被用于 IPv4 子网，发送主机必须将 32 位的 IPv4 目的地址转换为 48 位的以太网地址。使用 [&lt;a href=&#34;#RFC0826&#34;&gt;RFC0826&lt;/a&gt;] 的术语，就是需要从 &lt;strong&gt;逻辑 Internet&lt;/strong&gt; 地址向对应 &lt;strong&gt;物理&lt;/strong&gt; 硬件地址进行转换。这是 ARP 功能。ARP 工作在正常模式下，仅适用于 &lt;strong&gt;广播网络&lt;/strong&gt;，链路层能将一个消息交付到它连接的所有网络设备。这是 ARP 运行的一个重要要求。在非广播网络（有时被称为 &lt;strong&gt;非广播多路访问（NBMA）&lt;/strong&gt;）中，可能需要更复杂的映射协议 [&lt;a href=&#34;#RFC2332&#34;&gt;RFC2332&lt;/a&gt;] 。&lt;/li&gt;
&lt;li&gt;在一个共享的链路层网段上，ARP 向所有主机发送一个称为 &lt;strong&gt;ARP 请求&lt;/strong&gt; 的以太网帧。这被称为 &lt;strong&gt;链路层广播&lt;/strong&gt;。图 4-1 的斜线阴影中显示了一个&lt;strong&gt;广播域&lt;/strong&gt;。ARP 请求包含目的主机的 IPv4 地址（&lt;code&gt;10.0.0.1&lt;/code&gt;），并寻找以下问题的答案：“如果你将 IPv4 地址 &lt;code&gt;10.0.0.1&lt;/code&gt; 配置为自己的地址，请向我回应你的 MAC 地址。”&lt;/li&gt;
&lt;li&gt;通过 ARP，同一广播域中的所有系统可接收 ARP 请求。这包括可能根本不允许 IPv4 或 IPv6 协议的系统，但不包括位于不同 VLAN 中的系统，即使支持它们（VLAN 详细信息见第 3 章）。如果某个系统使用请求中指出的 IPv4 地址，它仅需要响应一个 &lt;strong&gt;ARP 应答&lt;/strong&gt;。这个应答包含 IPv4 地址（与请求相匹配）和对应的 MAC 地址。这个应答通常不是广播，而是仅直接发送给请求的发送方。同时，接收 ARP 请求的主机学习 IPv4 到 MAC 地址的映射，并记录在内存中供以后使用（见 4.3 节）。&lt;/li&gt;
&lt;li&gt;ARP 应答被原始请求的发送方接收，现在可发送引起这次 ARP 请求/应答交换过程的数据报。&lt;/li&gt;
&lt;li&gt;发送方可将数据报封装在以太网帧中直接发送到目的主机，并使用由 ARP 交换学到的以太网地址作为目的地址。由于这个以太网地址仅指向正确的目的主机，所有其他主机或路由器不会接收到这个数据报。因此，当仅使用直接交付时，并不需要经过路由器。&lt;/li&gt;
&lt;/ol&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1653399568330.png&#34; alt=&#34;图 4-1&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 4-1    以太网主机在同一广播域中。ARP 查询使用链路层广播帧发送，并被所有主机接收。 IP 地址匹配的主机直接向请求主机返回响应。 IP 地址不匹配的主机主动丢弃 ARP 查询&lt;/p&gt;
&lt;p&gt;ARP 用于运行 IPv4 的多接入链路层网络，每个主机都有自己首选的硬件地址。点到点链路（例如 PPP）不使用 ARP （见第 3 章）。当这些链路被建立后（通常是由用户或系统来发起创建），在链路两端通知正在使用的地址。由于不涉及硬件地址，因此不需要地址解析或 ARP。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;43-arp-缓存&#34;&gt;4.3 ARP 缓存&lt;/h2&gt;
&lt;p&gt;ARP 高效运行的关键是维护每个主机和路由器上的 &lt;strong&gt;ARP 缓存&lt;/strong&gt;（或表）。该缓存使用地址解析为每个接口维护从网络层地址到硬件地址的最新映射。当 IPv4 地址映射到硬件地址时，它对应于高速缓存中的一个条目，其正常到期时间是条目创建开始后的20分钟，这在 [&lt;a href=&#34;#RFC1122&#34;&gt;RFC1122&lt;/a&gt;] 中描述。&lt;/p&gt;
&lt;p&gt;我们可在 Linux 或 Windows 中使用 arp 命令查看 ARP 缓存。选项 -a 用于显示这两个系统的缓存中的所有条目。在 Linux 中，运行 arp 会产生以下输出：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Linux% arp
Address                  HWtype  HWaddress           Flags Mask            Iface
gw.home            ether   00:0D:66:4F:60:00   C                     eth0
printer.home              ether   00:0A:95:87:38:6A   C                     eth0
Linux% arp -a
printer.home (10.0.0.4) at 00:0A:95:87:38:6A [ether] on eth1
gw.home (10.0.0.1) at 00:0D:66:4F:60:00 [ether] on eth1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在 Windows 中，运行 arp 会产生以下类似的输出：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;c:\&amp;gt; arp -a
Interface: 10.0.0.56 --- 0x2
  Internet Address         Physical Address              Type
  10.0.0.1            00-0d-66-4f-60-00     dynamic
  10.0.0.4            00-0a-95-87-38-6a     dynamic
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里，我们看到的是 IPv4 到硬件地址的缓存。在第一个（Linux）例子中，每个映射是一个包含 5 个元素的条目：主机名（对应一个 IP 地址）、硬件地址类型、硬件地址、标志和本地网络接口（它对于这个映射是活跃的）。&lt;strong&gt;标志&lt;/strong&gt;列包含一个符号：C、 M 或 P。 C 类条目由 ARP 协议动态学习， M 类条目通过手工输入（arp -s ；见 4.9 节），而 P 类条目的含义是“发布”。也就是说，对于任何 P 类条目，主机对输入的 ARP 请求返回一个 ARP 应答。这个选项用于配置代理 ARP（见 4.7 节）。第二个 Linux 的例子显示了使用“BSD 风格”的类似信息。这里，给出了主机名和地址，对应的地址类型（[&lt;a href=&#34;#ether&#34;&gt;ether&lt;/a&gt;] 表示一个以太网类型的地址），以及映射活跃在哪个接口上。&lt;/p&gt;
&lt;p&gt;Windows 的 arp 程序显示了接口的 IPv4 地址，它的接口号是十六进制数（这里的 &lt;code&gt;0x2&lt;/code&gt;）。Windows 版本还指出地址是手动输入还是 ARP 学习。在这个例子中，两个条目都是动态的，这意味着它们来自 ARP 学习（如果通过手工输入，它们是静态的）。注意， 48 位 MAC 地址被显示为 6 个十六进制数，在 Linux 中使用冒号分隔，在 Windows 中使用短杠（dash）分隔。在传统上， UNIX 系统一直使用冒号，而 IEEE 标准和其他操作系统倾向于使用短杠。我们在 4.9 节中讨论 arp 命令的附加功能和其他选项。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;44-arp-帧格式&#34;&gt;4.4 ARP 帧格式&lt;/h2&gt;
&lt;p&gt;图 4-2 显示了在以太网中转换一个 IPv4 地址时常用的 ARP 请求和应答分组的格式（正如前面所说， ARP 通常也能用于 IPv4 以外的地址，虽然这是非常少见的）。前 14 字节构成标准的以太网头部，假设没有 802.1p/q 或其他标记，其余部分由 ARP 协议来定义。 ARP 帧的前 8 个字节是通用的，这个例子中的剩余部分专门用于将 IPv4 地址映射到 48 位的以太网地址。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1653401432482.png&#34; alt=&#34;图 4-2&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 4-2    IPv4 地址映射到 48 位的 MAC（以太网）地址时使用的 ARP 帧格式&lt;/p&gt;
&lt;p&gt;在图 4-2 所示的 ARP 帧的以太网头部中，前两个字段包含目的和源以太网地址。对于 ARP 请求，目的以太网地址 &lt;code&gt;ff:ff:ff:ff:ff:ff&lt;/code&gt; （全部为 1）是广播地址，在同一广播域中的所有以太网接口可接收这些帧。在以太网帧中，对于 ARP （请求或应答）， 2 字节的&lt;strong&gt;长度&lt;/strong&gt;或&lt;strong&gt;类型&lt;/strong&gt;字段必须为 &lt;code&gt;0x0806&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;长度/类型&lt;/strong&gt;字段之后的前 4 个字段指定了最后 4 个字段的类型和大小。这些值由 IANA [&lt;a href=&#34;#RFC5494&#34;&gt;RFC5494&lt;/a&gt;] 来指定。 术语&lt;strong&gt;硬件&lt;/strong&gt;和&lt;strong&gt;协议&lt;/strong&gt;用于描述 ARP 分组中的字段。例如，一个 ARP 请求询问协议地址（在这种情况下是 IPv4 地址）对应的硬件地址（在这种情况下是以太网地址）。这些术讳很少被用于 ARP 之外。相对来说，硬件地址的常见术语有 MAC、&lt;strong&gt;物理&lt;/strong&gt;或&lt;strong&gt;链路层地址&lt;/strong&gt;（或&lt;strong&gt;以太网&lt;/strong&gt;地址，当网络基于 IEEE 802.3/以太网的一系列规范时）。 &lt;strong&gt;硬件类型&lt;/strong&gt;字段指出硬件地址类型。 对于以太网，该值为 1。 &lt;strong&gt;协议类型&lt;/strong&gt;字段指出映射的协议地此类型。 对于 IPv4 地址，该值为 &lt;code&gt;0x0800&lt;/code&gt;。 当以太网帧包含 IPv4 数据报时，这可能与以太网帧的&lt;strong&gt;类型&lt;/strong&gt;字段值一致。对于下面两个 1 字节的字段，&lt;strong&gt;硬件大小&lt;/strong&gt;和&lt;strong&gt;协议大小&lt;/strong&gt;分别指出硬件地址和协议地址的字节数。对于以太网中使用 IPv4 地此的 ARP 请求或应答，它们的值分别为 6 和 4。 Op 字段指出该操作是 ARP 请求（值为 1）、 ARP 应答（2）、 RARP 请求（3）或 RARP应答（4）。由于 ARP 请求和 ARP 应答的&lt;strong&gt;长度/类型&lt;/strong&gt;字段相同，因此这个字段是必需的。&lt;/p&gt;
&lt;p&gt;紧跟在后面的 4 个字段是&lt;strong&gt;发送方硬件地址&lt;/strong&gt;（在这个例子中是以太网 MAC 地址）、&lt;strong&gt;发送方协议地址&lt;/strong&gt;（lPv4 地址）、&lt;strong&gt;目的硬件地址&lt;/strong&gt;（MAC/以太网地址）和&lt;strong&gt;目的协议地址&lt;/strong&gt;（IPv4 地址）。注意，这里存在一些重复的信息：以太网头部和 ARP 消息都包含发送方硬件地址。对于一个 ARP 请求，除了&lt;strong&gt;目的硬件地址&lt;/strong&gt;（设为 0）之外，其他字段都需要填充。当一个系统接收到一个 ARP 请求，它填充自己的硬件地址，将两个发送方地址和两个接收方地址互换，将 Op 字段设置为 2，然后发送生成的应答。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;45-arp-例子&#34;&gt;4.5 ARP 例子&lt;/h2&gt;
&lt;p&gt;在本节中，我们将使用 tcpdump 命令查看在执行一个正常 TCP/IP 应用（例如 Telnet）时运行 ARP 所实际发生的过程。Telnet 是一个简单的应用程序，可用于在两个系统之间建立一条 TCP/IP 连接。&lt;/p&gt;
&lt;h3 id=&#34;451-正常的例子&#34;&gt;4.5.1 正常的例子&lt;/h3&gt;
&lt;p&gt;为了查看 ARP 运行，我们将执行 telnet 命令，使用 TCP 端口 80 （称为 www）连接到主机 10.0.0.3 上的 Web 服务器。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;C:\&amp;gt; arp -a                    // 验证 arp 缓存为空
No ARP Entries Found
C:\&amp;gt; telnet 10.0.0.3 www                    // 连接到 Web 服务器 [端口80]
Connecting to 10.0.0.3...
Escape character is &#39;^]&#39;.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;按下 CTRL + 右括号键获得 Telnet 客户机的提示。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Welcome to Microsoft Telnet Client
Escape Character is &#39;CTRL+]&#39;
Microsoft Telnet&amp;gt; quit
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;指令 quit 用于退出程序。&lt;/p&gt;
&lt;p&gt;在这些命令执行的同时，我们在另一个系统上预习呢 tcpdump 命令，并观察交换的流量信息。使用 -e 选项可以显示 MAC 地址（这个例子中是 48 位以太网地址）。&lt;/p&gt;
&lt;p&gt;下面列出的内容包含来自 tcpdump 的输出。我们删除了输出的最后 4 行，它们用于终止连接（我们将在第 13 章中详细讨论），但与这里的讨论无关。注意，不同系统中的 tcpdump 版本提供的输出细节可能稍有不同。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Linux# tcpdump -e
1       0.0    0:0:c0:6f:2d:40    ff:ff:ff:ff:ff:ff    arp   60:
        arp    who-has    10.0.0.3    tell   10.0.0.56
2        0.002174    (0.0022)0:0:c0:c2:9b:26    0:0:c0:6f:2d:40    arp    60:
        arp    reply    10.0.0.3    is-at    0:0:c0:c2:9b:26

3       0.002831    (0.0007)0:0:c0:6f:2d:40    0:0:c0:c2:9b:26    ip    60:
        10.0.0.56.1030    &amp;gt;    10.0.0.3.www:    S    596459521:596459521(0)
        win    4096    &amp;lt;ms    1024&amp;gt;    [tos    0x10]
4       0.007834    (0.0050)0:0:c0:c2:9b:26    0:0:c0:6f:2d:40    ip    60:
        10.0.0.3.www    &amp;gt;    10.0.0.56.1030:    S    3562228225:3562228225(0)
        ack    596459522    win    4096    &amp;lt;mss    1024&amp;gt;
5       0.009615    (0.0018)0:0:c0:6f:2d:40    0:0:c0:c2:9b:26    ip    60:
        10.0.0.56.1030    &amp;gt;    10.0.0.3.discard:    .    ack    1    win    [tos    0x10]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在分组 1 中，源硬件地址为 &lt;code&gt;0:0:c0:6f:2d:40&lt;/code&gt;。 目的硬件地址为&lt;code&gt;ff:ff:ff:ff:ff:ff&lt;/code&gt;。 它是一个以太网广播地址。同一广播域（在同一局域网或 VLAN 中的所有主机，无论它们是否运行 TCP/IP）中的所有以太网接口接收并处理该帧，如图 4-1 所示。分组 1 的下一个输出字段为 arp，意味着帧类型字段为 &lt;code&gt;0x0806&lt;/code&gt;。表明它是 ARP 请求或 ARP 应答。在前 5 个分组中， arp 和 ip 后面打印的值 60 是以太网帧的长度。 ARP 请求或 ARP 应答的大小是 42 字节（ARP 消息为 28 字节，以太网头部为 14 字节）。每个帧均填充为最小以太网帧：60 字节数据和 4 字节 CRC （见第 3 章）。&lt;/p&gt;
&lt;p&gt;分组 1 的下一部分（即 arp who-has）用于标识该帧是 ARP 请求，目的地址是 IPv4 地址 &lt;code&gt;10.0.0.3&lt;/code&gt;，源地址是 IPv4 地址 &lt;code&gt;10.0.0.56&lt;/code&gt;。tcpdump 显示默认 IP 地址对应的主机名，但在这里没有显示（由于没有为它们建立反向 DNS 映射；第 11 章介绍 DNS 的细节）。接下来，我们使用 -n 选项查看 ARP 请求中的 IP 地址，无论它们是否进行 DNS 映射。&lt;/p&gt;
&lt;p&gt;我们从分组 2 中看到，虽然 ARP 请求是广播的，但 ARP 应答的目的地址是（单播）MAC 地址 &lt;code&gt;0:0:c0:6f:2d:40&lt;/code&gt;。因此，ARP 应答是直接发送到请求主机，它并不是通常的广播（在 4.8 节的一些情况下，这个规则可能会改变）。tcpdump 显示出该帧的 ARP 应答，以及响应者的 IPv4 地址和硬件地址。第 3 行是请求建立的第一个 TCP 段。其目的硬件地址属于目的主机（&lt;code&gt;10.0.0.3&lt;/code&gt;）。我们将在第 13 章涉及这部分的细节。&lt;/p&gt;
&lt;p&gt;对于每个分组，分组号后面的数字是 tcpdump 接收分组的相对时间（秒）。除第一个之外的每个分组都包含从前一段时间到现在的时间差（秒），该值放在括号中。我们可以看到发送 ARP 请求和接受 ARP 应答之间的时间约为 2.2ms。第一个 TCP 段在此后 0.7ms 发送。在这个例子中，ARP 动态地址解析的开销少于 3ms。注意，如果主机 10.0.0.3 的 ARP 表项在 10.0.0.56 的 ARP 缓存中是有效的，最初的 ARP 交换并不会发生，最初的 TCP 段可能已使用目的以太网地址立即发送。&lt;/p&gt;
&lt;p&gt;有关 tcpdump 输出的一个微妙问题是，在向 &lt;code&gt;10.0.0.56&lt;/code&gt; （第 4 行）发送自己的第一个 TCP 段之前，我们没看到来自 &lt;code&gt;10.0.0.3&lt;/code&gt; 的 ARP 请求。&lt;code&gt;10.0.0.3&lt;/code&gt; 在自己的 ARP 缓存中可能已有一个 &lt;code&gt;10.0.0.56&lt;/code&gt; 的条目，通常当系统接收到发送给它的 ARP 请求时，除了发送 ARP 应答外，它还会在 ARP 缓存中保存请求者的硬件地址和 IP 地址。这是一个基于逻辑假设的优化，如果请求者发送一个数据报，该数据报的接收者可能发送一个应答。&lt;/p&gt;
&lt;h3 id=&#34;452-对一个不存在的主机的-arp-请求&#34;&gt;4.5.2 对一个不存在的主机的 ARP 请求&lt;/h3&gt;
&lt;p&gt;如果 ARP 请求中指定的主机关闭或不存在，将会发生什么？为了查看这种情况，我们尝试访问一个不存在的本地 IPv4 地址，其前缀对应本地子网，但没有主机使用该地址。在这个例子中，我们使用 IPv4 地址  &lt;code&gt;10.0.0.99&lt;/code&gt;。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Linux% date ; telnet 10.0.0.99 ; date
Fri Jan 29 14:46:33 PST 2010
Trying 10.0.0.99...
telnet: connect to address 10.0.0.99: No route to host
Fri Jan 29 14:46:36 PST 2010               // 3s after previous date

Linux% arp -a
? (10.0.0.99) at &amp;lt;incomplete&amp;gt; on eth0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这是 tcpdump 的输出：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;1    21:12:07.440845 arp who-has 10.0.0.99 tell 10.0.0.56
2    21:12:08.436842 arp who-has 10.0.0.99 tell 10.0.0.56
3    21:12:09.436836 arp who-has 10.0.0.99 tell 10.0.0.56
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;由于我们已知使用广播地址发送 ARP 请求，因此本次并没有指定 -e 选项。 ARP 请求的频率接近每秒一次，这是 [&lt;a href=&#34;#RFC1122&#34;&gt;RFC1122&lt;/a&gt;] 建议的最大值。 Windows 系统中（没有给出图示）的测试显示出不同的行为。不是 3 个请求之间各间隔 1 秒，而是根据使用的应用程序或其他协议改变间隔。对于 ICMP 和 UDP （分别见第 8 章和第 10 章），使用的间隔约为 5 秒，而 TCP 使用的间隔为 10 秒。对于 TCP，在 TCP 放弃尝试建立一条连接之前， 10 秒间隔足以发送 2 个无须应答的 ARP 请求。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;46-arp-缓存超时&#34;&gt;4.6 ARP 缓存超时&lt;/h2&gt;
&lt;p&gt;超时通常与 ARP 缓存中的每个条目相关（我们在后面将会看到， arp 命令允许管理员设置缓存条目永远不超时）。在大多数实现中，完整条目的超时为 20 分钟，而不完整条目的超时为 3 分钟（我们在前面的例子中看到一个不完整条目，它强迫执行一次到不存在主机的 ARP 请求）。这些实现通常在每次使用一个条目后为它重新启动 20 分钟的超时。 [&lt;a href=&#34;#RFC1122&#34;&gt;RFC1122&lt;/a&gt;] 是描述主机需求的 RFC，它规定每个条目即使在使用也应启动超时，但很多实现并不这样做，它们在每次使用条目后重新启动超时。&lt;/p&gt;
&lt;p&gt;注意，这是关于&lt;strong&gt;软状态&lt;/strong&gt;的一个重要例子。软状态是指在超时到达前没有更新而被丢弃的信息。如果网络条件发生玫变，软状态有助于启动自动重新配置，因此很多 Internet 协议使用软状态。软状态的成本是协议必须刷新状态以避免过期。在一些协议设计中，经常包括“软状态刷新”，以保持软状态的活跃。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;47-代理-arp&#34;&gt;4.7 代理 ARP&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;代理 ARP&lt;/strong&gt; [&lt;a href=&#34;#RFC1027&#34;&gt;RFC1027&lt;/a&gt;] 使一个系统（通常是一台专门配置的路由器）可回答不同主机的 ARP 请求。它使 ARP 请求的发送者认为做出响应的系统就是目的主机，但实际上目的主机可能在其他地方（或不存在）。ARP 代理并不场景，通常应尽量避免使用它。&lt;/p&gt;
&lt;p&gt;代理 ARP 也被成为 &lt;strong&gt;混杂 ARP&lt;/strong&gt; 或 &lt;strong&gt;ARP 黑客&lt;/strong&gt;。这些名称来自 ARP 代理的历史用途：两个物理网络相互隐蔽自己。在这种情况下，两个物理网络可使用相同的 IP 前缀，只要将中间的路由器配置为一个代理 ARP，在一个网络中由代理响应对其他网络中主机的 ARP 请求。这种技术可用于向一组主机隐藏另一组主机。从前，这样做有两个常见原因：有些系统无法进行子网划分，有些系统使用比较旧的广播地址（全 0 的主机 ID，而不是当前全 1 的主机 ID）。&lt;/p&gt;
&lt;p&gt;Linux 支持一种称为&lt;strong&gt;自动代理 ARP&lt;/strong&gt; 的功能。它可通过在文件 &lt;code&gt;/proc/sys/net/ipv4/confys/proxy_aap&lt;/code&gt; 中写入字符 1，或使用 sysctl 命令来启用。它支持使用代理 ARP 功能，而不必为被代理的每个可能的 IPv4 地址手工输入 ARP 条目。这样做允许自动代理一个地址范围，而不是单个地址。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;48-免费-arp-和地址冲突检测&#34;&gt;4.8 免费 ARP 和地址冲突检测&lt;/h2&gt;
&lt;p&gt;ARP 的另一个功能被称为&lt;strong&gt;免费 ARP&lt;/strong&gt;。它发生在一台主机发送 ARP 请求以寻找自己的地址时。它通常出现在启动时，当接口被配置为“上行”时常这样做。下面是一个例子，在一台 Linux 机器上跟踪显示 Windows 主机的启动：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Linux# tcpdump -e -n arp
1        0.0    0:0:c0:6f:2d:40    ff:ff:ff:ff:ff:ff    arp    60:
        arp who-has 10.0.0.56    tell    10.0.0.56
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;（我们为 tcpdump 增加 -n 标志，以打印数字化的点分十进制地址而不是主机名。）就 ARP 请求字段而言，发送方协议地址和目的协议地址相同：&lt;code&gt;10.0.0.56&lt;/code&gt;。另外，以太网头部中的源地址字段被 tcpdump 显示为 &lt;code&gt;0:0:c0:6f:2d:40&lt;/code&gt;，它等于发送方硬件地址。免费 ARP 需要达到两个目标：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;允许一台主机确定另一台主机是否配置相同的 IPv4 地址。发送免费 ARP 的主机并不期望它的请求获得应答。但是，如果它接收到一个应答，通常显示的是错误消息“从以太网地址......发送的重复 IP 地址”。这是对系统管理员和用户的警告，在同一广播域（例如局域网或 VLAN）中有一个系统配置出错。&lt;/li&gt;
&lt;li&gt;如果发送免费 ARP 的主机已改变硬件地址（关闭主机或替换接口卡，然后重新启动主机），该帧导致任何接收广播并且其缓存中有该条目的其他主机，将该条目中的旧硬件地址更新为与该帧一致。如前面所述，如果一台主机接收到一个 ARP 请求，该请求来自一个已存在接收方缓存中的 IPv4 地址，则缓存条目更新为 ARP 请求中发送方的硬件地址。这由接收到 ARP 请求的主机完成，免费 ARP 正好利用这个特性。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;虽然免费 ARP 提供的一些迹象显示，多个站可尝试使用相同 IPv4 地址，但它实际上没有对这种情况提供解决机制（除了显示一个消息，实际由系统管理员完成）。为了解决这个问题， [&lt;a href=&#34;#RFC5227&#34;&gt;RFC5227&lt;/a&gt;] 描述了 &lt;strong&gt;IPv4 地址冲突检测（ACD）&lt;/strong&gt;。 ACD 定义了 &lt;strong&gt;ARP 探测&lt;/strong&gt;分组和 &lt;strong&gt;ARP 通告&lt;/strong&gt;分组。ARP 探测分组是一个 ARP 请求分组，其中&lt;strong&gt;发送方协议（IPv4）地址&lt;/strong&gt;字段被设置为 0。探测分组用于查看一个候选 IPv4 地址是否被广播域中的任何其他系统所使用。通过将&lt;strong&gt;发送方协议地址&lt;/strong&gt;字段设置为 0，避免候选 IPv4 地址被另一台主机使用时的缓存污染，这是它与免费 ARP 工作方式的一个差别。ARP 通告与 ARP 探测相同，除了其&lt;strong&gt;发送方协议地址&lt;/strong&gt;和&lt;strong&gt;目的协议地址&lt;/strong&gt;字段被填充为候选 IPv4 地址外。它用于通告发送方使用侯选 IPv4 地址的意图。&lt;/p&gt;
&lt;p&gt;为了执行 ACD，当一个接口被启用或从睡眠中唤醒，或一个新链路建立（例如，当一个新的无线网络关联建立）时，这台主机发送一个 ARP 探测分组。在发送 3 个探测分组之前，首先需要等待一个随机时间（范围为 0 ~ 1 秒，均匀分布）。当多个系统同时启用时，通过延迟来避免启用带来的拥塞，否则都立即执行 ACD，这将导致网络流量激增。探测分组之间存在一个随机的时间间距，大约 1 ~ 2 秒的延迟（均匀分布）。&lt;/p&gt;
&lt;p&gt;当请求站发送探测的探测时，它可能接收到 ARP 请求或应答。对其探测的应答表明其他站已使用候选 IP 地址。从不同系统发送的请求，其&lt;strong&gt;目的协议地址&lt;/strong&gt;字段中包含相同的候选 IPv4 地址，表明其他系统也在同时尝试获得候选 IPv4 地址。在这两种情况下，该系统将会显示一个地址冲突消息，并采用其他可选地址。例如，当使用 DHCP （见第 6 章）分配地址时，这是推荐的行为。 [&lt;a href=&#34;#RFC5227&#34;&gt;RFC5227&lt;/a&gt;] 对尝试获得地址设置了 10 次的冲突限制，在请求的主机进入限速阶段之前，它被允许每 60 秒执行一次 ACD，直至成功。&lt;/p&gt;
&lt;p&gt;根据前面所描述的过程，如果发送请求的主机没有发现冲突，它会间隔 2 秒向广播域中发送 2 个 ARP 通告，以表明它现在使用这个 IPv4 地址。在这个通告中，&lt;strong&gt;发送方协议地址&lt;/strong&gt;和&lt;strong&gt;目的协议地址&lt;/strong&gt;字段被设置为其声称的地址。发送这些通告的目的是确保更新缓存地址映射，以正确反映发送方当前使用的地址。&lt;/p&gt;
&lt;p&gt;ACD 被认为是一个持续的过程，这是它与免费 ARP 的区别。当一台主机通告它正使用的地址后，它会继续检查输入的 ARP 流量（请求和应答），查看自己的地址是否出现在&lt;strong&gt;发送方协议地址&lt;/strong&gt;字段中。如果是的话，说明其他系统与自己在使用相同的地址。在这种情况下，[&lt;a href=&#34;#RFC5227&#34;&gt;RFC5227&lt;/a&gt;] 提供了 3 种可能的解决方案：停止使用这个地址；保留这个地址，但发送一个“防御性” ARP 通告，如果冲突继续，则停止使用它；不理会冲突，仍继续使用。对于最后一个选择，仅建议那些真正需要一个固定、稳定地址的系统（例如打印机或路由器等嵌入式设备）使用。&lt;/p&gt;
&lt;p&gt;[&lt;a href=&#34;#RFC5227&#34;&gt;RFC5227&lt;/a&gt;] 还说明了使用链路层广播发送 ARP 应答的潜在好处。虽然这不是传统的 ARP 工作方式，但同一网段中所有站需处理 ARP 流量时，这样做可带来一些好处。广播应答可以更快地执行 ACD，这是由于所有站都会注意到这个应答，并在发现冲突时使自己的缓存无效。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;49-arp-命令&#34;&gt;4.9 arp 命令&lt;/h2&gt;
&lt;p&gt;在 Windows 和 Linux 中，我们使用带有 -a 标志的 arp 命令显示 ARP 缓存中的所有条目（在 Linux 上，我们可不使用 -a 而获得类似信息）。超级用户或管理员可指定 -d 选项来删除 ARP 缓存中的条目（这在运行一些例子前用于强制执行一次 ARP 交换。）&lt;/p&gt;
&lt;p&gt;我们也可以使用 -s 选项增加条目。它需要一个 IPv4 地址（或使用 DNS 从 IPv4 地址转换的主机名）和一个以太网地址。这个 IPv4 地址和以太网地址作为一个条目被添加在缓存中。这个条目是半永久性的（即它在缓存中不会超时，但在系统重启时消失）。&lt;/p&gt;
&lt;p&gt;Linux 版本的 arp 比 Windows 版本提供更多功能。当在命令行结尾使用关键字 temp，并使用 -s 增加一个条目时，这个条目被认为是临时的，并与其他 ARP 条目一样会超时。当在命令行结尾使用关键字 pub 并使用 -s 时，系统对该条目做出 ARP 应答。系统对 ARP 请求的 IPv4 地址以相应的以太网地址来应答。如果通告地址是系统自己的地址之一，该系统可作为一个指定 IPv4 地址的代理 ARP （见 4.7 节）。如果 arp -s 用于启用代理 ARP， Linux 对指定地址做出应答，在 &lt;code&gt;/proc/sys/net/ipv4/conf/*/proxy_arp&lt;/code&gt; 文件中写人 0。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;410-使用-arp-设置一台嵌入式设备的-ipv4-地址&#34;&gt;4.10 使用 ARP 设置一台嵌入式设备的 IPv4 地址&lt;/h2&gt;
&lt;p&gt;随着越来越多的嵌入式设备与以太网、 TCP/IP 协议兼容，那些无法直接输入网络配置信息的联网设备越来越普遍（例如，它们没有键盘，难以输入自已使用的 IP 地址）。这些设备通常采用以下两种方式之一配置：一种是使用 DHCP 自动分配地址和其他信息（见第 6 章）；另一种是使用 ARP 设置 IPv4 地址，虽然这种方法并不常见。&lt;/p&gt;
&lt;p&gt;通过 ARP 为嵌入式设备配置 IPv4 地址不是协议的初衷，这是由于它不是完全自动的。它的基本思路是为设备手动建立一个 ARP 映射（使用 arp -s 命令），然后向这个地址发送一个 IP 分组。由于相应 ARP 条目已存在，因此不会产生 ARP 请求/应答。相反，硬件地址可以立即使用。当然，设备的以太网（MAC）地址必须已知。它通常印在设备上，有时兼作制造商的设备序列号。当设备接收到一个目标为自身硬件地址的分组时，这个数据报包含的目的地址用于指定其初始 IPv4 地址。此后，这台设备可用其他方式（例如通过一个嵌入式 Web 服务器）完成配置。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;411-与-arp-相关的攻击&#34;&gt;4.11 与 ARP 相关的攻击&lt;/h2&gt;
&lt;p&gt;目前已有一系列涉及 ARP 的攻击。最直接的是使用代理 ARP 功能假扮主机，对 ARP 请求做出应答。如果受害主机不存在，这很直观，而且可能难以发现。如果该主机仍在运行，这被认为更困难，因为每个 ARP 请求可能有多个应答，这样比较容易发现。&lt;/p&gt;
&lt;p&gt;一种更巧妙的攻击可被 ARP 触发，它涉及一台主机被连接到多个网络，并且一个接口的 ARP 条目被其他 ARP 表“遗漏”的情况，这是由 ARP 软件的一个错误造成的。利用这种漏洞可将流量引导到错误网段上。 Linux 提供了一个直接影响该行为的方式，可通过修改文件 &lt;code&gt;/proc/sys/net/ipv4/conf/*/arp_filter&lt;/code&gt; 实现。如果将数值 1 写入这个文件，当输入的 ARP 请求到达一个接口时，就进行一次 IP 转发检查。这时需要查找请求者的 IP 地址，以确定哪个接口将用于发送返回的 IP 数据报。如果到达的 ARP 请求与返回发送方的 IP 数据报使用不同的接口，这个 ARP 应答被抑制（触发它的 ARP 请求被丢弃）。&lt;/p&gt;
&lt;p&gt;更具破坏性的 ARP 攻击涉及静态条目处理。如前所述，当查找对应一个特定 IP 地址的以太网（MAC）地址时，静态条目可用于避免 ARP 请求/应答。这种条目已被用于尝试增强安全性。它的思路是在 ARP 缓存中对重要主机使用静态条目，以快速检测任何针对该 IP 地址的主机欺骗。不幸的是，大多数 ARP 实现通常用 ARP 应答提供的条目代替静态缓存条目。这样的后果是，接收到 ARP 应答（即使它没发送 ARP 请求）的主机被欺骗，并使用攻击者提供的条目代替自己的静态条目。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;412-总结&#34;&gt;4.12 总结&lt;/h2&gt;
&lt;p&gt;ARP 是 TCP/IP 实现中的一个基本协议，但它通常在应用程序或用户没有察觉的情况下运行。 ARP 用于确定本地可达的 IPv4 子网使用的 IPv4 地址对应的硬件地址。它在数据报的目的地与发送方处于同一子网时使用，还用于数据报的目的地不在当前子网（在第 5 章详细说明）时将其转发到一台路由器。 ARP 缓存是其运行的基础，我们可使用 arp 命令查看和处理缓存。缓存中每个条目都有一个计时器，用于清除不完整的条目和完整的条目。 arp 命令可显示和修改 ARP 缓存中的条目。&lt;/p&gt;
&lt;p&gt;我们深入了解特殊 ARP 的正常运行：代理 ARP （一台路由器回答主机通过另一台路由器接口访问的 ARP 请求）和免费 ARP （发送自己拥有的 IP 地址的 ARP 请求，通常用于引导）。我们还讨论了 IPv4 地址冲突检测，采用一种持续运行的类似免费 ARP 的交换，来避免在同一广播域中地址重复。最后，我们讨论了一系列涉及 ARP 的攻击。如果高层协议没有强大的安全措施，这可能会导致高层协议出现问题（见第 18 章）。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;413-参考文献&#34;&gt;4.13 参考文献&lt;/h2&gt;
&lt;p&gt;&lt;span id=&#34;RFCO826&#34;&gt;[RFCO826]&lt;/span&gt; D. Plummer, &amp;quot;Ethernet Address Resolution Protocol: Or Converting Network Protocol Addresses to 48.bit Ethernet Address for Transmission on Ethernet Hardware,&amp;quot; Internet RFC 0826/STD 0037, Nov.1982.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFCO903&#34;&gt;[RFCO903]&lt;/span&gt;R. Finlayson, T. Mann,J. C. Mogul, and M. Theimer, &amp;quot;A Reverse Address Resolution Protocol,&amp;quot; Internet RFC 0903/STD 0038,June 1984.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC1027&#34;&gt;[RFC1027]&lt;/span&gt; S. Carl-Mitchell and J. S. Quarterman, &amp;quot;Using ARP to Implement Transparent Subnet Gateways,&amp;quot; Internet RFC 1027,Oct. 1987.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC1122&#34;&gt;[RFC1122]&lt;/span&gt;R. Braden, ed., &amp;quot;Requirements for Internet Hosts,&amp;quot; Internet RFC 1122/STD 0003,Oct. 1989.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC2332&#34;&gt;[RFC2332]&lt;/span&gt; J. Luciani, D. Katz, D. Piscitello, B. Cole, and N. Doraswamy, &amp;quot;NBMA Next Hop Resolution Protocol (NHRP),&amp;quot; Internet RFC 2332,Apr. 1998.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC5227&#34;&gt;[RFC5227]&lt;/span&gt; S. Cheshire, &amp;quot;IPv4 Address Conflict Detection,&amp;quot; Internet RFC 5227, July. 1998.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC5494&#34;&gt;[RFC5494]&lt;/span&gt; J.Arkko and C. Pignataro, &amp;quot;IANA Allocation Guidelines for the Address Resolution Protocol(ARP)&amp;quot; Internet RFC 5494,Apr. 2009.&lt;/p&gt;
">《TCP/IP 详解 卷一：协议》第四章：地址解析协议</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://wenbozhangw.github.io/post/lesslesstcpip-xiang-jie-juan-yi-xie-yi-greatergreater-di-san-zhang-lian-lu-ceng/"" data-c="
          &lt;h2 id=&#34;31-引言&#34;&gt;3.1 引言&lt;/h2&gt;
&lt;p&gt;在第 1 章中，我们知道 TCP/IP 协议族中设计链路层的目的是为 IP 模块发送和接收 IP 数据报。它可用于携带一些支持 IP 的辅助性协议，例如 ARP （见第 4 章）。 TCP/IP 支持多种不同的链路层，它依赖于使用的网络硬件类型：有线局域网，例如以太网；&lt;strong&gt;城域网（MAN）&lt;/strong&gt;，例如服务供应商提供的有线电视和 DSL 连接；有线语音网络，例如支持调制解调器的电话线；无线网络，例如Wi-Fi （无线局域网）；基于蜂窝技术的各种无线数据服务，例如 HSPA、EV-DO、LTE 和 WiMAX。在本章中，我们将详细讨论以下内容：在以太网和 Wi-Fi 的链路层中，如何使用&lt;strong&gt;点到点协议（PPP）&lt;/strong&gt;，如何在其他（链路或更高层）协议中携带链路层协议，以及一种称为隧道的技术等。详细描述当前使用的每种链路技术需要专门一本书才行，因此我们将注意力集中在一些常用的链路层协议，以及 TCP/IP 中如何使用它们。&lt;/p&gt;
&lt;p&gt;大多数链路层技术都有一个相关的协议，描述由网络硬件传输的相应 PDU 格式。在描述链路层的 PDU 时，我们通常使用术语&lt;strong&gt;帧&lt;/strong&gt;，以区分那些更高层的 PDU 格式，例如描述网络层和传输层 PDU 的分组和段。帧格式通常支持可变的帧长度，范围从几字节到几千字节。这个范围的上限称为&lt;strong&gt;最大传输单元（MTU）&lt;/strong&gt;，我们将在后续章节中提到链路层的这一特点。有些网络技术（例如调制解调器和串行线路）不强制规定最大的帧，因此它们可以由用户来配置。&lt;/p&gt;
&lt;h2 id=&#34;32-以太网和-ieee-802-局域网城域网标准&#34;&gt;3.2 以太网和 IEEE 802 局域网/城域网标准&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;以太网&lt;/strong&gt;这个术语通常指一套标准，由 DEC、 Intel 公司和 Xerox 公司在 1980 年首次发布，并在 1982 年加以修订。第一个常见格式的以太网，目前被称为“10Mb/s 以太网”或“共享以&lt;br&gt;
太网”，它被 IEEE 采纳（轻微修改）为 802.3 标准。这种网络的结构通常如图 3-1 所示。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1651118328245.png&#34; alt=&#34;图 3-1&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 3-1   基本的共享以太网包含一个或多个站（例如工作站、超级计算机），它们都被连接到一个共享的电缆段上。当介质被确定为空闲状态时，链路层的 PDU（帧）可以从一个站发送到一个或更多其他站。如果多个站同时发送数据，可能因信号传播延迟而发生碰撞。碰撞可以被检测到，它会导致发送站等待一个随机事件，然后重新发送数据。这种常见的方法称为带冲突检测的载波侦听多路访问&lt;/p&gt;
&lt;p&gt;由于多个站共享同一网络，该标准需要在每个以太网接口实现一种分布式算法，以控制一个站发送自己的数据。这种特定方法称为&lt;strong&gt;带冲突（或称碰撞）检测的载波侦听多路访问（CSMA/CD）&lt;/strong&gt;，它协调哪些计算机可访问共享的介质（电缆），同时不需要其他特殊协议或同步。这种相对简单的方法有助于降低成本和促进以太网投术普及。&lt;/p&gt;
&lt;p&gt;采用 CSMA/CD，一个站（例如计算机）首先检测目前网络上正在发送的信号，并在网络空闲时发送自己的帧。这是协议中的“载波侦听”部分。如果其他站碰巧同时发送，发生重叠的电信号被检测为一次碰撞。在这种情况下，每个站等待一个随机时间，然后再次尝试发送。这个时间量的选择依据一个统一的概率分布，随后每个碰撞被检测到的时间长度加倍。最终，每个站会得到机会发送，或者在尝试一定次数（传统以太网为 16）后超时。采用 CSMA/CD，在任何给定的时间内，网络中只能有一个帧传输。如 CSMA/CD 这样的访问方法更正式的名称为&lt;strong&gt;介质访问控制(MAC)协议&lt;/strong&gt;。 MAC 协议有很多类型，有些基于每个站尝试独立使用网络（例如 CSMA/CD 的基于竞争的协议），有些基于预先安排的协调（例如依据为每个站分配的时段发送） 。&lt;/p&gt;
&lt;p&gt;随着 10Mb/s 以太网的发展，更快的计算机和基础设施使得局域网速度不断提升。由于以太网的普及，已取得以下显著创新和成果：其速度从 10Mb/s 增加到 100Mb/s、 1000Mb/s、10Gb/s，现在甚至更高。 10Gb/s 技术在大型数据中心和大型企业中越来越普遍，并且已被证实可达到 100Gb/s 的速度。最早（研究）的以太网速度为 3Mb/s，但 DIX （Digital、 Intel、 Xerox）标准可达到 10Mb/s，它在一条共享的物理电缆或由电子中继器互联的一组电缆上运行。 20 世纪 90 年代初，共享的电缆已在很大程度上被双绞线（类似电话线，通常称为“10BASE-T”）代替。随着 100Mb/s （也称为“快速以太网”，最流行的版本是“100BASE-TX”）的发展，基于竞争的 MAC 协议已变得不流行。相反，局域网中每个站之间的线路通常不共享，而是提供了一个专用的星形拓扑结构。这可以通过以太网&lt;strong&gt;交换机&lt;/strong&gt;来实现，如图 3-2 所示&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1651120249525.png&#34; alt=&#34;图 3-2&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 3-2   一个交换式以太网包含一个或多个站，每个站使用一条专用的线路连接到一个交换机端口。在大多数情况下，交换式以太网以全双工方式运行，并且不需要使用 CSMA/CD 算法。交换机可以通过交换机端口级联形成更大的以太网，该端口有时也称为“上行”端口&lt;/p&gt;
&lt;p&gt;目前，交换机为以太网中的每个站提供同时发送和接收数据的能力（称为“全双工以太网”）。虽然 1000Mb/s 以太网（1000BASE-T）仍支持半双工（一次一个方向）操作，但相对于全双工以太网来说，它很少使用。下面我们将详细讨论交换机如何处理 PDU。&lt;/p&gt;
&lt;p&gt;当前连接 Internet 的最流行技术之一是无线网络，常见的无线局域网（WLAN） IEEE 标准称为无线保真或 Wi-Fi，有时也称为“无线以太网”或 802.11。虽然这个标准与 802 有线以太网标准不同，但帧格式和通用接口大部分来自 802.3，并且都是 IEEE 802 局域网标准的一部分。因此， TCP/IP 用于以太网的大部分功能，也可用于 Wi-Fi 网络。我们将详细探讨这些功能。首先，我们描绘一个建立家庭和企业网络的所有 IEEE 802 标准的蓝图。这里也包括那些涉及城域网的 IEEE 标准，例如 IEEE 802.16（WiMAX）和蜂窝网络中的异构网络无缝切换标准（IEEE 802.21）。&lt;/p&gt;
&lt;h3 id=&#34;321-ieee-802-局域网城域网标准&#34;&gt;3.2.1 IEEE 802 局域网/城域网标准&lt;/h3&gt;
&lt;p&gt;原始的以太网帧格式和工作过程由前面提到的行业协议所描述。这种格式被称为 DIX 格式或 Ethernet II 格式。对这种类型的以太网稍加修改后，由 IEEE 标准化为一种 CSMA/CD 网络，称为 802.3。在 IEEE 标准中，带 802 前缀的标准定义了局域网和城域网的工作过程。当前最流行的 802 标准包括 802.3 （以太网）和 802.11（WLAN/Wi-Fi）。这些标准随着时间推移而演变，经过独立修订后名称发生改变（例如 802.11g），并最终被纳入修订过的标准。表 3-1 显示了一个相当完整的列表，包括截至 2011 年年中支持 TCP/IP 的相关 IEEE 802 局域网和城域网标准。&lt;/p&gt;
&lt;center&gt;表 3-1   有关 TCP/IP 协议的局域网和城域网 IEEE 802 标准（2011）&lt;/center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;名称&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;th&gt;官方参考&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;802.1ak&lt;/td&gt;
&lt;td&gt;多注册协议（MRP）&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.1AK-2007&#34;&gt;802.1AK-2007&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.1AE&lt;/td&gt;
&lt;td&gt;MAC 安全（MACSec）&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.AE-2006&#34;&gt;802.AE-2006&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.1AX&lt;/td&gt;
&lt;td&gt;链路聚合（以前的 802.3ad）&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.AX-2008&#34;&gt;802.AX-2008&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.1d&lt;/td&gt;
&lt;td&gt;MAC 网桥&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.1D-2004&#34;&gt;802.1D-2004&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.1p&lt;/td&gt;
&lt;td&gt;流量类/优先级/QoS&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.1D-2004&#34;&gt;802.1D-2004&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.1q&lt;/td&gt;
&lt;td&gt;虚拟往前的局域网/MRP的更正&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.1Q-2005/Corl-2008&#34;&gt;802.1Q-2005/Corl-2008&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.1s&lt;/td&gt;
&lt;td&gt;多生成树协议（MSTP）&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.1Q-2005&#34;&gt;802.1Q-2005&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.1w&lt;/td&gt;
&lt;td&gt;快速生成树协议（RSTP）&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.1D-2004&#34;&gt;802.1D-2004&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.1X&lt;/td&gt;
&lt;td&gt;基于端口的网络控制访问（PNAC）&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.1X-2010&#34;&gt;802.1X-2010&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.2&lt;/td&gt;
&lt;td&gt;逻辑链路控制（LLC）&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.2-1998&#34;&gt;802.2-1998&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.3&lt;/td&gt;
&lt;td&gt;基本以太网和 10 Mb/s 以太网&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.3-2008&#34;&gt;802.3-2008&lt;/a&gt;] （第 1 节）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.3u&lt;/td&gt;
&lt;td&gt;100 Mb/s 以太网（“快速以太网”）&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.3-2008&#34;&gt;802.3-2008&lt;/a&gt;] （第 2 节）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.3x&lt;/td&gt;
&lt;td&gt;全双工运行和流量控制&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.3-2008&#34;&gt;802.3-2008&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.3z/802.3ab&lt;/td&gt;
&lt;td&gt;1000 Mb/s 以太网（“千兆以太网”）&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.3-2008&#34;&gt;802.3-2008&lt;/a&gt;] （第 3 节）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.3ae&lt;/td&gt;
&lt;td&gt;10 Gb/s 以太网&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.3-2008&#34;&gt;802.3-2008&lt;/a&gt;] （第 4 节）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.3ad&lt;/td&gt;
&lt;td&gt;链路聚合&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.1AX-2008&#34;&gt;802.1AX-2008&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.3af&lt;/td&gt;
&lt;td&gt;以太网供电（PoE，15.4W）&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.3-2008&#34;&gt;802.3-2008&lt;/a&gt;] （第2 节）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.3ah&lt;/td&gt;
&lt;td&gt;以太网接入（第一公里以太网）&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.3-2008&#34;&gt;802.3-2008&lt;/a&gt;] （第 5 节）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.3as&lt;/td&gt;
&lt;td&gt;帧格式扩展（2000 字节）&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.3-2008&#34;&gt;802.3-2008&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.3at&lt;/td&gt;
&lt;td&gt;以太网供电增强（“PoE+”，30W）&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.3at-2009&#34;&gt;802.3at-2009&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.3ba&lt;/td&gt;
&lt;td&gt;40/100Gb/s 以太网&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.3ba-2010&#34;&gt;802.3ba-2010&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.11a&lt;/td&gt;
&lt;td&gt;运行在 5GHz 的 54Mb/s 的无线局域网&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.11-2007&#34;&gt;802.11-2007&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.11b&lt;/td&gt;
&lt;td&gt;运行在 2.4GHz 的 11Mb/s 的无线局域网&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.11-2007&#34;&gt;802.11-2007&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.11e&lt;/td&gt;
&lt;td&gt;针对 802.11 的 QoS 增强&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.11-2007&#34;&gt;802.11-2007&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.11g&lt;/td&gt;
&lt;td&gt;运行在 2.4GHz 的 54Mb/s 的无线局域网&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.11-2007&#34;&gt;802.11-2007&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.11h&lt;/td&gt;
&lt;td&gt;频谱/电源管理扩展&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.11-2007&#34;&gt;802.11-2007&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.11i&lt;/td&gt;
&lt;td&gt;安全增强/代替 WEP&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.11-2007&#34;&gt;802.11-2007&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.11j&lt;/td&gt;
&lt;td&gt;运行在 4.9 ~ 5.0GHz（日本）&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.11-2007&#34;&gt;802.11-2007&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.11n&lt;/td&gt;
&lt;td&gt;预先在 2.4GHz 和 5GHz 的 6.5 ~ 600Mb/s 的无线局域网，&lt;br/&gt;使用可选的 MIMO 和 40MHz 管道&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.11n-2009&#34;&gt;802.11n-2009&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.11s（草案）&lt;/td&gt;
&lt;td&gt;网状网，拥塞控制&lt;/td&gt;
&lt;td&gt;开发中&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.11y&lt;/td&gt;
&lt;td&gt;运行在 3.7GHz 的 54Mb/s 的无线局域网（许可的）&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.11y-2008&#34;&gt;802.11y-2008&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.16&lt;/td&gt;
&lt;td&gt;微波存取全球互通技术（WiMAX）&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.16-2009&#34;&gt;802.16-2009&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.16d&lt;/td&gt;
&lt;td&gt;固定的无线城域网标准（WiMAX）&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.16-2009&#34;&gt;802.16-2009&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.16e&lt;/td&gt;
&lt;td&gt;固定/移动的无限城域网标准（WiMAX）&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.16-2009&#34;&gt;802.16-2009&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.16h&lt;/td&gt;
&lt;td&gt;改进的共存机制&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.16h-2010&#34;&gt;802.16h-2010&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.16j&lt;/td&gt;
&lt;td&gt;802.16 中的多跳中继&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.16j-2009&#34;&gt;802.16j-2009&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.16k&lt;/td&gt;
&lt;td&gt;802.16 网桥&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.16k-2007&#34;&gt;802.16k-2007&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.21&lt;/td&gt;
&lt;td&gt;介质无关切换&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#802.21-2008&#34;&gt;802.21-2008&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;除了 802.3、 802.11、 802.16 标准定义的特定类型的局域网之外，还有一些相关标准适用于所有 IEEE 标准的局域网技术。最常见的是定义**逻辑链路控制（LLC）**的 802.2 标准，其帧头部在 802 网络的帧格式中常见。在 IEEE 的术语中， LLC 和 MAC 是链路层的“子层”，LLC （多数帧格式）对每种网络都是通用的，而 MAC 层可能有所不同。虽然最初的以太网使用 CSMA/CD，但无线局域网常使用  CSMA/CA （CA 是“冲突避免”）。&lt;/p&gt;
&lt;p&gt;注意 不幸的是， 802.2 和 802.3 共同定义了与 Ethemet II 不同的帧格式，这个情况直到 802.3x 才最终纠正。它已经被纳入 [&lt;a href=&#34;#802.3-2008&#34;&gt;802.3-2008&lt;/a&gt;] 。在 TCP/IP 世界中，[&lt;a href=&#34;#RFC0894&#34;&gt;RFC0894&lt;/a&gt;] 和 [&lt;a href=&#34;#RFC2464&#34;&gt;RFC2464&lt;/a&gt;] 定义了针对以太网的 IP 数据报封装，但旧的 LLC/SNAP 封装仍发布在 [&lt;a href=&#34;#RFC1042&#34;&gt;RFC1042&lt;/a&gt;] 中。虽然这不再是一个大问题，但它曾经令人关注，并偶尔出现类似问题 [&lt;a href=&#34;#RFC4840&#34;&gt;RFC4840&lt;/a&gt;]。&lt;/p&gt;
&lt;p&gt;直到最近，帧格式在本质上还一直相同。为了获得该格式的详细信息，并了解它是如何演变的，我们现在将焦点转向这些细节。&lt;/p&gt;
&lt;h3 id=&#34;322-以太网帧格式&#34;&gt;3.2.2 以太网帧格式&lt;/h3&gt;
&lt;p&gt;所有的以太网（802.3）帧都基于一个共同的格式。在原有规范的基础上，帧格式已被改进以支持额外功能。图 3-3 显示了当前的以太网帧格式，以及它与 IEEE 提出的一个相对新的术语 IEEE 分组（一个在其他标准中经常使用的术语）的关系。&lt;/p&gt;
&lt;p&gt;以太网帧开始是一个&lt;strong&gt;前导&lt;/strong&gt;字段，接收器电路用它确定一个帧的到达时间，并确定编码位（称为&lt;strong&gt;时钟恢复&lt;/strong&gt;）之间的时间量。由于以太网是一个异步的局域网（即每个以太网接口卡中不保持精确的时钟同步），从一个接口到另一个接口的编码位之间的间隔可能不同。前导是一个公认的模式（典型值为 &lt;code&gt;0xAA&lt;/code&gt;），在发现**帧起始分隔符（SFD）**时，接收器使用它“恢复时钟”。 SFD 的固定值为 &lt;code&gt;0xAB&lt;/code&gt;。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1651207095547.png&#34; alt=&#34;图 3-3&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 3-3   以太网（IEEE802.3）帧格式包含一个源地址和目的地址、一个重载的&lt;strong&gt;长度/类型&lt;/strong&gt;字段、一个数据字段和一个帧校验序列（CRC32）。另外，基本帧格式提供了一个标签，其中包含一个 VLAN ID 和优先级信息（802.1p/q），以及一个最近出现的可扩展标签。前导和 SFD 被用于接收器同步。当以太网以半双工模式运行在 100Mb/s 或以上速率时，其他位可能被作为载体扩展添加到短帧中，以确保冲突检测电路的正常运行&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;注意  最初以太网的位编码使用两个电压等级的曼彻斯特相位编码（MPE）。通过 MPE，
每位被编码为电压变化，而不是绝对值。例如， 0 位被编码为从 -0.85V 到 +0.85V 的变化，
1 位被编码为从 +0.85V 到 -0.85V 的变化（0V 指共享线路处于空闲状态）。 10Mb/s 
以太网规范要求网络硬件使用 20MHz 振荡器，因为 MPE 的每位需要两个时钟周期。
字节 0xAA （二进制为10101010）在以太网的前导中，表示为一个 +0.85 和 -0.85V 之间
的 10MHz 频率的方波。在其他以太网标准中，曼彻斯特编码被替换为不同编码，以提高效率。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这个基本的帧格式包括 48 位（6 字节）的**目的地址（DST）&lt;strong&gt;和&lt;/strong&gt;源地址（SRC）**字段。这些地址有时也采用其他名称，例如“MAC地址”、“链路层地址”、“802 地址”、“硬件地址”或“物理地址”。以太网帧的目的地址也允许寻址到多个站点（称为“广播”或“组播”，见第 9 章）。广播功能用于 ARP 协议（见第 4 章），组播功能用于 ICMPv6 协议（见第 8 章），以实现网络层地址和链路层地址之间的转换。&lt;/p&gt;
&lt;p&gt;源地址后面紧跟着一个&lt;strong&gt;类型&lt;/strong&gt;字段，或一个&lt;strong&gt;长度&lt;/strong&gt;字段。在多数情况下，它用于确定头部后面的数据类型。 TCP/IP 网络使用的常见值包括IPv4 （&lt;code&gt;0x0800&lt;/code&gt;）、 IPv6 （&lt;code&gt;0x86DD&lt;/code&gt;）和 ARP （&lt;code&gt;0x0806&lt;/code&gt;）。 &lt;code&gt;0x8100&lt;/code&gt; 表示一个 Q 标签帧（可携带一个“虚拟局域网”或 802.1q 标准的 VLAN ID）。一个以太网帧的基本大小是 1518 字节，但最近的标准将该值扩大到 2000 字节。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;注意   最初的 IEEE （802.3）规范将长度/类型字段作为长度字段而不是类型字段使用。
因此，这个字段被重载（可用于多个目的）。关键是看字段值。目前，如果字段值大于
或等于 1536，则该字段表示类型，它是由标准分配的超过 1536 的值。如果字段值等于
或小于 1500，则该字段表示长度。 [ETHERTYPES] 给出了类型的完整列表。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在上述字段之后， [&lt;a href=&#34;#802.3-2008&#34;&gt;802.3-2008&lt;/a&gt;] 提供了多种标签包含由其他 IEEE 标准定义的各种协议字段。其中，最常见的是那些由 802.1p 和 802.1q 使用的标签，它提供虚拟局域网和一些 **服务质量（Qos）**指示符。这些在 3.2.3 节讨论。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;注意   当前的 [802.3-2008] 标准采用修改后的 802.3 帧格式，提供最大为 482 字节的
“标签”，它携带在每个以太网帧中。这些较大的帧称为信封帧，长度最大可能达到
2000 字节。包含 802.1p/q 标签的帧称为 Q 标签帧，也是信封帧。但是，并非所有
信封帧必然是 Q 标签帧。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在这些讨论过的字段之后，是帧的数据区或&lt;strong&gt;有效载荷&lt;/strong&gt;部分。这里是放高层 PDU （例如IP数据报）的地方。传统上，以太网的有效载荷一直是 1500 字节，它代表以太网的 MTU。 目前，大多数系统为以太网使用 1500 字节的 MTU，虽然在必要时它也可设置为一个较小的值。有效载荷有时被&lt;strong&gt;填充&lt;/strong&gt;（添加）数个 0，以确保帧总体长度符合最小长度要求，这些我们将在 3.2.2.2 节讨论。&lt;/p&gt;
&lt;h4 id=&#34;3221-帧校验序列循环冗余校验&#34;&gt;3.2.2.1 帧校验序列/循环冗余校验&lt;/h4&gt;
&lt;p&gt;在以太网帧格式中，有效载荷区域之后的最后字段提供了对帧完整性的检查。&lt;strong&gt;循环冗余校验（CRC）&lt;strong&gt;字段位于尾部，有 32 位，有时称之为 IEEE/ANSI 标准的 CRC32 [&lt;a href=&#34;#802.3-2008&#34;&gt;802.3-2008&lt;/a&gt;]。要使用一个 n 位 CRC 检测数据传输错误，被检查的消息首先需要追加 n 位 0 形成一个&lt;/strong&gt;扩展消息&lt;/strong&gt;。然后，扩展消息（使用模 2 除法）除以一个（n + 1）位的值，这个作为除数的值称为&lt;strong&gt;生成多项式&lt;/strong&gt;。放置在消息的 CRC 字段中的值是这次除法计算中余数的二进制反码（商被丢弃）。生成多项式已被标准化为一系列不同的 n 值。以太网使用 &lt;code&gt;n=32&lt;/code&gt;， CRC32 的生成多项式是 33 位的二进制数&lt;code&gt;100000100110000010001110110110111&lt;/code&gt;。为了理解如何使用（mod 2）二进制除法计算&lt;br&gt;
余数，我们看一个 CRC4 的简单例子。国际电信联盟（ITU）将 CRC4 的生成多项式值标准化为&lt;code&gt;10011&lt;/code&gt;，这是在 G.704 [&lt;a href=&#34;#G704&#34;&gt;G704&lt;/a&gt;] 标准中规定的。如果我们要发送 16 位的消息&lt;br&gt;
&lt;code&gt;1001111000101111&lt;/code&gt;，首先开始进行图 3-4 所示的（mod2）二进制除法。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1652281247055.png&#34; alt=&#34;图 3-4&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 3-4   长（mod2）二进制除法延时了 CRC4 的计算过程&lt;/p&gt;
&lt;p&gt;在该图中，我们看到这个除法的余数是 4 位的值 &lt;code&gt;1111&lt;/code&gt;。通常，该余数的反码（0000）将放置在帧的 CRC 或**帧校验序列（FCS）**字段中。在接收到数据之后，接收方执行相同的除法计算出余数，并判断该值与 FCS 字段的值是否匹配。如果两者不匹配，帧可能在传输过程中受损，通常被丢弃。 CRC 功能可用于提示信息受损，因为位模式的任何改变极可能导致余数的改变。&lt;/p&gt;
&lt;h4 id=&#34;3222-帧大小&#34;&gt;3.2.2.2 帧大小&lt;/h4&gt;
&lt;p&gt;以太网帧有最小和最大尺寸。最小的帧是 64 字节，要求数据区（有效载荷）长度（无标签）最小为 48 字节。当有效载荷较小时，填充字节（值为0）被添加到有效载荷尾部，以确保达到最小长度。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;注意   最小长度对最初的 10Mb/s 以太网的 CSMA/CD 很重要。为了使传输数据的
站能知道哪个帧发生了冲突，将一个以太网的最大长度限制为 2500m（通过4个
中继器连接的 5 个 500m 的电缆段）。根据电子在铜缆中传播速度约为 0.77c （约
2.31×108m/s），可得到 64 字节采用 10Mb/s 时的传输时间为 64×8/10000000=
51.2 μs，最小尺寸的帧能在电缆中传输约 11000m。如果采用一条最长为 2500m 
的电缆，从一个站到另一个站之间的最大往返距离为 5000m。以太网设计者确定最
小帧长度基于安全因素，在完全兼容（和很多不兼容）的情况下，一个输出帧的最
后位在所需时间后仍处于传输过程中，这个时间是信号到达位于最大距离的接收器
并返回的时间。如果这时检测到一个冲突，传输中的站能知道哪个帧发生冲突，即
当前正在传输中的那个帧。在这种情况下，该站发送一个干扰信号（高电压）提醒
其他站，然后启动一个随机的二进制指数退避过程。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;传统以太网的最大帧长度是 1518 字节（包括 4 字节 CRC 和 14 字节头部）。选择这个值出于一种折中：如果一个帧中包括一个错误（接收到不正确的 CRC 校验），只需重发 1.5kB 以修复该问题。另一方面， MTU 大小限制为 1500 字节。为了发送一个更大的消息，则需要多个帧（例如，对于 TCP/IP 网络常用的较大尺寸 64KB，需要至少 44 个帧）。&lt;/p&gt;
&lt;p&gt;由多个以太网帧构成一个更大的上层 PDU 的后果是，每个帧都贡献了一个固定开销（14 字节的头部和 4 字节的 CRC）。更糟的是，为了允许以太网硬件接收电路正确恢复来自网络的数据，并为其他站提供将自己的流量与已有流量区分开的机会，以太网帧在网络中不能无缝地压缩在一起。 Ethernet II 规范除了在帧开始处定义了 7 字节前导和 1 字节 SFD 之外，还指定了 12 字节的包间距（IPG）时间（10Mb/s 为9.6μs， 100Mb/s 为 960ns， 1000Mb/s 为 96ns， 10000Mb/s 为 9.6ns）。因此， Ethernet II 的每帧效率最多为 &lt;code&gt;1500/(12 + 8 + 14 + 1500 + 4)=0.975293&lt;/code&gt;，约 98%。一种提高效率的方式是，在以太网中传输大量数据时，尽量使帧尺寸更大一些。这可采用以太网&lt;strong&gt;巨型帧&lt;/strong&gt; [&lt;a href=&#34;#JF&#34;&gt;JF&lt;/a&gt;] 来实现，它是一种非标准的以太网扩展（主要在 1000Mb/s 以太网交换机中使用），通常允许帧尺寸高达 9000 字节。有些环境使用的帧称为&lt;strong&gt;超级巨型帧&lt;/strong&gt;，它们通常超过 9000 字节。在使用巨型帧时要谨慎，这些较大的帧无法与较小的 1518 字节的帧互操作，因为它们无法由大多数传统以太网设备处理。&lt;/p&gt;
&lt;h3 id=&#34;323-8021pq虚拟局域网和-qos-标签&#34;&gt;3.2.3 802.1p/q：虚拟局域网和 QoS 标签&lt;/h3&gt;
&lt;p&gt;随着交换式以太网的使用越来越多，位于同一以太网中的每台主机互连已成可能。这样做的好处是，任何主机都可直接与其他主机通信，它们使用 IP 和其他网络层协议，并很少或根本不需要管理员配置。另外，广播和组播流量（见第 9 章）被分发到所有希望接收的主机，而不必建立特殊的组播路由协议。虽然这是很多主机位于同一以太网的优势，但在很多主机使用广播时，广播到每台主机将带来大量网络流量，并出于某些安全因素可能要禁止任意站之间通信。&lt;/p&gt;
&lt;p&gt;为了解决大型多用途交换网络运行中的问题， IEEE 采用一种称为**虚拟局域网（VLAN）**的功能扩展 802 LAN 标准，它被定义在 802.1q [&lt;a href=&#34;#802.1Q-2005&#34;&gt;802.1Q-2005&lt;/a&gt;]标准中。兼容的以太网交换机将主机之间的流量分隔为常见的 VLAN。注意，正是由于这种分隔，连在同一交换机但在不同 VLAN 中的两台主机，它们之间的流量需要一台路由器来传递。已研发出交换机/路由器组合设备来满足这种需求，路由器性能最终得到改进以匹配 VLAN 交换性能。因此， VLAN 的吸引力已有所减弱，现代高性能路由器逐渐取代它们。尽管如此，它们仍在使用，在某些环境中仍受欢迎，因此有必要了解它们。&lt;/p&gt;
&lt;p&gt;工作站到 VLAN 的映射有几种方法。通过端口分配 VLAN 是一种简单而常见的方法，交换机端口所连接的站被分配在一个特定 VLAN 中，这样连接的任意站就都成为 VLAN 中的成员。其他选择包括基于 MAC 地址的 VLAN，以太网交换机使用表将一个站的 MAC 地址映射到一个 VLAN。如果有些站改变它们的 MAC 地址（由于某些用户行为，有时需要这样做），它们可能变得难以管理。 IP 地址也可用作分配 VLAN 的基础。&lt;/p&gt;
&lt;p&gt;当不同 VLAN 中的站连接在同一交换机时，交换机确保流量不在两个 VLAN 之间泄漏，无论这些站使用哪种类型的以太网接口。当多个 VLAN 跨越多个交换机（&lt;strong&gt;中继&lt;/strong&gt;）时，在以太网帧发送到另一台交换机之前，需要使用 VLAN 来标记该帧的归属。本功能使用一个称为 &lt;strong&gt;VLAN标签&lt;/strong&gt;（或头部）的标记，其中包含 12 位 &lt;strong&gt;VLAN 标识符&lt;/strong&gt;（提供 4096 个 VLAN，但保留 VLAN 0 和 VLAN 4095）。它还包含支持 QoS 的 3 位优先级（定义在 802.1p 标准中），如图 3-3 所示。在很多情况下，管理员必须配置交换机端口，以便发送 802.1p/q 帧时能中继到适当的端口。为了使这项工作更加容易，有些交换机通过中继端口支持&lt;strong&gt;本地 VLAN&lt;/strong&gt; 选项，这意味着未标记的帧默认与本地 VLAN 相关。中继端口用于互连带 VLAN 功能的交换机，其他端口通常用于直接连接工作站。有些交换机还支持专用的 VLAN 中继方法，例如思科 &lt;strong&gt;内部交换链路（ISL）&lt;/strong&gt; 协议。&lt;/p&gt;
&lt;p&gt;802.1p 规定了在帧中表示 QoS 标识符的机制。802.1p 头部包括一个 3 位优先级字段，它用于表明一个 QoS 级别。这个标准是 802.1q VLAN 标准的扩展。这两个标准可以一起工作，并在同一头部中共享某些位。它用 3 个有效位定义了 8 个服务级别。 0 级为最低优先级，用于传统的尽力而为的流量。 7 级为最高优先级，可用于关键路由或网管功能。这个标准规定了优先级如何被编码在分组中，但没指定如何控制哪些分组采用哪个级别，以及实现优先级服务的底层机制，这些可由具体的实现者来定义。因此，一个优先级流量相对于另一个的处理方式是由实现或供应商定义的。注意，如果 802.1p/q 头部中的 VLAN ID 字段被设置为 0， 802.1p 可以独立于 VLAN 使用。&lt;/p&gt;
&lt;p&gt;控制 802.1p/q 信息的 Linux 命令是 &lt;code&gt;vconfig&lt;/code&gt;。它可用来添加和删除虚拟接口，即与物理接口相关联的 VLAN ID。它也可用来设置 802.1p 优先级，更改虚拟接口确定方式，改变由特定 VLAN ID 标记的分组之间的映射，以及协议在操作系统中处理时如何划分优先级。下面的命令为 VLAN ID 为 2 的接口 eth1 添加、删除虚拟接口，修改虚拟接口的命名方式并添加新接口：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Linux# vconfig add eth1 2
Added VLAN with VID == 2 to IF -:eth1:-
Linux# ifconfig eth1.2
ethl.2 Link encap:Ethernet HWaddr 00:04:5A:9F:9E:80
            BROADCAST MULTICAST MTU:1500 Metric:1
            RX packets:0 errors:0 dropped:0 overruns:0 frame:0
            TX packets:0 errors:0 dropped:0 overruns:0 carrier:O
            collisions:0 txqueuelen:0
            RX bytes:0 (0.0 b) TX bytes:0 (0.0 b)
Linux# vconfig rem eth1.2
Removed VLAN -:eth1.2:-
Linux# vconfig set_name_type VLAN_PLUS_VID
Set name-type for VLAN subsystem. Should be visible in
            /proc/net/vlan/config
Linux# vconfig add eth1 2
Added VLAN with VID == 2 to IF -:eth1:-
Linux# ifconfig vlan0002
vlan0002 Link encap:Ethernet HWaddr 00:04:5A:9F:9E:80
            BROADCAST MULTICAST MTU:1500 Metric:1
            RX packets:0 errors:0 dropped:0 overruns:0 frame:0
            TX packets:0 errors:0 dropped:0 overruns:0 carrier:O
            collisions:0 txqueuelen:0
            RX bytes:0 (0.0 b) TX bytes:0 (0.0 b)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里，我们可以看到在 Linu x中，虚拟接口命名的默认方法是将相关物理接口与 VLAN ID 串联。例如， VLAN ID 2 与接口 eth1 关联为 eth1.2。这个例子还显示了另一种命名方法，VLAN 被枚举为名称  &lt;code&gt;vlan &amp;lt;n&amp;gt;&lt;/code&gt;，其中 &lt;code&gt;&amp;lt;n&amp;gt;&lt;/code&gt; 是 VLAN 的标识符。一旦这样设置， VLAN 设备发送帧会如期望的那样被标记为VLAN ID。我们可通过 Wireshark 看到，如图 3-5 所示。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1652326011999.png&#34; alt=&#34;图 3-5&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 3-5   VLAN ID 标记的帧显示在 Wireshark 中。默认的列和设置已被修改，以显示 VLAN ID 和原始以太网地址&lt;/p&gt;
&lt;p&gt;本图显示了一个在 VLAN 2 中传输的 ARP 分组（见第 4 章）。我们可以看到，该帧大小为 60 字节（不包括 CRC）。该帧用 Ethemet II 封装（类型 0x8100），表示一个 VLAN。另外，VLAN 头部表明该帧属于 VLAN 2，优先级为 0，并且是普通帧。其他字段如我们预期的是一个普通 ARP 分组。&lt;/p&gt;
&lt;h3 id=&#34;324-8021ax链路聚合以前的-8023ad&#34;&gt;3.2.4 802.1AX：链路聚合（以前的 802.3ad）&lt;/h3&gt;
&lt;p&gt;有些系统配备多个网络接口，具有 &lt;strong&gt;绑定（bonding）&lt;/strong&gt; 或 &lt;strong&gt;链路聚合&lt;/strong&gt; 能力。通过链路聚合，两个或更多接口被视为一个，通过冗余或将数据分割（分拆）到多个接口，提高性能并获得更好的可靠性。 IEEE修订的 802.1AX [&lt;a href=&#34;#802.1AX-2008&#34;&gt;802.1AX-2008&lt;/a&gt;] 定义了最常用的链路聚合方法，以及可管理这些链路的&lt;strong&gt;链路聚合控制协议（LACP）&lt;/strong&gt;。 LACP 使用一种特定格式的 IEEE 802 帧（称为LACPDU）。&lt;/p&gt;
&lt;p&gt;以太网交换机支持的链路聚合是一个替代方案，它比支持更高速网络接口的性价比高。如果多个端口聚合能提供足够的带宽，则可能并不需要高速接口。链路聚合不仅可被网络交换机支持，而且可在一台主机上跨越多个&lt;strong&gt;网络接口卡（NIC）&lt;/strong&gt;。在通常情况下，聚合的端口必须是同一类型，并工作在同一模式（半双工或全双工）下。&lt;/p&gt;
&lt;p&gt;Linux 可实现跨越不同类型设备的链路聚合（绑定），使用以下命令：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Linux# modporbe bonding
Linux# ifconfig bond0 10.0.0.111 netmask 255.255.255.128
Linux# ifenslave bond0 eth0 wlan0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这组命令中的第一个用于加载绑定驱动，它是一个支持链路聚合的特殊设备驱动程序。第二个命令使用 IPv4 地址来创建 bond0 接口。虽然 IP 相关信息对创建聚合接口不是必需的，但它是典型的。在 &lt;code&gt;ifenslave&lt;/code&gt; 命令执行后，绑定设备 bond0 用 MASTER 标志来标记，而设备 eth0 和 wlan0 用 SLAVE 标志来标记：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;bond0 Link encap:Ethernet HWaddr 00:11:A3:00:2C:2A
            inet addr:10.0.0.111 Bcast:10.0.0.127 Mask:255.255.255.128
            inet6 addr: fe80::211:a3ff:fe00:2c2a/64 Scope:Link
            UP BROADCAST RUNNING MASTER MULTICAST MTU:1500 Metric:1
            RX packets:2146 errors:0 dropped:0 overruns:0 frame:0
            TX packets:985 errors:0 dropped:0 overruns:0 carrier:O
            collisions:18 txqueuelen:0
            RX bytes:281939 (275.3 Kib) TX bytes:141391 (138.0 Kib)
eth0 Link encap:Ethernet HWaddr 00:11:A3:00:2C:2A
            UP BROADCAST RUNNING SLAVE MULTICAST MTU:1500 Metric:1
            RX packets:1882 errors:0 dropped:0 overruns:0 frame:0
            TX packets:961 errors:0 dropped:0 overruns:0 carrier:O
            collisions:18 txqueuelen:1000
            RX bytes:244231 (238.5 Kib) TX bytes:136561 (133.3 Kib)
            Interrupt:20 Base address:0x6c00
wlan0 Link encap:Ethernet HWaddr 00:11:A3:00:2C:2A
            UP BROADCAST RUNNING SLAVE MULTICAST MTU:1500 Metric:1
            RX packets:269 errors:0 dropped:0 overruns:0 frame:0
            TX packets:24 errors:0 dropped:0 overruns:0 carrier:O
            collisions:18 txqueuelen:1000
            RX bytes:38579 (37.6 Kib) TX bytes:4830 (4.7 Kib)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在这个例子中，我们将一个有线以太网接口和一个 Wi-Fi 接口绑定在一起。为主设备 bond0 分配了 IPv4 地址信息，通常分配给两个独立接口之一，它默认使用第一个从设备的 MAC 地址。当 IPv4 流量通过 bond0 虚拟接口发送时，很可能使用不同的从设备来发送。在 Linux 中，当绑定的驱动程序被加载时，可使用系统提供的参数选择选项。例如，模式选项决定了能否做以下工作：在接口之间使用循环交付，一个接口作为另一个接口的备份使用，基于对 MAC 源地址和目的地址执行的异或操作选择接口，将帧复制到所有接口，执行 802.3ad 标准的链路聚合，或采用更先进的负载平衡选项。第二种模式用于高可用性系统，当一个链路停止运行时（由 MII 监控来检测；更多细节见 [&lt;a href=&#34;#BOND&#34;&gt;BOND&lt;/a&gt;] ），这种系统将故障部分转移到冗余的网络基础设施上。第三种模式是基于流量的流向选择从接口。如果目的地完全不同，两个站之间的流量被固定到一个接口。在希望尽量少尝试重新排序，并保证多个接口负载平衡的情况下，这种模式可能是有效的。第四种模式针对容错。第五种模式用于支持 802.3ad 的交换机，在同类链路上实现动态聚合能力。&lt;/p&gt;
&lt;p&gt;LACP 协议旨在通过避免手工配置，以简化链路聚合的建立工作。在 LACP “主角” （客户端）和“参与者” （服务器）启用后，它们通常每秒都会发送 LACPDU。 LACP 自动确定哪些成员链路可被聚合成一个&lt;strong&gt;链路聚合组（LAG）&lt;/strong&gt;，并将它们聚合起来。这个过程的实现需要通过链路发送一系列信息（MAC地址、端口优先级、端口号和密钥）。一个接收站可比较来自其他端口的值，如果匹配就执行聚合。 LACP 协议的细节见[&lt;a href=&#34;#802.1AX-2008&#34;&gt;802.1AX-2008&lt;/a&gt;]。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;33-全双工-省电-自动协商和-8021x-流量控制&#34;&gt;3.3 全双工、省电、自动协商和 802.1X 流量控制&lt;/h2&gt;
&lt;p&gt;当以太网最初被开发出来时，它仅工作在半双工模式，并使用一条共享的电缆。也就是说，同一时间内只能在一个方向发送数据，因此在任何时间点只有一个站可发送一个帧。随着交换式以太网的发展，网络不再是单一的共享线路，而代之以很多链路的组合。因此，多个站之间可以同时进行数据交换。另外，以太网被修改为全双工操作，这样可以有效禁用冲突检测电路。这样也可以增加以太网的物理长度，因为半双工操作和冲突检测的相关时间约束被取消。&lt;/p&gt;
&lt;p&gt;在 Linux 中， &lt;code&gt;ethtool&lt;/code&gt; 程序可用于查询是否支持全双工，以及是否正在执行全双工操作。这个工具也可显示和设置以太网接口的很多属性：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Linux# ethtool eth0
Settings for eth0:
            Supported ports: [ TP MII ]
            supported link modes: 10baseT/Half 10baseT/Full
                                100baseT/Half 100baseT/Full
            Supports auto-negotiation: Yes
            Advertised link modes: 10baseT/Half 10baseT/Full
                                100baseT/Half 100baseT/Full
            Advertised auto-negotiation: Yes
            Speed: 10Mb/s
            Duplex: Half
            Port: MII
            PHYAD: 24
            Transceiver: internal
            Auto-negotiation: on
            Current message level: 0x00000001 (1)
            Link detected: yes
Linux# ethtool eth1
Settings for eth1:
            Supported ports: [ TP ]
            supported link modes: 10baseT/Half 10baseT/Full
                                100baseT/Half 100baseT/Full
                                1000baseT/Full
            Supports auto-negotiation: Yes
            Advertised link modes: 10baseT/Half 10baseT/Full
                                100baseT/Half 100baseT/Full
                                1000baseT/Full
            Advertised auto-negotiation: Yes
            Speed: 100Mb/s
            Duplex: Full
            Port: Twisted Pair
            PHYAD: 0
            Transceiver: internal
            Auto-negotiation: on
            Supports Wake-on: umbg
            Wake-on: g
            Current message level: 0x00000007 (7)
            Link detected: yes
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在这个例子中，第一个以太网接口（eth0）连接到一个半双工的 10Mb/s 网络。我们看到它能够&lt;strong&gt;自动协商&lt;/strong&gt;，这是一种来源于 802.3u 的机制，使接口能交换信息（例如速度）和功能（例如半双工或全双工运行）。自动协商信息在物理层通过信号交换，它可在不发送或接收数据时发送。我们可以看到，第二个以太网接口（eth1）也支持自动协商，它的速率为 100Mb/s，工作模式为全双工。其他值（Port、PHYAD、 Transceiver）指出物理端口类型、地址，以及物理层电路在 NIC 内部还是外部。当前消息级别用于配置与接口操作模式相关的日志消息，它的行为由使用的驱动程序指定。我们在下面的例子讨论如何设置这些值。&lt;/p&gt;
&lt;p&gt;在 Windows 中，我们可以看到以下细节，首先进入“控制面板”中的“网络连接”，然后在感兴趣的接口上单击鼠标右键并选择“属性”，然后单击“配置”框并选择“高级”选项卡。这时，将打开一个类似图 3-6 （这个例子来自 Windows 7 机器上的以太网接口）所示的对话框。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1652338313157.png&#34; alt=&#34;图 3-6&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 3-6   Windows (7) 的网络接口属性的“高级”选项卡。该控件允许用户提供网络设备驱动程序的运行参数&lt;/p&gt;
&lt;p&gt;在图 3-6 中，我们可看到通过适配器的设备驱动程序来配置的特殊功能。对于这个特殊的适配器和驱动程序， 802.1p/q 标签可启用或禁用，也可提供流量控制和唤醒功能（见 3.3.2 节）。我们可以手工设置速率和双工模式，或使用更典型的自动协商选项。&lt;/p&gt;
&lt;h3 id=&#34;331-双工不匹配&#34;&gt;3.3.1 双工不匹配&lt;/h3&gt;
&lt;p&gt;自动协商曾经有一些互操作性问题，特别是一台计算机及其相关的交换机端口使用不同的双工配置时，或者当自动协商只在链路的一端被禁用时。在这些情况下，可能会发生双工不匹配。令人惊讶的是，当这种状况发生时，连接不会完全失败，但可能带来显著的性能下降。当网络中出现中等程度的双向流量繁忙时（例如，在大数据传输期间），一个半双工接口会将输入的流量检测为冲突，从而触发以太网 MAC 的 CSMA/CD 的指数退避功能。同时，导致这个冲突的数据被丢弃，这可能需要更高层协议（例如 TCP）重传。因此，性能下降可能只在半双工接口发送数据，同时又有大量流量需要接收时才是明显的，站处于轻负载时通常不会发生这种情况。一些研究者已试图开发分析工具来检测这种问题 [&lt;a href=&#34;#SC05&#34;&gt;SC05&lt;/a&gt;]。&lt;/p&gt;
&lt;h3 id=&#34;332-局域网唤醒wol-省电和魔术分组&#34;&gt;3.3.2 局域网唤醒（WoL）、省电和魔术分组&lt;/h3&gt;
&lt;p&gt;在 Linux 和 Windows 的例子中，我们看到一些电源管理方面的功能。** Windows 唤醒功能**和 &lt;strong&gt;Linux 唤醒&lt;/strong&gt; 选项用于使网络接口或主机脱离低功耗（睡眠）状态，这是基于某类分组的传输来实现的。这种分组用来触发可配置的功率状态改变。在 Linux 中，用于唤醒的值可以是零，或者是多个用于低功耗状态唤醒的位，它们可以被以下几种帧所触发：任何物理层（PHY）活动（p）、发往站的单播帧（u）、组播帧（m）、广播帧（b）、 ARP 帧（a）、魔术分组帧（g），以及包括密码的魔术分组帧。这些都可以使用 &lt;code&gt;ethtool&lt;/code&gt; 的选项来配置。例如，可以使用以下命令：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Linux# ethtool -s eth0 wol umgb
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;当接收到任何 u、 m、 g 或 b 类型的帧时，这个命令将 eth0 设备配置为发送一个唤醒信号。Windows 提供了类似的功能，但标准的用户接口只支持魔术分组帧，以及一个预定义的 u、m、b和a类型帧的子集。魔术分组包含一个字节值 &lt;code&gt;0xFF&lt;/code&gt; 的特定重复模式。在通常情况下，这种帧采用 UDP 分组（见第 10 章）形式封装在以太网广播帧中发送。有几个工具可以生成它们，包括 wol [&lt;a href=&#34;#WOL&#34;&gt;WOL&lt;/a&gt;] ：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Linux# wol 00:08:74:93:C8:3C
Waking up 00:08:74:93:C8:3C...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这个命令的结果是构造一个魔术分组，我们可以使用 Wireshark 查看( 见图 3-7 )。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1652346183244.png&#34; alt=&#34;图 3-7&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 3-7   Wireshark 中的一个魔术分组帧，开始是 6 字节的 0xFF，然后重复 MAC 地址 16 次&lt;/p&gt;
&lt;p&gt;图 3-7 中显示的分组多数是传统的 UDP 分组，但端口号（1126 和 40000）是任意的。分组中最特别的是数据区域。它以一个 6 字节的值 0xFF 开始，其余部分包含重复 16 次的目的 MAC 地址&lt;code&gt;00:08:74:93:C8:3C&lt;/code&gt;。该数据的有效载荷模式定义了魔术分组。&lt;/p&gt;
&lt;h3 id=&#34;333-链路层流量控制&#34;&gt;3.3.3 链路层流量控制&lt;/h3&gt;
&lt;p&gt;以全双工模式运行扩展的以太网和跨越不同速率的网段时，可能需要由交换机将帧缓存（保存）一段时间。例如，当多个站发送到同一目的地（称为输出端口争用），这种情况可能发生。如果一个站聚合的流量速率超过该站的链路速率，那么帧就开始存储在中间交换机中。如果这种情况持续一段时间，这些帧可能被丢弃。&lt;/p&gt;
&lt;p&gt;缓解这种情况的一种方法是在发送方采取&lt;strong&gt;流量控制&lt;/strong&gt;（使它慢下来）。一些以太网交换机（和接口）通过在交换机和网卡之间发送特殊信号帧来实现流量控制。流量控制信号被发送到发送方，通知它必须放慢传输速率，但规范将这些细节留给具体实现来完成。以太网使用** PAUSE 消息（也称为PAUSE帧）**实现流量控制，它由 802.3x [&lt;a href=&#34;#802.3-2008&#34;&gt;802.3-2008&lt;/a&gt;] 来定义。&lt;/p&gt;
&lt;p&gt;PAUSE 消息包含在 MAC 控制帧中，通过将以太网&lt;strong&gt;长度/类型&lt;/strong&gt;字段值设为 &lt;code&gt;0x8808&lt;/code&gt;，以及使用 MAC 控制操作码 &lt;code&gt;0x0001&lt;/code&gt; 来标识。如果一个站接收到这种帧，表示建议它减缓发送速度。 PAUSE 帧总是被发送到 MAC 地址 &lt;code&gt;01:80:C2:00:00:01&lt;/code&gt;，并且只能在全双工链路上使用。它包含一个保持关闭（hold-off）时间值（指定量为 512 比特的时间），表明发送方在继续发送之前需要暂停多长时间。&lt;/p&gt;
&lt;p&gt;MAC 控制帧采用如图 3-3 所示的常规封装的帧格式，但紧跟在&lt;strong&gt;长度/类型&lt;/strong&gt;字段后的是一个 2 字节的操作码。 PAUSE 帧实际上是唯一一种使用 MAC 控制帧的帧类型。它包括一个 2 字节的保持关闭时间。 “整个” MAC 控制层（基本只是 802.3x 流量控制）的实现是可选的。&lt;/p&gt;
&lt;p&gt;以太网层次的流量控制可能有重大负面影响，因此通常并不使用它。当多个站通过一台过载的交换机发送时（见下一节），该交换机通常向所有主机发送 PAUSE 帧。不幸的是，交换机的内存使用可能对发送主机不均衡，因此有些主机可能被惩罚（流量控制），即使它们对交换机流量过载没有多少责任。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;34-网桥和交换机&#34;&gt;3.4 网桥和交换机&lt;/h2&gt;
&lt;p&gt;IEEE 802.1d 标准规定了网桥的操作，交换机本质上是高性能的网桥。网桥或交换机用于连接多个物理的链路层网络（例如一对物理的以太网段）或成组的站。最基本的设置涉及连接两个交换机来形成一个扩展的局域网，如图 3-8 所示。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;8&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1652347179551.png&#34; alt=&#34;图 3-8&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 3-8   一个包括两台交换机的扩展以太网。每个交换机端口有一个编号，每个站（包括每个交换机）有自己的 MAC 地址&lt;/p&gt;
&lt;p&gt;图中的交换机 A 和 B 互连形成一个扩展的局域网。在这个特定例子中，客户端系统都连接到 A，服务器都连接到 B，端口编号供参考。注意，每个网络单元（包括每个交换机）有自己的 MAC 地址。每个网桥经过一段时间对域外 MAC 地址的“学习”后，最终每个交换机会知道每个站可由哪个端口到达。每个交换机基于每个端口（也可能是每个 VLAN）的列表被存储在一张表（称为&lt;strong&gt;过滤数据库&lt;/strong&gt;）中。图 3-9 显示每个交换机了解每个站的位置后，形成的包含这些信息的数据库例子。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;9&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1652349458178.png&#34; alt=&#34;图 3-9&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;当第一次打开一个交换机（网桥）时，它的数据库是空的，因此它不知道除自己之外的任何站的位置。当它每次接收到一个目的地不是自己的帧时，它为除该帧到达的端口之外的所有端口做一个备份，并向所有端口发送这个帧的备份。如果交换机（网桥）未学习到站的位置，每个帧将会被交付到每个网段，这样会导致不必要的开销。学习能力可以显著降低开销，它是交换机和网桥的一个基本功能。&lt;/p&gt;
&lt;p&gt;目前，多数操作系统支持网络接口之间的网桥功能，这意味着具有多个接口的计算机可用作网桥。例如，在 Windows 中，多个接口可被桥接，进入“控制面板”的“网络连接”菜单，选中（突出显示）需要桥接的接口，点击鼠标右键，并选择“网桥连接”。这时，出现一个表示网桥功能的新图标。许多接口相关的正常网络属性消失，取而代之的是网桥设备（见图 3-10）。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;10&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1652350474031.png&#34; alt=&#34;图 3-10&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 3-10   在 Windows 中，通过选中需要桥接的网络接口，鼠标右击并选择桥接网络接口，可创建网桥设备。在网桥建立之后，可进一步修改网桥设备&lt;/p&gt;
&lt;p&gt;图 3-10 显示 Windows 7 中的虚拟网桥设备的属性面板。网桥设备的属性包括一个被桥接的相关设备列表，以及在网桥上运行的一组服务（例如， Microsoft网络客户端、文件和打印机共享等）。 Linux 以类似方式工作，它使用命令行参数。在这个例子中，我们使用图 3-11 所示的拓扑结构。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;11&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1652350584033.png&#34; alt=&#34;图 3-11&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 3-11   在这个简单的拓扑中，一台基于 Linux 的 PC 被配置为网桥，它在两个以太网之间实现互联。作为一个处于学习中的网桥，它不断积累并建立一些表，其中包含有关哪个端口可到达扩展局域网中的其他系统的信息&lt;/p&gt;
&lt;p&gt;在图 3-11 中，这个简单的网络使用一台基于 Linux、带两个端口的 PC 作为网桥。只有一个站连接到端口 2，网络其他部分都连接到端口 1。以下命令可启用网桥：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Linux# brctl addbr br0
Linux# brctl addif br0 eth0
Linux# brctl addif br0 eth1
Linux# ifconfig eth0 up
Linux# ifconfig eth1 up
Linux# ifconfig br0 up
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;以下几个命令可创建一个网桥设备 br0，并为网桥增加接口 eth0 和 eth1。 &lt;code&gt;brctl delif&lt;/code&gt; 命令可用于删除接口。在建立接口之后， &lt;code&gt;brctl showmacs&lt;/code&gt; 命令可用于检查过滤数据库（称为&lt;strong&gt;转发数据库&lt;/strong&gt;，用 Linux 的术语称为 fdbs）：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Linux# brctl show
bridge name  bridge id           STP     enabled     interfaces
br0          8000.0007e914a9cl   no       eth0          eth1
Linux# brctl showmacs br0
port no mac addr is local? ageing timer
1 00:04:5a:9f:9e:80 no 0.79
2 00:07:e9:14:a9:cl yes 0.00
1 00:08:74:93:c8:3c yes 0.00
2 00:14:22:f4:19:5f no 0.81
1 00:17:f2:e7:6d:91 no 2.53
1 00:90:f8:00:90:b7 no 17.13
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这个命令的输出显示关于网桥的其他细节。由于站可能出现移动、网卡更换、 MAC 地址改变或其他情况，所以就算网桥曾发现一个 MAC 地址可通过某个端口访问，这个信息也不能假设永远是正确的。为了解决这个问题，在每次学习一个地址后，网桥启动一个计时器（通常默认为5分钟）。在 Linux 中，每个学习条目使用一个与网桥相关的固定时间。如果在指定的“有效期”内，没有再次看到该条目中的地址，则将这个条目删除，如下所示：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Linux# brctl setageing br0 1
Linux# brctl showmacs br0
port no mac addr is local? ageing timer
1 00:04:5a:9f:9e:80 no 0.79
2 00:07:e9:14:a9:cl yes 0.00
1 00:08:74:93:c8:3c yes 0.00
2 00:14:22:f4:19:5f no 0.78
1 00:17:f2:e7:6d:91 no 0.00
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;为了方便演示，我们选择了一个比平时数值低的值作为&lt;strong&gt;有效期&lt;/strong&gt;。当一个条目因有效期满而被删除时，后续的帧将被发送到接收端口之外的所有端口（称为&lt;strong&gt;洪泛&lt;/strong&gt;），并更新过滤数据库中的这个条目。实际上，过滤数据库的使用和学习有利于优化性能，如果表是空的，网络将花费更多开销，但仍能履行职责。下一步，我们将注意力转移到两个以上的网桥通过冗余链路互联的情况。在这种情况下，帧的洪泛可能导致帧永远循环的洪泛灾难。显然，我们需要一种方法来解决这个问题。&lt;/p&gt;
&lt;h3 id=&#34;341-生成树协议&#34;&gt;3.4.1 生成树协议&lt;/h3&gt;
&lt;p&gt;网桥可能单独或与其他网桥共同运行。当两个以上的网桥使用（或交换机端口交叉连接）时，由于存在级联的可能性，因此可能形成很多组的循环帧。我们看如图 3-12 所示的网络。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;12&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1652351442343.png&#34; alt=&#34;图 3-12&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 3-12   一个扩展的以太网包括 4 台交换机和多条冗余链路。如果在这个网络中采用简单的洪泛转发帧，由于多余的倍增流量（所谓的广播风暴），将会导致一场大的灾难。这种情况需要使用 STP&lt;/p&gt;
&lt;p&gt;假设图 3-12 中的多个交换机刚被打开，并且它们的过滤数据库为空。当站 S 发送一个帧时，交换机 B 在端口 7、 8 和 9 复制该帧。这时，最初的帧已被“放大” 3 倍。这些帧被交换机 A、 D 和 C 接收。交换机 A 在端口 2 和 3 生成该帧的副本。交换机 D 和 C 分别在端口 20、 22 和 13、 14 生成更多副本。当这些副本在交换机 A、 C 和 D 之间双向传输，这时放大倍数已增大为6。 当这些帧到达时，&lt;br&gt;
转发数据库开始出现震荡，这是由于网桥反复尝试查找通过哪些端口可到达站 S。显然，这种情况是不能容忍的。如果允许这种情况发生，采用这种配置的网桥将无法使用。幸运的是，有一种协议可避免这种情况，这种协议称为&lt;strong&gt;生成树协议（STP）&lt;/strong&gt;。我们将介绍 STP 的一些细节，解释网桥和交换机采用哪些方法抑制放大。在当前的标准 [&lt;a href=&#34;#802.1D-2004&#34;&gt;802.1D-2004&lt;/a&gt;] 中，传统的 STP 被**快速生成树协议（RSTP）**代替，我们将在了解传统 STP 的基础上再介绍它。&lt;/p&gt;
&lt;p&gt;STP 通过在每个网桥禁用某些端口来工作，这样可避免拓扑环路（即两个网桥之间不允许出现重复路径），但如果拓扑结构未分区，则仍可到达所有站。在数学上，一个生成树是一张图中所有节点和一些线的集合，从任何节点到其他节点（跨越图）有一条路径或路由，但是没有环路（这些线的集合构成一棵树）。一张图可能存在多个生成树。 STP 用于找出这张图的其中一个生成树，该图将网桥作为节点并将链路作为线（或称“边”）。图 3-13 说明了这个想法。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;13&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1652352139379.png&#34; alt=&#34;图 3-13&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 3-13   通过 STP，链路 B-A、 A-C 和 C-D 在生成树中是活跃的。端口 6、7、 1、2、 13、14 和 20 处于转发状态；所有其他端口被阻塞（即不转发）。这样可以防止帧循环，避免广播风暴。如果配置发生变化或某台交换机故障，则将阻塞端口改变为转发状态，并由网桥计算一个新生成树&lt;/p&gt;
&lt;p&gt;在本图中，粗线表示网络中被 STP 选择用于转发帧的链路。其他链路没有被使用，端口 8、9、 12、21、22 和 3 被&lt;strong&gt;阻塞&lt;/strong&gt;。通过使用 STP，早期的各种问题并没有出现，这些帧只是作为另一个抵达帧的副本而被创建。这里没有出现放大的问题。由于任意两个站之间只有一条路径，因此可以避免循环。生成树的形成和维护由多个网桥完成，在每个网桥上运行一个分布式算法。&lt;/p&gt;
&lt;p&gt;用于转发数据库时， STP 必须处理以下情况，例如网桥启用和关闭、接口卡更换或 MAC 地址改变。显然，这种变化可能影响生成树运行，因此 STP 必须适应这些变化。这种适应通过交换一种称为**网桥协议数据单元（BPDU）**的帧来实现。这些帧用来形成和维护生成树。这棵树“生长”自一个网桥——该网桥由其他网桥选举为“根网桥”。&lt;/p&gt;
&lt;p&gt;如前所述，一个网络可能存在多个生成树。如何确定哪棵生成树最适于转发帧，这基于每条链路和根网桥位置的相关成本。这个成本是一个与链路速度成反比的整数（建议）。例如，一条 10Mb/s 链路的成本为 100， 100Mb/s 和 1000Mb/s 链路的成本分别为 19 和 4。 STP 计算到根网桥的成本最小的路径。如果必须遍历多条链路，相关成本是这些链路成本之和。&lt;/p&gt;
&lt;h4 id=&#34;3411-端口状态和角色&#34;&gt;3.4.1.1 端口状态和角色&lt;/h4&gt;
&lt;p&gt;为了理解 STP 的基本操作，我们需要了解网桥端口的状态机，以及 BPDU 内容。网桥端口可能有 5 个状态：阻塞、侦听、学习、转发和禁用。在图 3-14 所示的状态转换图中，我们可以看出它们之间的关系。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;14&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1652353538285.png&#34; alt=&#34;图 3-14&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 3-14   在正常的 STP 操作中，端口在 4 个主要状态之间转换。在阻塞状态下，帧不被转发，但一次拓扑变化或超时可能导致向侦听状态转换。转发状态是活跃的交换机端口承载数据流量的正常状态。括号中的状态名用于表示 RSTP 相关的端口状态&lt;/p&gt;
&lt;p&gt;在图 3-14 显示的生成树中，实线箭头表示端口的正常转换，小的虚线箭头表示由管理配置引起的改变。在初始化后，一个端口进入阻塞状态。在这种状态下，它不进行地址学习、数据转发或 BPDU 发送，但它会监控接收的 BPDU，并在它需要被包含在将到达的根网桥的路径中的情况下，使端口转换到侦听状态。在侦听状态下，该端口允许发送和接收 BPDU，但不进行地址学习或数据转发。经过一个典型的 15 秒的转发延迟，端口进入学习状态。这时，它被允许执行数据转发之外的所有操作。在进入转发状态并开始转发数据之前，需要等待另一个转发延迟。&lt;/p&gt;
&lt;p&gt;相对于端口状态机，每个端口都扮演一定的&lt;strong&gt;角色&lt;/strong&gt;。由于 RSTP （见 3.4.1.6 节）的出现，这个术语变得越来越重要。端口可能扮演&lt;strong&gt;根端口&lt;/strong&gt;、&lt;strong&gt;指定端口&lt;/strong&gt;、&lt;strong&gt;备用端口&lt;/strong&gt;或&lt;strong&gt;备份端口&lt;/strong&gt;等角色。根端口是生成树中位于指向根的线段终点的那些端口。指定端口是指处于转发状态，并与根相连线段中路径成本最小的端口。备用端口是与根相连线段中成本更高的端口。它们不处于转发状态。备份端口是指连接到同一线段中作为同一网桥指定端口使用的端口。因此，备份端口可轻易接管一个失效的指定端口，而不影响生成树拓扑的其余部分，但是它不能在全部网桥失效的情况下提供一条到根的备用路径。&lt;/p&gt;
&lt;h4 id=&#34;3412-bpdu-结构&#34;&gt;3.4.1.2 BPDU 结构&lt;/h4&gt;
&lt;p&gt;为了确定生成树中的链路， STP 使用图 3-15 所示的 BPDU。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;15&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1652354174126.png&#34; alt=&#34;图 3-15&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 3-15   BPDU 被放置在 802 帧的有效载荷区，并在网桥之间交换以建立生成树。重要的字段包括源、根节点、到根的成本和拓扑变化提示。在 802.1w 和 [&lt;a href=&#34;#802.1D-2004&#34;&gt;802.1D-2004&lt;/a&gt;] 中（包括快速 ST P或 RSTP），附加字段显示端口状态&lt;/p&gt;
&lt;p&gt;图 3-15 所示的格式适用于最初的 STP，以及新的 RSTP （见 3.4.1.6 节）。 BPDU 总被发送到组地址 &lt;code&gt;01:80:C2:00:00:00&lt;/code&gt; （链路层组和因特网组播寻址的详细信息见第 9 章），并且不会通过一个未修改的网桥转发。在该图中， DST、 SRC 和 L/T （长度/类型）字段是携带 BPDU 的传统以太网（802.3）帧头部的一部分。 3 字节的 LLC/SNAP 头部由 802.1 定义，并针对 BPDU 被设置为常数 &lt;code&gt;0x424203&lt;/code&gt;。并非所有 BPDU 都使用 LLC/SNAP 封装，但这是一个常见的选项。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;协议（Prot）&lt;/strong&gt; 字段给出协议 ID 号，它被设置为 0。&lt;strong&gt;版本（Vers）&lt;/strong&gt; 字段被设置为 0 或 2，取决于使用 STP 还是 RSTP。&lt;strong&gt;类型（rtype）&lt;/strong&gt; 字段的分配与版本类似。&lt;strong&gt;标志（Flags）&lt;/strong&gt; 字段包含&lt;strong&gt;拓扑变化（TC）&lt;/strong&gt; 和 &lt;strong&gt;拓扑变化确认（TCA）&lt;/strong&gt; 位，它们由最初的 802.1d 标准定义。附加位被定义为 &lt;strong&gt;建议（P）&lt;/strong&gt;、&lt;strong&gt;端口角色（00 为未知， 01 为备用， 10 为根， 11 为指定）&lt;/strong&gt;、&lt;strong&gt;学习（L）&lt;/strong&gt;、&lt;strong&gt;转发（F）&lt;strong&gt;和&lt;/strong&gt;协议（A）&lt;/strong&gt;。这些都作为 RSTP 内容在 3.4.1.6 节中讨论。根 ID 字段给出发送方使用的根网桥标识符，即从网桥 ID 字段中获得的 MAC 地址。这些 ID 字段都用一种特殊方式编码，包括 MAC 地址之前的一个 2 字节的优先级字段。优先级的值可通过管理软件来设置，以强制要求生成树采用某个特定网桥作为根（例如， Cisco 在自己的 Catalyst 交换机中使用默认值 &lt;code&gt;0x8000&lt;/code&gt;）。&lt;/p&gt;
&lt;p&gt;根路径成本是在 &lt;strong&gt;根 ID&lt;/strong&gt; 字段中指定的计算出的到达某个网桥的成本。 PID 字段是端口标识符和由发送帧给出的端口号，它被附加在一个可配置的 1 字节的&lt;strong&gt;优先级&lt;/strong&gt;字段（默认为 &lt;code&gt;0x80&lt;/code&gt;）之后。&lt;strong&gt;消息有效期（MsgA）&lt;/strong&gt; 字段指出消息有效期。&lt;strong&gt;最大有效期（MaxA）&lt;/strong&gt; 字段指出超时（默认为 20 秒）的最大期限。&lt;strong&gt;欢迎时间（HelloTime）&lt;/strong&gt; 字段指出配置帧的传输周期。&lt;strong&gt;转发延迟&lt;/strong&gt;字段指出处于学习和侦听状态的时间。所有的有效期和时间字段可在 1/256 秒内获得。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;消息有效期&lt;/strong&gt;字段不像其他的时间字段那样是固定值。当根网桥发送一个 BPDU 时，它将该字段设置为 0。 网桥转发接收到的不是根端口的帧，并将&lt;strong&gt;消息有效期&lt;/strong&gt;字段加1。从本质上来说，该字段是一个跳步计数器，用于记录 BPDU 经过的网桥数量。当一个 BPDU 被一个端口接收时，其包含的信息在内存和 STP 算法参与者中被保存至超时（超时发生在（MaxA-MsgA）时刻）。如果超过这个时间，根端口没有接收到另一个 BPDU，根网桥被宣布“死亡”，并重新开始根网桥选举过程。&lt;/p&gt;
&lt;h4 id=&#34;3413-建立生成树&#34;&gt;3.4.1.3 建立生成树&lt;/h4&gt;
&lt;p&gt;STP 的第一个工作是选举根网桥。根网桥是在网络（或 VLAN）中标识符最小（优先级与 MAC 地址结合）的网桥。当一个网桥初始化时，它假设自己是根网桥，并用自己的网桥 ID 作为根 ID 字段的值发送配置 BPDU 消息，如果它检测到一个 ID 更小的网桥，则停止发送自己的帧，并基于接收到的 ID 更小的帧构造下一步发送的 BPDU。发出根 ID 更小的 BPDU 的端口被标记为根端口（即端口在到根网桥的路径上）。剩余端口被设置为阻塞或转发状态。&lt;/p&gt;
&lt;h4 id=&#34;3414-拓扑变化&#34;&gt;3.4.1.4 拓扑变化&lt;/h4&gt;
&lt;p&gt;STP 的另一个重要工作是处理拓扑变化。虽然可用前面所述的数据库有效期机制适应拓扑变化，但这是一个比较差的方法，因为有效期计时器需要花费很长时间（5分钟）删除错误条目。相反， STP 采用一种方法检测拓扑变化，并快速通知它们所在的网络。在 STP 中，当一个端口进入阻塞或转发状态时，意味着发生拓扑变化。当网桥检测到一个连接变化（例如一条链路故障），它向根端口之外的端口发送&lt;strong&gt;拓扑变化通知（TCN）&lt;/strong&gt; BPDU，通知自己在树中的父网桥，直到根为止。树中通向根的下一个网桥向发送通知的网桥确认 TCN BPDU，并将它们转发到根。当接收到拓扑变化通知时，根网桥在后续的周期性配置消息中设置 TC 位。这种消息被网络中的每个网桥所转发，并被处于阻塞或转发状态的端口接收。设置这个位允许网桥减小转发延时计时器的有效期，将有效期以秒代替推荐的 5 分钟。这样，数据库中已有的错误条目可被快速清除和重新学习，同时允许访问那些被误删除的条目。&lt;/p&gt;
&lt;h4 id=&#34;3415-例子&#34;&gt;3.4.1.5 例子&lt;/h4&gt;
&lt;p&gt;在 Linux 中，网桥功能默认禁用 STP。假设在多数情况下拓扑相对简单，一台普通计算机可被用作网桥。可执行以下命令为当前使用的网桥启用 STP：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Linux# brctl stp br0 on
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;执行该命令的结果如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Linux# brctl stp br0 on
br0
bridge id       8000.0007e914a9c1
designated root     8000.0007e914a9c1
root port       0       path cost       0
max age     19.99       bridge max age      19.99
hello time      1.99        bridge hello time       1.99
forward delay       14.99       bridge forward delay        14.99
ageing time     0.99
hello timer     1.26        tcn timer       0.00
topology change timer       3.37        gc timer        3.26
flags       TOPOLOGY_CHANGE TOPOLOGY_CHANGE_DETECTED

eth0 (0)
port id       0000      state       forwarding
designated root     8000.0007e914a9c1       path cost       100
designated bridge     8000.0007e914a9c1     message age timer       0.00
designated port       8001       forward delay timer 0.00

designated cost       0       hold timer 0.26

flags

eth1 (0)
port id       0000      state       forwarding
designated root     8000.0007e914a9c1       path cost       19
designated bridge     8000.0007e914a9c1     message age timer       0.00
designated port       8002       forward delay timer 0.00
designated cost       0       hold timer 0.26

flags
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们看到一个简单的桥接网络的 STP 设置。网桥设备 br0 保存网桥的整体信息。这些信息包括网桥 ID （8000.0007e914a9cl），它由图 3-11 中基于 PC 的网桥（端口 1）的最小 MAC 地址生成。可在几秒钟内获得主要的配置参数（例如欢迎时间、拓扑变化计时器等）。标志值表示最近的拓扑变化，用于获得最近的网络连接变化的实际情况。输出的其余部分描述每个端口的信息，即 eth0（网桥端口 1）和 eth1（网桥端口 2）。注意， eth0 的路径成本大约是 eth1 成本的 10 倍。这个结果与 eth0 是一个 10Mb/s 以太网而 eth1 是一个100Mb/s 全双工网络是一致的。&lt;/p&gt;
&lt;p&gt;我们可使用 Wireshark 查看一个BPDU。在图 3-16 中，我们看到一个 52 字节的消息内容。消息长度为 52 字节（由于 Linux 捕获功能会拆除填充，因此它小于以太网的 64 字节的最小限制），这个长度是由以太网头部中的&lt;strong&gt;长度/类型&lt;/strong&gt;字段加 14 得到的。目的地址是预期的组地址 &lt;code&gt;01:80:C2:00:00:00&lt;/code&gt;。有效载荷长度是 38 字节，这个值包含在&lt;strong&gt;长度&lt;/strong&gt;字段中。 SNAP/LLC字段包含常数 &lt;code&gt;0x424243&lt;/code&gt;，并且封装帧是一个生成树（版本 0）帧。其余协议字段表明站 &lt;code&gt;00:07:e9:14:a9:c1&lt;/code&gt; 认为自己是生成树的根，优先级为 32768 （低优先级），并且 BPDU 从端口 2 以优先级 &lt;code&gt;0x80&lt;/code&gt; 发送。另外，最大有效期是 20 秒，欢迎时间是 2 秒，转发延迟是 15 秒。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;16&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1652356336887.png&#34; alt=&#34;图 3-16&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 3-16   Wireshark 显示一个 BPDU。以太网帧的目的地址是一个通过网桥（&lt;code&gt;01:80:C2:00:00:00&lt;/code&gt;）的组地址&lt;/p&gt;
&lt;h4 id=&#34;3416-快速生成树协议以前的-8021w&#34;&gt;3.4.1.6 快速生成树协议（以前的 802.1w）&lt;/h4&gt;
&lt;p&gt;传统 STP 的问题之一是在拓扑变化之后，只能通过一定时间内未接收到 BPDU 来检测。如果这个超时很大，收敛时间（沿着生成树重新建立数据流的时间）可能比预期大。 IEEE 802.1w标准（[&lt;a href=&#34;#802.1D-2004&#34;&gt;802.1D-2004&lt;/a&gt;] 的一部分）改进了传统 STP，它定义了采用新名称的 &lt;strong&gt;快速生成树协议（Rapid Sparming Tree Protocol， RSTP）&lt;/strong&gt; 。在 RSTP 中，对 STP 的主要改进是监视每个端口的状态，并在故障时立即发送一个拓扑变化通知。另外， RSTP 使用 BPDU 的标志字段中的全部 6 位来支持网桥之间的协议，以避免由计时器来启动协议操作。它将正常的 STP 端口状态由 5 个减少到 3 个（丢弃、学习和转发，由图 3-14 的括号中的状态名表示）。 RSTP 的丢弃状态代替了传统 STP 的禁止、阻塞和侦听状态。 RSTP 创建了一个称为&lt;strong&gt;备用端口&lt;/strong&gt;的新角色，作用是在根端口停止运行时立即代替它。&lt;/p&gt;
&lt;p&gt;由于 RSTP 只使用一种类型的 BPDU，因此这里没有专门的拓扑变化 BPDU。正如所说的那样， RSTP 的 BPDU 使用版本和类型号 2 而不是 0。在 RSTP 中，检测到一次拓扑变的交换机会发送一个表示拓扑变化的 BPDU，任何接收到它的交换机立即清除自己的过滤数据库。这个改变可显著影响协议的收敛时间。这时，无须等待拓扑变化传递到根网桥再经过转发延迟后返回，而是立即清除相关条目。总之，在大多数情况下，收敛时间可从几十秒减少到几分之一秒。&lt;/p&gt;
&lt;p&gt;RSTP 使&lt;strong&gt;边缘端口&lt;/strong&gt;（只连接到端站的端口）和正常的生成树端口之间，以及点到点链路和共享链路之间都有区别。边缘端口和点到点链路上的端口通常不会形成循环，因此允许它们跳过侦听和学习状态，直接进入转发状态。当然，如果假设一个边缘端口可能被入侵，例如两个端口交叉连接，它们可携带任何形式的BPDU （简单的端站通常不处理 BPDU），这时它们将被重新分类为生成树端口。点到点链路可根据接口操作模式来识别。如果这个接口运行在全双工模式下，则这条链路是点到点链路。&lt;/p&gt;
&lt;p&gt;在普通的 STP 中， BPDU 通常由一个通知网桥或根网桥来转发。在 RSTP 中， BPDU 为了“保持活跃”而由所有网桥来定期发送，以便确定相连的邻居是否正常运行。大多数高层路由协议也会这样做。注意，在 RSTP 中，拓扑变化没有像普通 STP 那样包括边缘端口连接或断开。当检测到一次拓扑变化时，通知网桥发送 TC 位被设置的 BPDU，不仅到根网桥而且到所有网桥。这样做允许将拓扑变化通知整个网络，并且比传统 STP 更快速。当一个网桥接收到这些消息时，它会更新除边缘端口之外的所有相关条目。&lt;/p&gt;
&lt;p&gt;RSTP 的很多功能由 Cisco 和其他公司开发，他们有时需要在自己的产品中为普通 STP做专门的扩展。 IEEE 委员会将这些扩展纳入 802.1d 标准的更新中，该标准涵盖所有类型的 STP，因此扩展局域网可在某些网段中运行传统 STP，同时在其他部分中运行 RSTP （虽然 RSTP 的优势将丧失）。 RSTP 已被扩展到 VLAN [&lt;a href=&#34;#802.1Q-2005&#34;&gt;802.1Q-2005&lt;/a&gt;] 中，它采用一种称为多生成树协议（MSTP）的协议。这个协议保留了RSTP （和 STP）报文格式，因此它有可能做到向后兼容，也支持形成多个生成树（每个 VLAN 一个生成树）。&lt;/p&gt;
&lt;h3 id=&#34;342-8021ak多注册协议&#34;&gt;3.4.2 802.1ak：多注册协议&lt;/h3&gt;
&lt;p&gt;**多注册协议（Multiple Registration Protocol， MRP）**提供了在桥接局域网环境中的站之间注册属性的通用方法。 [&lt;a href=&#34;#802.1ak-2007&#34;&gt;802.1ak-2007&lt;/a&gt;]定义了两个特殊的 MRP “应用程序”，称为 MVRP（用于注册 VLAN）和 MMRP （用于注册组 MAC 地址）。 MRP 代替了早期的 GARP 框架;MVRP 和 MMRP 分别代替了旧的 GVRP 和 GMRP 协议。这些协议最初都由 802.1q 定义。&lt;/p&gt;
&lt;p&gt;在使用 MVRP 时，当一个站被配置为一个 VLAN 成员时，该信息被传输到它所连接的交换机，并由该交换机将站加入 VLAN 通知其他交换机。这允许交换机根据站的 VLAN ID 添加自己的过滤表，也允许 VLAN 拓扑变化不必通过 STP 而重新计算现有生成树。避免重新计算 STP 是从 GVRP 向 MVRP 迁移的原因之一。&lt;/p&gt;
&lt;p&gt;MMRP 是一个站注册其感兴趣的组 MAC 地址（组播地址）的方法。这个信息可能被用于交换机建立端口，组播流量必须通过该端口来交付。如果没有这样的功能，交换机将不得不广播所有的组播流量，这样可能导致不必要的开销。 MMRP 是一个第 2 层协议，它与第 3 层协议 IGMP 和 MLD 相似，并在很多交换机中支持“  IGMP/MLD 探听”能力。我们将在第 9 章讨论 IGMP、MLD 和探听。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;35-无线局域网ieee-80211wi-fi&#34;&gt;3.5 无线局域网——IEEE 802.11（Wi-Fi）&lt;/h2&gt;
&lt;p&gt;目前，&lt;strong&gt;无线保真（Wi-Fi）&lt;/strong&gt; 是访问 Intemet 的最流行技术之一，其众所周知的 IEEE 标准名称为 802.11，它是一种常用的无线以太网标准。 Wi-Fi 已发展成为一种廉价、高效、便捷的方式，为大多数应用提供可接受的连通性和性能。 Wi-Fi 网络很容易建立。当前多数的便携式电脑和智能手机包含接入 Wi-Fi 基础设施的必要硬件。很多咖啡馆、机场、宾馆和其他公共设施提供了 Wi-Fi “热点”， Wi-Fi 在那些可能难以提供其他基础设施的发展中国家发展甚至更快。图 3-17 显示了 IEEE 802.11 网络体系结构。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;17&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1652419793689.png&#34; alt=&#34;图 3-17&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 3-17   一个无线局域网的 802.11 术语。接入点可采用一种分布式服务（一个无线或有线的主干）来连接，以形成一个扩展的无线局域网（称为一个 ESS）。站（包括 AP 和移动设备）之间的通信构成一个基本服务集。在通常情况下，每个 ESS 有一个指定的 ESSID，它的功能是作为一个网络的名称&lt;/p&gt;
&lt;p&gt;图 3-17 中的网络包括多个&lt;strong&gt;站（STA）&lt;/strong&gt;。在通常情况下，站和&lt;strong&gt;接入点（AP）&lt;strong&gt;组成一个操作子集。一个 AP 和相关的站被称为一个&lt;/strong&gt;基本服务集（BSS）&lt;/strong&gt;。 AP 之间通常使用一种有线的&lt;strong&gt;分布式服务&lt;/strong&gt;（称为 DS，基本是“主干”）连接，形成一个&lt;strong&gt;扩展服务集（ESS）&lt;/strong&gt;。这种方式通常被称为&lt;strong&gt;基础设施模式&lt;/strong&gt;。 802.11 标准也提供了一种 Ad hoc （自组织）模式。在这种配置中没有 AP 或 DS，而是直接采用站到站（对等）的通信。在 IEEE 的术语中，加入一个 Ad hoc 网络的 STA 形成一个&lt;strong&gt;独立基本服务集（IBSS）&lt;/strong&gt;。由 BSS 或 IBSS 的集合形成的无线局域网称为&lt;strong&gt;服务集&lt;/strong&gt;，它由一个**服务集标识符（SSID）**来标识。**扩展服务集标识符（ESSID）**是由 SSID 命名的一个 BSS 集合，它实际上是一个最长 32 个字符的局域网名称。在 WLAN 第一次建立时，该名称通常分配给 AP。&lt;/p&gt;
&lt;h3 id=&#34;351-80211-帧&#34;&gt;3.5.1 802.11 帧&lt;/h3&gt;
&lt;p&gt;802.11 网络有一个常见的总体框架，但包括多种类型的帧格式。每种类型的帧不一定包含所有字段。图 3-18 显示了常见帧格式和（最大尺寸的）数据帧。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;18&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1652420491239.png&#34; alt=&#34;图 3-18&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 3-18   802.11 基本数据帧格式（见 [&lt;a href=&#34;#802.11n-2009&#34;&gt;802.11n-2009&lt;/a&gt;]）。 MPDU 格式类似于以太网，但取决于接入点之间使用的 DS 类型：帧是发送到 DS 还是来自它，以及帧是否被聚合。 QoS 控制字段用于特殊功能， HT 控制字段用于控制 802.11n 的“高吞吐量”功能&lt;/p&gt;
&lt;p&gt;图 3-18 所示的帧包括一个用于同步的前导码，它取决于正在使用的 802.11 协议类型。接下来，**物理层会聚程序（PLCP）**头部以独立于物理层的方式提供特定的物理层信息。帧的 PLCP 部分的传输速率通常比其余部分低。这样做有两个目的：提高正确交付的概率（较低速度通常具有更好的容错性能），提供对传统设备的兼容性和防止慢速操作的干扰。帧的 MAC PDU（MPDU）与以太网相似，但是有一些额外的字段。&lt;/p&gt;
&lt;p&gt;MPDU 以帧控制字开始，其中包括 2 位的&lt;strong&gt;类型&lt;/strong&gt;字段，用于识别该帧的类型。这里有三种类型的帧：&lt;strong&gt;管理帧&lt;/strong&gt;、&lt;strong&gt;控制帧&lt;/strong&gt;和&lt;strong&gt;数据帧&lt;/strong&gt;。每种类型有不同的子类型。 [&lt;a href=&#34;#802.11n-2009&#34;&gt;802.11n-2009，表 7-1&lt;/a&gt;]给出了有关类型和子类型的完整列表。剩余字段由帧类型（如果有的话）来决定，后面将单独讨论。&lt;/p&gt;
&lt;h4 id=&#34;3511-管理帧&#34;&gt;3.5.1.1 管理帧&lt;/h4&gt;
&lt;p&gt;管理帧用于创建、维持、终止站和接入点之间的连接。它们也被用于确定是否采用加密，传输网络名称（SSID 或 ESSID），支持哪种传输速率，以及采用的时间数据库等。当一个 Wi-Fi 接口“扫描”临近的接入点时，这些帧被用于提供必要的信息。&lt;/p&gt;
&lt;p&gt;扫描是一个站发现可用的网络及相关配置信息的过程。这涉及每个可用频率和流量的侦听过程，以确定可用的接入点。一个站可以主动探测网络，在扫描时传输一个特殊的管理帧（“探测请求”）。这些探测请求有一定的限制，以保证 802.11 流量不在非 802.11 （例如医疗服务）频率上传输。下面是在 Linux 系统中手工启动扫描的例子：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Linux# iwlist wlan0 scan
wlan0 Scan completed :
                Cell 01 - Address: 00:02:6F:20:B5:84
                        ESSID: &amp;quot;Grizzly-5354-Aries-802.11b/g&amp;quot;
                        Mode:Master
                        Channel:4
                        Frequency:2.427 GHz (Channel 4)
                        Quality=5/100 Signal level=47/100
                        Encryption key:on
                        IE : WPA Version 1
                            Group Cipher : TKIP
                            Pairwise Ciphers (2) : CCMP TKIP
                            Authentication Suites (1) : PSK
                        Bit Rates:1 Mb/s; 2 Mb/s; 5.5 Mb/s; 11 Mb/s;
                                6 Mb/s; 12 Mb/s; 24 Mb/s; 36 Mb/s; 9 Mb/s;
                                18 Mb/s; 48 Mb/s; 54 Mb/s
                        Extra:tsf=0000009d832ff037
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里，我们看到在无线接口 wlan0 上手工启动扫描的结果。一个 MAC 地址为 &lt;code&gt;00:02:6F:20:B5:84&lt;/code&gt;的 AP 作为主角（即在基础设施模式中作为 AP）工作。它在信道 4 （2.427GHz）上广播 ESSID “Grizzly-5354-Aries-802.11b/g” （更多细节见 3.5.4 节讨论信道和频率时对信道选择的描述）。信号质量和强度决定执行扫描的站从 AP 接收信号的好坏，但相应值的含义可能因设备生产商而不同。 WPA 加密被用于这种链路（见3.5.5节），传输速率从 1Mb/s 到 54Mb/s 不等。 &lt;strong&gt;tsf（时间、同步、功能）&lt;/strong&gt; 的值表示 AP 的时间概念，它被用于需要同步的各种功能，例如省电模式（见3.5.2节）。&lt;/p&gt;
&lt;p&gt;当一个 AP 广播它的 SSID 时，任何站可尝试与 AP 建立连接。当一个连接建立时，大多数 Wi-Fi 网络会提供必要的配置信息，以便为站提供 Internet 接入（见第 6 章）。但是， AP 的运营商可能希望控制使用网络的站。有些运营商故意使连接变得更困难， AP 不广播其 SSID 被作为一项安全措施。这种方法提供了有限的安全性，这是由于 SSID 可以被猜测。链路加密和密码可提供更可靠的安全性，我们将在 3.5.5 节讨论。&lt;/p&gt;
&lt;h4 id=&#34;3512-控制帧rtscts-和-ack&#34;&gt;3.5.1.2 控制帧：RTS/CTS 和 ACK&lt;/h4&gt;
&lt;p&gt;控制帧与帧确认被用于一种流量控制方式。流量控制有助于接收方使一个过快的发送方降低发送速度。帧确认有助于发送方知道哪些帧已正确接收。这些概念也适用于传输层的 TCP 协议（见第15章）。 802.11 网络支持可选的&lt;strong&gt;请求发送/明确发送（RTS/CTS）&lt;/strong&gt;，通过放缓传输来进行流量控制。当 RTS/CTS 启用时，一个站在发送数据帧之前发送一个 RTS 帧，当接收方愿意接收额外的流量时，它会响应一个 CTS 帧。在 RTS/CTS 交换之后，这个站开启一个时间窗口（在 CTS 帧中标识），用于向确认接收的站发送数据帧。这种协同传输方法在无线网络中是常见的，模拟流量控制信号多年前已被用于有线的串行线路（有时称为硬件流量控制）。&lt;/p&gt;
&lt;p&gt;RTS/CTS 交换有助于避免隐藏终端问题，通过在允许发送时对每个站加以指导，以便发现对方站同时进行的传输。由于 RTS 和 CTS 帧比较短，因此它们不会长期使用信道。如果一个分组的大小足够大， AP 通常为每个分组启动一次 RTS/CTS 交换。在通常情况下， AP 提供一个称为&lt;strong&gt;分组大小阈值&lt;/strong&gt;（或类似）的配置选项。超过阈值的帧将会导致一个 RTS 帧优先于数据帧发送。如果需要执行 RTS/CTS 交换，大多数设备生产商设置的默认值为 500 字节。在 Linux 中， RTS/CTS 阈值可通过以下方式设置：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Linux# iwconfig wlan0 rts 250
wlan0 IEEE 802.11g ESSID:&amp;quot;Grizzly-5354-Aries-802.11b/g&amp;quot;
        Mode : Managed
        Frequency:2.427 GH
        Access Point: 00:02:6F:20:B5:84
        Bit Rate=24 Mb/s Tx-Power=0 dBm
        Retry min limit:7 RTs   thr=250 B    Fragment thr=2346 B
        Encryption key:xxxx- ... 一xxxx [3]
        Link Quality=100/100    Signal level=46/100
        Rx invalid nwid:0    Rx invalid crypt:0    Rx invalid frag:0
        Tx excessive retries:0    Invalid misc:0    Missed beacon:0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;iwconfig&lt;/code&gt; 命令可用于设置多种变量，包括 RTS 和分片阈值（见 3.5.1.3 节）。它也可用于确定统计数据，例如错误的网络 ID （ESSID）或加密密钥而导致的帧出错数量。它也可用于给出过多的重试次数（即重传次数），这是一个用于衡量链路可靠性的粗略指标，在无线网络中常用于指导路由决策 [&lt;a href=&#34;#ETX&#34;&gt;ETX&lt;/a&gt;]。在覆盖范围有限的 WLAN 中，隐藏终端问题通常很少发生，可将站的 RTS 阈值设置为很大（1500 或更大）来禁用 RTS/CTS。这可避免每个分组执行 RTS/CTS 交换带来的开销。&lt;/p&gt;
&lt;p&gt;在有线的以太网中，冲突较少意味着正确接收帧的概率较高。在无线网络中，更多的因素导致帧交付可能出错，例如信号不够强或受到干扰。为了帮助解决这些潜在问题， 802.11 采用一种重传/确认（ACK）方法来扩展 802.3 重传机制。确认是对预期在一定时间内接收的一个单播帧（802.11a/b/g）或一组帧（802.11n 或带“块确认”的 802.11e）的响应。组播或广播帧没有相关的确认，以避免出现“ACK爆炸”问题（见第 9 章）。在指定时间内没有接收到对应的 ACK 会导致帧的重传。&lt;/p&gt;
&lt;p&gt;重传可能在网络中形成重复的帧。当任何帧是某个帧的一次重传时，&lt;strong&gt;帧控制字&lt;/strong&gt;中的 &lt;strong&gt;重试（Retry）&lt;/strong&gt; 位需要设置为相应的值。接收站可通过它删除重复的帧。每个站需要保持一个小的缓存条目，以说明最近查看的地址和序列号/分片号。当一个接收帧与一个条目匹配时，则丢弃该帧。&lt;/p&gt;
&lt;p&gt;发送一个帧和接收一个 ACK 所需时间与链路距离和&lt;strong&gt;时隙&lt;/strong&gt;（802.11 MAC 协议的一个基本时间单位，见 3.5.3 节）相关。在大多数系统中，可配置等待的 ACK 时间（以及时隙），我们可采用不同方法完成配置。在大多数情况下，例如在家庭或办公室中使用，默认值是足够的。在长距离的 Wi-Fi 中，这些值可能需要调整（例如见 [&lt;a href=&#34;#MWLD&#34;&gt;MWLD&lt;/a&gt;] ）。&lt;/p&gt;
&lt;h4 id=&#34;3513-数据帧-分片和聚合&#34;&gt;3.5.1.3 数据帧、分片和聚合&lt;/h4&gt;
&lt;p&gt;在一个繁忙的网络中看到的帧大多数是数据帧，它们如大家所期望的那样携带数据。在通常情况下， 802.11 帧和链路层（LLC）帧之间存在一对一关系，它们保证更高层协议（例如 IP）是可用的。但是，802.11 支持帧&lt;strong&gt;分片&lt;/strong&gt;，可将一个帧分为多个分片。根据 802.11n 的规定，它也支持帧聚合，可将多个帧合并发送以减少开销。&lt;/p&gt;
&lt;p&gt;当使用帧分片时，每个分片有自己的 MAC 头部和尾部的 CRC，并且它们独立于其他分片处理。例如，到不同目的地的分片可以交错。当信道有明显的干扰时，分片有助于提高性能。除非使用块确认功能，否则每个分片将被单独发送，并由接收方为每个分片产生一个 ACK。 由于分片小于全尺寸的帧，如果需要启动一次重传，则只需要重传少量数据。&lt;/p&gt;
&lt;p&gt;分片仅用于目的地址为单播（非广播或组播）的帧。为了具备这种能力，顺序控制字段包含一个&lt;strong&gt;分片号&lt;/strong&gt;（4 位）和一个&lt;strong&gt;序列号&lt;/strong&gt;（12 位）。如果一个帧经过分片，所有分片包含相同的序列号值，而每个相邻的分片的分片号之差为 1。 由于分片号字段长度为 4 位，同一帧最多可能有 15 个分片。&lt;strong&gt;帧控制字&lt;/strong&gt;中的&lt;strong&gt;更多标志&lt;/strong&gt;字段表示更多分片还没有到达。最后一个分片将这个位设置为 0。接收方将接收到的同一序列号的分片根据分片号重组成原始帧。当所有包含同一序列号的分片被接收，并且最后一个分片将更多标志字段设为 0 时，这个帧被重组并交给更高层协议来处理。&lt;/p&gt;
&lt;p&gt;分片并不常使用，因为它需要经过调整。如果不调整就使用，可能导致性能下降。当帧大小更小的情况下，出现位差错的概率（参见下一段）更小。分片大小通常可设为 256 字节至 2048 字节，并作为一个阈值（只有那些超过阈值的帧才被分片）。很多 AP 通常设置更高的阈值（例如 Linksys 品牌 AP 的 2437 字节），这样就会默认不使用分片。&lt;/p&gt;
&lt;p&gt;分片有用的原因在于其出错的概率。如果 &lt;strong&gt;误码率（Bit Error Rate， BER）&lt;/strong&gt; 为 P， 1 位数据成功交付的概率为 &lt;code&gt;(1-P)&lt;/code&gt; ， N 位成功交付的概率为 (1-P)&lt;sup&gt;N&lt;/sup&gt; 。随着 N 的增长，这个值逐渐减小。因此，如果我们减小一个帧的大小，理论上可改善错误交付的概率。当然，如果我们将一个 N 位大小的帧分成 K 个分片，我们可发送至少 &lt;code&gt;N/K&lt;/code&gt; 个分片。我们给出一个具体的例子，假设要发送一个 1500 字节（12000 位）的帧。如果假设 P= 10&lt;sup&gt;-4&lt;/sup&gt; （一个相对较高的误码率），不分片时的成功交付概率为 (1-10&lt;sup&gt;-4&lt;/sup&gt;)&lt;sup&gt;12000&lt;/sup&gt;=0.301 ，那么只有约 30% 机会将这个帧成功交付，即平均发送三或四次可使它成功接收。&lt;/p&gt;
&lt;p&gt;如果我们对同样的例子使用分片，并将分片阈值设置为 500，这时将产生 3 个 4000 位的分片。每个分片成功交付的概率为 (1-10&lt;sup&gt;-4&lt;/sup&gt;)&lt;sup&gt;4000&lt;/sup&gt; = 0.670。因此，每个分片约有 67% 的机会成功交付。当然，我们必须在交付成功后重组该帧。 3 个分片、 2 个分片、 1 个分片与 0 个分片成功交付的概率分别为 (0.67)&lt;sup&gt;3&lt;/sup&gt;= 0.30、 3(0.67)&lt;sup&gt;2&lt;/sup&gt;(0.33) = 0.44、 3(0.67)(0.33)&lt;sup&gt;2&lt;/sup&gt;= 0.22、 (0.33)&lt;sup&gt;3&lt;/sup&gt;=0.04。 因此，虽然所有分片未重传而被成功交付的概率与未分片被成功交付的概率相同，但两个或三个分片被成功交付的机会相对较大。如果发生这种情况，顶多是一个分片需要重传，这比发送 1500 字节的未分片帧显然节省时间（大约三分之一）。当然，每个分片需要花费一些开销，如果误码率实际为 0 ，分片只会因创建更多帧而降低性能。&lt;/p&gt;
&lt;p&gt;802.11n 提供的增强功能之一是支持两种形式的帧聚合。一种形式称为&lt;strong&gt;聚合的 MAC 服务数据单元（A-MSDU）&lt;/strong&gt;，它可将多个完整的 802.3 （以太网）帧聚合在一个 802.11 帧中。另一种形式称为&lt;strong&gt;聚合的 MAC 协议数据单元（A-MPDU）&lt;/strong&gt;，它可将多个具有相同的源、目的和 QoS 的 MPDU 聚合为短帧。图 3-19 描述了两种类型的聚合。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;19&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1652429598770.png&#34; alt=&#34;图 3-19&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 3-19   802.11n 中的帧聚合包括 A-MSDU 和 A-MPDU。 A-MSDU 使用一个 FCS 聚合多个帧。A-MPDU 在聚合的每个 802.11 帧之间使用一个 4 字节的分隔符。每个 A-MPDU 子帧拥有自己的 FCS，并可以分别使用 ACK 确认，以及在必要时重传&lt;/p&gt;
&lt;p&gt;对于一次单一的聚合， A-MSDU 方法在技术上更有效率。每个 802.3 头部通常为 14 字节，相对 36 字节的 802.11 MAC 头部更短。因此，仅一个 802.11 MAC 头部对应于多个 802.3 帧，每聚合一个帧最多可节约 22 字节。一个 A-MSDU 可能高达 7935 字节，可容纳 100 多个小（例如 50 字节）的分组，但只能容纳少数（5 个）较大（1500 字节）的数据分组。 A-MSDU 仅对应一个 FCS。更大的 A-MSDU 帧会增大交付出错的概率，由于整个聚合只是针对一个 FCS，因此在出错时将不得不重传整个帧。&lt;/p&gt;
&lt;p&gt;A-MPDU 聚合是另一种形式的聚合，多个（最多 64 个） 802.11 帧可聚合起来，每个帧有自己的 802.11 MAC 头部和 FCS，每个帧最多 4095 字节。 A-MPDU 可携带最多 64KB 的数据，足够包含 1000 多个小的分组和大约 40 个较大（1.5KB）的分组。由于每个子帧都携带自己的 FCS，因此可有选择地重传那些出错的子帧。这使得 802.11n （最初在 802.11e）中的块确认功能成为可能，它是一种扩展的确认形式，为发送方提供哪个 A-MPDU 子帧交付成功的反馈信息。这种功能在目的上类似，但在细节上不同，我们将在 TCP （见第 14 章）中介绍选择确认。因此， A-MSDU 提供的聚合类型在无差错网络中传输大量小的分组时可能更有效率，但在实际运行中可能不如 A-MPDU 聚合好 [&lt;a href=&#34;#S08&#34;&gt;S08&lt;/a&gt;] 。&lt;/p&gt;
&lt;h3 id=&#34;352-省电模式和时间同步功能&#34;&gt;3.5.2 省电模式和时间同步功能&lt;/h3&gt;
&lt;p&gt;802.11 规范提供一种使站进入有限电源状态的方式，称为&lt;strong&gt;省电模式（PSM）&lt;/strong&gt;。 PSM 的设计目标是为了节省电源， STA 可在某个时间关闭无线电收发器电路。在不使用 PSM 时，收发器电路将始终运行，并消耗能量。在使用 PSM 时， STA 的输出帧在帧控制字中设置 1 位。当 AP 发现某些帧的该位被设置时，它会缓冲该帧直到该站需要时为止。 AP 发送信标帧（一种管理帧）提供不同信息，例如 SSID、信道和认证信息。当某个站使用 PSM 时， AP 可向该站提示存在缓冲的帧，只需在发送帧的&lt;strong&gt;帧控制字&lt;/strong&gt;中设置一个标识。在某个站执行 PSM 后，它会一直保持这样，直到接收到下一个 AP 信标帧，这时它将苏醒过来，并确定 AP 中是否有为它缓存的帧。&lt;/p&gt;
&lt;p&gt;我们应了解和关注 PSM 的使用。虽然它可能延长电池寿命，但是在大多数无线设备中，NIC 不是唯一可节约电源的模块。系统其他部分（例如屏幕和硬盘驱动器）也是电源的主要消耗者，因此总的电池寿命可能不会延长太多。另外， PSM 可能显著影响在帧传输之间空闲期间的吞吐量，时间被过多花费在模式切换上 [&lt;a href=&#34;#SHK07&#34;&gt;SHK07&lt;/a&gt;] 。&lt;/p&gt;
&lt;p&gt;在正确的时间（即一个 AP 打算发送一个信标帧时）唤醒 STA 检查等候帧的能力，取决于这个 AP 和它所服务的站对时间的感知。 Wi-Fi 采用&lt;strong&gt;时间同步功能（TSF）&lt;/strong&gt;。每个站保持一个 64 位计数器的参考时间（微秒），这个时间与网络中的其他站保持同步。同步保持在 4μs 加 PHY （速率为 1Mb/s 或以上）最大传播延迟之内。这是通过多个站接收一个 TSF 更新（另一个站发送的 64 位计数器副本），并检查其中的值是否比自己的值更大来实现。如果是，接收站将自己的时间更新为更大的值。这种方法可确保时钟总是向前走，但它也会带来一些问题，如果不同站的时钟速率稍有差异，较慢的站就会被最快的站的时钟所同步。&lt;/p&gt;
&lt;p&gt;通过将 802.11e （QoS）功能纳入 802.11 中， 802.11 的 PSM 扩展为提供定期批处理缓冲帧功能。这个频率用信标帧的数量来表示。这个功能被称为&lt;strong&gt;自动省电交付模式（APSD）&lt;/strong&gt;，它使用 QoS 控制字中的一些子字段。 APSD 对电源有限的设备可能非常有用，因为它们不像传统 802.11 PSM 那样，并不需要在每个信标间隔都被唤醒。相反，它们可选择在自己所选的较长时间内关闭无线电收发器电路。 802.11n 也扩展了 PSM 基本功能，允许一个 STA 装备的多个射频电路（见 3.5.4.2 节 MIMO）共同工作，关闭所有而不是其中一个电路，直到准备好一个帧为止。这被称为&lt;strong&gt;空间复用&lt;/strong&gt;省电模式。这个规范还包括称为&lt;strong&gt;省电多重轮询&lt;/strong&gt;的增强型 APSD，它提供同时双向（例如，到达 AP 和来自 AP）传输帧的方法。&lt;/p&gt;
&lt;h3 id=&#34;353-80211-介质访问控制&#34;&gt;3.5.3 802.11 介质访问控制&lt;/h3&gt;
&lt;p&gt;与有线网络（例如 802.3 局域网）相比，在无线网络中检测“冲突”具有更大挑战性。实际上，介质是相对单一的，无论是集中方式还是分布方式，都需要协同传输，避免多个站同时发送。 802.11 标准采用三种方法控制共享的无线介质，它们分别称为&lt;strong&gt;点协调功能（PCF）&lt;/strong&gt;、&lt;strong&gt;分布式协调功能（DCF）&lt;strong&gt;和&lt;/strong&gt;混合协调功能（HCF）&lt;/strong&gt;。 HCF 被纳入 802.11 规范 [&lt;a href=&#34;#802.11-2007&#34;&gt;802.11-2007&lt;/a&gt;] ，在 802.11e 中增加支持 QoS，它也被用于 802.11n。某些类型的站或 AP 强制实现 DCF，也可选择实现 PCF，但 PCF 使用得并不广泛（因此我们不详细讨论）。相对较新的支持 QoS 的 Wi-Fi 设备通常会实现 HCF，例如 802.11n 的 AP 和更早的 802.11e 的 AP。现在，我们将注意力转移到 DCF 上，并在下面的 QoS 内容中描述 HCF。&lt;/p&gt;
&lt;p&gt;DCF 是一种 CSMA/CA 类型，是基于竞争的介质访问方法。它可用于基础设施和 Ad hoc 网络。通过 CSMA/CA，一个站可查看介质是否空闲，如果空闲，它将有机会传输。如果不空闲，它在一段随机的时间内避免发送，直到它再次查看介质是否空闲为止。这个行为与有线局域网中使用的 CSMA/CD 检测方法相似。 802.11 信道仲裁是对 CSMA/CA 的改进，提供优先访问某些站或帧的功能。&lt;/p&gt;
&lt;p&gt;802.11 载波侦听能以物理和虚拟方式实现。一个站在准备发送时，通常需要等待一段时间（称为&lt;strong&gt;分布式帧间间隔（DIFS）&lt;/strong&gt;），以允许更高优先级的站访问信道。如果信道在 DIFS 期间变得繁忙，该站再次开始一个等待时间。当介质出现空闲时，希望发送数据的站将启动 3.5.3.3 节所述的冲突避免/退避过程。这个过程在一次成功（失败）的传输后，通过一个 ACK 知道数据被接收（或没有接收）后启动。在传输不成功的情况下，经过不同时间（称为&lt;strong&gt;扩展帧间间隔（EIFS）&lt;/strong&gt;）启动退避过程。现在，我们将详细地讨论 DCF 实现，包括虚拟和物理载波侦听机制。&lt;/p&gt;
&lt;h4 id=&#34;3531-虚拟载波侦听-rtscts-和网络分配向量&#34;&gt;3.5.3.1 虚拟载波侦听、RTS/CTS 和网络分配向量&lt;/h4&gt;
&lt;p&gt;在 802.11 MAC 协议中，虚拟载波侦听机制会检查每个 MAC 帧中的&lt;strong&gt;持续时间&lt;/strong&gt;字段。这通过站的侦听而非引导流量来实现。 RTS 和 CTS 帧中都有一个&lt;strong&gt;持续时间&lt;/strong&gt;字段，它们像普通帧那样在传输之前可选择是否交换，并估计介质将处于繁忙状态的时间。&lt;/p&gt;
&lt;p&gt;发送方基于帧长度、传输速率和 PHY 特性（例如速率等）设置&lt;strong&gt;持续时间&lt;/strong&gt;字段。每个站保持一个称为&lt;strong&gt;网络分配向量（NAV）&lt;strong&gt;的本地计数器，它被用于估计介质传输当前帧所需的时间，以及尝试下一次传输之前需等待的时间。当一个站侦听到一个&lt;/strong&gt;持续时间&lt;/strong&gt;大于自己的 NAV 时，它将自己的 NAV 更新为这个值。由于 RTS 和 CTS 帧中都有&lt;strong&gt;持续时间&lt;/strong&gt;字段，如果使用 NAV，在其范围内的任何站（无论是发送方还是接收方）都能看到&lt;strong&gt;持续时间&lt;/strong&gt;字段值。 NAV 采用单位时间来维护，并基于本地时钟递减。当本地 NAV 不为 0 时，介质被认为是繁忙的。在接收到一个 ACK 后，本地 NAV 将复位为 0。&lt;/p&gt;
&lt;h4 id=&#34;3532-物理载波侦听cca&#34;&gt;3.5.3.2 物理载波侦听（CCA）&lt;/h4&gt;
&lt;p&gt;每个 802.11 PHY 规范（例如，对于不同的频率和无线电技术）需提供一种评估信道是否空闲的功能，它基于能量和波形识别（通常是一个完好的 PLCP）。这个功能称为&lt;strong&gt;空闲信道评估（Clear Channel Assessment， CCA）&lt;/strong&gt;，它的实现依赖于 PHY。 CCA 功能是针对 802.11 MAC 的物理载波侦听功能，用于了解介质当前是否繁忙。它通常与 NAV 结合使用，以确定一个站在传输之前是否需要推迟（等待）。&lt;/p&gt;
&lt;h4 id=&#34;3533-dcf-冲突避免退避过程&#34;&gt;3.5.3.3 DCF 冲突避免/退避过程&lt;/h4&gt;
&lt;p&gt;在确定某个信道可能空闲时（已到达 NAV 持续时间，并且 CCA 没有提示信道繁忙），一个站在传输之前需推迟访问该信道。由于很多站可能在等待信道变空闲，每个站在发送之前需计算和等待一个&lt;strong&gt;退避时间&lt;/strong&gt;。退避时间等于一个随机数和&lt;strong&gt;时隙&lt;/strong&gt;的乘积（除非该站已有一个非零的退避时间尝试传输，在这种情况下无须重新计算）。时隙依赖于 PHY，通常是几十微秒。随机数是一个在区间 &lt;code&gt;[0，CW]&lt;/code&gt; 中均匀分布的数值，**竞争窗口（CW）**是一个整数，其中包含许多等待时隙，且 &lt;code&gt;aCWmin ≤ CW ≤ aCWmax&lt;/code&gt; （该限制由 PHY 定义）。 CW 值的集合从 PHY 指定的常数 aCWmin 开始，以 2 的幂（减 1）增加，直到每个连续传输尝试次数的常数 aCWmax 为止。这样做与以太网中由冲突检测事件引发的退避过程相似。&lt;/p&gt;
&lt;p&gt;在无线环境中，冲突检测是不实际的。由于难以发现发送方和接收方同时发送，也难以监听自己之外的传输，因此采用&lt;strong&gt;冲突避免&lt;/strong&gt;来代替冲突检测。另外， ACK 是针对单播帧的响应，以确定一个帧是否成功传递。当一个站正确接收一个帧时，在等待一小段时间（称为&lt;strong&gt;短帧间间隔（SIFS）&lt;/strong&gt;）后开始传输 ACK，并且不考虑介质的忙碌/空闲状态。这样做不会导致问题，由于 SIFS 的值始终比 DIFS 小，因此该站产生的 ACK 可优先访问信道，以完成接收确认。源站在一定时间内没有接收到 ACK，则意味着一次传输失败。在失败后，源站启动前面讨论的退避过程，并重新尝试发送帧。如果在一定时间（CTStimeout 常数）内没有接收到对较早 RTS 响应的 CTS，则启动同样的过程。&lt;/p&gt;
&lt;h4 id=&#34;3534-hcf-和-80211en-的-qos&#34;&gt;3.5.3.4 HCF 和 802.11e/n 的 QoS&lt;/h4&gt;
&lt;p&gt;802.11标准 [&lt;a href=&#34;#802.11-2007&#34;&gt;802.11-2007&lt;/a&gt;] 中的条款 5、 6、 7 和 9 都基于 IEEE 802.11e 工作组的部分工作，常用的术语有 802.11e、Wi-Fi QoS和 WMM（基于Wi-Fi的多媒体）。它们涉及 QoS 功能：修改 802.11 MAC 层和系统接口以支持多媒体应用，例如 IP 语音（VoIP）和流媒体。 QoS 功能实际是否必要，取决于网络层拥塞和应用类型。如果网络利用率较低，可能不必要支持 QoS 的 MAC，虽然其他 802.11e 功能可能有用（例如块确认和 APSD）。在网络利用率和拥塞较高的情况下，需要为 VoIP 等服务提供低抖动交付能力，这时支持 QoS 可能是可取的。这些规范相对较新，支持 QoS 的 Wi-Fi 设备通常比不支持 QoS 的设备更昂贵和更复杂。&lt;/p&gt;
&lt;p&gt;QoS 功能引入了新的术语，例如 QoS 站（QSTA）、 QoS 接入点（QAP）和 QoS BSS（QBSS，支持QoS 的 BSS）。在一般情况下，支持 QoS 功能的设备也支持传统的非 QoS 操作。 802.11n “高吞吐量”站（又称为 HTSTA）也是 QSTA。&lt;strong&gt;混合协调功能（HCF）&lt;strong&gt;是一种新的协调功能，支持基于竞争和可控制的信道访问，尽管可控制的信道访问技术很少使用。在 HCF 中，有两种专门的信道访问方法可协同工作：&lt;strong&gt;HFCA 控制信道访问（HCCA）&lt;strong&gt;和更流行的&lt;/strong&gt;增强型 DCF 信道访问（EDCA）&lt;/strong&gt;，它们分别对应于基于预约和基于竞争的访问。这里也有一些对&lt;/strong&gt;准入控制&lt;/strong&gt;的支持，它们可在高负载下完全拒绝访问。&lt;/p&gt;
&lt;p&gt;EDCA 建立在基本的 DCF 访问之上。通过 EDCA， 8 个&lt;strong&gt;用户优先级（UP）&lt;strong&gt;被映射为 4 个&lt;/strong&gt;访问类别（AC）&lt;/strong&gt;。用户优先级使用与 802.1d 优先级标记相同的结构，并被编号为 1 至 7 （在 2 和 3 之间还有一个优先级 0），其中 7 为最高优先级。 4 个访问类别分别为背景、尽力而为、视频和音频流量。优先级 1 和 2 用于背景 AC，优先级 0 和 3 用于尽力而为 AC，优先级 4 和 5 用于视频 AC，优先级 6 和 7 用于音频 AC。对于每个 AC， DCF 的一个变种竞争信道访问许可，称为&lt;strong&gt;传输机会（TXOP）&lt;/strong&gt;，为较高优先级的流量使用可选的 MAC 参数。在 EDCA 中，很多来自 DCF 的 MAC 参数（例如， DIFS、 aCWmin、 aCWmax）作为配置参数是可调整的。这些值可通过管理帧传输给 QSTA。&lt;/p&gt;
&lt;p&gt;HCCA 松散地建立在 PCF 之上，并使用轮询来控制信道访问。它属于同步方式的访问控制，并优先于基于竞争的 EDCA 访问。&lt;strong&gt;混合协调（HC）&lt;strong&gt;位于一个 AP 中，并优先于信道访问分配。在一次传输之前，一个站可为其流量发布一个&lt;/strong&gt;流量规范（TSPEC）&lt;/strong&gt;，并使用 8 和 15 之间的 UP 值。 HC 可为这种请求分配保留的 TXOP，它被用于基于 EDCA 的帧传输之前的短期控制访问阶段的帧交换。 HC 可拒绝 TXOP 的基于网络管理员设置的管理控制策略的 TSPEC。 HCF 利用前面讨论过的虚拟载波侦听机制和 DCF，以避免基于竞争的站被不基于竞争的访问所干扰。注意，在包括 QSTA 和常规站的网络中，可同时运行 HCF 和 DCF，并在两者之间切换，但 Ad hoc 网络不支持 HC，因此它不处理 TSPEC 和不执行管理控制。这种网络可能仍运行 HCF，但 TXOP 通过基于 EDCA 的竞争来获得。&lt;/p&gt;
&lt;h3 id=&#34;354-物理层的细节速率-信道和频率&#34;&gt;3.5.4 物理层的细节：速率、信道和频率&lt;/h3&gt;
&lt;p&gt;目前， [&lt;a href=&#34;#802.11-2007&#34;&gt;802.11-2007&lt;/a&gt;] 标准包括以下较早的修订版：802.11a、 802.11b、 802.11d、 802.11g、802.11h、 802.11i、 802.11j 和 802.11e。 802.11n 标准在 2009 年被采纳为 802.11 的修订版 [&lt;a href=&#34;#802.11n-2009&#34;&gt;802.11n-2009&lt;/a&gt;]。大多数的修订版为 802.11 网络提供额外的调制、编码和工作频率，但 802.11n 还增加了多种数据流和一种聚合多帧方法（见3.5.1.3节）。我们尽量避免详细讨论物理层，这里只是看一下可选的内容。表 3-2 包括 802.11 标准中特别描述的物理层部分。&lt;/p&gt;
&lt;center&gt;表 3-2   802.11 标准中描述的物理层部分&lt;/center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;标准（条款）&lt;/th&gt;
&lt;th&gt;速率（Mb/s）&lt;/th&gt;
&lt;th&gt;频率范围；调制&lt;/th&gt;
&lt;th&gt;信道设置&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;802.11a（第 17 条）&lt;/td&gt;
&lt;td&gt;6、9、12、18、24、36、48、54&lt;/td&gt;
&lt;td&gt;5.16GHz ~ 5.35GHz 和 5.725 ~ 5.825GHz；OFDM&lt;/td&gt;
&lt;td&gt;37 ~ 168（根据国家不同），20MHz/10MHz/5MHz 信道宽度选项&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.11b（第 18 条）&lt;/td&gt;
&lt;td&gt;1、2 、5.5、11&lt;/td&gt;
&lt;td&gt;2.401GHz ~ 2.495GHz；DSSS&lt;/td&gt;
&lt;td&gt;1 ~ 14（根据国家不同）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.11g（第 19 条）&lt;/td&gt;
&lt;td&gt;1、2 、5.5、6、9、11、12、18、24、36、48、54（加 22、23）&lt;/td&gt;
&lt;td&gt;2.401GHz ~ 2.495GHz；OFDM&lt;/td&gt;
&lt;td&gt;1 ~ 14（根据国家不同）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.11n&lt;/td&gt;
&lt;td&gt;6.5 ~ 600，很多选项（最多 4 个 MIMO 流）&lt;/td&gt;
&lt;td&gt;2.4GHz 和 5GHz 模式，信道宽度 20MHz 或 40MHz；OFDM&lt;/td&gt;
&lt;td&gt;1 ~ 13（2.4GHz 频段）；36 ~ 196（5GHz 频段）（根据国家不同）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;802.11y&lt;/td&gt;
&lt;td&gt;（与 802.11-2007 相同）&lt;/td&gt;
&lt;td&gt;3.650GHz ~ 3.700GHz （需许可）；OFDM&lt;/td&gt;
&lt;td&gt;1 ~ 25；36 ~ 64；100 ~ 161（根据国家不同）&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;第一列给出了标准的原有名称和在 [&lt;a href=&#34;#802.11-2007&#34;&gt;802.11-2007&lt;/a&gt;] 中的当前位置，并增 802.11n 和 802.11y 修订版的细节。在这个表中，需要注意的是， 802.11b/g 工作在 2.4GHz 的**工业、科学和医疗（ISM）&lt;strong&gt;频段， 802.11 仅工作在更高的 5GHz 的&lt;/strong&gt;无须许可的国家信息基础设施（U-NII）**频段，而 802.11n 可工作在这两个频段。 802.11y 修订版在美国工作在需要许可的 3.65 ~ 3.70GHz频段。我们应注意的一个重要的实践结论是：802.11b/g 设备与 802.11a 设备不会互操作或干扰，但是如果不认真进行部署， 802.11n 设备可能被任何设备干扰。&lt;/p&gt;
&lt;h4 id=&#34;3541-信道和频率&#34;&gt;3.5.4.1 信道和频率&lt;/h4&gt;
&lt;p&gt;监管机构（例如美国联邦通信委员会）将电磁波谱划分为不同频率范围，并分配给世界各地的不同应用。对于每个频率范围及其用途，根据本地政策可能需要或不需要申请许可证。在 802.11 中，多个信道可能以不同方式、不同功率水平工作，这取决于所在地区或国家的监管。 Wi-Fi 信道在某个基本中心频率的基础上以 5MHz 为单位进行编号。例如，信道 36 的基本中心频率为 5.00GHz，则信道 36 的中心频率为 &lt;code&gt;5000 + 36*5 = 5180MHz&lt;/code&gt;。虽然信道的中心频率之间以 5MHz 为间隔，但信道宽度可能超过 5MHz（802.11n 高达 40MHz）。因此，信道集中的某些频段内的信道经常重叠。实际上，这意味着一个信道上的传输可能干扰附近信道上的传输。&lt;/p&gt;
&lt;p&gt;图 3-20 给出了 802.11b/g 信道在 2.4GHz 的 ISM 频段内的信道与频率映射。每个信道宽度为 22MHz。并非所有信道都可在每个国家合法使用。例如，信道 14 仅被授权在日本使用，信道 12 和 13 被授权在欧洲使用，而美国只能使用信道1 ~ 11。其他国家可能更严格（见 802.11 标准的 Annex J 和修订版）。注意，政策和许可要求可能随时间而改变。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;20&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1652883012661.png&#34; alt=&#34;图 3-20&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 3-20   802.11b 和 802.11g 标准使用 2.4GHz 和 2.5GHz 之间的频段。这个频段被划分为 14 个 22MHz 宽的重叠信道，其中一些子集是否可合法使用取决于所在国家。在同一地区运行多个基站，分配非重叠的信道是可取的做法，例如美国的 1、 6 和 11。只有一个 40MHz 的 802.11n 信道可用于此频段而不会发生重叠&lt;/p&gt;
&lt;p&gt;如图 3-20 所示，重叠信道的影响是明显的。例如，一个传输方工作在信道 1 上，它与信道 2、 3、 4 和 5 重叠，但与更高的信道不重叠。在可使用多个接入点的环境中，选择使用哪条信道是很重要的，当同一区域中有多个接入点为多个网络提供服务时，如何选择信道至关重要。在美国，常用方法是同一区域中的 3 个 AP 使用不重叠的信道 1、 6 和 11，信道 11 在美国是无须许可即可使用的最高频率信道。在其他无线局域网也在同一频段运行的情况下，应该由所有受影响的 WLAN 管理员共同规划信道。&lt;/p&gt;
&lt;p&gt;如图 3-21 所示， 802.11a/n/y 共享一个有些复杂的信道设置，但提供了更多的不重叠信道（即美国的 12 个无须许可的 20MHz 信道）。&lt;/p&gt;
&lt;p&gt;在图 3-21 中，信道以 5MHz 为单位递增，但存在不同的信道宽度：5MHz、 10MHz、20MHz 和 40MHz。 40MHz 信道宽度是 802.11n 的一个选项（见 3.5.4.2 节），可将几个不同所有者的 Wi-Fi 系统聚合为 2 个 20MHz 信道（称为信道绑定）。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;21&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1652883308062.png&#34; alt=&#34;图 3-21&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 3-21   20MHz 信道中的一些可用的 802.11 信道号和中心频率。最常见的无须许可使用的频率范围包括 U-NII 频段，它们均在 5GHz 之上。较低频段被批准可用于大多数国家。 “欧洲”频段被批准用于大多数欧洲国家，高频段被批准用于美国和中国。 802.11a/y 信道的典型宽度为 20MHz，但 802.11n 的信道宽度可能为 40MHz。另外，在日本也可使用窄信道和某些信道（未显示）&lt;/p&gt;
&lt;p&gt;对于典型的 Wi-Fi 网络，在 AP 安装过程中需要指定其运行信道，并由用户所在的站修改信道以便连接到 AP。当运行在 Ad hoc 模式时，没有起控制作用的 AP，因此一个站通常需要为 AP 手工配置信道。可用的信道和运行功率可能受限于监管环境、硬件功能，以及所支持的驱动程序软件。&lt;/p&gt;
&lt;h4 id=&#34;3542-更高吞吐量的-80211802211n&#34;&gt;3.5.4.2 更高吞吐量的 802.11/8022.11n&lt;/h4&gt;
&lt;p&gt;2009 年年底， IEEE 将 [&lt;a href=&#34;#802.11-2007&#34;&gt;802.11-2007&lt;/a&gt;] 修订为802.11n [&lt;a href=&#34;#802.11n-2009&#34;&gt;802.11n-2009&lt;/a&gt;]。它对 802.11 做了一些重要改变。为了支持更高吞吐量，它采用&lt;strong&gt;多输入多输出（MIMO）&lt;strong&gt;管理&lt;/strong&gt;空间流（Spatial Stream）&lt;/strong&gt;，即由多个天线同时传输的多个数据流。一个给定信道上最多支持 4 个这种空间流。802.11n 信道宽度可以是 40MHz （使用两个相邻的 20MHz 信道），这是传统 802.11a/b/g/y 信道宽度的两倍。因此，它可将 802.11a/g 的最大传输速率（54Mb/s）提高 8 倍，达到 432Mb/s。802.11n 也提高了单个流的性能，使用一种更高效的调制方案（802.11n采用 MIMO-正交频分复用（OFDM），每个 20MHz 信道最多承载 52 个数据载波，每个 40MHz 信道最多承载 108 个数据载波，代替 802.11a 和 802.11g 中的 48 个），以及一种更有效的转发纠错编码（以编码率 5/6 代替 3/4），将每个流性能提升到 65Mb/s （20MHz 信道）或 135Mb/s （40MHz信道）。通过将&lt;strong&gt;保护间隔&lt;/strong&gt;（GI，一个强制的符号之间的空闲时间）从传统的 800ns 减少到 400ns，每个流的最大性能可提高到 72.2Mb/s （20MHz信道）和 150Mb/s （40MHz信道）。通过 4 个空间流的完美协同操作，这样可提供最高 600Mb/s 的传输速率。&lt;/p&gt;
&lt;p&gt;802.11n 标准支持大约 77 种调制和编码选项组合，其中包括 8 种对应单个流的选项， 24 种可在所有流中使用的**平等调制（EQM）&lt;strong&gt;选项，以及 43 种可在多个流上使用的&lt;/strong&gt;不平等调制（UEQM）&lt;strong&gt;选项。表 3-3 给出了调制和编码方案的一些组合，对应于&lt;/strong&gt;调制和编码方案（MCS）**的前 33 个值。更大的值（33 - 76）包括 2 个信道（值 33 - 38）、3 个信道（39 - 52）和 4 个信道（53 - 76）的组合。 MCS 值 32 是一个特殊组合，即 40MHz 信道的两路信号包含相同信息。每行给出了 2 个数据传输速率，一个使用早期的 800ns GI，一个使用较短的 400ns GI 以获得更大传输速率。两个带下划线的值 6Mb/s 和 600Mb/s，分别表示最小和最大吞吐率。&lt;/p&gt;
&lt;center&gt;表 3-3   802.11n 的 MCS 值包括平等和不平等调制，不同的 FEC 编码率，使用 20MHz 或 40MHz 信道宽度的 4 个空间流，以及 800ns 或 400ns GI 的组合。77 种组合提供从 6Mb/s 到 600Mb/s 的数据传输速率&lt;/center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;MCS 值&lt;/th&gt;
&lt;th&gt;调制类型&lt;/th&gt;
&lt;th&gt;FEC 编码率&lt;/th&gt;
&lt;th&gt;空间流&lt;/th&gt;
&lt;th&gt;速率（Mb/s）（20MHz）[800/400ns]&lt;/th&gt;
&lt;th&gt;速率（Mb/s）（40MHz）[800/400ns]&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;BPSK&lt;/td&gt;
&lt;td&gt;1/2&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;6.5/7.2&lt;/td&gt;
&lt;td&gt;13.5/15&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;QPSK&lt;/td&gt;
&lt;td&gt;1/2&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;13/14.4&lt;/td&gt;
&lt;td&gt;27/30&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;QPSK&lt;/td&gt;
&lt;td&gt;3/4&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;19.4/21.7&lt;/td&gt;
&lt;td&gt;40.5/45&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;16-QAM&lt;/td&gt;
&lt;td&gt;1/2&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;26/28.9&lt;/td&gt;
&lt;td&gt;54/60&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;16-QAM&lt;/td&gt;
&lt;td&gt;3/4&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;39/43.3&lt;/td&gt;
&lt;td&gt;81/90&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;16-QAM&lt;/td&gt;
&lt;td&gt;2/3&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;52/57.8&lt;/td&gt;
&lt;td&gt;108/120&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;16-QAM&lt;/td&gt;
&lt;td&gt;3/4&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;58.5/65&lt;/td&gt;
&lt;td&gt;121.5/135&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;16-QAM&lt;/td&gt;
&lt;td&gt;5/6&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;65/72.2&lt;/td&gt;
&lt;td&gt;135/150&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;BPSK&lt;/td&gt;
&lt;td&gt;1/2&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;13/14.4&lt;/td&gt;
&lt;td&gt;27/30&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;....&lt;/td&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;15&lt;/td&gt;
&lt;td&gt;64-QAM&lt;/td&gt;
&lt;td&gt;5/6&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;130/144.4&lt;/td&gt;
&lt;td&gt;270/300&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;16&lt;/td&gt;
&lt;td&gt;BPSK&lt;/td&gt;
&lt;td&gt;1/2&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;19.5/21.7&lt;/td&gt;
&lt;td&gt;40.5/45&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;31&lt;/td&gt;
&lt;td&gt;64-QAM&lt;/td&gt;
&lt;td&gt;5/6&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;260/288.9&lt;/td&gt;
&lt;td&gt;540/600&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;32&lt;/td&gt;
&lt;td&gt;BPSK&lt;/td&gt;
&lt;td&gt;1/2&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;td&gt;6/6.7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;76&lt;/td&gt;
&lt;td&gt;64x3/16x1-QAM&lt;/td&gt;
&lt;td&gt;3/4&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;214.5/238.3&lt;/td&gt;
&lt;td&gt;445.5/495&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;表 3-3 显示了可用于 802.11n 的各种编码组合，包括&lt;strong&gt;二进制相移键控（BPSK）&lt;/strong&gt;、&lt;strong&gt;正交相移键控（QPSK）&lt;/strong&gt;，以及各种&lt;strong&gt;正交幅度调制（16-QAM和64-QAM）&lt;/strong&gt;。这些调制方案为给定的信道提供更大的传输速率。但是，性能更高和更复杂的调制方案，通常更容易受到噪声干扰。**转发纠错（FEC）**包括一套方法，在发送方引入一些冗余位，用于检测和修改传输过程中的错误。对于 FEC，编码率是可用传输速率与底层信道规定速率之比。例如， 1/2 编码率表示每发送 2 位数据，只有 1 位有效交付。&lt;/p&gt;
&lt;p&gt;802.11n 可工作在 3 种模式下。在 802.11n 环境中，可选择所谓的&lt;strong&gt;绿地模式&lt;/strong&gt;， PLCP 包含特殊位序列（“训练序列”），它仅被 802.11n 设备获得，不与传统设备进行互操作。为了保持兼容性， 802.11n 提供了 2 种互操作模式。但是，这些模式对纯 802.11n 设备会带来性能损失。一种模式称为&lt;strong&gt;非 HT 模式&lt;/strong&gt;，禁止所有 802.11n 功能，但仍与原有设备兼容。这不是一种很有趣的模式，因此我们不再进一步讨论。另一种模式称为 &lt;strong&gt;HT 混合模式&lt;/strong&gt;，支持 802.11n 和传统操作，这取决于与哪个站进行通信。 PLCP 给出了向 HT STA 提供 AP 的802.11n 功能和保护传统 STA 所需的信息， PLCP 被修订为包含 HT 和传统信息，并以一个比绿地模式慢的速度传输，以便传统设备来得及处理。在一个传统站使用共享信道时， HT 保护还要求 HTAP 使用自定向 CTS 帧（或 RTS/CTS 帧交换）以传统速率通知传统站。尽管 RTS/CTS 帧是短的，但由于它们是以传统速率（6Mb/s）发送，所以这将显著降低 802.11n WLAN 性能。&lt;/p&gt;
&lt;p&gt;在部署一个 802.11n AP 时，应考虑分配适当的信道。在使用 40MHz 信道时， 802.11n AP 应运行在 5GHz 以上的 U-NII 频段， 2.4GHz 的 ISM 频段中根本没有足够的可用频段提供这么宽的信道。一种可选的 BSS 功能称为&lt;strong&gt;分阶段共存操作（PCO）&lt;/strong&gt;，允许一个 AP 定期在 20MHz 和 40MHz 信道宽度之间切换，更好地提供 802.11n AP 之间的共存，以一些额外流量代价为附近的传统设备提供服务。最后值得一提的是， 802.11n AP 通常比传统 AP 消耗更多能量。这种比基本的 15W 更高的电源功率，可由 **802.3af 以太网供电（PoE）**系统提供，这意味着需要使用 PoE+ （802.3at 能提供 30W），除非有其他形式的电源（例如一个外接电源）。&lt;/p&gt;
&lt;h3 id=&#34;355-wi-fi-安全&#34;&gt;3.5.5 Wi-Fi 安全&lt;/h3&gt;
&lt;p&gt;802.11 网络的安全模型有很大变化。早期， 802.11 采用一种称为**有线等效保密（WEP）**的加密方法。 WEP 后来被证明安全性薄弱，并出现了替换它的需求。工业界通过 &lt;strong&gt;Wi-Fi 保护访问（WPA）&lt;strong&gt;来回应，它使用加密块（见第 18 章的密码学基础知识）代替密钥方式。在 WPA 中，采用一种称为&lt;/strong&gt;临时密钥完整性协议（TKIP）&lt;strong&gt;的方案，确保每个帧都用不同密钥加密。它还包括一种称为 Michael 的消息完整性检查，以弥补 WEP 中的主要弱点之一。 WPA 被创建为一个占位符，可通过硬件升级方式使设备支持 WEP 功能。 IEEE 802.11i 工作组制定了一个功能更强的标准，最终被吸收到 [&lt;a href=&#34;#802.11-2007&#34;&gt;802.11-2007&lt;/a&gt;] 的第 8 条，并被工业界称为“WPA2”。WEP 和 WPA 都使用 RC4 加密算法 [&lt;a href=&#34;#S96&#34;&gt;S96&lt;/a&gt;]。 WPA2 使用&lt;/strong&gt;高级加密标准&lt;/strong&gt;（AES）算法 [&lt;a href=&#34;#AES01&#34;&gt;AES01&lt;/a&gt;]。&lt;/p&gt;
&lt;p&gt;我们刚才讨论的加密技术，用于在站和 AP 之间提供隐私保护（假设站拥有访问网络的合法授权）。在使用 WEP、 WPA 或 WPA2 的小规模环境中，授权通常通过预先设置一个共享密钥或密码来实现，它在每个站和 AP 的配置过程中生成。知道这个密钥的用户拥有访问网络的合法授权。这些密钥常用于保护隐私的加密密钥的初始化。这种&lt;strong&gt;预共享密钥（PSK）&lt;strong&gt;具有局限性。例如，管理员为授权用户提供密钥，这可能是相当麻烦的事。如果一个新的用户被授权，必须更换 PSK 并通知所有合法用户。这种方法难以用于有很多用户的环境。因此， WPA 和后期标准支持&lt;/strong&gt;基于端口的网络访问控制&lt;/strong&gt;标准，称为 802.1x [&lt;a href=&#34;#802.1x-2010&#34;&gt;802.1x-2010&lt;/a&gt;]。它提供了一种在 IEEE 802 局域网（称为 EAPOL，包括 802.3 和 802.11 [&lt;a href=&#34;#RFC4017&#34;&gt;RFC4017&lt;/a&gt;]）中使用&lt;strong&gt;扩展身份验证协议（EAP）&lt;/strong&gt;  [&lt;a href=&#34;#RFC3748&#34;&gt;RFC3748&lt;/a&gt;] 的方式。 EAP 可使用多种标准和非标准化的认证协议。它也可用于建立密钥，包括 WEP 密钥。第 18 章将详细讨论这些协议。我们在 3.6 节讨论 PPP 时也会看到 EAP 的使用。&lt;/p&gt;
&lt;p&gt;随着 IEEE 802.11i 工作组的工作完成， WPA 和 RC4/TKIP 组合扩展为一个称为 CCMP 的新方案，它被作为 WPA2 的一部分。 CCMP 是基于&lt;strong&gt;计数器模式&lt;/strong&gt;（CCM [&lt;a href=&#34;#RFC3610&#34;&gt;RFC3610&lt;/a&gt;]）的 AES ，以确保用于认证和完整性的&lt;strong&gt;密码块链接消息认证码&lt;/strong&gt;（CBC-MAC；注意术语MAC在这里的“其他”用途）的安全。 AES 采用 128 位的块和 128 位的密钥。 CCMP 和 TKIP 形成了 Wi-Fi 安全体系结构的基础，称为&lt;strong&gt;强健安全网络（RSN）&lt;/strong&gt;，并支持&lt;strong&gt;强健安全网络访问（RSNA）&lt;/strong&gt;。早期的一些方法（如 WEP）称为预 RSNA 方法。 RSNA 要求支持 CCMP （TKIP 可选），而 802.11n 标准完全不使用 TKIP。表 3-4 总结了这种复杂情况。&lt;/p&gt;
&lt;center&gt;表 3-4   Wi-Fi 安全已从不安全的 WEP 演变到 WPA，再到当前标准的 WPA2 方案&lt;/center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;名称/标准&lt;/th&gt;
&lt;th&gt;密码&lt;/th&gt;
&lt;th&gt;密钥流管理&lt;/th&gt;
&lt;th&gt;认证&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;WEP（预 RSNA）&lt;/td&gt;
&lt;td&gt;RC4&lt;/td&gt;
&lt;td&gt;（WEP）&lt;/td&gt;
&lt;td&gt;PSK，（802.1X/EAP）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;WPA&lt;/td&gt;
&lt;td&gt;RC4&lt;/td&gt;
&lt;td&gt;TKIP&lt;/td&gt;
&lt;td&gt;PSK，802.1X/EAP&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;WPA2/802.11(i)&lt;/td&gt;
&lt;td&gt;CCMP&lt;/td&gt;
&lt;td&gt;CCMP，（TKIP）&lt;/td&gt;
&lt;td&gt;PSK，802.1X/EAP&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;在所有情况下，预共享密钥和 802.1X 可用于认证和初始化密钥。 802.1X/EAP 的主要吸引力在于其可管理的认证服务器，它基于 AP 为每个用户提供访问控制决策。出于这个原因，使用 802.1X 的认证有时称为“企业” （例如 WPA 企业）。 EAP 本身可封装各种认证协议，我们将在第 18 章详细讨论这些协议。&lt;/p&gt;
&lt;h3 id=&#34;356-wi-fi-网状网80211s&#34;&gt;3.5.6 Wi-Fi 网状网（802.11s）&lt;/h3&gt;
&lt;p&gt;IEEE 正在制定 802.11s 标准，其中包括 Wi-Fi 的&lt;strong&gt;网状网（Mesh）&lt;strong&gt;操作。通过 Mesh 操作，无线站点可用作数据转发代理（像 AP 那样）。在作者编写本书期间（2011 年中期），这个标准仍未完成。 802.11s 草案定义了&lt;/strong&gt;混合无线路由协议（HWRP）&lt;/strong&gt;，它基于 &lt;strong&gt;Ad hoc 按需距离向量（AODV）&lt;strong&gt;路由 [&lt;a href=&#34;#RFC3561&#34;&gt;RFC3561&lt;/a&gt;] 和&lt;/strong&gt;优化链路状态路由（OLSR）&lt;strong&gt;协议 [&lt;a href=&#34;#RFC3626&#34;&gt;RFC3626&lt;/a&gt;] 等 IETF 标准。Mesh 站（Mesh STA）是一种 QoS 站，它可能参与 HWRP 或其他路由协议，但兼容节点必须包括 HWRP 实现和相关&lt;/strong&gt;通话时间链路度量&lt;/strong&gt;。 Mesh 节点使用 EDCA 来协同工作，或使用一种可选的称为 &lt;strong&gt;Mesh 确定性访问&lt;/strong&gt;的协同功能。 Mesh 点（MP）是与邻居形成 Mesh 连接的那些节点。那些包含 AP 功能的 Mesh 点称为 Mesh AP （MAP）。常规 802.11 站可使用 AP 或 MAP 访问无线局域网的其他部分。&lt;/p&gt;
&lt;p&gt;802.11s 草案为 RSNA 制定了一种可选的新安全方案，称为基于对等同时认证（SAE）的认证 [&lt;a href=&#34;#SAE&#34;&gt;SAE&lt;/a&gt;]。这种安全协议与其他协议有些区别，它并不需要一个特定的发起者和响应者之间的操作同步。相反，所有站都被平等对待，先发现其他站的任何站可启动一次安全交换（这可能导致两个站同时启动一次交换）。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;36-点到点协议&#34;&gt;3.6 点到点协议&lt;/h2&gt;
&lt;p&gt;PPP 表示点到点协议 [&lt;a href=&#34;#RFC1661&#34;&gt;RFC1661&lt;/a&gt;] [&lt;a href=&#34;#RFC1662&#34;&gt;RFC1662&lt;/a&gt;] [&lt;a href=&#34;#RFC2153&#34;&gt;RFC2153&lt;/a&gt;] 。这是一种在串行链路上传输 IP 数据报的流行方法，从低速的拨号调制解调器到高速的光链路 [&lt;a href=&#34;#RFC2615&#34;&gt;RFC2615&lt;/a&gt;]。它被一些 DSL 服务供应商广泛部署，也可分配 Internet 系统的参数（例如，最初的 IP 地址和域名服务器；见第 6 章）。&lt;/p&gt;
&lt;p&gt;PPP 实际上是一个协议集合，而不是一个单一的协议。它支持建立链接的基本方法——称为&lt;strong&gt;链路控制协议（Link Control Protocol， LCP）&lt;/strong&gt;，以及一系列 NCP 协议，在 LCP 建立了基本链路之后，用于为各种协议（包括 IPv4、 IPv6 和非 IP 协议）建立网络层链路。一些相关标准涉及对 PPP 的压缩和加密控制，以及在链接建立后的一些认证方法。&lt;/p&gt;
&lt;h3 id=&#34;361-链路控制协议&#34;&gt;3.6.1 链路控制协议&lt;/h3&gt;
&lt;p&gt;PPP 的 LCP 用于在点到点链路上建立和维护低层的双方通信路径。因此， PPP 操作只需关注一条链路的两端，它不需要像以太网和 Wi-Fi 的 MAC 层协议那样处理共享资源访问的问题。&lt;/p&gt;
&lt;p&gt;PPP 通常对底层的点到点链路有最低要求，LCP 更是这样。链路必须支持双向操作（LCP 使用的确认），以及异步或同步操作。通常， LCP 使用简单的位级别帧格式，基于&lt;strong&gt;高级数据链路控制（HDLC）&lt;strong&gt;建立链路协议。在 PPP 设计时， HDLC 就已建立了一种良好的帧格式 [&lt;a href=&#34;#ISO3309&#34;&gt;ISO3309&lt;/a&gt;] [&lt;a href=&#34;#ISO4335&#34;&gt;ISO4335&lt;/a&gt;] 。 IBM 将它修改为&lt;/strong&gt;同步数据链路控制（SDLC）&lt;/strong&gt;，在其专用的**系统网络体系结构（SNA）**协议族中用作链路层协议。 HDLC 协议还用作 802.2 中 LLC 标准的基础，并最终被用于 PPP。 图 3-22 显示了这种格式。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;22&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1652887335410.png&#34; alt=&#34;图 3-22&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 3-22   PPP 基本帧格式借用了 HDLC 的格式。它包括一个协议标识符、有效载荷区域，以及 2 或 4 字节的 FCS。其他字段是否存在取决于压缩选项&lt;/p&gt;
&lt;p&gt;在通常情况下， PPP 帧格式类似于图 3-22 所示的 HDLC 帧，由 2 个 1 字节的包含固定值 &lt;code&gt;0x7E&lt;/code&gt; 的&lt;strong&gt;标志&lt;/strong&gt;字段“包围” 。点到点链路的两个端点使用这些字段来发现一个帧的开始和结束。如果 &lt;code&gt;0x7E&lt;/code&gt; 值出现在帧内部，这时会带来一个小问题。它可通过两种方式来处理，这取决于 PPP 工作在异步还是同步链路上。对于异步链路， PPP 使用&lt;strong&gt;字符填充&lt;/strong&gt;（也称为字节填充）。如果标志字符出现在帧中其他地方，则用 2 字节序列 &lt;code&gt;0x7D5E&lt;/code&gt; （ &lt;code&gt;0x7D&lt;/code&gt; 称为“ppp转义字符”）替换。如果转义字符本身出现在帧中，则用 2 字节序列 &lt;code&gt;0x7D5D&lt;/code&gt;  替换。因此，接收方用 &lt;code&gt;0x7E&lt;/code&gt; 替换接收的 &lt;code&gt;0x7D5E&lt;/code&gt; ，并用 &lt;code&gt;0x7D&lt;/code&gt; 替换接收的 &lt;code&gt;0x7D5D&lt;/code&gt;。 在同步链路（例如 T1 线路、 T3 线路）上， PPP 使用&lt;strong&gt;位填充&lt;/strong&gt;。注意，标志字符的位模式为 &lt;code&gt;01111110&lt;/code&gt; （连续 6 个 1 的位序列），在除了标志字符之外的任何地方，位填充在 5 个连续 1 之后填充一个 0。这样做意味着，发送的字节可能超过 8 位，但这通常是正常的，因为低层串行处理硬件能去掉填充的比特流，并将它恢复成未填充时的样子。&lt;/p&gt;
&lt;p&gt;在第一个标志字段之后， PPP 采用 HDLC 的&lt;strong&gt;地址&lt;/strong&gt;（Addr）和控制字段。在 HDLC 中，地址字段用于指定哪个站正在处理，但是由于 PPP 只关心一个目的地，这个字段总是被设置为 &lt;code&gt;0xFF&lt;/code&gt; （所有站）。 HDLC 控制字段用于指示帧序列和重传行为。由于这些链路层的可靠性功能通常不是由 PPP 实现，所以控制字段设置为固定值 &lt;code&gt;0x03&lt;/code&gt;。 由于地址和控制字段在 PPP 中都是固定的常数，所以在传输过程中经常通过一个称为**地址和控制字段压缩（ACFC）**的选项来省略它们，该选项实质上是消除了这两个字段。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;注意   链路层网络应提供多少可靠性，多年来一直存在相当大的争议。在以太网
中，在放弃之前可尝试重传多达 16 次。通常， PPP 被配置为不重传，尽管确实
有增加重传的规范 [RFC1663]。折中方案是巧妙的，但它依赖于携带的流量类型。
[RFC3366] 详细讨论了要考虑的有关因素。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;PPP 帧的&lt;strong&gt;协议&lt;/strong&gt;字段表明携带的数据类型。在一个 PPP 帧中，可携带多种不同类型的协议。正式列表和用于&lt;strong&gt;协议&lt;/strong&gt;字段的分配号显示在“点到点协议字段分配”文档中 [&lt;a href=&#34;#PPPn&#34;&gt;PPPn&lt;/a&gt;] 。根据 HDLC 规范，协议号的分配方式为：高位字节的最低有效位为 0，低位字节的最低有效位为1。 &lt;code&gt;0x0000 ~ 0x3FFF&lt;/code&gt; （十六进制）范围内的值表示网络层协议， &lt;code&gt;0x8000 ~ 0xBFFF&lt;/code&gt; 范围内的值表示 NCP 的相关数据。 &lt;code&gt;0x4000 ~ 0x7FFF&lt;/code&gt; 范围内的值用于 NCP 不相关的“很少使用的”协议。 &lt;code&gt;0xC000 ~ 0xEFFF&lt;/code&gt; 范围内的值表示控制协议，例如 LCP。在某些情况下，如果**协议字段压缩（PFC）**选项在链路建立时协商成功，&lt;strong&gt;协议&lt;/strong&gt;字段可被压缩为 1 字节。 &lt;code&gt;0x0000 ~ 0x00FF&lt;/code&gt; 范围内的协议号适用于包括大多数流行的网络层协议在内的协议。注意， LCP 分组总是使用 2 字节的未压缩格式。&lt;/p&gt;
&lt;p&gt;PPP 帧的最后部分包含一个 16 位的 FCS（一个 CRC16，生成多项式为 &lt;code&gt;10001000000100001&lt;/code&gt;），涵盖除 FCS 字段本身和标志字节之外的整个帧。注意， FCS 的值涵盖任何字节或位被填充之前的帧。 LCP 选项（见 3.6.1.2 节）可将 CRC 从 16 位扩展到 32 位。在这种情况下，可采用与前面提到的以太网相同的 CRC32 多项式。&lt;/p&gt;
&lt;h4 id=&#34;3611-lcp-操作&#34;&gt;3.6.1.1 LCP 操作&lt;/h4&gt;
&lt;p&gt;LCP 在基本 PPP 分组之上进行了简单的封装。如图 3-23 所示。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;23&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1652888191158.png&#34; alt=&#34;图 3-23&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 3-23   LCP 分组采用很普通的格式，能识别封装数据的类型和长度。 LCP 帧主要用于建立 PPP 链路，这种格式已成为很多网络控制协议的基础&lt;/p&gt;
&lt;p&gt;LCP 的 PPP 协议字段值始终是 &lt;code&gt;0xC021&lt;/code&gt;，它不能用 PFC 删除，以免产生歧义。&lt;strong&gt;标识&lt;/strong&gt;字段是由 LCP 请求帧的发送方提供的序列号，并随着每个后续消息进行递增。在生成一个回复（ACK、 NACK 或 REJECT 响应）时，这个字段通过复制响应分组请求中包含的值来构造。采用这种方式，请求方可通过匹配标识符来识别相应请求的应答。&lt;strong&gt;代码&lt;/strong&gt;字段给出了请求或响应的操作类型：配置请求（&lt;code&gt;0x01&lt;/code&gt;）、配置 ACK （&lt;code&gt;0x02&lt;/code&gt;）、配置 NACK （&lt;code&gt;0x03&lt;/code&gt;）、配置 REJECT（&lt;code&gt;0x04&lt;/code&gt;）、终止请求（&lt;code&gt;0x05&lt;/code&gt;）、终止 ACK （&lt;code&gt;0x06&lt;/code&gt;）、代码 REJECT（&lt;code&gt;0x07&lt;/code&gt;）、协议REJECT（&lt;code&gt;0x08&lt;/code&gt;）、回送请求（&lt;code&gt;0x09&lt;/code&gt;）、回送应答 （&lt;code&gt;0x0A&lt;/code&gt;）、放弃请求 （&lt;code&gt;0x0B&lt;/code&gt;）、标识（&lt;code&gt;0x0C&lt;/code&gt;）和剩余时间（&lt;code&gt;0x0D&lt;/code&gt;）。 ACK 消息通常表明接受一组选项， NACK 消息用建议选项表明部分拒绝。 REJECT 消息完全拒绝一个或多个选项。拒绝代码表明前一个分组包含的某些字段值未知。长度字段给出了 LCP 分组的字节长度，它不能超过链路的&lt;strong&gt;最大接收单元（MRU）&lt;/strong&gt;，我们稍后讨论一种建议的最大帧限制。注意，长度字段是 LCP 协议的一部分；PPP 协议通常不提供这种字段。&lt;/p&gt;
&lt;p&gt;LCP 的主要工作是使一条点到点链路达到最低要求。&lt;strong&gt;配置&lt;/strong&gt;消息使链路两端开始基本配置过程，并建立商定的选项。&lt;strong&gt;终止&lt;/strong&gt;消息用于在完成后清除一条链路。 LCP 也提供了前面提到的一些附加功能。&lt;strong&gt;回送请求/应答&lt;/strong&gt;消息可由 LCP 在一条活跃链路上随时交换，以验证对方的操作。&lt;strong&gt;放弃请求&lt;/strong&gt;消息可用于性能测试，指示对方丢弃没有响应的分组。&lt;strong&gt;标识&lt;/strong&gt;和&lt;strong&gt;剩余时间&lt;/strong&gt;消息用于管理目的：了解对方的系统类型，指出链路保持建立的时间（例如出于管理或安全原因）。&lt;/p&gt;
&lt;p&gt;从历史上来看，如果一个远程工作站处于&lt;strong&gt;环回模式&lt;/strong&gt;（或者说“回路”），这时点到点链路会出现一个常见问题。电话公司的广域数据线路有时会为了测试而设置成环回模式，由一方发送的数据直接由另一方返回。虽然这可能对线路测试有用，但它对数据通信完全没有帮助，所以 LCP 包括一种发送&lt;strong&gt;魔术数字&lt;/strong&gt;（由发送方选择的任意数字）的方式，并查看是否立即返回相同类型的消息。如果是的话，该线路被检测为处于回路，并可能需要进行维护。&lt;/p&gt;
&lt;p&gt;为了对 PPP 链路建立和选项协商有一个更好的认识，图 3-24 显示了一个简化的分组交换时间表和一个简化的状态机（在链路两端实现）。&lt;/p&gt;
&lt;p&gt;一旦底层协议表明一个关联变为活跃（例如调制解调器检测到载波），则认为这个链路已被建立。链路质量测试包含链路质量报告和确认交换（见 3.6.1.2 节），它也可以在此期间完成。如果链接需要认证（这是常见的），例如当拨号到一个 ISP 时，可能需要一些额外的信息交换，以认证链路上的一方或双方的身份。当底层协议或硬件表明一个关联已停止（例如载波消失），或发送一个链路终止请求，并从对方接收到一个终止响应，则认为这个链路已被终止。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;24&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1652888802627.png&#34; alt=&#34;图 3-24&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 3-24   LCP 用于建立 PPP 链路和各方商定选项。典型的交换过程包括一对包含选项列表的配置请求和配置确认、一个认证交换、数据交换（未画出）和一个终止交换。因为 PPP 是一个包括很多部分的通用协议，所以在一条链路建立和终止之间可能发生很多其他类型的操作&lt;/p&gt;
&lt;h4 id=&#34;3612-lcp-选项&#34;&gt;3.6.1.2 LCP 选项&lt;/h4&gt;
&lt;p&gt;当 LCP 建立一条由一个或多个 NCP 使用的链路时，可以对一些选项进行协商。我们将讨论两种或更多的常见情况。**异步控制字符映射（ACCM）**或简称“ asyncmap”选项定义哪些控制字符（即 &lt;code&gt;0x00 ~ 0x1F&lt;/code&gt; 范围内的 ASCII 字符）需要被“转义”为 PPP 操作。转义一个字符表示不发送这个字符的真实值，而将 PPP 转义字符（&lt;code&gt;0x7D&lt;/code&gt;）放在控制字符原始值和 &lt;code&gt;0x2D&lt;/code&gt; 异或形成的值之前。例如， XOFF 字符（&lt;code&gt;0x13&lt;/code&gt;）将转换为（&lt;code&gt;0x7D33&lt;/code&gt;）发送。 ACCM 用于控制字符可能影响底层硬件操作的情况。例如，如果软件流控制能够使用 XON/XOFF 字符，而 XOFF 字符未经转义就通过链路传输，则硬件直到看到一个 XON 字符才停止数据传输。asyncmap 选项通常是一个 32 位的十六进制数，其中第 n 个最低有效位被设置为 1 ，表示值为 n 的控制字符应被转义。因此， asyncmap 为 &lt;code&gt;0xffffffff&lt;/code&gt; 表示转义所有控制字符，为 &lt;code&gt;0x00000000&lt;/code&gt;表示不转义任何控制字符，为 &lt;code&gt;0x000A0000&lt;/code&gt; 表示转义 XON （&lt;code&gt;0x11&lt;/code&gt;）和 XOFF （&lt;code&gt;0x13&lt;/code&gt;）。虽然 &lt;code&gt;0xffffffff&lt;/code&gt; 是默认值，但当前很多链路可在 asyncmap 被设置为 &lt;code&gt;0x00000000&lt;/code&gt; 时安全运行。&lt;/p&gt;
&lt;p&gt;由于 PPP 缺少一个长度字段，并且串行线路通常不提供帧封装，所以在理论上对一个 PPP 帧的长度没有硬性限制。实际上，最大帧大小通常由 MRU 指定。当一台主机指定一个 MRU 选项（&lt;code&gt;0x01&lt;/code&gt;）时，它要求对方不发送比 MRU 选项提供的值更长的帧。 MRU 值是数据字段的字节长度，它不计算其他 PPP 开销字段（即协议、 FCS、标志字段）。它的典型值是 1500 或 1492，但也可能多达 65535。 1Pv6 操作需要的长度最小为 1280。 PPP 标准要求具体实现能接收最大 1500 字节的帧， MRU 更多的是建议对方选择帧大小，而不是硬性限制帧大小。当小分组和大分组在同一条 PPP 链路上交错传输时，较大分组可能占用一条低带宽链路的大部分带宽，并影响小分组的正常传输。这可能导致抖动（延迟变化），对交互式应用（例如远程登录和 VoIP）产生负面影响。配置较小的 MRU （或 MTU）有助于缓解这个问题，但会产生更大的开销。&lt;/p&gt;
&lt;p&gt;PPP 支持一种交换链路质量报告信息的机制。在选项协商期间，可能包括一个包含所请求的特定质量协议的配置信息。选项中的第 16 位被保留给特定协议，但最常见的是一个包括**链路质量报告（LQR）**的 PPP 标准 [&lt;a href=&#34;#RFC1989&#34;&gt;RFC1989&lt;/a&gt;] ，它在 PPP 协议字段中使用值 &lt;code&gt;0xC025&lt;/code&gt;。如果启用该选项，则要求对方按某个周期间隔提供 LQR。 LQR 请求之间的最大周期间隔被编码为一个 32 位数字，它被保存在配置选项中，并以 1/100 秒为单位表示。对方可能比这个要求更频繁地生成 LQR。LQR 包括以下信息：一个魔术数字、发送和接收的分组数和字节数、出错的输入分组数和丢弃的分组数，以及交换的 LQR 总数。在一个典型的实现中，允许用户设置对方发送 LQR 的频繁程度。如果链路质量无法满足某些配置阈值，有些实现也提供了终止链路的方法。 LQR 可在 PPP 链路进入建立状态后请求。每个 LQR 被赋予一个序列号，因此它能确定一段时间内的趋势，甚至在 LQR 重新排序时也能确定。&lt;/p&gt;
&lt;p&gt;很多 PPP 实现支持一种&lt;strong&gt;回叫&lt;/strong&gt;功能。在一次典型的回叫建立过程中， PPP 拨号回叫客户端呼叫 PPP 回叫服务器，并提供认证信息，而服务器断开连接并回叫客户端。在呼叫费用不对称或对于某些安全级别的情况下，这种做法可能是有用的。 LCP 选项针对用于协商回叫的协议，该选项值为 &lt;code&gt;0x0D&lt;/code&gt;  [&lt;a href=&#34;#RFC1570&#34;&gt;RFC1570&lt;/a&gt;]。如果许可，**回叫控制协议（CBCP）**完成协商。&lt;/p&gt;
&lt;p&gt;PPP 使用的一些压缩和加密算法在处理时需要一定的最小字节数，称为&lt;strong&gt;块大小&lt;/strong&gt;。在数据不够长的情况下，通过填充增加数据长度，达到一个甚至多个块的大小。如果存在填充，它通常位于数据区后面，并位于 PPP FCS 字段之前。一种填充方法称为&lt;strong&gt;自描述填充&lt;/strong&gt; [&lt;a href=&#34;#RFC1570&#34;&gt;RFC1570&lt;/a&gt;]，它将填充值变为非零值。这时，每个字节获得填充区域的偏移量值。因此，填充的第一个字节值为 &lt;code&gt;0x01&lt;/code&gt;，最后一个字节包含填充字节数。最多支持 255 字节的填充。自描述填充选项（类型 10）用于让对方了解填充类型和&lt;strong&gt;最大填充值（MPV）&lt;/strong&gt;，它是这个关联允许的最大填充值。由于基本 PPP 帧缺少一个明确的长度字段，因此一个接收方可使用自描述填充，以确定应从接收的数据区删除多少填充字节。&lt;/p&gt;
&lt;p&gt;为了减小每个帧包含一个头部的固定开销，提出了一种将多个不同协议的有效载荷聚合成 PPP 帧的方法，称为 PPPMux [&lt;a href=&#34;#RFC3153&#34;&gt;RFC3153&lt;/a&gt;] 方法。主要 PPP 头部的协议字段被设置为聚合帧（&lt;code&gt;0x0059&lt;/code&gt;），然后每个有效载荷块被插入帧中。通过在每个有效载荷块之前插入 1 ~ 4 字节的子帧头部来实现。在子帧头部中， 1 位（称为 PFF）说明子帧头部中是否包含协议字段，1 位（称为 LXT）说明后面的长度字段是 1 字节还是 2 字节。除此之外， 1 或 2 字节的协议 ID 使用与外部的 PPP 头部相同的值和压缩方法。在子帧与默认 PID （该 PID 在配置阶段通过 **PPPMux 控制协议（PPPMuxCP）**建立）匹配时， PFF 可以为 0 （意味着不存在 PID 字段）。&lt;/p&gt;
&lt;p&gt;PPP 帧格式如图 3-19 所示，普通 PPP/HDLC 的 FCS 可以是 16 或 32 位。默认的 FCS 为 16 位，但 32 位的 FCS 值可通过 32 位的 FCS 选项来启用。其他的 LCP 选项包括使用 PFC 和 ACFC，以及认证算法的选择。&lt;/p&gt;
&lt;p&gt;国际化 [&lt;a href=&#34;#RFC2484&#34;&gt;RFC2484&lt;/a&gt;] 提供了一种使用语言和字符集的表示方式。字符集是一个来自“字符集注册表” [&lt;a href=&#34;#IANA-CHARSET&#34;&gt;IANA-CHARSET&lt;/a&gt;] 的标准值，并从 [&lt;a href=&#34;#RFC5646&#34;&gt;RFC5646&lt;/a&gt;] [&lt;a href=&#34;#RFC4647&#34;&gt;RFC4647&lt;/a&gt;] 的列表中选择语言。&lt;/p&gt;
&lt;h3 id=&#34;362-多链路-ppp&#34;&gt;3.6.2 多链路 PPP&lt;/h3&gt;
&lt;p&gt;PPP 的一个特殊版本称为&lt;strong&gt;多链路PPP （MP）&lt;/strong&gt; [&lt;a href=&#34;#RFC1990&#34;&gt;RFC1990&lt;/a&gt;]，可用于将多条点到点链路聚合为一条链路。这种想法与前面讨论过的链路聚合相似，并被用于多个电路交换信道（例如 ISDNB 信道）的聚合。 MP 包含一个特殊的 LCP 选项，表示支持多链路，以及一个用于多链路上 PPP 帧分片与重组的协商协议。一条聚合链路（称为一个&lt;strong&gt;捆绑&lt;/strong&gt;）可作为一条完整的虚拟链路来操作，并包含自己的配置信息。链路捆绑由大量&lt;strong&gt;成员链路&lt;/strong&gt;组成。每个成员链路可能有自己的选项集。&lt;/p&gt;
&lt;p&gt;实现 MP 的典型方法是使分组轮流经过各个成员链路传输。这种方法称为&lt;strong&gt;银行柜员算法&lt;/strong&gt;，它可能导致分组重新排序，可能为其他协议带来不良的性能影响。 （例如，虽然 TCP/IP 可以正确处理重新排序后的分组，但也可能不如没有重新排序处理得好。） MP 在每个分组中添加一个 2 ~ 4 字节的&lt;strong&gt;序列头部&lt;/strong&gt;，而远程 MP 接收方的任务是重建正确的顺序。图 3-25 显示了这种数据帧。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;25&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1652953897257.png&#34; alt=&#34;图 3-25&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 3-25   一个 MP 分片包含一个序列头部，允许在一个多链路捆绑的远端对分片重新排序。这个头部支持 2 种格式：短头部（2 字节）和长头部（4 字节）&lt;/p&gt;
&lt;p&gt;在图 3-25 中，我们看到一个 MP 分片的开始分片（B）、结束分片（E）位字段和&lt;strong&gt;序列号&lt;/strong&gt;字段。这里，需要注意的是长格式（4 字节用于分片信息）和短格式（2 字节用于分片信息）。在选项协商阶段，  LCP 的&lt;strong&gt;短序列号&lt;/strong&gt;选项（类型 18）用于选择使用的格式。如果一个帧没有被分片，但使用这种格式传输，则 B 和 E 位都被置位，表明该分片是第一个和最后一个（即它是整个帧）。否则，第一个分片的 B、 E 位组合被设置为 &lt;code&gt;10&lt;/code&gt;，最后一个分片的 B、 E位 组合被设置为 &lt;code&gt;01&lt;/code&gt; ，它们之间的所有分片被设置为 &lt;code&gt;00&lt;/code&gt;。序列号给出相对第一个分片的分组号偏移量。&lt;/p&gt;
&lt;p&gt;MP 使用一个称为多链路&lt;strong&gt;最大接收重构单元&lt;/strong&gt;（MRRU，类型 18）的 LCP 选项，它可将一系列更大的 MRU 应用于捆绑中。大于成员链路 MRU 的帧仍被允许通过这个 MP 链路，直到达到这个值的上限为止。&lt;/p&gt;
&lt;p&gt;由于一个 MP 捆绑可能跨越多条成员链路，因此需要一种方法来确定成员链路属于同一捆绑。同一捆绑中的成员链路由 LCP &lt;strong&gt;端点鉴别&lt;/strong&gt;（类型 19）选项识别。端点鉴别可使用电话号码、从 IP 或 MAC 地址中提取的数字，以及其他可管理的字符串。除了每个成员链路的常见内容，对这个选项的格式没有多少限制。&lt;/p&gt;
&lt;p&gt;建立 MP 的基本方法定义在 [&lt;a href=&#34;#RFC1990&#34;&gt;RFC1990&lt;/a&gt;] 中，希望各个成员链路可对称使用，相近数量的分片被分配到号码固定的每条链路上。为了实现更复杂的分配， [&lt;a href=&#34;#RFC2125&#34;&gt;RFC2125&lt;/a&gt;] 中规定了&lt;strong&gt;带宽分配协议（BAP）&lt;strong&gt;和&lt;/strong&gt;带宽分配控制协议（BACP）&lt;/strong&gt;。 BAP 用于为一个捆绑动态添加或删除链路，而 BACP 用于交换如何使用 BAP 添加或删除链路的信息。这种功能有助于实现&lt;strong&gt;按需带宽（BOD）&lt;/strong&gt;。在一些需要分配固定资源以满足应用（例如一定数量的电话连接）对带宽需求的网络中， BOD 通常需要监测流量，在应用需求高时创建新的连接，以及在应用需求低时删除连接。在某些开销和连接数量相关的情况下，这种功能是有用的。&lt;/p&gt;
&lt;p&gt;BAP/BACP 使用一种新的&lt;strong&gt;链路鉴别&lt;/strong&gt; LCP 选项（LCP 选项类型为 23）。这个选项包含一个 16 位的数字值，一个捆绑中的每条成员链路有不同的值。它被 BAP 用于确定需要添加或删除哪些链路。在一条 PPP 链路的网络阶段，每个捆绑都需要使用 BACP 协商。它的主要目的是找出&lt;strong&gt;首选对端&lt;/strong&gt;。也就是说，如果在多个对端之间同时建立多个捆绑时，将会优先为首选对端分配成员链路。&lt;/p&gt;
&lt;p&gt;BAP 包括 3 种分组类型：请求、响应和标识。请求用于向一个捆绑添加一条链路，或从一个捆绑中删除一条链路。标识用于为原始或被确认的请求返回结果。响应是对这些请求的 ACK 或 NACK。更多细节见 [&lt;a href=&#34;#RFC2125&#34;&gt;RFC2125&lt;/a&gt;] 。&lt;/p&gt;
&lt;h3 id=&#34;363-压缩控制协议&#34;&gt;3.6.3 压缩控制协议&lt;/h3&gt;
&lt;p&gt;从历史上来看， PPP 是相对较慢的拨号调制解调器使用的协议。因此，针对 PPP 链路上压缩后发送数据已提出一些方法。压缩类型是不同的，无论是调制解调器硬件支持的压缩类型（例如 V.42bis、 V.44），还是我们以后讨论的协议头部压缩。目前，有几个压缩选项可选。可在一条 PPP 链路的两个方向做出选择， LCP 可协商一个使&lt;strong&gt;压缩控制协议（CCP）&lt;/strong&gt; [&lt;a href=&#34;#RFC1962&#34;&gt;RFC1962&lt;/a&gt;] 生效的选项。 CCP 的作用就像 NCP （见 3.6.5 节），只不过在 LCP 链路建立交换阶段指明压缩选项时才开始处理配置压缩细节。&lt;/p&gt;
&lt;p&gt;CCP 在行为上很像 NCP，仅在链路进入网络状态时协商。它使用与 LCP 相同的分组交换过程和格式（除协议字段被设置为 &lt;code&gt;0x80FD&lt;/code&gt; 之外），另外还有一些特殊选项，并对常见的&lt;strong&gt;代码&lt;/strong&gt;字段值（1 ~ 7）定义了 2个 新的操作：复位请求（&lt;code&gt;0x0e&lt;/code&gt;）和复位确认（&lt;code&gt;0x0f&lt;/code&gt;）。如果在一个压缩帧中检测到一个错误，复位请求可用于要求对方复位压缩状态（例如字典、状态变量、状态机等）。在复位后，对方响应一个复位确认。&lt;/p&gt;
&lt;p&gt;一个或多个压缩帧可作为一个 PPP 帧的一部分（即包括 LCP 数据和可能的填充部分）。压缩帧携带的&lt;strong&gt;协议&lt;/strong&gt;字段值为 &lt;code&gt;0x00FD&lt;/code&gt;，但是如何指明存在多个压缩帧，这依赖于使用的特定压缩算法（见 3.6.6 节）。当 CCP 与 MP 结合使用时，既可用于一个捆绑，也可用于多条成员链路的某些组合。如果只用于成员链路，&lt;strong&gt;协议&lt;/strong&gt;字段设置为 &lt;code&gt;0x00FB&lt;/code&gt; （单个的链路压缩数据报）。&lt;/p&gt;
&lt;p&gt;CCP 可使用十几个压缩算法之一 [&lt;a href=&#34;#PPPn&#34;&gt;PPPn&lt;/a&gt;] 。大多数算法是官方标准的 IETF 文档，虽然它们可能已在 RFC 中加以描述（例如， [&lt;a href=&#34;#RFC1977&#34;&gt;RFC1977&lt;/a&gt;] 描述了 BSD 压缩方案， [&lt;a href=&#34;#RFC2118&#34;&gt;RFC2118&lt;/a&gt;] 描述了 Microsoft &lt;strong&gt;点对点压缩协议&lt;/strong&gt;（MPPC））。如果使用压缩， PPP 帧在进一步处理之前需要重构，因此高层的 PPP 操作通常不关心压缩帧的细节。&lt;/p&gt;
&lt;h3 id=&#34;364-ppp-认证&#34;&gt;3.6.4 PPP 认证&lt;/h3&gt;
&lt;p&gt;在一条 PPP 链路处于网络状态之前，通常有必要使用某种&lt;strong&gt;认证&lt;/strong&gt;（身份验证）机制，以识别建立链路的对方身份。基本的 PPP 规范默认不提供认证，因此图 3-24 中的认证交换在这种情况下不会出现。但是，某种形式的认证在多数时候是需要的，一些经过多年演变的协议被用于应对这种情况。在本章中，我们仅从高层的角度展开讨论，并将细节留给关于安全的章节（第 18 章）。与不提供认证相比，最简单、安全性最低的认证方案是&lt;strong&gt;密码认证协议（PAP）&lt;/strong&gt;。这种协议非常简单，一方请求另一方发送一个密码。由于该密码在 PPP 链路上未加密传输，窃听者在线路上可轻易捕获密码并使用它。由于这个重大的漏洞，不建议使用 PAP 进行认证。 PAP 分组像 LCP 分组那样编码，协议字段值设置为 &lt;code&gt;0xC0230&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;查询——握手认证协议（CHAP）&lt;/strong&gt; [&lt;a href=&#34;#RFC1994&#34;&gt;RFC1994&lt;/a&gt;] 提供了一种更安全的认证方法。在使用 CHAP 时，一个随机值从一方（称为认证方）发送到另一方。响应通过一种特殊的&lt;strong&gt;单向&lt;/strong&gt;（即不可逆）功能，将一个随机值和一个共享密钥（通常由密码生成）结合形成响应中的一个数字。在接收到这个响应之后，认证方能更可靠地验证对方密钥是否正确。这个协议在链路上不会以明文（未加密）形式发送密钥或密码，因此窃听者难以了解相关信息。由于每次使用不同的随机值，每个查询/响应的结果会改变，即使一个窃听者有可能捕捉到这个值，也无法通过重新使用（回放）来欺骗对方。&lt;/p&gt;
&lt;p&gt;EAP [&lt;a href=&#34;#RFC3748&#34;&gt;RFC3748&lt;/a&gt;] 是一个可用于各种网络的认证框架。它支持很多（约 40 个）不同的认&lt;br&gt;
证方法，从简单密码（例如 PAP 和 CHAP）到更可靠的认证类型（例如智能卡、生物识别）。EAP 定义了一种携带各种认证的消息格式，但需要额外的规范定义 EAP 消息如何在特定的链路上传输。&lt;/p&gt;
&lt;p&gt;当 EAP 被用于 PPP 时，前面讨论过的基本认证方法不变。 EAP 不是在链路建立（LCP 建立）阶段协商一种认证方法，认证操作将被推迟到认证状态（网络状态的前一个状态）。这允许更多信息类型用于影响**远程访问服务器（RAS）**的访问控制决策。当某种标准的协议用于执行各种认证机制，网络访问服务器可能无须处理 EAP 消息内容，但可依靠其他基础设施的认证服务器（例如 RADIUS 服务器 [&lt;a href=&#34;#RFC2865&#34;&gt;RFC2865&lt;/a&gt;] ）确定访问控制决策。这是当前的企业网和 ISP 设计中的首选方案。&lt;/p&gt;
&lt;h3 id=&#34;365-网络控制协议&#34;&gt;3.6.5 网络控制协议&lt;/h3&gt;
&lt;p&gt;虽然多种 NCP 可用于一条 PPP 链路（甚至同时），但我们将关注支持 IPv4 和 IPv6 的 NCP。 对于 IPv4， NCP 被称为&lt;strong&gt;IP控制协议（IPCP）&lt;/strong&gt; [&lt;a href=&#34;#RFC1332&#34;&gt;RFC1332&lt;/a&gt;] 。对于 IPv6， NCP 被称为 IPV6CP [&lt;a href=&#34;#RFC5072&#34;&gt;RFC5072&lt;/a&gt;] 。在 LCP 完成链路建立和认证之后，该链路每端都进入网络状态，并使用一个或多个 NCP （例如典型的是一个 IPCP）进行网络层的相关协商。&lt;/p&gt;
&lt;p&gt;IPCP （针对 IPv4 的标准 NCP）可用于在一条链路上建立 IPv4 连接，以及配置 &lt;strong&gt;Van Jacobson 头部压缩（VJ 压缩）&lt;/strong&gt; [&lt;a href=&#34;#RFC1144&#34;&gt;RFC1144&lt;/a&gt;] 。 IPCP 分组在 PPP 状态机进入网络状态之后交换。IPCP 分组使用与 LCP 相同的分组交换机制和分组格式，除非协议字段被设置为 &lt;code&gt;0x8021&lt;/code&gt;，并且代码字段被限制在范围 0 ~ 7。代码字段的值对应于消息类型：特定供应商（见 [&lt;a href=&#34;#RFC2153&#34;&gt;RFC2153&lt;/a&gt;] ）、配置请求、配置 ACK、配置 REJECT、终止请求、终止 ACK和代码 REJECT。 IPCP 可协商一系列选项，包括 IP 压缩协议（2）、 IPv4 地址（3）和移动 IPv4 （4） [&lt;a href=&#34;#RFC2290&#34;&gt;RFC2290&lt;/a&gt;]。其他选项可用于获得主要和次要的域名服务器（见第 11 章）。&lt;/p&gt;
&lt;p&gt;IPV6CP 使用与 LCP 相同的分组交换机制和分组格式，但它有两种不同的选择：接口标识符和 IPv6 压缩协议。接口标识符选项用于传输一个 64 位的 IID 值（见第 2 章），它作为形成一个链路本地 IPv6 地址的基础。由于它仅在本地链路上使用，因此不需要具有全球唯一性。这通过在 IPv6 地址的高位使用标准链路本地前缀，在低位设置某种功能的接口标识符来实现。这里模拟了 IPv6 自动配置过程（见第 6 章）。&lt;/p&gt;
&lt;h3 id=&#34;366-头部压缩&#34;&gt;3.6.6 头部压缩&lt;/h3&gt;
&lt;p&gt;PPP 拨号线路的速率一直较慢（54000b/s 或更少），很多小的分组通常使用 TCP/IP （例如 TCP 确认，见第 15 章）。这些分组大部分包含 TCP 和 IP 头部，同一 TCP 连接上的分组之间变化不大。其他高层协议的行为相似。因此，压缩（或消除）高层协议头部是一种有用的方法，这样以来就可在相对较慢的点到点链路上传输更少字节。现代的压缩或消除头部方法一直在随着时间演变。我们将从前面提到的 VJ 压缩开始，按时间顺序讨论它们。&lt;/p&gt;
&lt;p&gt;在 VJ 压缩中，部分高层（TCP 和 IP）头部被 1 字节的连接标识符代替。 [&lt;a href=&#34;#RFC1144&#34;&gt;RFC1144&lt;/a&gt;] 讨论了这种方法的起源，它最初来源于一种旧的、称为 CSLIP （压缩串行线路 IP）的点到点协议。一个典型 IPv4 头部的长度是 20 字节，一个没有选项的 TCP 头部的长度也是 20 字节。因此，一个常见的 TCP/IPv4 头部组合是 40 字节，并且很多字段在分组间没有变化。另外，很多字段在分组间只有很小或有限的变化。如果不变的值通过一条链路（或一段时间内）传输并被保存在一张表中，则在后续分组中可用一个小的索引代替该值。变化有限的值可以仅编码差异部分（即仅发送变化的部分）。因此，整个 40 字节头部通常可有效压缩到 3 或 4 字节。这样可显著提高在低速链路上的 TCP/IP 性能。&lt;/p&gt;
&lt;p&gt;头部压缩的下一步演化简称为 IP 头部压缩 [&lt;a href=&#34;#RFC2507&#34;&gt;RFC2507&lt;/a&gt;] [&lt;a href=&#34;#RFC3544&#34;&gt;RFC3544&lt;/a&gt;] 。它提供了一种压缩多个分组头部的方式，使用 TCP 或 UDP 传输层协议，以及 IPv4 或 IPv6 网络层协议。这种技术是 VJ 压缩技术的一种逻辑上的扩展，可用于多种协议以及 PPP 链路之外的其他链路。 [&lt;a href=&#34;#RFC2507&#34;&gt;RFC2507&lt;/a&gt;] 指出了底层链路层的一些强大的差错检测机制的必要性，因为，如果压缩头部在运输过程中损坏，出错的分组可在离开链路层时被构造。我们需要认识到，当头部压缩用于链路上时，可能不会像 PPP 的 FCS 计算那样强大。&lt;/p&gt;
&lt;p&gt;头部压缩的最新改进方案称为&lt;strong&gt;鲁棒性头部压缩（ROHC）&lt;/strong&gt; [&lt;a href=&#34;#RFC5225&#34;&gt;RFC5225&lt;/a&gt;]。它进一步改进了 IP 头部压缩以涵盖更多的传输协议，并允许同时处理多种头部压缩方式。前面提到的 IP 头部压缩可适用于不同类型的链路，包括 PPP。&lt;/p&gt;
&lt;h3 id=&#34;367-例子&#34;&gt;3.6.7 例子&lt;/h3&gt;
&lt;p&gt;我们查看一台 PPP 服务器的调试输出，它通过拨号的调制解调器与客户机交互。客户机是一台有 IPv6 功能的运行 Microsoft Windows Vista 的计算机，服务器是一台运行 Linux 的计算机。客户机配置为可在单一链路上协商多链路功能（属性|选项IPPP 设置），出于演示目的，服务器配置为使用 CCP 协商加密协议（见以下代码清单中的 MPPE）：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1652962371471.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1652962559431.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;p&gt;这里，我们可看到一些涉及 PPP 的交换，它是从服务器的角度来看的。 PPP 服务器进程创建的（虚拟）网络接口为 ppp0，它在连接串行端口 ttyS0 的拨号调制解调器上等待连接请求（称为“输入连接”）。当有连接请求到达时，服务器依次发送 &lt;code&gt;0x0&lt;/code&gt; 的异步控制字符映射（asyncmap）、 EAP 认证、 PFC 和ACFC 请求。客户拒绝 EAP 认证，并建议使用 MS-CHAP-v2 （ConENak） [&lt;a href=&#34;#RFC2759&#34;&gt;RFC2759&lt;/a&gt;]。服务器再次尝试发送请求，并使用 MS-CHAP-v2，这请求被接受和确认（ConfAck）。接下来，“输入”请求包括 CBCP，一个与 MP 支持相关的 1614 字节的 MRRU，以及一个端点 ID。 服务器拒绝 CBCP 和多链路操作（ConfRej）请求。客户机发送不带 MRRU 的端点鉴别请求，并被接收和确认。下一步，服务器发送一个名为 dialer 的 CHAP 查询。在该查询的响应到达之前，两个标识消息到达，表明对方以字符串 MSRASV5.20 和 MSRAS-0-VISTA 来标识。最后， CHAP 响应到达并验证通过，表明许可访问。这时， PPP 转换为网络状态。&lt;/p&gt;
&lt;p&gt;当进入网络状态时， CCP、 IPCP 和 IPV6CP NCP 被交换。 CCP 尝试协商&lt;strong&gt;微软点对点加密（MPPE）&lt;/strong&gt; [&lt;a href=&#34;#RFC3078&#34;&gt;RFC3078&lt;/a&gt;] 。MPPE 有些不同之处，因为它是一种加密协议，而不是一种压缩协议，它实际将分组扩大了 4 字节。但是，它提供了一个相对简单的方法，早在协商过程中就完成了加密。选项 &lt;code&gt;+H -M +S +L -D -C&lt;/code&gt; 表明 MPPE 是否采用无状态操作（H）、使用哪种加密密钥强度（安全， S；中等， M；低， L）、是否存在过时的 D 位，以及是否需要单独、专用的 MPPC 的压缩协议（C） [&lt;a href=&#34;#RFC2118&#34;&gt;RFC2118&lt;/a&gt;] 。最终，双方同意在有状态模式下使用强大的 128 位密钥（-H， +S）。注意，在这次协商过程中，客户机尝试发送一个 IPCP 请求，但服务器响应的是一个主动的 TermAck （一个 LCP 定义、 ICPC 采纳的消息）。它用于向对方指出服务器“需要重新谈判”         [&lt;a href=&#34;#RFC1661&#34;&gt;RFC1661&lt;/a&gt;]。&lt;/p&gt;
&lt;p&gt;在 MPPE 协商成功之后，服务器请求使用 VJ 头部压缩，并提供它的 IPv4 地址和 IPv6 地址，分别为 &lt;code&gt;192.168.0.1&lt;/code&gt; 和 &lt;code&gt;fe80::0206:5bff:fedd:c5c3&lt;/code&gt;。这个 IPv6 地址是从服务器的以太网 MAC 地址 &lt;code&gt;00:06:5B:DD:C5:C3&lt;/code&gt; 而来。客户机最初使用 IPCP 建议的 IPv4 地址和域名服务器&lt;code&gt;0.0.0.0&lt;/code&gt;，但被拒绝。客户机请求使用 &lt;code&gt;fe80::0000:0000:dead:beef&lt;/code&gt; 作为 IPv6 地址，这个请求被接受和确认。最后，客户机确认服务器的 IPv4 和 IPv6 地址，并且表明自己已建立 IPv6 地址。接着，客户机再次请求 IPv4 和服务器地址 &lt;code&gt;0.0.0.0&lt;/code&gt; ，再次被拒绝。 &lt;code&gt;192.168.0.1&lt;/code&gt; 被接受和确认。&lt;/p&gt;
&lt;p&gt;我们从这次交换中可看到， PPP 协商是既灵活又烦琐的。很多选项可以尝试、拒绝和重新协商。虽然在低延时链路上这可能不是一个大间题，但这种交换中的每个消息都需要花费几秒（或更长）到达目的地。如果在一条卫星链路上，则可能出现很大的超时。对用户来说，链路建立明显是一个太长的过程。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;37-环回&#34;&gt;3.7 环回&lt;/h2&gt;
&lt;p&gt;尽管可能看起来很奇怪，但在很多情况下，客户机可能希望使用 Internet 协议（例如 TCP/IP）与同一计算机上的服务器通信。为了实现这个目标，大多数实现支持一种工作在网络层的&lt;strong&gt;环回&lt;/strong&gt;（或称“回送”）能力——通常使用一个虚拟的环回网络接口来实现。它就像一个真正的网络接口，但实际上是一个由操作系统提供的专用软件，可通过 TCP/IP 与同一主机的其他部分通信。以 127 开始的 IPv4 地址就是为这个目的而保留， IPv6 地址 &lt;code&gt;::1&lt;/code&gt; （见第 2 章的 IPv4 和 IPv6 寻址约定）用于同样目的。传统上，类 UNIX 系统（包括 Linux）为环回接口分配的 IPv4 地址为 &lt;code&gt;127.0.0.1&lt;/code&gt; （IPv6 地址为 &lt;code&gt;::1&lt;/code&gt;），为它分配的名称为 &lt;code&gt;localhost&lt;/code&gt;。发送到环回接口的 IP 数据报不会出现在任何网络中。尽管我们可以想象传输层检测到另一端是一个环回地址，并跳过某些传输层逻辑和所有网络层逻辑，但大多数的实现在传输层和网络层对数据执行完整的处理流程，并仅在数据报离开网络层时将其回送给网络层协议栈。这种处理对于性能测试可能有用，例如在没有任何硬件开销的情况下，测量执行协议栈软件所需的时间。在 Linux 中，环回接口被称为 &lt;code&gt;Io&lt;/code&gt;。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;lo Link encap:Local Loopback
        inet  addr:127.0.0.1  Mask:255.0.0.0
        inet6 addr:  ::1/128  Scope:Host
        UP LOOPBACK RUNNING MTU:16436 Metric:1
        RX packets:458511 errors:0 dropped:0 overruns:0 frame:0
        TX packets:458511 errors:0 dropped:0 overruns:0 carrier:0
        collisions:0  txqueuelen:0
        RX bytes:266049199 (253.7 MiB)
        TX bytes:266049199 (253.7 MiB)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里，我们看到本地环回接口的 IPv4 地址为 &lt;code&gt;127.0.0.1&lt;/code&gt;，子网掩码为 &lt;code&gt;255.0.0.0&lt;/code&gt;（对应于分级寻址中的 A 类网络号 127）。 IPv6 地址1有一个128位的前缀，它表示只有一个地址。这个接口支持 16KB 的 MTU （可配置为更大尺寸，最大可达 2GB）。从主机在两个月前初始化开始，巨大的流量（接近 50 万个分组）无差错地通过该接口。我们不希望在本地环回设备上看到错误，假设它实际上没有在任何网络上发送分组。&lt;/p&gt;
&lt;p&gt;在 Windows 中，默认情况下没安装 Microsoft 环回适配器，尽管这样仍支持 IP 环回功能。这个适配器可用于测试各种网络配置，甚至在一个物理网络接口不可用的情况下。在 Windows XP 下安装该适配器，可选择“开始 | 控制面板 | 添加硬件 | 从列表中选择网络适配器 | 选择 Microsoft 作为制造商 | 选择 Microsoft 环回适配器” 。对于 Windows Vista 或 Windows 7，在命令提示符下运行程序 hdwwiz，并手动添加 Microsoft 环回适配器。在执行上述操作后， ipconfig 命令显示如下（这个例子来自 Windows Vista 环境）：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;C:\&amp;gt; ipconfig /all
...
Ethernet adapter Local Area Connection 2:
   Connection-specific DNS Suffix  . . . . . . . :
   Description . . . . . . . . . . . . . . . : Microsoft Loopback Adapter
   Physical Address. . . . . . . . . . . . . : 02-00-4C-4F-4F-50
   DHCP Enabled . . . . . . . . . . . : Yes
   Autoconfiguration Enabled. . . . . . . . . . : Yes
   Link-local IPv6 Address. . . . . . . . : fe80::9c0d:77a:52b8:39f0%18(Preferred)
   Autoconfiguration IPv4 Address . . . . . . . . . . . . : 169.254.57.240(Preferred)
   Subnet Mask  . . . . . . . . . . . . : 255.255.0.0
   Default Gateway. . . . . . . . . . . . . : 
   DHCPv6 IAID . . . . . . . . . . . : 302121036
   DNS Servers  . . . . . . . . . . . : fec0:0:0:ffff::1%1
                                       fec0:0:0:ffff::2%1
                                       fec0:0:0:ffff::3%1
    NetBIOS over Tcpip  . . . . . . . : Enabled
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里，我们可看到该接口已被创建，分配了 IPv4 和 IPv6 地址，并显示为一系列的虚拟以太网设备。现在，这台计算机具有以下环回地址：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;C:\&amp;gt; ping 127.1.2.3
Pinging 127.1.2.3 with 32 bytes of data:
Reply from 127.1.2.3: bytes=32 time&amp;lt;1ms TTL=128
Reply from 127.1.2.3: bytes=32 time&amp;lt;1ms TTL=128
Reply from 127.1.2.3: bytes=32 time&amp;lt;1ms TTL=128
Reply from 127.1.2.3: bytes=32 time&amp;lt;1ms TTL=128

Ping statistics for 127.1.2.3:
    Packets: Sent = Received = Lost = 0 (0% loss)，
Approximate round trip times in milli-seconds:
    Mininum = 0ms，Maximum = 0ms，Average = 0ms

C:\&amp;gt; ping ::1
Pinging ::1 with 32 bytes of data:
Reply from ::1: bytes=32 time&amp;lt;1ms TTL=128
Reply from ::1: bytes=32 time&amp;lt;1ms TTL=128
Reply from ::1: bytes=32 time&amp;lt;1ms TTL=128
Reply from ::1: bytes=32 time&amp;lt;1ms TTL=128

Ping statistics for ::1:
    Packets: Sent = Received = Lost = 0 (0% loss)，
Approximate round trip times in milli-seconds:
    Mininum = 0ms，Maximum = 0ms，Average = 0ms

C:\&amp;gt; ping 169.254.57.240
Pinging 169.254.57.240 with 32 bytes of data:
Reply from 169.254.57.240: bytes=32 time&amp;lt;1ms TTL=128
Reply from 169.254.57.240: bytes=32 time&amp;lt;1ms TTL=128
Reply from 169.254.57.240: bytes=32 time&amp;lt;1ms TTL=128
Reply from 169.254.57.240: bytes=32 time&amp;lt;1ms TTL=128

Ping statistics for 169.254.57.240:
    Packets: Sent = Received = Lost = 0 (0% loss)，
Approximate round trip times in milli-seconds:
    Mininum = 0ms，Maximum = 0ms，Average = 0ms
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们可以看到， IPv4 中以 127 开始的目的地址被环回。但是，对于 IPv6，只有地址 &lt;code&gt;::1&lt;/code&gt; 被定义用于环回操作。我们还可以看到，地址为 &lt;code&gt;169.254.57.240&lt;/code&gt; 的环回适配器如何立即返回数据。我们将在第 9 章讨论组播或广播数据报是否被复制并返回给发送主机（通过环回接口）。每个应用程序都可做出这种选择。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;38-mtu-和路径-mtu&#34;&gt;3.8 MTU 和路径 MTU&lt;/h2&gt;
&lt;p&gt;我们可以从图 3-3 中看到，在很多链路层网络（例如以太网）中，携带高层协议 PDU 的帧大小是有限制的。以太网有效载荷的字节数通常被限制为 1500， PPP 通常采用相同大小以保持与以太网兼容。链路层的这种特征被称为&lt;strong&gt;最大传输单元（MTU）&lt;/strong&gt;。大多数的分组网络（例如以太网）都有固定的上限。大多数的流类型网络（串行链路）提供可设置的上限，它可被帧协议（例如 PPP）所使用。如果 IP 需要发送一个数据报，并且这个数据报比链路层 MTU大，则 IP 通过分片将数据报分解成较小的部分，使每个分片都小于 MTU。我们将在第 5 章和第 10 章讨论 IP 分片。&lt;/p&gt;
&lt;p&gt;当同一网络中的两台主机之间通信时，本地链路的 MTU 在会话期间对数据报大小有直接影响。当两台主机之间跨越多个网络通信时，每条链路可能有不同大小的 MTU。在包含所有链路的整个网络路径上，最小的 MTU 称为&lt;strong&gt;路径 MTU&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;任何两台主机之间的路径 MTU 不会永远不变，这取决于当时使用的路径。如果网络中的路由器或链路故障， MTU 可能改变。另外，路径通常不对称（主机 A 到 B 路径可能不是 B 到 A 的反向路径），路径 MTU 不需要在两个方向上相同。&lt;/p&gt;
&lt;p&gt;[&lt;a href=&#34;#RFC1191&#34;&gt;RFC1191&lt;/a&gt;] 规定了** IPv4 路径 MTU 发现（PMTUD）**机制， [&lt;a href=&#34;#PMTUD&#34;&gt;RFC1981&lt;/a&gt;] 描述了用于 IPv6 的相应机制。 [&lt;a href=&#34;#RFC4821&#34;&gt;RFC4821&lt;/a&gt;] 描述了一个补充方案，以解决这些机制中的一些问题。 PMTUD 用于确定某个时间的路径 MTU，它在 IPv6 实现中是需要的。在后面的章节中，针对前面描述的 ICMP 和 IP 分片，我们将观察这个机制如何运行。我们在讨论 TCP 和 UDP 时，也会讨论它对传输性能的影响。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;39-隧道基础&#34;&gt;3.9 隧道基础&lt;/h2&gt;
&lt;p&gt;在某些情况下，两台计算机通过 Internet 或其他网络建立一条虚拟链路是有用的。虚拟专用网络（VpN）提供这种服务。实现这类服务的最常用方法称为&lt;strong&gt;隧道&lt;/strong&gt;。一般来说，隧道是在高层（或同等层）分组中携带低层数据。例如，在一个 IPv4 或 IPv6 分组中携带 IPv4 数据，在一个 UDP、 IPv4 或 IPv6 分组中携带以太网数据。隧道转变了在头部中协议严格分层的思路，并允许形成&lt;strong&gt;覆盖网络&lt;/strong&gt;（即这些“链路”实际是其他协议实现的虚拟链路，而不是物理连接的网络）。这是一个非常强大和有用的技术。这里，我们讨论了一些隧道方案的基础。&lt;/p&gt;
&lt;p&gt;为某个协议层的分组或另一层的分组建立隧道有多种方法。用于建立隧道的 3 个常见协议包括：&lt;strong&gt;通用路由封装（GRE）&lt;/strong&gt; [&lt;a href=&#34;#RFC2784&#34;&gt;RFC2784&lt;/a&gt;] 、&lt;strong&gt;Microsoft 专用的点对点隧道协议（PPTP）&lt;/strong&gt; [&lt;a href=&#34;#RFC2637&#34;&gt;RFC2637&lt;/a&gt;] 和 &lt;strong&gt;第 2 层隧道协议（L2TP）&lt;/strong&gt;  [&lt;a href=&#34;#RFC3931&#34;&gt;RFC3931&lt;/a&gt;] 。其他协议包括早期非标准的 IP-in-IP 隧道协议 [&lt;a href=&#34;#RFC1853&#34;&gt;RFC1853&lt;/a&gt;]。 GRE 和 IT2P 后来发展为标准，并分别代替了 IP-in-IP 和 PPTP （但这两种协议仍在使用）。我们将重点放在 GRE 和 PPTP，但更关注 PPTP，因为它是个人用户的常用协议，即使它并不是一个 IETF 标准。 L2TP 本身不提供安全保障，它常用于 IP 层安全（IPsec；见第 18 章）。由于 GRE 和 PPTP 有密切关系，我们现在看图 3-26 中的 GRE 头部，它们分别基于原来的标准和修订后的标准。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;26&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1652968099400.png&#34; alt=&#34;图 3-26&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 3-26   基本的 GRE 头部只有 4 字节，包括一个 16 位的校验和选项（很多 Internet 协议中的典型选项）。后来，这个头部被扩展为包括一个标识符（密钥字段），该标识符是同一流中的多个分组共有的，还包括一个序列号（用于顺序混乱的分组重新排序）&lt;/p&gt;
&lt;p&gt;从图 3-26 中的头部可以看出，基本 GRE 规范 [&lt;a href=&#34;#RFC2784&#34;&gt;RFC2784&lt;/a&gt;] 是相当简单的，它只提供了对其他分组的最简化的封装。第一个位字段（C）指出是否存在&lt;strong&gt;校验和&lt;/strong&gt;。如果是，&lt;strong&gt;校验和&lt;/strong&gt;字段中包含相同类型的&lt;strong&gt;校验和&lt;/strong&gt;，它在很多 Internet 相关协议中可看到（见 5.2.2 节）。如果&lt;strong&gt;校验和&lt;/strong&gt;字段存在，&lt;strong&gt;保留 1 &lt;strong&gt;字段也存在，并被设置为 0。 [&lt;a href=&#34;#RFC2890&#34;&gt;RFC2890&lt;/a&gt;] 扩展了基本格式，包括可选的&lt;/strong&gt;密钥&lt;/strong&gt;和&lt;strong&gt;序列号&lt;/strong&gt;字段，如果有这两个字段的话，图 3-26 中的 K 和 S 位字段分别被设置为1。 密钥字段在多个分组中被分配了一个同样的值，表示它们是属于同一流中的分组。如果分组顺序被打乱（例如通过不同链路），可利用序列号字段对分组重新排序。&lt;/p&gt;
&lt;p&gt;虽然 GRE 是 PPTP 的基础，并被 PPTP 使用，但这两个协议的目的不同。 GRE 隧道常用于网络基础设施内的流量传输，例如 ISP 之间或企业内部网与分支机构之间，虽然 GRE 隧道可与 IPsec 结合，但这个流量通常没必要加密。相反， PPTP 常用于用户和 ISP 或企业内部网之间，并需要加密（例如使用 MPPE）。 PPTP 本质上是 GRE 和 PPP 的结合，因此 GRE 可基于 PPP 提供虚拟的点到点链路。 GRE 使用 IPv4 或 IPv6 携带流量，因此它更像是一种第 3 层隧道技术。 PPTP 常用于携带第 2 层帧（例如以太网），因此需要模拟一条直接的局域网（链路层）连接。例如，它可用于对企业网络的远程访问。 PPTP 采用的是对标准 GRE 头部的改进方案（见图 3-27）。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;27&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1652968427453.png&#34; alt=&#34;图 3-27&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 3-27   PPTP 头部基于一个旧的、非标准的 GRE 头部。它包括一个序列号、一个累积的分组确认号和一些标识信息。多数字段在第一次使用时设置为 0&lt;/p&gt;
&lt;p&gt;我们可看到图 3-27 与标准 GRE 头部的一些差异，包括额外的 R、 S 和 A 位字段，以及&lt;strong&gt;标志&lt;/strong&gt;字段和&lt;strong&gt;回溯（Recur）&lt;strong&gt;字段。它们中的多数设置为 0，并且没有使用（它们的分配是基于一个旧的、非标准的 GRE 版本）。 K、 S 和 A 位字段分别表示&lt;/strong&gt;密钥&lt;/strong&gt;、&lt;strong&gt;序列号&lt;/strong&gt;和&lt;strong&gt;确认号&lt;/strong&gt;字段是否存在。如果存在，&lt;strong&gt;序列号&lt;/strong&gt;字段保存对方可看到的最大分组数。&lt;/p&gt;
&lt;p&gt;我们现在建立一个 PPTP 会话，稍后对 PPTP 的其他功能进行简单讨论。下面的例子类似于前面给出的 PPP 链路建立的例子，区别在于现在不常使用拨号连接， PPTP 为 PPP 提供了一条“原始”链路。第二个客户端使用 Windows Vista 系统，服务器使用 Linux 系统。当调试选项启用时，这个输出保存在/ &lt;code&gt;var/log/messages&lt;/code&gt; 文件中：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pptpd: MGR: Manager process started
pptpd: MGR: Maximum of 100 connections available
pptpd: MGR: Launching /usr/sbin/pptpctrl to handle client
pptpd: CTRL: local address = 192.168.0.1
pptpd: CTRL: remote address = 192.168.1.1
pptpd: CTRL: pppd iptions file = /etc/ppp/options.pptpd
pptpd: CTRL: Client 71.141.227.30 control connection started
pptpd: CTRL: Received PPTP Control Message (type : 1)
pptpd: CTRL: Made a START CTRL CONN RPLY packet
pptpd: CTRL: I wrote 156 bytes to the client.
pptpd: CTRL: Sent packet to client
pptpd: CTRL: Received PPPTP Control Message (type : 7)

pptpd: CTRL: Set parameters to 100000000 maxbps， 64 window size
pptpd: CTRL: Made a OUT CALL RPLY packet
pptpd: CTRL: Starting call (launching ppd， opening GRE)
pptpd: CTRL: pty_fd = 6
pptpd: CTRL: tty_fd = 7
pptpd: CTRL (PPPD Launcher) : program binary = /usr/sbin/pppd 
pptpd: CTRL (PPPD Launcher) : local address = 192.168.0.1
pptpd: CTRL (PPPD Launcher) : remote address = 192.168.1.1
pppd: pppd 2.4.4 started by root， uid 0
pppd: using channel 60
pptpd: CTRL: I wrote 32 but4es to the client.
pptpd: CTRL: Sent packet to client
pppd: Using interface ppp0
pppd: Connect: ppp0 &amp;lt;--&amp;gt; /dev/pts/1
pppd:sent [LCP ConfReq id=0x1 &amp;lt;asyncmap 0x0&amp;gt; &amp;lt;auth chap MS-v2&amp;gt;
            &amp;lt;magic 0x4e2ca200&amp;gt; &amp;lt;pcomp&amp;gt; &amp;lt;accomp&amp;gt;]
pptpd: CTRL: Received PPTP Control Message (type : 15)
pptpd: CTRL: Got a SET LINK INFO packet with standard ACCMs
pptpd: GRE: accepting packet #0
pppd: rcvd [LCP ConfReq id=0x0 &amp;lt;mru 1400&amp;gt; &amp;lt;magic 0x5e565505&amp;gt;
            &amp;lt;pcomp&amp;gt; &amp;lt;accomp&amp;gt;]]
pppd: sent [LCP ConfAck id=0x0 &amp;lt;mru 1400&amp;gt; &amp;lt;magic 0x5e565505&amp;gt;
            &amp;lt;pcomp&amp;gt; &amp;lt;accomp&amp;gt;]]
pppd: sent [LCP ConfReq id=0x0 &amp;lt;asyncmap 0x0&amp;gt; &amp;lt;auth chap MS-v2&amp;gt; 
            &amp;lt;magic 0x4e2ca200&amp;gt; &amp;lt;pcomp&amp;gt; &amp;lt;accomp&amp;gt;]]
pptpd: GRE: accepting packet #1
pppd: rcvd [LCP ConfAck id=0x1 &amp;lt;asyncmap 0x0&amp;gt; &amp;lt;auth chap MS-v2&amp;gt;
            &amp;lt;magic 0x4e2ca200&amp;gt; &amp;lt;pcomp&amp;gt; &amp;lt;accomp&amp;gt;]
pppd: sent [CHAP Challenge id=0x3 
            &amp;lt;eb88bfff67dlc239ef73e98ca32646a5&amp;gt;， name = &amp;quot;dialer&amp;quot;]
pptpd: CTRL: Received PPTP Control Message (type = 15)
pptpd: CTRL: Ignored a SET LINK INFO packet with real ACCMs!
pptpd: GRE: accepting packet #2
pppd: rcvd [CHAP Response id=0x3 
            &amp;lt;276f3678fofO3fa57f64b3c367529565000000
            00000000000fa2b2aeoad8db9d986f8e222a0217a620638a24
            3179160900&amp;gt;， name = &amp;quot;dialer&amp;quot;]
pppd: sent [CHAP Success id=0x3
            &amp;quot;S=C551119E0E1AAB68E86DED09A32D0346D7002E05
            M=Accessgranted&amp;quot;]
pppd: sent [CCP ConfReq id=0x1 &amp;lt;mppe +H -M +S +L -D -C&amp;gt;]
pptpd: GRE: accepting packet #3
pppd: rcvd [ IPV6CP ConfReq id=0x1 &amp;lt;addr fe80::1cfc:fddd:8e2c:e118&amp;gt;]
pppd: sent [ IPV6CP TermAck id=0x1 ]
pptpd:GRE: accepting packet #4
pppd: rcvd [CCP confReq id=0x2 &amp;lt;mppe +H -M -S -L -D -C&amp;gt;]
pppd: sent [CCP confNak id=0x2&amp;lt;mppe +H -M +S +L -D -C&amp;gt;]
pptpd: GRE: accepting packet #5
pptpd: GRE: accepting packet #6
pppd: rcvd [ IPCP ConfReq id=0x3 &amp;lt;addr 0.0.0.0&amp;gt;&amp;lt;ms-dns1 0.0.0.0&amp;gt;
&amp;lt;ms-wins 0.0.0.0&amp;gt;&amp;lt;ms-dns3 0.0.0.0&amp;gt;&amp;lt;ms-wins 0.0.0.0&amp;gt;]
pptpd: GRE: accepting packet #7
pppd: sent [ IPCP TermAck id=0x3]
pppd: rcvd [CCP ConfNak id=0x1 &amp;lt;mppe +H -M+S -L -D -C&amp;gt;
pppd: sent [CCP ConfReq id=0x2 &amp;lt;mppe +H -M +S -L -D -C&amp;gt;
pppd: rcvd [CCP confReq id=0x4 &amp;lt;mppe +H -M +S -L -D -C&amp;gt;
pppd: sent [CCP ConfAck id=0x4 &amp;lt;mppe +H -M +S -L -D -C&amp;gt;
pptpd: GRE: accepting packet #8
pppd: rcvd [CCP ConfAck id=0x2 &amp;lt;mppe +H -M +S -L -D -C&amp;gt;
pppd: MPPE 128-bit stateless compression enabled
pppd: sent [ IPCP ConfReq id=0x1 &amp;lt;addr 192.168.0.1&amp;gt;]
pppd: sent [ IPV6CP ConfReq id=0x1 &amp;lt;addr fe80::0206:5bff:fedd:c5c3&amp;gt;]
pptpd: GRE: accepting packet #9
pppd: rcvd [ IPCP ConfAck id=0x1 &amp;lt;addr 192.168.0.1&amp;gt;]
pptpd: GRE: accepting packet #10
pppd: rcvd [ IPV6CP ConfAck id=0x1 &amp;lt;addr fe80::0206:5bff:fedd:c5c3&amp;gt;]
pptpd: GRE:accepting packet #11
pppd: rcvd [ IPCP ConfReq id=0x5 &amp;lt;addr 0.0.0.0&amp;gt;
            &amp;lt;ms-dns1 0.0.0.0&amp;gt;&amp;lt;ms-wins 0.0.0.0&amp;gt;
            &amp;lt;ms-dns3 0.0.0.0&amp;gt;&amp;lt;ms-wins 0.0.0.0&amp;gt;]
pppd: sent [ IPCP ConfRej id=0x5 &amp;lt;ms-wins 0.0.0.0&amp;gt;&amp;lt;ms-wins 0.0.0.0&amp;gt;]
pptpd: GRE: accepting packet #12
pppd: rcvd [ IPV6CP ConfReq id=0x6 &amp;lt;addr fe80::1cfc:fddd:8e2c:e118&amp;gt;]
pppd: sent [ IPV6CP ConfAck id=0x6 &amp;lt;addr fe80::1cfc:fddd:8e2c:e118&amp;gt;]
pppd: local LL address fe80::0206:5bff:fedd:c5c3
pppd: remote LL address fe80::1cfc:fddd:8e2c:e118
pptpd: GRE: accepting packet #13
pppd: rcvd [ IPCP ConfReq id=0x7 &amp;lt;addr 0.0.0.0&amp;gt;
            &amp;lt;ms-dns1 0.0.0.0&amp;gt;&amp;lt;ms-dns3 0.0.0.0&amp;gt;]
pppd: sent [ IPCP ConfNak id=0x7 &amp;lt;addr 192.168.1.1&amp;gt;
            &amp;lt;ms-dns1 192.168.0.1&amp;gt;&amp;lt;ms-dns3 192.168.0.1&amp;gt;]
pptpd: GRE: accepting packet #14
pppd: rcvd [ IPCP ConfReq id=0x8 &amp;lt;addr 192.168.1.1&amp;gt;
            &amp;lt;ms-dns1 192.168.0.1&amp;gt;&amp;lt;ms-dns3 192.168.0.1&amp;gt;]
pppd: sent [ IPCP confAck id=0x8 &amp;lt;addr 192.168.1.1&amp;gt;
            &amp;lt;ms-dns1 192.168.0.1&amp;gt;&amp;lt;ms-dns3 192.168.0.1&amp;gt;]
pppd: local IP address 192.168.0.1
pppd: remote IP address 192.168.1.1
pptpd: GRE:accepting packet #15
pptpd: CTRL: sending ECHO REQ id 1
pptpd: CTRL: Made a ECHO REQ packet
pptpd: CTRL: l wrote 16 bytes to the client.
pptpd: CTRL: sent packet to client
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这个输出类似于前面看过的 PPP 的例子，区别在于一个 pppd 过程和一个 pptpd 过程。这些进程协同工作以建立到服务器的 PPTP 会话。整个建立过程开始于用 pptpd 接收 1 个类型为 1 的控制消息，表示客户机希望建立一个控制连接。 PPTP 使用分离的控制流和数据流，因此首先需要建立一个控制流。在响应这个请求之后，服务器接收到一个类型为 7 的控制消息（表示对方发送的呼叫请求）。最大速度（b/s）设置为一个很大的值 100000000，实际上意味着它是无限制的。&lt;strong&gt;窗口&lt;/strong&gt;设置为 64，这是在传输协议例如 TCP （见第 15 章）中经常看到的一个概念。这里，窗口用于流量控制。也就是说， PPTP 使用自己的序列号和确认号来确定多少帧成功到达目的地。如果成功交付的帧太少，发送者需要减小发送速率。为了确定帧确认的等待时间， PPTP 使用一种自适应的超时机制，根据链路的往返时间进行估算。当我们学习 TCP 时将看到这种计算过程。&lt;/p&gt;
&lt;p&gt;在设置窗口后不久， pppd 应用开始运行和处理 PPP 数据，就像我们之前在拨号例子中看到的那样。两者之间唯一的区别在于： pptpd 在分组到达和离开时转发给 pppd 过程，以及 pptpd 处理的少量特殊 PPTP 消息（例如 set link info 和 echo request）。这个例子说明了 PPTP 协议如何实际运行，就像一个针对 PPP 分组的 GRE 隧道。由于现有 PPP 实现（这里是 pppd）可处理封装的 PPP 分组，因此它是很方便的。注意，虽然 GRE 本身通常封装在 IPv4 分组中，但类似功能也可使用 IPv6 隧道分组 [&lt;a href=&#34;#RFC2473&#34;&gt;RFC2473&lt;/a&gt;] 。&lt;/p&gt;
&lt;h3 id=&#34;391-单向链路&#34;&gt;3.9.1 单向链路&lt;/h3&gt;
&lt;p&gt;当链路仅在一个方向工作时出现一个有趣的问题。这种在一个方向工作的链路称为&lt;strong&gt;单向链路（UDL）&lt;/strong&gt;，由于它们需要交换信息（例如 PPP 配置消息），因此前面介绍的很多协议在这种情况下不能正常运行。为了解决这种问题提出了一种标准，可在辅助 Internet 接口上创建隧道，它可与 UDL 操作相结合 [&lt;a href=&#34;#RFC3077&#34;&gt;RFC3077&lt;/a&gt;] 。典型情况是由卫星提供下行流量（流向用户）而形成一条 Intenet 连接，或者是调制解调器提供上行流量而形成一条拨号链路。这在卫星连接的用户主要是下载而不是上传的情况下是有用的，并且通常用于早期的卫星 Internet 连接。它使用 GRE 将链路层的上行流量封装在 IP 分组中。&lt;/p&gt;
&lt;p&gt;为了在接收方自动建立和维护隧道， [&lt;a href=&#34;#RFC3077&#34;&gt;RFC3077&lt;/a&gt;] 规定了一种&lt;strong&gt;动态隧道配置协议（DTCP）&lt;/strong&gt;。DTCP 涉及在下行链路中发送组播 &lt;strong&gt;Hello 消息&lt;/strong&gt;，因此任何有兴趣的接收方都可知道已有 UDL 及其 MAC 和 IP 地址。另外， Hello 消息表示网络中一个隧道端点的接口，它可通过用户端的辅助接口到达。在用户选择隧道端点之后， DTCP 在 GRE 隧道中将同一 MAC 作为 UDL 封装返回流量。服务提供商接收由 GRE 封装的这些第 2 层帧（通常是以太网），将它们从隧道中提取并适当转发。因此，上游（提供商） UDL 需要手工配置隧道，下游（很多用户）自动配置隧道。注意，这种 UDL 处理方法实际上是为上层协议不对称地“隐藏”链路。因此，这条链路“两个”方向上的性能（延迟、带宽）可能非常不对称，并可能对高层协议产生不利影响 [&lt;a href=&#34;#RFC3449&#34;&gt;RFC3449&lt;/a&gt;] 。&lt;/p&gt;
&lt;p&gt;这个例子说明，隧道的一个重要问题是配置的工作量，这个工作从前一直由手工完成。在通常情况下，隧道配置涉及选择一个隧道端点，以及用对方的 IP 地址配置位于隧道端点的设备，也许还需要选择协议和提供认证信息。一些相关技术已经出现，以协助自动配置或使用隧道。一种从 IPv4 向 IPv6 的过渡方法称为6to4 [&lt;a href=&#34;#RFC3056&#34;&gt;RFC3056&lt;/a&gt;] 。在 6to4 中， IPv6 分组在一个 IPv4 网络中通过隧道传输， [&lt;a href=&#34;#RFC3056&#34;&gt;RFC3056&lt;/a&gt;] 中规定它采用的封装方式。当相应主机经过了网络地址转换（见第 7 章），采用这种方法就会出现一个问题。这在当前是常见的，特别是对于家庭用户。自动配置隧道的 IPv6 过渡处理方法规定在 Teredo 技术方案中 [&lt;a href=&#34;#RFC4380&#34;&gt;RFC4380&lt;/a&gt;] 。 Teredo 在 UDP/IPv4 分组上形成 IPv6 分组的隧道。理解这种方法需要一些 IPv4、 IPv6 和 UDP 的背景知识，我们将在第 10 章详细讨论这种隧道自动配置选项。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;310-与链路层相关的攻击&#34;&gt;3.10 与链路层相关的攻击&lt;/h2&gt;
&lt;p&gt;对 TCP/IP 以下的层进行攻击以影响 TCP/IP 网络运行一直是常见的做法，这是由于大部分链路层信息不被高层共享，因而难以检测。不过，现在大家已知道很多这种攻击，我们在这里提到其中一些，以更好地理解链路层问题如何影响高层运行。&lt;/p&gt;
&lt;p&gt;在传统的有线以太网中，接口可被设置为&lt;strong&gt;混杂模式&lt;/strong&gt;，这允许它接收目的地不是自己的流量。在早期的以太网中，当介质是名副其实的共享电缆时，该功能允许任何一台连接以太网电缆的计算机“嗅探”别人的帧并检查其内容。当时很多高层协议包含密码等敏感信息，仅通过查看一个分组并解码就能轻易获得密码。两个因素对这种方法的影响很大：交换机部署和高层协议加密部署。在使用交换机后，只有连接到交换机端口的站提供流量，流量的目的地也是其他站（或其他桥接的站），以及广播/组播流量。这种流量很少包含敏感信息（例如密码），可在很大程度上阻止攻击。但是，在更高层使用加密更有效，这在当前是常见的。在这种情况下，嗅探分组难以获得多少好处，因为基本无法直接获取内容。&lt;/p&gt;
&lt;p&gt;另一种攻击的目标是交换机。交换机中有一个基于每个端口的站列表。如果这种表能被快速填充（例如被大量伪装的站快速填充），交换机可能被迫放弃合法条目，从而导致中断对合法站的服务。一个相关但可能更严重的攻击是使用 STP。在这种情况下，一个站可伪装成一个到根网桥拥有低成本路径的站，从而吸引流量直接导向它。&lt;/p&gt;
&lt;p&gt;随着 Wi-Fi 网络的使用，有线以太网中存在的一些窃听和伪装问题变得更严重，这是由于任何站都可进入监控模式并嗅探分组（802.11 接口置于监控模式通常比以太网接口置于混杂模式更有挑战性，这样做依赖于一个适当的设备）。一些早期“攻击” （可能不是真的被攻击，依据相关的法律框架）涉及扫描中的简单漫游，寻找提供 Internet 连接的接入点（即&lt;strong&gt;驾驶攻击&lt;/strong&gt;）。虽然很多接入点使用加密来限制授权用户的访问，但有些人却能打开或使用&lt;strong&gt;捕获门户&lt;/strong&gt;技术访问注册网页，然后进行基于 MAC 地址的过滤访问。通过观察站注册以及冒充合法注册用户来“劫持”连接，捕获门户系统已被破坏。&lt;/p&gt;
&lt;p&gt;一种更先进的 Wi-Fi 攻击涉及对加密保护的攻击，尤其是很多早期接入点使用的 WEP 加密。针对 WEP [&lt;a href=&#34;#BHL06&#34;&gt;BHL06&lt;/a&gt;] 的攻击有显著的破坏性，它促使 IEEE 修订了自已的标准。新的WPA2 （和 WPA）加密体系明显更强，因此不再推荐使用 WEP。&lt;/p&gt;
&lt;p&gt;如果攻击者可访问两个端点之间的信道，它可采用很多方式来攻击 PPP 链路。对于很简单的认证机制（例如 PAP），嗅探可用于捕获密码，以便后续的非法访问。通过 PPP 链路（例如路由流量）上的更高层流量，可导致系统的不可用。&lt;/p&gt;
&lt;p&gt;从攻击的角度看，隧道经常是目标，有时也成为攻击工具。作为目标，隧道穿过一个网络（通常是 Internet），它是被截获和分析的目标。隧道端点配置也可被攻击，尝试由端点建立更多隧道（一个 DoS 攻击）或攻击配置自身。如果该配置被攻破，可能打开一个未授权的隧道端点。在这点上，隧道变成工具而不再是目标，有些协议（例如 L2TP）提供一种与协议无关的简便方法，以在链路层访问私有的内部网络。在一种 GRE 相关的攻击中，例如将流量简单地插入一个非加密隧道，它到达隧道端点并被注入“私有”网络，虽然它本来只应被送往端点本地。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;311-总结&#34;&gt;3.11 总结&lt;/h2&gt;
&lt;p&gt;在本章中，我们探讨 Internet 协议族的低层，也就是我们关注的链路层。我们首先介绍以太网的演变，速度从 10Mb/s 增加到 10Gb/s 及以上，功能上的变化包括 VLAN、优先级、链路聚合和帧格式等方面。我们介绍了交换机如何通过网桥改善性能，这主要通过在多个独立站的集合之间提供直连电路来实现，以及由全双工操作取代早期半双工操作。我们还介绍了 IEEE 802.11 无线局域网 Wi-Fi 标准的一些细节，并说明它与以太网的相似点和区别。它已成为最流行的 IEEE 标准之一，并通过两个主要频段 2.4GHz 和 5GHz 提供无须许可的网络访问。我们还介绍了 Wi-Fi 安全方法的演变，从较弱的 WEP 到更强的 WPA 和 WPA2 框架。在 IEEE 标准的基础上，我们讨论了点到点链路和 PPP 协议。 PPP 实际上可封装任何类型的分组，可用于 TCP/IP 和非 TCP/IP 网络，采用一种类似 HDLC 的帧格式，并且可用于从低速拨号调制解调器到高速光纤线路。它本身是一整套协议，涉及压缩、加密、认证和链路聚合。它只支持两个参与者之间通信，无法处理对共享介质的访问控制，例如以太网或 Wi-Fi 的 MAC 协议。&lt;/p&gt;
&lt;p&gt;大多数实现提供了环回接口。通过特殊的环回地址，通常为 &lt;code&gt;127.0.0.1&lt;/code&gt; （IPv6 为 &lt;code&gt;::1&lt;/code&gt;），或将 IP 数据报发送到主机自己的 IP 地址，都可访问该接口。环回数据可被传输层处理，并在网络层被 IP 处理。我们描述了链路层的一个重要特点，即 MTU 和路径 MTU 的相关概念。&lt;/p&gt;
&lt;p&gt;我们也讨论了隧道的使用，涉及在更高层（或同等层）分组中携带低层协议。这种技术可形成覆盖网络，在 Internet 中将隧道作为网络基础设施的其他层中的链路。这项技术已变得非常流行，包括新功能的实验（例如在一个 IPv4 网络上运行的一个 IPv6 覆盖网络）和实际使用（例如 VPN）。&lt;/p&gt;
&lt;p&gt;最后简要讨论了链路层涉及的各种攻击类型，它们既是目标又是工具。很多攻击涉及流量截取与分析（例如查找密码），但很多复杂攻击涉及伪造端点和修改传输中的流量。其他攻击涉及修改控制信息，例如隧道端点或 STP 信息，以将流量导向其他意想不到的位置。链路层访问也提供了一种执行 DoS 攻击的通用方式。这方面最著名的攻击是干扰通信信号，这种攻击几乎从无线电问世以来就有了。&lt;/p&gt;
&lt;p&gt;本章仅涵盖了当前 TCP/IP 使用的一些常见链路技术。 TCP/IP 成功的原因之一在于它能工作在几乎任何一种链路技术之上。从本质上来说， IP 只要求发送方和接收方之间存在某条路径，它们可能经过一些级联的中间链路。这是一个相对适中的要求，很多研究的目标甚至延伸得更远，发送方和接收方之间可能永远没有一条端到端路径 [&lt;a href=&#34;#RFC4838&#34;&gt;RFC4838&lt;/a&gt;]。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;312-参考文献&#34;&gt;3.12 参考文献&lt;/h2&gt;
&lt;p&gt;&lt;span id=&#34;802.11-2007&#34;&gt;[802.11-2007]&lt;/span&gt;&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks, Part 11: Wireless LAN Medium Access Control (MAC) and Physical Layer (PHY) Specifications,&amp;quot; June 2007.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;802.11n-2009&#34;&gt;[802.11n-2009]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks, Part 11: Wireless LAN Medium Access Control (MAC) and Physical Layer (PHY) Specifications Amendment 5: Enhancements for Higher Throughput,&amp;quot; Oct. 2009.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;802.11y-2008&#34;&gt;[802.11y-2008]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks, Part 11: Wireless LAN Medium Access Control (MAC) and Physical Layer (PHY) Specifications Amendment 3: 3650-3700 MHz Operation in USA,&amp;quot; Nov. 2009.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;802.16-2009&#34;&gt;[802.16-2009]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks, Part 16: Air Interface for Fixed Broadband Wireless Access Systems,&amp;quot; May 2009.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;802.16h-2010&#34;&gt;[802.16h-2010]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks, Part 16: Air Interface for Fixed Broadband Wireless Access Systems Amendment 2: Improved Coexistence Mechanisms for License-Exempt Operation,&amp;quot; July 2010.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;802.16j-2009&#34;&gt;[802.16j-2009]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks, Part 16: Air Interface for Fixed Broadband Wireless Access Systems Amendment 1: Multihop Relay Specification,&amp;quot; June 2009.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;802.16k-2007&#34;&gt;[802.16k-2007]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks, Part 16:Air Interface for Fixed Broadband Wireless Access Systems Amendment 5: Bridging of IEEE 802.16,&amp;quot;Aug. 2010.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;802.1AK-2007&#34;&gt;[802.1AK-2007]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks, Virtual Bridged Local Area Networks Amendment 7: Multiple RegistrationProtocol,&amp;quot; June 2007.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;802.1AE-2006&#34;&gt;[802.1AE-2006]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks Media Access Control (MAC) Security,&amp;quot; Aug. 2006.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;802.1ak-2007&#34;&gt;[802.1ak-2007]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks--—Virtual Bridged Local Area Networks--Amendment 7: Multiple Registration Protocol,&amp;quot; June 2007.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;802.1AX-2008&#34;&gt;[802.1AX-2008]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks—Link Aggregation,&amp;quot; Nov. 2008.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;802.1D-2004&#34;&gt;[802.1D-2004]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks Media Access Control (MAC) Bridges,&amp;quot; June 2004.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;802.1Q-2005&#34;&gt;[802.1Q-2005]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks Virtual Bridged Local Area Networks,&amp;quot; May 2006.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;802.1X-2010&#34;&gt;[802.1X-2010]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks Port-Based Network Access Control,&amp;quot;Feb. 2010.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;802.2-1998&#34;&gt;[802.2-1998]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks Logical Link Control&amp;quot;(also ISO/IEC 8802-2:1998), May 1998.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;802.21-2008&#34;&gt;[802.21-2008]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks, Part 21: Media Independent Handover Services&amp;quot; Jan. 2009.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;802.3-2008&#34;&gt;[802.3-2008]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks, Part 3:Carrier Sense Multiple Access with Collision Detection (CSMA/CD) Access Method and Physical Layer Specifications,&amp;quot;Dec. 2008.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;802.3at-2009&#34;&gt;[802.3at-2009]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks—Specific Requirements, Part 3: Carrier Sense Multiple Access with Collision Detection (CSMA/CD) Access Method and Physical Layer Specifications Amendment 3: Date Terminal Equipment (DTE) Power via the Media Dependent Interface (MDI) Enhancements,&amp;quot; Oct. 2009.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;802.3ba-2010&#34;&gt;[802.3ba-2010]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks, Part 3: Carrier Sense Multiple Access with Collision Detection (CSMA/CD) Access Method and Physical Layer Specifications, Amendment 4: Media Access Control Parameters, Physical Layers, and Management Parameters for 40Gb/s and 100Gb/s Operation,&amp;quot; June 2010.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;802.11n-2009&#34;&gt;[802.11n-2009]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks, Part 11: Wireless LAN Medium Access Control (MAC) and Physical Layer (PHY) Specifications,Amendment 5: Enhancements for Higher Throughput,&amp;quot; Oct. 2009.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;AESO1&#34;&gt;[AESO1]&lt;/span&gt; U.S. National Institute of Standards and Technology, FIPS PUB 197, &amp;quot;Advanced Encryption Standard,&amp;quot; Nov.2001.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;BHLO6&#34;&gt;[BHLO6]&lt;/span&gt; A.Bittau, M.Handley, and J.Lackey, &amp;quot;The Final Nail in WEP&#39;s Coffin, &amp;quot; Proc. IEEE Symposium on Security and Privacy, May 2006.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;BOND&#34;&gt;[BOND]&lt;/span&gt; http://bonding.sourceforge.net&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;ETHERTYPES&#34;&gt;[ETHERTYPES]&lt;/span&gt; http://www.iana.org/assignments/ethernet-numbers&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;ETX&#34;&gt;[ETX]&lt;/span&gt; D. De Couto, D.Aguayo, J. Bicket, and R. Morris,&amp;quot;A High-Throughput Path Metric for Multi-Hop Wireless Routing,&amp;quot; Proc. Mobicom, Sep. 2003.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;G704&#34;&gt;[G704]&lt;/span&gt; ITU, &amp;quot;General Aspects of Digital Transmission Systems: Synchronous Frame Structures Used at 1544, 6312, 2048k, 8488, and 44736 kbit/s Hierarchical Levels,&amp;quot; ITU-T Recommendation G.704, July 1995.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;IANA-CHARSET&#34;&gt;[IANA-CHARSET]&lt;/span&gt; &amp;quot;Character Sets,&amp;quot; http://www.iana.org/assignments/character-sets&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;ISO3309&#34;&gt;[ISO3309]&lt;/span&gt; International Organization for Standardization, &amp;quot;Information Processing Systems--Data Communication High-Level Data Link Control Procedure--Frame Structure,&amp;quot; IS 3309,1984.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;ISO4335&#34;&gt;[ISO4335]&lt;/span&gt; International Organization for Standardization, &amp;quot;Information Processing Systems-Data Communication High-Level Data Link Control Procedure—Elements of Procedure,&amp;quot; IS 4335,1987.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;JF&#34;&gt;[JF]&lt;/span&gt; M.Mathis,&amp;quot;Raising the Internet MTU,&amp;quot; http://www.psc.edu/~mathis/MTU&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;MWLD&#34;&gt;[MWLD]&lt;/span&gt; &amp;quot;Long Distance Links with MadWiFi,&amp;quot; http://madwifi-project.org/wiki/UserDocs/LongDistance&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;PPPn&#34;&gt;[PPPn]&lt;/span&gt; http://www.iana.org/assignments/ppp-numbers&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC0894&#34;&gt;[RFC0894]&lt;/span&gt; C.Hornig, &amp;quot;A Standard for the Transmission of IP Datagrams over Ethernet Networks,&amp;quot; Internet RFC 0894/STD 0041, Apr. 1984.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC1042&#34;&gt;[RFC1042]&lt;/span&gt; J. Postel and J. Reynolds,&amp;quot;Standard for the Transmission of IP Datagrams over IEEE 802 Networks,&amp;quot; Internet RFC 1042/STD 0043, Feb. 1988.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC1144&#34;&gt;[RFC1144]&lt;/span&gt; V.Jacobson, &amp;quot;Compressing TCP/IP Headers for Low-Speed Serial Links&amp;quot; Internet RFC 1144, Feb. 1990.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC1191&#34;&gt;[RFC1191]&lt;/span&gt; J. Mogul and S. Deering,&amp;quot;Path MTU Discovery,&amp;quot; Internet RFC 1191, Nov. 1990.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC1332&#34;&gt;[RFC1332]&lt;/span&gt; G. McGregor, &amp;quot;The PPP Internet Protocol Control Protocol,&amp;quot; Internet RFC 1332, May 1992.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC1570&#34;&gt;[RFC1570]&lt;/span&gt; W.Simpson, ed., &amp;quot;PPP LCP Extensions,&amp;quot; Internet RFC 1570, Jan. 1994.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC1661&#34;&gt;[RFC1661]&lt;/span&gt; W. Simpson, &amp;quot;The Point-to-Point Protocol (PPP),&amp;quot; Internet RFC 1661/STD 0051, July 1994.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC1662&#34;&gt;[RFC1662]&lt;/span&gt; W. Simpson, ed.,&amp;quot;PPP in HDLC-like Framing,&amp;quot; Internet RFC 1662/STD 0051, July 1994.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC1663&#34;&gt;[RFC1663]&lt;/span&gt; D. Rand,&amp;quot;PPP Reliable Transmission,&amp;quot; Internet RFC 1663, July 1994.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC1853&#34;&gt;[RFC1853]&lt;/span&gt; W. Simpson, &amp;quot;IP in IP Tunneling,&amp;quot; Internet RFC 1853 (informational), Oct. 1995.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC1962&#34;&gt;[RFC1962]&lt;/span&gt; D. Rand, &amp;quot;The PPP Compression Protocol (CCP),&amp;quot; Internet RFC 1962, June 1996.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC1977&#34;&gt;[RFC1977]&lt;/span&gt; V.Schryver, &amp;quot;PPP BSD Compression Protocol,&amp;quot; Internet RFC 1977 (informational), Aug. 1996.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC1981&#34;&gt;[RFC1981]&lt;/span&gt; J. McCann and S. Deering ,&amp;quot;Path MTU Discovery for IP Version 6,&amp;quot; Internet RFC 1981,Aug. 1996.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC1989&#34;&gt;[RFC1989]&lt;/span&gt; w. Simpson, &amp;quot;PPP Link Quality Monitoring,&amp;quot; Internet RFC 1989, Aug.1996.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC1990&#34;&gt;[RFC1990]&lt;/span&gt; K. Sklower, B. Lloyd, G. McGregor, D. Carr, and T. Coradetti, &amp;quot;The PPP Multilink Protocol (MP)&amp;quot; Internet RFC 1990, Aug. 1996.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC1994&#34;&gt;[RFC1994]&lt;/span&gt; W. Simpson, &amp;quot;PPP Challenge Handshake Authentication Protocol (CHAP),&amp;quot; Internet RFC 1994, Aug. 1996.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC2118&#34;&gt;[RFC2118]&lt;/span&gt; G.Pall, &amp;quot;Microsoft Point-to-Point (MPPC) Protocol,&amp;quot; Internet RFC 2118 (informational), Mar. 1997.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC2125&#34;&gt;[RFC2125]&lt;/span&gt; C.Richards and K. Smith, &amp;quot;The PPP Bandwidth Allocation Protocol (BAP)/The PPP Bandwidth Allocation Control Protocol (BACP),&amp;quot; Internet RFC 2125, Mar. 1997.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC2153&#34;&gt;[RFC2153]&lt;/span&gt; W. Simpson,&amp;quot;PPP Vendor Extensions,&amp;quot; Internet RFC 2153(informational), May 1997.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC2290&#34;&gt;[RFC2290]&lt;/span&gt; J. Solomon and S.Glass,&amp;quot;Mobile-IPv4 Configuration Option for PPP IPCP,&amp;quot; Internet RFC 2290, Feb. 1998.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC2464&#34;&gt;[RFC2464]&lt;/span&gt; M.Crawford, &amp;quot;Transmission of IPv6 Packets over Ethernet Networks,&amp;quot; Internet RFC 2464, Dec. 1988.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC2473&#34;&gt;[RFC2473]&lt;/span&gt; A.Conta and S. Deering ,&amp;quot;Generic Packet Tuneling in IPv6 Specification,&amp;quot; Internet RFC 2473, Dec. 1998.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC2484&#34;&gt;[RFC2484]&lt;/span&gt; G.Zorn, &amp;quot;PPP LCP Internationalization Configuration Option,&amp;quot; Internet RFC 2484, Jan. 1999.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC2507&#34;&gt;[RFC2507]&lt;/span&gt; M. Degermark, B. Nordgren, and S. Pink, &amp;quot;IP Header Compression,&amp;quot; Internet RFC 2507, Feb. 1999.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC2615&#34;&gt;[RFC2615]&lt;/span&gt; A. Malis and W. Simpson, &amp;quot;PPP over SONET/SDH,&amp;quot; Internet RFC 2615, June 1999.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC2637&#34;&gt;[RFC2637]&lt;/span&gt; K.Hamzeh, G. Pall, W. Verthein, J. Taarud, W. Little, and G.Zorn, &amp;quot;Point-to-Point Tunneling Protocol (PPTP),&amp;quot; Internet RFC 2637 (informational), July 1999.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC2759&#34;&gt;[RFC2759]&lt;/span&gt; G.Zorn, &amp;quot;Microsoft PPP CHAP Extensions, Version 2,&amp;quot; Internet RFC 2759 (informational), Jan. 2000.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC2784&#34;&gt;[RFC2784]&lt;/span&gt; D. Farinacci, T. Li, S. Hanks, D. Meyer, and P. Traina, &amp;quot;Generic Routing Encapsulation (GRE),&amp;quot;Internet RFC 2784, Mar. 2000.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC2865&#34;&gt;[RFC2865]&lt;/span&gt; C.Rigney, S. Willens, A. Rubens, and W. Simpson, &amp;quot;Remote Authentication Dial In User Service (RADIUS),&amp;quot; Internet RFC 2865, June 2000.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC2890&#34;&gt;[RFC2890]&lt;/span&gt; G. Dommety,&amp;quot;Key and Sequence Number Extensions to GRE,&amp;quot; Internet RFC 2890, Sept. 2000.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC3056&#34;&gt;[RFC3056]&lt;/span&gt; B.Carpenter and K. Moore,&amp;quot;Connection of IPv6 Domains via IPv4 Clouds,&amp;quot; Internet RFC 3056, Feb. 2001.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC3077&#34;&gt;[RFC3077]&lt;/span&gt; E. Duros, W. Dabbous, H.Izumiyama, N. Fujii, and Y.Zhang,&amp;quot;A Link-Layer Tunneling Mechanism for Unidirectional Links,&amp;quot; Internet RFC 3077, Mar. 2001.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC3078&#34;&gt;[RFC3078]&lt;/span&gt; G.Pall and G.Zorn, &amp;quot;Microsoft Point-to-Point Encryption (MPPE) Protocol,&amp;quot; Internet RFC 3078 (informational), Mar. 2001.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC3153&#34;&gt;[RFC3153]&lt;/span&gt; R.Pazhyannur, I. Ali, and C. Fox, &amp;quot;PPP Multiplexing,&amp;quot; Internet RFC 3153, Aug. 2001.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC3366&#34;&gt;[RFC3366]&lt;/span&gt; G.Fairhurst and L. Wood,&amp;quot;Advice to Link Designers on Link Automatic Repeat reQuest (ARQ),&amp;quot;Internet RFC 3366/BCP 0062,Aug.2002.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC3449&#34;&gt;[RFC3449]&lt;/span&gt; H. Balakrishnan, V.Padmanabhan, G. Fairhurst, and M. Sooriyabandara, &amp;quot;TCP Performance Implications of Network Path Asymmetry,&amp;quot; Internet RFC 3449/BCP 0069, Dec. 2002.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC3544&#34;&gt;[RFC3544]&lt;/span&gt; T.Koren, S.Casner, and C. Bormann, &amp;quot;IP Header Compression over PPP&amp;quot; Internet RFC 3544, July 2003.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC3561&#34;&gt;[RFC3561]&lt;/span&gt; C.Perkins,E. Belding-Royer, and S. Das,&amp;quot;Ad Hoc On-Demand Distance Vector (AODV) Routing,&amp;quot; Internet RFC 3561 (experimental), July 2003.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC3610&#34;&gt;[RFC3610]&lt;/span&gt; D. Whiting,R.Housley, and N.Ferguson, &amp;quot;Counter with CBC-MAC (CCM),&amp;quot; Internet RFC 3610(informational), Sept. 2003.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC3626&#34;&gt;[RFC3626]&lt;/span&gt; T. Clausen and P. Jacquet, eds.,&amp;quot;Optimized Link State Routing Protocol (OLSR),&amp;quot; Internet RFC 3626 (experimental), Oct. 2003.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC3748&#34;&gt;[RFC3748]&lt;/span&gt; B. Aboba et al., &amp;quot;Extensible Authentication Protocol (EAP),&amp;quot; Internet RFC 3748, June 2004.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC3931&#34;&gt;[RFC3931]&lt;/span&gt; J. Lau, M. Townsley, and L. Goyret, eds,&amp;quot;Layer Two Tunneling Protocol--Version 3 (L2TPv3),&amp;quot; Internet RFC 3931, Mar. 2005.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC4017&#34;&gt;[RFC4017]&lt;/span&gt; D.Stanley, J. Walker, and B. Aboba,&amp;quot;Extensible Authentication Protocol (EAP) Method Requirements for Wireless LANs,&amp;quot; Internet RFC 4017 (informational), Mar. 2005.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC4380&#34;&gt;[RFC4380]&lt;/span&gt;C. Huitema,&amp;quot;Teredo: Tunneling IPv6 over UDP through Network Address Translations (NATs),&amp;quot; Internet RFC 4380,Feb. 2006.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC4647&#34;&gt;[RFC4647]&lt;/span&gt; A. Phillips and M. Davis, &amp;quot;Matching of Language Tags,&amp;quot; Internet RFC 4647/BCP 0047, Sept. 2006.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC4821&#34;&gt;[RFC4821]&lt;/span&gt; M.Mathis and J. Heffner, &amp;quot;Packetization Layer Path MTU Discovery,&amp;quot; Internet RFC 4821, Mar. 2007.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC4838&#34;&gt;[RFC4838]&lt;/span&gt; V.Cerf et al.,&amp;quot;Delay-Tolerant Networking Architecture,&amp;quot; Internet RFC 4838 (informational), Apr. 2007.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC4840&#34;&gt;[RFC4840]&lt;/span&gt; B.Aboba, ed., E. Davies, and D. Thaler, &amp;quot;Multiple Encapsulation Methods Considered Harmful,&amp;quot; Internet RFC 4840 (informational), Apr. 2007.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC5072&#34;&gt;[RFC5072]&lt;/span&gt; S. Varada, ed., D. Haskins, and E.Allen, &amp;quot;IP Version 6 over PPP,&amp;quot; Internet RFC 5072,Sept. 2007.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC5225&#34;&gt;[RFC5225]&lt;/span&gt; G. Pelletier and K.Sandlund, &amp;quot;RObust Header Compression Version 2 (ROHCv2): Profiles for RTP, UDP,IP, ESP, and UDP-Lite,&amp;quot; Internet RFC 5225, Apr. 2008.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC5646&#34;&gt;[RFC5646]&lt;/span&gt; A. Phillips and M. Davis, eds., &amp;quot;Tags for Identifying Languages,&amp;quot; Internet RFC 5646/BCP 0047,Sept. 2009.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;S08&#34;&gt;[S08]&lt;/span&gt; D. Skordoulis et al., &amp;quot;IEEE 802.11n MAC Frame Aggregation Mechanisms for Next-Generation High-Throughput WLANs,” IEEE Wireless Communications, Feb. 2008.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;S96&#34;&gt;[S96]&lt;/span&gt; B. Schneier,Applied Cryptography, Second Edition (John Wiley &amp;amp; Sons, 1996).&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;SAE&#34;&gt;[SAE]&lt;/span&gt; D. Harkins, &amp;quot;Simultaneous Authentication of Equals: A Secure, Password-Based Key Exchange for Mesh Networks,&amp;quot; Proc. SENSORCOMM,Aug.2008.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;SC05&#34;&gt;[SC05]&lt;/span&gt; S. Shalunov and R.Carlson, &amp;quot;Detecting Duplex Mismatch on Ethernet,&amp;quot; Proc. Passive and Active Measurement Workshop, Mar. 2005.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;SHKO7&#34;&gt;[SHKO7]&lt;/span&gt; C.Sengul, A.Harris, and R. Kravets,&amp;quot;Reconsidering Power Management,&amp;quot; Invited Paper, Proc. IEEE Broadnets, 2007.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;WOL&#34;&gt;[WOL]&lt;/span&gt; http://wake-on-lan.sourceforge.net&lt;/p&gt;
">《TCP/IP 详解 卷一：协议》第三章：链路层</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://wenbozhangw.github.io/post/rfc4291-ip-version-6-addressing-architecture/"" data-c="
          &lt;p&gt;本规范定义了 IP 版本 6 （IPv6）协议的寻址体系结构。该文档包括 IPv6 地址模型、IPv6 地址的文本表示、IPv6 单播地址、任播地址和组播地址的定义，以及 IPv6 节点所需的地址。本文档废除了 RFC 3513，“IP 版本 6 寻址架构”。&lt;/p&gt;
&lt;p&gt;本文档为 Internet 社区指定了一个 Internet 标准跟踪协议，并请求讨论和改进建议。请参阅最新版本的“互联网官方协议标准”（STD 1）以了解该协议的标准化状态和状态。本备忘录的分发不受限制。&lt;/p&gt;
&lt;p&gt;Copyright （C） The Internet Society （2006）.&lt;/p&gt;
&lt;!-- more --&gt;
&lt;h1 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h1&gt;
&lt;p&gt;本规范定义了 IP 版本 6 协议的寻址体系结构。它包括各种类型 IPv6 地址（单播、任播和组播）的基本格式。&lt;/p&gt;
&lt;h1 id=&#34;2-ipv6-addressing&#34;&gt;2. IPv6 Addressing&lt;/h1&gt;
&lt;p&gt;IPv6 地址是接口和接口集的 128 位标识符（其中“接口”的定义见 [IPv6] 章节 2）。地址有三种类型：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;单播（Unicast）：单个接口的标识符。发送到单播地址的数据包会被发送到该地址标识的接口。&lt;/li&gt;
&lt;li&gt;任播（Anycast）：一组接口的标识符（通常属于不同的节点）。发送到任播地址的数据包被发送到由该地址（根据路由协议的距离度量，是“最近的”）识别的接口之一。&lt;/li&gt;
&lt;li&gt;多播（Multicast）：一组接口的标识符（通常属于不同节点）。发送到多播地址的数据包会被传送到该地址标识的所有接口。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;IPv6 中没有广播（broadcast）地址，其功能被多播（multicast）地址取代。&lt;/p&gt;
&lt;p&gt;在本文档中，地址中的字段被赋予特定的名称，例如“子网（subnet）”。当此名称与名称后的标识符术语“ID”一起使用时（例如，“子网ID”），它指的是命名字段的内容。当它与术语“前缀”（例如，“子网前缀”）一起使用时，它指的是从左侧开始到包含此字段在内的所有地址。&lt;/p&gt;
&lt;p&gt;在 IPv6 中，对于任何字段，全 0 和全 1 都是的合法值，除非明确排除。具体来说，前缀可能包含 0 值字段，或者以 0 值字段结尾。&lt;/p&gt;
&lt;h2 id=&#34;21-addressing-model&#34;&gt;2.1 Addressing Model&lt;/h2&gt;
&lt;p&gt;所有类型的 IPv6 地址都是分配给接口的，而不是分配给节点。IPv6 单播地址只的是单个接口。因为每个接口属于单个节点，所以该节点的任何接口的单播地址都可以用作该节点的标识符。&lt;/p&gt;
&lt;p&gt;所有接口都要求至少有一个链路本地单播地址（有关其他要求的地址，请参见 2.8 节）。一个接口也可以有多个任意类型（单播、任播和组播）或任何范围的 IPv6 地址。如果接口不作为任何与非邻居的 IPv6 报文的源或目的地址，这不需要作用域大于 link-scope 的单播地址。这在某些情况对点对点接口很方便。这种寻址模型有一个例外：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;如果实现中向 internet 层呈现时，将多个物理接口视为一个接口，则一个单播地址或一组单播地址
可以分配给多个物理接口。这样做有利于多个物理接口上的负载均衡。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;目前，IPv6 延续了 IPv4 模型，子网前缀与一条链路相关联。多个子网前缀可以分配给同一个链路。&lt;/p&gt;
&lt;h2 id=&#34;22-text-representation-of-addresses&#34;&gt;2.2 Text Representation of Addresses&lt;/h2&gt;
&lt;p&gt;有三种将 IPv6 地址表示为文本串的约定格式：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;首选形式为 &lt;code&gt;x:x:x:x:x:x:x:x&lt;/code&gt;，这里“&lt;code&gt;x&lt;/code&gt;”是地址的 8 个 16 位地址片段的 1到 4 个 16 进制数字。例如：&lt;code&gt;ABCD:EF01:2345:6789:ABCD:EF01:2345:6789&lt;/code&gt; 、 &lt;code&gt;2001:DB8:0:0:8:800:200C:417A&lt;/code&gt; 。请注意，没有必要在单个字段中写入前导零，但每个字段必须至少有一个数字（除了 2. 中描述的情况）。&lt;/li&gt;
&lt;li&gt;由于需要分配一些特定类型的 IPv6 地址，地址通常包含很长的零位字符串。为了使写包含零位的地址更容易，可以使用一种特殊的语法来压缩零位。使用“&lt;code&gt;::&lt;/code&gt;”表示一组或多组 16 位的 0。“&lt;code&gt;::&lt;/code&gt;”在一个地址中只能出现一次。&amp;quot;&lt;code&gt;::&lt;/code&gt;&amp;quot;也可以用来压缩地址的前导或尾随零。例如下面的地址：&lt;pre&gt;&lt;code&gt;2001:DB8:0:0:8:800:200C:417A   a unicast address
FF01:0:0:0:0:0:0:101            a multicast address
0:0:0:0:0:0:0:1                 the loopback address
0:0:0:0:0:0:0:0                 the loopback address
&lt;/code&gt;&lt;/pre&gt;
可以表示为：&lt;pre&gt;&lt;code&gt;2001:DB8::8:800:200C:417A   a unicast address
FF01::101                    a multicast address
::1                          the loopback address
::                           the loopback address
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;在混用 IPv4 和 IPv6 节点的环境，另一种有时更方便的形式是 &lt;code&gt;x:x:x:x:x:x:d.d.d.d&lt;/code&gt;。这里“&lt;code&gt;x&lt;/code&gt;”是地址的 6 个高阶 16 位地址片段的 16 进制值，“&lt;code&gt;d&lt;/code&gt;”是地址的 4 个低阶 8 位地址片段的 10 进制值（标准的 IPv4 地址表示）。例如：&lt;code&gt;0:0:0:0:0:0:13.1.68.3&lt;/code&gt; 、&lt;code&gt;0:0:0:0:0:FFFF:129.144.52.38&lt;/code&gt; 或者压缩格式：&lt;code&gt;::13.1.68.3&lt;/code&gt;、&lt;code&gt;::FFFF:129.144.52.38&lt;/code&gt; 。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;23-text-representation-of-address-prefixes&#34;&gt;2.3 Text Representation of Address Prefixes&lt;/h2&gt;
&lt;p&gt;IPv6 地址前缀的文本表示类似于 IPv4 地址前缀在无类域间路由（Classless Inter-Domain Routing，CIDR）斜线表示法[CIDR]中的书写方式。IPv6地址前缀由以下符号表示：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ipv6-address/prefix-length
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其中，&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ipv6-address    是用第 2.2 节列出的任何一种符号表示法表示的 IPv6 地址。
prefix-length   是十进制值，规定地址中最左边多少个连续位构成前缀。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;例如，以下是 60 位前缀 &lt;code&gt;20010DB80000CD3&lt;/code&gt; （十六进制）的合法表示形式：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;2001:0DB8:0000:CD30:0000:0000:0000:0000/60
2001:0DB8::CD30:0:0:0:0/60
2001:0DB8:0:CD30::/60
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;以下不是上述前缀的合法表示：&lt;br&gt;
&lt;code&gt;2001:0DB8:0:CD3/60&lt;/code&gt;：在地址的任何16位块中，可以删除前导零，但不删除尾随零&lt;br&gt;
&lt;code&gt;2001:0DB8::CD30/60&lt;/code&gt;：“/”左边的地址扩展为 &lt;code&gt;2001:0DB8:0000:0000:0000:0000:0000:CD30&lt;/code&gt;&lt;br&gt;
&lt;code&gt;2001:0DB8::CD3/60&lt;/code&gt;：“/”左边的地址扩展为 &lt;code&gt;2001:0DB8:0000:0000:0000:0000:0000:0CD3&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;当书写节点地址和该节点地址的前缀（例如，节点的子网前缀）时，二者合并写法如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;节点地址          2001:0DB8:0:CD30:123:4567:89AB:CDEF
和它的子网号      2001:0DB8:0:CD30::/60
二者能够缩写为    2001:0DB8:0:CD30:123:4567:89AB:CDEF/60
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;24-address-type-identification&#34;&gt;2.4 Address Type Identification&lt;/h2&gt;
&lt;p&gt;IPv6 地址的类型由地址的高阶位来标识，具体如下:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Address type&lt;/th&gt;
&lt;th&gt;Binary prefix&lt;/th&gt;
&lt;th&gt;IPv6 notation&lt;/th&gt;
&lt;th&gt;Section&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Unspecified&lt;/td&gt;
&lt;td&gt;00...0（128位）&lt;/td&gt;
&lt;td&gt;::/128&lt;/td&gt;
&lt;td&gt;2.5.2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Loopback&lt;/td&gt;
&lt;td&gt;00...1（128位）&lt;/td&gt;
&lt;td&gt;::1/128&lt;/td&gt;
&lt;td&gt;2.5.3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Multicast&lt;/td&gt;
&lt;td&gt;11111111&lt;/td&gt;
&lt;td&gt;FF00::/8&lt;/td&gt;
&lt;td&gt;2.7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Link-Local unicast&lt;/td&gt;
&lt;td&gt;1111111010&lt;/td&gt;
&lt;td&gt;FE80::/10&lt;/td&gt;
&lt;td&gt;2.5.6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Global Unicast&lt;/td&gt;
&lt;td&gt;（everything else）&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;任播（Anycast）地址取自（任何作用域的）单播地址空间，在语法上与单播地址不可区分。&lt;/p&gt;
&lt;p&gt;全球单播（Global Unicast）地址的一般格式见 2.5.4 节。一些特殊用途的包含嵌入式 IPv4 地址的全球单播地址子类型（用于 IPv4-IPv6 互操作）将在章节 2.5.5 中描述。&lt;/p&gt;
&lt;p&gt;将来的规范可能会为其他目的重新定义全局单播空间的一个或多个子范围，但除非发生这种情况，否则实现必须把没有以上述列出的任何一种前缀开始的所有地址，当作是全球单播地址。&lt;/p&gt;
&lt;h2 id=&#34;25-unicast-addresses&#34;&gt;2.5 Unicast Addresses&lt;/h2&gt;
&lt;p&gt;IPv6 单播地址可以与任意位长的前缀聚合，类似于无分类域间路由中的 IPv4 地址。&lt;/p&gt;
&lt;p&gt;IPv6 中有几种类型的单播地址，特别是全局单播、站点-本地单播（已弃用，参见 2.5.7 节）和链路-本地单播。全球单播也有一些特殊用途的子类型，例如带有嵌入式 IPv4 地址的 IPv6 地址。将来可以定义更多的地址类型或子类型。&lt;/p&gt;
&lt;p&gt;IPv6 节点可能非常了解，也可能很少了解 IPv6 地址内部结构，这取决于节点扮演的角色（例如，主机 vs 路由器）。至少，一个节点可以认为单播地址（包括它自己的）没有内部结构：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;   |                           128 bits                              |
   +-----------------------------------------------------------------+
   |                          node address                           |
   +-----------------------------------------------------------------+
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;一个稍微复杂的主机（但仍然相当简单）可能还知道它所连接的链路的子网前缀，不同的地址可能有不同的 n 位值：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;   |          n bits               |           128-n bits            |
   +-------------------------------+---------------------------------+
   |       subnet prefix           |           interface ID          |
   +-------------------------------+---------------------------------+
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;虽然一个非常简单的路由器可能不知道 IPv6 单播地址的内部结构，但路由器通常会知道一个或多个路由协议运行分层边界。已知的边界会因路由器而异，这取决于路由器在路由层次结构中的位置。&lt;/p&gt;
&lt;p&gt;除了前面讨论的子网边界的知识，节点不应该对 IPv6 地址的结构做任何假设。&lt;/p&gt;
&lt;h3 id=&#34;251-interface-identifiers&#34;&gt;2.5.1 Interface Identifiers&lt;/h3&gt;
&lt;p&gt;IPv6 单播地址中的&lt;strong&gt;接口标识符&lt;/strong&gt;（Interface identifiers，IID）用于标识链路上的接口。它们在子网前缀中必须是唯一的。建议同一条链路上的不同节点不要使用相同的接口标识符。它们在更广泛的范围内也可能是唯一的。在某些情况下，接口的标识符将直接从该接口的链路层地址派生。同一个节点上的多个接口可以使用相同的接口标识符，只要这些接口属于不同的子网。&lt;/p&gt;
&lt;p&gt;注意接口标识符的唯一性与 IPv6 地址的唯一性无关。例如，可以使用本地作用域接口标识（local  scope interface identifier）创建全局单播地址，也可以使用通用作用域接口标识（universal scope interface identifier）创建链路本地地址（Link-Local address）。&lt;/p&gt;
&lt;p&gt;除了以二进制值 &lt;code&gt;000&lt;/code&gt; 开头的单播地址外，所有单播地址的“接口ID”长度都要求为 64 位，并按照修改的 EUI-64 格式构造。&lt;/p&gt;
&lt;p&gt;修改的基于 EUI-64 格式的接口标识符在从通用令牌派生时可能具有通用作用域（例如，IEEE 802 48位MAC 或 IEEE EUI-64 标识符 [EUI64]），或者在通用全球令牌不可用时可能具有本地作用域（例如，串行链路、隧道端点）或不希望使用全球标记时（例如，隐私临时令牌 [PRIV]）。&lt;/p&gt;
&lt;p&gt;修改的 EUI-64 格式的接口标识符由 IEEE EUI-64 标识符组成时，是通过将“u”位（IEEE EUI-64 术语中的通用/本地位）反转来形成的。在产生的修改 EUI-64 格式中，“u”位被设置为 （1） 表示通用范围，它被设置为 （0） 表示本地范围。IEEE EUI-64 二进制标识符的前三个字节如下:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;          0       0 0       1 1       2
         |0       7 8       5 6       3|
         +----+----+----+----+----+----+
         |cccc|ccug|cccc|cccc|cccc|cccc|
         +----+----+----+----+----+----+
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;以互联网标准位顺序书写，其中“u”是 通用/本地（universal/local）位，“g”是个体/组（individual/group）位，“c”是公司 ID 的位。附录A“Creating Modified EUI-64 Format Interface Identifiers”提供了创建基于修改后的 EUI-64 格式的接口标识符的示例。&lt;/p&gt;
&lt;p&gt;在形成接口标识符时，将“u”位反转的动机是，当硬件令牌不可用时，系统管理员可以方便地配置非全局标识符。例如，串行连接（serial link）和隧道端点（tunnel end-points）都可能出现这种情况。另一种形式是 &lt;code&gt;0200:0:0:1&lt;/code&gt;、&lt;code&gt;0200:0:0:2&lt;/code&gt;，等等，代替更简单的 &lt;code&gt;0:0:0:0:1&lt;/code&gt;、&lt;code&gt;0:0:2&lt;/code&gt;，等等。&lt;/p&gt;
&lt;p&gt;IPv6 节点不需要验证使用修改过的 EUI-64 令牌（“u”位设置为universal）创建的接口标识符是否唯一。&lt;/p&gt;
&lt;p&gt;在修改的EUI-64格式标识符中使用通用/本地位是为了允许未来技术的开发，从而利用具有通用作用域的接口标识符。&lt;/p&gt;
&lt;p&gt;形成接口标识符的细节在适当的“&lt;code&gt;IPv6 over &amp;lt;link&amp;gt;&lt;/code&gt;”规范中定义，例如“IPv6 over Ethernet”[ETHER]和“IPv6 over FDDI”[FDDI]。&lt;/p&gt;
&lt;h3 id=&#34;252-the-unspecified-address&#34;&gt;2.5.2 The Unspecified Address&lt;/h3&gt;
&lt;p&gt;地址 &lt;code&gt;0:0:0:0:0:0&lt;/code&gt; 称为未指定地址（unspecified address）。它永远不能被分配给任何节点。它用来表示没有地址。使用它的一个例子是，正在初始化的主机还没有学习到它自己的地址之前，它发送的任何 IPv6 分组中 Source Address 字段的内容。&lt;/p&gt;
&lt;p&gt;未指定的地址不能用作 IPv6 报文的目的地址或在 IPv6 路由报头中。源地址不指定的 IPv6 报文不能被 IPv6 路由器转发。&lt;/p&gt;
&lt;h3 id=&#34;253-the-loopback-address&#34;&gt;2.5.3 The Loopback Address&lt;/h3&gt;
&lt;p&gt;单播地址 &lt;code&gt;0:0:0:0:0:1&lt;/code&gt; 称为环回地址（Loopback Address）。节点可以使用它向自身发送 IPv6 数据包。它不能被分配给任何物理接口。它被视为具有 Link-Local 作用域，可以被认为是到一个不存在的虚拟链路的虚拟接口（通常称为“环回接口（loopback interface）”）的 Link-Local 单播地址。&lt;/p&gt;
&lt;p&gt;环回地址不能作为发送到单个节点外的 IPv6 报文的源地址。以环回地址为目的地地址的 IPv6 分组决不能发送到单一节点以外，也不能被 IPv6 路由器转发。对于目的地址为 loopback 的接口，必须丢弃报文。&lt;/p&gt;
&lt;h3 id=&#34;254-global-unicast-addresses&#34;&gt;2.5.4 Global Unicast Addresses&lt;/h3&gt;
&lt;p&gt;IPv6 全球单播地址的一般格式如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;   |         n bits         |   m bits  |       128-n-m bits         |
   +------------------------+-----------+----------------------------+
   | global routing prefix  | subnet ID |       interface ID         |
   +------------------------+-----------+----------------------------+
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其中全局路由前缀（global routing prefix）是一个分配给站点（子网/链路集群）的值（通常是层次结构的），子网 ID （subnet ID）是站点内链路的标识符，接口 ID （interface ID）如章节 2.5.1 所定义。&lt;/p&gt;
&lt;p&gt;除以二进制 &lt;code&gt;000&lt;/code&gt; 开头的地址外，所有的全球单播地址都有一个 64 位的接口 ID 字段（即n + m = 64），格式如章节 2.5.1 所述。以二进制 &lt;code&gt;000&lt;/code&gt; 开头的全球单播地址对接口 ID 字段的大小或结构没有这样的约束。&lt;/p&gt;
&lt;p&gt;以二进制 &lt;code&gt;000&lt;/code&gt; 开头的全球单播地址的例子是在 2.5.5 节中描述的嵌入 IPv4 地址的 IPv6 地址。在[GLOBAL] 中可以找到一个以二进制值而不是 &lt;code&gt;000&lt;/code&gt; （因此有一个64位的接口ID字段）开头的全局地址示例。&lt;/p&gt;
&lt;h3 id=&#34;255-ipv6-addresses-with-embedded-ipv4-addresses&#34;&gt;2.5.5 IPv6 Addresses with Embedded IPv4 Addresses&lt;/h3&gt;
&lt;p&gt;定义了两种 IPv6 地址，它们携带 IPv4 地址的低阶 32 位。即“IPv4-Compatible IPv6 address”和“IPv4-mapped IPv6 address”。&lt;/p&gt;
&lt;h4 id=&#34;2551-ipv4-compatible-ipv6-address&#34;&gt;2.5.5.1 IPv4-Compatible IPv6 Address&lt;/h4&gt;
&lt;p&gt;定义“IPv4-Compatible IPv6 address”是为了帮助实现 IPv6 的过渡。“IPv4-Compatible IPv6 address”格式如下:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;   |                80 bits               | 16 |      32 bits        |
   +--------------------------------------+--------------------------+
   |0000..............................0000|0000|    IPv4 address     |
   +--------------------------------------+----+---------------------+
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;注:“IPv4-Compatible IPv6 address”中的 IPv4 地址必须为全球唯一的 IPv4 单播地址。&lt;/p&gt;
&lt;p&gt;“IPv4-Compatible IPv6 address”现在已弃用，因为当前的 IPv6 转换机制不再使用这些地址。不需要新的或更新的实现来支持这种地址类型。&lt;/p&gt;
&lt;h4 id=&#34;2552-ipv4-mapped-ipv6-address&#34;&gt;2.5.5.2 IPv4-mapped IPv6 Address&lt;/h4&gt;
&lt;p&gt;定义了第二种类型的 IPv6 地址，它包含一个嵌入式 IPv4 地址。该地址类型用于将 IPv4 节点的地址表示为 IPv 6地址。“IPv4-mapped IPv6 address”格式如下:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;   |                80 bits               | 16 |      32 bits        |
   +--------------------------------------+--------------------------+
   |0000..............................0000|FFFF|    IPv4 address     |
   +--------------------------------------+----+---------------------+
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;关于“IPv4-mapped IPv6 address”的使用背景参见 [RFC4038]。&lt;/p&gt;
&lt;h3 id=&#34;256-link-local-ipv6-unicast-addresses&#34;&gt;2.5.6 Link-Local IPv6 Unicast Addresses&lt;/h3&gt;
&lt;p&gt;链路本地（Link-Local）地址用于单个链路。Link-Local 地址格式如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;   |   10     |
   |  bits    |         54 bits         |          64 bits           |
   +----------+-------------------------+----------------------------+
   |1111111010|           0             |       interface ID         |
   +----------+-------------------------+----------------------------+
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Link-Local 地址被设计用于在单个链路上寻址，用于自动地址配置、邻居发现或没有路由器时。&lt;/p&gt;
&lt;p&gt;路由器不能将源地址或目的地址为 Link-Local 的报文转发到其他链路。&lt;/p&gt;
&lt;h3 id=&#34;257-site-local-ipv6-unicast-addresses&#34;&gt;2.5.7 Site-Local IPv6 Unicast Addresses&lt;/h3&gt;
&lt;p&gt;站点-本地（Site-Local）地址最初设计用于在站点内部寻址，而不需要全局前缀。站点本地地址现在已如 [SLDEP] 中定义的那样被弃用。&lt;/p&gt;
&lt;p&gt;Site-Local 地址有以下格式：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;   |   10     |
   |  bits    |         54 bits         |         64 bits            |
   +----------+-------------------------+----------------------------+
   |1111111011|        subnet ID        |       interface ID         |
   +----------+-------------------------+----------------------------+
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这个前缀在 [RFC3513] 中定义的特殊行为在新的实现中必须不再被支持（即，新的实现必须将这个前缀视为全局单播）。&lt;/p&gt;
&lt;p&gt;现有的实现和部署可能会继续使用这个前缀。&lt;/p&gt;
&lt;h2 id=&#34;26-anycast-addresses&#34;&gt;2.6 Anycast Addresses&lt;/h2&gt;
&lt;p&gt;IPv6 任播地址是一个被分配给多个接口（通常属于不同的节点）的地址，其属性是，发送到任播地址的数据包将被路由到具有该地址的“最近”接口，根据路由协议的距离度量。&lt;/p&gt;
&lt;p&gt;任播地址从单播地址空间中分配，使用任何定义的单播地址格式。因此，任播地址和单播地址在语法上是不可区分的。当一个单播地址被分配给多个接口，从而将其转换为任播地址时，被分配该地址的节点必须显式配置，以知道它是任播地址。&lt;/p&gt;
&lt;p&gt;对于任何被分配的任播地址，该地址有一个最长的前缀 P，它标识了属于该任播地址的所有接口所在的拓扑区域。在由 P 标识的区域内，任播地址必须在路由系统中作为一个单独的条目维护（通常称为“主机路由”）；在由 P 标识的区域之外，任播地址可以聚合到前缀 P 的路由表项中。&lt;/p&gt;
&lt;p&gt;注意，在最坏的情况下，任播集合的前缀 P 可能是空前缀，也就是说，集合的成员可能没有拓扑局部性。在这种情况下，任播地址必须在整个 Internet 中作为一个单独的路由条目来维护，这对支持多少这样的“全局”任播集合提出了一个严重的扩展限制。因此，预计对全局任播集合的支持可能不可用或非常有限。&lt;/p&gt;
&lt;p&gt;任播地址的一个预期用途是识别属于提供互联网服务的组织的一组路由器。这些地址可以用作 IPv6 路由报头中的中间地址，以使数据包通过特定的服务提供者或服务提供者序列被交付。&lt;/p&gt;
&lt;p&gt;其他一些可能的用途是识别连接到特定子网的路由器集合，或提供进入特定路由域的入口的路由器集合。&lt;/p&gt;
&lt;h3 id=&#34;261-required-anycast-address&#34;&gt;2.6.1 Required Anycast Address&lt;/h3&gt;
&lt;p&gt;子网路由器任播（Subnet-Router anycast）地址是预定义的。其格式如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;   |                         n bits                 |   128-n bits   |
   +------------------------------------------------+----------------+
   |                   subnet prefix                | 00000000000000 |
   +------------------------------------------------+----------------+
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;任播地址中的“subnet prefix”是标识特定链路的前缀。该任播地址在语法上与接口标识符为零的接口的单播地址相同。&lt;/p&gt;
&lt;p&gt;发送到 Subnet-Router anycast 地址的数据包将被发送到子网中的一个路由器。所有的路由器都需要支持子网路由器的任播地址，因为它们有接口。&lt;/p&gt;
&lt;p&gt;Subnet-Router anycast 地址用于节点需要与任意一组路由器进行通信的应用程序。&lt;/p&gt;
&lt;h2 id=&#34;27-multicast-addresses&#34;&gt;2.7 Multicast Addresses&lt;/h2&gt;
&lt;p&gt;IPv6 组播地址是一组接口（通常在不同的节点上）的标识符。一个接口可以属于任意数量的多播组。多播地址的格式如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;   |   8    |  4 |  4 |                  112 bits                   |
   +------ -+----+----+---------------------------------------------+
   |11111111|flgs|scop|                  group ID                   |
   +--------+----+----+---------------------------------------------+
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;地址开头的二进制 &lt;code&gt;11111111&lt;/code&gt; 标识该地址为多播地址。&lt;br&gt;
flags 是 4 个 flag 的集合：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;+-+-+-+-+
|0|R|P|T|
+-+-+-+-+
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;高阶标志是保留的，必须初始化为0。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;T = 0&lt;/code&gt; 表示一个永久分配的（众所周知的）组播地址，由IANA （Internet assigned Numbers Authority）分配。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;T = 1&lt;/code&gt; 表示非永久分配（“瞬态”或“动态”分配）的多播地址。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;P&lt;/code&gt; 标志的定义和用法可以在 [RFC3306] 中找到。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;R&lt;/code&gt; 标志的定义和用法可以在 [RFC3956] 中找到。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;scop 是一个 4 位组播作用域值，用于限制组播组的作用域。取值如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;         0  reserved
         1  Interface-Local scope
         2  Link-Local scope
         3  reserved
         4  Admin-Local scope
         5  Site-Local scope
         6  （unassigned）
         7  （unassigned）
         8  Organization-Local scope
         9  （unassigned）
         A  （unassigned）
         B  （unassigned）
         C  （unassigned）
         D  （unassigned）
         E  Global scope
         F  reserved
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Interface-Local 作用域只覆盖节点上的一个接口，只适用于组播的环回传输。从其他节点收到的 Interface-Local 作用域的报文必须被丢弃。

Link-Local 组播作用域与对应的单播作用域跨越相同的拓扑区域。

Admin-Local 作用域是必须管理性配置的最小作用域，即不是从物理连接或其他非多播相关配置中自动获得的。

Site-Local 作用域旨在跨越单个站点。

Organization-Local 作用域旨在跨越属于单个组织的多个站点。

标有“（unassigned）”的作用域可供管理员定义其他多播区域。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;group ID 标识给定范围内的多播组（永久或临时）。组播组 ID 字段结构的附加定义在 [RFC3306] 中提供。&lt;/p&gt;
&lt;p&gt;永久分配的多播地址的“含义”与作用域值无关。例如，如果“NTP服务器组”被分配一个组 ID 为 &lt;code&gt;101&lt;/code&gt; （十六进制）的永久多播地址，那么&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;FF01:0:0:0:0:0:0:101 表示所有 NTP 服务器与发送者在同一个接口（即同一个节点）上。
FF02:0:0:0:0:0:0:101 表示与发送方在同一条链路上的所有 NTP 服务器。
FF05:0:0:0:0:0:0:101 表示与发送方在同一站点的所有 NTP 服务器。
FF0E:0:0:0:0:0:0:101 表示互联网上的所有 NTP 服务器。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;非永久分配的多播地址（Non-premanently-assigned multicast address）仅在给定范围内有意义。例如，一组确定的非永久性的，本地站点多播地址 &lt;code&gt;FF15:0:0:0:0:0:0:101&lt;/code&gt; 标识的组与在不同站点处使用相同地址的组、使用不同范围的相同组 ID 的非永久组、以及具有相同组 ID 的永久组都没有关系。&lt;/p&gt;
&lt;p&gt;多播地址不能用作 IPv6 数据包中的源地址，也不能出现在任何路由头中。&lt;/p&gt;
&lt;p&gt;路由器不得转发任何超出目的多播地址中 scop 字段所指示范围之外的多播数据包。&lt;/p&gt;
&lt;p&gt;节点不得向其 scop 字段包含保留值 0 的多播地址发起分组；如果收到这样的数据包，它必须被无声地丢弃。节点不应该向其 scop 字段包含保留值 F 的多播地址发起分组；如果发送或接收到这样的数据包，它必须被视为与目的地为全局（scop E）多播地址的数据包相同。&lt;/p&gt;
&lt;h3 id=&#34;271-pre-defined-multicast-addresses&#34;&gt;2.7.1 Pre-Defined Multicast Addresses&lt;/h3&gt;
&lt;p&gt;下面是预定义的众所周知（well-known）的多播地址。本节中定义的组 ID 是为显式范围值定义的。&lt;/p&gt;
&lt;p&gt;不允许将这些组 ID 用于任何其他范围值，T 标志等于0。&lt;/p&gt;
&lt;p&gt;保留的多播地址：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;                                      FF00:0:0:0:0:0:0:0
                                      FF01:0:0:0:0:0:0:0
                                      FF02:0:0:0:0:0:0:0
                                      FF03:0:0:0:0:0:0:0
                                      FF04:0:0:0:0:0:0:0
                                      FF05:0:0:0:0:0:0:0
                                      FF06:0:0:0:0:0:0:0
                                      FF07:0:0:0:0:0:0:0
                                      FF08:0:0:0:0:0:0:0
                                      FF09:0:0:0:0:0:0:0
                                      FF0A:0:0:0:0:0:0:0
                                      FF0B:0:0:0:0:0:0:0
                                      FF0C:0:0:0:0:0:0:0
                                      FF0D:0:0:0:0:0:0:0
                                      FF0E:0:0:0:0:0:0:0
                                      FF0F:0:0:0:0:0:0:0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上述多播地址被保留，不得分配给任何多播组。&lt;br&gt;
所有节点地址:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;                              FF01:0:0:0:0:0:0:1
                              FF02:0:0:0:0:0:0:1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上述多播地址标识范围 1（接口本地，interface-local）或范围 2（链路本地，link-local）内的所有 IPv6 节点的组。&lt;/p&gt;
&lt;p&gt;所有路由器地址:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;                               FF01:0:0:0:0:0:0:2
                               FF02:0:0:0:0:0:0:2
                               FF05:0:0:0:0:0:0:2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上述多播地址标识范围 1（接口本地，interface-local）或范围 2（链路本地，link-local）或 5 （站点本地，site-local）内的所有 IPv6 路由器的组。&lt;/p&gt;
&lt;p&gt;请求节点地址（Solicited-Node Address）：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;                               FF02:0:0:0:0:1:FFXX:XXXX
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Solicited-Node 组播地址的计算是节点单播地址和任播地址的函数。Solicited-Node 多播地址是由一个地址的低阶的 24 位（单播或任播）和附加位前缀 &lt;code&gt;FF02:0:0:0:0:1:FF00::/104&lt;/code&gt; 来形成的。从而得到范围 &lt;code&gt;FF02:0:0:0:0:1:FF00:0000&lt;/code&gt; 到 &lt;code&gt;FF02:0:0:0:0:1:FFFF:FFFF&lt;/code&gt;  的多播地址。&lt;/p&gt;
&lt;p&gt;例如，对应于 IPv6 地址 &lt;code&gt;4037::01:800:200E:8C6C&lt;/code&gt; 的请求节点多播地址是 &lt;code&gt;FF02::1:FF0E:8C6C&lt;/code&gt;。仅在高阶位不同的 IPv6 地址（例如，由于与不同聚合相关联的多个高阶前缀）将映射到相同的被请求节点地址，从而减少节点必须加入的多播地址的数量。&lt;/p&gt;
&lt;p&gt;要求节点计算并加入（在适当的接口上）已经为该节点的接口（手动或自动）配置的所有单播和任播地址的相关 Solicited-Node 多播地址。&lt;/p&gt;
&lt;h2 id=&#34;28-a-nodes-required-addresses&#34;&gt;2.8 A Node&#39;s Required Addresses&lt;/h2&gt;
&lt;p&gt;主机需要识别以下地址作为其自身的标识：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;它需要每个接口的 Link-Local 地址。&lt;/li&gt;
&lt;li&gt;（手动或自动）为节点接口配置的任何其他 Unicast 和 Anycast 地址。&lt;/li&gt;
&lt;li&gt;环回地址。&lt;/li&gt;
&lt;li&gt;在章节 2.7.1 中定义的所有节点组播地址。&lt;/li&gt;
&lt;li&gt;Solicited-Node 的单播和任播地址的组播地址。&lt;/li&gt;
&lt;li&gt;该节点所属的所有其他组的多播地址。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;路由器需要识别主机需要识别的所有地址，以及以下用于识别自身的地址：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;配置为充当路由器的所有接口的 Subnet-Router Anycast 地址。&lt;/li&gt;
&lt;li&gt;路由器已配置的所有其他 Anycast 地址。&lt;/li&gt;
&lt;li&gt;在章节 2.7.1 定义的 All-Routers 组播地址。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;3-secutiry-considerations&#34;&gt;3. Secutiry Considerations&lt;/h1&gt;
&lt;p&gt;IPv6 寻址文档对 Internet 基础设施安全没有任何直接影响。在 [AUTH] 中定义了 IPv6 报文的认证。&lt;/p&gt;
&lt;h1 id=&#34;4-iana-considerations&#34;&gt;4. IANA Considerations&lt;/h1&gt;
&lt;p&gt;不建议使用“IPv4-Compatible IPv6 address”。IANA 应该继续将 &lt;a href=&#34;#http://www.iana.org/assignments/ipv6-address-space&#34;&gt;http://www.iana.org/assignments/ipv6-address-space&lt;/a&gt; 上包含这些地址的地址块列为“由 IETF 保留的”，而不为任何其他目的重新分配它。例如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;      0000::/8        Reserved by IETF        [RFC3513]      [1]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;IANA 已经添加了以下注释和到这个地址块的链接。&lt;br&gt;
[5]  0000::/96 以前被定义为“IPv4-Compatible IPv6 address”前缀。该定义已被 RFC 4291弃用。&lt;br&gt;
IANA 相应地更新了 IANA 注册表中关于 IPv6 地址体系结构的参考。&lt;/p&gt;
&lt;h1 id=&#34;5-acknowledgements&#34;&gt;5. Acknowledgements&lt;/h1&gt;
&lt;p&gt;The authors would like to acknowledge the contributions of Paul Francis, Scott Bradner, Jim Bound, Brian Carpenter, Matt Crawford, Deborah Estrin, Roger Fajman, Bob Fink, Peter Ford, Bob Gilligan, Dimitry Haskin, Tom Harsch, Christian Huitema, Tony Li, Greg Minshall, Thomas Narten, Erik Nordmark, Yakov Rekhter, Bill Simpson, Sue Thomson, Markku Savela, Larry Masinter, Jun-ichiro Itojun Hagino, Tatuya Jinmei, Suresh Krishnan, and Mahmood Ali.&lt;/p&gt;
&lt;h1 id=&#34;6-references&#34;&gt;6. References&lt;/h1&gt;
&lt;h2 id=&#34;61-normative-references&#34;&gt;6.1 Normative References&lt;/h2&gt;
&lt;p&gt;[IPV6]  Deering, S. and R. Hinden, &amp;quot;Internet Protocol, Version 6 (IPv6) Specification&amp;quot;, RFC 2460, December 1998.&lt;/p&gt;
&lt;h2 id=&#34;62-informative-references&#34;&gt;6.2 Informative References&lt;/h2&gt;
&lt;p&gt;[AUTH]    Kent, S. and R. Atkinson, &amp;quot;IP Authentication Header&amp;quot;, RFC 2402, November 1998.&lt;/p&gt;
&lt;p&gt;[CIDR]    Fuller, V., Li, T., Yu, J., and K. Varadhan, &amp;quot;Classless Inter-Domain Routing (CIDR): an Address Assignment and Aggregation Strategy&amp;quot;, RFC 1519, September 1993.&lt;/p&gt;
&lt;p&gt;[ETHER]   Crawford, M., &amp;quot;Transmission of IPv6 Packets over Ethernet Networks&amp;quot;, RFC 2464, December 1998.&lt;/p&gt;
&lt;p&gt;[EUI64]   IEEE, &amp;quot;Guidelines for 64-bit Global Identifier (EUI-64) Registration Authority&amp;quot;, http://standards.ieee.org/regauth/oui/tutorials/EUI64.html, March 1997.&lt;/p&gt;
&lt;p&gt;[FDDI]    Crawford, M., &amp;quot;Transmission of IPv6 Packets over FDDI Networks&amp;quot;, RFC 2467, December 1998.&lt;/p&gt;
&lt;p&gt;[GLOBAL]  Hinden, R., Deering, S., and E. Nordmark, &amp;quot;IPv6 Global Unicast Address Format&amp;quot;, RFC 3587, August 2003.&lt;/p&gt;
&lt;p&gt;[PRIV]    Narten, T. and R. Draves, &amp;quot;Privacy Extensions for Stateless Address Autoconfiguration in IPv6&amp;quot;, RFC 3041, January 2001.&lt;/p&gt;
&lt;p&gt;[RFC3513] Hinden, R. and S. Deering, &amp;quot;Internet Protocol Version 6 (IPv6) Addressing Architecture&amp;quot;, RFC 3513, April 2005.&lt;/p&gt;
&lt;p&gt;[RFC3306] Haberman, B. and D. Thaler, &amp;quot;Unicast-Prefix-based IPv6&lt;br&gt;
Multicast Addresses&amp;quot;, RFC 3306, August 2002.&lt;/p&gt;
&lt;p&gt;[RFC3956] Savola, P. and B. Haberman, &amp;quot;Embedding the Rendezvous Point (RP) Address in an IPv6 Multicast Address&amp;quot;, RFC 3956, November 2004.&lt;/p&gt;
&lt;p&gt;[RFC4038] Shin, M-K., Hong, Y-G., Hagino, J., Savola, P., and E. Castro, &amp;quot;Application Aspects of IPv6 Transition&amp;quot;, RFC 4038, March 2005.&lt;/p&gt;
&lt;p&gt;[SLDEP]   Huitema, C. and B. Carpenter, &amp;quot;Deprecating Site Local Addresses&amp;quot;, RFC 3879, September 2004.&lt;/p&gt;
&lt;h1 id=&#34;appendix-a-creating-modified-eui-64-format-interface-identifiers&#34;&gt;Appendix A: Creating Modified EUI-64 Format Interface Identifiers&lt;/h1&gt;
&lt;p&gt;根据特定链接或节点的特征，有许多方法可以创建修改 EUI-64格式的接口标识符。本附录描述了其中的一些方法。&lt;/p&gt;
&lt;h2 id=&#34;links-or-nodes-with-ieee-eui-64-identifiers&#34;&gt;Links or Nodes with IEEE EUI-64 Identifiers&lt;/h2&gt;
&lt;p&gt;将 IEEE EUI-64 标识符转换为接口标识符所需的唯一更改是将“u”（通用/本地）位反转。一个例子是表单的全局唯一 IEEE EUI-64 标识符：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;   |0              1|1              3|3              4|4              6|
   |0              5|6              1|2              7|8              3|
   +----------------+----------------+----------------+----------------+
   |cccccc0gcccccccc|ccccccccmmmmmmmm|mmmmmmmmmmmmmmmm|mmmmmmmmmmmmmmmm|
   +----------------+----------------+----------------+----------------+
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其中，“&lt;code&gt;c&lt;/code&gt;”是指定的 company_id 的位，“&lt;code&gt;0&lt;/code&gt;”是通用/本地位的值，表示通用范围，“&lt;code&gt;g&lt;/code&gt;”是单个/组位，“&lt;code&gt;m&lt;/code&gt;”是制造商选择的扩展标识符的位。IPv6 接口标识符的形式如下:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;   |0              1|1              3|3              4|4              6|
   |0              5|6              1|2              7|8              3|
   +----------------+----------------+----------------+----------------+
   |cccccc1gcccccccc|ccccccccmmmmmmmm|mmmmmmmmmmmmmmmm|mmmmmmmmmmmmmmmm|
   +----------------+----------------+----------------+----------------+
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;唯一的变化是将通用/本地位的值颠倒。&lt;/p&gt;
&lt;h2 id=&#34;links-or-nodes-with-ieee-802-48-bit-macs&#34;&gt;Links or Nodes with IEEE 802 48-bit MACs&lt;/h2&gt;
&lt;p&gt;[EUI64]定义了一种从 IEEE 48 位 MAC 标识符创建 IEEE EUI-64 标识符的方法。这是在 48 位 MAC （在 company_id 和供应商提供的 id 之间）的中间插入两个 octet，其十六进制值为 &lt;code&gt;0xFF&lt;/code&gt; 和&lt;code&gt;0xFE&lt;/code&gt;（参见附录末尾的注释）。一个例子是具有全局作用域的 48 位 IEEE MAC：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;   |0              1|1              3|3              4|
   |0              5|6              1|2              7|
   +----------------+----------------+----------------+
   |cccccc0gcccccccc|ccccccccmmmmmmmm|mmmmmmmmmmmmmmmm|
   +----------------+----------------+----------------+
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其中，“&lt;code&gt;c&lt;/code&gt;”是分配的 company_id 的位，“&lt;code&gt;0&lt;/code&gt;”是通用/本地位的值，用来表示 Global 作用域，“&lt;code&gt;g&lt;/code&gt;”是单个/组位，“&lt;code&gt;m&lt;/code&gt;”是制造商选择的扩展标识符的位。接口标识符的形式如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;   |0              1|1              3|3              4|4              6|
   |0              5|6              1|2              7|8              3|
   +----------------+----------------+----------------+----------------+
   |cccccc1gcccccccc|cccccccc11111111|11111110mmmmmmmm|mmmmmmmmmmmmmmmm|
   +----------------+----------------+----------------+----------------+
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;当 IEEE 802 48 位 MAC 地址可用时（在接口或节点上），由于其可用性和唯一性，实现可能使用它们来创建接口标识符。&lt;/p&gt;
&lt;h2 id=&#34;links-with-other-kinds-of-identifiers&#34;&gt;Links with Other Kinds of Identifiers&lt;/h2&gt;
&lt;p&gt;除了 IEEE EUI-64 或 IEEE 802 48 位 MAC 之外，还有许多类型的链路具有链路层接口标识符。例如 LocalTalk 和 Arcnet 。创建 Modified EUI-64 格式标识符的方法是采用链接标识符（例如，LocalTalk 8 位节点标识符），并将其填充到左侧。例如，LocalTalk 的 8 位节点标识符的十六进制值 &lt;code&gt;0x4F&lt;/code&gt; 会导致如下接口标识符：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;   |0              1|1              3|3              4|4              6|
   |0              5|6              1|2              7|8              3|
   +----------------+----------------+----------------+----------------+
   |0000000000000000|0000000000000000|0000000000000000|0000000001001111|
   +----------------+----------------+----------------+----------------+
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;注意，这将导致通用/本地位被设置为“0”，以表示本地作用域。&lt;/p&gt;
&lt;h2 id=&#34;links-without-identifiers&#34;&gt;Links without Identifiers&lt;/h2&gt;
&lt;p&gt;有许多链接没有任何类型的内置标识符。其中最常见的是串行连接和配置的隧道。必须选择在子网前缀内唯一的接口标识符。&lt;/p&gt;
&lt;p&gt;当链路上没有内置标识符时，首选方法是使用另一个接口的通用接口标识符或分配给节点本身的标识符。当使用这种方法时，将同一节点连接到同一子网前缀的其它接口不能使用同一标识符。&lt;/p&gt;
&lt;p&gt;如果链路上没有可用的通用接口标识符，则实现需要创建一个本地范围的接口标识符。唯一的要求是它在子网前缀中是唯一的。有许多可能的方法来选择子网前缀唯一接口标识符。其中包括以下内容：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Manual Configuration&lt;/li&gt;
&lt;li&gt;Node Serial Number&lt;/li&gt;
&lt;li&gt;Other Node-Specific Token&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;子网前缀唯一（subnet-prefix-unique）接口标识符应该以这样一种方式生成，使得它在节点重新启动后或者在节点中添加或删除接口时不会改变。&lt;/p&gt;
&lt;p&gt;适当算法的选择取决于链路和实现。在适当的“&lt;code&gt;IPv6 over &amp;lt;link &amp;gt;&lt;/code&gt;”规范中定义了关于形成接口标识符的细节。强烈建议将冲突检测算法作为任何自动算法的一部分来实现。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;注意：[EUI-64] 实际上将 0xFF 和 0xFE 定义为要插入的位，以从 IEEE MAC- 48 标识
符创建 IEEE EUI-64 标识符。从 IEEE EUI-48 标识符开始时，使用 0xFF 和 0xFE 
值。由于对 IEEE MAC-48 和 EUI-48 标识符之间的差异存在误解，早期版本的规范中使用
了不正确的值。

本文档特意继续使用 0xFF 和 0xFE，因为它符合 IPv6 接口标识符的要求(即它们在链路上
必须是唯一的)，IEEE EUI-48 和 MAC-48 标识符在语法上是等效的，并且在实践中不会引
起任何问题。
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;appendix-b-changes-from-rfc-3513&#34;&gt;Appendix B: Changes from RFC 3513&lt;/h2&gt;
&lt;p&gt;RFC 3513“IP Version 6 Addressing Architecture”有以下变化：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;取消了对使用 IPv6 任播地址的限制，因为现在已经有了足够的使用任播地址的经验，这些问题并不是 IPv6 所特有的，并且 GROW 工作组正在这一领域开展工作。&lt;/li&gt;
&lt;li&gt;不赞成使用站点本地单播前缀。变化包括以下内容：
&lt;ul&gt;
&lt;li&gt;从2.4节的特殊前缀列表中删除了Site-Local。&lt;/li&gt;
&lt;li&gt;将标题为“Local-use IPv6 Unicast Addresses”的部分分成两个部分，“Link-Local IPv6 Unicast Addresses”和“Site-   Local IPv6 Unicast Addresses”。&lt;/li&gt;
&lt;li&gt;向新部分添加了描述 Site-Local 不推荐使用的文本。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;更改以解决 IAB 回应 Robert Elz 上诉时提出的问题。变化包括以下内容：
&lt;ul&gt;
&lt;li&gt;在第 2.5 节中添加了说明，即节点不应假设 IPv6 地址的结构。&lt;/li&gt;
&lt;li&gt;更改了第 2.5.1 节和附录 A 中的文本，将“&lt;code&gt;u&lt;/code&gt;”位设置为一 (1) 的修改后的 EUI-64 格式接口标识符称为通用标识符。&lt;/li&gt;
&lt;li&gt;在第 2.5.1 节中添加了说明，即 IPv6 节点不需要验证以修改后的 EUI-64 格式创建的接口标识符（其中“&lt;code&gt;u&lt;/code&gt;”位设置为 1 ）是否唯一。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;将第 2.5.4 节“Global Unicast  Addresses”中指示的参考更改为 RFC 3587。&lt;/li&gt;
&lt;li&gt;删除了示例中提到的 NSAP 地址。&lt;/li&gt;
&lt;li&gt;澄清了文本表示中的“&lt;code&gt;x&lt;/code&gt;”可以是一到四位数。&lt;/li&gt;
&lt;li&gt;不推荐使用“IPv6 Compatible Address”，因为它没有在 IPv6 转换机制中使用。&lt;/li&gt;
&lt;li&gt;在关于多播地址的第 2.7 节中添加了“&lt;code&gt;R&lt;/code&gt;”和“&lt;code&gt;P&lt;/code&gt;”标志，以及指向定义它们的文档的指针。&lt;/li&gt;
&lt;li&gt;编辑上的改动。&lt;/li&gt;
&lt;/ul&gt;
">RFC4291: IP Version 6 Addressing Architecture</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://wenbozhangw.github.io/post/guidelines-for-use-of-extended-unique-identifiereui-organizationally-unique-identifieroui-and-company-idcid/"" data-c="
          &lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;本教程介绍由 IEEE 注册结构（IEEE RA, IEEE Registration Authority）分配的组织标识符（origanizational identifiers）以及基于它们的扩展标识符（extended identifiers）。它涵盖了与受让人以及标准开发人员相关的标识符格式（identifier formats）、assignment（分配）、指导方针（guidelines）和策略（policies）。本教程包括与组织标识符（如组织唯一标识符（Organizational Unique Identifier，OUI）和公司 ID（Company ID），以及扩展标识符（Extended Unique Identifier，EUI）和扩展本地标识符（Extended Local Identifier，ELI））相关的信息。&lt;/p&gt;
&lt;!-- more --&gt;
&lt;hr&gt;
&lt;h2 id=&#34;status-and-history&#34;&gt;Status and History&lt;/h2&gt;
&lt;p&gt;本教程替代以下三个 IEEE RA 教程文档：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Guidelines for Use Organizationally Unique Identifier (OUI) and Company ID (CID)&lt;/li&gt;
&lt;li&gt;Guidelines for 48-Bit Global Identifier (EUI-48)&lt;/li&gt;
&lt;li&gt;Guidelines for 64-Bit Global Identifier (EUI-64)&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;contents&#34;&gt;Contents&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#abstract&#34;&gt;Abstract&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#status-and-history&#34;&gt;Status and History&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#contents&#34;&gt;Contents&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ieee-administered-organizational-identifiers-oui-and-cid&#34;&gt;IEEE-Administered organizational identifiers: OUI and CID&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#oui&#34;&gt;OUI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#oui-36&#34;&gt;OUI-36&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#cid&#34;&gt;CID&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#extended-identifiers&#34;&gt;Extended Identifiers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#extended-unique-identifiers&#34;&gt;Extended Unique Identifiers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#extended-local-identifiereli&#34;&gt;Extended Local Identifier&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ieee-ra-assignment-of-identifiers&#34;&gt;IEEE RA assignment of identifiers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#eui-structure-and-representation&#34;&gt;EUI Structure and Representation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#eui-bit-ordering&#34;&gt;EUI Bit Ordering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#unassigned-and-null-eui-values&#34;&gt;Unassigned and NULL EUI values&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#appropriate-eui-use&#34;&gt;Appropriate EUI Use&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#maintaining-longevity-of-eui-48-and-eui-64&#34;&gt;Maintaining Longevity of EUI-48 and EUI-64&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#non-overlapping-assignments&#34;&gt;Non-Overlapping Assignments&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ieee-ra-policies-to-reduce-the-volume-of-unused-eui-48s&#34;&gt;IEEE RA Policies to Reduce the Volume of Unused EUI-48s&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#mapping-an-eui-48-to-an-eui-64&#34;&gt;Mapping an EUI-48 to an EUI-64&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#other-worldwide-identifiers-based-on-eui&#34;&gt;Other worldwide identifiers based on EUI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#context-dependent-identifiers&#34;&gt;Context dependent identifiers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#restrictions-on-the-use-of-context-dependent-identifiers&#34;&gt;Restrictions on the Use of Context Dependent Identifiers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#deprecated-and-obsolete-identifiers&#34;&gt;Deprecated and Obsolete Identifiers&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;ieee-administered-organizational-identifiers-oui-and-cid&#34;&gt;IEEE-Administered organizational identifiers: OUI and CID&lt;/h2&gt;
&lt;p&gt;IEEE 注册机构（IEEE Registration Authority，IEEE RA）向组织分配全局唯一标识符。两种类型的标识符：24 位组织唯一标识符（24-bit Organizationally Unique Identifier, OUI）和 24 位公司 ID （24-bit Company ID，CID）—— 是相互关联的，它们来自相同的 24 位空间，但落在不同的子空间，由成为 X 位的特定位来区分，如表 1 所示。X 位位置如图 1 所示。每个分配的 OUI 和 CID 相对于所有分配的 OUI 和 CID 是唯一的（IEEE 注册管理机构努力避免重复作业，全局唯一性还依赖于赋值的正确使用和没有可能导致重复的错误）。&lt;/p&gt;
&lt;center&gt;表 1 ：24 位 CID/OUI 空间划分为两个子空间&lt;/center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;X bit&lt;/th&gt;
&lt;th&gt;identifier&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;OUI&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;CID&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;OUI 或 CID 可用于识别公司、组织、实体、制造商、供应商等。&lt;/p&gt;
&lt;p&gt;IEEE 注册管理局还识别并分配 36 位的 OUI-36 作为组织的全球唯一标识符。被分配的 OUI-36 的前 24 位不重复任何 OUI 或 CID 分配。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;oui&#34;&gt;OUI&lt;/h2&gt;
&lt;p&gt;OUI 是一个 24 位（3 个 octet）序列。OUI 的结构如图 1 所示。Octet 0 是起始（most significant，最高有效位）octet。Octet 0 的最低有效位（least significant）和第二最低有效位分别为 M 位和 X 位。在 OUI 中，M 和 X 位的值都是 0。&lt;/p&gt;
&lt;p&gt;注意：大约有 18 个分配给早起以太网实施者的组织标识符（有些是在 IEEE std 802.3-1085 批准之前分配的 BlockID）的 X 位等于 1。BlockID，就像取代它的 OUI 一样，是一个 24 位的数字，作为 2&lt;sup&gt;24&lt;/sup&gt;  的 48 位 MAC 地址块的基数。BlockID 分配被记录在 MA-L（OUI）注册表中。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1650724485618.png&#34; alt=&#34;图 1：Structure of OUI&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;OUI 可以表示为 6 个十六进制数字。或者，它可以表示为由连字符分割的 octet；IEEE RA 将其称为十六进制（hex）表示。表 2 显示了 OUI 的一个例子，以 base-16 形式 &lt;code&gt;ACDE48&lt;/code&gt; 和 hex 形式 &lt;code&gt;AC-DE-48&lt;/code&gt;（这个例子中的八位字符串可以被使用，并且不是一个保留值）。表 2 的最后一行表示 24 位二进制 OUI 序列。&lt;/p&gt;
&lt;center&gt; 表 2：Example OUI &lt;/center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;octet identifier&lt;/th&gt;
&lt;th&gt;0&lt;/th&gt;
&lt;th&gt;1&lt;/th&gt;
&lt;th&gt;2&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;example value (hex)&lt;/td&gt;
&lt;td&gt;AC&lt;/td&gt;
&lt;td&gt;DE&lt;/td&gt;
&lt;td&gt;48&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;example value (binary)&lt;/td&gt;
&lt;td&gt;1010(MSB) 1100&lt;/td&gt;
&lt;td&gt;1101 1110&lt;/td&gt;
&lt;td&gt;0100 1000(LSB)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h2 id=&#34;oui-36&#34;&gt;OUI-36&lt;/h2&gt;
&lt;p&gt;OUI-36 是一个 36 位（four-and-one-half-octet）序列。Octet 0 是起始的（most significant，最高有效位）octet。Octet 0 的最低有效位（least significant）和第二最低有效位分别为 M 位和 X 位。在 OUI-36 中，M 和 X 位的值都是 0。&lt;/p&gt;
&lt;p&gt;当需要 36 位组织标识符或 36 位协议标识符（protocol identifier）时，可以使用 OUI-36 分配。例如，一些协议指定 36 位标识符来标识一个组织或该组织指定的对象。OUI 的受让人可以在 OUI 的末尾加上 12 位来创建 OUI-36。如果 OUI-36 的受让人需要唯一的 24 位组织标识符，建议使用 CID 分配。&lt;/p&gt;
&lt;p&gt;OUI-36 可以表示为 9 个十六进制数字。或者，也可以表示为由连字符分割的 octet，使用 IEEE RA 十六进制（hex）表示法。表 3 显示了一个 OUI-36 示例，它具有 base-16 形式 &lt;code&gt;ACDE48234&lt;/code&gt; 和 hex 形式 &lt;code&gt;AC-DE-48-23-4&lt;/code&gt;。表 3 的最后一行表示 36 位二进制 OUI-36 序列。&lt;/p&gt;
&lt;center&gt; 表 3：Example OUI-36 &lt;/center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;octet identifier&lt;/th&gt;
&lt;th&gt;0&lt;/th&gt;
&lt;th&gt;1&lt;/th&gt;
&lt;th&gt;2&lt;/th&gt;
&lt;th&gt;3&lt;/th&gt;
&lt;th&gt;4&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;example value (hex)&lt;/td&gt;
&lt;td&gt;AC&lt;/td&gt;
&lt;td&gt;DE&lt;/td&gt;
&lt;td&gt;48&lt;/td&gt;
&lt;td&gt;23&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;example value (binary)&lt;/td&gt;
&lt;td&gt;1010(MSB) 1100&lt;/td&gt;
&lt;td&gt;1101 1110&lt;/td&gt;
&lt;td&gt;0100 1000&lt;/td&gt;
&lt;td&gt;0010 0011&lt;/td&gt;
&lt;td&gt;0100（LSB）&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;一个 OUI-36 是由 IEEE RA 通过将 12 位连接到 24 位 IEEE 保留的基底 OUI 来创建的，并将这 12 位连接到 Octet 2 的最低有效位之后，如图 1 所示。基底 OUI 不会被分配给另一个组织，也不会被用作 OUI。OUI-36 的受让人不得将 OUI-36 截断用作 OUI，因为 IEEE RA 将使用基底 OUI 将 OUI-36 值分配给多个组织。&lt;/p&gt;
&lt;p&gt;对于基底 OUI 不应做任何假设。例如，不应该假定对单个组织的多个 OUI-36 任务将共一个公共基底 OUI。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;cid&#34;&gt;CID&lt;/h2&gt;
&lt;p&gt;CID 是一个 24 位（three-octet）的序列。CID 的结构如下面的图 2 所示。Octet 0 是起始的（most significant，最高有效位）octet。Octet 0 的 4 个最低有效位分别为 M bit、X bit、Y bit、Z bit，从最低有效位开始。在 CID 中，M、X、Y 和 Z 位分别为 0、1、0 和 1。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1650727795660.png&#34; alt=&#34;图 2：Structure of CID&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;CID 可以表示为 6 个十六进制数字。或者，也可以表示为由连字符分割的 octet，使用 IEEE RA 十六进制（hex）表示法。表 4 显示了一个 base-16 表示的 &lt;code&gt;AADE48&lt;/code&gt; 和 hex 表示的 &lt;code&gt;AA-DE-48&lt;/code&gt; 的示例。表 4 的最后一行表示 24 位二进制 CID 序列。&lt;/p&gt;
&lt;center&gt; 表 4：Example CID &lt;/center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;octet identifier&lt;/th&gt;
&lt;th&gt;0&lt;/th&gt;
&lt;th&gt;1&lt;/th&gt;
&lt;th&gt;2&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;example value (hex)&lt;/td&gt;
&lt;td&gt;AA&lt;/td&gt;
&lt;td&gt;DE&lt;/td&gt;
&lt;td&gt;48&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;example value (binary)&lt;/td&gt;
&lt;td&gt;1010(MSB) 1010&lt;/td&gt;
&lt;td&gt;1101 1110&lt;/td&gt;
&lt;td&gt;0100 1000(LSB)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h2 id=&#34;extended-identifiers&#34;&gt;Extended Identifiers&lt;/h2&gt;
&lt;p&gt;除了最为全局唯一的组织标识符，OUI、OUI-36 或 CID 还可以通过连接额外的区分位（differentiating bits），作为扩展标识符（extended identifiers）的基础，包括协议标识符（protocol identifiers）和上下文相关的标识符（context dependent identifiers）。这些扩展标识符可能是全局唯一的（例如，EUI-48 和 EUI-64），或者仅在使用它们的上下文中唯一。详情见下文。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;extended-unique-identifiers&#34;&gt;Extended Unique Identifiers&lt;/h3&gt;
&lt;p&gt;一个扩展唯一标识符（Extended Unique Identifier，EUI）是 48 位扩展唯一标识符（48-bit Extended Unique Identifier，EUI-48）或 64 位位扩展唯一标识符（64-bit Extended Unique Identifier，EUI-64）。除了一些例外情况，特别是在协议标识符方面，每个 EUI 都是全局唯一的，并绑定到需要唯一标识的硬件设备实例或其他对象。EUI-48 和 EUI-64 标识符最常用来作为全局唯一的网络地址（有时成为 MAC 地址），这在各种标准中都有规定。例如，根据 IEEE Std 802，EUI-48 通常被用作硬件接口的地址，历史上使用的名称是 &lt;code&gt;MAC-48&lt;/code&gt;。另一个例子是，根据 IEEE 标准 1588，EUI-64 可以作为时钟的标识符。IEEE Std 802 还指定 EUI-64 使用 64 位全球唯一的网络地址。关于 EUI-48 和 EUI-64 的进一步细节如下。&lt;/p&gt;
&lt;p&gt;当 EUI 被用作 MAC 地址（例如，IEEE 802 网络地址），初始 octet（Octet 0）中最低有效的两位被用于特殊用途。Octet 0 的最低有效位（I/G 位，I/G 表示 Individual/Group）表示单个地址（I/G = 0，Individual address）或组地址（I/G = 1，Group address），Octet 0 的第二最低有效位（U/L 位，U/L 表示 Universal/Local）表示通用地址（U/L = 0，Universal address）或本地地址（U/L = 1，Local address）的管理。普遍管理地址（universally administered address）是全局唯一的地址（globally unique address）。&lt;/p&gt;
&lt;p&gt;在扩展 OUI 创建的 EUI 中，OUI 是起始的（最高有效）三个字节。在扩展 OUI-36 创建的 EUI 中，OUI-36 是起始的（最高有效）四个半字节。&lt;/p&gt;
&lt;p&gt;由于由 IEEE RA 分配的 OUI 和 OUI-36 的 X 位等于 0，因此从分配的 OUI 或 OUI-36 创建的扩展标识符 EUI 具有 &lt;code&gt;U/L = 0&lt;/code&gt;，当用作 MAC 地址时，因此是一个普遍管理地址。&lt;/p&gt;
&lt;p&gt;由于所有由 IEEE RA 分配的 OUI 和 OUI-36 的 M 位 都等于 0，因此从被分配的 OUI 或 OUI-36 创建的扩展标识符 EUI 的 &lt;code&gt;I/G = 0&lt;/code&gt;，当用做 MAC 地址时，因此是一个单独的地址。&lt;/p&gt;
&lt;p&gt;OUI 或 OUI-36 的受让人被授权分配组 MAC 地址，通过将 OUI 或 OUI-36 的修改版本扩展其 M 位为 1 ，使 &lt;code&gt;I/G = 1&lt;/code&gt;。这些地址不是 EUI，并且不能全局识别硬件实例，即使 &lt;code&gt;U/L = 0&lt;/code&gt;。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;extended-local-identifiereli&#34;&gt;Extended Local Identifier（ELI）&lt;/h2&gt;
&lt;p&gt;一个扩展本地标识符（ELI）是有一个 CID 拼接而成的，CID 由起始的三个（最低有效）字节组成。ELI-48 是 48 为 ELI，ELI-64 是 64 位 ELI。&lt;/p&gt;
&lt;p&gt;由于由 IEEE RA 进行的 CID 分配的 X 位等于 1，因此从已分配的 CID 创建的 ELI 作为扩展标识符具有 &lt;code&gt;U/L = 1&lt;/code&gt;，因此当用作 MAC 地址时，它是一个本地地址。本地地址不是全局唯一的，网络管理员负责确保分配的任何本地地址在使用范围内是唯一的。（本地地址的唯一性通常不需要扩展到路由器之外。）IEEE Std 802（从修订 IEEE Std 802c-2017 开始）指定了结构化本地地址计划（Structured Local Address Plan，SLAP），它基于 CID 的 Y 位和 Z 位的指定值，描述了本地 MAC 地址空间的一个象限中 ELIs 的使用。在本地 MAC 地址空间的其他象限（quadrants），SLAP 用于描述不基于 CID 的标准分配标识符（Standard Assigned Identifiers，SAIs）和管理分配标识符（Administratively Assigned Identifiers, AAIs）的使用。&lt;/p&gt;
&lt;p&gt;由于所有由 IEEE RA 进行的 CID 分配的 M 位都等于 0，因此从已分配的 CID 创建的 ELI 作为扩展标识符的 &lt;code&gt;I/G = 0&lt;/code&gt;，因此当用作 MAC 地址时，它是一个单独的地址。CID 的受让人可以通过将已分配 CID 的修改版本扩展为 M 为 1（使 &lt;code&gt;I/G = 1&lt;/code&gt;）来分配本地组 MAC 地址。得到的扩展标识符是  ELI。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;ieee-ra-assignment-of-identifiers&#34;&gt;IEEE RA assignment of identifiers&lt;/h3&gt;
&lt;p&gt;一个被分配的 EUI 块可以被看做是通过扩展标识符连接从基数（例如，OUI）扩展而来的数组序列。它也可以被描述为 EUI-48 或 EUI-64 的连续范围。&lt;/p&gt;
&lt;p&gt;EUI 块由 IEEE RA 分配为三种不同的大小。MA-L 分配块（assignment block）提供 2&lt;sup&gt;24&lt;/sup&gt; 的 EUI-48 标识符和 2&lt;sup&gt;40&lt;/sup&gt; 的 EUI-64 标识符。MA-M 分配块提供 2&lt;sup&gt;20&lt;/sup&gt; 的 EUI-48 标识符和 2&lt;sup&gt;36&lt;/sup&gt; 的 EUI-64 标识符。MA-S 分配块提供 2&lt;sup&gt;12&lt;/sup&gt; 的 EUI-48 标识符和 2&lt;sup&gt;28&lt;/sup&gt; 的 EUI-64 标识符。&lt;/p&gt;
&lt;p&gt;MA-L 的分配包括 OUI 的分配，OUI 是已分配的 EUI-48 和 EUI-64 扩展标识符块的基础。MA-L 相当于 2014 年 1 月 1 日之前进行的 OUI 赋值，也包括 OUI 以及 EUI-48 和 EUI-64 标识符相关 块的分配。&lt;/p&gt;
&lt;p&gt;MA-S 分配包括 OUI-36 的分配，OUI-36 是已分配的 EUI-48 和 EUI-64 扩展标识符块的基础。MA-S 不包括 24 位 OUI 的分配。分配的 MA-S 的 24 位初始位是一个分配给 IEEE RA 的 OUI。&lt;/p&gt;
&lt;p&gt;说明 —— MA-S 分配于 2014 年 1 月 1日可用。MA-S 分配取代了 2014 年 1 月 1 日之前 IEEE RA 提供的个人地址块（Individual Address Block，IAB）和 OUI-36 分配。IAB 只提供了一个包含 4096 个 EUI-48 标识符的块，并没有提供任何其他标识符，例如 EUI-64 标识符；请参阅本教程后面的 &lt;a href=&#34;#iab-based-identifiers&#34;&gt;IAB Based Identifiers&lt;/a&gt; 小节。&lt;/p&gt;
&lt;p&gt;MA-M 不包括 OUI 的分配。MA-M 的受让人可以在 MA-M 分配块中创建一个 OUI-36 作为地址的前 36 位。如果 MA-M 的受让人需要唯一的 24 位组织标识符，建议使用 CID 分配。被分配的 MA-M 块的前 24 位是一个分配给 IEEE 的 OUI，不会被重新分配。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;注意&lt;/em&gt; —— MA-M 分配于 2014 年 1 月 1 日生效，以响应客户对中间标识块（intermediate block of identifiers）的请求。&lt;/p&gt;
&lt;p&gt;CID 分配是一个唯一的 24 位标识符，可用于标识公司、组织等。CID 分配不包括任何 EUI-48 或 EUI-64 分配，且一个 CID 不得用于创建 EUI-48 或 EUI-64。对于寻找唯一 24 位标识符的实体，CID 可以作为 MA-M 或 MA-S 分配的补充，因为这些分配不包括 OUI。&lt;/p&gt;
&lt;p&gt;表 5 总结了来自 IEEE RA 的 OUI、OUI-36、CID、EUI-48 和 EUI-64 分配。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;IEEE RA 公开列表：
&amp;lt;https://regauth.standards.ieee.org/standards-ra-web/pub/view.html#registries&amp;gt; 
为 MA-L、MA-M 和 MA-S 提供了单独的数据库。如果前 24 位匹配 IEEE RA 已分配的 OUI，那
么搜索前 28 位或 36 位可能会发现分配了 MA-M 或 MA-S。如果在 MA-S 中没有找到 
OUI-36，那么对前 24 或 28 位的搜索可能会发现一个 MA-L 或 MA-M 分配，该分配块中的一
个成员可能已经创建了 OUI-36 。
&lt;/code&gt;&lt;/pre&gt;
&lt;center&gt;表 5：EUI, OUI, and CID assignment summary&lt;/center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;IEEE RA Assignment&lt;/th&gt;
&lt;th&gt;Number of IEEE assigned bits&lt;/th&gt;
&lt;th&gt;Block size of globally unqiue EUI-48 identifiers&lt;/th&gt;
&lt;th&gt;Block size of globally unqiue EUI-64 identifiers&lt;/th&gt;
&lt;th&gt;company or organization identifier included&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;MA-L（MAC Adresses - Large）&lt;/td&gt;
&lt;td&gt;24&lt;/td&gt;
&lt;td&gt;2&lt;sup&gt;24&lt;/sup&gt; （16,777,216）&lt;/td&gt;
&lt;td&gt;2&lt;sup&gt;40&lt;/sup&gt; （1,099,511,627,776）&lt;/td&gt;
&lt;td&gt;OUI（24-bit）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MA-M（MAC Adresses - Medium）&lt;/td&gt;
&lt;td&gt;28&lt;/td&gt;
&lt;td&gt;2&lt;sup&gt;20&lt;/sup&gt; （1,048,576）&lt;/td&gt;
&lt;td&gt;2&lt;sup&gt;36&lt;/sup&gt; （68,719,476,736）&lt;/td&gt;
&lt;td&gt;none&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MA-S（MAC Adresses - Small）&lt;/td&gt;
&lt;td&gt;36&lt;/td&gt;
&lt;td&gt;2&lt;sup&gt;12&lt;/sup&gt; （4096）&lt;/td&gt;
&lt;td&gt;2&lt;sup&gt;28&lt;/sup&gt; （268,435,456）&lt;/td&gt;
&lt;td&gt;OUI-36（36-bit）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CID（Company ID）&lt;/td&gt;
&lt;td&gt;24&lt;/td&gt;
&lt;td&gt;0 （zero）&lt;/td&gt;
&lt;td&gt;0 （zero）&lt;/td&gt;
&lt;td&gt;CID（24-bit）&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;IEEE 标识符的受让人负责在其指定的块内管理扩展标识符。IEEE RA 不能控制扩展标识符的分配，并且对于使用 IEEE 分配的标识符（例如，重复的上下文相关标识符、EUI-48 或 EUI-64 值）的组织分配重复的扩展标识符不承担任何责任。&lt;/p&gt;
&lt;p&gt;表 5 中 IEEE 管理的标识符的分配通常是公开的，可从 IEEE RA 获得，因此感兴趣的用户可以标识 EUI-48、EUI-64、OUI、OUI-36 或 CID 的注册所有者。然而，对于选择使用私有上市选项的受让人，IEEE 分配是公开的，但不公开受让人的身份。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;eui-structure-and-representation&#34;&gt;EUI Structure and Representation&lt;/h2&gt;
&lt;p&gt;表 6 说明了 EUI-48 的结构及其与 IEEE RA 的分配的关系。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1650783393894.png&#34; alt=&#34;表 6&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;一个 EUI-48 是一个由六个 octets 组成的字符串，在表 6 中从 Octet 0（起始的和最高有效的）标记到 Octet 5（最后的和最低有效的）。表 6 的最后两行包括一个 EUI-48 的例子，以 base-16 表示 &lt;code&gt;ACDE48234567&lt;/code&gt; 和 hex 表示 &lt;code&gt;AC-DE-48-23-45-67&lt;/code&gt;。注意：EUI-48 可以用 IEEE RA 十六进制（hex）表示（octet 用连字符隔开），也可以用纯 16 进制数字表示。&lt;/p&gt;
&lt;p&gt;表 6 举例说明了 EUI-48 是如何产生的：OUI &lt;code&gt;AC-DE-48&lt;/code&gt; 的 MA-L 分配，扩展标识符为 &lt;code&gt;23-45-67&lt;/code&gt; 的实体分配；以 &lt;code&gt;AC-DE-48-2&lt;/code&gt; 为基址的 MA-M 分配，以及扩展标识符为 &lt;code&gt;3-45-67&lt;/code&gt; 的实体分配；以一个带有 OUI-36 &lt;code&gt;AC-DE-48-23-4&lt;/code&gt; 的 MA-S 分配，以及一个扩展标识符为 &lt;code&gt;5-67&lt;/code&gt; 的实体分配。&lt;/p&gt;
&lt;p&gt;EUI-64 以类似的方式表示，它是一个由 8 个 octet 组成的字符串，从 Octet 0（起始位和最高有效位）到 Octet 7（最后位和最低有效位）。表 7 显示了这一点，使用 base-16 表示 &lt;code&gt;ACDE48234567019F&lt;/code&gt; 和 hex 表示 &lt;code&gt;AC-DE-48-23-45-67-01-9F&lt;/code&gt; 为例的 EUI-64。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1650787323392.png&#34; alt=&#34;表 7: Structure if EUI-64&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;hr&gt;
&lt;h2 id=&#34;eui-bit-ordering&#34;&gt;EUI Bit Ordering&lt;/h2&gt;
&lt;p&gt;虽然 EUI octet 的顺序和 octet 中的位是特定的和固定的，但是它们的传输顺序可以根据协议变化。通常，基于 octet 的传输以 octet 标识符升序的方式传输，从 Octet 0 开始。一些分组代码对多个 octet 进行编码。数据的位串行编码可能在 octet 内的位传输顺序上有所不同。同样，地址在内存中的存储顺序也会因协议的不同而不同。有关比特传输顺序的进一步信息可在相关标准中找到，如 IEEE Std 802。&lt;/p&gt;
&lt;p&gt;考虑到位顺序和字节定位可能存在混淆，应用程序和协议必须明确地指定标识符值（表示为十六进制数字）到使用的寄存器或字节和位序列的映射。为了确保清晰，每个映射都应该是自包含的（self-contained）。如果认为有必要对其他文件进行交叉引用，则应将具体的文件和页码进行交叉引用，使不熟悉的读者能够容易地找到来源。&lt;/p&gt;
&lt;p&gt;为了避免现有标准的变化，工作组可能会提供关于在其标准中使用标识符的教程，并将其发布在 IEEE RA 网站上。&lt;/p&gt;
&lt;p&gt;如果某个标准，或其在其他标准中的交叉引用部分，不符合这些文档策略，IEEE 注册管理委员会（IEEE Registration Authority Committee，RAC）可以建议不批准该标准。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;unassigned-and-null-eui-values&#34;&gt;Unassigned and NULL EUI values&lt;/h2&gt;
&lt;p&gt;许多应用程序发现定义一个独特的空标识符（null identifier）很有用，通常表示没有有效的 EUI-48  或 EUI-64 值。例如，空值可能是集成电路寄存器的上电状态，直到硬件或固件用有效的 EUI 初始化寄存器。类似的，当另一个设备或对象的 EUI 被放置在一个协议字段时，可能会使用一个空值，直到学习将有效的 EUI 值放置在协议字段的中为止 。如果方便地使用空值，管理信息库参数也可能面临类似的初始值问题。&lt;/p&gt;
&lt;p&gt;全零的 EUI-48 值（&lt;code&gt;00-00-00-00-00-00&lt;/code&gt;） 和 EUI-64 （&lt;code&gt;00-00-00-00-00-00-00-00&lt;/code&gt;），虽然被分配给一个组织，但尚未也不会被受让人用作 EUI。（它们可以被认为是分配给 IEEE 注册管理局的）全 1 的 48 位值（&lt;code&gt;FF-FF-FF-FF-FF-FF&lt;/code&gt;）和 64 位值（&lt;code&gt;FF-FF-FF-FF-FF-FF-FF-FF&lt;/code&gt;）是指示网络上所有站点的 IEEE 多播（group）MAC 地址。这些全 1 值不是有效的 EUI。&lt;/p&gt;
&lt;p&gt;推荐的空值分别为 &lt;code&gt;FF-FF-FF-FF-FF-FF&lt;/code&gt; 和 &lt;code&gt;FF-FF-FF-FF-FF-FF-FF-FF&lt;/code&gt;，作为未知的 EUI-48 和 EUI-64 的默认值。基于零值的 OUI 的值，例如 &lt;code&gt;00-00-00-00-00-00&lt;/code&gt; 和 &lt;code&gt;00-00-00-00-00-00-00-00&lt;/code&gt;，不能用作标识符。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;appropriate-eui-use&#34;&gt;Appropriate EUI Use&lt;/h2&gt;
&lt;p&gt;EUI 用于需要固定大小的全局唯一标识符的应用程序。&lt;/p&gt;
&lt;p&gt;除某些情况外，如协议标识符，受让人将 EUI-48 或 EUI-64 与单个可识别对象（如网络接口）相关联。根据设备支持的功能，它可以使用多个标识符。例如，智能手机可以使用 EUI-48 作为 802.11/ Wi-Fi ® MAC 地址和蓝牙®接口的第二标识符。以太网连接的设备可以有一个 EUI-48 MAC 地址和一个 EUI-64 唯一标识 802.1 AS clock（即，&amp;quot;clockIdentity&amp;quot;）。&lt;/p&gt;
&lt;p&gt;使用 EUI-64 而不是 EUI-48，以避免在大容量（特别是非联网）应用程序中过度消耗 OUI 值。考虑到使用所有 EUI-64 标识符的可能性极小，IEEE RA 对它们在标准内的使用施加了最小的限制。除非有向后兼容的限制，否则使用 EUI-64 比使用 EUI-48 更可取。但是，为了向后兼容，这种转换对于一些与 IEEE 802 相关的应用程序（例如，需要桥接到 48 位 IEEE 802 网络的新网络）可能是困难的。因此，IEEE 注册委员会将考虑在 802 相关系统中选择性地使用 48 位标识符。详细见下文 &lt;a href=&#34;#maintaining-longevity-of-eui-48-and-eui-64&#34;&gt;Maintaining Longevity of EUI-48 and EUI-64&lt;/a&gt; 。&lt;/p&gt;
&lt;p&gt;EUI-48 和 EUI-64 是由 IEEE 注册的。组织被允许为商业目的有限地使用这些术语。如果这种使用是在标准中指定的特性或功能的标识，或者是声称符合 IEEE 标准，那么没有 IEEE 明确批准的使用是可以接受的，但是术语的其他使用必须由 IEEE RAC 审查和批准。&lt;/p&gt;
&lt;p&gt;当 EUI 在 IEEE 标准或标准草案中使用时，草案的正确性和清晰度应由 IEEE RAC 进行审查。当 EUI 在非 IEEE 标准中被引用时，标准开发人员应该联系 IEEE RAC 以检查正确的用法。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;maintaining-longevity-of-eui-48-and-eui-64&#34;&gt;Maintaining Longevity of EUI-48 and EUI-64&lt;/h2&gt;
&lt;p&gt;可用的 EUI-48 标识符的总数虽然很大，但并不是无穷无尽的。IEEE RAC 有责任与 IEEE 标准和非 IEEE 标准一起促进 EUI-48 能力的持续可用性，以使使用这些标准的全球社区受益。&lt;/p&gt;
&lt;p&gt;最初，EUI-48 表示仅用于识别实际物理设备的项目（identify item of real physical equipment）、设备的部分（parts of such equipment）或适用于许多实例的物理设备的功能（functions that apply to many instance of physical equipment）。&lt;/p&gt;
&lt;p&gt;48 位标识符的使用后来得到了扩展，以便它们可以用作协议标识符。通过这种使用，它们确定了物理设备实例之间操作的协议设计和设计修订。与物理设备的项目数量相比，这种协议所需的标识符要少得多。&lt;/p&gt;
&lt;p&gt;除此类协议标识符外，EUI-48 标识符仍用于标识实际物理设备的项目或此类设备的部分，如可分离子系统或单独寻址的网络端口。每个硬件子系统的预期使用不应超过一个 EUI-48 标识符，或者此类设备的每个物理实例最多不超过非常低数量的 EUI-48 标识符（例如，用于链路聚合的 IEEE Std 802.1 AX 中的端口组）。分配单个 EUI-48 标识符，以识别或允许寻址与物理设备的真实项目相关联的固定和永久功能，这在该设备的整个寿命期间或无限期使用期间发生。&lt;/p&gt;
&lt;p&gt;任何标准规范，或 EUI 区块的受让人实现或受让人管理，要求对可用的数字空间进行细分，将区块分配给产品类型，或将区块分配给物理设备，而每个 EUI-48 标识符没有可识别的物理实例，或对于编码功能中的重要位或位模式的标识符，有可能迅速耗尽地址空间。为了减耗尽的可能性，强烈鼓励新应用程序和对当前应用程序的延伸，以利用 EUI-64 而不是 EUI-48 来识别硬件实例。IEEE 将审查标准中规定的要求地址格式与现有 EUI-48 设备相匹配的新应用程序，此类例外情况将根据具体情况进行审批。不支持 EUI-48 的非标准使用。&lt;/p&gt;
&lt;p&gt;IEEE RAC 征求任何关于威胁到唯一的 EUI-48/EUI-64 地址空间的信息，无论是 IEEE 提议的标准还是另一个标准或规范。信息应该发送到 IEEE RAC（ieee-registration-authority@ieee.org）。此外，为了履行保持这些标识符功能寿命的职责，IEEE RAC 将通过联络或直接协调采取行动，以防止潜在的误用 EUI-48。&lt;/p&gt;
&lt;p&gt;当 IEEE 802 在 1980 年开始工作时，EUI-48 标识符的目标寿命是 100 年。在这个世纪中，超过三分之一的时间里，EUI-48 标识符的使用继续增长，没有迹象表明 EUI-48 地址将在 2080 年过时。因此，IEEE RAC 认为这些限制的一致实施是确保 EUI-48 标识符寿命和基本的现实基础。&lt;/p&gt;
&lt;p&gt;如果一个实体（无论是否是 IEEE RA 客户），有意或无意地滥用了 IEEE RA 分配，使得 EUI-48/EUI-64 地址或该实体从其 RA 分配中创建的任何其他标识符被分配到其分配之外，则该实体违反了 IEEE RAC 政策。在这种情况下，IEEE RAC 可以建议 IEEE RA 向该实体收取额外费用，以弥补任何潜在的重复和/或组织未来的滥用。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;non-overlapping-assignments&#34;&gt;Non-Overlapping Assignments&lt;/h2&gt;
&lt;p&gt;无论应用程序如何，都鼓励受让人只分配一种形式的 EUI-48 或 EUI-64 标识符。换句话说，鼓励组织不要将相同的标识符分配给多个组织的不同最终应用使用。该建议的目的是减少由管理每个组织中多个与上下文相关地址空间的复杂性而可能引入的错误。&lt;/p&gt;
&lt;p&gt;例如，指定 I/O 驱动程序软件接口、语言代码和硬件型号的 EUI-48 值不应该重叠。同样的，指定 I/O 驱动程序软件接口、语言代码、硬件型号和硬件实例的 EUI-64 值永远不会重叠。虽然可能消耗更多的标识符值，但是通过消除主观的应用程序类判断，这种不重叠策略有望减少标识符值的无意重复。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;ieee-ra-policies-to-reduce-the-volume-of-unused-eui-48s&#34;&gt;IEEE RA Policies to Reduce the Volume of Unused EUI-48s&lt;/h2&gt;
&lt;p&gt;MA-L 分配包括超过 1600 万个（2&lt;sup&gt;24&lt;/sup&gt;） EUI-48 值。为了减少未使用 EUI-48 的发生（例如，当受让人需要远远少于 1600 万 EUI-48 时），IEEE RAC 在第一次引入 CID 时制定了以下分配 MA-L、MA-M、MA-S 和 CID 标识符的策略：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;首次客户（即受让人）不能购买 MA-L。第一次需要 24 位公司/组织标识符的客户可以购买 CID，而第一次需要 EUI-48  或 EUI-64（或废弃标识符）的客户可以购买 MA-M 或 MA-S，具体取决于客户需要多少特定标识符。这个策略的例外必须由 IEEE RAC 审查。&lt;/li&gt;
&lt;li&gt;回头客（即以前购买过 MA-L、MA-M、MA-S 和/或 CID 的客户）可以购买任意标识符块大小，受以下限制：
&lt;ol&gt;
&lt;li&gt;如果当前 EUI-48 的 MA-L 或 MA-M 分配的 95% 被使用，IEEE 注册机构将接受额外的分配申请。这同样适用于 2014 年 1 月之前发布的 OUI 转让。当现有 EUI-48 大部分已用完时，可能会发出额外的转让。客户必须同意，在之前的 EUI-48 配额用完之前，不得使用新的配额生产产品。这适用于所有注册表分配。&lt;/li&gt;
&lt;li&gt;一个客户有一个 MA-L （2014 年 1 月 1 日或之前，是的）或 CID 分配，不应该需要购买新的公司标识，但有资格购买新 CID 用作其他用途，例如，当电流 CID 作业提供了 ELI 地址空间不足。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;由 IEEE 管理的组织标识符标识管理级联的扩展标识符以创建例如 EUI 的组织。不应孤立地使用 IEEE 管理的标识符来表示公司或组织的一个部门或类似部分。当受让人认为有必要识别这样的内部组时，可以使用 EUI-48 或 EUI-64 标识符。（使用一些扩展位标识部门或产品的受让人，管理实践并不能免除受让人使用上述大多数 EUI-48 值的要求。）类似的，标准开发组织中的组也可以由其发起组织管理的不同 EUI-48 （或 EUI-64）标识符标识。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;mapping-an-eui-48-to-an-eui-64&#34;&gt;Mapping an EUI-48 to an EUI-64&lt;/h2&gt;
&lt;p&gt;不支持将 EUI-48 映射到 EUI-64。这里描述映射是出于历史原因。&lt;/p&gt;
&lt;p&gt;将一个分配了 MA-S/OUI-36 或 MA-M 的 EUI-48 映射到一个 EUI-64 可能会创建一个分配了不同 MA-S/OUI-36 或 MA-M 的 EUI-64 的副本。IEEE RA 已经采取了适当的措施来减少基于此映射的副本创建，但是，为了保护 EUI-64 标识符的完整性，不建议使用此映射。&lt;/p&gt;
&lt;p&gt;一些标准已经描述了如何将一个 EUI-48 的值映射到 EUI-64，具体如下：设 EUI-48 的六个 octet 被标记位 eui48[0] 到 eui48[5]。设映射的 EUI-64 的八个 octet 被标记为 eui64[0] 到 eui64[7]。对应关系描述如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;eui64[0] = eui48[0]&lt;/li&gt;
&lt;li&gt;eui64[1] = eui48[1]&lt;/li&gt;
&lt;li&gt;eui64[2] = eui48[2]&lt;/li&gt;
&lt;li&gt;eui64[3] = FFhex&lt;/li&gt;
&lt;li&gt;eui64[4] = FEhex or eui64[4] = FFhex&lt;/li&gt;
&lt;li&gt;eui64[5] = eui48[3]&lt;/li&gt;
&lt;li&gt;eui64[6] = eui48[4]&lt;/li&gt;
&lt;li&gt;eui64[7] = eui48[5]&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;换句话说，eui48[2] 和 eui48[3] 之间插入 &lt;code&gt;FF-FE&lt;/code&gt;hex 值或 &lt;code&gt;FF-FF&lt;/code&gt;hex 值生成 EUI-64 值。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;other-worldwide-identifiers-based-on-eui&#34;&gt;Other worldwide identifiers based on EUI&lt;/h2&gt;
&lt;p&gt;WWN（World Wide Names）有部分格式来源于 EUI-48 或 EUI-64。WWN 在 SCSI 和相关协议中用作磁盘和端点地址。请参阅最新的 INCITS SATA 和 SAS 标准以了解更多细节。&lt;/p&gt;
&lt;p&gt;来自 EUI-64 的 IPv6 地址定义在 IETF RFC 4291，附录a。请参见 IETF RFC 2460、5952 和 6052。&lt;/p&gt;
&lt;p&gt;UUID 寻址由 EUI-64 地址和 OUI 派生，在 ITU-T X.667 的 IETF RFC 4122 中定义。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;context-dependent-identifiers&#34;&gt;Context dependent identifiers&lt;/h2&gt;
&lt;p&gt;就像 OUI 可以扩展为创建 EUI-48 和 EUI-64 标识符，或者 CID 可以扩展为创建本地管理的 MAC 地址一样，其他扩展标识符也可以从 OUI 或 CID 分配中创建。这样的扩展标识符，称为上下文依赖标识符（Context Dependent Identifier，CDI），不一定是全局唯一的，但只在指定上下文中是唯一的。&lt;/p&gt;
&lt;p&gt;上下文依赖标识符（Context Dependent Identifier，CDI）是基于 OUI、CID 或 OUI-36 的扩展标识符，通常在带有附加规范的标准中指定，以允许对标识符的明确解释和对其他数据的解析。一些例子包括（但不限于）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在一个标准中定义上下文依赖标识符的所有字段。例如，使用 OUI 或 CID 来标识硬件制造商，以及表示硬件型号和版本的附加字段。（OUI 或 CID 所有者通常在标准指定的范围内为附加字段分配值。）如果正确定义，这样的标识符在标准上下文中是唯一的。&lt;/li&gt;
&lt;li&gt;在标准中定义特定于供应商的管理信息扩展，但允许唯一标识符的受让人指定附加字段。这个扩展标识符在定义的管理信息库上下文中是唯一的。&lt;/li&gt;
&lt;li&gt;特定于供应商的协议可以通过 OUI/CID 进行识别，标准定义的固定字段允许识别来自同一供应商的多个协议；或使用 OUI/CID 指示用来解析 OUI/CID 之后的数据的规则集。&lt;/li&gt;
&lt;li&gt;CDI-32 和 CDI-40 的遗留定义（参见 &lt;a href=&#34;#deprecated-and-obsolete-identifiers&#34;&gt;Deprecated and Obsolete Identifiers&lt;/a&gt; ）。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;restrictions-on-the-use-of-context-dependent-identifiers&#34;&gt;Restrictions on the Use of Context Dependent Identifiers&lt;/h2&gt;
&lt;p&gt;除非与 22 位公司标识的遗留定义兼容，否则在创建上下文依赖标识符时，OUI 被用作 24 位字段。在这种情况下，CID 应作为 OUI 的有效替代品。上下文相关标识符的规范应该允许使用 OUI 或 CID 作为上下文相关标识符的基础。&lt;/p&gt;
&lt;p&gt;对于那些指定上下文依赖标识符的人，需要注意以下事项：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果准确地定义要求扩展标识符的分配必须在上下文是唯一的，那么就存在处于不同目的无意中重新使用现有标识符分配的危险，导致分配值使用的模糊性；&lt;/li&gt;
&lt;li&gt;如果选择的扩展标识符的大小相对于在单个 OUI/CID 下需要分配的标识符值的实际数量较小，那么结果可能是 OUI/CID 值的消耗率不可接受。并且 OUI 的所有者可能难以满足注册机构的要求，也就是说在使用进一步的分配之前，他们现有的 OUI 所代表的块分配的 95% 需要被消耗掉；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此，上下文相关的标识符的使用是可以接受的，但必须满足以下所有要求：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;相关标准中明确定义了上下文相关标识符使用的上下文，以及要求标识符值在上下文中唯一。&lt;/li&gt;
&lt;li&gt;所选扩展标识符的大小足以容纳在定义的上下文中单个 OUI 下分配不同值的所有可能的需求。&lt;/li&gt;
&lt;li&gt;IEEE RAC 已经批准了标识符和将使用它的上下文的定义。&lt;/li&gt;
&lt;li&gt;描述提议的上下文相关标识符机器提议应用的标准草案或工作组材料应提交给 IEEE RAC。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;deprecated-and-obsolete-identifiers&#34;&gt;Deprecated and Obsolete Identifiers&lt;/h2&gt;
&lt;p&gt;对于“已弃用（deprecated）”这个词，IEEE 并没有一个标准的定义。当被 IEEE RA 或 IEEE RAC 使用时，术语 &lt;code&gt;deprecated&lt;/code&gt; 意味着它所描述的项目（例如，标识符(identifier)、映射(mapping)、需求(requirement)、推荐(recommendation)、过程(process) 等）不应用与任何新的应用程序。如果合理，遗留使用可以保存在 revision 或 amendment 中（例如，修订不会将不一致性引入标准中。）当术语发生变化时，应该尽快更新使用当前术语并删除已弃用的术语。此外，除符合相关标准外，新设备和新设计不得使用废弃项目，除非符合相关标准。不需要修改现有设备和部署的设备来不使用不赞成使用的项目。&lt;/p&gt;
&lt;p&gt;过去使用的一些标识符和术语，包括一些由 IEEE 管理的标识符创建的标识符(即，由分配了 IEEE 管理标识符的组织创建的标识符)，现在已被弃用或废弃。这些标识符和术语包括独立地址块（IAB）、基于 OUI 的 22 位标识符、MAC-48 标识符和 EUI-60。这些标识符将在下面的小节中进行简要描述。&lt;/p&gt;
&lt;h3 id=&#34;iab-based-identifiers&#34;&gt;IAB Based Identifiers&lt;/h3&gt;
&lt;p&gt;不再分配 36 位的 IAB 标识符。IAB 分配的是 4096 个 MAC-48 地址块（现在称为 EUI-48）。基本的 24 位 OUI 被分配给 IEEE RA，IEEE RA 分配的附加 12 位扩展产生地址块的前 36 位。然后，4096 个 EUI-48 标识符随后由受让人通过另外一个 12 位与 36 位 IAB 基数连接而创建。&lt;/p&gt;
&lt;p&gt;IAB 只能用于指定 EUI-48 标识符；使用用于创建 IAB 的 24 位 OUI 值创建的任何其他标识符仍然是 IEEE RA 的财产。此外，IAB 不能用于使用分配给受让人的 36 位来创建任何其他标识符（例如，受让人不能通过将 28 位附加到它已被分配的 IAB 标识符来创建 EUI-64）。&lt;/p&gt;
&lt;p&gt;虽然 IEEE RA 不保证 36 位 IAB 标识符总是从相同的 OUI 创建的，但所有 IAB 分配实际上都是从两个特定的 OUI 创建的：&lt;code&gt;00-50-C2&lt;/code&gt;hex 和 &lt;code&gt;40-D8-55&lt;/code&gt;hex。使用前者知道基于它的所有 IAB 都被分配，然后使用后者。&lt;/p&gt;
&lt;p&gt;IAB 和 MA-S 的 EUI-48 用法是相同的，因此被分配了 IAB 的组织可以继续按照最初的意图使用它。向 IEEE RA 提出的任何新的 IAB 请求都将通过分配 MA-S 来完成。&lt;/p&gt;
&lt;p&gt;展望未来，现有的 IAB 公开列表将作为历史注册表进行维护。因为没有新的 IAB 会被分配，因此 IAB 注册表不会增加。&lt;/p&gt;
&lt;h3 id=&#34;22-bit-oui-based-identifiers&#34;&gt;22-Bit OUI-Based Identifiers&lt;/h3&gt;
&lt;p&gt;虽然 OUI 始终被指定为 24 位值，但过去指定了各种可选的上下文相关的标识符。一些标准规定只能使用 OUI 的 22 位（去掉 M 和 X 位）。不赞成这种用途。所有使用 OUI 的新规范，除网络寻址外，应使用 IEEE RA 指定的所有 24 为 OUI。这允许使用 OUI 或 CID。&lt;/p&gt;
&lt;h3 id=&#34;mac-48&#34;&gt;MAC-48&lt;/h3&gt;
&lt;p&gt;MAC-48 这个术语现在已经过时了。MAC-48 类似于 EUI-48，也就是说，它是一个由 IEEE RA 分配的 24 位 OUI 和一个由组织分配的 24 位扩展标识符的串联。然而，它被用来处理现有的基于 802 的网络应用程序中寻址硬件接口。术语EUI-48在历史上用于标识设计实例，与硬件接口相对；示例包括软件接口标准（如 VGA）、产品型号以及供应商特定内容的形式/功能。MAC-48 和 EUI-48 之间的细微差别尚不清楚，因此 EUI-48 一词现在用于两种用途，MAC-48 标识符一词现在已经过时了。（IEEE RAC 不了解任何情况，但是如果 MAC-48 用作任何 48 位 MAC 地址的名称，那么 EUI-48 不是 MAC-48 的合适替代术语，因为 EUI-48 仅指单独的、全球唯一的网络地址。）&lt;/p&gt;
&lt;h3 id=&#34;eui-60&#34;&gt;EUI-60&lt;/h3&gt;
&lt;p&gt;EUI-60 不应用于未来的应用。在可预见的未来，没有计划取消这些 EUI-60 值的使用。EUI-64 （与 EUI-60 相反）标识符应该在未来的应用程序、未来的标准以及现有标准的 revisions 和 amendments 中使用，这些标准要求每个硬件使用唯一的实例标识符。&lt;/p&gt;
&lt;h3 id=&#34;cdi-32-and-cdi-40&#34;&gt;CDI-32 and CDI-40&lt;/h3&gt;
&lt;p&gt;CDI-32 和 CDI-40 历史上被推荐作为上下文依赖的标识符。&lt;/p&gt;
&lt;p&gt;历史上，CDI-32 是由 IEEE RA 分配的 OUI 值和由该组织分配的 8 位扩展标识符的串联。&lt;/p&gt;
&lt;p&gt;历史上，CDI-40 是由 IEEE RA 分配的 OUI 值和由该组织分配的 16 位扩展标识符的串联。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;来源：https://standards.ieee.org/wp-content/uploads/import/documents/tutorials/eui.pdf&lt;/p&gt;
">Guidelines for Use of Extended Unique Identifier(EUI), Organizationally Unique Identifier(OUI), and Company ID(CID)</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://wenbozhangw.github.io/post/lesslesstcpip-xiang-jie-juan-yi-xie-yi-greatergreater-di-er-zhang-internet-di-zhi-jie-gou/"" data-c="
          &lt;h2 id=&#34;21-引言&#34;&gt;2.1 引言&lt;/h2&gt;
&lt;p&gt;本章介绍了 Internet 中使用的网络层地址，又称为 IP 地址。我们讨论了如何为 Internet 中的设备分配地址，有助于路由可扩展性的地址层次结构分配方式，以及特殊用途的地址，包括广播、组播和任播地址。我们还讨论了 IPv4 和 IPv6 地址结构和用途的区别。&lt;/p&gt;
&lt;!-- more --&gt;
&lt;p&gt;连接到 Internet 的每个设备至少有一个 IP 地址。基于 TCP/IP 协议的专用网络中使用的设备也需要 IP 地址。在任何情况下， IP 路由器（见第 5 章）实现的转发程序使用 IP 地址来识别流量去向。 IP 地址也表示流量来源。 IP 地址在某些方面与电话号码相似，但最终用户通常知道并直接使用电话号码，而IP 地址通常被 Internet 中的 DNS （见第11章）屏蔽在用户视线之外， DNS 让大多数用户使用名字而不是数字地址。当用户需要自已建立网络或 DNS 由于某种原因失效时，用户需要直接处理 IP 地址。为了了解 Internet 如何识别主机和路由器，并在它们之间实现流量的交付，我们必须了解 IP 地址的作用。因此，我们对它们的管理、结构和用途感兴趣。&lt;/p&gt;
&lt;p&gt;当一台设备连接到全球性的 Internet 时，为它们分配地址就必须经过协调，这样就不会重复使用网络中的其他地址。对于专用网络，使用的 IP 地址必须经过协调，以避免在专用网络中出现类似的重复。成组的 IP 地址被分配给用户和组织。这些地址的拥有者再将它们&lt;strong&gt;分配&lt;/strong&gt;给设备，这通常根据某些“编号方案”进行。对于全球性的 Internet 地址，一个分层结构管理实体帮助用户和服务提供商分配地址。个人用户通常由 **Internet服务提供商（ ISP ）**分配地址，通过支付费用来获得地址和执行路由。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;22-表示-ip-地址&#34;&gt;2.2 表示 IP 地址&lt;/h2&gt;
&lt;p&gt;大多数 Internet 用户熟悉IP地址，并且了解最流行的地址类型：IPv4 地址。这些地址通常采用所谓的点分四组或点分十进制表示法，例如 &lt;code&gt;165.195.130.107&lt;/code&gt;。点分四组表示法由四个用点分隔的十进制数组成。每个这样的数字是一个非负整数，范围为 &lt;code&gt;[0， 255]&lt;/code&gt;，代表整个 IP 地址的四分之一。点分四组表示法是编写完整的 IPv4 地址（一个用于 Internet 系统的 32 位非负整数）的简单方式，它使用便捷的十进制数。在很多情况下，我们将关注这种地址的二进制结构。很多 Internet 站点，例如 &lt;a href=&#34;http://www.subnetmask.info&#34;&gt;http://www.subnetmask.info&lt;/a&gt; 和 &lt;a href=&#34;http://www.subnetcalculator.com&#34;&gt;http://www.subnetcalculator.com&lt;/a&gt; ，包含用于 IP 地址和相关信息之间格式转换的计算器。表2-1给出了几个 IPv4 地址的例子，以及对应的二进制表示，供大家开始学习。&lt;/p&gt;
&lt;center&gt; 表 2-1 用点分四组和二进制表示法写的 IPv4 地址 &lt;/center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;点分四组表示&lt;/th&gt;
&lt;th&gt;二进制表示&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0.0.0.0&lt;/td&gt;
&lt;td&gt;00000000 00000000 00000000 00000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.2.3.4&lt;/td&gt;
&lt;td&gt;00000001 00000010 00000011 00000100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10.0.0.255&lt;/td&gt;
&lt;td&gt;00001010 00000000 00000000 11111111&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;255.255.255.255&lt;/td&gt;
&lt;td&gt;11111111 11111111 11111111 11111111&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;在 IPv6 中，地址的长度是 128 位，是 IPv4 地址长度的 4 倍。一般来说，大多数用户对它不太熟悉。 IPv6 地址的传统表示方法是采用称为&lt;strong&gt;块&lt;/strong&gt;或&lt;strong&gt;字段&lt;/strong&gt;的四个十六进制数，这些被称为块或字段的数由冒号分隔。例如，一个包含 8 个块的 IPv6 地址可写为&lt;code&gt;5f05:2000:80ad:5800:0058:0800:2023:1d71&lt;/code&gt; 。虽然不像用户熟悉的十进制数，但将十六进制数转换为二进制更容易。另外，一些已取得共识的 IPv6 地址简化表示法已被标准化 [&lt;a href=&#34;#RFC4291&#34;&gt;RFC4291&lt;/a&gt;] ：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;一个块中前导的零不必书写。在前面的例子中，地址可写为 &lt;code&gt;5f05:2000:80ad:5800:58:800:2023:1d71&lt;/code&gt; 。&lt;/li&gt;
&lt;li&gt;全零的块可以省略，并用符号 &lt;code&gt;::&lt;/code&gt; 代替。例如，地址 &lt;code&gt;0:0:0:0:0:0:0:1&lt;/code&gt; 可简写为 &lt;code&gt;::1&lt;/code&gt;。同样，地址 &lt;code&gt;2001:0db8:0:0:0:0:0:2&lt;/code&gt; 可简写为 &lt;code&gt;2001:0db8::2&lt;/code&gt; 。为了避免出现歧义，一个 IPv6 地址中符号 &lt;code&gt;::&lt;/code&gt; 只能使用一次。&lt;/li&gt;
&lt;li&gt;在 IPv6 格式中嵌入 IPv4 地址可使用混合符号形式，紧接着 IPv4 部分的地址块的值为 &lt;code&gt;ffff&lt;/code&gt;，地址的其余部分使用点分四组格式。例如，IPv6 地址 &lt;code&gt;::ffff:10.0.0.1&lt;/code&gt; 可表示 IPv4 地址 &lt;code&gt;10.0.0.1&lt;/code&gt;。它被称为 &lt;strong&gt;IPv4 映射的 IPv6 地址&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;IPv6 地址的低 32 位通常采用点分四组表示法。因此，IPv6 地址 &lt;code&gt;::0102:f001&lt;/code&gt; 相当于地址 &lt;code&gt;::1.2.240.1&lt;/code&gt;。它被称为 &lt;code&gt;IPv4 兼容的 IPv6 地址&lt;/code&gt;。需要注意，IPv4 兼容地址与 IPv4 映射地址不同；它们只是在能用类似 IPv4 地址的方式书写或由软件处理方面给人以兼容的感觉。这种地址最初用于 IPv4 和 IPv6 之间的过渡计划，但现在不再需要 [&lt;a href=&#34;#RFC4291&#34;&gt;RFC4291&lt;/a&gt;] 。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;表 2-2 介绍了一些 IPv6 地址的例子以及它们的二进制表示。&lt;/p&gt;
&lt;center&gt; 表 2-2  IPv6 地址和它的二进制表示的几个例子 &lt;/center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;十六进制表示&lt;/th&gt;
&lt;th&gt;二进制表示&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;5f05:2000:80ad:5800:0058:0800:2023:1d71&lt;/td&gt;
&lt;td&gt;0101111100000101 0010000000000000 1000000010101101 0101100000000000 0000000001011000 0000100000000000 0010000000100011 0001110101110001&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;::1&lt;/td&gt;
&lt;td&gt;0000000000000000 0000000000000000 0000000000000000 0000000000000000 0000000000000000 0000000000000000 0000000000000000 0000000000000001&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;::1.2.240.1 或 ::102:f001&lt;/td&gt;
&lt;td&gt;0000000000000000 0000000000000000 0000000000000000 0000000000000000 0000000000000000 0000000000000000 0000000100000010 1111000000000001&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;在某些情况下（例如表示一个包含地址的 URL 时），IPv6 地址中的冒号分隔符可能与其他分隔符混淆，例如 IP 地址和端口号之间使用的冒号。在这种情况下，用括号字符 &lt;code&gt;[&lt;/code&gt; 和 &lt;code&gt;]&lt;/code&gt; 包围 IPv6 地址。例如， URL&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;http://[2001:0db8:85a3:08d3:1319:8a2e:0370:7344]:443/
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;是指IPv6主机 &lt;code&gt;2001:0db8:85a3:08d3:1319:8a2e:0370:7344&lt;/code&gt; 中的端口号 443 使用 HTTP、 TCP 和 IPv6 协议。&lt;/p&gt;
&lt;p&gt;[&lt;a href=&#34;#RFC4291&#34;&gt;RFC4291&lt;/a&gt;] 提供的灵活性造成了不必要的混淆，这是因为能用多种方式表示相同的 IPv6 地址。为了弥补这种情况，[&lt;a href=&#34;#RFC5952&#34;&gt;RFC5952&lt;/a&gt;] 制定了一些规则，以缩小选择范围，同时与 [&lt;a href=&#34;#RFC4291&#34;&gt;RFC4291&lt;/a&gt;] 保持兼容。这些规则如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;前导的零必须压缩（例如，&lt;code&gt;2001:0db8::0022&lt;/code&gt; 编程 &lt;code&gt;2001:db8::22&lt;/code&gt;）。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;::&lt;/code&gt;  只能用于影响最大的地方（压缩最多的零），但并不只是针对 16 位的块。如果多个块中包含等长度的零，顺序靠前的块将被替换为 &lt;code&gt;::&lt;/code&gt; 。&lt;/li&gt;
&lt;li&gt;a 到 f 的十六进制数字应该用小写表示。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在大多数情况下，我们会遵守这些规则。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;23-基本的-ip-地址结构&#34;&gt;2.3 基本的 IP 地址结构&lt;/h2&gt;
&lt;p&gt;IPv4 地址空间中有 &lt;code&gt;4 294 967 296&lt;/code&gt; 个可能的地址，而 IPv6 的地址个数为&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;340 282 366 920 938 463 463 374 607 431 768 211 456
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;由于拥有大量地址（特别是 IPv6），可以方便地将地址空间划分成块。IP 地址可根据类型和大小分组。大多数 IPv4 地址块最终被细分为一个地址，用于识别连接 Internet 或某些专用的内联网的计算机网络接口。这些地址称为&lt;strong&gt;单播&lt;/strong&gt;地址。 IPv4 地址空间中大部分是单播地址空间。 IPv6 地址空间中大部分目前未使用。除了单播地址，其他类型的地址包括广播、组播和任播地址，它们可能涉及多个接口，还有一些特殊用途的地址，我们将在后面讨论它们。在开始介绍当前地址结构的细节之前，理解 IP 地址的历史演变是有用的。&lt;/p&gt;
&lt;h3 id=&#34;231-分类寻址&#34;&gt;2.3.1 分类寻址&lt;/h3&gt;
&lt;p&gt;当最初定义 Internet 地址结构时，每个单播 IP 地址都有一个网络部分，用于识别接口使用的 IP 地址在哪个网络中可被发现；以及一个主机地址，用于识别由网络部分给出的网络中的特定主机。因此，地址中的一些连续位称为&lt;strong&gt;网络号&lt;/strong&gt;，其余位称为&lt;strong&gt;主机号&lt;/strong&gt;。当时，大多数主机只有一个网络接口，因此术语&lt;strong&gt;接口地址&lt;/strong&gt;和&lt;strong&gt;主机地址&lt;/strong&gt;有时交替使用。&lt;/p&gt;
&lt;p&gt;现实中的不同网络可能有不同数量的主机，每台主机都需要一个唯一的 IP 地址。一种划分方法是基于当前或预计的主机数量，将不同大小的 IP 地址空间分配给不同的站点。地址空间的划分涉及五大&lt;strong&gt;类&lt;/strong&gt;。每类都基于网络中可容纳的主机数量，确定在一个 32 位的 IPv4 地址中分配给网络号和主机号的位数。图 2-1 显示了这个基本思路。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1650619000045.png&#34; alt=&#34;图 2-1&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 2-1 IPv4 地址空间最初分为五大类。A、B、C 类用于为 Internet （单播地址）中的接口分配地址，以及其他一些特殊情况下使用。类由地址中的头几位来定义：&lt;code&gt;0&lt;/code&gt; 为 A 类，&lt;code&gt;10&lt;/code&gt; 为 B 类，&lt;code&gt;110&lt;/code&gt; 为 C 类等。D 类地址供组广播使用（见第 9 章），E 类地址保留&lt;/p&gt;
&lt;p&gt;这里，我们看到5个类被命名为 A、 B、 C、 D 和 E。 A、 B、 C 类空间用于单播地址。如果我们仔细看这些地址结构，可看到不同类的相对大小，以及在实际使用中的地址范围。表 2-3 给出了这种类结构（有时被称为&lt;strong&gt;分类地址&lt;/strong&gt;结构）。&lt;/p&gt;
&lt;center&gt; 表 2-3 最初（“分类”）的 IPv4 地址空间划分&lt;/center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;类&lt;/th&gt;
&lt;th&gt;地址范围&lt;/th&gt;
&lt;th&gt;高序位&lt;/th&gt;
&lt;th&gt;用途&lt;/th&gt;
&lt;th&gt;百分比&lt;/th&gt;
&lt;th&gt;网络数&lt;/th&gt;
&lt;th&gt;主机数&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;A&lt;/td&gt;
&lt;td&gt;0.0.0.0 ~ 127.255.255.255&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;单播/特殊&lt;/td&gt;
&lt;td&gt;1/2&lt;/td&gt;
&lt;td&gt;128&lt;/td&gt;
&lt;td&gt;16777216&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;B&lt;/td&gt;
&lt;td&gt;128.0.0.0 ~ 191.255.255.255&lt;/td&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;单播/特殊&lt;/td&gt;
&lt;td&gt;1/4&lt;/td&gt;
&lt;td&gt;16384&lt;/td&gt;
&lt;td&gt;65536&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;C&lt;/td&gt;
&lt;td&gt;192.0.0.0 ~ 223.255.255.255&lt;/td&gt;
&lt;td&gt;110&lt;/td&gt;
&lt;td&gt;单播/特殊&lt;/td&gt;
&lt;td&gt;1/8&lt;/td&gt;
&lt;td&gt;2097152&lt;/td&gt;
&lt;td&gt;256&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;D&lt;/td&gt;
&lt;td&gt;224.0.0.0 ~ 239.255.255.255&lt;/td&gt;
&lt;td&gt;1110&lt;/td&gt;
&lt;td&gt;组播&lt;/td&gt;
&lt;td&gt;1/16&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;E&lt;/td&gt;
&lt;td&gt;240.0.0.0 ~ 255.255.255.255&lt;/td&gt;
&lt;td&gt;1111&lt;/td&gt;
&lt;td&gt;保留&lt;/td&gt;
&lt;td&gt;1/16&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;该表显示了分类地址结构的主要使用方式，如何将不同大小的单播地址块分配给用户。类划分基于给定大小的可用网络数和给定网络中的可分配主机数之间的折中。例如，某个站点分配了一个A类网络号 &lt;code&gt;18.0.0.0 &lt;/code&gt;(MIT)，其中有 2&lt;sup&gt;24&lt;/sup&gt; 个地址分配给主机（即 IPv4 地址使用范围 &lt;code&gt;18.0.0.0 ~ 18.255.255.255&lt;/code&gt;），但在整个 Internet 中只有 127 个A类网络。某个站点分配了一个 C 类网络号，例如 &lt;code&gt;192.125.3.0&lt;/code&gt;，只能容纳 256 台主机（也就是说在范围 &lt;code&gt;192.125.3.0 ~ 192.125.3.255&lt;/code&gt; 内），但有超过 200 万的 C 类网络号是可用的。&lt;/p&gt;
&lt;p&gt;注意  这些数字是不准确的。有几个地址通常不作为单播地址使用。特别是，地址块中的第一个和最后一个地址通常不使用。在我们的例子中，站点分配的地址块为 &lt;code&gt;18.0.0.0&lt;/code&gt;，实际能分配多达 2&lt;sup&gt;24&lt;/sup&gt; - 2 = 16777214 个单播IP地址。&lt;/p&gt;
&lt;p&gt;Internet 地址分类方法在经历 Internet 增长（20 世纪 80年代）的第一个十年中没有变化。此后，它开始出现规模问题，当每个新的网段被添加到 Internet 中，集中协调为其分配一个新的 A 类、B 类或 C 类网络号变得很不方便。另外， A 类和 B 类网络号通常浪费太多主机号，而 C 类网络号不能为很多站点提供足够的主机号。&lt;/p&gt;
&lt;h3 id=&#34;232-子网寻址&#34;&gt;2.3.2 子网寻址&lt;/h3&gt;
&lt;p&gt;Internet 发展初期首先遇到一个困难，那就是很难为接入 Internet 的新网段分配一个新的网络号。在 20 世纪 80 年代初，随着局域网（LAN）的发展和增加，这个问题变得更棘手。为了解决这个问题，人们很自然想到一种方式，在一个站点接入 Internet 后为其分配一个网络号，然后由站点管理员进一步划分本地的子网数。在不改变 Internet 核心路由基础设施的情况下解决这个问题将会更好。&lt;/p&gt;
&lt;p&gt;实现这个想法需要改变一个 IP 地址的网络部分和主机部分的限制，但这样做只是针对一个站点自身而言； Internet 其余部分将只能“看到”传统的 A 类、 B 类和 C 类部分。支持此功能的方法称为 &lt;strong&gt;子网寻址&lt;/strong&gt; [&lt;a href=&#34;#RFCO950&#34;&gt;RFCO950&lt;/a&gt;] 。通过子网寻址，一个站点被分配一个 A 类、 B 类或 C 类的网络号，保留一些剩余主机号进一步用于站点内分配。该站点可能将基础地址中的主机部分进一步划分为一个子网号和一个主机号。从本质上来说，子网寻址为 IP 地址结构增加了一个额外部分，但它没有为地址增加长度。因此，一个站点管理员能在子网数和每个子网中预期的主机数之间折中，同时不需要与其他站点协调。&lt;/p&gt;
&lt;p&gt;子网寻址提供额外灵活性的代价是增加成本。由于当前的&lt;strong&gt;子网&lt;/strong&gt;字段和&lt;strong&gt;主机&lt;/strong&gt;字段的定义由站点指定的（不是由网络号分类决定），一个站点中所有路由器和主机需要一种新的方式，以确定地址中的子网部分和其中的主机部分。在出现子网之前，这个信息可直接从一个网络号中获得，只需知道是 A 类、 B 类或 C 类地址（由地址的前几位表示）。图 2-2 给出了使用子网寻址的例子，显示了一个 IPv4 地址可能的格式。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1650625617558.png&#34; alt=&#34;图 2-2&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 2-2  一个 B 类地址被划分子网的例子。它使用 8 位作为子网 ID，提供 256 个子网和每个子网中 254 台主机。这种划分可由网络管理员改变&lt;/p&gt;
&lt;p&gt;图 2-2 是一个 B 类地址被“划分子网”的例子。假设 Internet 中的一个站点已被分配一个 B 类网络号。该站点将每个地址的前 16 位固定为某些特定号码，这是由于这些位已被分配给核心机构。后 16 位（仅用于在无子网的 B 类网络中创建主机号）现在可以由站点的网络管理员接需分配。在这个例子中， 8 位被选定为子网号，剩下 8 位为主机号。这个特殊配置允许站点支持 256 个子网，每个子网最多可包含 254 台主机（当前每个子网的第一个和最后一个地址无效，即从整个分配范围中除去第一个和最后一个地址)。注意，只有划分子网的网络中的主机和路由器知道子网结构。在需要进行子网寻址之前， Internet 其他部分仍将它作为站点相关的地址来看待。图 2-3 显示了如何工作。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1650628367587.png&#34; alt=&#34;图 2-3&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 2-3  某个站点被分配一个典型的 B 类网络号 &lt;code&gt;128.320&lt;/code&gt;。网络管理员决定用于站点范围内的子网掩码为 &lt;code&gt;255.255.255.0&lt;/code&gt;，提供 256 个子网，每个子网可容纳 &lt;code&gt;256 - 2 = 254&lt;/code&gt; 台主机。同一子网中每台主机的 IPv4 地址拥有相同子网号。左侧的局域网段中主机的 IPv4 地址开始于 &lt;code&gt;128.32.1&lt;/code&gt;，右侧的所有主机开始于 &lt;code&gt;128.32.2&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;本图显示了一个虚拟的站点，使用一个边界路由器（即 Internet 的一个连接点）连接 Internet 和两个内部局域网。&lt;code&gt;x&lt;/code&gt; 的值可以是 &lt;code&gt;[0，255]&lt;/code&gt; 范围内的任意值。每个以太网是一个 IPv4 子网，整体分配为 B 类地址的网络号 &lt;code&gt;128.32&lt;/code&gt;。 Internet 中的其他站点要访问这个站点，目的地址以   &lt;code&gt;128.32&lt;/code&gt; 开始的所有流量直接由 Internet 路由系统交给边界路由器（特别是其接口的 IPv4 地址&lt;code&gt;137.164.23.30&lt;/code&gt;)。在这点上，边界路由器必须区分 &lt;code&gt;128.32&lt;/code&gt; 网络中的不同子网。特别是，它必须能区分和分离目的地址为 &lt;code&gt;128.32.1.x&lt;/code&gt; 和目的地址为 &lt;code&gt;128.32.2.x&lt;/code&gt; 的流量。这些地址分别表示子网号 &lt;code&gt;1&lt;/code&gt; 和 &lt;code&gt;2&lt;/code&gt;，它们都采用 &lt;code&gt;128.32&lt;/code&gt; 的 B 类网络号。为了做到这点，路由器必须知道在地址中如何找到子网ID。这可通过一个配置参数实现，我们将在后面加以讨论。&lt;/p&gt;
&lt;h3 id=&#34;233-子网掩码&#34;&gt;2.3.3 子网掩码&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;子网掩码&lt;/strong&gt;是由一台主机或路由器使用的分配位，以确定如何从一台主机对应 IP 地址中获得网络和子网信息。 IP 子网掩码与对应的 IP 地址长度相同（IPv4为 32 位， IPv6为 128 位）。它们通常在一台主机或路由器中以 IP 地址相同的方式配置，既可以是静态的（通常是路由器），也可以使用一些动态方式，例如&lt;strong&gt;动态主机配置协议&lt;/strong&gt;(DHCP ；见第 6 章)。对于 IPv4，子网掩码以 IPv4 地址相同的方式（即点分十进制）编写。虽然最初不需要以这种方式分配，当前子网掩码由一些 1 后跟一些 0 构成。这样安排，就可以用容易记的格式表示掩码，只需给出一些连续位的 1 （左起）的掩码。这种格式是当前最常见的格式，有时也被称为&lt;strong&gt;前缀长度&lt;/strong&gt;。表 2-4 列出了 IPv4 的一些例子。&lt;/p&gt;
&lt;center&gt;表 2-4 各种格式的 IPv4 子网掩码的例子&lt;/center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;点分十进制表示&lt;/th&gt;
&lt;th&gt;容易记的格式（前缀长度）&lt;/th&gt;
&lt;th&gt;二进制表示&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;128.0.0.0&lt;/td&gt;
&lt;td&gt;/1&lt;/td&gt;
&lt;td&gt;10000000 00000000 00000000 00000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;255.0.0.0&lt;/td&gt;
&lt;td&gt;/8&lt;/td&gt;
&lt;td&gt;11111111 00000000 00000000 00000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;255.192.0.0&lt;/td&gt;
&lt;td&gt;/10&lt;/td&gt;
&lt;td&gt;11111111 11000000 00000000 00000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;255.255.0.0&lt;/td&gt;
&lt;td&gt;/16&lt;/td&gt;
&lt;td&gt;11111111 11111111 00000000 00000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;255.255.254.0&lt;/td&gt;
&lt;td&gt;/23&lt;/td&gt;
&lt;td&gt;11111111 11111111 11111110 00000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;255.255.255.192&lt;/td&gt;
&lt;td&gt;/27&lt;/td&gt;
&lt;td&gt;11111111 11111111 11111111 11100000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;255.255.255.255&lt;/td&gt;
&lt;td&gt;/32&lt;/td&gt;
&lt;td&gt;11111111 11111111 11111111 11111111&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;表 2-5 列出了 IPv6 的一些例子。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;十六进制表示&lt;/th&gt;
&lt;th&gt;容易记的格式（前缀长度）&lt;/th&gt;
&lt;th&gt;二进制表示&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;ffff:ffff:ffff:ffff::&lt;/td&gt;
&lt;td&gt;/64&lt;/td&gt;
&lt;td&gt;1111111111111111 1111111111111111 &lt;br/&gt; 1111111111111111 1111111111111111 &lt;br/&gt; 0000000000000000 0000000000000000 &lt;br/&gt; 0000000000000000 0000000000000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ff00::&lt;/td&gt;
&lt;td&gt;/8&lt;/td&gt;
&lt;td&gt;1111111100000000 0000000000000000 &lt;br/&gt; 0000000000000000 0000000000000000 &lt;br/&gt; 0000000000000000 0000000000000000 &lt;br/&gt; 0000000000000000 0000000000000000&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;掩码由路由器和主机使用，以确定一个 IP 地址的网络 / 子网部分的结束和主机部分的开始。子网掩码中的一位设为 1 表示一个 IP 地址的对应位与一个地址的网络 / 子网部分的对应位相结合，并将结果作为转发数据报的基础（见第5章）。相反，子网掩码中的一位设为 0，表示一个 IP 地址的对应位作为主机 ID 的一部分。例如，我们在图 2-4 中可以看到，当子网掩码为 &lt;code&gt;255.255.255.0&lt;/code&gt; 时，如何处理 IPv4 地址 &lt;code&gt;128.32.1.14&lt;/code&gt;。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1650631778417.png&#34; alt=&#34;图 2-4&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 2-4  一个 IP 地址可以与一个子网掩码使用按位与操作，以形成用于路由的地址的网络 / 子网标识符（前缀）。在这个例子中， IPv4 地址 &lt;code&gt;128.32.1.14&lt;/code&gt; 使用长度为 24 的掩码得到前缀&lt;code&gt;128.32.1.0/24&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;这里，我们看如何将地址中的每位与子网掩码中的对应位进行与运算。回顾按位与运算，如果掩码和地址中的对应位都是 1，则结果位都只能是 1。在这个例子中，我们看到地址 &lt;code&gt;128.32.1.14&lt;/code&gt; 属于子网 &lt;code&gt;128.32.1.0/24&lt;/code&gt; 。图 2-3 中是边界路由器需要的信息，以确定一个目的地址为 &lt;code&gt;128.32.1.14&lt;/code&gt; 的数据报需要转发到的系统所在的子网。注意， Internet 路由系统其余部分不需要子网掩码的知识，因为站点之外的路由器做出路由决策只基于地址的网络号部分，并不需要网络 / 子网或主机部分。因此，子网掩码纯粹是站点内部的局部问题。&lt;/p&gt;
&lt;h3 id=&#34;234-可变长度子网掩码&#34;&gt;2.3.4 可变长度子网掩码&lt;/h3&gt;
&lt;p&gt;目前为止，我们已讨论如何将一个分配给站点的网络号进一步细分为多个可分配的大小相同的子网，并根据网络管理员的合理要求使每个子网能支持相同数量的主机。我们发现在同一站点的不同部分，可将不同长度的子网掩码应用于相同网络号。虽然这样增加了地址配置管理的复杂性，但也提高了子网结构的灵活性，这是由于不同子网可容纳不同数量的主机。目前，大多数主机、路由器和路由协议支持&lt;strong&gt;可变长度子网掩码（VLSM）&lt;/strong&gt;。要了解 VLSM 如何工作，可以看图 2-5 所示的网络拓扑，它使用 VLSM 为图 2-3 扩展了两个额外的子网。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1650635390775.png&#34; alt=&#34;图 2-5&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 2-5 VLSM 可用于分割一个网络号，使每个子网支持不同数量的主机。每个路由器和主机除了 IP 地址，还需要配置一个子网掩码。大多数软件支持 VLSM，除了一些旧的路由协议（例如 RIP 版本 1）&lt;/p&gt;
&lt;p&gt;在图 2-5 显示的更复杂的例子中，三个不同的子网掩码被用于站点中的子网 &lt;code&gt;128.32.0.0/16&lt;/code&gt; : &lt;code&gt;/24&lt;/code&gt;、 &lt;code&gt;/25&lt;/code&gt; 和 &lt;code&gt;/26&lt;/code&gt;。这样，每个子网可提供不同数量的主机。主机数受 IP 地址中没有被网络 / 子网号使用的剩余位限制。对于 IPv4 和 &lt;code&gt;/24&lt;/code&gt; 前缀，允许有 &lt;code&gt;32-24=8&lt;/code&gt; 位 （ 256 台主机）；对于 &lt;code&gt;/25&lt;/code&gt;，有 &lt;code&gt;1/2&lt;/code&gt; 数量（ 128 台主机）；对于 &lt;code&gt;/26&lt;/code&gt; ，有 1/4 数量（ 64 台主机）。注意，主机和路由器的每个接口都需要用 IP 地址和子网掩码来描述，但掩码决定了网络拓扑的不同。基于路由器中运行的动态路由协议(例如 OSPF、 IS-IS、 RIPv2)，流量能正确地在同一站点中的主机之间流动，以及通过 Internet 前往或来自外部站点。&lt;/p&gt;
&lt;p&gt;尽管这可能并不显而易见，但有一个常见情况，即一个子网中只包含两台主机。当路由器之间被一条点到点链路连接，则每个端点都需要分配一个 IP 地址，常见做法是 IPv4 使用 &lt;code&gt;/31&lt;/code&gt; 为前缀，目前也有建议 IPv6 使用 &lt;code&gt;/127&lt;/code&gt; 为前缀 [&lt;a href=&#34;#RFC6164&#34;&gt;RFC6164&lt;/a&gt;] 。&lt;/p&gt;
&lt;h3 id=&#34;235-广播地址&#34;&gt;2.3.5 广播地址&lt;/h3&gt;
&lt;p&gt;在每个 IPv4 子网中，一个特殊地址被保留作为子网广播地址。子网广播地址通过将 IPv4 地址的网络 / 子网部分设置为适当值，以及主机部分的所有位设置为 1 而形成。我们看图 2-5 中最左边的子网，它的前缀是 &lt;code&gt;128.32.1.0/24&lt;/code&gt;。子网广播地址的构建方式为：对子网掩码取反（即将所有的0位改变为1，反之亦然），并与子网中任意计算机的地址(或等值的网络 / 子网前缀)进行按位或运算。注意，如果两个输入位之一为 1，按位或运算的结果为1。图 2-6 显示了这个计算过程，其中使用 IPv4 地址&lt;code&gt;128.32.1.14&lt;/code&gt;。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1650636499514.png&#34; alt=&#34;图 2-6&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 2-6  子网广播地址由子网掩码首先取反，然后与 IPv4 地址进行或运算构成。在这种情况下，一个 &lt;code&gt;/24&lt;/code&gt; 的子网掩码，剩余的 &lt;code&gt;32-24 = 8&lt;/code&gt; 位设置为 1，得到一个十进制 255 和子网广播地址 &lt;code&gt;128.32.1.255&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;如图2-6所示，子网 &lt;code&gt;128.32.1.0/24&lt;/code&gt; 的子网广播地址是 &lt;code&gt;128.32.1.255&lt;/code&gt;。从历史上看，使用这种地址作为目的地的数据报，也被称为&lt;strong&gt;定向广播&lt;/strong&gt;。至少在理论上，这种广播可作为一个单独的数据报通过 Internet 路由直至到达目标子网，再作为一组广播数据报发送给子网中所有主机。对这个想法做进一步概括，我们可形成一个目的 IPv4 地址为 &lt;code&gt;128.32.255.255&lt;/code&gt; 的数据报，并且通过图 2-3 或图 2-5 所示的连接网络将它发送到 Internet 。这时，该数据报将发送给目标站点中的所有主机。&lt;/p&gt;
&lt;p&gt;注意   定向广播是一个大问题，从安全的角度来看，它们至今在 Internet 中仍被禁用。 [&lt;a href=&#34;#RFCO919&#34;&gt;RFCO919&lt;/a&gt;] 描述了针对 IPv4 的各类广播， [&lt;a href=&#34;#RFC1812&#34;&gt;RFC1812&lt;/a&gt;] 建议支持由路由器转发定向广播，它不仅可用，而且默认启用。 [&lt;a href=&#34;#RFC2644&#34;&gt;RFC2644&lt;/a&gt;] 使这个策略发生逆转，路由器现在默认禁止转发定向广播，甚至完全省略支持能力。&lt;/p&gt;
&lt;p&gt;除了子网广播地址，特殊用途地址 &lt;code&gt;255.255.255.255&lt;/code&gt; 被保留为&lt;strong&gt;本地网络广播&lt;/strong&gt;（也称为&lt;strong&gt;有限广播&lt;/strong&gt;），它根本不会被路由器转发（详见 2.5 节中的特殊用途地址）。注意，虽然路由器可能不转发广播，但子网广播和连接在同一网络中的计算机的本地网络广播将工作，除非被终端主机明确禁用。这种广播不需要路由器；如果有的话，链路层的广播机制用于支持它们（见第3章）。广播地址通常与某些协议一起使用，例如 UDP/IP （第 10 章）或 ICMP （第 8 章），因为这些协议不涉及 TCP/IP 那样的双方会话。 IPv6 没有任何广播地址；广播地址可用于 IPv4 中，而 IPv6 仅使用组播地址（见第 9 章）。&lt;/p&gt;
&lt;h3 id=&#34;236-ipv6-地址和接口标识符&#34;&gt;2.3.6 IPv6 地址和接口标识符&lt;/h3&gt;
&lt;p&gt;除了比 IPv4 地址长 4 倍这个因素， IPv6 地址还有一些额外的特点。 IPv6 地址使用特殊前缀表示一个地址范围。一个 IPv6 地址范围是指它可用的网络规模。有关范围的重要例子包括&lt;strong&gt;节点本地&lt;/strong&gt;（只用于同一计算机中通信）、&lt;strong&gt;链路本地&lt;/strong&gt;（只用于同一网络链路或 IPv6 前缀中的节点）或&lt;strong&gt;全球性&lt;/strong&gt;（ Internet 范围）。在 IPv6 中，大部分节点通常在同一网络接口上使用多个地址。虽然 IPv4 中也支持这样做，但是并不常见。一个 IPv6 节点中需要一组地址，包括组播地址(见 2.5.2 节)，它来源于 [&lt;a href=&#34;#RFC4291&#34;&gt;RFC4291&lt;/a&gt;] 。&lt;/p&gt;
&lt;p&gt;注意   另一个范围层次称为站点本地，使用的前缀为 &lt;code&gt;fec0::/10&lt;/code&gt;，最初是由 IPv6 支持的，后来被 [&lt;a href=&#34;#RFC3879&#34;&gt;RFC3879&lt;/a&gt;] 放弃并用于单播地址。主要问题包括如何处理这种地址，这是由于它可能被重用于多个站点，以及如何准确定义一个“站点”。&lt;/p&gt;
&lt;p&gt;链路本地 IPv6 地址（和一些全球性 IPv6 地址）使用**接口标识符（ IID ）**作为一个单播 IPv6 地址的分配基础。除了地址是以二进制值 000 开始之外， IID 在所有情况下都作为一个 IPv6 地址的低序位，这样它们必须在同一网络中有唯一前缀。 IID 的长度通常是 64 位，并直接由一个网络接口相关的链路层 MAC 地址形成，该地址使用 &lt;strong&gt;修改的 EUI-64 格式&lt;/strong&gt; [&lt;a href=&#34;#EUI64&#34;&gt;EUI64&lt;/a&gt;]，或者由其他进程随机提供的值形成，以提供可防范地址跟踪的某种程度的隐私保护（见第 6 章）。&lt;/p&gt;
&lt;p&gt;在 IEEE 标准中， EUI 表示&lt;strong&gt;扩展唯一标识符&lt;/strong&gt;。 EUI-64 标识符开始于一个 24 位的&lt;strong&gt;组织唯一标识符（ OUI ）&lt;/strong&gt;，接着是一个由组织分配的 40 位&lt;strong&gt;扩展标识符&lt;/strong&gt;，它由前面 24 位识别。 OUI 由 IEEE 注册权威机构 [&lt;a href=&#34;#IEEERA&#34;&gt;IEEERA&lt;/a&gt;] 来维护和分配。 EUI 可能是“统一管理”或“本地管理”的。在 Internet 环境下，这种地址通常是统一管理的。&lt;/p&gt;
&lt;p&gt;多年来，很多 IEEE 标准兼容的网络接口（例如以太网）在使用短格式的地址（48位的&lt;br&gt;
EUI）。 EUI-48 和 EUI-64 格式之间的显著区别是它们的长度（见图 2-7）。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1650724664618.png&#34; alt=&#34;图 2-7&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 2-7   EUI-48 和 EUI-64 格式由 IEEE 定义。这些都是用于 IPv6 的地址，它们是通过将接口标识符反 u 位来形成的&lt;/p&gt;
&lt;p&gt;OUI 的长度是 24 位，并占据 EU1-48 和 EU1-64 地址的前 3 个字节。这些地址的第一个字节的低两位分别是 u 位和 g 位。当 u 位被设置时，表示该地址是本地管理。当 g 位被设置时， 表示该地址是一组或组播类型的地址。目前，我们只关心 g 位未被设置的情况。&lt;/p&gt;
&lt;p&gt;一个 EUI-64 地址可以由 EUI-48 地址形成，将 EU1-48 地址的24位 OUI 值复制到 EU1-64 地址，并将 EUI-64 地址的第 4 和第 5 个字节的 16 位替换为 &lt;code&gt;1111111111111110&lt;/code&gt; （十六进制 &lt;code&gt;FFFE&lt;/code&gt;），然后复制由组织分配的剩余位。例如， EUI-48 地址 &lt;code&gt;00-11-22-33-44-55&lt;/code&gt; 在 EUI-64地址中将会变成 &lt;code&gt;00-11-22-FF-FE-33-44-55&lt;/code&gt;。 这个映射的第一步是当可以用基本 EUI-48 地址时由 IPv6 构造接口标识符。修改的 EUI-64 用于形成 IPv6 地址的 IID，但是需要对 u 位取反。&lt;/p&gt;
&lt;p&gt;当一个 IPv6 接口标识符需要一种接口，并且该接口没有由制造商提供 EUI-48 地址，但是有其他类型的基本地址时（例如 AppleTalk ），基本地址可用 0 从左侧填充形成接口标识符。当接口标识符是为缺乏任意形式标识符的接口（例如隧道、串行链路）创建时，它可由相同节点上（不在同一子网中）的其他接口，或者与节点有关联的某些标识符派生。在缺乏其他选择的情况下，手动分配是最后的方案。&lt;/p&gt;
&lt;h4 id=&#34;2361-例子&#34;&gt;2.3.6.1 例子&lt;/h4&gt;
&lt;p&gt;我们探讨使用 Linux 的 ifconfig 命令形成一个链路本地 IPv6 地址的方式:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Linux% ifconfig eth1
eth1     Link encap:Ethernet    HWaddr 00:30:48:2A:19:89
            inet addr:12.46.129.28  Bcast:12.46.129.127
            Mask:255.255.255.128
            inet6 addr: fe80::230:48ff:fe2a:1989/64 Scope:Link
            UP BROADCAST RUNNING MULTICAST  MTU:1500    Metric:1
            RX packets:1359970341 errors:0 dropped:0 overruns:0 frame:0
            TX packets:1472870787 errors:0 dropped:0 overruns:0 carrier:0
            collisions:0    txqueuelen:1000
            RX bytes:4021555658 (3.7 GiB)   TX bytes:3258456176 (3.0 GiB)
            Base address:0x3040 Memory:f8220000-f8240000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里，我们可看到以太网硬件地址 &lt;code&gt;00:30:48:2A:19:89&lt;/code&gt; 如何被映射为一个IPv6地址。首先，它被转换为 EUI-64 形成地址 &lt;code&gt;00:30:48:ff:fe:2a:19:89&lt;/code&gt;。 接着， u 位被取反，形成 IID 值&lt;code&gt;02:30:48:ff:fe:2a:19:89&lt;/code&gt;。 为了完成链路本地 IPv6 地址，我们使用保留的链路本地前缀 &lt;code&gt;fe80::/10&lt;/code&gt; （见 2.5 节）。总之，这样形成完整地址 &lt;code&gt;fe80::230:48ff:fe2a:1989&lt;/code&gt;。      &lt;code&gt; /64&lt;/code&gt; 是标准长度，用于从一个 IPv6 地址中识别子网/主机部分，它由 [&lt;a href=&#34;#RFC4291&#34;&gt;RFC4291&lt;/a&gt;] 要求的一个 IID 派生。&lt;/p&gt;
&lt;p&gt;另一个有趣的例子来自支持 IPv6 的 Windows 系统。在这个例子中，我们将看到一个特殊的隧道端点，它被用于使 IPv6 流量通过仅支持 IPv4 的网络:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;c:\&amp;gt; ipconfig /all
...
Tunnel adapter Automatic Tunneling pseud Interface:

Connection-specific DNS Suffix .  : foo
Description . . . . . . . . . . . : Automatic Tunneling
                                      Pseudo一Interface
Physical Address . . . . . . . . . : 0A-99-BD-87
dhcp Enabled . . . . . . . . . . . : No
IP Address . . . . . . . . . . . . : fe80::5efe:10.153.141.135%2
Default Gateway  . . . . . . . . . : 
DNS Servers  . . . . . . . . . . . : fec0:0:0:ffff::1%2
                                     fec0:0:0:ffff::2%2
                                     fec0:0:0:ffff::3%2
NetBIOS over Tcpip . . . . . . . . : Disabled
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在这个例子中，我们可以看到一个特殊的隧道接口为 ISATAP[&lt;a href=&#34;#RFC5214&#34;&gt;RFC5214&lt;/a&gt;]。实际上，所谓的物理地址是 IPv4 地址的十六进制编码：&lt;code&gt;0A-99-8D-87&lt;/code&gt; 与 &lt;code&gt;10.153.141.135&lt;/code&gt; 相同。这里，使用的 OUI （&lt;code&gt;00-00-5E&lt;/code&gt;）是由 IANA 分配的 [&lt;a href=&#34;#IANA&#34;&gt;IANA&lt;/a&gt;]。它被用于与十六进制值 &lt;code&gt;fe&lt;/code&gt; 组合，表示一个嵌入的 IPv4 地址。然后，这个组合与标准的链路本地前缀 &lt;code&gt;fe80::/10&lt;/code&gt; 组合，最终形成地址 &lt;code&gt;fe80::5efe:10.153.141.135&lt;/code&gt;。 附加在地址结尾的 &lt;code&gt;%2&lt;/code&gt; 在 Windows 中称为** 区域ID**，表示主机中对应于 IPv6 地址的接口索引号。 IPv6 地址通常由一个自动配置过程创建，我们在第6章详细讨论这个过程。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;24-cidr-和聚合&#34;&gt;2.4 CIDR 和聚合&lt;/h2&gt;
&lt;p&gt;20 世纪 90 年代初，在采用子网寻址缓解增长带来的痛苦后， Internet 开始面临更严重的规模问题。有三个问题很重要，需要立即引起注意：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;到1994年，一半以上的 B 类地址已被分配。预计， B 类地址空间大约在 1995 年将被用尽。&lt;/li&gt;
&lt;li&gt;32 位的 IPv4 地址被认为不足以应付 Internet 在 21 世纪初的预期规模。&lt;/li&gt;
&lt;li&gt;全球性路由表的条目数（每个网络号对应一条）， 1995 年大约为 65000 个条目，目前仍在增长中。随着越来越多 A 类、 B 类和 C 类路由条目的出现，路由性能将受到影响。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;从 1992 年开始，这些问题受到 IETF 中的 ROAD （路由和寻址）小组的关注。他们认为问题 1 和 3 将很快来临，问题 2 需要一个长期的解决方案。他们提出的短期解决方案是有效清除 IP 地址的分类缺陷，并提高层次化分配的 IP 地址的聚合能力。这些措施将有助于解决问题 1 和 3 。 IPv6 被设想用于解决问题 2。&lt;/p&gt;
&lt;h3 id=&#34;241-前缀&#34;&gt;2.4.1 前缀&lt;/h3&gt;
&lt;p&gt;为了帮助缓解 IPv4 地址（特别是B类地址）的压力，分类寻址方案通常使用一个类似 VLSM 的方案，扩展 Internet 路由系统以支持&lt;strong&gt;无类别域间路由（Classless Inter-Domain Routing，CIDR）&lt;/strong&gt; [&lt;a href=&#34;#RFC4632&#34;&gt;RFC4632&lt;/a&gt;]。这提供了一种方便的分配连续地址范围的方式，包含多于 255 台但少于 65536 台主机。也就是说，不只是单个 B 类或多个 C 类网络号可分配给站点。使用 CIDR，未经过预定义的任何地址范围可作为一个类的一部分：但需要一个类似于子网掩码的掩码，有时也称为 CIDR 掩码。CIDR 掩码不再局限于一个站点，而对全球性路由系统都是可见的。因此，除了网络号之外，核心 Internet 路由器必须能解释和处理掩码。这个数字组合称为网络前缀，它用于 IPv4 和 IPv6 地址管理。&lt;/p&gt;
&lt;p&gt;消除一个 IP 地址中网络和主机号的预定义分隔，将使更细粒度的 IP 地址分配范围成为可能。与分类寻址类似，地址空间分割成块最容易通过数值连续的地址来实现，以便用于某种类型或某些特殊用途。目前，这些分组普遍使用地址空间的前缀表示。一个 n 位的前缀是一个地址的前 n 个位的预定义值。对于IPv4， n （前缀长度）的值通常在范围 0 ~ 32 ；对于 IPv6，通常在范围 0 ~ 128。它通常被追加到基本 IP 地址，并且后面跟着一个 &lt;code&gt;/&lt;/code&gt; 字符。表 2-6 给出了一些前缀的例子，以及相应的 IPv4 或 IPv6 地址范围。&lt;/p&gt;
&lt;center&gt;表 2-6 前缀的例子及其相应的 IPv4 或 IPv6 地址范围&lt;/center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;前缀&lt;/th&gt;
&lt;th&gt;前缀（二进制）&lt;/th&gt;
&lt;th&gt;地址范围&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0.0.0.0/0&lt;/td&gt;
&lt;td&gt;00000000 00000000 00000000 00000000&lt;/td&gt;
&lt;td&gt;0.0.0.0 ~ 255.255.255.255&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;128.0.0.0/1&lt;/td&gt;
&lt;td&gt;&lt;b&gt;1&lt;/b&gt;0000000 00000000 00000000 00000000&lt;/td&gt;
&lt;td&gt;128.0.0.0 ~ 255.255.255.255&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;128.0.0.0/24&lt;/td&gt;
&lt;td&gt;&lt;b&gt;10000000 00000000 00000000&lt;/b&gt; 00000000&lt;/td&gt;
&lt;td&gt;128.0.0.0 ~ 128.0.0.255&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;198.128.128.192/27&lt;/td&gt;
&lt;td&gt;&lt;b&gt;11000110 10000000 10000000 1100&lt;/b&gt;0000&lt;/td&gt;
&lt;td&gt;198.128.128.192 ~ 198.128.128.223&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;165.195.130.107/32&lt;/td&gt;
&lt;td&gt;&lt;b&gt;10100101 11000011 100000010 01101011&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;165.195.130.107&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2001:db8::/32&lt;/td&gt;
&lt;td&gt;&lt;b&gt;0010000000000001 0000110110111000&lt;/b&gt; 0000000000000000 0000000000000000 0000000000000000 0000000000000000 0000000000000000 0000000000000000&lt;/td&gt;
&lt;td&gt;2001:db8:: ~ 2001:db8:ffff:ffff&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;在这个表中，由前缀来定义并固定的位被加粗表示。剩余位可设置为 0 和 1 的任意组合，从而涵盖可能的地址范围。显然，一个较小的前缀长度可对应于一个更大的地址范围。另外，早期的分类寻址方案易于被这个方案覆盖。例如， C 类网络号 &lt;code&gt;192.125.3.0&lt;/code&gt; 可以写成前缀 &lt;code&gt;192.125.3.0/24&lt;/code&gt; 或 &lt;code&gt;192.125.3/24&lt;/code&gt;。 分类的 A 类和 B 类网络号可分别用前缀长度 &lt;code&gt;/8&lt;/code&gt; 和 &lt;code&gt;/16&lt;/code&gt; 表示。&lt;/p&gt;
&lt;h3 id=&#34;242-聚合&#34;&gt;2.4.2 聚合&lt;/h3&gt;
&lt;p&gt;通过取消分类结构的 IP 地址，能分配各种尺寸的 IP 地址块。但是，这样做没有解决问题列表中的第三个问题，它并没有帮助减少路由表条目数。一条路由表条目告诉一个路由器向哪里发送流量。从本质上来说，路由器检查每个到达的数据报中的目的 IP 地址，找到一条匹配的路由表条目，并从该条目中提取数据报的“下一跳”。这有点像驾驶汽车去一个特定地址，并在沿路每个路口找到一个标志，指示沿着哪个方向去目的地路线的下一个路口。如果你能理解在每个路口设置很多标志，以指向每个可能的目的地的情形，就能认识到20 世纪 90 年代初 Internet 面临的一些问题。&lt;/p&gt;
&lt;p&gt;当时，没什么技术可以解决以下问题：在维护 Internet中 到所有目的地的最短路径的同时，又能够显著减少路由表条目数。最有名的方法是 20 世纪 70 年代末由 Kleiurock 和 Kamoun 发表的&lt;strong&gt;分层路由研究&lt;/strong&gt; [&lt;a href=&#34;#KK77&#34;&gt;KK77&lt;/a&gt;]。他们发现，如果将网络拓扑排列为一棵树，并且以对这个网络拓扑“敏感的”方式来分配地址，这样可获得一个非常小的路由表，同时保持到所有目的地的最短路径。大家可以看图 2-8 。&lt;/p&gt;
&lt;p&gt;图 2-8 中左侧树的根（顶级）是标记为 &lt;code&gt;19.12.4.8&lt;/code&gt; 的路由器。为了知道每个可能的目的地的下一跳，它需要一个树中在其“下面的”所有路由器的条目：&lt;code&gt;190.16.11.2&lt;/code&gt;、 &lt;code&gt;86.12.0.112&lt;/code&gt;、&lt;code&gt;159.66.2.231&lt;/code&gt;、 &lt;code&gt;133.17.97.12&lt;/code&gt;、 &lt;code&gt;66.103.2.19&lt;/code&gt;、 &lt;code&gt;18.1.1.1&lt;/code&gt;、 &lt;code&gt;19.12.4.9&lt;/code&gt;  &lt;code&gt;203.44.23.198&lt;/code&gt;。 对于任何其他目的地，它只需简单地路由到标有“网络其他部分”的云中。结果共有 9 个条目。相比之下，右侧树的根被标记为 &lt;code&gt;19.0.0.1&lt;/code&gt;，并要求其路由表中只有 3 个条目。注意，右树中左侧的所有路由器以前缀 &lt;code&gt;19.1&lt;/code&gt; 开始，右侧的所有路由器以前缀 &lt;code&gt;19.2&lt;/code&gt; 开始。因此，路由器 &lt;code&gt;19.0.0.1&lt;/code&gt; 的表中只需将以 &lt;code&gt;19.1&lt;/code&gt; 开始的目的地显示下一跳为 &lt;code&gt;19.1.0.1&lt;/code&gt;，而将以 &lt;code&gt;19.2&lt;/code&gt; 开始的目的地显示下一跳为 &lt;code&gt;19.2.0.1&lt;/code&gt;。任何其他目的地都被路由到标有“网络其他部分”的云中。结果共有 3 个条目。注意，这种行为是递归的，图 2-8b 所示树中的任意路由器，需要的条目数都不会超过它拥有的链路数。这是这种特殊的地址分配方法所带来的直接结果。即使越来越多的路由器加人图 2-8b 所示的树，这个良好的属性也保持不变。这是[&lt;a href=&#34;#KK77&#34;&gt;KK77&lt;/a&gt;]的分层路由思想的精髓。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;8&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1650894706114.png&#34; alt=&#34;图 2-8&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 2-8   在树状拓扑网络中，网络地址可采用特殊方式分配，以限制需保存在路由器中的路由信息（“状态”）数量。如果不以这种（左侧的）方式分配地址，没有存储与需到达的节点数量成正比的状态，则最短路径无法得到保证。当以保存状态的树状拓扑敏感的方式分配地址时，如果网络拓扑发生变化，通常需要重新分配地址&lt;/p&gt;
&lt;p&gt;在 Internet 环境中，可采用分层路由思想以一种特定方式减少 Internet 路由条目数。这通过一个称为&lt;strong&gt;路由聚合&lt;/strong&gt;的过程来实现。通过将相邻的多个 IP 前缀合并成一个短前缀（称为一个&lt;strong&gt;聚合&lt;/strong&gt;或&lt;strong&gt;汇聚&lt;/strong&gt;），可以覆盖更多地址空间。我们可以看图 2-9。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;9&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1650897953256.png&#34; alt=&#34;图 2-9&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 2-9   在这个例子中，箭头表示将两个地址前缀聚合为一个，带下划线的前缀是每一步的结果。第一步，&lt;code&gt;190.154.27.0/26&lt;/code&gt; 和 &lt;code&gt;190.154.27.64.0/26&lt;/code&gt; 可以聚合，这是由于它们数值相邻，但是&lt;code&gt;190.154.27.192/26&lt;/code&gt; 不能聚合。通过与 &lt;code&gt;190.154.27.128/26&lt;/code&gt; 相加，它们可经过两步聚合形成&lt;code&gt;190.154.27.0/24&lt;/code&gt;。最后，通过与相邻的 &lt;code&gt;190.154.26.0/24&lt;/code&gt; 相加，生成聚合结果 &lt;code&gt;190.154.26.0/23&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;首先看图 2-9 中左侧的三个地址前缀。前两个（ &lt;code&gt;190.154.27.0/26&lt;/code&gt; 和&lt;code&gt;190.154.27.64/26&lt;/code&gt;）数值相邻，因此可被组合（聚合）。箭头表示聚合发生的地方。前缀 &lt;code&gt;190.154.27.192/26&lt;/code&gt; 不能在第一步被聚合，由于它们并非数值相邻。当增加一个新前缀 &lt;code&gt;190.154.27.128/26&lt;/code&gt; （下划线），前缀 &lt;code&gt;190.154.27.192/26&lt;/code&gt; 和 &lt;code&gt;190.154.27.128/26&lt;/code&gt; 可能被聚合，并形成 &lt;code&gt;190.154.27.128/25&lt;/code&gt; 前缀。这个聚合现在与聚合 &lt;code&gt;190.154.27.0/25&lt;/code&gt; 相邻，因此它们可进一步聚合成 &lt;code&gt;190.154.27.0/24&lt;/code&gt;。当增加前缀 &lt;code&gt;190.154.26.0/24&lt;/code&gt; （下划线），两个 C 类的前缀可以聚合成 &lt;code&gt;190.154.26.0/23&lt;/code&gt;。这样，原来的三个前缀和两个增加的前缀可聚合成一个前缀。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;25-特殊用途地址&#34;&gt;2.5 特殊用途地址&lt;/h2&gt;
&lt;p&gt;IPv4 和 IPv6 地址空间中都包括几个地址范围，它们被用于特殊用途（因此不能用于单播地址分配）。对于 IPv4 ，这些地址显示在表 2-7 中 [&lt;a href=&#34;#RFC5735&#34;&gt;RFC5735&lt;/a&gt;]。&lt;/p&gt;
&lt;center&gt;表 2-7 IPv4 特殊用途地址（定义于 2010 年 1 月）&lt;/center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;前缀&lt;/th&gt;
&lt;th&gt;特殊用途&lt;/th&gt;
&lt;th&gt;参考文献&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0.0.0.0/8&lt;/td&gt;
&lt;td&gt;本地网络中的主机。仅作为源 IP 地址使用&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC1122&#34;&gt;RFC1122&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10.0.0.0/8&lt;/td&gt;
&lt;td&gt;专用网络（内联网）的地址。这种地址不会出现在公共 Internet 中&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC1918&#34;&gt;RFC1918&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;127.0.0.0/8&lt;/td&gt;
&lt;td&gt;Internet 主机回送地址（同一计算机）。通常只用 127.0.0.1&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC1122&#34;&gt;RFC1122&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;169.254.0.0/16&lt;/td&gt;
&lt;td&gt;“链路本地”地址，只用于一条链路，通常自动分配。见第 6 章&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC3927&#34;&gt;RFC3927&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;172.16.0.0/12&lt;/td&gt;
&lt;td&gt;专用网络（内联网）的地址。这种地址不会出现在公共 Internet 中&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC1918&#34;&gt;RFC1918&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;192.0.0.0/24&lt;/td&gt;
&lt;td&gt;IETF 协议分配（IANA 保留）&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC5736&#34;&gt;RFC5736&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;192.0.2.0/24&lt;/td&gt;
&lt;td&gt;批准用于文档中的 TEST-NET-1 地址。这种地址不会出现在公共 Internet 中&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC5737&#34;&gt;RFC5737&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;192.88.99.0/24&lt;/td&gt;
&lt;td&gt;用于 6to4 中继（任播地址）&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC3068&#34;&gt;RFC3068&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;192.168.0.0/16&lt;/td&gt;
&lt;td&gt;专用网络（内联网）的地址。这种地址不会出现在公共 Internet 中&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC1918&#34;&gt;RFC1918&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;192.18.0.0/15&lt;/td&gt;
&lt;td&gt;用于基准和性能测试&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2544&#34;&gt;RFC2544&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;198.51.100.0/24&lt;/td&gt;
&lt;td&gt;TEST-NET-2 地址。被批准用于文档中&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC5737&#34;&gt;RFC5737&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;203.0.113.0/24&lt;/td&gt;
&lt;td&gt;TEST-NET-3 地址。被批准用于文档中&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC5737&#34;&gt;RFC5737&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;224.0.0.0/4&lt;/td&gt;
&lt;td&gt;IPv4 组播地址（以前的 D 类），仅作为目的 IP 地址使用&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC5771&#34;&gt;RFC5771&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;240.0.0.0/4&lt;/td&gt;
&lt;td&gt;保留空间（以前的 E 类），除了 255.255.255.255&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC1112&#34;&gt;RFC1112&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;255.255.255.255/32&lt;/td&gt;
&lt;td&gt;本地网络（受限的）广播地址&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC0919&#34;&gt;RFC0919&lt;/a&gt;] [&lt;a href=&#34;#RFC9022&#34;&gt;RFC9022&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;在 IPv6 中，许多地址范围和个别地址用于特定用途，它们都列在表 2-8 中 [&lt;a href=&#34;#RFC5156&#34;&gt;RFC5156&lt;/a&gt;]。&lt;/p&gt;
&lt;center&gt;表 2-8 IPv6 特殊用途地址（定义于 2008 年 4 月）&lt;/center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;前缀&lt;/th&gt;
&lt;th&gt;特殊用途&lt;/th&gt;
&lt;th&gt;参考文献&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;::/0&lt;/td&gt;
&lt;td&gt;默认路由条目。不用于寻址&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC5156&#34;&gt;RFC5156&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;::/128&lt;/td&gt;
&lt;td&gt;未指定地址，可作为源 IP 地址使用&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;RFC4291&#34;&gt;RFC4291&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;::1/128&lt;/td&gt;
&lt;td&gt;IPv6 主机回送地址，不用于发送出本地主机的数据报中&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;RFC4291&#34;&gt;RFC4291&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;::ffff:0:0/96&lt;/td&gt;
&lt;td&gt;IPv4 映射地址。这种地址不会出现在分组头部，只用于内部主机&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;RFC4291&#34;&gt;RFC4291&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;::{ipv4-address}/96&lt;/td&gt;
&lt;td&gt;IPv4 兼容地址。已过时，未使用&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;RFC4291&#34;&gt;RFC4291&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2001::/32&lt;/td&gt;
&lt;td&gt;Teredo 地址&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC4380&#34;&gt;RFC4380&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2001:10::/28&lt;/td&gt;
&lt;td&gt;ORCHI（覆盖可路由加密散列标识符）。这种地址不会出现在公共 Internet 中&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC4843&#34;&gt;RFC4843&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2001:db8::/32&lt;/td&gt;
&lt;td&gt;用于文档和实例的地址范围。这种地址不会出现在公共 Internet 中&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC3849&#34;&gt;RFC3849&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2002::/16&lt;/td&gt;
&lt;td&gt;6to4 隧道中继的 6to4 地址&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC3056&#34;&gt;RFC3056&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3ffe::/16&lt;/td&gt;
&lt;td&gt;用于 6bone 实验。已过时，未使用&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC3701&#34;&gt;RFC3701&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5f00::/16&lt;/td&gt;
&lt;td&gt;用于 6bone 实验。已过时，未使用&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC3701&#34;&gt;RFC3701&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;fc00::7&lt;/td&gt;
&lt;td&gt;唯一的本地单播地址，不用于全球性 Internet&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC4193&#34;&gt;RFC4193&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;fe80::/10&lt;/td&gt;
&lt;td&gt;链路本地单播地址&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;RFC4291&#34;&gt;RFC4291&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ff00::/8&lt;/td&gt;
&lt;td&gt;IPv6 组播地址，仅作为目的 IP 地址使用&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;RFC4291&#34;&gt;RFC4291&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;对于 IPv4 和 IPv6，没有指定作为特殊、组播或保留地址的地址范围可供单播使用。一些单播地址空间（IPv4 的前缀 &lt;code&gt;10/8&lt;/code&gt;、 &lt;code&gt;172.16/12&lt;/code&gt; 和 &lt;code&gt;192.168/16&lt;/code&gt;，以及 IPv6 的前缀 &lt;code&gt;fc00::/7&lt;/code&gt;） 被保留用于构建专用网络。来自这些范围的地址可用于一个站点或组织内部的主机和路由器之间的通信，但不能跨越全球性的 Internet。因此，这些地址有时也被称为不可路由的地址。也就是说，它们不能在公共 Internet 中路由。&lt;/p&gt;
&lt;p&gt;专用、不可路由的地址空间管理完全由本地决定。IPv4 专用地址在家庭网络、中等规模和大型企业内部网络中很常见。它们经常与网络地址转换（NAT）结合使用，在 IP 数据报进入 Internet 时修改其中的 IP 地址。我们在第 7 章详细讨论 NAT。&lt;/p&gt;
&lt;h3 id=&#34;251-ipv4ipv6-地址转换&#34;&gt;2.5.1 IPv4/IPv6 地址转换&lt;/h3&gt;
&lt;p&gt;在有些网络中，可能需要在 IPv4 和 IPv6 之间转换 [&lt;a href=&#34;#RFC6127&#34;&gt;RFC6127&lt;/a&gt;]。目前，已制定了一个用于单播转换的框架 [&lt;a href=&#34;#RFC6144&#34;&gt;RFC6144&lt;/a&gt;]，以及一个正在开发的用于组播转换的方案 [&lt;a href=&#34;#IDv-4v6mc&#34;&gt;IDv 4v6mc&lt;/a&gt;]。一个基本功能是提供自动、基于算法的地址转换。例如，使用“知名的” IPv6 前缀 &lt;code&gt;64:ff9b::/96&lt;/code&gt;或其他指定前缀， [&lt;a href=&#34;#RFC6052&#34;&gt;RFC6052&lt;/a&gt;] 定义了如何在单播地址中实现它。&lt;/p&gt;
&lt;p&gt;该方案使用一种特殊地址格式，称为&lt;strong&gt;嵌入 IPv4 的 IPv6 地址&lt;/strong&gt;。这种地址在 IPv6 地址内部包含 IPv4 地址。它可采用 6 种格式之一来编码， IPv6 前缀长度必须是下列数值之一：32、&lt;br&gt;
40、 48、 56、 64 或 96。图 2-10 显示了可用的格式。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;10&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1650940609621.png&#34; alt=&#34;图 2-10&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 2-10   IPv4 地址可以嵌人 IPv6 地址中，形成一个嵌入 IPv4 的 IPv6 地址。有 6 种不同的格式可用，这取决于使用的 IPv6 前缀长度。众所周知的前缀（Well-Known Prefix） &lt;code&gt;64:ff9b::/96&lt;/code&gt; 可用于 IPv4 和 IPv6 单播地址之间的自动转换&lt;/p&gt;
&lt;p&gt;在该图中，前缀既可以是一个众所周知的前缀，也可以是组织为转换器分配的唯一前缀。第 64 至 71 位必须设置为 0，以保持与 [&lt;a href=&#34;#RFC4291&#34;&gt;RFC4291&lt;/a&gt;] 指定标识符的兼容性。后缀的位被保留，并且应设置为 00 然后，采用简单方法来生成嵌入 IPv4 的 IPv6 地址：将 IPv6 前缀与 32 位的 IPv4 地址相串联，并确保第 64 至 71 位被设置为 0 （如果有必要，插入）。在后缀的后面增加 0，直到生成一个 128 位地址。嵌入 IPv4 的 IPv6 地址使用 96 位前缀选项，该选项通常用前面提到的 IPv6 映射地址来表示（ [&lt;a href=&#34;#RFC4291&#34;&gt;RFC4291&lt;/a&gt;]中的 2.2(3) 节）。例如，嵌入 IPv4 地址 &lt;code&gt;198.51.100.16&lt;/code&gt; 和众所周知的前缀，生成地址 &lt;code&gt;64:ff9b::198.51.100.16&lt;/code&gt;。&lt;/p&gt;
&lt;h3 id=&#34;252-组播地址&#34;&gt;2.5.2 组播地址&lt;/h3&gt;
&lt;p&gt;IPv4 和 IPv6 支持组播寻址。一个 IP 组播地址（也称为&lt;strong&gt;组&lt;/strong&gt;或&lt;strong&gt;组地址&lt;/strong&gt;）标识一组主机接口，而不是单个接口。一般来说，一个组可以跨越整个 Internet。一个组所覆盖的网络部分称为组的&lt;strong&gt;范围&lt;/strong&gt; [&lt;a href=&#34;#RFC2365&#34;&gt;RFC2365&lt;/a&gt;]。常见的范围包括&lt;strong&gt;节点本地&lt;/strong&gt;（同一计算机）、&lt;strong&gt;链路本地&lt;/strong&gt;（同一子网）、&lt;strong&gt;站点本地&lt;/strong&gt;（适用于一些站点）、&lt;strong&gt;全球&lt;/strong&gt;（整个Internet）和&lt;strong&gt;管理&lt;/strong&gt;。管理范围的地址可用于一个网络区域内已手动配置到路由器的地址。站点管理员可将路由器配置为&lt;strong&gt;管理范围边界&lt;/strong&gt;，这意味着相关组的组播流量不会被路由器转发。注意，站点本地和管理范围只在使用组播寻址时有效。&lt;/p&gt;
&lt;p&gt;在软件的控制下，每个 Internet 主机中的协议栈能加入或离开一个组播组。当一台主机向一个组发送数据时，它会创建一个数据报，使用（单播） IP 地址作为源地址，使用组播 IP 地址作为目的地址。已加入组的所有主机将接收发送到该组的任何数据报。发送方通常不知道主机是否接收到数据报，除非它们明确做出应答。事实上，发送方甚至不知道通常有多少台主机接收它的数据报。&lt;/p&gt;
&lt;p&gt;至此，原有的组播服务模型已成为大家所知的&lt;strong&gt;任意源组播（ASM）&lt;/strong&gt;。在这种模型下，任何发送方可以发送给任何组；一个加入组的接收方被指定唯一的组地址。一种新方案称为&lt;strong&gt;源特定组播（SSM）&lt;/strong&gt; [&lt;a href=&#34;#RFC3569&#34;&gt;RFC3569&lt;/a&gt;][&lt;a href=&#34;#RFC4607&#34;&gt;RFC4607&lt;/a&gt;]，在每个组中只使用一个发送方（见 [&lt;a href=&#34;#RFC4607&#34;&gt;RFC4607&lt;/a&gt;] 的勘误表）。在这种情况下，当一台主机加入一个组后，它会被指定一个信道地址，其中包括一个组地址和一个源 IP 地址。 SSM 避免了 ASM 模型部署时的复杂性。尽管有多种组播形式在整个 Internet 中广泛使用，但 SSM 是当前更受欢迎的候选者。&lt;/p&gt;
&lt;p&gt;在 Internet 社区中，对广域组播的理解和实现已经过十年以上的不懈努力，并且已经开发出大量的广域组播协议。全球性 Internet 组播如何工作的细节超出本文的范围，有兴趣的读者可以查看 [&lt;a href=&#34;#IMRO2&#34;&gt;IMRO2&lt;/a&gt;]。第 9 章详细介绍本地 IP 组播如何工作。现在，我们要讨论 IPv4 和 IPv6 组播地址的格式和意义。&lt;/p&gt;
&lt;h3 id=&#34;253-ipv4-组播地址&#34;&gt;2.5.3 IPv4 组播地址&lt;/h3&gt;
&lt;p&gt;对于 IPv4， D 类空间（&lt;code&gt;224.0.0.0 ~ 239.255.255.255&lt;/code&gt;）已被保留支持组播。 28 位空闲意味着可提供 2&lt;sup&gt;28&lt;/sup&gt;= 268 435 456 个主机组（每个组是一个 IP 地址）。这个地址空间被分为几个主要部分，它建立在对路由分配和处理的基础上 [&lt;a href=&#34;#IP4MA&#34;&gt;IP4MA&lt;/a&gt;]。表 2-9 列出了这些主要部分。&lt;/p&gt;
&lt;center&gt;表 2-9  用于支持组播的 IPv4 的 D 类地址空间的主要部分&lt;/center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;范围（包含）&lt;/th&gt;
&lt;th&gt;特殊用途&lt;/th&gt;
&lt;th&gt;参考文献&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;224.0.0.0 ~ 224.0.0.255&lt;/td&gt;
&lt;td&gt;本地网络控制；不转发&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC5771&#34;&gt;RFC5771&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;224.0.1.0 ~ 224.0.1.255&lt;/td&gt;
&lt;td&gt;互联网络控制；正常转发&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC5771&#34;&gt;RFC5771&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;224.0.2.0 ~ 224.0.255.255&lt;/td&gt;
&lt;td&gt;Ad hoc 块 1&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC5771&#34;&gt;RFC5771&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;224.1.0.0 ~ 224.1.255.255&lt;/td&gt;
&lt;td&gt;保留&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC5771&#34;&gt;RFC5771&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;224.2.0.0 ~ 224.2.255.255&lt;/td&gt;
&lt;td&gt;SDP/SAP&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC4566&#34;&gt;RFC4566&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;224.3.0.0 ~ 224.3.255.255&lt;/td&gt;
&lt;td&gt;Ad hoc 块 2&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC5771&#34;&gt;RFC5771&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;224.5.0.0 ~ 224.255.255.255&lt;/td&gt;
&lt;td&gt;保留&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#IP4MA&#34;&gt;IP4MA&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;225.0.0.0 ~ 231.255.255.255&lt;/td&gt;
&lt;td&gt;保留&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#IP4MA&#34;&gt;IP4MA&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;232.0.0.0 ~ 232.255.255.255&lt;/td&gt;
&lt;td&gt;源特定组播（SSM）&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC4607&#34;&gt;RFC4607&lt;/a&gt;] [&lt;a href=&#34;#RFC4608&#34;&gt;RFC4608&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;233.0.0.0 ~ 233.251.255.255&lt;/td&gt;
&lt;td&gt;GLOP&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC3180&#34;&gt;RFC3180&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;233.252.0.0 ~ 233.255.255.255&lt;/td&gt;
&lt;td&gt;Ad hoc 块 3（233.252.0.0/24 为文档保留）&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC5771&#34;&gt;RFC5771&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;234.0.0.0 ~ 234.255.255.255 &lt;br/&gt;235.0.0.0 ~ 238.255.255.255&lt;/td&gt;
&lt;td&gt;基于单播前缀的 IPv4 组播地址保留&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC6034&#34;&gt;RFC6034&lt;/a&gt;] [&lt;a href=&#34;#IP4MA&#34;&gt;IP4MA&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;239.0.0.0 ~ 239.255.255.255&lt;/td&gt;
&lt;td&gt;管理范围&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2365&#34;&gt;RFC2365&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;到 &lt;code&gt;224.255.255.255&lt;/code&gt; 的地址块被分配给某些应用协议或组织使用。这些分配工作由 IANA 或 IETF 完成。本地网络控制块限制为发送方的本地网络；发送到这些地址的数据报不会被组播路由器转发。 “所有主机”组（&lt;code&gt;224.0.0.1&lt;/code&gt;）是这个块中的一个组。互联网络控制块类似于本地网络控制范围，其目的是控制需要被路由到本地链路的流量。该地址块的一个例子是网络时间协议（NTP）组播组（&lt;code&gt;224.0.1.1&lt;/code&gt;） [&lt;a href=&#34;#RFC5905&#34;&gt;RFC5905&lt;/a&gt;]。&lt;/p&gt;
&lt;p&gt;第一个 Ad hoc（特定）块用于保留一些地址，避免它们落人本地或互联网络控制块。在此范围内的大多数分配是用于商业服务，其中一些不（或永远不）需要全球地址分配；它们可能最终被返还以支持 GLOP 寻址（见下一段落）。在 SDP/ SAP 块中包含某些应用所使用的地址，例如会话目录工具（SDR） [&lt;a href=&#34;#H96&#34;&gt;H96&lt;/a&gt;]，它使用&lt;strong&gt;会话通告协议（SAP）&lt;strong&gt;发送组播会议通告 [&lt;a href=&#34;#RFC2974&#34;&gt;RFC2974&lt;/a&gt;]。新的&lt;/strong&gt;会话描述协议（SDP）&lt;/strong&gt; [&lt;a href=&#34;#RFC4566&#34;&gt;RFC4566&lt;/a&gt;]最初只是 SAP 的一个组成部分，当前它不仅用于 IP 组播，而且与其他机制一起描述多媒体会话。&lt;/p&gt;
&lt;p&gt;其他主要地址块的出现稍晚于 IP 组播的演变。如前面所述，某些应用使用 SSM 块实现 SSM，结合自已的单播源地址形成一个 SSM 信道。在 GLOP 块中，组播地址基于主机的**自治系统（AS）**号，该主机处于应用分配地址的一端。 AS 号用于 ISP 之间的 Internet 范围的路由协议，以聚合路由器和实现路由策略。 AS 号最初是 16 位，但现在已扩展到 32 位 [&lt;a href=&#34;#RFC4893&#34;&gt;RFC4893&lt;/a&gt;]。GLOP 地址的生成是将一个 16 位 AS 号放在 IPv4 组播地址的第 2 和第 3 字节，并且保留 1 字节的空间表示可能的组播地址（即多达 256 个地址）。因此，它可在一个 16 位 AS 号和与这个 AS 号相关联的 GLOP 组播地址之间来回映射。这个计算过程很简单，目前已开发出几个在线计算器。&lt;/p&gt;
&lt;p&gt;最近， IPv4 组播地址分配机制将多个组播地址与一个 IPv4 单播地址前缀关联。这被称为基于&lt;strong&gt;单播前缀的组播&lt;/strong&gt;寻址（UBM），它在 [&lt;a href=&#34;#RFC6034&#34;&gt;RFC6034&lt;/a&gt;] 中描述。它基于 IPv6 发展早期的一个类似结构，我们在前面 2.5.4 节讨论过。 UBM 的 IPv4 地址范围是 &lt;code&gt;234.0.0.0&lt;/code&gt; 至  &lt;code&gt;234.255.255.255&lt;/code&gt;。单播地址需分配一个 &lt;code&gt;/24&lt;/code&gt; 或更短的前缀以使用 UBM 地址。分配更短的地&lt;br&gt;
址（即 &lt;code&gt;/25&lt;/code&gt; 或更长的前缀）必须使用一些其他机制。 UBM 地址被构造成前缀 &lt;code&gt;234/8&lt;/code&gt;、分配的&lt;br&gt;
单播前缀和组播组 ID 的串联。图 2-11 显示了这个格式。&lt;/p&gt;
&lt;p&gt;为了确定与一个单播分配相关的 UBM 地址，分配前缀只是简单地在前面添加前缀 &lt;code&gt;234/8&lt;/code&gt;。例如，单播 IPv4 地址前缀 &lt;code&gt;192.0.2.0/24&lt;/code&gt; 有一个关联的 UBM 地址 &lt;code&gt;234.192.0.2&lt;/code&gt;。 通过对组播地址简单地“左平移” 8 位，有可能确定一个组播地址的所有者。例如，我们知道组播地址范围 &lt;code&gt;234.128.32.0/24&lt;/code&gt; 被分配给加州大学伯克利分校，这是由于相应的单播 IPv4 地址空间 &lt;code&gt;128.32.0.0/16&lt;/code&gt; （&lt;code&gt;234.128.32.0&lt;/code&gt; 的“左移”版本）是由加州大学伯克利分校所拥有(可以使用 WHOIS 查询来确定，见 2.6.1.1 节)。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;11&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1651033894464.png&#34; alt=&#34;图 2-11&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 2-11   IPv4 的 UBM 地址格式。为单播地址分配 &lt;code&gt;/24&lt;/code&gt; 或更短的前缀，关联的组播地址分配基于前缀 &lt;code&gt;234/8&lt;/code&gt;、分配的单播前缀和组播组 ID 的串联。因此，较短的单播前缀分配包含更多单播和组&lt;br&gt;
播地址&lt;/p&gt;
&lt;p&gt;UBM 地址比其他类型的组播地址分配有更多优点。例如，用于 GLOP 寻址时，它们可以不受 16 位 AS 号限制。另外，它们可作为已存在的单播地址空间的分配结果。因此，使用组播地址的站点知道哪些地址可用，并且不需要进一步协调。最后， UBM 地址可以比 GLOP 地址更好地分配，对应的 AS 号可分配到更细粒度。在今天的 Internet 中，一个 AS 号可以与多个站点关联，但令人沮丧的是 UBM 支持在地址和所有者之间的简单映射。&lt;/p&gt;
&lt;p&gt;管理范围的地址块可用于限制分布在路由器和主机的特定集合中的组播流量。它可以看作组播对专用单播 IP 地址的模拟。这种地址不能用于将组播分发到 Internet，这是因为其中大多数流量被阻塞在企业边界。大型站点有时会划分管理范围的组播地址，以用于某些特定范围（例如，工作组、部门和地理区域）。&lt;/p&gt;
&lt;h3 id=&#34;254-ipv6-组播地址&#34;&gt;2.5.4 IPv6 组播地址&lt;/h3&gt;
&lt;p&gt;对于 IPv6，对组播的使用相当积极，前缀 &lt;code&gt;ff00::/8&lt;/code&gt; 已被预留给组播地址，并且 112 位可用于保存组号，可提供的组数为 2&lt;sup&gt;112&lt;/sup&gt;= 5 192 296 858 534 827 628 530 496 329 220 096。其一般格式如图 2-12 所示。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;12&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1651035439616.png&#34; alt=&#34;图 2-12&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 2-12   基本的 IPv6 组播地址格式包括 4 个标志位（0，保留； R，包含会合点； P，使用单播前缀； T，是临时的）。 4 位范围值表示组播的范围（全球、本地等）。组 ID 编码在低序的 112 位中。如果 P 或 R 位被设置，则使用一种代替格式&lt;/p&gt;
&lt;p&gt;IPv6 组播地址的第 2 字节包含一个 4 位标志字段和一个 4 位&lt;strong&gt;范围&lt;/strong&gt; ID 字段。范围字段表示到某些组播地址的数据报的分配限制。十六进制值 0、3 和 f 保留。十六进制值 6、 7 和 9 ~ d未分配。表 2-10 给出了这些值（根据 [&lt;a href=&#34;#RFC4291&#34;&gt;RFC4291&lt;/a&gt;] 中的2.7节）。&lt;/p&gt;
&lt;center&gt;表 2-10  IPv6 范围字段的值 &lt;/center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;值&lt;/th&gt;
&lt;th&gt;范围&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;保留&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;接口/机器本地&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;链路/子网本地&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;保留&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;管理&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;站点本地&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;6 ~ 7&lt;/td&gt;
&lt;td&gt;未分配&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;组织本地&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;9 ~ d&lt;/td&gt;
&lt;td&gt;未分配&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;e&lt;/td&gt;
&lt;td&gt;全球&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;f&lt;/td&gt;
&lt;td&gt;保留&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;很多 IPv6 组播地址由 IANA 分配为永久使用，并且故意跨越多个地址范围。这些组播地址对每个范围都有一定偏移量（由于这个原因，这些地址被称为&lt;strong&gt;相对范围&lt;/strong&gt;或&lt;strong&gt;可变范围&lt;/strong&gt;）。例如，可变范围的组播地址：&lt;code&gt;ff0x::101&lt;/code&gt; 是由 [&lt;a href=&#34;#IP6MA&#34;&gt;IP6MA&lt;/a&gt;] 为 NTP 服务器预留。 &lt;code&gt;x&lt;/code&gt; 表示可变范围，表 2-11 显示了一些预留定义的地址。&lt;/p&gt;
&lt;center&gt;表 2-11  针对 NTP （101）的永久可变范围的 IPv6 组播地址保留的例子 &lt;/center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;地址&lt;/th&gt;
&lt;th&gt;含义&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;ff01::101&lt;/td&gt;
&lt;td&gt;同一机器中的所有 NTP 服务器&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ff02::101&lt;/td&gt;
&lt;td&gt;同一链路/子网中的所有 NTP 服务器&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ff04::101&lt;/td&gt;
&lt;td&gt;某些管理定义范围内的所有 NTP 服务器&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ff05:101&lt;/td&gt;
&lt;td&gt;同一站点中的所有 NTP 服务器&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ff08::101&lt;/td&gt;
&lt;td&gt;同一组织中的所有 NTP 服务器&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ff0e::101&lt;/td&gt;
&lt;td&gt;Internet 中的所有 NTP 服务器&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;在 IPv6 中，当 P 和 R 位字段设置为 0 时，使用图 2-12 中给出的组播地址格式。当 P 设置为 1，无须基于每个组的全球性许可，对组播地址有两个可选方法。它们被描述在 [&lt;a href=&#34;#RFC3306&#34;&gt;RFC3306&lt;/a&gt;] 和 [&lt;a href=&#34;#RFC4489&#34;&gt;RFC4489&lt;/a&gt;] 中。第一种方法称为&lt;strong&gt;基于单播前缀&lt;/strong&gt;的 IPv6 组播地址分配，由 ISP 或地址分配机构提供单播前缀分配，并且有效分配一个组播地址集合，从而限制了因避免重复而需全球协调的数量。第二种方法称为&lt;strong&gt;链路范围&lt;/strong&gt;的 IPv6 组播，使用接口标识符，并且组播地址是基于主机的 IID。为了了解这些不同格式如何工作，首先要了解 IPv6 组播地址中位字段的使用细节。它们被定义在表 2-12 中。&lt;/p&gt;
&lt;center&gt;表 2-12  IPv6 组播地址标志 &lt;/center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;位字段（标志）&lt;/th&gt;
&lt;th&gt;含义&lt;/th&gt;
&lt;th&gt;参考文献&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;R&lt;/td&gt;
&lt;td&gt;会合点标志（0，常规的；1，包括 RP 地址）&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC3956&#34;&gt;RFC3956&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;P&lt;/td&gt;
&lt;td&gt;前缀标志（0，常规的；1，基于单播前缀的地址）&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC3306&#34;&gt;RFC3306&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;T&lt;/td&gt;
&lt;td&gt;临时标志（0，永久分配的；1，临时的）&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC4291&#34;&gt;RFC4291&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;当 T 位字段被设置时，表示组地址是临时或动态分配的；它不是 [&lt;a href=&#34;#IP6MA&#34;&gt;IP6MA&lt;/a&gt;] 中定义的标准地址。当 P 位字段被设置为 1， T 位也必须被设置为 1 。 当这种情况发生时，使用基于单播地址前缀的特殊格式的 IPv6 组播地址，如图 2-13 所示。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;13&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1651040916674.png&#34; alt=&#34;图 2-13&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 2-13  IPv6 组 播地址可以基于单播 IPv6 地址来创建 [&lt;a href=&#34;#RFC3306&#34;&gt;RFC3306&lt;/a&gt;]。在这样做时， P 位字段设置为 1，单播前缀和 32 位的组 ID 被加入地址。这种形式的组播地址分配简少了全球地址分配协议的需求&lt;/p&gt;
&lt;p&gt;这里，我们可以看到如何使用基于单播前缀的地址改变组播地址格式，包括一个单播前缀及其长度，以及一个更小的（32 位）组 ID。该方案的目的是提供全球唯一的 IPv6 组播地址分配方式，同时不需要提出新的全球性机制。由于 IPv6 单播地址已分配全球性的前缀单元（见 2.6 节），所以在组播地址中可以使用这个前缀中的位，从而在组播应用中利用现有的单播地址分配方法。例如，一个组织分配了一个单播前缀 &lt;code&gt;3ffe:ffff:1::/48&lt;/code&gt;，那么它随之分配了一个基于单播的组播前缀 &lt;code&gt;ff3x:30:3ffe:ffff:1::/96&lt;/code&gt;，其中 &lt;code&gt;x&lt;/code&gt; 是任何有效范围。 SSM 通过设置前缀长度和将前缀字段设置为 0 来支持这种格式，以便有效地将前缀 &lt;code&gt;ffx::/32&lt;/code&gt; （其中 &lt;code&gt;x&lt;/code&gt; 是任何有效的范围值）用于所有这类 IPv6 SSM 组播地址。&lt;/p&gt;
&lt;p&gt;为了创建唯一的链路本地范围的组播地址，可使用一种基于 IID 的方法 [&lt;a href=&#34;#RFC4489&#34;&gt;RFC4489&lt;/a&gt;]，当只需要链路本地范围时，这种方法是基于单播前缀分配的首选。在这种情况下，可使用另一种形式的 IPv6 组播地址结构（见图 2-14 ）。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;14&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1651042022256.png&#34; alt=&#34;图 2-14&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 2-14   IPv6 链路范围的组播地址格式。只适用于链路（或更小）范围内的地址，组播地址可以结合 IPv6 接口 ID 和组 ID 来形成。这种映射是直接的，所有地址使用前缀形式 &lt;code&gt;ff3:0011/32&lt;/code&gt;，其中 &lt;code&gt;x&lt;/code&gt; 是范围 ID 并且小于 3&lt;/p&gt;
&lt;p&gt;图 2-14 所示的地址格式与图 2-13 的格式相似，除了&lt;strong&gt;前缀长度&lt;/strong&gt;字段被设置为 255，并将随后字段中的前缀替换为 IPv6 的 IID。这个结构的优点是不需要提供前缀以形成组播地址。在不需要路由器的 Ad hoc（无线自组织）网络中，一台单独的计算机可基于自已的 IID 形成唯一的组播地址，而无须运行一个复杂的许可协议。如前所述，这种格式只适用于本地链路或节点组播范围。但是，当需要更大的范围时，无论是基于单播前缀的地址还是永久组播地址都可使用。作为这种格式的一个例子，一个 IID &lt;code&gt;02-11-22-33-44-55-66-77&lt;/code&gt; 的主机将使用 组播地址  &lt;code&gt;ff3x:0011:0211:2233:4455:6677:gggg:gggg&lt;/code&gt;，其中 &lt;code&gt;x&lt;/code&gt; 是一个等于或小于 2 的范围值， &lt;code&gt;gggg:gggg&lt;/code&gt; 是一个 32 位组播组 ID 的十六进制表示。&lt;/p&gt;
&lt;p&gt;我们还要讨论的位字段是 R 位字段。当使用基于单播前缀的地址（P 位被设置）时，它表示组播路由协议需要知道一个会合点。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;注意   会合点（RP）是一个路由器中用于处理一个或多个组播组的组播路由的 IP 地址。 RP 用于
PIM-SM协议 [RFC4601]，以帮助参加同一组播组中的发送方和接收方找到对方。 Internet 范围
的组播部署遇到的问题之一是会合点定位。这种方法重载 IPv6 组播地址以包含一个 RP 地址。因
此，从一个组地址找到一个 RP 是简单的，只需从中选择合适的位的子集。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;当标志 P 被设置时，图 2-15 显示了组播地址修改后的格式。&lt;/p&gt;
&lt;p&gt;图 2-15 所示的格式与图 2-13 类似，但不使用 SSM （这样前缀长度不能为零）。另外，新引入了一个称为 RIID 的 4 位字段。为了形成图 2-15 所示格式的基于 RP 地址的 IPv6 地址，前缀长度字段表示的位数从前缀字段提取，并放置在一个新的 IPv6 地址的高位。然后，RIID 字段值被用作 RP 地址的低 4 位。剩余的部分用零填充。作为一个例子，我们看一个组播地址&lt;code&gt;ff75:940:2001:db8:dead:beef:f00d:face&lt;/code&gt;。在这个例子中，范围为 5 （站点本地）， RIID 字段值为 9，前缀长度为 &lt;code&gt;0x40 = 64&lt;/code&gt; 位。因此，前缀本身为 &lt;code&gt;2001:db8‥dead:beef&lt;/code&gt;， RP 地址为 &lt;code&gt;2001‥db8:dead:beef::9&lt;/code&gt;。更多的例子见 [&lt;a href=&#34;#RFC3956&#34;&gt;RFC3956&lt;/a&gt;]。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;15&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1651043845441.png&#34; alt=&#34;图 2-15&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 2-15   RP 的单播 IPv6 地址可以嵌入 IPv6 组播地址 [&lt;a href=&#34;#RFC3956&#34;&gt;RFC3956&lt;/a&gt;]。56]。这样，它可以直接找到用于路由的 RP 关联的地址。RP 被用于组播路由系统，以协调不在同一子网中的组播发送方和接收方&lt;/p&gt;
&lt;p&gt;与 IPv4 相似， IPv6 也有一些保留的组播地址。除了前面提到的可变范围地址，这些地址还根据范围划分成组。表 2-13 给出了一个 IPv6 组播空间中的保留列表。 [&lt;a href=&#34;#IP6MA&#34;&gt;IP6MA&lt;/a&gt;] 提供了更多的信息。&lt;/p&gt;
&lt;center&gt;表 2-13   IPv6 组播地址空间中的保留地址&lt;/center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;地址&lt;/th&gt;
&lt;th&gt;范围&lt;/th&gt;
&lt;th&gt;特殊用途&lt;/th&gt;
&lt;th&gt;参考文献&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;ff01::1&lt;/td&gt;
&lt;td&gt;节点&lt;/td&gt;
&lt;td&gt;所有节点&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC4291&#34;&gt;RFC4291&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ff01::2&lt;/td&gt;
&lt;td&gt;节点&lt;/td&gt;
&lt;td&gt;所有路由器&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC4291&#34;&gt;RFC4291&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ff01::fb&lt;/td&gt;
&lt;td&gt;节点&lt;/td&gt;
&lt;td&gt;mDNSv6&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#IDChes&#34;&gt;IDChes&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ff02::1&lt;/td&gt;
&lt;td&gt;链路&lt;/td&gt;
&lt;td&gt;所有节点&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC4291&#34;&gt;RFC4291&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ff02::2&lt;/td&gt;
&lt;td&gt;链路&lt;/td&gt;
&lt;td&gt;所有路由器&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC4291&#34;&gt;RFC4291&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ff02::4&lt;/td&gt;
&lt;td&gt;链路&lt;/td&gt;
&lt;td&gt;DVMRP 路由器&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC1075&#34;&gt;RFC1075&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ff02::5&lt;/td&gt;
&lt;td&gt;链路&lt;/td&gt;
&lt;td&gt;OSPFIGP&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2328&#34;&gt;RFC2328&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ff02::6&lt;/td&gt;
&lt;td&gt;链路&lt;/td&gt;
&lt;td&gt;基于 OSPFIGP 设计的路由器&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2328&#34;&gt;RFC2328&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ff02::9&lt;/td&gt;
&lt;td&gt;链路&lt;/td&gt;
&lt;td&gt;RIPng 路由器&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC2080&#34;&gt;RFC2080&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ff02::a&lt;/td&gt;
&lt;td&gt;链路&lt;/td&gt;
&lt;td&gt;EIGRP 路由器&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#EIGRP&#34;&gt;EIGRP&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ff02::d&lt;/td&gt;
&lt;td&gt;链路&lt;/td&gt;
&lt;td&gt;PIM 路由器&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC5059&#34;&gt;RFC5059&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ff02::16&lt;/td&gt;
&lt;td&gt;链路&lt;/td&gt;
&lt;td&gt;支持 MLDv2 的路由器&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC3810&#34;&gt;RFC3810&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ff02::6a&lt;/td&gt;
&lt;td&gt;链路&lt;/td&gt;
&lt;td&gt;所有探测器&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC4286&#34;&gt;RFC4286&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ff02::6d&lt;/td&gt;
&lt;td&gt;链路&lt;/td&gt;
&lt;td&gt;LL-MANET 路由器&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC5498&#34;&gt;RFC5498&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ff02::fb&lt;/td&gt;
&lt;td&gt;链路&lt;/td&gt;
&lt;td&gt;mDNSv6&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#IDChes&#34;&gt;IDChes&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ff02::1:2&lt;/td&gt;
&lt;td&gt;链路&lt;/td&gt;
&lt;td&gt;所有 DHCP 代理&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC3315&#34;&gt;RFC3315&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ff02::1:3&lt;/td&gt;
&lt;td&gt;链路&lt;/td&gt;
&lt;td&gt;LLMNR&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC4795&#34;&gt;RFC4795&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ff02::1:ffxx:xxxx&lt;/td&gt;
&lt;td&gt;链路&lt;/td&gt;
&lt;td&gt;请求节点地址范围&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC4291&#34;&gt;RFC4291&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ff05::2&lt;/td&gt;
&lt;td&gt;站点&lt;/td&gt;
&lt;td&gt;所有路由器&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC4291&#34;&gt;RFC4291&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ff05::fb&lt;/td&gt;
&lt;td&gt;站点&lt;/td&gt;
&lt;td&gt;mDNSv6&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#IDChes&#34;&gt;IDChes&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ff05::1:3&lt;/td&gt;
&lt;td&gt;站点&lt;/td&gt;
&lt;td&gt;所有 DHCP 服务器&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC3315&#34;&gt;RFC3315&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ff0x::&lt;/td&gt;
&lt;td&gt;可变的&lt;/td&gt;
&lt;td&gt;保留&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC4291&#34;&gt;RFC4291&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ff0x::fb&lt;/td&gt;
&lt;td&gt;可变的&lt;/td&gt;
&lt;td&gt;mDNSv6&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#IDChes&#34;&gt;IDChes&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ff0x::101&lt;/td&gt;
&lt;td&gt;可变的&lt;/td&gt;
&lt;td&gt;NTP&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC5905&#34;&gt;RFC5905&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ff0x::133&lt;/td&gt;
&lt;td&gt;可变的&lt;/td&gt;
&lt;td&gt;聚合服务器访问协议&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC5352&#34;&gt;RFC5352&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ff0x::18c&lt;/td&gt;
&lt;td&gt;可变的&lt;/td&gt;
&lt;td&gt;所有 AC 的地址（CAPWAP）&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC5415&#34;&gt;RFC5415&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ff3x::/32&lt;/td&gt;
&lt;td&gt;（特殊的）&lt;/td&gt;
&lt;td&gt;SSM 块&lt;/td&gt;
&lt;td&gt;[&lt;a href=&#34;#RFC4607&#34;&gt;RFC4607&lt;/a&gt;]&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;255-任播地址&#34;&gt;2.5.5 任播地址&lt;/h3&gt;
&lt;p&gt;任播地址是一个单播 IPv4 或 IPv6 地址，这些地址根据它所在的网络确定不同的主机。这是通过配置路由器通知 Internet 中多个站点有相同单播路由来实现。因此，一个任播地址不是指 Internet 中的一台主机，而是对于任播地址“最合适”或“最接近”的一台主机。任播地址最常用于发现一台提供了常用服务的计算机 [&lt;a href=&#34;#RFC4786&#34;&gt;RFC4786&lt;/a&gt;]。例如，某个数据报发送到一个任播地址，可用于找到 DNS 服务器（见第 11 章）， 6to4 网关将 IPv6 流量封装在 IPv4 隧道中 [&lt;a href=&#34;#RFC3068&#34;&gt;RFC3068&lt;/a&gt;]，或用于组播路由的 RP 中 [&lt;a href=&#34;#RFC4610&#34;&gt;RFC4610&lt;/a&gt;]。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;26-分配&#34;&gt;2.6 分配&lt;/h2&gt;
&lt;p&gt;IP 地址空间通常被分配为大的块，这由一些分层次组织的权威机构完成。权威机构是为各种“所有者”分配地址空间的组织， “所有者”通常是 ISP 或其他较小的权威机构。权威机构经常参与全球单播地址空间分配，但有时也分配其他类型的地址（组播和特殊用途）。权威机构为用户分配一个不限时的地址块，或是一个限时（例如实验）的地址块。这个层次结构的顶部是 IANA [&lt;a href=&#34;#IANA&#34;&gt;IANA&lt;/a&gt;] ，它负责分配 IP 地址和 Internet 协议使用的其他号码。&lt;/p&gt;
&lt;h3 id=&#34;261-单播&#34;&gt;2.6.1 单播&lt;/h3&gt;
&lt;p&gt;对于单播 IPv4 和 IPv6 的地址空间， IANA 将分配权限主要委托给几个&lt;strong&gt;地区性 Internet 注册机构（RIR）&lt;/strong&gt;。 RIR 之间通过一个组织互相协作，即 2003 年创建的号码资源组织（NRO）[&lt;a href=&#34;#NRO&#34;&gt;NRO&lt;/a&gt;]。表 2-14 给出了本书写作时（2011 年中期）的一组 RIR，它们都加人了 NRO。截至 2011 年初， IANA 拥有的剩余的 IPv4 单播地址空间将移交给这些 RIR 分配。&lt;/p&gt;
&lt;center&gt; 表 2-14  加入 NRO 的地区性 Internet 注册机构 &lt;/center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;RIR 名称&lt;/th&gt;
&lt;th&gt;负责的地区&lt;/th&gt;
&lt;th&gt;参考文献&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;AfriNIC——非洲网络信息中心&lt;/td&gt;
&lt;td&gt;非洲&lt;/td&gt;
&lt;td&gt;http://www.afrinic.net&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;APNIC——亚洲太平洋地区网络信息中心&lt;/td&gt;
&lt;td&gt;亚洲/太平洋地区&lt;/td&gt;
&lt;td&gt;http://www.apnic.net&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ARIN——美洲 Internet 号码注册机构&lt;/td&gt;
&lt;td&gt;北美洲&lt;/td&gt;
&lt;td&gt;http://www.arin.net&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;LACNIC——拉丁美洲和加勒比地区的 IP 地址注册&lt;/td&gt;
&lt;td&gt;拉丁美洲和一些加勒比岛屿&lt;/td&gt;
&lt;td&gt;http://lacnic.net/en/index.html&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;RIPE NCC——欧洲网络协调中心&lt;/td&gt;
&lt;td&gt;欧洲、中东、中亚&lt;/td&gt;
&lt;td&gt;http://www.ripe.net&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;这些实体通常处理较大的地址块 [&lt;a href=&#34;#IP4AS&#34;&gt;IP4AS&lt;/a&gt;] [&lt;a href=&#34;#IP6AS&#34;&gt;IP6AS&lt;/a&gt;]。他们为一些国家（例如澳大利亚和新加坡）运营的小型注册机构和大型 ISP 分配地址空间。接下来， ISP 为自已和自已的客户提供地址空间。当用户登记 Internet 服务时，他们通常以地址前缀形式使用 ISP 地址空间的一部分（通常很小）。这些地址范围由客户的 ISP 拥有和管理，并被称为&lt;strong&gt;供应商聚合（PA）&lt;strong&gt;的地址，这是由于它们包含一个或多个前缀，并可与 ISP 的其他前缀实现聚合。这种地址有时也称为&lt;/strong&gt;不可移植&lt;/strong&gt;的地址。交换供应商通常需要客户自已修改连接到 Internet 的所有主机和路由器的IP前缀（这种不愉快的操作通常称为&lt;strong&gt;重新编号&lt;/strong&gt;）。&lt;/p&gt;
&lt;p&gt;一种可选的地址空间类型称为&lt;strong&gt;供应商独立（PI）&lt;strong&gt;的地址空间。从 PI 空间分配的地址可以直接分配给用户，并且可以由任何 ISP 来使用。但是，由于这些地址是客户拥有的，它们没有与 ISP 的地址在数字上相邻，因此它们不能聚合。一个 ISP 需要为客户的 PL 地址提供路由，客户可能需要为路由服务支付额外费用，或根本不支持这种服务。在某种意义上，一个 ISP 同意为客户的 PI 地址提供路由，相对于其他客户有一个额外成本，它会增加自已的路由表大小。另一方面，很多站点喜欢使用 PI 地址，他们可能愿意支付额外费用，因为有助于转换 ISP 时避免重新编号（这被称为&lt;/strong&gt;供应商锁&lt;/strong&gt;）。&lt;/p&gt;
&lt;h4 id=&#34;2611-例子&#34;&gt;2.6.1.1 例子&lt;/h4&gt;
&lt;p&gt;这时，可能需要使用 Internet 中的WHOIS服务，以确定如何分配地址空间。例如，我们可通过访问相应的URL http://whois.arin.net/rest/ip/72.1.140.203.txt ，形成一个对 IPv4 地址  &lt;code&gt;72.1.140.203&lt;/code&gt; 的信息查询：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Net Range:    72.1.140.192 - 72.1.140.223
CIDR:         72.1.140.192/27
OriginAS:
NetName:      SPEK-SEA5-PART-1
NetHandle:    NET-71-1-140-192-1
Parent:       NET-72-1-128-0-1
NetType:      Reassigned
RegDate:      2005-06-29
Updated:      2005-06-29
Ref:          http://whois.arin.net/rest/net/NET-71-1-140-192-1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里，我们看到地址 &lt;code&gt;72.140.203&lt;/code&gt; 实际上是网络 SPEK-SEA5-PART-1 的一部分，并且已分配地址范围 &lt;code&gt;72.1.140.192/27&lt;/code&gt;。另外，我们可以看到， SPEK-SEA5-PART-1 的地址范围是 NET-72-1-128-0-1 的 PA 地址空间的一部分。我们可生成一个关于该网络的信息查询，需要访问 URL  http://whois.arin.net/rest/net/NET-71-1-128-0-1.txt 。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Net Range:    72.1.128.0 - 72.1.191.255
CIDR:         72.1.128.0/18
OriginAS:
NetName:      SPEAKEASY-6
NetHandle:    NET-71-1-128-0-1
Parent:       NET-72-0-0-0-0
NetType:      Direct Allocation
RegDate:      2004-09-09
Updated:      2009-05-19
Ref:          http://whois.arin.net/rest/net/NET-71-1-128-0-1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这个记录指出地址范围 &lt;code&gt;72.1.128.0/18&lt;/code&gt;（称为“句柄”或名称 NET-72-1-128-0-1）已被直接分配，它在 ARIN 管理的地址范围 &lt;code&gt;72.0.0.0/8&lt;/code&gt; 之外。有关 ARIN 支持的数据格式和多种方法的更多细节，可以通过 WHOIS 查询在 &lt;a href=&#34;#WRWS&#34;&gt;[WRWS]&lt;/a&gt; 中看到。&lt;/p&gt;
&lt;p&gt;通过其他 Internet 注册机构，我们可以看到不同的结果。例如，如果使用 Web 查询接口 http://www.ripe.net/whois 搜索有关 IPv4 地址 &lt;code&gt;193.5.93.80&lt;/code&gt; 的信息，我们将获得下面的结果：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% This is the RIPE Database query service.
% The objects are in RPSL format.
%
% The RIPE Database is subject to Terms and Conditions.
% See http://www.ripe.net/db/support/db-terms-conditions.pdf
% 
% Note: This output has been filtered.
%       To receive output for a database update， use the &amp;quot;-B&amp;quot; flag.
% Information related to &#39;193.5.88.0 - 193.5.95.255&#39;
inetnum:         193.5.88.0 - 193.5.95.255
netname:         WIPONET
descr:           World Intellectual Property Organization
descr:           UN Specialized Agency
descr:           Geneva
country:         CH
org:             ORG-WWIP1-RIPE
admin-c:         AM4504-RIPE
tech-c:          AM4504-RIPE
mnt-by:          RIPE-NCC-END-MNT
status:          ASSIGNED PI
mnt-by:          ICC-NETMGR-MNT
mnt-by:          CH-UNISOURCE-MNT
mnt-by:          DE-COLT-MNT
created:         2002-08-16T08:00:36Z
last-modified:   2018-06-22T08:40:13Z
source:          RIPE
sponsoring-org:  ORG-UNIC3-RIPE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们可以看到，地址 &lt;code&gt;193.5.93.80&lt;/code&gt; 是分配给 WIPO 的地址块 &lt;code&gt;193.5.88.0/21&lt;/code&gt; 的一部分。注意，这个块的状态为 &lt;code&gt;ASSIGNED PI&lt;/code&gt;，意味着该地址块是供应商独立类型。 RPSL 的参考文献表示数据库记录使用路由策略规范语言 [&lt;a href=&#34;#RFC2622&#34;&gt;RFC2622&lt;/a&gt;] [&lt;a href=&#34;#RFC4012&#34;&gt;RFC4012&lt;/a&gt;]， ISP 用它来表示自已的路由策略。这些信息允许网络运营商配置路由器，以帮助缓解 Internet 中的路由不稳定。&lt;/p&gt;
&lt;h3 id=&#34;262-组播&#34;&gt;2.6.2 组播&lt;/h3&gt;
&lt;p&gt;在 IPv4 和 IPv6 中，组播地址（即组地址）可根据其范围来描述，它们需要确定组播方式（静态、动态的协议或算法），以及是否使用 ASM 或 SSM。这些组的分配策略已被制定（ [&lt;a href=&#34;#RFC5771&#34;&gt;RFC5771&lt;/a&gt;] 针对 IPv4 ； [&lt;a href=&#34;#RFC3307&#34;&gt;RFC3307&lt;/a&gt;] 针对 IPv6 ），整体架构在 [&lt;a href=&#34;#RFC6308&#34;&gt;RFC6308&lt;/a&gt;] 中详细描述。全球范围之外的组（例如管理范围的地址和 IPv6 链路范围的组播地址）可在 Internet 的各个部分重复使用，并由网络管理员配置管理范围之外的地址块或由端主机自动选择。静态分配的全球范围地址通常是固定的，并且可能被硬件编码到应用中。这种地址空间是有限的，特别是在 IPv4 中，这种地址实际上计划被用于任何其他 Internet 站点。通过算法确定的全球范围地址可以像 GLOP 基于 AS 号创建，或是根据相关的单播前缀分配。注意， SSM 可使用全球范围的地址（即来自SSM块）、管理范围的地址，或前缀实际为 0 的基于单播前缀的 IPv6 地址。&lt;/p&gt;
&lt;p&gt;我们可以看到，大量的协议和复杂的组播地址格式，导致组播地址管理成为一个难题（更不用说全球组播路由 [&lt;a href=&#34;#RFC5110&#34;&gt;RFC5110&lt;/a&gt;]）。从用户的角度来看，组播很少使用，可能受到的关注有限。从程序员的角度来看，在应用设计中支持组播可能是有价值的， [&lt;a href=&#34;#RFC3170&#34;&gt;RFC3170&lt;/a&gt;]提供了一些这方面的设想。当网络管理员需要实现组播时，与服务提供商的交流可能是必要的。另外，一些组播地址分配方案已由厂商开发 [&lt;a href=&#34;#CGEMA&#34;&gt;CGEMA&lt;/a&gt;] 。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;27-单播地址分配&#34;&gt;2.7 单播地址分配&lt;/h2&gt;
&lt;p&gt;一个站点分配了单播 IP 地址范围后 —— 通常是从自己的 ISP 处获得，站点或网络管理员需要决定如何为每个网络接口指定地址，以及如何建立子网结构。如果这个站点只有一个物理网段（例如大多数家庭），这个过程相对简单。对于规模较大的企业，尤其是那些由多个 ISP 提供服务，并且多个物理网段分布在很大地理区域的企业，这个过程可能非常复杂。我们来看在以下情况下如何工作，家庭用户使用一个专用地址和一个 ISP 提供的 IPv4 地址。这是目前常见的场景。接着，我们继续介绍一些更复杂的情况。&lt;/p&gt;
&lt;h3 id=&#34;271-单个供应商无网络单个地址&#34;&gt;2.7.1 单个供应商/无网络/单个地址&lt;/h3&gt;
&lt;p&gt;目前，我们可获得的最简单的 Internet 服务是由 ISP 提供一个在一台计算机上使用的 IP 地址（在美国通常只是IPv4）。例如，对于 DSL 服务，单个地址可被分配到一个点到点链路的一端，并可能只是暂时的。例如，如果用户的计算机通过 DSL 连接 Internet，它可能在某天被分配了一个地址&lt;code&gt;63.204.134.177&lt;/code&gt;。在计算机上运行的任何程序可以发送和接收 Internet流量，这些流量将采用 &lt;code&gt;63.204.134.177&lt;/code&gt; 作为 IPv4 源地址。一台主机同样也有其他活动的 IP 地址。这些地址包括本地的“回送”地址（&lt;code&gt;127.0.0.1&lt;/code&gt;）和一些组播地址，至少包括所有主机的组播地址（&lt;code&gt;224.0.0.1&lt;/code&gt;）。如果主机正在运行 IPv6，它至少使用所有节点的 IPv6 组播地址（&lt;code&gt;ff02::!&lt;/code&gt;）、 ISP 分配的任何 IPv6 地址、 IPv6 回送地址( &lt;code&gt;::1&lt;/code&gt; )和为每个网络接口配置的一个用于 IPv6 的链接本地地址。&lt;/p&gt;
&lt;p&gt;为了在 Linux 上查看一台主机使用的组播地址（组），我们可使用 ifconfig 和 netstat 命令查看正在使用的 IP 地址和组：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Linux% ifconfig ppp0
ppp0  Link encap: Point-to-Point Protocol
      inet addr:71.141.244.213
      P-t-P:71.141.255.254   Mask:255.255.255.255
      UP POINTOPOINT RUNNING NOARP MULTICAST   MTU:1492   Metric:1
      RX packets:33134  errors:0  dropped:0  overruns:0  frame:0
      TX packets:41031  errors:0  dropped:0  overruns:0  carrier:0
      collisions:0  txqueuelen:3
      RX bytes:17748984 (16.9 MiB)   TX bytes:9272209 (8.8 MiB)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Linux% netstat -gn
IPv6/IPv4 Group Memberships
Interface   RefCnt   Group
---------   ------   ----------------
lo          1        224.0.0.1
ppp0        1        224.0.0.251
ppp0        1        224.0.0.1
lo          1        ff02::1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里，我们看到设备 ppp0 关联的一条点到点链路，它已分配 IPv4 地址 &lt;code&gt;71.141.244.213&lt;/code&gt; ;但没有分配 IPv6 地址。这台主机系统已启用 IPv6，但当检查它的组成员时，我们看到其本地回送（lo）接口出现在“所有 IPv6 节点”组播组中。我们也可以看到， IPv4 所有节点组正在使用，以及 mDNS （组播DNS）服务 [&lt;a href=&#34;#IDChes&#34;&gt;IDChes&lt;/a&gt;] 。 mDNS 协议使用静态 IPv4 组播地址 &lt;code&gt;224.0.0.251&lt;/code&gt;。&lt;/p&gt;
&lt;h3 id=&#34;272-单个供应商单个网络单个地址&#34;&gt;2.7.2 单个供应商/单个网络/单个地址&lt;/h3&gt;
&lt;p&gt;很多拥有多台计算机的 Internet 用户发现，只有一台计算机连接到 Internet 并不是理想情况。因此，他们通常拥有家庭局域网（LAN）或无线局域网（WLAN），并使用一台路由器或主机作为路由器连接 Internet。这种配置与单个计算机的情况相似，除了路由器将分组从家庭网络转发到 ISP，它们也执行 NAT （见第 7 章；在 Windows 中称为 Internet 连接共享（ICS）），在与 ISP 通信时重写分组中的 IP 地址。从 ISP 的角度来看，只有一个 IP 地址被使用。目前，这些操作大部分是自动的，因此需要手动配置的地址很少。路由器使用 DHCP 为家庭用户提供自动地址分配。如果有必要，它们也为与 ISP 建立链路提供地址分配。第 6 章详细介绍 DHCP 操作和主机配置。&lt;/p&gt;
&lt;h3 id=&#34;273-单个供应商多个网络多个地址&#34;&gt;2.7.3 单个供应商/多个网络/多个地址&lt;/h3&gt;
&lt;p&gt;很多组织发现仅分配一个单播地址，特别是当它只是暂时分配时，通常无法满足自己的上网需求。对于运行 Internet服务器（例如 Web 站点）的组织，通常希望拥有一个固定的 IP 地址。这些站点经常有多个局域网，其中有些是内部的（通过防火墙和 NAT 设备与 Internet 分离），有些可能是外部网（为 Internet 提供服务）。对于这样的网络，通常需要有一个站点或网络管理员，以确定站点需要多少个 IP 地址，如何构建网站的子网，以及哪些子网是内部或外部网。图 2-16 显示了典型的中小规模企业方案。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;16&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1651066473523.png&#34; alt=&#34;图 2-16&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 2-16   一个典型的小型到中型规模的企业网络。该网站已被分配 &lt;code&gt;128.32.2.64/26&lt;/code&gt; 范围内的 64 个公开（可路由）的 IPv4 地址。 “DMZ”网络包含 Internet 中可见的服务器。内部路由器使用 NAT 为企业内部的计算机提供 Internet 访问&lt;/p&gt;
&lt;p&gt;在该图中，一个站点已分配前缀 &lt;code&gt;128.32.2.64/26&lt;/code&gt;，提供最多 64 （减 2）个可路由的 IPv4 地址。 “DMZ”网络（“非军事区”网络，在主防火墙之外，见第 7 章）用来连接服务器，以便 Internet 中的用户可以访问它们。这种计算机通常提供 Web 访问、登录服务器和其他服务。这些服务器的 IP 地址来自前缀范围的一小部分；很多站点只拥有少数的公共服务器。站点前缀中的保留地址交给 NAT 路由器，将它们作为一个“NAT 池”（见第 7 章）的基础。 NAT 路由器可以使用池中的任何地址重写进入或离开内部网络的数据报。图 2-16 显示的网络设置很方便，这里主要有两个原因。&lt;/p&gt;
&lt;p&gt;首先，将内部网络与 DMZ 分隔开，有助于保护内部的计算机免受破坏，并由 DMZ 服务器来面对攻击。另外，它会设置区域内的 IP 地址。在边界路由器、 DMZ 和内部 NAT 路由器建立后，可在内部使用任何地址结构，其中可以使用很多（专用的） IP 地址。当然，这个例子只是建立小型的企业网络的一种方式，其他因素（例如成本）可能最终决定路由器、网络和 IP 地址在小型或中型规模的企业中的部署方式。&lt;/p&gt;
&lt;h3 id=&#34;274-多个供应商多个网络多个地址多宿主&#34;&gt;2.7.4 多个供应商/多个网络/多个地址（多宿主）&lt;/h3&gt;
&lt;p&gt;对于一些依赖 Internet 接人来保证持续运营的组织，他们通常使用一个以上的供应商（称为&lt;strong&gt;多宿主&lt;/strong&gt;），以便在失效时或其他情况下提供冗余连接。由于 CIDR，只有一个 ISP 的组织通常拥有与该 ISP 相关联的 PA 地址。如果他们又使用一个 ISP，这样会出现每个主机使用哪个 IP 地址的问题。目前，已有针对多个 ISP 同时运行的方法，以及在 ISP 之间转换的指导原则（其中提出了一些类似问题）。对于 IPv4， [&lt;a href=&#34;#RFC4116&#34;&gt;RFC4116&lt;/a&gt;]讨论了 PI 或 PA 地址如何用于多宿主。我们看图 2-17 所示的情况。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;17&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1651067041956.png&#34; alt=&#34;图 2-17&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 2-17   供应商聚合和供应商独立的 IPv4 地址用于一个假设的多宿主企业。如果 PI 地址是可用的，站点运营者倾向于选择使用 PI 空间。 ISP更喜欢 PA 空间，因为它可促进前缀聚合，减少路&lt;br&gt;
由表的大小&lt;/p&gt;
&lt;p&gt;这里，一个虚拟的站点 S 有两个 ISP，即 P1 和 P2。如果它使用来自 P1 块（&lt;code&gt;12.46.129.0/25&lt;/code&gt;）的 PA 地址空间，将在 C 和 D 点把该前缀分别通知 P1 和 P2。 这个前缀可被 P1 聚合到自已的 &lt;code&gt;12/8&lt;/code&gt; 块，并在 A 点将它通知 Internet 其他部分，但 P2 不能在 B 点聚合该前缀，因为它与自已的前缀（&lt;code&gt;137.164/16&lt;/code&gt;）在数值上不相邻。另外，从Internet 其他部分的一些主机的角度来看， &lt;code&gt;12.46.129.0/25&lt;/code&gt; 的流量趋向于 ISP P2 而不是 ISP P1，因为站点 S 的前缀比它通过 P1 时更长（“更具体”）。这是 Internet 路由（详情见第 5 章）采用最长匹配前缀算法工作方式的结果。本质上，一台 Internet 其他部分的主机经过 A 点匹配的前缀 &lt;code&gt;12.0.0.0/8&lt;/code&gt; 或 B 点匹配的前缀 &lt;code&gt;12.46.129.0/25&lt;/code&gt; 都可到达 &lt;code&gt;12.46.129.1&lt;/code&gt;。 由于每个前缀都匹配（即目的地址 &lt;code&gt;12.46.129.1&lt;/code&gt; 中包含一组共同的前缀位），则具有更大或更长的那个前缀是首选，在这种情况下是 P2。因此， P2 位于无法聚合来自 S 的前缀的位置，并需要携带更多站点 S 的流量。&lt;/p&gt;
&lt;p&gt;如果站点 S 决定使用 PI 空间而不是 PA 空间，这个情况更对称。但是，不聚合是可能的。在这种情况下，它在 C 和 D 点将 PI 前缀 &lt;code&gt;198.134.135.0/24&lt;/code&gt; 分别通知 PI 和 P2，但任何 ISP 都不能聚合它，因为它与 ISP 地址块中任何一个数值都不相邻。因此，每个 ISP 在 A 点和 B 点通知可识别的前缀 &lt;code&gt;198.134.135.0/24&lt;/code&gt;。在这种方式下，在 Internet 路由中执行“自然的”最短路径计算，站点 S 可通过更靠近发送主机的 ISP 到达。另外，如果站点 S 决定切换另一个 ISP，它不需要改变其分配的地址。不幸的是，无法聚合这种地址可能关系到 Internet 未来的扩展性，因此 PI 空间相对供不应求。&lt;/p&gt;
&lt;p&gt;IPv6 多宿主已成为 IETF 近年来的研究课题，并出现了 Multi6 体系结构 [&lt;a href=&#34;#RFC4177&#34;&gt;RFC4177&lt;/a&gt;] 和 Shim6 协议 [&lt;a href=&#34;#RFC5533&#34;&gt;RFC5533&lt;/a&gt;] 。 Multi6 概括了一些已提出处理意见的方法。从广义上来说，上述选择包括使用一种相当于前面提到的 IPv4 多宿主的路由方式、使用&lt;strong&gt;移动 IPv6&lt;/strong&gt; 的能力&lt;br&gt;
[&lt;a href=&#34;#RFC6275&#34;&gt;RFC6275&lt;/a&gt;]，以及采用一种将节点标识符与定位符分离的新方法。当前， IP 地址作为连接 Internet 的一个网络接口标识符（本质上是一种名称）和定位符（一种路由系统理解的地址）。&lt;br&gt;
这种分离使得将来即使在底层 IP 地址改变的情况下网络协议也能够实现。提供这种分离的协议有时称为&lt;strong&gt;标识符/定位符分&lt;/strong&gt;离或 &lt;strong&gt;id/loc 分离&lt;/strong&gt;协议。&lt;/p&gt;
&lt;p&gt;Shim6 介绍了一个网络层协议“隔离层”（shim），传输层协议使用它分离来自 IP 地址的“上层协议标识符” 。多宿主通过选择使用的 IP 地址（定位符）来实现，基于动态网络环境且不需要 PI 地址分配。通信主机（端点）之间对使用的定位符及交换的时机进行协商。标识符与定位符分离是其他几项工作的主题，包括实验性的&lt;strong&gt;主机标识协议（HIP）&lt;/strong&gt; [&lt;a href=&#34;#RFC4423&#34;&gt;RFC4423&lt;/a&gt;]，它使用加密的主机标识符来标识主机。这种标识符实际上是与主机相关的公共/私人密钥对中的公钥，因此来源于一个特定主机的 HIP 流量可被认证。第 18 章将详细讨论安全问题。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;28-与-ip-地址相关的攻击&#34;&gt;2.8 与 IP 地址相关的攻击&lt;/h2&gt;
&lt;p&gt;IP 地址基本上都是数字，只有少数网络攻击涉及它们。一般情况下，执行攻击可发送“欺骗”数据包（见第 5 章）或其他相关活动。也就是说， IP 地址现在有助于查明涉嫌不良活动的个体（例如，对等网络中的版权侵权或非法材料分发）。这样做可能被以下几个原因所误导。例如，在很多情况下，IP 地址只是暂时的，并在不同时间重新分配给不同用户。因此，在精确计时中出现任何错误，容易造成数据库中的 IP 地址到用户的映射出错。另外，访问控制没有被广泛和安全地部署；用户可能通过一些公共的接入点，或一些无意中开放的家庭或办公室的无线路由器连接 Internet。在这种情况下，不知情的家庭或企业所有者可能因 IP 地址而成为嫌疑人，即使这个人并不是网络流量的发送者。这种情况也可能因受攻击的主机被用于组成僵尸网络而发生。目前，这类计算机（和路由器）可通过基于 Internet 的黑市来租赁，并被用于执行攻击、非法内容服务和其他违法活动 [&lt;a href=&#34;#RFC4948&#34;&gt;RFC4948&lt;/a&gt;] 。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;29-总结&#34;&gt;2.9 总结&lt;/h2&gt;
&lt;p&gt;IP 地址用于识别和定位整个 Internet 系统（单播地址）中设备的网络接口。它也用于识别多个接口（组播、广播或任播地址）。每个接口有一个最少 32 位的 IPv4 地址，并且通常有几个 128 位的 IPv6 地址。单播地址由一些分层次组织的管理机构分配成块。由这些机构分配的前缀表示一个单播 IP 地址空间块，这些块通常分配给 ISP，并由它们为自已的用户分配地址。这种前缀通常是 ISP 地址块的子区间（称为供应商聚合的地址或 PA 地址），但也可能代之为用户拥有的地址（称为供应商独立的地址或 PI 地址）。数值相邻的地址前缀（PA 地址）可被聚合，以节省路由表空间和提高 Internet 扩展性。这种方法出现于由 A、 B、 C 类网络号组成的“有类别” Internet 网络结构被无类别域间路由（CIDR）所取代时。  CIDR 允许根据对地址空间的不同需求，将不同大小的地址块分配给某个组织， CIDR 实际上可以更有效地分配地址空间。任播地址是根据发送者位置指向不同主机的单播地址；这种地址常用于发现可能出现在不同位置的网络服务。&lt;/p&gt;
&lt;p&gt;IPv6 单播地址与 IPv4 地址有所不同。最重要的是， IPv6 地址有一个范围的概念，无论是单播地址还是组播地址，都需要明确指出地址的有效范围。典型的范围包括节点本地、链路本地和全球范围。链路本地地址通常基于一个标准前缀和一个 IID 创建，这个 IID 可由低层协议（例如硬件 / MAC 地址）基于地址提供或取随机值。这种方法有助于自动配置 IPv6 地址。&lt;/p&gt;
&lt;p&gt;IPv4 和 IPv6 都支持同时指向多个网络接口的地址格式。 IPv4 支持广播地址和组播地址，但 IPv6 只支持组播地址。广播允许一人对所有人通信，而组播允许一人对多人通信。发送方向组播组（IP 地址）的发送，其行为有点像电视频道；发送方并不知道接收方信息或一个信道中有多少个接收方。 Internet 中的全球性组播已发展了十多年，并且涉及很多协议，有些是针对路由，有些是针对地址分配和协调，有些是针对主机希望加入或离开一个组的信息。无论是 IPv4 还是 IPv6，特别是 IPv6，都有很多类型和用途的组播地址。 IPv6 组播地址格式变化提供了基于单播前缀分配组的方法，在组中嵌入路由信息（RP地址），并且能基于 IID 创建组播地址。&lt;/p&gt;
&lt;p&gt;可以说 CIDR 的开发和部署是 Internet 核心路由系统的一个根本性变化。 CIDR 成功地为分配地址空间提供更多灵活性，并通过聚合提升路由的可扩展性。另外， IPv6 在 20 世纪 90 年代初开始受到更多重视，这是出于很快将会需要更多地址的想法。当时没有预见的是，NAT （见第7章）的广泛使用显著推迟了 IPv6 的使用，这是因为连接 Internet 的每台主机不再需要唯一的地址。相反，大型网络使用专用地址空间已司空见惯。但是，可用于路由的 IP 地址数量最终将减少到零，因此未来将会出现一些变化。 2011 年 2 月， IANA 分配了最后 5 个 &lt;code&gt;/8&lt;/code&gt; 的 IPv4 地址前缀， 5 个 RIR 备分配 1 个前缀。2011 年 04 月 15 日， APNIC 用尽了其所有可分配的前缀。剩余前缀由不同 RIR 持有，预计最多只能几年保持未分配状态。 [&lt;a href=&#34;#IP4R&#34;&gt;IP4R&lt;/a&gt;] 是一个关于当前 IPv4 地址利用率的统计。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;210-参考文献&#34;&gt;2.10 参考文献&lt;/h2&gt;
&lt;p&gt;&lt;span id=&#34;CGEMA&#34;&gt; [CGEMA] &lt;/span&gt; Cisco Systems, &amp;quot;Guidelines for Enterprise IP Multicast Address Allocation,&amp;quot; 2004, http://www.cisco.com/warp/public/cc/techno/tity/prodlit/ipmlt_wp.pdf&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;EIGRP&#34;&gt; [EIGRP] &lt;/span&gt; B.Albrightson, J.J.Garcia-Luna-Aceves, and J.Boyle, &amp;quot;EIGRP -- A Fast Routing Protocol Based on Distance Vectors,&amp;quot; Proc. Infocom, 2004.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;EUI64&#34;&gt; [EUI64] &lt;/span&gt; Institute for Electrical and Electronics Engineers, &amp;quot;Guidelines for 64-Bit Global Identifier (EU1-64) Registration Authority&amp;quot; Mar. 1997 http://standards.ieee.org/regauth/oui/tutorials/EUI64.html&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;H96&#34;&gt; [H96] &lt;/span&gt; M.Handley &amp;quot;The SDR Session Directory: An Mbone Conference Scheduling and Booking System,&amp;quot; Department of Computer Science, University College London, Apr. 1996, http://cobweb.ecn.purdue.edu/~ace/mbone/mbone/sdr/intro.html&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;IANA&#34;&gt; [IANA] &lt;/span&gt; Internet Assigned Numbers Authority, http://www.iana.org&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;IDChes&#34;&gt; [IDChes] &lt;/span&gt; S.Cheshire and M.Krochmal, &amp;quot;Multicast DNS,&amp;quot; Internet draft-cheshire-dnsext-multicastdns, Work in progress, Oct. 2010&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;IDv4v6mc&#34;&gt; [IDv4v6mc] &lt;/span&gt; S.Venaas, X.Li, and C.Bao, &amp;quot;Framework for IPv4/IPv6 Multicast Translation,&amp;quot; Internet draft-venaas-behave-v4v6mc-framework, Work in progress, Dec. 2010.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;IEEERA&#34;&gt; [IEEERA] &lt;/span&gt; IEEE Registration Authority, http://standards.ieee.org/regauth&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;IMR02&#34;&gt; [IMR02] &lt;/span&gt; B.Edwards, L.Giuliano, and B.Wright, Interdomain Multicast Routing: Practical Juniper Networks and Cisco Systems Solutions (Addison-Wesley, 2002).&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;IP4AS&#34;&gt; [IP4AS] &lt;/span&gt; http://www.iana.org/assignments/ipv4-address-space&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;IP4MA&#34;&gt; [IP4MA] &lt;/span&gt; http://www.iana.org/assignments/multicast-addresses&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;IP4R&#34;&gt; [IP4R] &lt;/span&gt;  IPv4 Address Report, http://www.potaroo.net/tools/ipv4&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;IP6AS&#34;&gt; [IP6AS] &lt;/span&gt; http://www.iana.org/assignments/ipv6-address-space&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;IP6MA&#34;&gt; [IP6MA] &lt;/span&gt; http://www.iana.org/assignments/ipv6-multicast-addresses&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;KK77&#34;&gt; [KK77] &lt;/span&gt; L.Kleinrock and F.Kamoun, &amp;quot;Hierarchical Routing for Large Networks, Performance Evaluation and optimization,&amp;quot; Computer Networks, 1(3), 1977.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;NRO&#34;&gt; [NRO] &lt;/span&gt; Number Resource organization, http://www.uro.net&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFCO919&#34;&gt; [RFCO919] &lt;/span&gt; J.C.Mogul, &amp;quot;Broadcasting Internet Datagrams,&amp;quot; Internet RFC O919/BCP OOO5, Oct. 1984.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFCO922&#34;&gt; [RFCO922] &lt;/span&gt; J.C.Mogul, &amp;quot;Broadcasting Internet Datagrams in the Presence of Subnets,&amp;quot; Internet RFC O922/STD OOO5, Oct. 1984.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFCO950&#34;&gt; [RFCO950] &lt;/span&gt; J.C.Mogul and T.Postel, &amp;quot;Internet Standard Subnetting Procedure,&amp;quot; Internet RFC O950/STD OOO5, Aug. 1985.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC1O75&#34;&gt; [RFC1O75] &lt;/span&gt; D.Waitzman, C.Partridge, and S.E.Deering, &amp;quot;Distance Vector Multicast Routing Protocol,&amp;quot; Internet RFC lO75 (experimental), Nov. 1988.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC1112&#34;&gt; [RFC1112] &lt;/span&gt; S.E.Deering, &amp;quot;Host Extensions for IP Multicasting,&amp;quot; Internet RFC 1112/STD OOO5, Aug. 1989.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC1122&#34;&gt; [RFC1122] &lt;/span&gt; R.Braden, ed., &amp;quot;Requirements for Internet Hosts-Communication Layers,&amp;quot; Internet RFC l122/STD OOO3, Oct. 1989.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC1812&#34;&gt; [RFC1812] &lt;/span&gt; F.Baker, ed., &amp;quot;Requirements for IP Version 4 Routers,&amp;quot; Internet RFC 1812/STD OOO4, June 1995.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC1918&#34;&gt; [RFC1918] &lt;/span&gt; Y.Rekhter, B.Moskowitz, D.Karrenberg, G.J.deGroot, and E.Lear, &amp;quot;Address Allocation for Private Internets,&amp;quot; Internet RFC 1918/BCP OOO5, Feb. 1996.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC2080&#34;&gt; [RFC2080] &lt;/span&gt; G.Malkin and R.Minnear, &amp;quot;RIPng for IPv6,&amp;quot; Internet RFC 2080, Jan. 1997&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC2328&#34;&gt; [RFC2328] &lt;/span&gt; J.Moy &amp;quot;OSPF Version 2,&amp;quot; Internet RFC 2328/STD OO54, Apr. 1988.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC2365&#34;&gt; [RFC2365] &lt;/span&gt; D. Meyer, &amp;quot;Administratively Scoped IP Multicast,&amp;quot; Internet RFC 2365/ BCP OO23, July 1998.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC2544&#34;&gt; [RFC2544] &lt;/span&gt; S.Bradner and J.McQuaid, &amp;quot;Benchmarking Methodology for Network Interconnect Devices,&amp;quot; Internet RFC 2544 (informational), Mar. 1999.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC2622&#34;&gt; [RFC2622] &lt;/span&gt; C.Alaettinoglu, C.Villamizar, E.Gerich, D.Kessens, D.Meyer, T.Bates, D.Karrenberg, and M.Terpstra, &amp;quot;Routing Policy Specification Language(RPSL),&amp;quot; Internet RFC 2622, June 1999.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC2644&#34;&gt; [RFC2644] &lt;/span&gt; D.Senie, &amp;quot;Changing the Default for Directed Broadcasts in Routers,&amp;quot; Internet RFC 2644/BCP OO34, Aug. 1999.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC2974&#34;&gt; [RFC2974] &lt;/span&gt; M.Handley C.Perkins, and E.Whelan, &amp;quot;Session Announcement Protocol,″ Internet RFC 2974 (experimental), Oct. 2000.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC3056&#34;&gt; [RFC3056] &lt;/span&gt; B.Carpenter and K. Moore, &amp;quot;Connection of IPv6 Domains via IPv4 Clouds,&amp;quot; Internet RFC 3056, Feb. 2001.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC3068&#34;&gt; [RFC3068] &lt;/span&gt; C.Huitema, &amp;quot;An Anycast Prefix for 6to4 Relay Routers,&amp;quot; Internet RFC 3068, June 2001.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC3170&#34;&gt; [RFC3170] &lt;/span&gt; B.Quinn and K.Almeroth, &amp;quot;IP Multicast Applications: Challenges and Solutions,&amp;quot; Internet RFC 3170 (informational), Sept. 2001.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC3180&#34;&gt; [RFC3180] &lt;/span&gt; D.Meyer and P.Lothberg, &amp;quot;GLOP Addressing in 233/8,&amp;quot; Internet RFC 3180/BCP OO53, Sept. 2001.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC3306&#34;&gt; [RFC3306] &lt;/span&gt; B.Haberman and D.Thaler, &amp;quot;Unicast-Prefix-Based IPv6 MulticastAddresses,&amp;quot; Internet RFC 3306, Aug. 2002.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC3307&#34;&gt; [RFC3307] &lt;/span&gt; B.Haberman, &amp;quot;Allocation Guidelines for IPv6 Multicast Addresses,″ Internet RFC 3307 Aug. 2002.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC3315&#34;&gt; [RFC3315] &lt;/span&gt; R.Droms, ed., J.Bound, B.Volz, T.Lemon, C.Perkins, and M.Camey &amp;quot;Dynamic Host Configuration Protocol for IPv6 (DHCPv6),″ Internet RFC 3315, Aug. 2002.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC3569&#34;&gt; [RFC3569] &lt;/span&gt; S. Bhattacharyya, ed., &amp;quot;An overview of Source-Specific Multicast (SSM),&amp;quot; Internet RFC 3569 (informational), July 2003.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC3701&#34;&gt; [RFC3701] &lt;/span&gt; R.Fink and R.Hinden, &amp;quot;6bone (IPv6 Testing Address Allocation) Phaseout,&amp;quot; Internet RFC 3701 (informational), Mar. 2004.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC3810&#34;&gt; [RFC3810] &lt;/span&gt; R.Vida and L.Costa, eds., &amp;quot;Multicast Listener Discovery Version 2 (MLDv2) for IPv6,″ Internet RFC 3810, June 2004.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC3849&#34;&gt; [RFC3849] &lt;/span&gt; G.Huston, A.Lord, and P.Smith, &amp;quot;IPv6 Address Prefix Reserved for Documentation,&amp;quot; Internet RFC 3849 (informational), July 2004.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC3879&#34;&gt; [RFC3879] &lt;/span&gt; C.Huitema and B.Carpenter, &amp;quot;Deprecating Site Local Addresses,″ Internet RFC 3879 Sept. 2004.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC3927&#34;&gt; [RFC3927] &lt;/span&gt; S.Cheshire, B.Aboba, and E.Guttman, &amp;quot;Dynamic Configuration of IPv4 LinkLocal Addresses,&amp;quot; Internet RFC 3927, May 2005.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC3956&#34;&gt; [RFC3956] &lt;/span&gt; P.Savola and B.Haberman, &amp;quot;Embedding the Rendezvous Point (RP) Address in an IPv6 Multicast Address,&amp;quot; Internet RFC 3956, Nov 2004.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC4012&#34;&gt; [RFC4012] &lt;/span&gt; L.Blunk, J.Damas, F.Parent, and A.Robachevsky, &amp;quot;Routing Policy Specification Language Next Generation (RPSLng),&amp;quot; Internet RFC 4012, Mar. 2005.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC4116&#34;&gt; [RFC4116] &lt;/span&gt; J.Abley K.Lindqvist, E.Davies, B.Black, and V.Gill, &amp;quot;IPv4 Multi-homing Practices and Limitations,″ Internet RFC 4116 (informational), July 2005.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC4177&#34;&gt; [RFC4177] &lt;/span&gt; G.Huston, &amp;quot;Architectural Approaches to Multi-homing for IPv6,&amp;quot; Internet RFC 4177 (informational), Sept. 2005.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC4193&#34;&gt; [RFC4193] &lt;/span&gt; R.Hinden and B.Haberman, &amp;quot;Unique Local IPv6 Unicast Addresses,″ Oct.2005.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC4286&#34;&gt; [RFC4286] &lt;/span&gt; B.Haberman and J.Martin, &amp;quot;Multicast Router Discovery&amp;quot; Internet RFC 4286, Dec. 2005.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC4291&#34;&gt; [RFC4291] &lt;/span&gt; R.Hinden and S.Deering, &amp;quot;IP Version 6 Addressing Architecture,″ Internet RFC 4291, Feb. 2006.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC4380&#34;&gt; [RFC4380] &lt;/span&gt; C.Huitema, &amp;quot;Teredo: Tunneling IPv6 over UDP through Network Address Translations (NATs),″ Internet RFC 4380, Feb. 2006.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC4423&#34;&gt; [RFC4423] &lt;/span&gt; R.Moskowitz and P.Nikander, &amp;quot;Host Identity Protocol (HIP) Architecture,&amp;quot; Internet RFC 4423 (informational), May 2006.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC4489&#34;&gt; [RFC4489] &lt;/span&gt; J.-S.Park, M.-K.Shin, and H.-J.Kim, &amp;quot;A Method for Generating Link-Scoped IPv6 Multicast Addresses,&amp;quot; Internet RFC 4489 Apr. 2006.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC4566&#34;&gt; [RFC4566] &lt;/span&gt; M.Handley, V.Jacobson, and C.Perkins, &amp;quot;SDP: Session Description Protocol,&amp;quot; Internet RFC 4566, July 2006.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC4601&#34;&gt; [RFC4601] &lt;/span&gt; B.Fenner, M.Handley H.Holbrook, and I.Kouvelas, &amp;quot;Protocol Independent Multicast-Sparse Mode (PIM-SM) : Protocol Specification (Revised),″ Internet RFC 4601, Aug. 2006.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC4607&#34;&gt; [RFC4607] &lt;/span&gt; H.Holbrook and B.Cain, &amp;quot;Source-Specific Multicast for IP″ Internet RFC 4607, Aug. 2006.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC4608&#34;&gt; [RFC4608] &lt;/span&gt; D.Meyer, R.Rockell, and G.Shepherd, &amp;quot;Source-Specific Protocol Independent Multicast in 232/8,&amp;quot; Internet RFC 4608/BCP 0120, Aug. 2006.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC4610&#34;&gt; [RFC4610] &lt;/span&gt; D.Farinacci and Y.Cai, &amp;quot;Anycast-RP Using Protocol Independent Multicast (PIM),″ Internet RFC 4610, Aug. 2006.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC4632&#34;&gt; [RFC4632] &lt;/span&gt; V.Fuller and T.Li, &amp;quot;Classless Inter-domain Routing (CIDR): The Internet Address Assignment and Aggregation Plan,&amp;quot; Internet RFC 4632/BCP 0122, Aug. 2006.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC4786&#34;&gt; [RFC4786] &lt;/span&gt; J.Abley and K.Lindqvist, &amp;quot;Operation of Anycast Services,″ Internet RFC 4786/BCP O126, Dec. 2006.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC4795&#34;&gt; [RFC4795] &lt;/span&gt; B.Aboba, D.Thaler, and L.Esibov, &amp;quot;LinkLocal Multicast Name Resolution (LLMNR),&amp;quot; Internet RFC 4795 (informational), Jan. 2007.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC4843&#34;&gt; [RFC4843] &lt;/span&gt; P.Nikander, J.Laganier, and F.Dupont, &amp;quot;An IPv6 Prefix for overlay Routable Cryptographic Hash Identifiers (ORCHID),″ Internet RFC 4843 (experimental), Apr. 2007.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC4893&#34;&gt; [RFC4893] &lt;/span&gt; Q.Vbhra and E.Chen, &amp;quot;BGP Support for Four-Octet AS Number Space,″ Internet RFC 4893, May 2007.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC4948&#34;&gt; [RFC4948] &lt;/span&gt; L.Andersson, E.Davies, and L.Zhang, eds., &amp;quot;Report from the IAB Workshop on Unwanted Traffic March 9-10, 2006,&amp;quot; Internet RFC 4948 (informational), Aug. 2007.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC5059&#34;&gt; [RFC5059] &lt;/span&gt; N.Bhaskar, A.Ga11, J.Lingard, and S.Venaas, &amp;quot;Bootstrap Router (BSR) Mechanism for Protocol Independent Multicast (PIM),″ Internet RFC 5059 Jan. 2008.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC5110&#34;&gt; [RFC5110] &lt;/span&gt; P.Savola, &amp;quot;Overview of the Internet Multicast Routing Architecture,&amp;quot; Internet RFC 5110 (informational), Jan. 2008.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC5156&#34;&gt; [RFC5156] &lt;/span&gt; M.Blanchet, &amp;quot;Special-Use IPv6 Addresses,&amp;quot; Internet RFC 5156 (informational), Apr. 2008.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC5214&#34;&gt; [RFC5214] &lt;/span&gt; F.Templin, T.Gleeson, and D.Thaler, &amp;quot;Intra-Site Automatic Turnnel Addressing Protocol (ISATAP),″ Internet RFC 5214 (informational), Mar. 2008.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC5352&#34;&gt; [RFC5352] &lt;/span&gt; R.Stewart, Q.Xie, M.Stillman, and M.Tuexen, &amp;quot;Aggregate Server Access Protocol (ASAP),&amp;quot; Internet RFC 5352 (experimental), Sept. 2008.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC5415&#34;&gt; [RFC5415] &lt;/span&gt; P.Calhoun, M.Montemurro, and D.Stanley, eds., &amp;quot;Control and Provisioning of Wireless Access Points (CAPWAP) Protocol Specification,″ Internet RFC 5415, Mar. 2009.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC5498&#34;&gt; [RFC5498] &lt;/span&gt; I.Chakeres, &amp;quot;IANA Allocations for Mobile Ad Hoc Network (MANET) Protocols,″ Internet RFC 5498, Mar. 2009.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC5533&#34;&gt; [RFC5533] &lt;/span&gt; E.Nordmark and M.Bagnulo, &amp;quot;Shim6: Level 3 Multihoming Shim Protocol for IPv6,&amp;quot; Internet RFC 5533, June 2009.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC5735&#34;&gt; [RFC5735] &lt;/span&gt; M.Cotton and L.Vegoda, &amp;quot;Special Use IPv4 Addresses,″ Internet RFC 5735/BCP O153, Jan. 2010.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC5736&#34;&gt; [RFC5736] &lt;/span&gt; G.Huston, M.Cotton, and L.Vegoda, &amp;quot;IANA IPv4 Special Purpose Address Registry&amp;quot; Internet RFC 5736 (informational), Jan. 2010.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC5737&#34;&gt; [RFC5737] &lt;/span&gt; J.Arkko, M.Cotton, and L.Vegoda, &amp;quot;IPv4 Address Blocks Reserved for Documentation,&amp;quot; Internet RFC 5737 (informational), Jan. 2010.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC5771&#34;&gt; [RFC5771] &lt;/span&gt; M.Cotton, L.Vegoda, and D.Meyer, &amp;quot;IANA Guidelines for IPv4 Multicast Address Assignments,&amp;quot; Internet RFC 5771/BCP 0051, Mar. 2010.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC5952&#34;&gt; [RFC5952] &lt;/span&gt; S.Kawamura and M.Kawashima, &amp;quot;A Recommendation for IPv6 Address Text Representation,&amp;quot; Internet RFC 5952, Aug, 2010.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC5905&#34;&gt; [RFC5905] &lt;/span&gt; D.Mills, J.Martin, ed., J.Burbank, and W.Kasch, &amp;quot;Network Time Protocol Version 4: Protocol and Algorithms Specification,&amp;quot; Internet RFC 5905, June 2010.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC6034&#34;&gt; [RFC6034] &lt;/span&gt; D.Thaler, &amp;quot;Unicast-Prefix-Based IPv4 Multicast Addresses,″ Internet RFC 6034, Oct. 2010&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC6052&#34;&gt; [RFC6052] &lt;/span&gt; C.Bao, C.Huitema, M.Bagnulo, M.Boucadair, and X.Li, &amp;quot;IPv6 Addressing of IPv4/IPv6 Translators,″ Internet RFC 6052, Oct. 2010.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC6217&#34;&gt; [RFC6217] &lt;/span&gt; J.Arkko and M.Townsley &amp;quot;IPv4 Run-Out and IPv4-1Pv6 Co-Existence Scenarios,&amp;quot; Internet RFC 6127 (experimental), May 2011.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC6144&#34;&gt; [RFC6144] &lt;/span&gt; F.Baker, X.Li, C.Bao, and K.Yin, &amp;quot;Framework for IPv4/IPv6 Translation,″ Internet RFC 6144 (informational), Apr. 2011.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC6164&#34;&gt; [RFC6164] &lt;/span&gt; M.Kohno, B.Nitzan, R.Bush, Y.Matsuzaki, L.Colitti, and T.Narten, &amp;quot;Using 127-Bit IPv6 Prefixes on Inter-Router Links,&amp;quot; Internet RFC 6164, Apr. 2011.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC6275&#34;&gt; [RFC6275] &lt;/span&gt; C.Perkins, ed., D.Johnson, and J.Arkko, &amp;quot;Mobility Support in IPv6,&amp;quot; Internet RFC 3775, July 2011.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC6308&#34;&gt; [RFC6308] &lt;/span&gt; P.Savola, &amp;quot;Overview of the Internet Multicast Addressing Architecture,&amp;quot; Internet RFC 6308 (informational), June 2011.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;WRWS&#34;&gt; [WRWS] &lt;/span&gt; http://www.arin.net/resources/whoisrws&lt;/p&gt;
">《TCP/IP 详解 卷一：协议》第二章：Internet 地址结构</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://wenbozhangw.github.io/post/gai-shu/"" data-c="
          &lt;p&gt;有效沟通取决于使用共同的语言。这一观点对于人类、动物以及计算机而言都是适用的。当一种语言用于一组行为时，需要使用一种协议。根据《新牛津美国辞典》，对协议的第一定义是:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;国家事务或外交场合的正式程序或规则系统。&lt;/strong&gt;&lt;/p&gt;
&lt;!-- more --&gt;
&lt;p&gt;我们每天执行很多协议:询问和回答问题、谈判商业交易、协同工作等。计算机也会执行备种协议。一系列相关协议的集合称为一个协议族。指定一个协议族中的备种协议之间的相互关系并划分需要完成的任务的设计，称为协议族的体系结构或参考模型。 TCP/IP是一个实现Internet体系结构的协议族，它来源于 ARPANET 参考模型（ARM） [&lt;a href=&#34;#RFCO871&#34;&gt;RFCO871&lt;/a&gt;]。 ARM 受到了早期分组交换工作的影响，这些工作包括美国的 Paul  Baran [&lt;a href=&#34;#B64&#34;&gt;B64&lt;/a&gt;] 和 Leonard Kleiurock [&lt;a href=&#34;#K64%5D&#34;&gt;K64&lt;/a&gt;、英国的Donald Davies [&lt;a href=&#34;#DBSW66&#34;&gt;DBSW66&lt;/a&gt;] 、法国的Louis Pouzin [&lt;a href=&#34;#P73&#34;&gt;P73&lt;/a&gt;] 。虽然数年之后制定了其他协议体系结构（例如， ISO协议体系结构[&lt;a href=&#34;#Z80&#34;&gt;Z80&lt;/a&gt;]、 Xerox的XNS [&lt;a href=&#34;#X85&#34;&gt;X85&lt;/a&gt;] 和 IBM 的 SNA [&lt;a href=&#34;#I96&#34;&gt;I96&lt;/a&gt;] ），但TCP/IP已成为最流行的协议族。这里有几本有趣的书籍，它们关注计算机通信的历史和Internet的发展，例如 [&lt;a href=&#34;#PO7&#34;&gt;PO7&lt;/a&gt;] 和 [&lt;a href=&#34;#WO2&#34;&gt;WO2&lt;/a&gt; ]。&lt;/p&gt;
&lt;p&gt;值得一提的是，TCP/IP体系结构来源于实际工作，用于满足多种不同的分组交换计算机网络的互联需求 [&lt;a href=&#34;#CK74&#34;&gt;CK74&lt;/a&gt;]。这由一组网关（后来称为路由器）来实现，网关可以在互不兼容的网络之间提供翻译功能。随着越来越多的提供备种服务的节点投人使用，由此产生的“串联”网络或多类型网络（catenet）——后来称为互联网络（internetwork）将更加有用。在协议体系结构全面发展之前的几年，有人已经设想了全球性网络可能提供的服务类型。例如，在 1968 年， J. C. R. Licklider和Bob Taylor已预见到支持“超级通信”的全球性互联通信网络的潜在用途 [&lt;a href=&#34;#LT68&#34;&gt;LT68&lt;/a&gt;] ：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;今天的在线社区彼此在功能和地理位置上是分离的。每个成员只能看到以自己社区为中心的设施的处理、存储和软件能力等功能。但是，现在的变化趋势是分离的社区之间的互联，从而将它们变成我们所说的超级社区。互联使所有社区中的所有成员能访问整个超级社区中的程序和数据资源……这个变化将形成一个由很多网络组成的不稳定网络，该网络无论在内容还是配置上都在变化。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;因此，支撑 ARPANET 和后来的 Internet 的全球网络概念，很明显是针对我们今天使用的很多服务类型而设计的。但是，要做到这点是不容易的。其成功来源于对设计和实现的重视，创新型用户和开发人员，以及提供足够多的资源，促使概念转化为原型系统，并最终转化为商业化的网络产品。&lt;/p&gt;
&lt;p&gt;本章是对 Internet 体系结构和 TCP/IP 协议族的概述，提供了一些历史知识，并为后续章节建立足够的背景支撑。体系结构(协议和物理)实际上是一组设计决策，涉及支持哪些特点和在哪里实现这些特点。设计一个体系结构更多的是艺术而不是科学，但我们将讨论体系结构中随着时间推移被认为可行的那些特点，网络体系结构的主题已在Day [&lt;a href=&#34;#D08&#34;&gt;D08&lt;/a&gt;] 中被广泛讨论，它是这方面的几种方案之一。&lt;/p&gt;
&lt;h2 id=&#34;11-体系结构原则&#34;&gt;1.1 体系结构原则&lt;/h2&gt;
&lt;p&gt;TCP/IP 协议族允许计算机、智能手机和嵌入式设备之间通信，它们可以采用备种尺寸、来自不同计算机生产商和运行备种软件。在 21 世纪到来之际，这已成为现代通信、娱乐和商务活动的必要需求。 TCP/IP 确实是一个 &lt;strong&gt;开放的系统&lt;/strong&gt;，协议族定义和很多实现是公开的，收费很少或根本不收费。它构成全球因特网（Internet）的基础（因特网是一个拥有遍布全球的大约 20 亿用户（2010 年，占全球人口的 30%）的广域网）。尽管很多人认为因特网和&lt;strong&gt;万维网&lt;/strong&gt;是可互换的术语，但我们通常认为因特网在计算机之间提供了消息通信能力，而万维网是一种使用因特网来通信的具体应用。在 20 世纪 90 年代早期，万维网恐怕是最重要的因特网应用，并使因特网技术得到全世界的重视。&lt;/p&gt;
&lt;p&gt;Internet 体系结构在几个目标的指导下建立。在 [&lt;a href=&#34;#C88&#34;&gt;C88&lt;/a&gt;] 中， Clark 描述首要目标是“发展一种重复利用已有的互联网络的技术” 。这句话的本质是 Internet 体系结构应将多种网络互联起来，并在互联的网络上同时运行多个应用。基于这个首要目标， Clark 提供了以下的二级目标列表：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Internet 通信在网络或网关失效时必须能持续。&lt;/li&gt;
&lt;li&gt;Internet 必须支持多种类型的通信服务。&lt;/li&gt;
&lt;li&gt;Internet 体系结构必须兼容多种网络。&lt;/li&gt;
&lt;li&gt;Internet 体系结构必须允许对其资源的分布式管理。&lt;/li&gt;
&lt;li&gt;Internet 体系结构必须是经济有效的。&lt;/li&gt;
&lt;li&gt;Internet 体系结构必须允许低能力主机的连接。&lt;/li&gt;
&lt;li&gt;Internet 中使用的资源必须是可统计的。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上面列出的很多目标将被最终的设计决策所采纳。但是，在制定这些体系结构原则时，这些原则影响到设计者所做的选择，最后少数几种设计方案脱颖而出。我们将提到其中几种重要方案及其结果。&lt;/p&gt;
&lt;h3 id=&#34;111-分组-连接和数据报&#34;&gt;1.1.1 分组、连接和数据报&lt;/h3&gt;
&lt;p&gt;直到 20 世纪 60 年代，网络的概念主要是基于电话网络。它是针对在一次通话中连接双方通话而设计的。一次通话通常要在通话双方之间建立一条&lt;strong&gt;连接&lt;/strong&gt;。建立一个连接意味着，在一次通话过程中，通话双方之间需要建立一条线路（最初是一条物理电路）。当一次通话结束时，这条连接被释放，允许这条线路用于其他用户通话。通话时间和连接端身份用于用户计费。当一次连接建立后，它为用户提供一定数量的&lt;strong&gt;带宽&lt;/strong&gt;或&lt;strong&gt;容量&lt;/strong&gt;，以便传输信息（通常是语音）。电话网从最初的模拟网络演变到数字网络，这样极大地提高了自身的可靠性和性能。在线路一端输入的数据，沿着某些预先建立的经过网络交换机的路径，通常具有某个时&lt;br&gt;
间（&lt;strong&gt;延迟&lt;/strong&gt;）上限，在线路另一端以一种可预测方式出现。这样，在用户需要且线路可用的情况下，可以提供可预测的服务。线路是一条通过网络的路径，它为一次通话过程而保留，即使在并不繁忙的情况下。关于电话网络的常识是：在一次通话期间，即使我们没有说任何话，也要为这段时间而付费。&lt;/p&gt;
&lt;p&gt;20世纪60年代出现的一个重要概念（如 [&lt;a href=&#34;#B64&#34;&gt;B64&lt;/a&gt;] 中）是&lt;strong&gt;分组交换&lt;/strong&gt;思想。在分组交换中，包含一定字节数的数字信息“块” （分组）独立通过网络。来自不同来源或发送方的块可以组合，而且以后可以分解，这称为“（多路）&lt;strong&gt;复用&lt;/strong&gt;”。这些块在到达目的地的过程中，需要在交换设备之间传输，并且路径可以改变。这样做有两个潜在的优点： 网络更有弹性（设计者不用担心网络受到物理攻击），基于&lt;strong&gt;统计复用&lt;/strong&gt;可更好地利用网络链路和交换设备。&lt;/p&gt;
&lt;p&gt;当一台分组交换机接收到分组时，它们通常存储在&lt;strong&gt;缓存&lt;/strong&gt;或&lt;strong&gt;队列&lt;/strong&gt;中，并通过&lt;strong&gt;先到达先服务&lt;/strong&gt;（FCFS）的方式处理。这是最简单的分组处理调度方式，又称为&lt;strong&gt;先进先出&lt;/strong&gt;（FIFO）。 FIFO 缓冲区管理和按需调度很容易结合起来实现统计复用，它是 Internet 中用来处理不同来源的混合流量的主要方法。在统计复用中，流量基于到达的统计或时间模式而混合在一起。这种多路复用是简单而有效的，因为如果网络带宽被使用和有流量通过，那么网络中的每个瓶颈或阻塞点将会繁忙（高利用率）。这种方法的缺点是可预测性有限，通过某些特定应用的性能可看出，它依赖于对共享网络的其他应用的统计。统计复用就像是一条高速公路，车辆可以变换车道，但是最终会分散在备处，任何点的收缩都可能造成道路繁忙。&lt;/p&gt;
&lt;p&gt;某些替代性的技术，例如&lt;strong&gt;时分复用&lt;/strong&gt;（TDM）和&lt;strong&gt;静态复用&lt;/strong&gt;，通常在每个连接上为数据保留一定量的时间或其他资源。虽然这种技术可能具有更好的可预测性，可用于支持恒定比特率的电话通话功能，但它可能无法充分利用网络带宽，这是由于保留的带宽可能未使用。注意，当电路是通过 TDM 技术来实现时，&lt;strong&gt;虚电路&lt;/strong&gt;（VC）会表现出很多电路行为，但是不依赖于物理的电路交换机，而通过顶层的面向连接的分组来实现。这是流行的 x.25 协议的基础，该技术直到 20 世纪 90 年代初才开始被帧中继大规模取代，并最终被&lt;strong&gt;数字用户线&lt;/strong&gt;（DSL）技术和支持Internet连接的电缆调制解调器所取代（见第 3 章）。&lt;/p&gt;
&lt;p&gt;对于虚电路抽象和面向连接的分组网络（例如 x.25 ），需要在每个交换机中为每个连接存储一些信息或&lt;strong&gt;状态&lt;/strong&gt;。原因是每个分组只携带少量的额外信息，以提供到某个状态表的索引。例如，在 x.25 中， 12 位的&lt;strong&gt;逻辑信道标识符&lt;/strong&gt;（LCI）或&lt;strong&gt;逻辑信道号&lt;/strong&gt;（LCN）被用于这个目的。在每台交换机中， LCI 或 LCN 和交换机中的&lt;strong&gt;每个流状态&lt;/strong&gt;相结合，以决定分组交换路径中的下一台交换机。在使用信令协议在一条虚电路上交换数据之前，每个流状态已经建立，该协议支持连接建立、清除和状态信息。因此，这种网络称为&lt;strong&gt;面向连接的&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;无论是建立在线路还是交换的基础上，面向连接的网络是多年来最流行的联网方式。在 20 世纪 60 年代后期，&lt;strong&gt;数据报&lt;/strong&gt;作为另一种可选方案而得到发展。数据报起源于 CYCLADES [&lt;a href=&#34;#P73&#34;&gt;P73&lt;/a&gt;] 系统，它是一个特定类型的分组，有关来源和最终目的地的所有识别信息都位于分组中（而不是分组交换机中）。虽然这通常需要较大的数据包，但不需要在交换机中维护连接状态，它可用于建立一个&lt;strong&gt;无连接的&lt;/strong&gt;网络，并且没必要使用复杂的信令协议。数据报很快被早期的 Internet 设计者所接受，这个决定对协议族其他部分有深远影响。&lt;/p&gt;
&lt;p&gt;另一个相关的概念是&lt;strong&gt;消息边界&lt;/strong&gt;或&lt;strong&gt;记录标记&lt;/strong&gt;。如图 1-1 所示，当一个应用将多个信息块发送到网络中，这些信息块可能被通信协议保留，也可能不被通信协议保留。大多数数据报协议保存消息边界。这样设计是很自然的，因为数据报本身有一个开始和结束。但是，在电路交换或虚电路网络中，一个应用程序可能需要发送几块数据，接收程序将所有数据作为一个块或多个块来读取。这些类型的协议不保留消息边界。在底层协议不保留消息边界，而应用程序需要它的情况下，应用程序必须自已来提供这个功能。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1650284886786.png&#34; alt=&#34;图 1-1 &#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 1-1 应用程序将协议携带的数据写人消息。消息边界是两次写入之间的位置或字节偏移量。保留消息边界的协议由接收方给出发送方的消息边界。不保留消息边界的协议（例如，像 TCP 这样的流协议）忽略这类信息，并使它在接收方无效。这样做的结果是，如果这个功能是必需的，应用程序需要自已实现发送方的消息边界&lt;/p&gt;
&lt;h3 id=&#34;112-端到端论点和命运共享&#34;&gt;1.1.2 端到端论点和命运共享&lt;/h3&gt;
&lt;p&gt;当我们设计一个大的系统（例如操作系统或协议族）时，随之而来的问题通常是在什么位置实现某个功能。影响 TCP/IP 协议族设计的一个重要原则称为&lt;strong&gt;端到端论点&lt;/strong&gt; [&lt;a href=&#34;#SRC84&#34;&gt;SRC84&lt;/a&gt;] ：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;只有在通信系统端角度的应用知识的帮助下，才能完全和正确地实现问题中提到的功能。因此，作为通信自身的一个特点，不可能提供有疑问的功能。 （有时，通信系统提供的一个功能不完整的版本可能用于提高性能。）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在第一次阅读时，这种观点看起来似乎相当直观，它可能对通信系统设计产生深远影响。它认为只有涉及通信系统的应用程序或最终用户，其正确性和完整性才可能得到实现。即使为正确实现应用程序做了努力，其功能可能注定不会很完善。总之，这个原则认为重要功能（例如差错控制、加密、交付确认）通常不会在大型系统的低层（见 1.2.1 节）实现。但是，低层可以提供方便端系统工作的功能，并最终可能改善性能。这种观点表明低层功能不应以完美为目标，这是因为对应用程序需求做出完美推测是不可能的。&lt;/p&gt;
&lt;p&gt;端到端论点倾向于支持一种使用“哑”网络和连接到网络的“智能”系统的设计方案。这是我们在 TCP/IP 设计中所看到的，很多功能（例如，保证数据不丢失、发送方控制发送速率）在端主机的应用程序中实现。选择哪些功能在同一计算机、网络或软件栈中实现，这是另一个称为命运共享的相关原则 [&lt;a href=&#34;#C88&#34;&gt;C88&lt;/a&gt;] 。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;命运共享&lt;/strong&gt;建议将所有必要的状态放在通信端点，这些状态用于维护一个活动的通信关联（例如虚拟连接）。由于这个原因，导致通信失效的情况也会导致一个或更多端点失效，这样显然会导致整个通信的失败。命运共享是一种通过虚拟连接（例如，由 TCP 实现）维持活动的设计理念，即便网络连接在一段时间内失效。命运共享也支持一种“带智能终端主机的哑网络”模型，当前 Internet 中的矛盾是：哪些功能在网络中实现，哪些功能不在网络中实现。&lt;/p&gt;
&lt;h3 id=&#34;113-差错控制和流量控制&#34;&gt;1.1.3 差错控制和流量控制&lt;/h3&gt;
&lt;p&gt;在网络中存在数据损坏或丢失的情况。这可能出于各种原因，例如硬件间题、数据传输中被修改、在无线网络中超出范围，以及其他因素。对这种错误的处理称为&lt;strong&gt;差错控制&lt;/strong&gt;，它可以在构成网络基础设施的系统、连接到网络的系统或其他组合中实现。显然，端到端论点和命运共享建议在应用程序附近或内部实现差错控制。&lt;/p&gt;
&lt;p&gt;通常，在只有少数位出错的情况下，我们关注的是，当数据已被接收或正在传输过程中，有些数学代码可用于检测和修复这种位差错 [&lt;a href=&#34;#LC04&#34;&gt;LC04&lt;/a&gt;] 。这个任务通常在网络中执行。当更多严重损坏发生在分组网络时，整个分组通常被重新发送或&lt;strong&gt;重新传输&lt;/strong&gt;。在线路交换或虚电路交换网络（例如 X.25 ）中，重新传输通常在网络内部进行。这对那些顺序要求严格和无差错交付的应用是有用的，但有些应用不需要这种功能或不希望为数据可靠交付而付出代价（例如连接建立和重新传输延迟）。一个可靠的文件传输应用并不关心交付的文件数据块的顺序，最终将所有块无差错地交付并接原来顺序重新组合即可。&lt;/p&gt;
&lt;p&gt;针对网络中可靠、按顺序交付的实现开销，帧中继和 Internet 协议采用一种称为&lt;strong&gt;尽力而为交付&lt;/strong&gt;的服务。在尽力而为的交付中，网络不会花费很大努力来确保数据在没有差错或缺陷的情况下交付。某些差错通常用差错检测码或&lt;strong&gt;校验和&lt;/strong&gt;来检测，例如那些可能影响一个数据报定向的差错，当检测到这种差错时，出错的数据报仅被丢弃而没有进一步行动。&lt;/p&gt;
&lt;p&gt;如果尽力而为的交付成功，发送方能以超过接收方处理能力的速度生成信息。在尽力而为的 IP 网络中，降低发送方的发送速度可通过&lt;strong&gt;流量控制&lt;/strong&gt;机制实现，它在网络外部或通信系统高层中运行。注意， TCP 会处理这种问题，我们将在第 15 章和第 16 章中详细讨论。这与端到端论点一致：TCP 在端主机中实现速率控制。它也与命运共享一致：这种方案在网络基础设施中有些单元失效的情况下，不会影响网络设备的通信能力（只要有些通信路径仍然可用）。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;12-设计和实现&#34;&gt;1.2 设计和实现&lt;/h2&gt;
&lt;p&gt;虽然建议用一个特定方法实现一个协议体系结构，但是这通常不是强制的。因此，我们对协议体系结构和&lt;strong&gt;实现体系结构&lt;/strong&gt;加以区分，实现体系结构定义了协议体系结构中的概念如何用于软件形式的实现中。&lt;/p&gt;
&lt;p&gt;很多负责实现 ARPANET 协议的人员都熟悉操作系统的软件结构，一篇有影响力的论文描述的“ THE”多编程系统 [&lt;a href=&#34;#D68&#34;&gt;D68&lt;/a&gt;] ，主张使用一种层次结构的处理方式，以检查一个大型软件实现逻辑的稳健性和正确性。最终，这有助于形成一种网络协议的设计理念，它涉及实现（和设计）的多个层次。这种方案现在称为&lt;strong&gt;分层&lt;/strong&gt;，它是实现协议族的常用方案。&lt;/p&gt;
&lt;h3 id=&#34;121-分层&#34;&gt;1.2.1 分层&lt;/h3&gt;
&lt;p&gt;通过分层，每层只负责通信的一个方面。采用多层是有益的，这是因为分层设计允许开发人员分别实现系统的不同部分，它们通常由在不同领域的专业人员完成。最常提到的协议分层概念基于一个称为&lt;strong&gt;开放系统互连标准&lt;/strong&gt;（OSI）的模型 [&lt;a href=&#34;#Z80&#34;&gt;Z80&lt;/a&gt;]，该模型是由国际标准化组织（ISO）定义的。图 1-2 显示了标准的 OSI 层次，包括它们的名称、编号和若干例子。Internet 的分层模型比较简单，我们将在 1.3 节中介绍。&lt;/p&gt;
&lt;p&gt;尽管 OSI 模型建议的 7 个逻辑层在协议体系结构的模块化实现中是可取的，但是通常认为 TCP/IP 体系结构包含 5 层。在 20 世纪 70 年代初，已有很多关于 OSI 模型的相对优势和不足，以及 ARPANET 模型优于它的争论。公平地说，尽管 TCP/IP 最终取得“胜利”，但来自 ISO 协议族（由 ISO 遵循 OSI 模型进行标准化）的一些思想，甚至整个协议已被用于 TCP/IP 中（例如 IS-IS [&lt;a href=&#34;#RFC3787&#34;&gt;RFC3787&lt;/a&gt;] ）。&lt;/p&gt;
&lt;p&gt;如图1-2的简要介绍，每层都有不同任务。自下而上，&lt;strong&gt;物理层&lt;/strong&gt;定义了一种通过某种通信介质（例如一条电话线或光纤电缆）传输数字信息的方法。以太网和无线局域网（Wi-Fi）标准的一部分也在这层，但我们不打算在本书中深人介绍。&lt;strong&gt;链路层&lt;/strong&gt;或&lt;strong&gt;数据链路层&lt;/strong&gt;包含为共享相同介质的邻居建立连接的协议或方法。有些链路层网络（例如 DSL ）只连接两个邻居。当超过一个邻居可以访问共享网络时，这个网络称为&lt;strong&gt;多接入网络&lt;/strong&gt;。Wi-Fi 和以太网是这种多接入链路层网络的例子，特定协议用于协调多个站在任何时间访问共享介质。我们将在第3章中讨论。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1650351221367.png&#34; alt=&#34;图 1-2&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 1-2 ISO 定义的标准 7 层 OSI 模型。每个网络设备（至少从理论上）并不需要实现所有协议。OSI 的术语和层数被广泛使用&lt;/p&gt;
&lt;p&gt;在层次结构中，我们对&lt;strong&gt;网络层&lt;/strong&gt;或&lt;strong&gt;互联网络层&lt;/strong&gt;最有兴趣。对于分组网络（例如 TCP/IP ），它提供了一种可互操作的分组格式，可通过不同类型的链路层网络来连接。本层也包括针对主机的地址方案和用于决定将分组从一台主机发送到另一台主机的路由算法。对于上述 3 层，我们发现协议（至少在理论上）仅实现在端主机中，这也包括&lt;strong&gt;传输层&lt;/strong&gt;。我们对传输层也有很大兴趣，它提供了一个会话之间的数据流，而且可能相当复杂，这取决于它提供的服务类型（例如，分组网络的可靠交付可能会丢弃数据）。&lt;strong&gt;会话&lt;/strong&gt;表示运行中的应用（例如， cookies 用于 Web 浏览器的 Web 登录会话过程中）之间的交互，会话层协议可提供例如连接初始化和重新启动、增加&lt;strong&gt;检查点&lt;/strong&gt;（保存到目前为止已完成的工作）等功能。在会话层之上是&lt;strong&gt;表示层&lt;/strong&gt;，它负责信息的格式转换和标准化编码。正如我们所看到的， Internet 协议不包括正式的会话层或表示层，如果需要的话，这些功能由应用程序来实现。&lt;/p&gt;
&lt;p&gt;最高层是&lt;strong&gt;应用层&lt;/strong&gt;。各种应用通常会实现自已的应用层协议，它们对用户来说是最容易看到的。目前已存在大量的应用层协议，并且程序员仍在不断开发新协议。因此，应用层是创新最多，以及新功能开发和部署的地方。&lt;/p&gt;
&lt;h3 id=&#34;122-分层实现中的复用-分解和封装&#34;&gt;1.2.2 分层实现中的复用、分解和封装&lt;/h3&gt;
&lt;p&gt;分层体系结构的一个主要优点是具有&lt;strong&gt;协议复用&lt;/strong&gt;的能力。这种复用形式允许多种协议共存于同一基础设施中。它也允许相同协议对象（例如连接）的多个实例同时存在，并且不会被混淆。&lt;/p&gt;
&lt;p&gt;复用可以发生在不同层，并在每层都有不同类型的&lt;strong&gt;标识符&lt;/strong&gt;，用于确定信息属于哪个协议或信息流。例如，在链路层，大多数的链路技术（例如以太网和 Wi-Fi ）在每个分组中包含一个&lt;strong&gt;协议标识符&lt;/strong&gt;字段，用于指出链路层帧携带的协议（IP 是这种协议）。当某层的一个称为&lt;strong&gt;协议数据单元&lt;/strong&gt;（PDU）的对象（分组、消息等）被低层携带时，这个过程称为在相邻低层的&lt;strong&gt;封装&lt;/strong&gt;（作为不透明数据）。因此，第 N 层的多个对象可以通过第 N-1 层的封装而复用。图 1-3 显示了封装的工作过程。第 N-1 层的标识符在第 N 层的分解过程中用于决定正确的接收协议或程序。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1650355972137.png&#34; alt=&#34;图 1-3&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 1-3 封装通常与分层一起使用。单纯的封装涉及获得某层的 PDU，并在低层将它作为不透明（无须解释）的数据来处理。封装发生在发送方，拆封（还原操作）发生在接收方。多数协议在封装过程中使用头部，少数协议也使用尾部&lt;/p&gt;
&lt;p&gt;在图1-3中，每层都有自已的消息对象（PDU）的概念，对应于负责创建它的那个特定层。例如，如果第4层（传输层）协议生成一个分组，将它称为第4层 PDU 或&lt;strong&gt;传输层&lt;/strong&gt; PDU（TPDU）更准确。如果某层获得由它的上层提供的 PDU，它通常“承诺”不查看 PDU 中的具体内容。这是封装的本质，每层都将来自上层的数据看成不透明、无须解释的信息。最常见的处理是某层在获得的 PDU 前面增加自已的头部，有些协议是增加尾部（不是 TCP/IP）。头部用于在发送时复用数据，接收方基于一个分解（拆分）标识符执行分解。在 TCP/IP 网络中，这类标识符通常是硬件地址、 IP 地址和端口号。头部中也包含一些重要的状态信息，例如一条虚电路是正在建立还是已经建立。由此产生的对象是另一个 PDU。&lt;/p&gt;
&lt;p&gt;图1-2 建议的分层的另一个重要特点是：在单纯的分层中，并不是所有网络设备都需要实现所有层。图 1-4 显示在某些情况下，如果设备只希望执行特定操作，那么它只需要实现少数几层。&lt;/p&gt;
&lt;p&gt;在图 1-4 中，有些理想化的小型互联网络包括两种端系统，即交换机和路由器。在本图中，每个编号对应于在特定层中的一种协议。正如我们所见，每个设备实现协议栈的一个子集。左侧的主机对应的物理层实现了 3 种链路层协议（D、 E 和 F），以及运行在同一网络层协议上的3种传输层协议（A、 B 和 C）。端主机实现了所有层，交换机实现到第 2 层（这台交换机实现了 D 和 G），路由器实现到第 3 层。由于路由器具有互联不同类型的链路层网络的能力，因此它必须为互联的每种网络实现链路层协议。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1650358451406.png&#34; alt=&#34;图 1-4&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 1-4 不同的网络设备实现协议栈的不同子集。端主机通常实现所有层。路由器实现传输层之下的各层。这种理想化的结构经常被破坏，这是由于路由器和交换机通常包括类似于主机的功能（例如管理和建立），因此它们需要实现所有层，即使有些层很少使用&lt;/p&gt;
&lt;p&gt;尽管我们只显示两台主机之间的通信，但是链路层和物理层网络（标记为 D 和 G）可能连接多台主机。如果这样，可以在任意两台实现相应的高层协议的系统之间通信。在图 1-4 中，针对一个特定的协议族，可以区分为&lt;strong&gt;端系统&lt;/strong&gt;（两边的两台主机）和&lt;strong&gt;中间系统&lt;/strong&gt;（中间的路由器）。网络层之上的各层使用&lt;strong&gt;端到端&lt;/strong&gt;协议。在我们的描述中，只有端系统需要这些层次。但是，网络层提供了一种&lt;strong&gt;逐跳&lt;/strong&gt;协议，它用于两个端系统和每个中间系统。通常不认为交换机或桥接是一个中间系统，这是由于它们没有使用互联网络协议的地址格式来编址，并在很大程度上以透明于网络层协议的方式运行。从路由器和端系统的角度来看，交换机或网桥实际是不可见的。&lt;/p&gt;
&lt;p&gt;顾名思义，路由器有两个或更多的网络接口（由于它连接两个或多个网络）。有多个接口的系统称为&lt;strong&gt;多宿主&lt;/strong&gt;。一台主机也可以是多宿主的，但除非它专门将分组从一个接口转发到另一个接口，否则不能把它称为路由器。另外，路由器不一定只是在网络中转发分组的特殊硬件设备。在多数的 TCP/IP 实现中，如果正确配置的话，允许多宿主主机作为路由器使用。在这种情况下，我们可以把该系统称为主机（当它运行&lt;strong&gt;文件传输协议&lt;/strong&gt;（FTP） [&lt;a href=&#34;#RFCO959&#34;&gt;RFCO959&lt;/a&gt;] 或 Web 应用时）或路由器（当它将分组从一个网络转发到另一个网络时）。我们将结合上下文使用相关的术语。&lt;/p&gt;
&lt;p&gt;互联网络的目标之一是对应用隐藏所有关于物理布局（拓扑）和低层协议的异构性的细节。虽然在图 1-4 所示的由两个网络组成的互联网络中并不明显，但应用层不关心（不在乎）以下事实：尽管连接在网络中的主机都采用链路层协议 D （例如以太网），但主机之间由采用链路层协议 G 的路由器和交换机隔开。主机之间可能有 20 个路由器，它们可采用其他类型的物理连接，应用程序无须修改即可运行（虽然性能可能有所不同）。以这种方式对细节加以抽象是促使互联网络概念变得强大和有用的原因。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;13-tcpip-协议族结构&#34;&gt;1.3 TCP/IP 协议族结构&lt;/h2&gt;
&lt;p&gt;到目前为止，我们已讨论了体系结构、协议、协议族和抽象的实现技术。在本节中，我们将讨论构成 TCP/IP &lt;strong&gt;协议族&lt;/strong&gt;的体系结构和特定协议。虽然这已成为 Internet 使用的协议的既定术语，但是也有很多 TCP 和 IP 之外的协议被包含在 Internet 使用的协议集或协议族中。我们将从最终形成 Internet 协议分层基础的ARPANET参考模型开始，研究它与前面讨论的 OSI 参考模型的区别。&lt;/p&gt;
&lt;h3 id=&#34;131-arpanet-参考模型&#34;&gt;1.3.1 ARPANET 参考模型&lt;/h3&gt;
&lt;p&gt;图 1-5 描述了源于 ARPANET 参考模型的分层，它最终被 TCP/IP 协议族采纳。它的结构比 OSI 模型更简单，但在实现中包括一些特定协议，并且不适合于常规层次的简化。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1650512857626.png&#34; alt=&#34;图 1-5&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 1-5 基于 ARM 或 TCP/IP 的协议分层被用于 Internet。这里没有正式的会话或表示层。另外，这里有几个不适合归入标准层的“附属”或辅助协议，它们为其他协议的运行提供重要功能。其中有些协议没有被 IPv6 使用（例如 IGMP 和 ARP）。&lt;/p&gt;
&lt;p&gt;从图 1-5 底部沿着协议栈上移，我们首先看到的层次是 2.5，这是一个“非正式”的层。有几个协议工作在这层，一个最古老和最重要的协议是地址解析协议（ARP）。它是 IPv4 的专用协议，只用于多接入链路层协议（例如以太网和 Wi-Fi），完成IP层使用的地址和链路层使用的地址之间的转换。我们将在第4章讨论这个协议。IPv6的地址映射功能作为 ICMPv6 的一部分，我们将在第 8 章讨论。&lt;/p&gt;
&lt;p&gt;我们在图 1-5 中编号为 3 的层中看到 IP，它是 TCP/IP 中最重要的网络层协议。我们将在第 5 章讨论它的细节。 IP 发送给链路层协议的 PDU 称为 &lt;strong&gt;IP 数据报&lt;/strong&gt;，它的大小是 64KB（IPv6 将它扩大为 4GB）。在很多情况下，当使用的上下文是清晰的，我们将会使用简化的术语“&lt;strong&gt;分组&lt;/strong&gt;”来表示 IP 数据报。大的分组放入链路层 PDU （称为&lt;strong&gt;帧&lt;/strong&gt;）时需要进行缩小处理，这个过程称为&lt;strong&gt;分片&lt;/strong&gt;，它通常由 IP 主机和某些路由器在必要时执行。在分片的过程中，大数据报的一部分被放入多个称为&lt;strong&gt;分片&lt;/strong&gt;的小数据报中，并在到达目的地后组合（称为&lt;strong&gt;重组&lt;/strong&gt;）。我们将在第 10 章中讨论分片。&lt;/p&gt;
&lt;p&gt;在本书中，我们使用术语 IP 表示 IP 版本 4 和 6 ，使用 IPv6 表示 IP 版本 6，并使用 IPv4 表示 IP 版本 4，它是当前最流行的版本。在讨论体系结构时，我们很少关注 IPv4 和 IPv6 的细节。当我们讨论寻址和配置的工作原理（第 2 章和第 6 章）时，这些细节将变得更重要。&lt;/p&gt;
&lt;p&gt;由于每个 IP 分组都是一个数据报，所以都包含发送方和接收方的第 3 层地址。这些地址称为 IP 地址，即 32 位的 IPv4 地址或 128 位的 IPv6 地址；我们将在第 2 章详细讨论它们。IP 地址长度不同是 IPv4 和 IPv6 之间的最大差别。每个数据报的目的地址用于决定将该数据报发送到哪里，而做出此决定和发送数据报到下一跳的过程称为&lt;strong&gt;转发&lt;/strong&gt;。路由器和主机都能进行转发，但更多的是由路由器实现转发。这里有 3 种类型的IP地址，地址类型决定如何进行转发：&lt;strong&gt;单播&lt;/strong&gt;（目的地是一台主机）、&lt;strong&gt;广播&lt;/strong&gt;（目的地是一个指定网络中的所有主机）和&lt;strong&gt;组播&lt;/strong&gt;（目的地是属于一个组播组中的一组主机）。第 2 章将详细介绍与 IP 一起使用的地址类型。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Internet控制消息协议&lt;/strong&gt;（ICMP）是IP的一个辅助协议，我们将它标注为 3.5 层协议。 IP 层使用它与其他主机或路由器的IP层之间交换差错消息和其他重要信息。 ICMP有两个版本：IPv4 使用的ICMPv4， IPv6使用的 ICMPv6。 ICMPv6 是相当复杂的，包括地址自动配置和邻居发现等功能，它们在IPv4网络中由其他协议（例如ARP）处理。虽然 ICMP 主要由 IP 使用，但它也能被其他应用使用。事实上，两个流行的诊断工具（ ping 和 traceroute ）都使用 ICMP。 ICMP 消息被封装在 IP 数据报中，采用与传输层 PDU 相同的封装方式。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Internet组管理协议&lt;/strong&gt;（ IGMP）是 IPv4 的另一个辅助协议。它采用组播寻址和交付来管理作为&lt;strong&gt;组播组&lt;/strong&gt;成员的主机（一组接收方接收一个特定目的地址的组播流量）。我们在这里只描述广播和组播的一般特点，在第 9 章介绍 IGMP 和&lt;strong&gt;组播监听&lt;/strong&gt;发现（MLD，用于IPv6）协议。&lt;/p&gt;
&lt;p&gt;在第 4 层中，常见的两种 Internet 传输协议有很大区别。广泛使用的&lt;strong&gt;传输控制协议&lt;/strong&gt;（TCP）会处理数据包丢失、重复和重新排序等 IP 层不处理的问题。它采用面向连接（VC）的方式，并且不保留消息边界。相反，&lt;strong&gt;用户数据报协议&lt;/strong&gt;（UDP）仅提供比 IP 协议稍多的功能。 UDP允许应用发送数据报并保留消息边界，但不强制实现速率控制或差错控制。&lt;/p&gt;
&lt;p&gt;TCP 在两台主机之间提供可靠的数据流传输。 TCP 涉及很多工作，例如将来自应用的数据分解成在网络层中传输的适当尺寸的块，确认接收到的分组和设置超时，以便对方能够确认自已发送的分组。由于传输层提供这种可靠的数据流，所以应用层可以忽略这些细节。TCP 发送到 IP 的 PDU 称为** TCP 段**。&lt;/p&gt;
&lt;p&gt;另一方面， UDP 为应用层提供一种更简单的服务。它允许将数据报从一台主机发送到另一台主机，但不保证数据报能到达另一端。任何可靠性都需要由应用层提供。事实上， UDP 所做的是提供一套端口号，用于复用、分解数据和校验数据的完整性。正如我们所看到的，即使 UDP 和 TCP 在同一层次，它们也是完全不同的。这里给出每种传输层协议的用途，我们可看到使用 TCP 和 UDP 的不同应用。&lt;/p&gt;
&lt;p&gt;这里还有两个传输层协议，它们相对比较新，并被用于某些系统中。由于它们的使用还不是很广泛，所以我们没对它们进行太多讨论，但它们是值得注意的。首先是&lt;strong&gt;数据报拥塞控制协议&lt;/strong&gt;（DCCP），它在 [&lt;a href=&#34;#RFC4340&#34;&gt;RFC4340&lt;/a&gt;] 中定义。它提供了一种介于 TCP 和 UDP 之间的服务类型：面向连接、不可靠的数据报交换，但具有拥塞控制功能。拥塞控制包括发送方控制发送速率的多种技术，以避免流量堵塞整个网络。我们将在第 16 章中结合 TCP 详细介绍拥塞控制。&lt;/p&gt;
&lt;p&gt;另一个是&lt;strong&gt;流控制传输协议&lt;/strong&gt;（SCTP），它在 [&lt;a href=&#34;#RFC4960&#34;&gt;RFC4960&lt;/a&gt;] 中定义，是用于某些特定系统的传输协议。 SCTP 提供类似于 TCP 的可靠交付，但不要求严格保持数据的顺序。它还允许多个数据流逻辑上在同一连接上传输，并提供了一个消息抽象，这是它与 TCP 的主要区别。SCTP 用于在 IP 网络上携带信令消息，这类似于某些电话网络中的用途。&lt;/p&gt;
&lt;p&gt;在传输层之上，应用层负责处理特定应用的细节。有很多常见的应用，几乎每个应用的实现都是基于 TCP/IP 的。应用层与应用的细节有关，但与网络中的数据传输无关。较低的三层则相反：它们对具体应用一无所知，但需要处理所有的通信细节。&lt;/p&gt;
&lt;h3 id=&#34;132-tcpip-中的复用-分解和封装&#34;&gt;1.3.2 TCP/IP 中的复用、分解和封装&lt;/h3&gt;
&lt;p&gt;我们已讨论了协议复用、分解和封装的基础内容。每层都会有一个标识符，允许接收方决定哪些协议或数据流可复用在一起。每层通常也有地址信息，它用于保证一个 PDU 被交付到正确的地方。图 1-6 模拟了如何在一台 Internet 主机上进行分解。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1650548793721.png&#34; alt=&#34;图 1-6&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 1-6 TCP/IP 协议栈将地址信息和协议分解标识符相结合，以决定一个数据报是否被正确接收，以及哪个实体将会处理该数据报。有几层还会检测数值（例如校验和），以保证内容在传输中没有损坏&lt;/p&gt;
&lt;p&gt;虽然它不是 TCP/IP 协议族的真实部分，但我们也能自底向上地说明从链路层开始如何进行分解，这里使用以太网作为例子。我们在第 3 章讨论几种链路层协议。以太网帧包含一个 48 位的目的地址（又称为链路层或介质访问控制（MAC）地址）和一个16位的&lt;strong&gt;以太网类型&lt;/strong&gt;字段。 &lt;code&gt;0x0800&lt;/code&gt; （十六进制）表示这个帧包含 IPv4 数据报。 &lt;code&gt;0x0806&lt;/code&gt; 和 &lt;code&gt;0x86DD&lt;/code&gt; 分别表示 ARP 和 IPv6。 假设目的地址与接收方的一个地址匹配，这个帧将被接收并校验差错，&lt;strong&gt;以太网类型&lt;/strong&gt;字段用于选择处理它的网络层协议。&lt;/p&gt;
&lt;p&gt;如果接收到的帧包含一个IP数据报，以太网头部和尾部信息将被清除，并将剩余字节（包含帧的&lt;strong&gt;有效载荷&lt;/strong&gt;）交给 IP 来处理。 IP检测一系列的字段，包括数据报中的目的 IP 地址。如果目的地址与自已的一个IP地址匹配，并且数据报头部（IP不检测有效载荷）没有错误，则检测 8 位的 IPv4 协议字段（在 IPv6 中称为下一个头部字段），以决定接下来调用哪个协议来处理。常见的值包括1 （ICMP）、 2 （IGMP）、 4 （IPv4）、 6 （TCP） 和 17 （UDP）。数值4 （和41，表示 IPv6 ）的含义是有趣的，因为它表示一个 IP 数据报可能出现在另一个 IP 数据报的有效载荷中。它违反了分层和封装的原有概念，但是作为&lt;strong&gt;隧道技术&lt;/strong&gt;的基础，我们在第3章进行更多讨论。&lt;/p&gt;
&lt;p&gt;如果网络层（ IPv4 或 IPv6 ）认为传入的数据报有效，并且已确定正确的传输层协议，则将数据报（必要时由分片重组而成）交给传输层处理。在传输层中，大部分协议（包括 TCP 和 UDP ）通过端口号将复用分解到适当的应用。&lt;/p&gt;
&lt;h3 id=&#34;133-端口号&#34;&gt;1.3.3 端口号&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;端口号&lt;/strong&gt;是 16 位的非负整数（范围是0 - 65535）。这些数字是抽象的，在物理上没有指任何东西。相反，每个IP地址有 65536 个可用的端口号，每个传输协议可使用这些端口号（在大多数情况下），它们被用于确定正确的接收数据的具体服务。对于客户机/服务器应用（见 1.5.1 节），一台服务器首先“绑定”到一个端口号，然后一个或多个客户机可使用某种特定的传输协议与一台服务器上的端口号建立连接。从这个意义上来说，端口号的功能更像电话号码的扩展，差别是它们通常是由某个标准来分配。&lt;/p&gt;
&lt;p&gt;标准的端口号由 Internet 号码分配机构（IANA）分配。这组数字被划分为特定范围，包括&lt;strong&gt;熟知&lt;/strong&gt;端口号（0 ~ 1023）、&lt;strong&gt;注册&lt;/strong&gt;端口号（ 1024 ~ 49151 ）和&lt;strong&gt;动态/私有&lt;/strong&gt;端口号（49152 ~ 65535）。在传统上，服务器需要绑定到（即在上面提供服务）一个熟知端口，它需要管理员或“根”访问这样的特殊权限。&lt;/p&gt;
&lt;p&gt;熟知端口用于识别很多众所周知的服务，例如安全外壳协议（SSH，端口22）、 FTP （端口 20 和 21）、 Telnet远程终端协议（端口 23）、电子邮件/简单邮件传输协议（SMTP，端口 25）、域名系统（DNS，端口 53）、超文本传输协议或Web（HTTP和HTTPS，端口 80 和 443）、交互式邮件访问协议（ IMAP 和IMAPS，端口 143 和 993 ）、简单网络管理协议（SNMP，端口 161 和 162 ）、轻量级目录访问协议（LDAP，端口 389 ），以及其他几种服务。拥有多个端口的协议（例如 HTTP 和 HTTPS ）通常使用不同端口号，这取决于是否将&lt;strong&gt;传输层安全&lt;/strong&gt;（TLS）与基础的应用层协议共同使用（见第 18 章）。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;注意  如果我们测试这些标准服务和其他 TCP/IP 服务（Telnet、 FTP、 SMTP等）使用的端口
号，会发现它们大多数是奇数。这是有历史原因的，这些端口号从NCP端口号派生而来（ NCP是网络控
制协议，在 TCP 之前作为 ARPANET 的传输层协议）。NCP 虽然简单，但不是全双工的，因此每个
应用需要两个连接，并为每个应用保留奇偶成对的端口号。当 TCP 和 UDP 成为标准的传输层协议
时，每个应用只需要一个端口号，因此来自 NCP 的奇数端口号被使用。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;注册端口号提供给有特殊权限的客户机或服务器，但 IANA 会维护一个为特定用途而保留的注册表，开发新应用时通常应避免使用这些端口号，除非你已购买某些 IANA 分配的端口号。动态/私有端口号基本不受监管。正如我们所看到的，在某些情况下（例如在客户端），端口号的值无关紧要，这是因为它们只是短期被使用。这些端口号又称为&lt;strong&gt;临时&lt;/strong&gt;端口号。它们被认为是临时的，因为客户机只需支持一个应用的客户程序，并不需要被服务器发现以建立一个连接。相反，服务器通常需要不变的名称和端口号，以便被客户机所发现。&lt;/p&gt;
&lt;h3 id=&#34;134-名称-地址和-dns&#34;&gt;1.3.4 名称、地址和 DNS&lt;/h3&gt;
&lt;p&gt;在 TCP/IP 中，每台计算机（包括路由器）的每个链路层接口至少有一个IP地址。 IP 地址足以识别主机，但它们不方便被人们记忆或操作（尤其是更长的 IPv6 地址）。在 TCP/IP 环境中， DNS 是一个分布式数据库，提供主机名和 IP 地址之间的映射（反之亦然）。域名建立是有层次的，以 .com、.org、.gov、.in、.uk 和 .edu 等&lt;strong&gt;域&lt;/strong&gt;结尾。 DNS 是一个应用层协议，因此它的运行依赖于其他协议。虽然大多数 TCP/IP 协议不必关心域名，但用户（例如使用 Web 浏览器）通常会频繁使用域名，因此如果 DNS 不能正常工作，正常的 Internet 访问也难以使用。第 11 章将详细介绍 DNS。&lt;/p&gt;
&lt;p&gt;执行域名操作的应用可以调用一个标准的 API 函数（见 1.5.3 节），将需要查找的 IP 地址（或地址）对应到一个主机名。同样，另一个函数提供反向查找功能，为一个给定的 IP 地址查找对应的主机名。大多数应用程序将主机名作为输人，但是经常也需要一个IP地址。 Web 浏览器支持这种功能。例如，在浏览器中输人&lt;strong&gt;统一资源定位符&lt;/strong&gt;（URL）， &lt;code&gt;http://131.243.2.201/index.html&lt;/code&gt;  和 &lt;code&gt;http://[2001:400:610:102::C9]/index.html&lt;/code&gt;，它们等效于 &lt;code&gt;http://ee.lbl.gov/index.html&lt;/code&gt; （在写作时，第二个例子需要成功建立 IPv6 连接）。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;14-internet-内联网和外联网&#34;&gt;1.4 Internet、内联网和外联网&lt;/h2&gt;
&lt;p&gt;如前所述， Internet （因特网）已发展成为由很多网络互联起来的网络集合。小写字母开头的 internet 表示使用常见协议族互联的多个网络。大写字母开头的 Internet 表示可使用 TCP/IP 通信的世界范围的主机集合。 Internet 是一个 internet，但反过来说是错误的。&lt;/p&gt;
&lt;p&gt;组网在 20 世纪 80 年代得到快速发展的原因之一，那就是很多相互隔离的单机系统组合起来后作用并不明显。几个独立的系统连接起来组成一个&lt;strong&gt;网络&lt;/strong&gt;。虽然已向前迈进了一步，但我们在 20 世纪 90 年代意识到，不能互操作的独立网络不如一个更大的网络有价值。这个概念是 Metcalfe 定律的基础，计算机网络价值大致与连接的端系统（例如用户或设备）数量的平方成正比。 Internet 构想和它支持的协议使不同网络互联成为可能。实际上，这个看似简单的概念非常有用。&lt;/p&gt;
&lt;p&gt;最容易的方式是构造一个由路由器连接两个或多个网络的互联网络。路由器通常是连接网络的一台专用设备，其优点是提供很多不同物理网络的连接，例如以太网、 Wi-Fi、点到点链路、 DSL、电缆 Internet 服务等。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;注意   这些设备又被称为 IP 路由器，但我们将使用路由器这个术语。这些设备在历史上曾被称为网
关，这个术语用于很多比较旧的 TCP/IP 文献中。当前的网关术语用于表示应用层网关 （ALG），它
为一个特定应用（通常是电子邮件或文件传输）连接两个不同协议族（ TCP/IP 和 IBM 的 SNA）。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;近年来，一些其他术语已被采用 TCP/IP 协议的各种互联网络所采纳。&lt;strong&gt;内联网&lt;/strong&gt;是一个用于描述专用互联网络的术语，它通常由一个商业机构或其他企业来运行。大多数情况下，内联网提供的访问资源只供特定企业的成员使用。用户可使用&lt;strong&gt;虚拟专用网&lt;/strong&gt;（VPN）连接到（例如企业）内联网。 VPN 有助于保证内联网中潜在的敏感资源只供授权用户访问，它通常使用前面提到的隧道概念。我们将在第7章详细讨论 VPN。&lt;/p&gt;
&lt;p&gt;在很多情况下，一个企业或商业机构可能希望建立一个网络，其中包含可供合作伙伴或其他相关公司通过 Internet 访问的服务器。这种涉及 VPN 的网络通常被称为&lt;strong&gt;外联网&lt;/strong&gt;，由连接在提供服务的企业防火墙之外的计算机组成（见第 7 章）。从技术上来说，内联网、外联网和 Internet 之间的差别不大，但使用方式和管理策略通常不同，并由此出现更多的专业术语。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;15-设计应用&#34;&gt;1.5 设计应用&lt;/h2&gt;
&lt;p&gt;到目前为止，我们已接触的网络概念提供了一个简单的服务模型 [&lt;a href=&#34;#RFC6250&#34;&gt;RFC6250&lt;/a&gt;] ：在运行于不同（或相同）计算机上的程序之间传输数据。通过这种能力可完成任何有用的事。我们需要使用网络应用来提供服务或执行计算。网络应用的典型结构基于少数几种模式。最常见的模式是&lt;strong&gt;客户机/服务器&lt;/strong&gt;模式和&lt;strong&gt;对等&lt;/strong&gt;模式。&lt;/p&gt;
&lt;h3 id=&#34;151-客户机-服务器&#34;&gt;1.5.1 客户机 / 服务器&lt;/h3&gt;
&lt;p&gt;大多数网络应用被设计为一端是客户机，而另一端是服务器。服务器为客户机提供某类服务，例如访问服务器主机中的文件。我们可以将服务器分为两类：&lt;strong&gt;迭代&lt;/strong&gt;和&lt;strong&gt;并发&lt;/strong&gt;。迭代服务器经过以下步骤:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;等待客户机请求到达。&lt;/li&gt;
&lt;li&gt;处理客户机请求。&lt;/li&gt;
&lt;li&gt;将响应发送给请求的客户机。&lt;/li&gt;
&lt;li&gt;回到步骤 1。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;迭代服务器的问题是步骤 2 需要经过较长时间。在此期间，无法为其他客户机服务。并发服务器经过以下步骤:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;等待客户机请求到达。&lt;/li&gt;
&lt;li&gt;启用一个新服务器实例来处理客户机请求。这可能实际创建一个新的进程、任务或线程，它依赖于底层操作系统的支持。这个新的服务器处理一个客户机的全部请求。当请求的任务完成后，这个新的服务器终止。同时，原有服务器实例继续执行 3。&lt;/li&gt;
&lt;li&gt;回到步骤 1。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;并发服务器的优点是服务器只产生其他服务器实例，并由它们来处理客户机请求。本质上，每个客户都有自已的服务器。假设操作系统支持多个程序（目前所有操作系统基本都支持），则多个客户机可以同时得到服务。我们将原因归于服务器而不是客户机，这是由于客户机通常无法判断与它通信的是迭代或并发服务器。大多数服务器通常是并发的。&lt;/p&gt;
&lt;p&gt;注意，我们使用术语&lt;strong&gt;客户机&lt;/strong&gt;和&lt;strong&gt;服务器&lt;/strong&gt;表示应用，而不是应用所运行的特定计算机系统。相似的术语有时用于表示执行客户机或服务器应用的硬件。虽然这些术语有时并不准确，但它们在实际应用中表现良好。因此，我们通常发现一个服务器（硬件）上运行着多个服务器（应用）。&lt;/p&gt;
&lt;h3 id=&#34;152-对等&#34;&gt;1.5.2 对等&lt;/h3&gt;
&lt;p&gt;有些应用以更分布式的形式设计，其中没有专门的服务器。相反，每个应用既是客户机，又是服务器，有时同时是两者，并能转发请求。有些很流行的应用（例如 Skype [&lt;a href=&#34;#SKYPE&#34;&gt;SKYPE&lt;/a&gt;] 、 BitTorrent[&lt;a href=&#34;#BT&#34;&gt;BT&lt;/a&gt;] ）采用这种式。这种应用称为对等或 P2P 应用。并发的 P2P 应用接收到传入的请求，确定它是否能响应这个请求，如果不能，将这个请求转发给其他对等方。因此，一组 P2P 应用共同形成一个应用网络，也称为&lt;strong&gt;覆盖网络&lt;/strong&gt;。目前，这种覆盖网络是常见的，并且功能强大。例如， Skype 已发展成国际电话呼叫的最大运营商。根据某些估计，在 2009 年， BitTorrent 已占所有 Internet 流量的一半以上 [&lt;a href=&#34;#IPIS&#34;&gt;IPIS&lt;/a&gt; ]。&lt;/p&gt;
&lt;p&gt;P2P网络的一个主要问题是&lt;strong&gt;发现服务&lt;/strong&gt;。也就是说，一个对等方如何在一个网络中发现提供它所需的数据或服务的其他对等方，以及可能进行交互的那些对等方的位置？这通常由一个引导程序来处理，以便每个客户机在最初配置中使用它所需的对等方的地址和端口号。一旦连接成功，新的参与者向其他活跃的对等方发出请求，并根据协议获得对等方提供的服务或文件。&lt;/p&gt;
&lt;h3 id=&#34;153-应用程序编程接口&#34;&gt;1.5.3 应用程序编程接口&lt;/h3&gt;
&lt;p&gt;无论是 P2P 或客户机/服务器，都需要表述其所需的网络操作（例如建立一个连接、写入或读取数据）。这通常由主机操作系统使用一个网络&lt;strong&gt;应用程序编程接口&lt;/strong&gt;（API）来实现。最流行的 API 被称为套接字 Berkeley 套接字，它最初由 [&lt;a href=&#34;#LJFK93&#34;&gt;LJFK93&lt;/a&gt;] 开发。&lt;/p&gt;
&lt;p&gt;本书不是讲述网络编程的，我们只是通过介绍它说明 TCP/IP 的特点，以及哪个特点是由套接字 API 提供的。针对套接字的编程例子细节见 [&lt;a href=&#34;#SFR04&#34;&gt;SFR04&lt;/a&gt;] 。对于IPv6的套接字修改的描述，大量在线文档 [&lt;a href=&#34;#RFC3493&#34;&gt;RFC3493&lt;/a&gt;] 、 [&lt;a href=&#34;#RFC3542&#34;&gt;RFC3542&lt;/a&gt;] 、 [&lt;a href=&#34;#RFC3678&#34;&gt;RFC3678&lt;/a&gt;] 、  [&lt;a href=&#34;#RFC4584&#34;&gt;RFC4584&lt;/a&gt;] 、 [&lt;a href=&#34;#RFC5014&#34;&gt;RFC5014&lt;/a&gt;] 免费提供。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;16-标准化进程&#34;&gt;1.6 标准化进程&lt;/h2&gt;
&lt;p&gt;刚接触TCP/IP协议族的新手通常不了解谁负责各种协议的制定和标准化，以及它们如何运作。有些组织负责解决这个问题。我们最常关注的组织是 Internet 工程任务组（IETF）[&lt;a href=&#34;#RFC4677&#34;&gt;RFC4677&lt;/a&gt;] 。这个组织每年在世界不同地点举行3次会议，以便开发、讨论和通过 Internet 的“核心”协议标准。究竟什么构成“核心”是有争论的，但常见协议（例如IPv4、 IPv6、TCP、 UDP 和 DNS）显然属于此列。 IETF 会议对所有人开放，但它不是免费的。&lt;/p&gt;
&lt;p&gt;IETF是一个论坛，它选举出称为 Internet 架构委员会（IAB）和 Internet 工程指导组（IESG）的领导组织。 IAB 负责提供 IETF 活动指导和执行其他任务，例如任命其他&lt;strong&gt;标准制定组织&lt;/strong&gt;（SDO）的联络员。IESG 具有决策权力，可以修改现有标准，以及建立和审批新的标准。”繁重“或细致的工作通常由 IETF 工作组执行，工作组主席负责协调执行此任务的志愿者。&lt;/p&gt;
&lt;p&gt;除了 IETF，还有另外两个重要组织与 IETF 密切合作。 Internet 研究任务组（IRTF）讨论那些没有成熟到足以形成标准的协议、体系结构和程序。 IRTF 主席是 IAB 的列席成员。 IAB 和 Internet 协会（ISOC）共同影响和促进世界范围的有关 Internet 投术和使用的政策和培训。&lt;/p&gt;
&lt;h3 id=&#34;161-rfc&#34;&gt;1.6.1 RFC&lt;/h3&gt;
&lt;p&gt;Internet 社会中的每个官方标准都以一个 RFC （征求意见）的形式发布。 RFC可以通过多种方式创建， RFC 发布者（RFC编者）对一个已发布的 RFC 创建多个文件。当前文件（在 2010 年）包括 IETF、IAB、IRTF 和独立提交的文件。在被接受并作为 RFC 发布之前，文件将作为临时的 Internet 草案存在，在编辑和审查过程中将接收意见和公布进展。&lt;/p&gt;
&lt;p&gt;不是所有 RFC 都是标准。只有标准跟踪类别的 RFC 被认为是官方标准。其他类别包括当前最佳实践（BCP）、信息、实验和历史。重要的是，一个文件成为一个 RFC，并不意味着 IETF 已采纳它作为标准。事实上，针对现有 RFC 有明显分歧。&lt;/p&gt;
&lt;p&gt;RFC 的大小不等，从几页到几百页。每个 RFC 由一个数字来标识，例如 RFC 1122，新 RFC 被赋予更大的数字。它们可以从一些站点免费获得，包括 &lt;a href=&#34;http://www.rfceditor.org&#34;&gt;http://www.rfceditor.org&lt;/a&gt; 。由于历史原因，下载的 RFC 通常是基本的文本文件，虽然有些 RFC 已使用更先进的文件格式来格式化或撰写。&lt;/p&gt;
&lt;p&gt;许多 RFC 具有特殊意义，它们总结、澄清或解释其他一些特殊标准。例如， [&lt;a href=&#34;#RFC5000&#34;&gt;RFC5000&lt;/a&gt;] 定义了一组其他 RFC （这个 RFC 最近正在撰写中），它们在 2008 年中期被视为官方标准。一个更新列表见当前标准站点 &lt;a href=&#34;#OIPSW&#34;&gt;[OIPSW]&lt;/a&gt; 。&lt;strong&gt;主机需求&lt;/strong&gt; RFC （[&lt;a href=&#34;#RFC1122&#34;&gt;RFC1122&lt;/a&gt;] 和 [&lt;a href=&#34;#RFC1123&#34;&gt;RFC1123&lt;/a&gt;] ）定义 Internet 中 IPv4 主机的协议实现，&lt;strong&gt;路由器需求&lt;/strong&gt; RFC [&lt;a href=&#34;#RFC1812&#34;&gt;RFC1812&lt;/a&gt;] 对路由器进行相同定义。&lt;strong&gt;节点需求&lt;/strong&gt; RFC [&lt;a href=&#34;#RFC4294&#34;&gt;RFC4294&lt;/a&gt;] 对 IPv6 系统进行上述定义。&lt;/p&gt;
&lt;h3 id=&#34;162-其他标准&#34;&gt;1.6.2 其他标准&lt;/h3&gt;
&lt;p&gt;虽然 IETF 负责我们在书中讨论的大部分协议的标准化，但是其他SDO负责定义的协议同样值得我们注意。这些重要组织包括电气和电子工程师学会（IEEE）、万维网联盟（W3C）以及国际电信联盟（ITU）。在本书描述的相关活动中， IEEE 关注第 3 层以下标准（例如 Wi-Fi 和以太网）， W3C关注应用层协议，特别是那些涉及 Web 的技术（例如基于 HTML 的语法）。 ITU特别是 ITU-T （原来的 CCITT）标准化的协议用于电话和蜂窝网络，它正成为 Internet 中一个越来越重要的组成部分。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;17-实现和软件分发&#34;&gt;1.7 实现和软件分发&lt;/h2&gt;
&lt;p&gt;实际上，标准的 TCP/IP 实现来自加州大学伯克利分校计算机系统研究组（CSRG）。它们通过 4.x BSD 系统发布，直到 20 世纪 90 年代中期才出现 BSD 网络发布版。这个源代码已成为许多其他实现的基础。今天，每个流行的操作系统都有自已的实现。在本书中，我们倾向于以 Linux、 Windows 的 TCP/IP 实现为例，有时也采用 FreeBSD 和 Mac OS （两者都由 BSD 版本派生而来）。在大多数情况下，某些特定实现通常无关紧要。&lt;/p&gt;
&lt;p&gt;图 1-7 显示了各种 BSD 版本的年代列表，给出了我们在后面章节中涉及 TCP/IP 的重要特点。它也显示了 Linux 和 Windows 开始支持 TCP/IP 的时间。 BSD 网络发布版显示在第二列，它是免费提供的公共源代码发布版，其中包括所有网络代码，既包括协议本身，又包括很多应用程序和实用工具（例如 Telnet 远程终端程序和 FTP 文件传输程序）。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1650554902565.png&#34; alt=&#34;图 1-7&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;图 1-7 软件版本支持 TCP/IP 的历史可追溯到 1995 年。各种 BSD 版本率先支持 TCP/IP。 在 20 世纪 90 年代早期，由于 BSD 版本的合法性不确定， Linux 最初是为 PC 用户量身定制的代替品。几年后，微软开始在 Windows 中支持 TCP/IP&lt;/p&gt;
&lt;p&gt;20 世纪 90 年代中期， Internet 和 TCP/IP 已很好地被实现。随后，所有流行的操作系统都开始支持 TCP/IP 协议。通过研究 TCP/IP 的新特点发现，之前首先出现在 BSD 版本中的功能，现在通常首先出现在 Linux 版本中。最近， Windows 已实现了一个新的 TCP/IP 协议栈（从 Windows Vista 开始），它具备很多新特点和本地 IPv6 功能。Linux、FreeBSD、MacOS X也支持 IPv6，并且不需要设置任何特殊配置选项。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;18-与-internet-体系结构相关的攻击&#34;&gt;1.8 与 Internet 体系结构相关的攻击&lt;/h2&gt;
&lt;p&gt;在整本书中，我们将简要描述攻击和漏洞，这些内容在讨论设计或实现主题时已谈到。很少有攻击将 Internet 体系结构整体作为目标。但是，值得注意的是， Internet 体系结构交付 IP 数据报是基于目的 IP 地址。因此，恶意用户能在自已发送的每个 IP 数据报的源地址字段中插人任何 IP 地址，这种行为称为&lt;strong&gt;欺骗&lt;/strong&gt;。生成的数据报被交付到目的地，但难以确定它的真实来源。也就是说，很难或不能确定从 Internet 中接收的数据报来源。&lt;/p&gt;
&lt;p&gt;欺骗可以与 Internet 中出现的各种攻击相结合。&lt;strong&gt;拒绝服务&lt;/strong&gt;（DoS）攻击通常涉及消耗大量的重要资源，以导致合法用户被拒绝服务。例如，向一台服务器发送大量 IP 数据报，使它花费所有时间处理接收的分组和执行其他无用的工作，这是一种类型的 DoS 攻击。有些 DoS 攻击可能涉及以很多流量堵塞网络，导致其无法发送其他分组。这通常需要使用很多计算机来发送，并形成一个**分布式DoS （DDoS）**攻击。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;未授权访问&lt;/strong&gt;攻击涉及以未授权方式访问信息或资源。它可以采用多种技术来实现，例如利用协议实现上的错误来控制一个系统（称为占有这个系统，并将它变成一个&lt;strong&gt;僵尸&lt;/strong&gt;）。它也可以涉及各种形式的伪装，例如攻击者的代理冒充一个合法用户（例如运行用户证书）。有些更恶毒的攻击涉及使用恶意软件（malware）控制很多远程系统，并以一种协同、分布式的方式（称为&lt;strong&gt;僵尸网络&lt;/strong&gt;（botnets））使用它们。那些出于（非法）获利或其他恶意目的而有意开发恶意软件和利用系统的程序员通常称为&lt;strong&gt;黑帽&lt;/strong&gt;。所谓的&lt;strong&gt;白帽&lt;/strong&gt;也在利用同样的技术做这方面的事情，但他们只是通知系统存在漏洞而不是利用它们。&lt;/p&gt;
&lt;p&gt;关于 Internet 体系结构，值得注意的是，最初的 Internet 协议没有进行任何加密，加密可用于支持认证、完整性或保密。因此，恶意用户仅通过分析网络中的分组，通常就可以获得私人信息。如果具有修改传输中的分组的能力，他就可以冒充用户或更改消息内容。虽然这些问题由于加密协议（见第 18 章）而显著减少，但旧的或设计不当的协议有时在简单的窃听攻击面前仍很脆弱。由于无线网络的流行，“嗅探”其他人发送的分组比较容易，因此应避免使用旧的或不安全的协议。注意，虽然可在某层（例如 Wi-Fi 网络的链路层）启用加密，但只有主机到主机的加密（IP 层或以上）能保护穿过多个网段，以及可能采用遍历方式到达最终目的地的 IP 数据报。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;19-总结&#34;&gt;1.9 总结&lt;/h2&gt;
&lt;p&gt;本章快速浏览了网络体系结构和设计，特别是 TCP/IP 协议族的概念，后面章节将详细讨论它们。 Internet 体系结构被设计成支持现有不同网络互联，同时提供了广泛的服务和协议操作。选择使用数据报的分组交换是看中它的鲁棒性和效率。数据安全性和交付可预测性（例如有限的延迟）是次要原因。&lt;/p&gt;
&lt;p&gt;基于对操作系统分层和模块化软件设计的理解，早期的 Internet 协议实现者采纳了经过封装的分层设计。 TCP/IP 协议族的 3 个主要层次是网络层、传输层和应用层，我们前面提到过每层具有不同功能。我们还提到了链路层，它与 TCP/IP 协议关系密切。我们将在以后的章节中详细讨论。&lt;/p&gt;
&lt;p&gt;在 TCP/IP 中，网络层和传输层之间的区别至关重要：网络层（ IP ）提供了一个不可靠的数据报服务，必须由 Internet 中所有可寻址的系统来实现，而传输层（ TCP 和 UDP ）为端主机上运行的应用程序提供了端到端服务。主要的传输层协议有根本性的差异。 TCP提供了带流量控制和拥塞控制的有序、可靠的流交付。除了用于多路分解的端口号和错误检测机制之外， UDP提供的功能基本没有超越IP。但是，与 TCP 不同， UDP支持组播交付。&lt;/p&gt;
&lt;p&gt;每层都使用地址和分解标识符，用以避免混淆不同协议或相同协议的不同关联/连接。链路层多接入网络通常使用 48 位地址；IPv4 使用 32 位地址， IPv6使用 128 位地址。TCP 和 UDP 传输协议使用一系列不同的端口号。有些端口号由标准来分配，有些端口号是临时使用的，通常由客户端与服务器通信时使用。端口号并不代表任何实际内容，它们只是作为应用程序与对方通信的一种方式。&lt;/p&gt;
&lt;p&gt;虽然端口号和 IP 地址通常足以识别 Internet 中的一个服务，但它们不方便人们记忆或使用（特别是 IPv6 地址）。因此， Internet 使用了一种层次结构的主机名，可以通过 DNS 将主机名转换为 IP 地址（或者反过来），而DNS是一个运行在 Internet 上的分布式数据库应用程序。 DNS 已成为 Internet 基础设施中的重要组成部分，我们应尽力使它以更安全的方式运行（见第18章）。&lt;/p&gt;
&lt;p&gt;互联网络（ internet）是一个网络集合，其中最常见的基本设备是路由器，它被用于在 IP 层连接多个网络。 Internet 是一个遍布全球和互联近两亿用户的互联网络（在 2010 年）。专用的互联网络称为内联网，通常使用特殊设备（防火墙，在第 10 章讨论）连接 Internet，它可以防止未授权的访问企图。外联网通常由一个机构的多个内联网组成，它能以有限的方式被合作伙伴或分支机构所访问。&lt;/p&gt;
&lt;p&gt;网络应用通常采用客户机/服务器或对等模式设计。客户机/服务器是更流行、更传统的模式，但对等模式也获得了巨大成功。无论哪种设计模式，应用程序都要调用 API 执行网络任务。最常见的 TCP/IP 网络 API 称为套接字。它由 BSD UNIX 发布版提供，其软件版本率先使用 TCP/IP。 20 世纪 90年代末， TCP/IP 协议族和套接字 API 被用于所有流行的操作系统。&lt;/p&gt;
&lt;p&gt;安全性不是 Internet 体系结构的主要设计目标。由于端主机易于篡改不安全的 IP 数据报的源 IP 地址，接收方难以确定分组的来源。分布式 DoS 攻击仍是一个挑战，作为受害者的端主机形成僵尸网络进行 DDoS 和其他攻击，而主机所有者通常对这些并不知情。最后，早期的 Internet 协议难以保护敏感信息的隐私，但这些协议中的大多数当前已过时，其现代版本通常采用加密方式为主机之间通信提供保密和认证。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;110-参考文献&#34;&gt;1.10 参考文献&lt;/h2&gt;
&lt;p&gt;&lt;span id=&#34;B64&#34;&gt;[B64]&lt;/span&gt; P.Baran, &amp;quot;On Distributed Communications: 1. Introduction to Distributed Communications Networks,&amp;quot;  RAND Memorandum RM-3420-PR, Aug. 1964.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;BT&#34;&gt; [BT] &lt;/span&gt; http://www.bittorrent.com&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;C88&#34;&gt; [C88] &lt;/span&gt; D.Clark, &amp;quot;The Design Philosophy of the DARPA Internet Protocols,&amp;quot; Proc. ACM SIGCOMM, Aug. 1988.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;CK74&#34;&gt;[CK74] &lt;/span&gt; V Cerf and R.Kahn, &amp;quot;A Protocol for Packet Network Intercommunication,&amp;quot; IEEE Transactions on Communications, COM-22（5）, May 1974.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;D08&#34;&gt; [D08] &lt;/span&gt; J.Day Patterns in Network Architecture: A Return to Fundamentals（Prentice Hall, 2008）.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;D68&#34;&gt; [D68] &lt;/span&gt; E.Dijkstra,  &amp;quot;The Structure of the &#39;THE&#39;-Multiprogramming system,” Communications of the ACM, 11（5）, May 1968.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;DBSW66&#34;&gt; [DBSW66] &lt;/span&gt; D.Davies, K.Bartlett, R.Scantlebury and P Wilkinson, ‘A Digital Communications Network for Computers Giving Rapid Response at Remote Terminals,” Proc. ACM Symposium on Operating System Principles, Oct. 1967.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;I96&#34;&gt; [I96] &lt;/span&gt; IBM Corporation, Systems Network Architecture--APPN Architecture Reference, Document SC30-3422-04, 1996.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;IPIS&#34;&gt; [IPIS] &lt;/span&gt; Ipoque, Internet Study 2008/2009,  http://www.ipoque.com/resources/internet-studies/internet-study-2008_2009&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;K64&#34;&gt;[K64]&lt;/span&gt; L.Kleiurock, Communication Nets: Stochastic Message Flow and Delay  （McGraw-Hill, 1964）.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;LC04&#34;&gt; [LC04] &lt;/span&gt; S.Lin and D. Costello Jr., Error Control Coding, Second Edition  （Prentice Hall, 2004）.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;LJFK93&#34;&gt; [LJFK93] &lt;/span&gt; S.Leffler, W.Joy, R.Fabry, and M.Karels,  &amp;quot;Networking Implementation Notes-4.4BSD Edition,&amp;quot; June 1993.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;LT68&#34;&gt; [LT68] &lt;/span&gt; J.C.R.Licklider and R.Taylor, “The Computer as a Communication Device,&amp;quot; Science and Technology, Apr. 1968.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;OIPSW&#34;&gt; [OIPSW] &lt;/span&gt; http://www.rfc-editor.org/rfcxx00.htm&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;PO7&#34;&gt; [PO7] &lt;/span&gt; J.Pelkey, Entrepreneurial Capitalism and Innovation: A History of Computer Communications 1968-1988, available at http://historyofcomputercommunications.info&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;P73&#34;&gt; [P73] &lt;/span&gt; L.Pouzin, &amp;quot;Presentation and Major Design Aspects of the CYCLADES Computer Network,&amp;quot; NATO Advanced Study Institute on Computer Communication Networks, 1973.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFCO871&#34;&gt;[RFCO871]&lt;/span&gt; M.Padlipsky &amp;quot;A Perspective on the ARPANET Reference Model,&amp;quot; Internet RFC O871, Sept. 1982.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFCO959&#34;&gt; [RFCO959] &lt;/span&gt; J.Postel and J.Reynolds, “File Transfer Protocol,” Internet RFC O959/STD OOO9 0ct. 1985.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC1122&#34;&gt; [RFC1122] &lt;/span&gt; R.Braden, ed., &amp;quot;Requirements for Internet Hosts-Communication Layers,″ Internet RFC 1122/STD OOO3, Oct. 1989.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC1123&#34;&gt; [RFC1123] &lt;/span&gt; R.Braden, ed., &amp;quot;Requirements for Internet Hosts-Application and Support,″ Internet RFC l123/STD OOO3, Oct. 1989.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC1812&#34;&gt; [RFC1812] &lt;/span&gt; F.Baker, ed., &amp;quot;Requirements for IP Version 4 Routers,″ Internet RFC 1812, June 1995.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC3493&#34;&gt; [RFC3493] &lt;/span&gt; R.Gilligan, S.Thomson, J.Bound, J.McCann, and W.Stevens, &amp;quot;Basic Socket Interface Extensions for IPv6,&amp;quot; Internet RFC 3493 （informational）, Feb. 2003.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC3542&#34;&gt; [RFC3542] &lt;/span&gt; W.Stevens, M.Thomas, E.Nordmark, and T.Jinmei, &amp;quot;Advanced Sockets Application Program Interface （API） for IPv6,″ Internet RFC 3542 （informational）, May 2003.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC3678&#34;&gt; [RFC3678] &lt;/span&gt; D.Thaler, B.Fenner, and B.Quinn, &amp;quot;Socket Interface Extensions for Multicast Source Filters,&amp;quot; Internet RFC 3678 （informational）, Jan. 2004.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC3787&#34;&gt; [RFC3787] &lt;/span&gt; J.Parker, ed., &amp;quot;Recommendations for Interoperable IP Networks Using Intermediate System to Intermediate System （IS-1S）,&amp;quot; Internet RFC 3787 （informational）, May 2004.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC4294&#34;&gt; [RFC4294] &lt;/span&gt; J.Loughney ed., &amp;quot;IPv6 Node Requirements,&amp;quot; Internet RFC 4294 （informational）, Apr. 2006.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC4340&#34;&gt; [RFC4340] &lt;/span&gt; E.Kohler, M.Handley and S.Floyd, &amp;quot;Datagram Congestion Control Protocol （DCCP）,&amp;quot; Internet RFC 4340, Mar. 2006.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC4584&#34;&gt; [RFC4584] &lt;/span&gt; S.Chakrabarti and E.Nordmark, &amp;quot;Extension to Sockets API for Mobile IPv6,″ Internet RFC 4584 （informational）,JuIy 2006.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC4677&#34;&gt; [RFC4677] &lt;/span&gt; P.Hoffman and S.Harris, &amp;quot;The Tao of IETF-A Novice&#39;s Guide to the Internet Engineering Task Force,” Internet RFC 4677 （informational）, Sept. 2006.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC4960&#34;&gt; [RFC4960] &lt;/span&gt; R.Stewart, ed., &amp;quot;Stream Control Transmission Protocol,&amp;quot; Internet RFC 4960, Sept. 2007.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC5000&#34;&gt; [RFC5000] &lt;/span&gt; RFC Editor, &amp;quot;Internet official Protocol Standards,&amp;quot; Internet RFC 5000/STD OOO1 （informational）, May 2008.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC5014&#34;&gt; [RFC5014] &lt;/span&gt; E.Nordmark, S.Chakrabarti, and J.Laganier, &amp;quot;IPv6 Socket API for Source Address Selection,&amp;quot; Internet RFC 5014 （informational）, Sept. 2007.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;RFC6250&#34;&gt; [RFC6250] &lt;/span&gt; D.Thaler, “Evolution of the IP Model,″ Internet RFC 6250 （informational）, May 2011.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;SFR04&#34;&gt; [SFR04] &lt;/span&gt; W.R.Stevens, B.Fenner, and A.Rudoff, UNIX Network Programming, Volume 1, Third Edition（Prentice Hall, 2004）.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;SKYPE&#34;&gt; [SKYPE] &lt;/span&gt; http://www.skype.com&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;SRC84&#34;&gt; [SRC84] &lt;/span&gt; J.Saltzer, D.Reed, and D.Clark, &amp;quot;End-to-End Arguments in System Design,” ACM Transactions on Computer System, 2（4）, Nov. 1984.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;WO2&#34;&gt; [WO2] &lt;/span&gt; M.Waldrop, The Dream Machine: J.C.R.Licklider and the Revolution That Made Computing Personal（Penguin Books, 1992）.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;X85&#34;&gt; [X85] &lt;/span&gt; Xerox Corporation, XeroX Network Systems Architecture--General Information Manual, XNSG O68504, 1985.&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;Z80&#34;&gt; [Z80] &lt;/span&gt; H.Zimmermann, &amp;quot;OSI Reference Model-The ISO Model of Architecture for open systems Interconnection,&amp;quot; IEEE Transactions on Communications, COM28（4）, Apr. 1980.&lt;/p&gt;
">《TCP/IP 详解 卷一：协议》第一章：概述</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://wenbozhangw.github.io/post/what-is-jep/"" data-c="
          &lt;p&gt;JEP 是 JDK改进提案(JDK Enhancement Proposal) 的缩写，简单来说，这是一个关于增强 JDK 的建议。&lt;br&gt;
JEP 可以是关于语言功能的，也可以是关于 API 的，例如 &lt;a href=&#34;https://openjdk.java.net/jeps/395&#34;&gt;JEP 395&lt;/a&gt; 中关于 Record 的提案。Records 是一种语言特征，在反射 API 中进行了一些更改；或者关于 switch 表达式的新 switch 语法的 &lt;a href=&#34;https://openjdk.java.net/jeps/361&#34;&gt;JEP 361&lt;/a&gt; ，这是语言特性；它也可以是关于 JVM 是如何工作的，例如 &lt;a href=&#34;https://openjdk.java.net/jeps/333&#34;&gt;JEP 333&lt;/a&gt; 是关于 ZGC 的；它可能是和安全更新相关的，和工具相关的，任何有关 Java 的东西。&lt;/p&gt;
&lt;!-- more --&gt;
&lt;p&gt;JEP 是十年前创建的，它们有编号，第一个 JEP 是 &lt;a href=&#34;https://openjdk.java.net/jeps/1&#34;&gt;JEP 1: JDK Enhancement-Proposal &amp;amp; Roadmap Process&lt;/a&gt;，创建于 2011 年 6 月 23 日，它给出了详细的 JEP 定义，JEP 的第一个目标是描述一个新事物，Java可能需要从社区获得评论和反馈，这个新元素在将来仍然会很遥远，JEP 可能需要大约三年来实现。JEP 1 的第二个目标是定义一个统一的格式来描述这些新事物，以及你可以找到这些 JEP 的地方。JEP 只适用于重大修改，小错误修复不会通过 JEP 发布。JEP 告诉我们几件事，一个 JEP 应该代表至少两周的开发，JEP 应该讨论一些需要广泛了解的东西，可以创建 JEP 来讨论远远没有准备好但值得研究的事情，这个目标就是：得到一些评论，一些反馈，一些关于这些的想法。因此，如果你想这么做，只需要使用 JEP，JEP 也可以撤回。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://openjdk.java.net/jeps/2&#34;&gt;JEP 2: JEP Template&lt;/a&gt;，创建于 2011 年 6 月 23 日，该 JEP 提供了关于应该如何编写 JEP 的细节，最后一个是 2011 年 8 月 14 日发布的第三个 JEP，编号为 0，即&lt;a href=&#34;https://openjdk.java.net/jeps/0&#34;&gt;JEP 0: JEP Index&lt;/a&gt;，JEP 0 实际上是所有 JEP 的目录，如果你在寻找一个特定的 JEP，看这个是最好的。&lt;/p&gt;
&lt;p&gt;一个新的语言特征可以分散多个 JEP 之间，例如对于 Record 功能，分别有 JDK 14 的 &lt;a href=&#34;https://openjdk.java.net/jeps/359&#34;&gt;JEP 359&lt;/a&gt; 第一次预览；还有 JDK 15 中的 &lt;a href=&#34;https://openjdk.java.net/jeps/384&#34;&gt;JEP 384&lt;/a&gt; 的 Record 第二次预览；JDK 17 的 &lt;a href=&#34;https://openjdk.java.net/jeps/395&#34;&gt;JEP 395&lt;/a&gt; 最终 Record 特性。最终，我们就有了 Record 的功能。&lt;/p&gt;
&lt;p&gt;JEP 可以给你带来这几样东西，它的目标，它的非目标，它的动机，为什么有这个 JEP 以及它将带来的 JDK 的改进，最后一点，它应该描述这个 JEP 是关于什么的，以及它将对JDK中的其他地方产生什么影响。&lt;/p&gt;
&lt;p&gt;所以，对于 Record 的 JEP，目标是设计一个面向对象的结构，表达一个简单的值聚合类型；第二，是帮助开发人员关注模块化的不可变数据，而不是可扩展行为；第三，自动实现数据驱动方法，如 &lt;code&gt;equals()&lt;/code&gt; 和 accessors；第四，保持长久 Java 原则，例如名义类型(nominal typing) 和 迁移兼容性(migration compatibility)。我把这些方法称为样本代码(boilerplate)，因为这就是你想要的，简单地说，Record 是值的集合(aggregation of values)，保存不可变数据(hold immutable data)，自动实现(automatically implement)。保持 Java 主体，每一种类型作为名字，所以简单地说，Record 只是一个命名的元组。&lt;/p&gt;
&lt;p&gt;这里有三个非目标，第一个非目标是向样板代码(boilerplate)宣战；第二个非目标，解决使用 Java bean 命名约定的可变类问题；第三个非目标，添加注释驱动的代码生成。&lt;/p&gt;
&lt;p&gt;Records 的动机在这里是为了更容易地创建仅仅作为数据载体的类。接下来是描述，在 &lt;a href=&#34;https://openjdk.java.net/jeps/395&#34;&gt;JEP 395&lt;/a&gt; 中的 Title 下，你可以看到几页非常清晰的代码示例和模式解释，这是一个非常容易阅读和教育的文本。JEP 不是作为规范文档编写的，在规范文档中你可可能会想添加只对实现者有用的不易于阅读的规范文档，不适合需要 Record 作为日常工作工具的开发人员。最后，依赖部分，这里是对反射 API 的影响，在 Java 反射 API 的几个类中有更多的方法，以及 Record 如何与封闭类(sealed class)一起工作，因为 Record 是用 final class 建模的。&lt;/p&gt;
&lt;p&gt;简单地说，JEP 是为了易于阅读，易于访问和学习教育而编写的文档，所以你可以阅读它们，这对你的 Java 有好处。&lt;/p&gt;
">What is JEP ?</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://wenbozhangw.github.io/post/domain-driven-design-tackling-complexity-in-the-heart-of-software/"" data-c="
          &lt;h2 id=&#34;acknowledgements&#34;&gt;Acknowledgements&lt;/h2&gt;
&lt;p&gt;四年多来，我一直在写这本书，以这样或那样的形式，一路上有很多人帮助和支持我。&lt;/p&gt;
&lt;p&gt;我感谢许多阅读手稿和评论的人。如果没有这些反馈，这本书是不可能完成的。有几家对他们的评论给予了特别慷慨的关注。由Russ Rufer和Tracy Bialek领导的硅谷模式小组(Silicon Valley Patterns Group)花了七周时间仔细审阅这本书的第一份完整草稿。由拉尔夫·约翰逊(Ralph Johnson)领导的伊利诺伊大学读书小组也花了几周时间仔细审查后来的草稿。听这些小组长时间、生动的讨论，产生了深远的影响。Kyle Brown和Martin Fowler提供了详细的反馈，有价值的见解和无价的道德支持(坐在一条鱼上)。沃德·坎宁安的反馈很重要。Alistair Cockburn鼓励我，帮助我在出版过程中找到自己的方向。大卫·西格尔(David Siegel)和尤金·沃林福德(Eugene Wallingford)帮我避免了在技术层面上的尴尬。Vibhu Mohindra和Vladimir Gitlevitch煞费苦心地检查了所有的代码示例。&lt;/p&gt;
&lt;p&gt;Rob Mee阅读了我最早的一些探索材料，并与我一起进行头脑风暴，当我在探索某种方式来传达这种设计风格时。然后他给我灌了一份很久以后的草稿。&lt;/p&gt;
&lt;p&gt;Josh Kerievsky负责了这本书发展的一个主要转折点:他说服我尝试“亚历山大”模式格式，这成为了这本书的组织支柱。在1999年的PLoP会议之前的密集“指导”过程中，他还帮助我将第二部分中的一些材料第一次整合成一个连贯的形式。这成了本书其余大部分内容的基础。&lt;/p&gt;
&lt;p&gt;在构思这本书之前，我必须先形成自己对软件开发的看法和理解。这一发展在很大程度上要归功于一些才华横溢的人的慷慨，他们是我的非正式导师，也是我的朋友。David Siegel, Eric Gold和Iseult White，以不同的方式帮助我形成了软件设计的思维方式。几乎同时，Bruce Gordon, Richard Freyberg和Judith Segal也以不同的方式帮助我在成功的项目工作中找到自己的道路。&lt;/p&gt;
&lt;p&gt;在这个关键时期，我也有很多想法，这些想法形成了我自己技术观点的基础。其中一些贡献将在主要文本中清楚说明，并在可能时加以引用。其他的是如此的基本，我甚至没有意识到他们对我的影响。&lt;/p&gt;
&lt;p&gt;我的硕士论文导师，Bala Subramanium博士，让我对数学建模产生了兴趣，我们把它应用到化学反应动力学中，但建模就是建模，而这项工作正是我写这本书的原因之一。&lt;/p&gt;
&lt;p&gt;甚至在此之前，我的思维方式的形成多亏了我的父母，Carol 和 Gary Evans，以及一些特殊的老师，特别是 Dale Courier（一所高中的数学老师），Mary Brown（高中英语作文老师），和一个六年级的科学课老师的名字，我很抱歉已经遗忘了。&lt;/p&gt;
&lt;p&gt;最后，我要感谢我的朋友和家人，还有 Fernando De Leon，感谢他们在这漫长的过程中给予我的鼓励。&lt;/p&gt;
&lt;h2 id=&#34;preface&#34;&gt;Preface&lt;/h2&gt;
&lt;p&gt;领先的软件设计师已经认识到领域建模和设计(domain modeling and design)作为关键的主题至少已经有 20 年了，但是令人惊讶的是，几乎没有人写过需要做什么或者如何做。虽然它从来没有被清晰的表述出来，但一种哲学已经发展成为对象社区中的一股暗流，我称之为“领域驱动设计(domain-driven design)”。&lt;/p&gt;
&lt;p&gt;在过去的十年里，我专注于在几个业务和技术领域开发复杂的系统。我尝试过设计和开发过程中的最佳实践，因为它们已经从面向对象开发社区的领导者那里出现了。我的一些项目非常成功；一些失败了。成功案例的共同特征是丰富的领域模型，它通过设计的迭代不断发展，并成为项目结构的一部分。&lt;/p&gt;
&lt;p&gt;本书提供了一个设计决策的框架和一个讨论领域设计的技术词汇表。它综合了广泛接受的最佳实践，以及我自己的见解和经验。面对复杂领域的项目可以使用这个框架，系统地实现领域驱动设计。&lt;/p&gt;
&lt;h3 id=&#34;contrasting-tree-projects&#34;&gt;Contrasting Tree Projects&lt;/h3&gt;
&lt;p&gt;我看到一个项目用一个有用的、简单的基于网络的交易系统很快就完成了。开发人员凭自己的感觉，但简单的软件也可以在不太关注设计的情况下编写出来。由于这一初步成功，人们对未来发展的期望很高。就在这个时候，有人找我做第二个版本的工作。当我仔细观察的时候，我发现他们缺少一个领域模型，甚至在项目上没有通用的语言，并且被强加于非结构化的设计。所以当项目领导不同意我的评估时，我拒绝了这份工作。一年后，他们发现自己陷入了困境，无法发布第二个版本。尽管他们对技术的使用不是典范，但业务逻辑战胜了他们。他们的第一个版本过早地僵化为一个高维护的遗产。&lt;/p&gt;
&lt;p&gt;要想提高复杂性的上限，需要一种更严肃的领域逻辑设计方法。在我职业生涯的早期，我很幸运地完成了一个强调领域设计的项目。这个项目，在一个至少和上面一样复杂的领域，也开始了一个适度的初步成功，为机构交易者交付一个简单的应用程序。但这一交付之后，开发的速度连续加快。每次后续的迭代都为集成和细化功能打开了令人兴奋的新选项。团队的方式能够灵活地响应交易员的需求和扩展能力。这种向上的轨迹直接归因于一个尖锐的领域模型，它在代码中反复的细化和表达。随着团队对该领域有了新的认识，模型也加深了。开发人员之间以及开发人员与领域专家之间的交流质量得到了提高，而且设计非但没有增加越来越重的维护负担，反而变得更容易修改和扩展。&lt;/p&gt;
&lt;p&gt;不幸的是，并非所有以这种意图开始的项目都能达到这种良性循环。我参加的一个项目一开始有一个远大的志向，那就是建立一个基于领域模型的全球企业系统，但最后却有一个失望的结果。这个团队有很好的工具，对业务有很好的理解，并且非常重视建模。但是开发人员角色的分离导致了模型和实现之间的脱节，因此设计没有反映正在进行的深入分析。在任何情况下，详细业务对象的设计都不够严格，无法支持在详细的应用程序中组合它们。由于开发人员的技能水平参差不齐，且对所需的特定类型的严格性没有清晰的理解，重复的迭代并没有产生代码的改进。几个月过去了，开发工作陷入了复杂性的泥潭，团队是去了系统的凝聚力。经过多年的努力，该项目确实生产处了规模不大、有用的软件，但已经放弃了早期的雄心壮志和模型重点。&lt;/p&gt;
&lt;p&gt;当然，很多事情会让项目偏离轨道，比如官僚主义、目标不明确、资源缺乏等，但是设计方法在很大程度上决定了软件的复杂程度。当复杂性失去控制时，软件就不能再被很好地理解以方便地更改或扩展。相比之下，一个好的设计可以从这些复杂的功能中创造机会。&lt;/p&gt;
&lt;p&gt;其中一些设计因素是技术性的，大量的工作已经投入到网络、数据库和软件的其他技术层面的设计中。关于如何解决这些问题的书已经出版了。开发人员已经培养了他们的技能。&lt;/p&gt;
&lt;p&gt;然而，许多应用程序最显著的复杂性并不是技术上的。它属于领域本身，用户的活动或业务。如果在设计中没有处理这个领域的复杂性，那么基础设施技术是否经过了良好的考虑就无关紧要了。一个成功的设计必须系统地处理软件的这个核心方面。&lt;/p&gt;
&lt;p&gt;这本书的前提是：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;对大多数软件项目，主要关注点应该放在域和域逻辑(domain and domain logic)上。&lt;/li&gt;
&lt;li&gt;复杂的领域涉及应该基于模型。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;领域驱动设计是一种思维方式和一组优先级，旨在加速必须处理复杂领域的软件项目。为了实现这个目标，这本书提出了一套管饭的设计实践，技术和原则。&lt;/p&gt;
&lt;h3 id=&#34;design-vs-development-process&#34;&gt;Design vs. Development Process&lt;/h3&gt;
&lt;p&gt;设计的书。过程的书。它们甚至很少相互引用。每一个都是一个复杂的主题。这是一本设计的书籍。但我认为，要想将设计理念成功地付诸实践，而不是在学术讨论中枯竭，这两个问题是不可分割的。当人们学习设计技术时，他们会面对真正项目的混乱现实。他们不知道什么时候该考虑某个特定的设计方面，什么时候该放弃以节省时间。虽然我们可以与其他团队成员讨论抽象设计原则的应用，但更自然的做法是讨论我们一起做的事情。所以，虽然这是一本书，但我要在需要的时候，打破这个人为的界限。这将把设计至于开发过程的上下文中。&lt;/p&gt;
&lt;p&gt;这本书并不是针对特定的方法论，而是面向“敏捷开发过程”的新系列。具体的说，它假定在项目中有一些过程实践。这两个实践是应用本书中的方法的先决条件。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;迭代开发。迭代开发的实践已经被提倡和实践了几十年，并且是敏捷开发方法的基石。关于敏捷开发和极限编程的文献中有很多很好的讨论，其中有 [Cockburn1998] 和 [Beck 1999]。&lt;/li&gt;
&lt;li&gt;开发人员和领域专家之间的密切关系。领域驱动的设计将大量的知识转化为一个模型，该模型反映了对领域的深刻理解和对关键概念的关注。这是一个了解领域的人和知道如何构建软件的人之间的协作。因为它是迭代的，所以这种协作必须在项目的整个生命周期中继续进行。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;极限编程（Extreme Programming, XP）是由 Kent Beck，Ward Cunningham 和其他人 [Beck 2000] 构想的，它是敏捷过程中最杰出的，也是我接触最多的。为了使讨论更加具体，我将在整本书中使用 XP 作为讨论设计和过程交互的基础。说明的原则很容易适用于其他敏捷过程。&lt;/p&gt;
&lt;p&gt;近年来，人们开始反对复杂的开发方法，这种方法是无用的、静态的文档、强迫性的前期计划和设计来给项目增加负担。相反，敏捷过程（如 XP）强调的是应对变化和不确定性的能力。&lt;/p&gt;
&lt;p&gt;XP 认识到设计决策的重要性，但强烈反对预先设计。相反，它投入了令人钦佩的努力来增加沟通，并增加项目快速改变方向的能力。有了这种反应能力，开发人员可以在项目的任何阶段使用“最简单的可以工作的东西”，然后不断地重构，进行许多小的设计改进，最终达到符合客户真正需求的设计。&lt;/p&gt;
&lt;p&gt;对于一些设计狂热者来说，这是一剂继续的解毒剂。项目陷入了没有价值的繁琐文档中。他们遭受了“分析麻痹”，如此害怕一个不完美的设计，以至于他们没有取得任何进展。必须有所改变。&lt;/p&gt;
&lt;p&gt;不幸的是，其中一些新的过程思想很容易被误解。每个人对“最简单”都有不同的定义。没有设计原则来指导这些小的重新设计的持续重构，会产生难以理解或更改的代码库——这与敏捷性背道而驰。而且，尽管对未来预料到的需求的恐惧尝尝导致过度工程化，但试图避免过度工程化可能会发展成另一种恐惧：对任何深度设计思考的恐惧。&lt;/p&gt;
&lt;p&gt;事实上，XP 最适合具有敏锐设计意识的开发人员。XP 过程假设您可以通过重构来改进设计，并且您经常和迅速地这样做。但是设计选择使重构本身变得更容易或更困难。XP 过程试图增加团队交流。但是模型和设计的选择会澄清或混淆沟通。我们需要的是一种能够发挥作用的领域建模和设计方法。&lt;/p&gt;
&lt;p&gt;这本书交织了设计和开发实践，并说明了领域驱动的设计和敏捷开发是如何相互加强的。在敏捷开发过程的上下文中，一种复杂的领域建模方法将加速开发。过程与领域开发的相互关系使这种方法比任何真空中的“纯”设计处理更实用。&lt;/p&gt;
&lt;h3 id=&#34;the-structure-of-this-book&#34;&gt;The Structure of This Book&lt;/h3&gt;
&lt;p&gt;本书分为四个主要部分:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;第一部分：Putting the Domain Model to Work&lt;/em&gt; 中提出了领域驱动开发的基本目标，这些开发将在后面的部分中激励实践。由于软件开发有很多方法，第一部分定义了术语，并概述了领域模型置于驱动通信和设计的角色中的含义。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;第二部分：The Building Blocks of Model-driven Design&lt;/em&gt; 将面向对象领域建模的最佳时间核心浓缩为一组基本模块。本节的重点是弥合模型和实际运行的软件之间的差距。共享这些标准模式为设计带来的秩序，并使团队成员很容易理解彼此的工作。使用标准模式还可以建立一种公共语言，所有团队成员都可以使用它来讨论模型和设计决策。&lt;/p&gt;
&lt;p&gt;但是，本节的主要观点是关于保持模型和实现相互对齐的那种决策、增强彼此的有效性。这种对齐需要注意单个元素的细节。在这种小范围内的精心制作为开发人员提供了一个稳定的平台来应用第三部分和第四部分中的建模方法。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;第三部分：Refactoring Toward Deeper Insight&lt;/em&gt; 超越了构建模块的挑战，将它们组装成提供回报的实际模型。本节强调的是发现过程，而不是直接跳到深奥的设计原则。有价值的模型不会马上出现。它们要求对该领域有深刻的理解。这种理解来自于深入，实现一个基于 天真的(naïve) 模型的初始设计，然后一次又一次地转换它。每次团队获得洞察力时，模型都会被转换为揭示更丰富的知识，代码也会被重构，以反映更深层的模型，并使其潜能可用于应用程序。然后，有时，这种洋葱式的剥离会带来一个突破更深层模型的机会，伴随着一系列深刻的设计变化。&lt;/p&gt;
&lt;p&gt;探索本质上是开放式的，但并不一定是随机的。&lt;em&gt;第三部分&lt;/em&gt;深入研究了可以指导选择的建模原则，以及帮助知道搜索的技术。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;第四部分：Strategic Design&lt;/em&gt; 处理出现在复杂系统、大型组织、与外部系统和遗留系统的交互中的情况。本节讨论了适用于系统作为一个整体的三个原则：有界上下文(Bounded Context)、蒸馏(Distillation)、大规模结构(Large-Scale Structure)。战略设计决策有团队，甚至在团队之间制作。战略设计使我能够以更大的规模实现&lt;em&gt;第一部分&lt;/em&gt;的目标，适用于大型系统或适合企业范围内的应用程序。&lt;/p&gt;
&lt;p&gt;整本书的讨论都是用显示的例子来说明的，这些例子来自实际的项目，而不是过于简化的“玩具”问题。&lt;/p&gt;
&lt;p&gt;这本书的大部分内容都是作为一套“模式”而写的。读者应该能够完全理解材料而不关心这个设备，但是那些对模式的样式和格式感兴趣的人可以阅读附录1。&lt;/p&gt;
&lt;h3 id=&#34;who-this-book-is-written-for&#34;&gt;Who This Book is Written For&lt;/h3&gt;
&lt;p&gt;这本书主要是为面向对软件的开发人员编写的。软件项目团队的大多数成员都可以从它的某些部分中受益。这对于哪些正在进行项目的人来说是最有意义的，他们尝试着去做这些事情，或者那些已经有了与之相关的深刻经验的人。&lt;/p&gt;
&lt;p&gt;本书需要一些面向对象建模的只是。这些例子包括 UML 图和 Java 代码，因此在基本层面上阅读这些语言的能力很重要，但是没有必要掌握 UML 或 Java 的细节。极限编程的知识将为开发过程的讨论增加视角，但是没有背景知识的讨论应该是可以理解的。&lt;/p&gt;
&lt;p&gt;对于一个中级软件开发人员，一个已经知道一些面向对象设计的读者，可能已经读过一到两本软件设计书籍，这本书将填补空白，并提供了如何在软件项目的现实生活中使用对象建模的观点。它将帮助中级开发人员将复杂的建模和设计技能应用到实际问题。&lt;/p&gt;
&lt;p&gt;高级或专业的软件开发人员应该对处理该领域的综合框架感兴趣。系统的设计方法将帮助他们带领团队走这条路。连贯的属于将有助于他们与同行交流。&lt;/p&gt;
&lt;p&gt;不同背景的读者可能希望通过本书采取不同的路径，将重点转移到不同的点上。我建议所有读者从第一部分和第一章的介绍开始。这本书是一本叙事性的书，可以从头读到尾，也可以从任何一章的开头读。一个已经对某个主题有所了解的浏览者应该能够通过阅读标题和粗体文本来抓住要点。一个非常高级的读者可能想要浏览第一部分和第二部分，并且可能对第三部分和第四部分最感兴趣。&lt;/p&gt;
&lt;p&gt;除了这些核心读者外，这本书还会引起分析人员和相对技术性的项目经理的兴趣。分析人员可以利用模型和设计之间的练习，在“敏捷”项目的上下文中做出更有效的贡献。分析师也可以使用一些战略设计原来来更好地集中和组织他们的工作。&lt;/p&gt;
&lt;p&gt;项目经理应该关注如何使团队更有效，以及如何设计对业务专家和用户有意义的软件。而且，由于战略设计决策与团队组织和工作风格有关，这些设计决策必然涉及到项目的领导，并对项目的发展轨迹产生重大影响。&lt;/p&gt;
&lt;p&gt;虽然理解领域驱动设计的开发人员将获得有价值的设计技术和观点，但当团队应用领域驱动的设计方法并将领域模型移到项目讨论的中心时，将获得最大的收益。团队成员将共享一种语言，这种语言丰富了他们的交流，并使其与软件保持联系。它们将生成与模型同步的实现，从而为应用程序开发提供优势。他们将分享不同团队的设计工作如何关联的映射，并将系统地关注对组织最有特色和最有价值的功能。&lt;/p&gt;
&lt;p&gt;领域驱动的设计是一个困难的技术挑战，它可以带来巨大的回报，在大多数软件项目开始僵化为遗留项目的阶段，它打开了机会。&lt;/p&gt;
&lt;p&gt;Eric Evans, San Francisco, California, March 2003&lt;br&gt;
http://domainlanguage.com&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&#34;part-i-putting-the-domain-model-to-work&#34;&gt;Part I. Putting the Domain Model to Work&lt;/h1&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1644831969455.png&#34; alt=&#34;The 18th century Chinese map&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;上面的 18 世纪中国地图代表了整个世界。在中心占据了大部分空间的是中国，周围是敷衍了事的其他国家的代表。这是一个适合那个故意向内转的社会的世界模式。这幅地图所代表的的世界观在与外国人打交道时一定没有帮助。当然，它根本不会为现代中国服务。地图是模型，每一个模型都代表了现实的某些方面或一个有趣的想法。这是一种简化。这是一种对现实的解释，它抽象了与解决手头问题有关的方面，而忽略了无关的细节。&lt;/p&gt;
&lt;p&gt;每个软件程序都与用户的某些活动或兴趣有关。用户应用程序的主题区域就是软件的“领域(domain)”。有些领域涉及物理世界。航空公司预定程序的领域涉及到真实的人称作真实的飞机。有些领域是无形的。会计程序的领域是货币和金融。软件领域通常与计算机没有什么关系，尽管也有例外。源代码控制系统的领域是软件开发本身。&lt;/p&gt;
&lt;p&gt;要创建有价值的软件，我们必须提供与软件将涉及的活动相关的知识体系。所需的知识量可能令人生畏。信息的数量和复杂性可能是压倒性的。这时，开发团队可以使用建模来处理过载问题。模型是一种有选择地简化和有意识地结构化的知识形式。一个合适的模型可以使信息有意义，并使其与问题相关。&lt;/p&gt;
&lt;p&gt;领域模型不是一个特定的图：这就是图所要传达的思想。它不仅仅是领域专家头脑中的知识；&lt;em&gt;它是对知识的严格阻止和选择性的抽象&lt;/em&gt;。图可以表示和交流模型，也可以是精心编写的代码，也可以是英语句子。&lt;/p&gt;
&lt;p&gt;领域建模不是使模型尽可能“真实”的问题。即使在有形的现实世界中，我们的模型也是人为创造的。也不只是构建一个软件机制来提供必要的结果。它更像电影制作，松散地代表现实以达到特定的目的。即使是异步纪录片也不会展现未经编辑的真实生活。正如电影制作人员选择体验的各个方面，并以一种特殊的方式来讲述一个故事或表达一个观点一样，选择领域模型是为了它的实用性。&lt;/p&gt;
&lt;h3 id=&#34;the-utility-of-a-model-in-domain-driven-design&#34;&gt;The Utility of a Model in Domain-Driven Design&lt;/h3&gt;
&lt;p&gt;在领域驱动的设计中，有三个基本的用途决定模型的选择。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;该模型规定了软件核心的设计形式。正是模型和实现之间的密切关系，使模型具有相关性，并确保进入模型的分析适用于最终产品，即运行的程序。这种模型和实现的绑定还有助于维护和继续开发，因为可以根据对模型的理解来解释代码。（第三章）&lt;/li&gt;
&lt;li&gt;模型是所有团队成员使用的语言的主干。由于模型和实现的绑定，开发人员可以用这种语言来讨论程序。他们无需翻译就可以与领域专家交流。因为语言是基于模型的，我们的自然语言能力可以被用来完善模型本身。（第二章）&lt;/li&gt;
&lt;li&gt;模型是对知识的提炼。模型是团队一致同意的构建领域知识和区分最感兴趣的元素的方法。当我们选择术语、分解概念并将它们联系起来时，模型捕获了我们如何选择考虑这个领域。共享语言允许开发人员和领域专家有效地协作，将信息转换成这种形式。模型和实现的绑定意味着使用软件早期版本的经验也是对模型过程的有效反馈。（第一章）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;接下来的三章依次探讨这些贡献的意义和价值，以及它们互相交织的方式。以这些方式使用模型可以支持具有丰富功能的软件开发，否则将需要大量的临时开发投资。&lt;/p&gt;
&lt;p&gt;然而，大多数项目从他们的领域模型中得到的很少。这本书将研究有效领域开发的一系列潜在障碍，以及通过设计原则（从高级概念到具体技术）客服这些障碍的方法。&lt;/p&gt;
&lt;h3 id=&#34;the-centrality-of-ddomain-functionality&#34;&gt;The Centrality of Ddomain Functionality&lt;/h3&gt;
&lt;p&gt;软件的核心是为用户解决领域相关问题的能力。所有其他功能，尽管可能很重要，都支持这一基本目的。当领域复杂时，这是一项艰巨的任务，需要有才能和技能的人集中努力。开发人员必须深入该领域以积累业务知识。他们必须磨炼自己的建模技能并掌握领域设计。&lt;/p&gt;
&lt;p&gt;然而，这并不是大多数软件项目的优先级。大多数有才华的开发人员对他们工作的特定领域并没有太多的兴趣，更不用说对扩展他们的领域建模技能做出重大承诺了。技术人员喜欢可量化的技术问题，以锻炼他们的技术能力。这个领域很混乱，需要大量复杂的新知识，而这些知识似乎并不能发展一个计算机科学家的能力。&lt;/p&gt;
&lt;p&gt;取而代之的是，技术人才致力于复杂的框架，试图用技术解决领域问题。软件核心的复杂性必须迎面解决。没有这个重点是一个项目风险。&lt;/p&gt;
&lt;p&gt;在一次电视访谈节目中，喜剧演员 John Cleese 讲述了《Monty Python and the Holy Grail》拍摄期间的一个故事。他们一遍又一遍地拍摄一个特定的场景，但不知怎么的，这并不有趣。最后，他休息了一下，和他的喜剧伙伴 Michael Palin （现场的另一个演员）商量了一下，他们想出了一个轻微的变化。他们又拍了一集，所结果很有趣，所以就收工了。&lt;/p&gt;
&lt;p&gt;第二天早上，Mr. Cleese 正在看电影剪辑师从前一天的工作中整理出来的粗剪。回到他们苦苦挣扎过的场面，他发现这一点也不好玩。一个早期的镜头被使用过。&lt;/p&gt;
&lt;p&gt;他问电影编辑，为什么他没有按照导演的指示使用最后的镜头。“用不上。有人走了进来。”编辑回答。Mr. Cleese 看了一遍又一遍。他仍然看不出有什么不对。最后，剪辑员停下胶卷，指着照片边缘的一个外套袖子，在图片的边缘可以看到一会儿。&lt;/p&gt;
&lt;p&gt;电影编辑担心其他看过这部电影的电影编辑会根据他作品的技术完美程度来评判他的作品。他专注于自己专业的精确执行，在这个过程中，场景的核心已经丢失。[“The Late Late Show with Craig Kilborn”, CBS, September, 2001]&lt;/p&gt;
&lt;p&gt;幸运的是，一个懂喜剧的导演恢复了滑稽的场景。同样地，当热情的开发人员忙于开发复杂的技术框架，而这些技术框架并不服务于领域开发，或者实际上阻碍了领域开发，而反应了对领域深刻理解的模型的开发却在混乱中丢失时，理解领域中心的团队领导可以让他们的软件项目回到正规。&lt;/p&gt;
&lt;p&gt;这本书将说明领域开发提供了培养非常复杂的设计技能的机会。大多数业务领域的混乱是一个有趣的技术挑战。事实上，在许多科学学科中，当研究人员试图解决现实世界的混乱时，“复杂性”是当前最令人兴奋的话题之一。当软件开发人员面对一个从未形式化的复杂领域时，也会有同样的前景。创建一个清晰的模型，并通过复杂的过程来解决问题是令人兴奋的。&lt;/p&gt;
&lt;p&gt;开发者可以使用系统的思维方式来寻找洞察力并生成有效的模型。有一些设计技术可以为庞大的软件应用程序带来秩序。这些技能的培养使开发人员更有价值，即使是在最初不熟悉的领域。&lt;/p&gt;
&lt;h2 id=&#34;1-crunching-knowledge&#34;&gt;1. Crunching Knowledge&lt;/h2&gt;
&lt;p&gt;几年前，我开始为印刷电路板（Printed Circuit Board, PCB）设计一个专门的软件工具。有一个问题：我对电子硬件一无所知。当然，我接触到了一些 PCB 设计师，但他们通常在三分钟内就让我晕头转向。我怎样才能充分理解编写这个软件呢？我当然不会在截止日期之前成为一名电气工程师！&lt;/p&gt;
&lt;p&gt;我们尝试让他们确切地告诉我软件该做什么。坏主意。他们是伟大的电路设计师，但他们的软件理念通常涉及阅读 ASCII 文件，对其进行分类，用一些注释将其写出来，然后生成一份报告。这显然不会带来他们所期望的生产力的飞跃。&lt;/p&gt;
&lt;p&gt;最初的几次会议令人沮丧，但在他们要求的报告中有一丝希望。他们总是设计“网(nets)”和各种各样的是细节。在这个领域，网络本质上是一种导线，它可以连接 PCB 上任意数量的组件，并将电子信号传输到与之相连的任何东西上。我们有了领域模型的第一个元素。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1644908366466.png&#34; alt=&#34;Figure 1.1&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;当我们讨论他们希望软件做的事情时，我开始为他们绘制图表。我使用了对象交互图的非正式变体来演示场景。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1644908930476.png&#34; alt=&#34;Figure 1.2&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;PCB 专家 1：组件(components)不必是芯片。
开发人员（我）：所以我应该称它们为组件(components)?
专家 1：我们称它们为“组件实例(component instances)”。可能有许多相同的组件。
专家 2：“网络(net)” box 看起来就像一个组件实例。
专家 1：他没有用我们的符号。我想，对他们来说，一切都是一个 box。
开发人员：很抱歉，是的。我想我最好再多解释一下这个符号。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;他们不断地纠正我，这样我才开始学习。我们消除了他们术语中的冲突和歧义，以及他们技术观点的差异，他们从中学习。他们开始更精确和一致地解释事物，我们开始一起开发一个模型。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;专家 1：仅仅说一个信号到达一个 ref-des 是不够的，我们必须知道引脚(pin)。
开发人员：Ref-des ?
专家 2：和组件实例一样。Ref-des 是我们使用的一种特殊工具。
专家 1：无论如何，一个 net 将一个实例的特定引脚连接到另一个实例的特定引脚。
开发人员：你是说一个引脚只属于一个组件实例并连接到只有一个网络(net)？
专家 1：是的，没错。
专家 2：而且，每个网络(net)都有一个拓扑结构，一种决定网络(net)元素连接方式的排列。
开发人员：好的，这个怎么样？
&lt;/code&gt;&lt;/pre&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1644910473897.png&#34; alt=&#34;Figure 1.3&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;为了专注于我们的探索，我们暂时把自己限制在研究一个特定的功能上。“探测模拟(probe simulation)”将跟踪信号的转播，以检测设计中可能存在的某些类型的问题。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;开发人员：我明白信号是如何通过网络(Net)传输到所有连接的引脚上(Pins)的，但它是如何进一步传播的呢？拓扑(Topology)和它有关系吗？
专家 2：没有。组件推动信号通过。
开发人员：我们当然不能模拟芯片内部的行为。这太复杂了。
专家 2：我们不需要。我们可以简化一下。只是将组件从某些引脚(Pins)推到某些其他引脚的列表。
开发人员：像这样？
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;[经过大量的反复试验，我们一起勾勒出了一个场景]&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1644911795739.png&#34; alt=&#34;Figure 1.4&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;开发人员：但是您需要从这次计算中了解什么呢？
专家 2：我们要找的是长时间的信号延迟——比如说，任何超过两到三跳(hops)的信号路径。这是经验法则。如果路径太长，信号可能在时钟周期内无法到达。
开发人员：超过三跳(hops)......我们需要计算路径长度。什么算跳(hop)呢？
专家 2：每次信号通过网络(Net)，就是一次跳跃(hop)。
开发人员：所以我们可以传递跳(hops)数，没经过一个网络(Net)可以增加它，就像这样。
&lt;/code&gt;&lt;/pre&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1644912129042.png&#34; alt=&#34;Figure 1.5&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;开发人员：我唯一不清楚的部分是“推送(pushes)”从何而来。我们是否为每个组件实例存储这些数据？
专家 2：推送(pushes)对于组件的所有实例来说都是一样的。
开发人员：所以组件的类型决定推送(pushes)。它们对每一个都是实例都是一样的？
&lt;/code&gt;&lt;/pre&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1644912318182.png&#34; alt=&#34;Figure 1.6&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;专家 2：我不确定这到底意味着什么，但我想每个组件的推送存储(push-throughs)应该是这样的。
开发人员：对不起，我说得有点太详细了。我只是在思考它。
开发人员：所以，现在，拓扑(Topology)在哪里发挥作用呢？
专家 1：这不是用来模拟探针的。
开发人员：那我现在就退出，好吗？我们可以在讲到这些功能的时候再讲。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;事情就这样发生了（比这里显示的更加磕磕绊绊）。头脑风暴和精炼；质疑和解释。随着我对领域的理解，以及他们对模型将如何在解决方案中发挥作用的理解，模型得到了开发。表示早期模型的类图如下所示。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;8&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1644912664180.png&#34; alt=&#34;Figure 1.7&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;在做了几天的业余工作后，我觉得自己已经能够理解一些代码了。我写了一个非常简单的原型，有一个自动化测试框架驱动。我避开了所有的基础设施。没有持久性，也没有 UI，这让我能够专注于行为。我能够在短短几天内演示一个简单的探测模拟。尽管他使用虚拟数据并将原始文本写入控制台，但它仍然适用 Java 对象进行路径长度的实际计算。这些 Java 对象反应了领域专家和我共享的模型。&lt;/p&gt;
&lt;p&gt;这个原型的具体性使他们更清楚模型的含义，以及它如何与功能软件相关。从那时起，我们的模型讨论变得更有互动性，因为他们可以看到我如何将我新获得的知识整合到模型中，然后再到软件中。他们从原型中得到具体的反馈来评估自己的想法。&lt;/p&gt;
&lt;p&gt;在这个模型中嵌入的是与我们正在解决的问题相关的 PCB 领域的知识，这个模型自然变得比这里展示的要复杂得多。它巩固了许多同义词和描述上的细微变化。它排除了数百个工程师理解但不直接相关的事实，比如组件的实际数字特征。像我这样的软件专家可以通过查看图表，在几分钟内就开始了解软件是关于什么的。他或她将有一个框架来组织新信息，并更快速地学习，更好地猜测什么是重要的，什么不是，并更好地与 PCB 工程师沟通。&lt;/p&gt;
&lt;p&gt;当工程师们描述他们需要的新功能时，我让他们向我介绍这些物体相互作用的场景。当模型对象不能带我们通过一个重要的场景时，我们将新的内容或旧的更改进行了头脑风暴或改变。我们完善了模型：协同进化的代码。几个月后，他们有了超出预期的丰富工具。&lt;/p&gt;
&lt;h3 id=&#34;why-it-worked&#34;&gt;Why It Worked&lt;/h3&gt;
&lt;p&gt;我们做的一些事情导致了这次成功。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;尽快绑定模型和实现。这个粗糙的原型铸就了关键的环节。&lt;/li&gt;
&lt;li&gt;培养一种基于模型的语言。一开始，他们必须像我解释基本的 PCB 问题，而我必须解释类图的含义。但随着研究的进行，从模型中直接取出的术语，组织成与模型结构一致的句子，在他们或我听到后，立即测试了模型的可行性。&lt;/li&gt;
&lt;li&gt;知识丰富的模型。对象有行为和强制的规则。这个模型不仅仅是一个数据模式，它对于解决一个复杂的问题是不可或缺的。它捕捉了各种各样的知识。&lt;/li&gt;
&lt;li&gt;知识经过提炼。随着模型变得更完整，重要的概念被添加到模型中，但同样重要的是，当概念被证明没有用处或中心时，它们就会被丢弃。当一个不需要的概念被绑定到一个需要的概念上时，一个新的模型将本质概念区分开来，从而另一个概念可以被抛弃。&lt;/li&gt;
&lt;li&gt;知识处理(Knowledge crunching)。这种语言结合了草图和头脑风暴的态度，把我们的讨论变成了模型的实验室，在那里可以练习、尝试和判断数百种实验变化。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;正式这最后一点，知识处理，使我们有可能找到一个知识丰富的模型和方法来提炼它。它需要头脑风暴和大量实验的创造力。&lt;/p&gt;
&lt;p&gt;金融分析师分析数字。他们筛选大量的详细数据，将它们组合再组合，寻找潜在的含义，寻找一种能揭示真正重要的东西的简单表述——一种可以成为财务决策基础的理解。&lt;/p&gt;
&lt;p&gt;有效的领域建模人员是知识处理者。他们获取大量的信息，并寻找相关的细流。他们尝试一个又一个有组织的想法，寻找对大众有意义的简单观点。许多模型都经过了尝试、拒绝或改造。成功来自于一系列新兴的抽象概念，这些概念能够理解所有的细节。这种蒸馏(distillation)是对已发现的最相关的特定知识的严格表达。&lt;/p&gt;
&lt;p&gt;知识处理不是一项单独的活动。由开发人员和领域专家组成的团队协作，通常由开发人员领导。他们一起吸收信息并将其转化为有用的形式。这些原始资料来自领域专家的头脑，来自现有系统的用户，来自技术团队使用相关遗留系统或同一领域的另一个项目的先前经验。它根据为项目编写的文档或在业务中使用的文档形式出现，以及大量的讨论。早期的版本或原型将经验反馈给团队，并改变早期的解释。&lt;/p&gt;
&lt;p&gt;在旧的瀑布方法(waterfall method)中，业务专家与分析人员交谈，分析人员对结果进行消化和抽象，并将结果传递给编写软件的程序员。这种方法之所以失败是因为它完全缺乏反馈。分析师完全有责任仅基于业务专家的输入来创建模型。他们没有机会从程序员那里学习或获得早期版本的经验。知识只向一个方向流淌，而不会累积。&lt;/p&gt;
&lt;p&gt;其他项目有迭代，但没有积累知识，因为它们没有抽象。他们让专家来描述他们想要的功能，然后他们去构建它。他们将结果展示给专家，并询问他们下一步要做什么。如果程序员实践了重构，他们可以保持软件足够干净，以便继续扩展它，但如果程序员对领域不感兴趣，他们只了解应用程序应该做什么，而不是它背后的原则。有用的软件可以通过这种方式构建，但项目永远不会获得那种强大的新特性作为旧特性的必然结果展现出来的那种影响力。&lt;/p&gt;
&lt;p&gt;优秀的程序员自然会开始抽象和开发可以做更多工作的模型。但是，如果这种情况只发生在技术环境中，而不与领域专家合作，概念都是天真的(naïve)。这种浅薄的知识使得软件只能完成基本的工作，但却与领域专家的思维方式缺乏深层次的联系。&lt;/p&gt;
&lt;p&gt;团队成员之间的交互随着所有成员一起处理模型而改变。领域模型的不断细化破势开发人员学习他们所协助的业务的重要原则，而不是机械地生成功能。领域专家经常通过被迫将他们知道的提炼为要点来精炼他们自己的理解，并且他们开始了解概念严格的软件项目所需的要求。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;所有这些都使团队成为更有能力的知识处理者(knowledge crunchers)。他们剔除无关的东西。他们将模型重新塑造成一种更加有用的形式。因为分析人员和程序员对它进行了输入，所以它被清晰地组织和抽象，并且可以为实现提供杠杆作用。因为领域专家正在向它提供信息，所以它反应了对业务的深刻认识，而那些抽象是真正的业务原则。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;随着模型的改进，它将成为组织信息的工具，这些信息将继续在项目中流动。它侧重于需求分析。他与编程和设计密切相关。并且，有一个良性循环中，它加深了团队成员对领域的洞察，让他们更清楚地看到，并导致模型的进一步细化。这些模型从来都不是完美的。他们在不断发展。它们在理解领域时必须是实用的且有用的。它们必须足够严格，以使应用程序易于实现和理解。&lt;/p&gt;
&lt;h3 id=&#34;continuous-learning&#34;&gt;Continuous Learning&lt;/h3&gt;
&lt;p&gt;*当我们开始编写软件时，我们知道的永远不够。*关于项目的知识是支离破碎的，分散在许多人和文档中，并与其他信息混合在一起，所以我们甚至不知道哪些知识是我们真正需要的。看起来技术上不那么令人生畏的领域可能是具有欺骗性的——我们没有意识到有多少我们不知道。这导致我们做出错误的假设。&lt;/p&gt;
&lt;p&gt;与此同时，所有的项目都会泄露知识。学会了一些东西的人会继续前进。重组又使团队分散，知识分散。关键的子系统是以这样一种方式外包的：交付的是代码而不是知识。在典型的设计方法中，代码和文档不能表达辛辛苦苦获得的知识，因此当口头传统因任何原因被打断时，这些知识就会丢失。&lt;/p&gt;
&lt;p&gt;高效的团队有意识地增长他们的知识，实践“持续学习(continuous learning)”[Kerievsky 2001]。对于开发人员来说，这意味着提高技术知识，以及通用的领域建模技能（如本书中的技能）。但这样包括认真学习他们所从事的特定领域。这些自学成才的团队成员组成了一个稳定的核心团队，专注于涉及最关键领域的开发任务（参见第 15 章，“Distillation”）。&lt;/p&gt;
&lt;p&gt;知识在核心团队的头脑中积累。&lt;/p&gt;
&lt;p&gt;此时，停下来问自己一个问题。你学过 PCB 设计流程吗？尽管这只是对该主题的一个肤浅处理，但是在讨论领域模型时应该有一些学习。我学到了很多。我们学习如何成为一名 PCB 工程师。这不是我们的目标。我学会了与 PCB 专家交谈，理解与应用程序相关的主要该你那，并检查我们正在构建的内容。&lt;/p&gt;
&lt;p&gt;事实上，我们发现探测模拟在开发中处于低优先级，最终被放弃了。与此同时，该模型的部分内容也随之小时，这些内容包括通过组件传递信号和计算跳数(counting hops)。应用程序的核心在别处，而模型的改变将这些方面置于中心位置。领域专家了解了更多信息，并明确了应用程序的目标。（第 15 章，“Distillation” 将深入讨论这些问题。）&lt;/p&gt;
&lt;p&gt;尽管如此，早起的工作还是必不可少的。重要的模型元素被保留，但更重要的是，它启动了使所有后续工作有效的过程：由团队成员、开发成员和领域专家获得的知识，共享语言的开始，以及通过实现结束反馈循环。探索之旅总要从某个地方开始。&lt;/p&gt;
&lt;h3 id=&#34;knowledge-rich-design&#34;&gt;Knowledge Rich Design&lt;/h3&gt;
&lt;p&gt;在这样的模型中所不找到的知识超越了“找到名词(find the nouns)”。业务活动和规则与涉及的实体一样，都是领域的中心，任何领域都有各种类别的概念。知识处理产生了反应这种洞察力的模型。在模型更改的同时，开发人员重构实现以表达模型，并向应用程序提供该知识的使用。&lt;/p&gt;
&lt;p&gt;随着这种超越实体和价值的移动，知识处理会变得更加激烈，因为业务规则之间可能存在实际的不一致。领域专家通常没有意识到他们的心理过程有多复杂，因为在他们工作的过程中，他们浏览所有这些规则，调和矛盾，用常识填补空白。软件做不到这一点。正式通过与软件专家密切合作的知识计算，规则才得以澄清、充实、协调或置于范围之外。&lt;/p&gt;
&lt;h3 id=&#34;example-extracting-a-hidden-concept&#34;&gt;Example : Extracting a Hidden Concept&lt;/h3&gt;
&lt;p&gt;让我们从一个非常简单的领域模型开始，该模型将用作预定货物到船舶航行的应用程序的基础。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;9&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1645087839643.jpg&#34; alt=&#34;Figure 1.8&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;我们可以指出，预定应用程序的职责是将每一个 &lt;strong&gt;Cargo&lt;/strong&gt; 与一个 &lt;strong&gt;Voyage&lt;/strong&gt; 关联起来，并记录和跟踪这种关系。到目前为止一切都好。在应用程序代码的某个地方可能有这样一个方法：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public int makeBooking(Cargo cargo, Voyage voyage) { int confirmation = orderConfirmationSequence.next(); voyage.addCargo(cargo, confirmation);
return confirmation;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;航运业的标准做饭是接受比一艘船在一次航程中所能装载的更多的货物。这就是所谓的“超额预定(over-booking)”。有时使用一个简单的容量百分比，例如预定容量的 110%。在其他情况下，则适用复杂的规则，有利于主要客户或某些种类的货物。&lt;/p&gt;
&lt;p&gt;这是航运领域的一个基本规则，航运业的任何业务人员都知道它，但可能不是软件团队中的所有技术人员都能理解它。&lt;/p&gt;
&lt;p&gt;需求文档包含这一行: &lt;code&gt;Allow 10% overbooking.&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;类图和代码现在看起来像这样:&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;10&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1645088352838.png&#34; alt=&#34;Figure 1.9&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public int makeBooking(Cargo cargo, Voyage voyage) {
    double maxBooking = voyage.capacity() * 1.1;
    if ((voyage.bookedCargoSize() + cargo.size()) &amp;gt; maxBooking) return –1; 
    int confirmation = orderConfirmationSequence.next(); voyage.addCargo(cargo, confirmation);
    return confirmation;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;现在，一个重要的业务规则作为一个保护子句隐藏在应用程序的方法中。稍后我们将看分层架构原则(LAYERED ARCHITECTURE)(第四章)，它将指导我们将朝顶规则重构为领域对象，但现在让我们集中于如何使这些知识更明确，并且对项目中的每个人都更容易访问。&lt;/p&gt;
">Domain-Driven Design Tackling Complexity in the Heart of Software</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://wenbozhangw.github.io/post/on-the-criteria-to-be-used-in-decomposing-systems-into-modules/"" data-c="
          &lt;p&gt;本文讨论了将模块化作为一种机制来提高系统的灵活性和可理解性，同时允许缩短系统的开发时间。&amp;quot;模块化(modularization)&amp;quot;的有效性取决于将系统划分为模块时使用的标准(criteria)。本文提出了系统设计问题，描述了常规分解和非常规分解(conventional and unconventional decomposition)。结果表明，非常规分解方法具有明显的优势。讨论了用于得到分解的标准。如果采用传统的假设，即一个模块由一个或多个子程序(subroutines)构成，那么在大多数情况下，非常规分解的效率会比较低。本文还简述了一种不具有这种效果的替代实现方法。&lt;/p&gt;
&lt;p&gt;关键词：软件，模块，模块化，软件工程，KWIC指标，软件设计&lt;/p&gt;
&lt;p&gt;CR类别:4.0&lt;/p&gt;
&lt;!-- more --&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;模块化编程哲学的清晰陈述可以在 1970 年 Gouthier 和 Pont 关于系统程序设计的教科书中找到，我们引用如下：&lt;sup&gt;[&lt;a href=&#34;#reference-1&#34;&gt;1&lt;/a&gt;]&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;定义良好的项目工作分割可以确保系统模块化。每个任务构成一个独立的、不同的程序模块。在实现时，每个模块及其输入和输出都定义良好，在与其的接口中不会与其他系统模块混淆。在检验时，独立测试模块的完整性；在签出(checkout)开始之前，在同步几个任务的完成方面存在一些调度问题。最后，系统以模块化的方式进行维护；系统错误和缺陷可以追踪到特定的系统模块，从而限制了详细错误搜索的范围。&lt;/p&gt;
&lt;p&gt;通常没有提到用户将系统划分为模块的标准。本文将讨论这个问题，并通过实例，提出一些可以用于将系统分解为模块的标准。&lt;/p&gt;
&lt;h2 id=&#34;a-brief-status-report&#34;&gt;A Brief Status Report&lt;/h2&gt;
&lt;p&gt;模块化编程领域的主要进步是编码技术和汇编程序的发展，它们 (1) 允许在不了解另一个模块代码的情况下编写一个模块，(2) 允许在不重新组装整个系统的情况下重新组装和替换模块。这个工具对于生成大块的代码非常有价值，但是最常被用作问题系统示例的系统是高度模块化的程序，并且利用了上面提到的技术。&lt;/p&gt;
&lt;h2 id=&#34;expected-benefits-of-modular-programming&#34;&gt;Expected Benefits of Modular Programming&lt;/h2&gt;
&lt;p&gt;模块化编程的预期好处是：(1) 管理——开发实践应该缩短，因为单独的小组将在每个模块上工作，几乎不需要交流；(2) 产品灵活性——应该有可能对一个模块进行重大更改，而不需要更改其他模块；(3) 可理解性——应该有可能一次只研究一个模块。因此，整个系统可以更好地设计，因为它可以更好地理解。&lt;/p&gt;
&lt;h2 id=&#34;what-is-modularization&#34;&gt;What Is Modularization&lt;/h2&gt;
&lt;p&gt;下面是几个称为 &lt;em&gt;模块化(modularizations)&lt;/em&gt; 的部分系统描述。在这种情况下，“模块(module)” 被认为是职责分配，而不是子程序。模块化包括在独立模块的工作开始之前必须做出的设计决策。每个备选方案都包含了不同的决策，但在所有情况下，目的都是描述所有“系统级(system level)”决策（即影响多个模块的决策）。&lt;/p&gt;
&lt;h2 id=&#34;example-system-1-a-kwic-index-production-system&#34;&gt;Example System 1 : A KWIC Index Production System&lt;/h2&gt;
&lt;p&gt;以下对 KWIC 索引的描述将满足本文的要求。KWIC 索引系统接收一个有序的行集合(set of lines)，每一行是一个有序的单词集合，而每个词是一个有序的字符集。任何行都可以通过重复删除第一个单词并将其附加到行尾来进行 &amp;quot;循环移位（circularly shifted）&amp;quot;。KWIC 索引系统按字母顺序输出所有行的所有循环移位列表。&lt;/p&gt;
&lt;p&gt;这是一个小系统。除了在极端情况下（庞大的数据库，没有配套软件），这样一个系统可以由一个好的程序员在一两周内制作出来。因此，激发模块化编程的困难对于这个系统来说都不重要。因为彻底地对待一个大系统是不切实际的，所以我们必须把这个问题当做一个大项目来处理。我们给出了一种典型的模块化方法，以及另一种已成功应用于本科课程项目的模块化方法。&lt;/p&gt;
&lt;h3 id=&#34;modularization-i&#34;&gt;Modularization I&lt;/h3&gt;
&lt;p&gt;我们看到以下模块：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Module 1: Input&lt;/strong&gt;。该模块从输入介质中读取数据行，并将其存储在内核中，以供其他模块处理。字符被打包成一个单词，使用一个其他未使用的字符来表示单词的结尾。保留索引以显示每行的起始地址。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Module 2: Cricular Shift&lt;/strong&gt;。这个模块在输入模块完成它的工作后被调用。它准备了一个索引，该索引给出了每个循环移位的第一个字符的地址，以及模块 1 组成的数组中该行的原始索引。它将输出保留在内核中，并使用成对的单词（原始行号、起始地址）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Module 3: Alphabetizing&lt;/strong&gt;。该模块将模块 1 和模块 2 产生的数组作为输入。它生成的数组格式与模块 2 生成的数组格式相同。然而，在本例中，循环移位是按另一个顺序（字母顺序）列出的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Module 4: Output&lt;/strong&gt;。使用模块 3 和模块 1 生成的数组，该模块生成了一个格式良好的输出，列出了所有的循环移位。在一个复杂系统中，每一行的实际开始将被标记，指向进一步信息的指针可能被插入，循环移位的开始实际上可能不是行中的第一个单词，等等。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Module 5: Master Control&lt;/strong&gt;。这个模块除了控制其他四个模块之间的顺序外，没有什么别的功能。它还可以处理错误信息、空间分配等。&lt;/p&gt;
&lt;p&gt;应该清楚的是，上述内容并不构成一份确定的文档。在工作开始之前，还需要提供更多的信息。定义文档将包含许多显示核心格式、指针约定、调用约定等的图片。在工作开始之前，必须指定四个模块之间的所有接口。&lt;/p&gt;
&lt;p&gt;从模块化编程的支持者的意义上来说，这是一种模块化。该系统被划分为若干具有定义良好接口的模块；每一个都足够小，足够简单，足以被彻底理解和良好的编程。小规模的实现证明，这大约是大多数程序员为指定的任务提出的分解。&lt;/p&gt;
&lt;h3 id=&#34;modularization-ii&#34;&gt;Modularization II&lt;/h3&gt;
&lt;p&gt;我们看到以下模块：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Module 1: Line Storage&lt;/strong&gt;。这个模块由许多函数或子程序(subroutines)组成，这些函数或子程序提供了模块化用户可以调用它的方法。函数调用 &lt;code&gt;CHAR(r, w, c)&lt;/code&gt; 的值将是一个整数，表示第 r 行中的第 c 个字符，第 w 个单词。一个调用例如 &lt;code&gt;SETCHAR(r, w, c, d)&lt;/code&gt; 将返回第 r 行 的第 w 个单词的第 c 个字符是由字符 d 表示（即&lt;code&gt;CHAR(r, w, c) = d&lt;/code&gt;）。&lt;code&gt;WORDS(r)&lt;/code&gt; 返回第 r 行单词的个数。调用这些例程(routines)的方式有一定的限制；如果违反了这些限制，例程就&amp;quot;陷入&amp;quot;由例程用户提供的错误处理子例程。附加的例程可以向调用者显示任何一行中的单词数、当前存储的行数以及任何一个单词中的字符数。提供函数 &lt;code&gt;DELINE&lt;/code&gt; 和 &lt;code&gt;DELWRD&lt;/code&gt; 来删除已经存储的部分行。类似的模块的精确说明已经在 [&lt;a href=&#34;#reference-3&#34;&gt;3&lt;/a&gt;] 和 [&lt;a href=&#34;#reference-8&#34;&gt;8&lt;/a&gt;] 中给出，我们在此不再重复。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Module 2: INPUT&lt;/strong&gt;。该模块从输入媒体中读取原始行，并调用行存储模块将它们存储在内部。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Module 3: Cricular Shifter&lt;/strong&gt;。该模块提供的主要函数与模块 I 通的函数类似。该模块给人的印象是，我们创建了一个 line holder，该 holder 包含的不是所有的 line，而是所有 line 的循环移位。因此，函数调用 &lt;code&gt;CSCHAR(l, w, c)&lt;/code&gt; 提供了表示第 l 个循环移位的 w 个单词的第 c 个字符的值。(1) 如果 &lt;code&gt;i &amp;lt; j&lt;/code&gt;，则第 i 行移位在第 j 行移位之前；(2) 对于每一行，第一次移位的是原行(original line)，第二次移位通过一个单词旋转到第一次移位得到，以此类推。提供了一个函数 &lt;code&gt;CSSETUP&lt;/code&gt;，必须在其他函数有指定值之前调用它。有关此类模块的更精确规范，请参见 [&lt;a href=&#34;#reference-8&#34;&gt;8&lt;/a&gt;]。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Module 4: Alphabetizer&lt;/strong&gt;。该模块主要由两个功能组成。其中一个，&lt;code&gt;ALPH&lt;/code&gt;，必须在另一个具有定义值之前被调用。第二个，&lt;code&gt;ITH&lt;/code&gt;，将作为一个索引。&lt;code&gt;ITH(i)&lt;/code&gt; 将给出以字符顺序排列的循环移位的索引。[&lt;a href=&#34;#reference-8&#34;&gt;8&lt;/a&gt;] 给出了这些函数的正式定义。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Module 5: Ouput&lt;/strong&gt;。这个模块将打印所需的行的集合或循环移位。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Module 6: Master Control&lt;/strong&gt;。功能类似于上面的模块化。&lt;/p&gt;
&lt;h2 id=&#34;comparison-of-the-two-modularizations&#34;&gt;Comparison of the Two Modularizations&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;General&lt;/strong&gt;。这两种方案都将奏效。前者相当传统；第二个已经成功地在一个 class project [&lt;a href=&#34;#reference-7&#34;&gt;7&lt;/a&gt;] 中使用。两者都将编程减少到相对独立的一些小的、可管理的程序的编程。&lt;/p&gt;
&lt;p&gt;首先请注意，这两个分解可能共享所有的数据表示和访问方法。我们的讨论是关于两种不同的方法来分割可能是同一个对象。根据分解 1 构建的系统在组装后可以与根据分解 2 构建的系统完全相同。这两种选择的区别在于它们划分工作任务的方式和模块之间的接口。两种情况下使用的算法可能是相同的。即使在可运行表示中(runnable representation)相同，这些系统也有本质上的不同。这是可能的，因为可运行表示只需要用于运行；其他表示用于更改、记录、理解等。这两种系统在其他表现形式中并不相同。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Changeability&lt;/strong&gt;。有许多设计决策是有问题的，并且可能在许多情况下发生改变。这是一个不完整的列表。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;输入格式。&lt;/li&gt;
&lt;li&gt;决策将所有行存储在核心中。对于大型工作，在任何时候将所有的行都放在核心上可能是不方便或不切实际的。&lt;/li&gt;
&lt;li&gt;决策将四个字符压缩成一个单词。在我们处理少量数据的情况下，打包字符可能是不可取的；单词的每个字符的布局都可以节省时间。在其他情况下，我们可以打包，但格式会不同。&lt;/li&gt;
&lt;li&gt;决策为循环移位创建索引，而不是实际存储它们。同样，对于小型索引或大型核心，将它们写出来可能是更可取的方法。或者，我们可以选择在 CSSETUP 期间不准备任何东西。所有计算都可以在调用其他函数（如 CSCHAR）期间完成。&lt;/li&gt;
&lt;li&gt;决策按名字福顺序排列列表一次，而不是(a)在需要的时候搜索每个项目，或(b)部分按字母顺序排列，就像在 Hoare 的 FIND [&lt;a href=&#34;#reference-2&#34;&gt;2&lt;/a&gt;] 中做的那样。在许多情况下，将字母排序所涉及的计算分配到生成索引所需的时间是有利的。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;通过观察这些变化，我们可以看到这两种模块之间的差异。第一个变化局限于两个分解中的一个模块。对于第一次分解，第二次更改将导致每个模块的更改！第三个变化也是如此。在第一次分解中，所有程序都必须使用核心中的行存储格式。在第二种分解中，情况完全不同。除了模块 1 之外，所有人都不知道这些行存储的确切方式。任何存储方式的改变都只能局限于该模块！&lt;/p&gt;
&lt;p&gt;在这个系统的某些版本中，分解中有一个额外的模块。在杭存储模块中使用了符号表(symbol table)模块（如 [&lt;a href=&#34;#reference-3&#34;&gt;3&lt;/a&gt;] 中指定的）。这个事实对系统的其他部分是完全看不见的。&lt;/p&gt;
&lt;p&gt;第四个变化局限于第二个分解中的循环移位模块，但是在第一个分解中，字母排序器和输出例程也知道这个变化。&lt;/p&gt;
&lt;p&gt;在第一次分解中，第五次变化也将被证明是最困难的。输出模块期望索引在开始之前已经完成。第二次分解中的字母排序模块被设计成这样，用户无法检测到何时实际完成了字母排序。不需要更改其他模块。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Independent development&lt;/strong&gt;。在第一个模块化中，模块之间的接口是上面描述的相当复杂的格式和表组织(table organizations)。这些代表了不能掉以轻心的设计决策。表的结构和组织对各个模块的效率至关重要，必须仔细设计。这些格式的开发将是模块化开发的主要部分，这一部分必须由几个开发小组共同努力。在第二种模块化中，接口更加抽象；它们主要由函数名、形参的数量和类型组成。这些都是相对简单的决策，模块的独立开发应该更早开始。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Comprehensibility&lt;/strong&gt;。为了理解第一个模块化中的输出模块，需要理解字符排序器(alphabetizer)、循环移位器(circular shifter)和输入模块(input module)的一些内容。输出所使用的表的某些方面只会因为其他模块的工作方式而更有意义。由于其他模块中使用的算法，表的结构将受到限制。这个系统只有在整体上才能被理解。我的主观判断是，在第二次模块化中不是这样的。&lt;/p&gt;
&lt;h2 id=&#34;the-criteria&#34;&gt;The Criteria&lt;/h2&gt;
&lt;p&gt;许多读者现在将看到在每个分解中使用了哪些标准。在第一个分解中，使用的准则是使处理中的每个主要步骤成为一个模块。有人可能会说，为了得到第一个分解，我们需要做一个流程图。这是分解或模块化最常见的方法。它是所有程序员培训的结果，它告诉我们，我们应该从一个粗略的流程开始，然后从那里走向一个详细的实现。流程图对于有 5000 - 10000 条指令的系统来说是一种有用的抽象，但当我们超越它时，它似乎是不够的需要一些额外的东西。&lt;/p&gt;
&lt;p&gt;使用 &amp;quot;信息隐藏(information hiding)&amp;quot;[&lt;a href=&#34;#reference-4&#34;&gt;4&lt;/a&gt;] 作为标准进行第二次分解。模块不再对应于处理中的步骤。例如，行存储模块在系统的几乎所有操作都使用。根据所使用的方法，字母排列可以，也可以不对应于处理中的一个节点。类似的，在某些情况下，循环移位可能根本不生成任何表，而是根据要求计算每个字符。第二次分解中的每个模块都具有其设计决策知识的特征，这些知识对所有其他模块都是隐藏的。他的接口或定义被选择来尽可能少地揭示它内部工作。&lt;/p&gt;
&lt;h2 id=&#34;improvement-in-circular-shift-module&#34;&gt;Improvement in Circular Shift Module&lt;/h2&gt;
&lt;p&gt;为了说明这样一个准则的影响，让我们从第二次分解来仔细看看循环移位模块的设计。现在，事后看来，这个定义揭示了的信息比必要的还要多久。虽然，我们小心地隐藏了存储或计算循环移位列表的方法，但我们指定了该列表的顺序。程序可以有效地编写，如果我们只指定(1) 行表示(lines indicated)在循环移位的当前定义将全部在表中存在，(2) 其中一个将包括两次，和(3) 一个额外的功能存在这将使我们能够确定原始的行的改变。通过规定转换的顺序，我们提供了比必要的更多的信息，因此不必要地限制了我们可以在不改变定义的情况下构建系统类别。例如，我们不允许在这一的系统中按字母顺序产生循环移位，ALPH 为空，而 ITH 只是将其参数作为值返回。我们在第二次分解构造系统时未能做到这点，必须清楚地将其归类为设计错误。&lt;/p&gt;
&lt;p&gt;除了每个模块对系统的其他部分隐藏一些设计决策的一般标准之外，我们还可以提到一些具体的分解示例，它们似乎是明智的。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;一个&lt;em&gt;数据结构(data structure)&lt;/em&gt;，它的内部链接，&lt;em&gt;访问过程(accessing procedures)&lt;/em&gt; 和 &lt;em&gt;修改过程(modifying procedures)&lt;/em&gt; 都是单个模块的一部分。它们不像传统的那样被许多模块共享。这个概念可能只是 Balzer [&lt;a href=&#34;#reference-9&#34;&gt;9&lt;/a&gt;] 和 Mealy [&lt;a href=&#34;#reference-10&#34;&gt;10&lt;/a&gt;] 论文背后假设的详细阐述、考虑到这一点的设计显然是 BLISS [&lt;a href=&#34;#reference-11&#34;&gt;11&lt;/a&gt;] 的设计背后。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;调用给定例程所需的指令序列和例程本身是同一个模块的一部分(The sequence of instructions necessary to call a given routine and the routine itself are part of the same module)&lt;/em&gt;。这条规则在用于实验的 Fortran 系统中是不相关的，但是对于用汇编语言构建的系统来说确实必不可少的。真正的机器不存在完美的通用调用序列(general calling sequences)，因此，随着我们继续寻找理想序列，它们往往会发生变化。通过将生成调用的责任分配给负责例程的人，我们是这种改进变得容易，也使在相同的软件结构中有几个不同的序列更加可行。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;操作系统和类似程序中队列中使用的控制快的格式必须隐藏在&amp;quot;控制模块&amp;quot;中(The formats of control blocks used in queues in operating systems and similar programs must be hidden within a &amp;quot;control block module&amp;quot;)&lt;/em&gt;。 传统的做法是对各个模块之间的接口进行格式化。因为设计的发展迫使控制模块格式频繁的改变，这样的决定通常被证明是非常昂贵的。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;字符代码、字母顺序和类似的数据应该隐藏在一个模块中，以获得最大的灵活性(Character codes, alphabetic orderings, and similar data should be hidden in a module for greatest flexibility)&lt;/em&gt;。&lt;/li&gt;
&lt;li&gt;处理某些项的顺序应该（尽可能）隐藏在单个模块中。从设备的添加到操作系统中某些资源的不可用等各种变化是的排序非常不稳定。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;efficiency-and-implementation&#34;&gt;Efficiency and Implementation&lt;/h2&gt;
&lt;p&gt;如果我们不小心的话，第二种分解会比第一种分解效率低得多。如果每个函数实际上是作为一个具有复杂调用序列的过程来实现的，那么由于模块之间的重复切换，将会有大量这样的调用。第一个分解不会遇到这个问题，因为模块之间的控制转移相较少。&lt;/p&gt;
&lt;p&gt;为了节省过程调用开销，同时获得我们在上面看到的优势，我们必须以一种不同寻常的方式实现这些模块。在许多情况下，程序最好由汇编程序(assembler)插入到代码中；在其他情况下，将插入高度专业化和高效的转移。为了成功和有效地利用第二种类型的分解，需要一种工具，这种工具可以将程序编写为子例程，但是通过任何合适的任何适当的实现来组装。如果使用这种技术，模块之间的分离在最终代码中可能不清楚。因此，额外的程序修改功能也是有用的。换句话说，程序的几种表示（前面提到过）必须在机器中与执行它们之间映射的程序一起维护。&lt;/p&gt;
&lt;h2 id=&#34;a-decomposition-common-to-a-compiler-and-interpretor-for-the-same-language&#34;&gt;A Decomposition Common to a Compiler and Interpretor for the Same Language&lt;/h2&gt;
&lt;p&gt;在早期尝试将这些分解规则应用于设计项目时，我们为用 [&lt;a href=&#34;#reference-6&#34;&gt;6&lt;/a&gt;] 中扫描的符号表示的 Markov 算法构建了一个转换器。尽管我们无意研究一种语言的编译和解释性翻译程序之间的关系，但我们发现，我们的分解对于这种语言的纯编译器和多种解释器都是有效的。尽管在每种编译器类型的最终运行表示中存在深刻和实质性的差异，但我们发现，早起分解中隐含的决定适用于所有类型。&lt;/p&gt;
&lt;p&gt;如果我们按照编译器(compiler)或解释器(interpretor)的经典路线划分职责（例如，语法识别器(syntax recognizer)、代码生成器(code generator)、编译器的运行时例程(run time routines for a compiler)），这就不会是真的。相反，分解是基于各种决策的隐藏，如上面的示例所示。因此，寄存器表示(register representation)、搜索算法(search algorithm)、规则解释(rule interpretation)等都是模块，这些问题都存在于编译和解释转换器(compiling and interpretive translators)中。不仅分解在所有情况下都是有效的，而且许多例程只需要在任何类型的翻译器进行微小的更改就可以使用。&lt;/p&gt;
&lt;p&gt;此示例为该语言提供了额外的支持，即在进行模块分解时，不应该使用预期发生处理的时间顺序。他进一步证明了，仔细的分解工作可以导致大量的工作从一个项目转移到另一个项目。&lt;/p&gt;
&lt;p&gt;对这个示例的更详细的讨论包含在 [&lt;a href=&#34;#reference-8&#34;&gt;8&lt;/a&gt;] 中。&lt;/p&gt;
&lt;h2 id=&#34;hierarchical-structure&#34;&gt;Hierarchical Structure&lt;/h2&gt;
&lt;p&gt;我们可以在根据分解 2 定义的系统中找到 Dijkstra [&lt;a href=&#34;#reference-5&#34;&gt;5&lt;/a&gt;] 所示的意义上的程序层次结构。如果一个符号表存在，他在没有任何其他模块的情况下运行，因此它是在 1 级。如果没有使用符号表，则行存储是在第 1 级，否则行存储在第二层。输入和循环移位器的功能需要行存储。输出和字母排序器将需要循环移位器，但是由于循环移位器和行持有器(line holder)在某种意义上是兼容的，所以很容易构建这些例程的参数化版本，这些例程可以用于按字母顺序排列或打印出原始行或循环移位。在第一次使用中，他们不需要循环移位器；第二次他们会使用。换句话说，我们的设计允许我们有一个单一的程序表示，它可以在两个层次中的任何一个层次上运行。&lt;/p&gt;
&lt;p&gt;在讨论系统结构时，很容易混淆良好的分解和层次结构的好处。如果模块或程序之间可以定义某种关系，并且这种关系是部分排序的，那我们就有了层次结构。我们关心的关系是 &amp;quot;使用&amp;quot; 或 &amp;quot;依赖&amp;quot;。最好使用程序直接的关系，因为在很多情况下，一个模块只依赖于另一个模块的一部分（例如，虚幻移位器只依赖于 line holder 的输出部分，而不依赖与 SETWORD 的正确工作）。可以想象，如果没有这种部分排序，我们可以获得我们已经讨论过的好处，例如，如果所有模块都在同一水平上。部分排序给我们带来了两个额外的好处。首先，系统的某些部分受益（简化），因为它们使用 lower level 服务。其次，我们能够切断上层，仍然有一个可用的和有用的产品。例如，符号表可用于其他应用程序；line holder 可以作为问答系统的基础。层次结构的存在保证了我们可以 “修剪(prune)” 树的上层，并在旧的树干上开始一颗新树。如果我们设计的系统中 &amp;quot;low level&amp;quot; 模块使用了 &amp;quot;high level&amp;quot; 模块，我们就不会有层次结构，我们会发现很难删除系统的某些部分，&amp;quot;level&amp;quot; 在系统中也没有多少意义。（这里的 &amp;quot;lower&amp;quot; 以为 &amp;quot;lower numbered&amp;quot;）。&lt;/p&gt;
&lt;p&gt;我们可以想象拥有一个版本 1 中所显示的分解类型的系统（接口中的重要设计决策），但是保留层次结构，因此我们必须得出这样的结论：层次结构和 &amp;quot;干净的&amp;quot; 分解是系统结构的两个可取但独立的属性。&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;我们已经试图通过这些示例说明，在流程图的基础上开始将系统分解为模块几乎总是不正确的。我们建议从一组困难的设计决策或可能发生变化的决策开始。然后，每个模块都被设计为对其他模块隐藏这样的决定。因为，在大多数情况下，设计决策超越了执行时间，模块将不对应与处理中的步骤。为了更加高效的实现，我们必须放弃模块是一个或多个子例程的假设，而是允许子例程和程序被来自不同模块的代码集合组装起来。&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;span id=&#34;reference-1&#34;&gt;&lt;/span&gt; Gauthier, Richard, and Pont, Stephen. &lt;em&gt;Designing Systems Programs&lt;/em&gt;, (C), Prentice-Hall, Englewood Cliffs, N.J., 1970.&lt;/li&gt;
&lt;li&gt;&lt;span id=&#34;reference-2&#34;&gt;&lt;/span&gt; Hoare, C. A. R. Proof of a program, FIND. Comm. ACM 14, 1 (Jan. 1971), 39-45.&lt;/li&gt;
&lt;li&gt;&lt;span id=&#34;reference-3&#34;&gt;&lt;/span&gt; Parnas, D. L. A technique for software module specification with examples. Comm. ACM 15, 5 (May, 1972), 330-336.&lt;/li&gt;
&lt;li&gt;&lt;span id=&#34;reference-4&#34;&gt;Parnas, D. L. Information distribution aspects of design methodology. Tech. Rept., Depart. Computer Science, CarnegieMellon U., Pittsburgh, Pa., 1971. Also presented at the IFIP Congress 1971, Ljubljana, Yugoslavia.&lt;/li&gt;
&lt;li&gt;&lt;span id=&#34;reference-5&#34;&gt;Dijkstra, E. W. The structure of &amp;quot;THE&amp;quot;-multiprogramming system. Comm. ACM 11, 5 (May 1968), 341-346.&lt;/li&gt;
&lt;li&gt;&lt;span id=&#34;reference-6&#34;&gt;Galler, B., and Perlis, A. J. &lt;em&gt;A View of Programming Languages&lt;/em&gt;, Addison-Wesley, Reading, Mass., 1970.&lt;/li&gt;
&lt;li&gt;&lt;span id=&#34;reference-7&#34;&gt;Parnas, D. L. A course on software engineering. Proc. SIGCSE Technical Symposium, Mar. 1972.&lt;/li&gt;
&lt;li&gt;&lt;span id=&#34;reference-8&#34;&gt;Parnas, D. L. On the criteria to be used in decomposing systems into modules. Tech. Rept., Depart. Computer Science, Carnegie-Mellon U., Pittsburgh, Pa., 1971.&lt;/li&gt;
&lt;li&gt;&lt;span id=&#34;reference-9&#34;&gt;Balzer, R. M. Dataless programming. Proc. AFIPS 1967 FJCC, Vol. 31, AFIPS Press, Montvale, N.J., pp. 535-544.&lt;/li&gt;
&lt;li&gt;&lt;span id=&#34;reference-10&#34;&gt;Mealy, G. H. Another look at data. Proc. AFIPS 1967 FJCC, Vol. 31, AFIPS Press, Montvale, N.J., pp. 525-534.&lt;/li&gt;
&lt;li&gt;&lt;span id=&#34;reference-11&#34;&gt;Wulf, W. A., Russell, D. B., and Habermann, A. N. BLISS, A language for systems programming. Comm. ACM 14, 12 (Dec. 1971), 780-790.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;source&#34;&gt;Source&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://dl.acm.org/doi/10.1145/361598.361623&#34;&gt;https://dl.acm.org/doi/10.1145/361598.361623&lt;/a&gt;&lt;/p&gt;
">On the Criteria To Be Used in Decomposing Systems into Modules</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://wenbozhangw.github.io/post/abstract-data-type-wikipedia/"" data-c="
          &lt;p&gt;&lt;strong&gt;抽象数据类型&lt;/strong&gt;(&lt;strong&gt;A&lt;/strong&gt;bstract &lt;strong&gt;D&lt;/strong&gt;ata &lt;strong&gt;T&lt;/strong&gt;ype, &lt;strong&gt;ADT&lt;/strong&gt;) 是计算机科学中具有类似行为的特定类别的数据结构和数学模型；或者具有类似语义的一种或多种程序设计语言的数据类型。抽象数据类型是间接定义的，通过其上的可执行的操作以及这些操作的效果的数学约束（与可能的代价）。&lt;/p&gt;
&lt;p&gt;例如，抽象的堆栈(stack)由 3 个操作定义：推入 push，弹出 pop（接受约束：每次弹出返回的最新被推入且没有被弹出的数据，也就是后进先出），查看堆栈顶端数据 peek。当分析使用堆栈算法的效率，所有这 3 个操作用时相同，无论堆栈中包含多少项数据；并且堆每项数据栈使用了常量大小的存储。&lt;/p&gt;
&lt;p&gt;抽象数据类型（ADT）是纯粹理论实体，用于简化描述抽象算法，分类与评价数据结构，形式描述程序设计语言的类似系统。一个 ADT 可以用特定数据类型或数据结构实现，在许多程序设计语言中有许多种实现方式；或者用形式规范语言描述。ADT 常实现为模块(module)：模块的接口声明了对应于 ADT 操作的例程(procedure)，有时用注释描述了约束。&lt;/p&gt;
&lt;!-- more --&gt;
&lt;h2 id=&#34;示例&#34;&gt;示例&lt;/h2&gt;
&lt;p&gt;在编程语言（或库）和教科书中，常见的几个抽象数据类型如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;&#34;&gt;关联数组&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;复数&lt;/li&gt;
&lt;li&gt;容器&lt;/li&gt;
&lt;li&gt;双端队列&lt;/li&gt;
&lt;li&gt;列表&lt;/li&gt;
&lt;li&gt;Multimap&lt;/li&gt;
&lt;li&gt;优先队列&lt;/li&gt;
&lt;li&gt;队列&lt;/li&gt;
&lt;li&gt;集合&lt;/li&gt;
&lt;li&gt;堆栈&lt;/li&gt;
&lt;li&gt;字符串&lt;/li&gt;
&lt;li&gt;树&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;接口和实现的分离&#34;&gt;接口和实现的分离&lt;/h2&gt;
&lt;p&gt;实现于程序时，抽象数据类型只显现出其接口，并将实现加以隐藏。用户只需关心它的接口，而不是如何实现。未来更可以改变实现的方式。（其支持信息隐藏原理，或保护程序免受变化的冲击。）&lt;/p&gt;
&lt;p&gt;抽象数据类型的强处在于对用户隐藏了实现细节，仅公开其接口。这表示抽象数据类型可以用各种方法来实现，只要遵循其接口，就不会影响到用户。&lt;/p&gt;
&lt;p&gt;在抽象数据类型和数据结构之间，有一个实现上的微妙差别。例如，列表的抽象数据类型可以数组为基础、或者使用链表来实现。列表即是一种具良好运算（加入元素、移除元素等等）定义的抽象数据类型。链表是以指针为基础的数据结构，且可用来创建一个列表。链表常用于列表的抽象数据类型。&lt;/p&gt;
&lt;p&gt;同样地，二叉树搜索法的抽象数据结构可以几个方式实现：二叉树、AVL树、红黑树、数组等等。且无须关心其实现，二叉树搜索法总是有相同的运算（插入、移除、查找等等）。&lt;/p&gt;
&lt;p&gt;从实现中分离出接口，并不表示用户不该知道实现的方法，而是用户不能依赖于实现细节。例如，一个抽象数据类型可以用脚本语言创建，或其它可以被反编译的语言（如 C语言）。即使用户可发现实现的方法，只要所有客户端程序遵循该接口，且改变实现方式时不会产生影响，那就仍是抽象数据类型。&lt;/p&gt;
&lt;p&gt;在面向对象的用语中，抽象数据类型相当于类别；抽象数据类型的实体就相当于对象。某些语言包含了用于宣告抽象数据类型的构造函数。例如，C++ 和 Java 为此提供了类的构造函数。&lt;/p&gt;
&lt;h2 id=&#34;抽象数据结构&#34;&gt;抽象数据结构&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;抽象数据结构&lt;/strong&gt;即根据所要运算的数据以及其计算复杂性所定义的抽象存储区，而不关心具体的数据结构的实现。&lt;/p&gt;
&lt;p&gt;就实现高效率的算法而言，对数据结构的选择相当重要。抽象数据结构的选择，决定了高效率的算法的设计，和估计其计算复杂性。&lt;/p&gt;
&lt;p&gt;这个概念与编程语言理论中所使用的抽象数据类型非常接近，大致上抽象数据结构和抽象数据类型的名称，和具体的数据结构的名称一致。&lt;/p&gt;
&lt;h2 id=&#34;内置抽象数据类型&#34;&gt;内置抽象数据类型&lt;/h2&gt;
&lt;p&gt;一部分抽象数据类型在程序设计中相当普遍且实用，所以在某些编程语言中，成为原生类型、或加进标准库中。例如，Perl 的数组可以用列表或双端队列之类的抽象数据类型来实现，散列表也可以用 Map 或 Table 来做。C++ 标准库和 Java 库也提供了列表、堆栈、队列、Map、优先权队列和字符串。&lt;/p&gt;
&lt;h2 id=&#34;实际示例&#34;&gt;实际示例&lt;/h2&gt;
&lt;h3 id=&#34;作为抽象数据类型的有理数&#34;&gt;作为抽象数据类型的有理数&lt;/h3&gt;
&lt;p&gt;有理数（可以 a/b 格式表示的数，且 a 和 b 都是整数）本来是不能在电脑中表示出来。不过可以合理的抽象数据类型来定义，如下。&lt;/p&gt;
&lt;p&gt;构造：使用两个整数 a 与 b 创建实体，其中 a 为分子，b 为分母。&lt;/p&gt;
&lt;p&gt;运算：加法、减法、乘法、除法、乘幕、比较、约分，转成实数（浮点数）。&lt;/p&gt;
&lt;p&gt;要完成整个规格，就要根据数据来定义所有的运算。例如，当两个有理数 a/b 和 c/d 相乘时，相乘的结果就要定义为 ( a c ) / ( b d )。还有输入、输出、先决条件、后置条件，以及对抽象数据类型的各种假定。&lt;/p&gt;
&lt;h3 id=&#34;堆栈&#34;&gt;堆栈&lt;/h3&gt;
&lt;h4 id=&#34;接口&#34;&gt;接口&lt;/h4&gt;
&lt;p&gt;堆栈的抽象数据类型接口，以 C 语法编写：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;long stack_create(); /* 建立新的堆栈实体 */
void stack_push(long stack, void *item); /* 将一个项目推入堆栈 */
void *stack_pop(long stack); /* 从堆栈顶部取得项目 */
void stack_delete(long stack); /* 刪除堆栈 */
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;用法&#34;&gt;用法&lt;/h4&gt;
&lt;p&gt;抽象数据类型可以如下方式使用：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;long stack;
struct foo *f;

stack = stack_create(); /* 建立堆栈 */

stack_push(stack, f); /* 将 foo 结构推入堆栈 */

f = stack_pop(stack); /* 从堆栈取得顶部的结构 */
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;各种实现&#34;&gt;各种实现&lt;/h4&gt;
&lt;p&gt;上述堆栈的抽象数据类型，一开始可以使用数组来实现，然后改用链表，而不会伤到任何用户的代码。有多少方法可以实现抽象数据类型，取决于编程语言。例如，上述示例可使用 C 编写一个结构，以及随同的一组数据结构，可使用数组或链表来存放记录；当构造函数函数返回一个抽象句柄时，就对用户隐藏了真实的实现过程。&lt;/p&gt;
">Abstract data type - wikipedia</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://wenbozhangw.github.io/post/ji-yu-hang-pai-ying-xiang-he-lida-de-guang-fu-wu-ding-qian-li-kuai-su-sao-miao-ping-gu-fang-fa/"" data-c="
          &lt;p&gt;本文提出了一种用于屋顶光伏发电潜力评估的快速扫描产量预测方法。该方法有三个主要部分。对于每个屋顶，首先利用航拍图像重建虚拟三维屋顶段，然后利用拟合算法将光伏组件自动贴合到屋顶段上，最后计算出预期的年产量。对每个屋面采用三种不同的快速产量计算方法计算年产量。两种方法是太阳猴(SM)和光伏地理信息系统(PVGIS)的商业软件包，而另一种是代尔夫特理工大学光伏材料和器件(PVMD)小组开发的基于天线的简化方法。为了验证快速扫描方法，在荷兰的城市地区选择了一组145个屋顶和215个屋顶段。对于所选择的屋顶，将安装模块的数量和计算的产量与实际的模块布局和现有光伏系统的实测产量进行比较。结果表明，快速扫描预测方法与实测结果吻合较好，相对标准偏差分别为7.2%、9.1%和7.5%。结果表明，包含障碍物的方法(如SM和PVMD)优于忽略周围障碍物遮挡的方法(如PVGIS)。结果还表明，3D屋顶段作为快速扫描PV产量预测方法的输入值具有附加价值，因为仅使用建筑的2D土地登记数据预测产量的精度明显较低。&lt;/p&gt;
&lt;!-- more --&gt;
&lt;p&gt;以更可持续和更无化石的方式满足人类能源需求的挑战让人类感到气馁，向风能和太阳能等可再生能源的过渡已经开始。2018年，全球光伏年装机容量超过100 GW，累计运行总容量超过0.5 TW (SolarPower Europe, 2019;光伏发电系统规划，2018)。尽管光伏系统的价格在过去几十年里大幅下降，但光伏的采用并没有迅速增长(Karakaya和Sriwannawit, 2015)。社会的心态必须转向光伏和光伏革命(Smets, 2017)。因此，需要更多的社会推动来帮助太阳能光伏产业的发展。&lt;/p&gt;
&lt;p&gt;这种社会推动可以通过各种方式支持自动光伏系统设计。首先，设计光伏系统所需的时间可以大大减少。从软件辅助设计到视觉现场检查(例如，计算屋顶瓦的数量，粗略估计屋顶光伏潜力)，屋顶光伏系统的实际设计可能需要10分钟到几个小时(尼泊尔普拉莫德，2019年;de Proost, 2019)。由于国内光伏发电系统市场竞争激烈，目前国内光伏发电系统的设计成品率较低。如果系统设计的报价是自动生成的，那么PV安装公司可以节省大量的时间。一个自动化的光伏系统设计也可以使光伏销售过程更加高效。这样可以减少给潜在客户打电话的时间和精力。整个太阳能市场的活动可以增加作为一个更有效的销售过程的结果，因为它将提高生产力。此外，一个先进的设计算法可以设计出更精确的能量产出，更好的美学或更好的成本效益的系统，比人类可以在同样的时间内完成。可以计算出模块的最佳位置，使全年的阴影最小化。此外，算法可以找到其他模块配置，使更多模块适合同一屋顶。例如，它可以根据客户的要求，通过比较东西或南向的设置，在每平方米产量和总产量之间找到平衡。从另一个角度来看，通过以一种快速和用户友好的方式促进产量预测和系统设计，消费者将较少关注他们的屋顶是否适合光伏系统。&lt;/p&gt;
&lt;p&gt;为了实现这一目标，开发了一种所谓的快速扫描产量预测方法。该方法实现了屋顶光伏系统设计和产量预测的自动化。它还通过尽可能减少运行时间，实现了大规模的屋顶光伏潜力评估(如一个城市或一个地区)。本文旨在介绍快速扫描方法，并讨论以下研究问题的结果:(1)自动模块安装在住宅屋顶上的现实程度如何?(2)不同快速产量计算方法的产量预测精度如何?(3)快速扫描方法的不同部分有多快，如何对其进行优化?&lt;/p&gt;
&lt;p&gt;第二节概述了城市屋顶太阳能潜力估算的相关文献，并简要说明了研究提纲。在第3节中，描述了快速扫描方法的不同部分。第4节给出了模块拟合算法的结果和产量计算方法，并讨论了仿真时间。最后，将在第5节中得出结论，并就今后的工作提出建议。&lt;/p&gt;
&lt;h2 id=&#34;2-文献综述与研究概要&#34;&gt;2. 文献综述与研究概要&lt;/h2&gt;
&lt;p&gt;建筑屋顶光伏发电的潜力通常由以下几个方面决定:(i)寻找可用的屋顶面积光伏组件，(ii)模拟阵列平面(POA)太阳辐照度，(iii)计算这种系统的年交流发电量。&lt;/p&gt;
&lt;p&gt;利用平均条件，可以利用土地利用、建筑密度和人口密度来计算屋顶总面积，假设利用系数固定，可以得到PV的可用屋顶面积(Izquierdo et al.， 2008)。2010年，Winginton et al.利用屋顶表面积和人口之间的关系来估计美国安大略省东南部的屋顶光伏发电潜力(Wiginton et al.， 2010)。同样，我们分析了西班牙安达卢西亚不同类型的住宅屋顶的太阳能容量(Ordóñez et al.， 2010)。2012年，Defaix等人发布了27个欧洲成员国的建筑集成光伏(BIPV)潜力，从人均平均建筑面积开始，寻找每个国家可用的屋顶表面(Defaix等人，2012)。对于印度城市孟买，我们使用航拍图像来计算建筑足迹面积(BFA)比率和光伏可用屋顶面积(PVA)的值，以估计这座城市的光伏潜力(Singh和Banerjee, 2015)。印度早前对德里光伏潜力的调查是基于拇指规则、标准假设和专家的意见，因为数据无法获得(革命，2013年)。2014年，Mainzer等人分析了德国各个城市的技术光伏潜力，通过统计数据估计了每座建筑的可用面积和能源需求(Mainzer等人，2014)。2015年，Byrne等人计算了首尔(韩国)每一种建筑类型的净可用屋顶面积，包括模块倾斜及其对地面覆盖比(GCR)和城市预期光伏潜力的影响的参数研究(Byrne等人，2015)。2017年，Khan等人对沙特阿拉伯王国的13个城市进行了类似的研究，并估计了潜在发电量(Khan等人，2017)。&lt;/p&gt;
&lt;p&gt;基于地理信息系统(GIS)的其他方法最近也得到了越来越多的使用，特别是自从GIS成为一种常用的工具以来(Schallenberg-Rodríguez, 2013)。如果有的话，可以使用建筑物外部形状的GIS数据来估计可用屋顶面积。2011年，利用建筑外部形状的GIS数据，并对利用系数进行假设，评估了以色列屋顶光伏的潜在发电量(Vardimon, 2011)。Martín-Chivelet提出了GCR的解析表达式和PV潜力的逐步评估方法(MartínChivelet, 2016)。2015年，Freitas等人对城市地区太阳势计算方法进行了综述，认为计算方法需要在精度和计算时间之间进行折衷(Freitas等人，2015)。&lt;/p&gt;
&lt;p&gt;如果3D信息和/或高度数据是可用的，如激光雷达测量，俯仰角和方位角的屋顶段可以用来确定POA辐照度。2012年，Brito等人利用LiDAR数据评估了里斯本郊区的光伏潜力(Brito等人，2012)。得出结论,为光伏穿透屋顶总面积的10%以下,PV潜力可以估计忽略了阴影和考虑PV的最佳倾角和取向,然而,高渗透,潜在的可以被考虑水平估计地表建筑物内占用面积。2011年，Bergamasco等人利用MATLAB评估了屋顶集成光伏系统的光伏潜力，首先是在皮埃蒙特地区进行的一项研究(Bergamasco和Asinari, 2011年)。随后，将MATLAB算法进行了阴影和屋顶内障碍物检测的增强，并应用于都灵市，处理了6万多栋建筑(Bergamasco和Asinari, 2011)。2013年，Kodysh等人将激光雷达数据和GIS方法结合起来，估算了美国田纳西州诺克斯县不同屋顶表面的辐照度(Kodysh等人，2013年)。然而，研究的输出是每个屋顶表面积的太阳辐照度，因为PV和电力输出的可用面积不在研究范围内。2014年，利用可用屋顶面积的GIS数据，并考虑到其他建筑造成的遮阳，评估了台湾的屋顶光伏潜力(Ko et al.， 2015)。有一些使用3D城市模型来计算总屋顶面积和预期发电量的例子，如Rodriguez等人在德国路德维希堡的工作(Rodríguez et al.， 2017)。然而，3D城市模型的创建或获取成本很高，目前世界上大多数地区都无法获得3D城市模型。此外，使用3D模型和光线投射进行遮阳计算是非常需要计算的，因此，限制了PV势可确定的规模。&lt;/p&gt;
&lt;p&gt;上面描述的一些研究通过GCR因子计算了将放置在可用屋顶面积上的光伏组件的离散数量，然而，它们都没有计算出适合每个屋顶段的实际模块布局。唯一的例外是Mainzer等人在2017年进行的一项研究，该研究利用地理建筑数据和航空图像结合图像识别技术，将模块虚拟地放置在屋顶上(Mainzer等人，2017)。他们的模块拟合算法在可用面积上递增迭代，并在每个屋顶分段内尽可能多地安装光伏模块。然而，它忽略了从屋顶边缘取下的距离，以及模块与平屋顶边缘的对齐。&lt;/p&gt;
&lt;p&gt;为了模拟POA辐照度和计算年度交流能源产量，可以在产量计算模型中应用各种细节。例如，天际线轮廓（抵御天空中定义的光伏系统周围的土地和建筑物的轮廓）会影响到达PV模块的太阳辐照度（Calcabrini等，2019）。虽然阴影降低了PV模块性能（Ziar等，2017），但在产量预测方法中，通常不会针对每个屋顶确定天际线轮廓，忽略由其引起的阴影。更先进的收益率计算模型，包括温度，模块技术和逆变器利用的非线性效果显着增加了运行时，并相当提高了准确性（Mainzer等，2017）。但是，在处理大批次的屋顶时，两种精度（数据集的近距离，在这种情况下，建模的PV产量，到所建模和测量的KWH / KWP值的完美预测线和精度（接近在数据集中，在这种情况下，模拟的光伏产量，他们自己的平均KWH / KWP线路很重要。&lt;/p&gt;
&lt;p&gt;现实生活中可能导致光伏造型中的系统和随机误差。系统错误从完美的预测（参考）转移建模数据点，而随机错误导致建模数据点分散。系统和随机误差分别涉及准确性和精度。对于大型研究或初始调查（Quick-Scan）的批次，精度与准确性一样重要。原因是，获得精度比准确性快，并且需要更少的输入和/或详细建模，并且当找到用于屋顶的PV电位的精确批次输出数据时，所有结果都可以通过简单转移（调谐）。 （和快速）校正因子具有精确和准确的批量输出数据。因此，该研究的目的是开发一种方法，可以快速扫描许多屋顶的光伏电位，高精度，然后，通过校正因子进一步修改它，也可以进行准确的结果数据集。值得注意的是，将一个校正因子应用于所有产量预测将改善几个单独的PV系统产量预测，同时它可能使少数几个产生的产量预测。但是，所有PV系统的总体预测将改善。&lt;/p&gt;
&lt;p&gt;本研究中开发的方法使用从航空图像和GIS数据产生的3D屋顶段数据，以评估要安装在每个屋顶上的离散数量的光伏模块。 通过选择在其屋顶上具有PV系统的建筑物并将结果与实际放置的模块数量进行比较来测试模块拟合。 此外，LIDAR高度数据用于通过周围障碍物来解释阴影的影响。 使用Real PV系统的AC产量测量获得三种不同产量计算方法的精度。 开发方法试图保持计算时间尽可能低，以使算法可用于区域或国家规模的屋顶PV。&lt;/p&gt;
&lt;h2 id=&#34;3-方法&#34;&gt;3. 方法&lt;/h2&gt;
&lt;p&gt;在图1中，示出了快速扫描算法的一般结构。为了初始化，将一组分成三维屋顶段的屋顶输入到算法中。对于每个线段，使用两种独立的方法计算线段方向。然后进行模块装配，以找到可以放置在其上的模块的最大数量。对于容纳大多数模块的解决方案，产量计算是按屋顶部分进行的。最后，快速扫描算法的输出将是已安装模块的数量、以千瓦时为单位的预期年交流发电量和特定年发电量 KWH / KWP，每个模块按屋顶或物理地址汇总。在安装光伏系统之前，行业和研究团体广泛使用的优点是kWh或kWh / kWp，这给出了光伏系统将产生多少的指示。但是，在安装后，监视预期和真实光伏产量之间的差异，使用了优异性能比（PR）。由于该研究的目标是屋顶的产生评估，因此使用KWH和KWH / KWP作为优点。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1642922901318.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;为了开发适用于任何地址的快速扫描，有必要了解屋顶的信息:屋顶面积(用于光伏组件安装)、坡度和方向(用于产量预测)。一种方法是使用在几个国家都可以获得的建筑物轮廓的土地登记数据。然而，大多数屋顶不是由一个平面组成的，并且具有在建筑物轮廓中无法检测到的障碍物。在本研究中，使用立体航空图像将屋顶分成具有不同斜度和方向的段。该算法显示在图1的下部。通过使用目标建筑的土地登记数据中的建筑轮廓来选择屋顶。通过匹配从不同角度拍摄的一对航空图像的屋顶像素来制作视差图(地理信息系统中的立体匹配(莱门斯，1988年；维米尔，2018年))。然后，通过比较屋顶上的许多点来获得3D点云，如图2中的视差图所示。&lt;/p&gt;
">基于航拍影像和LiDA的光伏屋顶潜力快速扫描评估方法</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://wenbozhangw.github.io/post/guang-fu-mian-ji-ji-suan/"" data-c="
          &lt;p&gt;1、公式里有区分平面屋和斜坡屋，这个数据图里没有对应提现&lt;br&gt;
2、图中没有提现建筑类型&lt;br&gt;
3、是否能够周长和面积算出容积率（墙面计算需要）&lt;br&gt;
4、是否考虑墙面安装、墙面安装可能需要考虑建筑高度&lt;/p&gt;
">光伏面积计算</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://wenbozhangw.github.io/post/programming-with-abstract-data-types/"" data-c="
          &lt;p&gt;使用高级语言进行工作的动机是通过为程序员提供一种包含适合其问题领域的原语(primitives)或抽象(abstractions)的语言来简化编程任务。这样程序员就可以把精力花费在正确的地方；程序员可以专注于解决他的问题，结果程序将更加可靠。显然，这是一个值得实现的目标。&lt;/p&gt;
&lt;p&gt;不幸的是，设计师很难提前选择使用该语言的用户可能需要的所有抽象(abstractions)。如果要使用一种语言，它很可能会被用来解决设计者没有预见到的问题，而且这种语言中嵌入的抽象可能并不足以解决这些问题。&lt;/p&gt;
&lt;p&gt;本文提出了一种方法，当发现需要新的数据抽象时，可以扩展内置的抽象集。这种处理抽象的方法是为结构化编程设计语言的产物。本文描述了这种语言的相关方面，并给出了抽象的用法和定义的实例。&lt;/p&gt;
&lt;!-- more --&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;本文介绍了一种计算机抽象表示的方法。这种方法是在设计一种支持结构化编程的语言时开发的，他也适用于使用高级语言工作。我们首先解释它的相关性(relevance)，并比较结构化编程和高级语言的工作。&lt;/p&gt;
&lt;p&gt;结构化编程的目的是增强程序的可靠性(reliability)和可理解性(understandability)。高级编程语言，虽然主要目的是为了通过减轻程序员的任务来提高程序员的工作效率，但同时也期望可以提高代码的可靠性和可理解性。因此，可以期望从这两个领域的工作中获得类似的好处。&lt;/p&gt;
&lt;p&gt;然而，这两个领域的工作沿着不同的方向进行。高级编程语言试图向用户呈现抽象（操作、数据结构和控制结构）对他的应用领域很有用。用户可以使用这些抽象，而不用关心它们是如何实现的——他只关心它们做什么。因此，他能够忽略与其应用领域无关的细节，专注于解决自己的问题。&lt;/p&gt;
&lt;p&gt;结构化编程试图对编程任务加一种约束，以便重新适应的程序具有良好的结构。在这种约束下，问题是通过一个连续分解(successive decomposition)的过程来解决的。第一步是编写一个程序来解决这个问题，但是这个程序运行在一个抽象的机器上，这个抽象的机器仅提供那些最合适解决这个问题的数据对象和操作。这些数据对象和操作中的部分或全部是真正抽象的，即，在所使用的编程语言中不作为原语呈现。目前，我们将把它们简单的归为 &amp;quot;abstraction&amp;quot; 一词。&lt;/p&gt;
&lt;p&gt;程序员最初关心的是（或证明）他的程序是否令人满意地正确的解决了问题。在本文的分析中，他关注的是他的程序使用抽象的方式，而不是哪些抽象如何实现的细节。当他对程序的正确性感到满意时，他就把注意力转向程序使用的抽象。每个抽象都代表一个新问题，需要额外的程序来解决它。新的程序也可以编写为在抽象机器上运行，从而引入更多的抽象。当在构造程序过程中产生的所有抽象都被进一步的程序实现时，原来的问题就完全解决了。&lt;/p&gt;
&lt;p&gt;现在很明显，高级语言和结构化编程的方法是相互关联的：每种方法都是基于利用那些对解决问题正确的抽象想法。此外，在这两种方法中使用抽象的基本原理是相同的：让程序员不用担心与他正在解决的问题无关的细节。&lt;/p&gt;
&lt;p&gt;在高级语言中，设计者视图提前确定有用的抽象集。另一方面，结构化编程语言不包含关于特定的有用抽象集的先入为主的观念，而是必须提供一种机制，通过这种机制，语言可以扩展到包含用户需要的抽象。包含这种机制的语言可以被视为通用的、无限高级的语言(indefinitely-high-level language)。&lt;/p&gt;
&lt;p&gt;在本文中，我们描述了一种抽象方法，当发现需要新的抽象时，允许对内置的抽象集进行扩充。我们从分析编写程序中使用的抽象开始，并确定对数据抽象的需求。非正式的描述了一种支持数据抽象的使用和定义的语言，并给出了一些示例程序。文中的其余部分讨论了该方法与之前的工作的关系，以及该语言实现的一些方面。&lt;/p&gt;
&lt;h2 id=&#34;the-meaning-of-abstraction&#34;&gt;The Meaning of Abstraction&lt;/h2&gt;
&lt;p&gt;上一节中对结构化编程的描述是模糊的，因为它是用&amp;quot;抽象(abstraction)&amp;quot;和&amp;quot;抽象机器(abstract mechine)&amp;quot;这样没有定义的术语来描述的。在本节中，我们将分析&amp;quot;抽象(abstraction)&amp;quot;的含义，以确定程序员需要什么样的抽象，以及结构化编程语言如何支持这些需求。&lt;/p&gt;
&lt;p&gt;我们希望从抽象中得到一种机制，它允许表达相关的细节，一直不相关的细节。在编程的情况下，抽象的使用是相关的；抽象实现的方式无关紧要。如果我们考虑传统的编程语言，我们会发现它们为抽象提供了强大的帮助：函数(function)或过程(procedure)。当一个程序员使用一个过程时，他只关心（或者应该关心）它做什么——它为他提供了什么函数。他不关心由程序执行的算法。另外，过程提供了一种分解问题的方法——在过程中执行部分编码任务，在程序中执行调用过程的另一部分。因此，过程的存在对捕捉抽象的意义有很大的帮助。&lt;/p&gt;
&lt;p&gt;不幸的是，过程本身并不能提供足够丰富的抽象词汇表(vocabulary of abstractions)。上文提及的抽象机器的抽象数据对象(abstract data object)和控制结构(control structures)不能用独立的过程准确地表示。因为我们在结构化编程的上下文中考虑抽象，所以我们将忽略控件抽象(control abstractions)的讨论。&lt;/p&gt;
&lt;p&gt;这就引出了抽象数据类型的概念，这是语言设计的核心。抽象数据类型定义了一个抽象对象的类，该类完全由这些对象上可用的操作来描述。这意味着抽象数据类型可以通过定义该类型的特征化操作(characterizing operations)来定义。&lt;/p&gt;
&lt;p&gt;我们认为，上述概念抓住了抽象对象的基本属性。当程序员使用一个抽象数据对象时，他只关心该对象表现出的行为，而不关心如何通过实现(implementation)来实现该行为的任何细节。对象的行为由一组特征和操作捕获。只有在定义如何实现特征化操作时，才需要实现信息，例如对象在存储中是如何表示的。对象的用户不需要知道或提供这些信息。&lt;/p&gt;
&lt;p&gt;抽象类型与编程语言提供的内置类型非常相似。内置类型（如整数或整数数组）的用户只关心创建该类型的对象，然后对它们执行操作。他（通常）不关心数据对象是如何表示的，他认为对象上的操作是不可分割的(indivisible)和原子的(atomic)，而实际上可能需要几个机器指令来执行它们。此外，（通常）不允许他拆分对象。例如，考虑内置类型整数。&lt;/p&gt;
&lt;p&gt;程序员想要声明数组类型的对象，并对它们执行通常的算术运算。他通常对整数对象作为位串(bit string)不感兴趣，并且不能使用计算机内的使用的位格式。此外，他希望这种语言能够保护他不犯一些愚蠢地误用类型错误（例如，将一个整数加到一个字符上），要么将这种事情视为错误（强类型），要么通过某种类型的自动转换。&lt;/p&gt;
&lt;p&gt;在内置数据类型的情况下，程序员正在使用以较低的细节级别实现的概念或抽象——编程语言本身以及编译器。同样，抽象数据类型在一个级别使用，并在较低的级别实现，但是较低级别不会因为是语言的一部分自动出现，相反，抽象数据类型是通过编写一种特殊的程序来实现的，称为操作cluster(operation cluster)，简称cluster，它根据可以对其执行的操作来定义类型。该语言通过允许使用抽象数据类型来促进此活动，而无需其现场(on-the-spot)定义。语言处理程序支持抽象数据类型的方法是：在类型的使用和它的定义之间建立链接（可以提前或推迟提供），并且通过一种非常强大的数据类型形式将数据类型的视图强制为一组操作。&lt;/p&gt;
&lt;p&gt;我们注意到，抽象数据类型概念的一个结果是，程序中的大多数抽象操作(abstract operations)将属于特征抽象类型(characterizing abstract types)的操作集。我们将使用属于函数抽象(functional abstraction)来表示哪些不属于任何特征集的抽象操作。函数抽象(functional abstraction)将被时限为一个或多个数据类型的特征操作的组合，并且将以通常的方式通过过程(producer)支持。正弦波轨迹(sine routine)的实现可以是一个泰勒级数(Taylor expansion)展开，用实际类型的特征操作而表现。&lt;/p&gt;
&lt;h2 id=&#34;the-programming-language&#34;&gt;The Programming Language&lt;/h2&gt;
&lt;p&gt;我们现在给出了一种编程语言的非正式描述，允许抽象数据类型的使用和定义。这种语言是在 M.I.T 下正在开发的结构化编程语言的简化版本。它主要来自 PASCALI ，并且在许多方面的是传统的编程语言一样，但它在几个重要的方面与传统语言不同。&lt;/p&gt;
&lt;p&gt;该语言提供了两种形式的模块相对应于两种形式的抽象：过程（支持函数抽象）和操作cluster（支持抽象数据类型）。每个模块都是自己翻译（编译）的。&lt;/p&gt;
&lt;p&gt;语言在传统意义上没有空闲变量(free variables)。在一个模块中，只有其他模块的名称是空闲的，因此需要在外部定义；也就是说，cluster名称和过程名称。这些名称借助编程器以绑定为目的创建的模块名称目录相绑定。翻译后的模块中没有任何名称需要绑定。&lt;/p&gt;
&lt;p&gt;该语言只有结构化控制。没有 &lt;code&gt;goto&#39;s&lt;/code&gt;或&lt;code&gt;labels&lt;/code&gt;，而只有拼接(concatenation)、选择(selection)(&lt;code&gt;if&lt;/code&gt;， &lt;code&gt;case&lt;/code&gt;)和迭代(iteration)(&lt;code&gt;while&lt;/code&gt;)结构的变体。一些结构化的错误处理机制正在开发中。在本文中，他仅用保留字的存在&lt;code&gt;error&lt;/code&gt;来表示。&lt;/p&gt;
&lt;p&gt;语言允许使用和定义抽象数据类型的方式可以通过一个例子来最好地说明。我们选择了以下问题：编写一个程序 &lt;code&gt;Polish_gen&lt;/code&gt;，它将从中 INFIX 语言转换为 POLISH 修复后的语言。&lt;code&gt;Polish_Gen&lt;/code&gt; 是一个通用程序，没有关于输入或输出设备（或文件）的假设(assumptions)。他只有一下堆输入语言的假设(assumptions)：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;输入语言具有运算符优先语法。&lt;/li&gt;
&lt;li&gt;输入语言的符号要没事字母和数字的任意字符串，要么是单个的非字母数字字符；空格用于终止符号，但其他部分将被忽略。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;例如，如果Polish_gen接收到字符串：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;a + b * (c + d)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;作为输入，它将生成字符串&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;a b c d + * +
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;作为输出。我们选择这个问题作为示例，是因为对编程语言感兴趣的人对这个问题及其解决方案很熟悉，而且这个问题足够复杂，可以说明许多抽象的使用。&lt;/p&gt;
&lt;h2 id=&#34;using-abstract-data-types&#34;&gt;Using Abstract Data Types&lt;/h2&gt;
&lt;p&gt;如图 1 所示，过程 &lt;code&gt;Polish_gen&lt;/code&gt; 执行上述转换。它需要三个参数：输入，一个抽象类型的对象，包含输入语言的句子(input， an object of abstract type infile which holds the sentence of the input language)；输出，抽象类型的输出对象，它将接受输出语言的句子(output， an object of abstract type outfile which will accept a sentence of the output language)；和 g，抽象类型语法的对象可用于识别输入语言的符号并确定其优先关系(and g， an object of abstract type grammar which can be used to recognize symbols of the input language and determine their precedence relations)。此外，&lt;code&gt;Polish_gen&lt;/code&gt;还利用了局部变量的抽象类型堆栈和令牌(stack and token)。请注意，所有的数据类型名称(data-type-names)在 &lt;code&gt;Polish_gen&lt;/code&gt; 中都是可用的(free)，&amp;quot;scan&amp;quot;也是如此，它为 &lt;code&gt;Polish_gen&lt;/code&gt; 使用的单个功能抽象(single functional abstraction)命名。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1642761202797.png&#34; alt=&#34;图1&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;该语言使用相同的语法来声明抽象数据类型的变量，以声明原始类型(primitive type)的的变量。语法区分了涉及创建对象的声明和不涉及对象创建的声明。例如&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;t: token
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;声明 t 是保存抽象类型 token 对象的变量的名称，但是不创建任何 token 对象，因此 t 的值最初是未定义的。因此变量 t 的声明方式与 mustscan 相同&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mustscan: boolean
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;类型名称后出现括号表示创建了一个对象。例如&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;s: stack(token)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;表示 s 是保存抽象类型堆栈对象的变量的名称，堆栈对象将在 s 中创建和存储。创建对象所需的信息在参数列表中传递；在该示例中，唯一的参数 token 定义了可以放在堆栈上的元素类型。堆栈的声母类似于数组声明，例如 &lt;code&gt;array[1..10]的字符&lt;/code&gt;，因为它们都要求指定元素的类型。&lt;/p&gt;
&lt;p&gt;语言是强类型的;因此，抽象对象只有三种使用方式:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;抽象对象可以由定义其抽象类型的操作来操作。&lt;/li&gt;
&lt;li&gt;抽象对象可以作为参数传递给过程。在这种情况下，调用过程传递的实际实参的类型必须与被调用过程中相应形参的类型相同。&lt;/li&gt;
&lt;li&gt;抽象对象可以复制给变量，但前提是该变量声明保存该类型的对象。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;对抽象对象的定义操作的应用是通过使用复合名称(compound name)的操作调用来表示的，例如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;grammar$eof(g)
stack$push(s， t)
token$is_op(t)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;复合名称的第一部分表示操作所属的抽象类型，而第二个组件标识操作。操作调用总是至少有一个参数——操作所属的抽象类型的对象。&lt;/p&gt;
&lt;p&gt;操作调用(operation call)中包含 type-name 有几个原因。第一，由于操作调用可能有几个不同抽象类型的参数，缺少 type-name 可能会导致对实际操作的对象产生歧义。其次，复合名称的使用允许不同数据类型对操作使用相同的名称，而不会产生标识符冲突。第三，我们认为一旦读者习惯了这种表示方法，type-name 前缀将增强程序的可理解性。不仅操作的类型很明显，而且操作调用与过程调用也有明显的区别。&lt;/p&gt;
&lt;p&gt;语句 &lt;code&gt;t:= scan(input， g)&lt;/code&gt; 演示了将抽象对象作为参数传递，以及将抽象对象赋值给变量。过程扫描，如图2所示，期望类型为 &lt;code&gt;infile&lt;/code&gt; 和 &lt;code&gt;grammar&lt;/code&gt; 的对象作为其参数，并返回类型为token的对象，&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1643007130633.png&#34; alt=&#34;图2&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;我们已经解释了对象可以与变量声明一起创建。也可以独立于变量声明创建对象。对象创建是通过 type-name 的出现加上括号来指定的(无论是否在声明中)。例如，在 &lt;code&gt;scan&lt;/code&gt; 的最后一行 &lt;code&gt;token(g， newsymb)&lt;/code&gt;  声明一个token对象，表示刚刚扫描的符号，将被创建; 创建对象所需的信息(刚扫描的语法和符号)在参数列表中传递。&lt;/p&gt;
&lt;p&gt;现在可以给出 &lt;code&gt;Polish_gen&lt;/code&gt; 逻辑的简要描述。&lt;code&gt;Pollsh__gen&lt;/code&gt; 使用函数抽象扫描从输入字符串中获取语法符号。&lt;code&gt;Scan&lt;/code&gt; 以 token 的形式返回符号——引入 token 的目的是提供高效执行，而不会透露语法如何表示符号的信息。&lt;code&gt;Polish_gen&lt;/code&gt; 将包含新扫描符号的 token 存储在变量t中。如果t持有一个表示标识符(如&amp;quot;a&amp;quot;)而不是操作符(如&amp;quot;+&amp;quot;)的 token ，该标识符将立即被放入输出文件。否则，将栈顶部的 token 与t进行比较，以确定它们之间的优先关系。如果关系是 &amp;quot;~&amp;quot;，t被推到栈上(例如，&amp;quot;+&amp;quot; &amp;lt; &amp;quot;*&amp;quot;)。如果关系是&amp;quot;=&amp;quot;，t和栈顶 token 都被丢弃(例如，&amp;quot;(&amp;quot;=&amp;quot;)&amp;quot;)，如果关系是 &amp;quot;~&amp;quot;，栈顶 token 中的操作符被追加到输出文件中，暴露一个新的栈顶 token。由于运算符 token 的优先级比 t 更高，因此布尔变量 mustscan 用于放置扫描新符号并确保下一个比较是具有 t 的当前值。由于文件符号末尾的语法依赖表示(&lt;code&gt;grammar$eof(g)&lt;/code&gt;)最初被推到堆栈上，因此堆栈将变为空，导致 &lt;code&gt;Polish__gen&lt;/code&gt; 只有在耗尽输入生成匹配的eof token时才会完成。(我们已经做了一个简化的假设，即输入是中缀语言的合法句子。)&lt;/p&gt;
&lt;p&gt;scan 过程通过定义抽象类型 infile 的操作输入问题中获取字符。它使用数据类型 char 和 string，以及对这些类型的对象的操作。虽然这些类型如内置所示，但它们很容易地变成抽象类型。在这种情况下，内置的谓词字母数字(predicate alphanumeric)将被表示为 &lt;code&gt;char$alphanumeric&lt;/code&gt;。只有语法会被改变；在任何一种情况下，类型的含义和使用都是相同的。&lt;/p&gt;
&lt;p&gt;综上所述，&lt;code&gt;Polish_gen&lt;/code&gt;使用了 5 个数据抽象，infile， outfile， grammar， token 和 stack，外加一个函数抽象(functional abstraction)， scan。数据抽象的强大功能可以通过类型 infile 和 outfile 来说明，它们分别用来屏蔽与 &lt;code&gt;Polish_gen&lt;/code&gt; 的输入和输出相关的任何物理事实。当 I/O 实际发生时，&lt;code&gt;Polish_gen&lt;/code&gt; 不知道正在使用什么输入和输出设备，也不知道字符串是如何在设备上表示的。对于参数 output，它知道如何添加一个字符串字符(&lt;code&gt;outfile$out_str&lt;/code&gt;)，以及如何表示输出已经完成(&lt;code&gt;outfile$close&lt;/code&gt;)。对于参数 input，他知道如何获取下一个字符(&lt;code&gt;infile$get&lt;/code&gt;)，如何查看下一个字符而不将其从输入中删除(&lt;code&gt;infile$peek&lt;/code&gt;)，以及如何识别输入的结尾(&lt;code&gt;infile$eof&lt;/code&gt;)。（注意，为了正确的 scan 操作，infile 必须在到达文件结束后的 &lt;code&gt;infile$get&lt;/code&gt; 或 &lt;code&gt;infile$peek&lt;/code&gt; 上的任何调用中提供非空白的非字母数字字符串）在每种情况下，它的知识(knowledge)都由提供这些服务的操作的名称组成。&lt;/p&gt;
&lt;h2 id=&#34;defining-abstract-data-types&#34;&gt;Defining Abstract Data Types&lt;/h2&gt;
&lt;p&gt;在本节中，我们描述了编程对象 —— 操作cluster(operation cluster) —— 其翻译(编译)提供了类型的实现。该cluster包含实现每个特征操作的代码，从而体现了数据类型由一组操作定义的想法。&lt;/p&gt;
&lt;p&gt;例如，考虑 &lt;code&gt;Polish_gen&lt;/code&gt; 使用的抽象类型 stack。cluster支持 stack 如图 3 所示。该cluster实现了一种非常常用的 stack 对象，其中 stack 元素的类型是预先知道的。cluster 参数 element_type 表示特定 stack 对象要包含的元素类型。&lt;/p&gt;
&lt;p&gt;cluster定义的第一部分非常简短地描述了cluster呈现给用户的接口。cluster接口定义了cluster的名称，创建cluster实例(cluster 实现的抽象类型对象)所需的参数，以及定义 cluster 实现的类型的操作列表，例如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;stack: cluster(element-type: type)
    is push, pop, top, erasetop, empty
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;保留字 &lt;code&gt;is&lt;/code&gt; 是值数据类型的特征是一组操作。&lt;/p&gt;
&lt;p&gt;cluster 定义的其余部分描述了如何实际支持抽象类型，包含三个部分：对象表示、创建对象的代码和操作定义。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1643018152626.png&#34; alt=&#34;图3&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;对象表示(Object Representation)。抽象数据类型的用户将该类型的对象视为不可分割的实体。然而，在 cluster 内部，对象被视为可分解为更基本类型的元素。 rep(Representation) 描述为：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;rep{(&amp;lt;rep-parameters&amp;gt;)} = &amp;lt;type-definition&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;定义了一个新类型，用保留字 rep 表示，该类型只能在 cluster 中访问，并描述了在 cluster 中如何查看对象。&lt;code&gt;&amp;lt;type-definition&amp;gt;&lt;/code&gt;定义了一个模版，该末班允许构建和分解该类型的对象。通常，它会利用语言提供的数据结构方法：数组（可能是无界的）或 PASCAL 记录。可选的 &lt;code&gt;(&amp;quot;{}&amp;quot;) &amp;lt;rep-parameters&amp;gt;&lt;/code&gt; 使得可以延迟指定 &lt;code&gt;&amp;lt;type-definition&amp;gt;&lt;/code&gt; 的某些方面，知道创建了 rep 的实例。考虑 stack cluster 的 rep 描述：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;rep(type_param: type) = (tp: integer; e_type: type; stk: array[1..] of type_param)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;&amp;lt;type-definition&amp;gt;&lt;/code&gt;指定 stack 对象由包含名为 tp, stk 和 e 类型的三个组件的记录表示。参数 type_param，它可以存储在名为 stk 的无界数组中，该数组将保存推入 task 对象的元素。同样的类型也将存储在 e_type 组件中，并用于类型检查，如下所述。tp 组件保存 stack 最顶层元素的索引。&lt;/p&gt;
&lt;p&gt;对象创建(Object Creation)。保留字 create 标记为 create_code，这是创建抽象类型对象时要执行的代码。cluster 可以被视为一个过程，其过程主体是创建代码。当用户指示要创建抽象类型的对象时，例如，&lt;code&gt;s: stack(token)&lt;/code&gt; ，发生的一件事（在执行时）是对 create_code 的调用，导致该过程体被执行。cluster 的参数实际上是 create_code 的参数。由于除了对外部定义模块的引用之外，没有提供自由变量，因此这些参数对 rep 中的操作或 &lt;code&gt;&amp;lt;type definition&amp;gt;&lt;/code&gt; 都是不可访问的。因此，关于要保存的参数的任何信息都必须显式插入到 rep 的每个实例中。&lt;/p&gt;
&lt;p&gt;stack cluster 中显示的代码是典型的 create_code。首先，创建 rep 的对象；也就是说，分配空间以将对象保存由 rep 定义。然后，一些初始值存储在对象中。最后，对象将返回给调用者。返回对象后，其类型从 rep 类型更改为 cluster 定义的抽象类型。&lt;/p&gt;
&lt;p&gt;操作(Operations)。cluster 的其余部分由一组操作定义组成，这些定义提供了对数据类型允许的操作的实现。操作定义与普通的过程定义类似，除了它们可以访问 cluster 的 rep 之外，这允许它们分解 cluster 类型的对象。操作本身不是模块；它们将被编译器接受，仅作为 cluster 的一部分。&lt;/p&gt;
&lt;p&gt;操作总是至少有一个参数 —— 类型为 rep。因为 cluster 可以同时支持多个其定义类型的对象，所以这个参数告诉操作要操作的特定对象。请注意，在调用者和操作之间传递时，该参数的类型将从抽象类型更改为 rep 类型。&lt;/p&gt;
&lt;p&gt;因为该语言是强类型的，所以必须检查推送到给定 stack 上的对象类型是否与 stack 可容纳的元素类型一致。这个一致性要求在语法上是通过声明 push 的第二个参数的类型与 stack 对象的 rep 的 e_type 组件（即 push 的第一个参数）相同来指定的。翻译（编译）程序可以生成代码来验证类型在运行时是否匹配，如果不匹配则引发错误。&lt;/p&gt;
&lt;h2 id=&#34;controlling-the-use-of-information&#34;&gt;Controlling the Use of Information&lt;/h2&gt;
&lt;p&gt;引入抽象数据类型是为了让程序员在使用数据抽象时不必担心无关的细节。但事实上，我们已经走得更远了。因为语言是强类型的，用户无法使用任何实现细节。在本节中，我们将讨论这种限制所带来的好处：结果是程序更模块化，更容易理解、修改、维护和证明其正确性。&lt;/p&gt;
&lt;p&gt;token 是个很好的类型示例，创建它是为了控制对实现细节的访问。与其引入一个新的类型，&lt;code&gt;Polish_gen&lt;/code&gt; 可以被写为接受来自 scan 的字符串，将字符串存储在 stack 上，并比较字符串以确定优先关系（通过一个适当的操作 &lt;code&gt;grammar$prec_rel&lt;/code&gt;）。这样的解决方案是低效的。因为优先级矩阵可以由 grammar 的保留字表中运算符的位置索引，因此有效的实现将仅查找一次字符串，一旦发现如果是操作者符号，则使用在 &lt;code&gt;Polish_gen&lt;/code&gt; 中的操作符的索引。&lt;/p&gt;
&lt;p&gt;然而，这会暴露有关 grammar 表示的信息。如果 &lt;code&gt;Polish_gen&lt;/code&gt; 或使用 grammar 的一些其他模块利用此信息，则 grammar cluster 的正常维护和修改可以引入难以追踪的错误。因此，引入了新类型，token，以限制关于 grammar 是如何表示的信息的分布。限制，grammar cluster 的重新定义只能影响 token  cluster —— token cluster 对从 grammar 接收到的索引没有任何假设。如果在查找优先关系（如索引越界）时发生错误，则该错误只能是由 token 或 grammar cluster 中的某些内容引起的。&lt;/p&gt;
&lt;p&gt;事实上，选择 token 的实现——例如，token 是用整数还是字符串表示——涉及到设计决策。这个决策可以延迟到 token 的 cluster 被定义时，而不必在 &lt;code&gt;Polish_gen&lt;/code&gt; 编码期间做出来。因此，&lt;code&gt;Polish_gen&lt;/code&gt; 的编程可以根据 Dijkstra 的编程原则之一来完成：每次只构建一个决策。遵循这一原则，可以简化 &lt;code&gt;Polish_gen&lt;/code&gt; 的逻辑，使其更容易理解和维护。&lt;/p&gt;
&lt;p&gt;使 representation 无法访问也导致一个更容易证明正确的程序。程序的证明分为两部分：证明 cluster 正确实现该类型，以及使用类型的程序是正确的。只有在前一种证明中才需要考虑类型对象的实现细节；后一个证明仅仅基于类型的抽象属性，这些抽象属性可以用每种类型的特征操作之间的关系来表示。&lt;/p&gt;
&lt;h2 id=&#34;relationship-to-previous-work&#34;&gt;Relationship to Previous Work&lt;/h2&gt;
&lt;p&gt;在为定义数据类型创建合适的机制方面已经做了很多工作。这里不可能调研所有的工作，也不是说所有的工作都与本文相关。在本节中，我们将概述与 cluster 最密切相关的工作领域，因为它们提供了一些用于定义抽象数据类型的工具，并讨论 cluster 方法与这些工作的区别。相关工作可以大致分为三类：可扩展语言(extensible languages)、一组标准抽象操作符的实现规范(implementation specifications for a set of standard abstract operators)和 SIMULA 67 类定义(SIMULA 67 class definitions)。&lt;/p&gt;
&lt;h3 id=&#34;extensible-languages&#34;&gt;Extensible Languages&lt;/h3&gt;
&lt;p&gt;可扩展语言的大部分工作和成功都是在数据类型定义领域。然而，这项工作主要面向定义表示(defining representations)，而不是抽象类型。通过使用语言的基本模式构造工具(primitive mode construction facilities of the language)，根据现有模式构造表示()，可以创建新的数据表示(new data representations)，或者通常称为模式(mode)。可扩展语言提供的模式构建工具通常包括定义对象指针、定义不同模式类的联合以及构造对象聚合（数组和记录）的机制。这些与本文中用来定义 rep 的方法密切对应。这些模式定义机制的使用意味着定义了一组构造函数(constructors)、选择器(selectors)和谓词(predicates)，它们可以应用于所定义模式的对象。在某些语言中，模式定义可以允许这组操作被特定的操作扩充，比如在语言中明确规定的赋值操作。&lt;/p&gt;
&lt;p&gt;可扩展语言的主要问题是它们不鼓励使用数据抽象。一般来说，在模式定义中定义描述抽象数据类型的所有操作是不可能的。正如我们注意到的，只有数据类型的 representation 是使用模式扩展机制定义的。任何不等同于 representation 的构造函数、选择器或谓词的抽象操作都必须由过程或宏在模式定义之外定义，可以使用语法扩展功能使其看起来像操作符。因此，用户必须学习两种不同的机制；定义不是像在操作 cluster 中那样收集在一个地方，而是被分割成不同的部分。此外，很难限制对抽象数据类型的特征操作的对 representation 的访问。&lt;/p&gt;
&lt;h3 id=&#34;standard-abstract-operations&#34;&gt;Standard Abstract Operations&lt;/h3&gt;
&lt;p&gt;源自 Mealy 和 Balzer 早期工作的作品在精神上更接近于这里采取的方法。Mealy 建立这样一个观点，即数据集合是从一组选择器到一组值的 map ，对数据集合的操作要么是 map 上的转换，要么是使用 map 来访问元素。这种观点导致了标准化一组用于数据集合的抽象操作符的尝试。例如，Balzer 为这样的集合提出了一个特定的抽象，它定义了一组四个抽象操作符，用于创建、访问、修改和销毁抽象数据集合。用户将通过指定如何实现每个抽象操作来定义一个特定的集合。这项工作已经被扩展（例如，Earley），但是它的主要重点仍然是定义一个标准的抽象操作集。更复杂的操作被定义为根据这些操作编写的过程。&lt;/p&gt;
&lt;p&gt;尽管区分一些抽象操作（如&amp;quot;create&amp;quot;）很有用，因为他们很可能适用于所有抽象数据类型，但期望一组预先确定的操作足以操作所有抽象数据对象似乎是不合理的。因此，将操作的选择留给类型的创建者，就像操作 cluster 一样，提供了一个更紧密定制的抽象。&lt;/p&gt;
&lt;h3 id=&#34;simula-classes&#34;&gt;SIMULA Classes&lt;/h3&gt;
&lt;p&gt;在行驶时，最接近的语言是 SIMULA 67。SIMULA 类定义与 cluster 定义有很多相似之处。然而，这两种语言有一个非常重要的哲学差异，这导致了几个重要的语言差异。SIMULA 的类被设计用来表示和提供对数据对象的完全访问。类中的每个属性和函数都可以在嵌入类定义的块中访问。因此，用户总是知道 representation 的实际形式。&lt;/p&gt;
&lt;p&gt;与此相反，cluster 的 representation 在 cluster 之外是不可访问的。cluster 中的操作提供了访问 representation 内容的唯一访问，即使这样，也只有 cluster 的定义的操作的一个子集可以从外部访问。由于这种哲学上的差异，两种语言中引用数据的机制、非局部变量引用的使用以及块和块结构的使用都有很大的不同。&lt;/p&gt;
&lt;h2 id=&#34;implementation-considerations&#34;&gt;Implementation Considerations&lt;/h2&gt;
&lt;p&gt;cluster 实现的大部分方面都和常规处理方式一样。然而，该实现有几个方面值得特别提及，因为它们是和常规实现不同的，或者对使用 cluster 来表示抽象数据的实用性有重大影响。&lt;/p&gt;
&lt;h3 id=&#34;modules-and-module-names&#34;&gt;Modules and Module-Names&lt;/h3&gt;
&lt;p&gt;编译器接收一个模块作为输入。模块通常是一个 cluster，但有时也会是一个过程，如 &lt;code&gt;Polish_gen&lt;/code&gt; 或 &lt;code&gt;scan&lt;/code&gt;。在模块转换的过程中，会遇到外部定义的模块名，用来指代过程和数据类型。（请注意，对抽象数据类型上操作的引用不会引入任何额外的外部引用，因为它们是相对于操作名前缀的抽象类型。）&lt;/p&gt;
&lt;p&gt;当编译器处理一个模块时，它会构建或添加一个描述单元(description-unit)，该描述单元包含关于该模块的信息。描述单元中包含的信息包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;由编译器生成的目标代码的位置。&lt;/li&gt;
&lt;li&gt;模块对其用户可用的接口的描述。特别是，维护关于模块期望的所有参数和值类型的完整信息。如果该模块是一个 cluster，则将保留 cluster 中每个操作的信息。&lt;/li&gt;
&lt;li&gt;使用该模块的所有模块的列表。&lt;br&gt;
显然更多信息可以存储在描述单元：以符号表等形式调试信息，文档信息，以输入/输出关系的谓词演算描述的形式，甚至是基本原理的分析对于设计模块的决定。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;描述单元(description unit)是关于模块的所有信息的焦点。它可以在处理模块时创建，也可以创建为其他模块引用的目标。在处理描述单元所代表的的模块之前创建描述单元支持自顶向下设计，并提供了一种定义递归的简单方法。由于描述单元保存了所有使用模块的列表，所以当模块实际定义时，可以检查使用和定义的一致性，并在那时生成适当的错误消息。实际的定义可能会延迟一段时间，因为描述单元可以用来定位代码，以模拟模块的行为，已达到调试的目的。&lt;/p&gt;
&lt;p&gt;在翻译（编译）模块的过程中，翻译器必须将每个模块名绑定到对应模块的代码，从而为每个模块名赋予含义。这是通过描述单元完成的。翻译程序通过一个目录获得对描述单元的访问，该目录包含一组 module-name/description unit pair，它将其作为参数接收。所有外部引用都必须通过此目录解析；如果无法解析它们，则生成适当的错误消息。&lt;/p&gt;
&lt;p&gt;该目录是一个用户构造的对象，一般来说，构建该对象是为了控制一组特定相关模块的翻译。实际的描述单元存储在一个类似于 MULTICS 文件系统的多级树形文件系统中，对于目录中描述单元的引用实际上是对这个文件系统的引用。用于构造目录和操作文件的原语独立于语言，形成了 &amp;quot;file system cluster&amp;quot; 和 &amp;quot;directory cluster&amp;quot;。&lt;/p&gt;
&lt;h3 id=&#34;type-checking&#34;&gt;Type Checking&lt;/h3&gt;
&lt;p&gt;本文中描述的语言是基于强类型检查的思想，语言翻译器应该在两个独立编程过程之间的接口上执行强类型检查。在本节中，我们将讨论由强类型检查引起的一些问题。&lt;/p&gt;
&lt;p&gt;强类型检查意味着，每当一个对象从调用函数传递到被调用函数时，它的类型必须与被调用函数中声明的类型兼容。如果被调用的函数是一个过程，则类型必须完全匹配。如果被调用的函数是一个操作，那么类型必须完全匹配，除非对象是由该操作所属的 cluster 定义的抽象类型。在本例中，对象的类型更改为该 cluster 的 rep 类型。因此，类型检查机制控制对象的 representation 是否对给定的操作可见。在这种情况下，如果类型错误未被检测到，则应该在 cluster 之外不可访问的信息将变为可访问的，程序模块化将被破坏。&lt;/p&gt;
&lt;p&gt;这种语言中的类型检查比大多数传统语言中的要复杂。这是因为用户定义的抽象，包括数据类型和过程，都可以使用类型作为参数。考虑上面定义的数据类型 stack 。我们已经注意到 stack 和数组之间的相似性：在每种情况下，都必须在创建实例之前提供结果组件的类型规范。构造器(constructs)，如 stack 和 array，被称为类型生成器(tyoe generators)，因为它们定义了一个 class 类型(type of class)，而不是单个类型。类中的每个单独类型都是通过为类型生成器的每个类型参数提供类型定义来生成的。类型生成器（如 stack）是为了满足未来用户的需要而创建的，它定义一个开放的类型类，并且在编译 stack cluster 时不知道其他 class 类型的成员。&lt;/p&gt;
&lt;p&gt;允许用户定义类型生成器的影响之一是，cluster 中针对该 “类型” 的一些操作是多态的(polymorphic)；也就是说，操作可以在许多不同的类型域(type domains)上定义，这会受到任何给定的参数集的类型是类型一致的(type-consistent)约束。这种操作的一个例子是 stack cluster 中的 push 操作。push 的操作数是一个 stack 和一个值。push 的类型一致性要求是，如果 stack 的类型是 &amp;quot;stack of T&amp;quot;，那么 push 的值必须是 T 类型；因此，操作 push 的强类型检查包括确定其 stack 参数是否真的是一个 stack、确定 stack 参数的类型、确定被 push 值的类型以及确定它们是否满足一致性要求。&lt;/p&gt;
&lt;p&gt;最好进行编译时类型检查，因为类型错误可以尽早检测到。然而，由于在语言中可以自由地使用类型，编译时类型检查可以有多完整还不清楚。因此，该语言的设计是基于运行时类型检查机制的，该机制通过尽可能多的编译时检查进行扩充。&lt;/p&gt;
&lt;p&gt;很明显，给定合适的 representation 类型表示形式，就可以编写运行时检查是否具有相同匹配的类型。导致对象的 representation 暴露给操作的那种类型检查可以在运行时通过 Morris I0 描述的技术来处理，该技术是操作系统汇总保护工作的产物。（cluster 和受保护的子系统之间有很强的相关性；cluster提供了封装私有信息的自然机制。）&lt;/p&gt;
&lt;p&gt;在未来，我们也许可以不用运行时机制，因为 John Reynolds 最近的工作表明，完整的编译时类型检查是可能的。我们期待 Reynolds 的工作的完成，并打算在不久的将来设计一个基于编译时类型检查的语言版本。&lt;/p&gt;
&lt;h3 id=&#34;retention&#34;&gt;Retention&lt;/h3&gt;
&lt;p&gt;该语言被设计成允许使用 stack 规则(discipline)实现 cluster、procedure 和 operation 的激活。cluster、procedure 和 operation 在执行时没有自由变量，其中定义的所有变量都是纯本地的。要保留或共享的所有信息都必须存储在对象的 representation 中。在使用保留策略的堆中分配对象。在实践中，有许多容易识别的情况， 对象不需要放在堆中，而是可以在 stack 上分配，要么是因为对象不共享，要么是因为一旦分配了对象，其内容就永远不会更改。这些情况可以由语言翻译（编译）人员进行优化。&lt;/p&gt;
&lt;h3 id=&#34;efficiency&#34;&gt;Efficiency&lt;/h3&gt;
&lt;p&gt;我们认为将两个结构与一个程序相联系是有帮助的：它的逻辑结构(logical structure)和物理结构(physical structure)。程序员的主要任务是构建一个具有良好逻辑结构的程序——一个易于理解、易于修改和维护的程序。然而，一个好的逻辑结构并不一定意味着一个好的物理结构——一个有效执行的物理结构。事实上，用于实现良好逻辑结构（层次结构，仅通过函数访问数据等）的技术在许多情况下似乎意味着糟糕的物理结构。&lt;/p&gt;
&lt;p&gt;我们相信编译器的任务是把好的逻辑结构映射成好的物理结构。这两个结构可能有差异的事实是可以接受的，前提是编译器被验证了，并且所有编程工具（例如，调试工具）都被定义为隐藏差异。&lt;/p&gt;
&lt;p&gt;该语言旨在优化编译器进行编译，从而在输出代码中实现良好的物理结构。语言对于操作调用的一样具有灵活性，这一事实可以获得一个重要的效率。每个操作调用可以被对应操作的实际调用或操作的内联代码替换。语言设计的两个方面使得这种灵活性成为可能：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;因为操作调用的语法在两种情况下都是相同的，所以可以更改所使用的编译技术，而无需重写使用操作符的过程。&lt;/li&gt;
&lt;li&gt;cluster 的不变部分——操作代码——已经被小心地与 rep 分开，rep 保存着依赖于对象的信息；因此，代码的内联嵌入(inline insertion)是可能的。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;操作代码的内联插入允许该代码受编译器中可用的优化转换(optimization transformations)。优化转换，例如编译时间评估和常见的子表达式消除，删除冗余计算，从而降低执行操作所需的时间。例如，如果在 &lt;code&gt;Polish_gen&lt;/code&gt; 中插入哪些操作，则可以消除 stack cluster 操作中的所有错误检查。这些标准优化技术应该非常有效，因为编译器正在处理结构化程序；缺乏自由变量，以及 goto 和其他混乱的控制结构意味着可以执行彻底的数据和控制流程分析。换句话说，编译器可以从程序的良好逻辑结构中受益，以获得对它的彻底了解，就像一个人一样。&lt;/p&gt;
&lt;p&gt;获得这种执行时间优化的代价是增加了重新定义或修改模块的成本。每次这样的修改都可能需要重新编译使用内联修改函数的模块。由于使用内联代码的决定可能会延迟，直到性能测量表明系统的哪些部分是关机的，因此只有当内联代码会带来积极的性能好处时，才需要放弃简单的程序修改的灵活性。请注意，保存在描述单元中的模块的使用列表可能用于在进行更改时自动重新编译。&lt;/p&gt;
&lt;h2 id=&#34;conclusions&#34;&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;本文描述了一种新的抽象——抽象数据类型，它增强类我们利用抽象构建程序的能力。这种方法作为一个概念和编程语言的一部分进行了讨论。给出了几个应用实例。抽象数据类型被定义为一类对象，其特征完全是对这些对象执行的操作。为了提供对抽象数据类型的编程语言支持，引入了一种新的语言结构—— operation cluster。&lt;/p&gt;
&lt;p&gt;开发该语言背后的根本原因是，通过提供一种语言来表达程序设计过程中暴露的抽象，从而使结构化编程的时间更容易理解。我们认为抽象数据类型的概念以一种对程序员最有用的形式提供了数据抽象：他只需要知道抽象对象的行为，这正是他编写程序所需要的信息，而有关对象在存储中如何表示以及操作如何实现的无关细节对他来说是隐藏的。事实上，他无法利用实现细节，从而导致了程序质量的改进：程序将更加模块化，更容易理解、修改、维护和证明其正确性。&lt;/p&gt;
&lt;p&gt;当然，程序的质量在很大程度上决定于好的程序设计。尽管一门语言永远不能教会程序员什么构成了一个良好的程序，但它可以引导他思考正确的事情。我们相信抽象是优秀设计的关键，并且我们在使用该语言的实验中发现，它鼓励程序员有意识的寻找抽象，特别是数据抽象，并认真思考它们的使用和定义。&lt;/p&gt;
&lt;p&gt;我们相信，本文中讨论的抽象方法可以有效地整合到许多不同类型的语言中。任何一种语言，无论多高级，都不可能包含任何使用它的人所需要的所有抽象。因此，本文中描述的抽象构建机制(abstraction-building-mechanism)将是一种非常高级的语言的有用特性。&lt;/p&gt;
&lt;h2 id=&#34;acknowledgements&#34;&gt;Acknowledgements&lt;/h2&gt;
&lt;p&gt;作者非常感谢Jack Dennis、Austin Henderson、Greg Pflster和其他推荐人对论文的内容和结构所作的有益的评论。&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Wirth, N. The progranmting language PASCAL. Acta Informatica, Vol. I (1971), pp 35-63.&lt;/li&gt;
&lt;li&gt;Parnas, D.L. Information distribution aspects of design methodology, Proceedings of the IFIP Congress, August 1971.&lt;/li&gt;
&lt;li&gt;DiJkstra, E. W. Notes on structured programming. Structured Programming, A.P.I.C. Studies in Data Processing, No. 8, Academic Press, New York, 1972, pp 1-81.&lt;/li&gt;
&lt;li&gt;Schuman, S. A. and P. Jorrand. Definition mechanisms in extensible programming languages. Proceedings of the AFIPS, Vol. 37, 1970, pp 9-19.&lt;/li&gt;
&lt;li&gt;Mealy, G. Another look at data. Proceedings of the AFIPS, Vol. 31, 1967, pp 525-534.&lt;/li&gt;
&lt;li&gt;Balzer, R. M. Dataless programming. Proceedings of the AFIPS, Vol. 31, 1967, pp 557-566.&lt;/li&gt;
&lt;li&gt;Earley, J. Toward an understanding of data structures. Comm. of the ACM, Vol. 14, No. I0 (October 1971), pp 617-627.&lt;/li&gt;
&lt;li&gt;Dahl, O.-J., B. Myhrhaug, and K. Nygaard. The SIMULA 67 Common Base Language. Norwegian Computing Center, Oslo, Publication S-22, 1970.&lt;/li&gt;
&lt;li&gt;Daley, R. C., and P. G. Neumann. A general purpose file system for secondary storage. Proceedings of the AFIPS, Vol. 27, 1965, pp 213-229.&lt;/li&gt;
&lt;li&gt;Morris, J. H., Jr. Protection in programming languages. Comm. of the ACM, Vol. 16, No. i (January 1973), pp 15-21.&lt;/li&gt;
&lt;li&gt;Zilles, S. N. Procedural encapsulation: a linguistic protection technique. SIGPLAN Notices, Vol. 8, No. 9 (September 1973), pp 140-146.&lt;/li&gt;
&lt;li&gt;Reynolds, J. Personal communication.&lt;/li&gt;
&lt;li&gt;Liskov, B. H. A design methodology for reliable software systems. Proceedings of the AFIPS, Vol. 41, 1972, pp 191-199.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;本文来源&#34;&gt;本文来源&lt;/h2&gt;
&lt;p&gt;PROGRAMMING WITH ABSTRACT DATA TYPES&lt;br&gt;
Barbara Liskov Massachusetts Institute of Technology Project MAC&lt;br&gt;
Cambridge， Massachusetts&lt;br&gt;
Stephen Zilles Cambridge Systems Group&lt;br&gt;
IBM Systems Development Division Cambridge， Massachusetts&lt;/p&gt;
&lt;p&gt;原文：&lt;a href=&#34;/Users/wenbo.zhang/Library/CloudStorage/OneDrive-%E4%B8%AA%E4%BA%BA/Gridea/post-file/liskov1974.pdf&#34;&gt;Programming with abstract data types&lt;/a&gt;&lt;/p&gt;
">Programming with abstract data types</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://wenbozhangw.github.io/post/aerospike-guan-fang-jian-yi-jian-kong-zhi-biao/"" data-c="
          &lt;p&gt;Aerospike 建议您监控此处列出的指标。 有关指标的完整列表，请参阅 &lt;a href=&#34;https://docs.aerospike.com/reference/metrics&#34;&gt;Metric Reference&lt;/a&gt; 。&lt;/p&gt;
&lt;!-- more --&gt;
&lt;p&gt;除了监控 Aerospike 服务器的运行状况，您还应该监控集群服务器的硬件资源，例如可用磁盘空间、可用 RAM、交换和 CPU 使用率。&lt;/p&gt;
&lt;h2 id=&#34;推荐的警报指标&#34;&gt;推荐的警报指标&lt;/h2&gt;
&lt;h3 id=&#34;clock_skew_stop_writes&#34;&gt;clock_skew_stop_writes&lt;/h3&gt;
&lt;p&gt;位置：Namespace&lt;br&gt;
版本：4.0&lt;br&gt;
说明：如果 &lt;a href=&#34;https://docs.aerospike.com/reference/metrics#clock_skew_stop_writes&#34;&gt;clock_skew_stop_writes&lt;/a&gt; 为 &lt;code&gt;true&lt;/code&gt;，发出严重报警。&lt;br&gt;
确保时钟在集群中同步。&lt;/p&gt;
&lt;h3 id=&#34;dead_partitions&#34;&gt;dead_partitions&lt;/h3&gt;
&lt;p&gt;位置：Namespace&lt;br&gt;
版本：4.0&lt;br&gt;
说明：如果 &lt;a href=&#34;https://docs.aerospike.com/reference/metrics#dead_partitions&#34;&gt;dead_partitions&lt;/a&gt; 不为零，发出严重报警。&lt;br&gt;
如果您确定不存在潜在的数据不一致，或者数据不一致是可以接受的，请考虑发出 &lt;a href=&#34;https://docs.aerospike.com/reference/info#revive&#34;&gt;revive&lt;/a&gt; 和 &lt;a href=&#34;https://docs.aerospike.com/reference/info#recluster&#34;&gt;recluster&lt;/a&gt; 命令。&lt;/p&gt;
&lt;h3 id=&#34;device_available_pct&#34;&gt;device_available_pct&lt;/h3&gt;
&lt;p&gt;位置：Namespace&lt;br&gt;
版本：3.9&lt;br&gt;
说明：如果 &lt;a href=&#34;https://docs.aerospike.com/reference/metrics#device_available_pct&#34;&gt;device_available_pct&lt;/a&gt; 低于 20%，则应该对操作组员告警。这种情况可能表明碎片整理无法跟上当前负载。&lt;br&gt;
如果  &lt;a href=&#34;https://docs.aerospike.com/reference/metrics#device_available_pct&#34;&gt;device_available_pct&lt;/a&gt; 低于 15%，应该发出严重报警。&lt;br&gt;
如果  &lt;a href=&#34;https://docs.aerospike.com/reference/metrics#device_available_pct&#34;&gt;device_available_pct&lt;/a&gt; 低于 5%，则可用磁盘资源非常低。这种情况可能会导致 &lt;a href=&#34;https://docs.aerospike.com/reference/metrics#stop_writes&#34;&gt;stop_writes&lt;/a&gt; 。&lt;/p&gt;
&lt;h3 id=&#34;hwm_breached&#34;&gt;hwm_breached&lt;/h3&gt;
&lt;p&gt;位置：Namespace&lt;br&gt;
版本：3.9&lt;br&gt;
说明：如果 &lt;a href=&#34;https://docs.aerospike.com/reference/metrics#hwm_breached&#34;&gt;hwm_breached&lt;/a&gt; 为 &lt;code&gt;true&lt;/code&gt;，应该提醒您的操作组员内存或磁盘资源紧张。这种情况可能表明需要增加集群容量。&lt;/p&gt;
&lt;h3 id=&#34;memory_free_pct&#34;&gt;memory_free_pct&lt;/h3&gt;
&lt;p&gt;位置：Namespace&lt;br&gt;
版本：3.9&lt;br&gt;
说明：如果 &lt;code&gt;memory_free_pct&lt;/code&gt; 接近 &lt;code&gt;high-water-memory-pct&lt;/code&gt; 或 &lt;code&gt;stop-writes-pct&lt;/code&gt; 的配置值，应该发出报警调查问题原因。出现这个问题可能表明需要减少对象数量或增加容量，如果使用二级索引，则可能需要进一步调查 &lt;code&gt;memory_used_sindex_bytes&lt;/code&gt;，如果使用 Set 索引，则需要进一步调查 &lt;code&gt;memory_used_set_index_bytes&lt;/code&gt;，如果数据存储在内存中，则需要调查 &lt;code&gt;heap_efficiency_pct&lt;/code&gt;。&lt;/p&gt;
&lt;h3 id=&#34;pmem_available_pct&#34;&gt;pmem_available_pct&lt;/h3&gt;
&lt;p&gt;位置：Namespace&lt;br&gt;
版本：4.8&lt;br&gt;
说明：如果 &lt;a href=&#34;https://docs.aerospike.com/reference/metrics#pmem_available_pct&#34;&gt;pmem_available_pct&lt;/a&gt; 低于 20%，应该警告您的操作组员。这种情况可能表明碎片整理无法跟上当前负载。&lt;br&gt;
如果  &lt;a href=&#34;https://docs.aerospike.com/reference/metrics#pmem_available_pct&#34;&gt;pmem_available_pct&lt;/a&gt; 低于 15%，应该发出严重报警。&lt;br&gt;
如果  &lt;a href=&#34;https://docs.aerospike.com/reference/metrics#pmem_available_pct&#34;&gt;pmem_available_pct&lt;/a&gt;  低于 5%，则可用 PMEM 资源非常低。这种情况可能会导致 &lt;a href=&#34;https://docs.aerospike.com/reference/metrics#stop_writes&#34;&gt;stop_writes&lt;/a&gt; 。&lt;/p&gt;
&lt;h3 id=&#34;unavailable_partitions&#34;&gt;unavailable_partitions&lt;/h3&gt;
&lt;p&gt;位置：Namespace&lt;br&gt;
版本：4.0&lt;br&gt;
说明：如果 &lt;a href=&#34;https://docs.aerospike.com/reference/metrics#unavailable_partitions&#34;&gt;unavailable_partitions&lt;/a&gt; 不为零，应该严重报警。&lt;br&gt;
检查网络问题并确保集群正确形成。&lt;/p&gt;
&lt;h3 id=&#34;client_connections&#34;&gt;client_connections&lt;/h3&gt;
&lt;p&gt;位置：Statistics&lt;br&gt;
说明：如果 &lt;code&gt;client_connections&lt;/code&gt; 低于预期的低值， 那么这种情况可能表明客户端和服务器之间的网络存在问题。&lt;br&gt;
如果 &lt;code&gt;client_connections&lt;/code&gt; 高于预期的高值， 那么这种情况可能表明客户端快速打开和关闭套接字存在问题。&lt;br&gt;
如果 &lt;code&gt;client_connections&lt;/code&gt; 处于或接近 &lt;a href=&#34;https://docs.aerospike.com/reference/metrics#proto_fd_max&#34;&gt;proto_fd_max&lt;/a&gt; ， 那么 Aerospike 服务器要么当前无法接受新连接，要么很快就无法接受。&lt;/p&gt;
&lt;h3 id=&#34;client_connections_opened&#34;&gt;client_connections_opened&lt;/h3&gt;
&lt;p&gt;位置：Statistics&lt;br&gt;
版本：5.6&lt;br&gt;
说明：如果 &lt;code&gt;client_connections_opened&lt;/code&gt; 在没有添加或删除客户端的情况下发生意外更改，或者工作负载发生了重大变化， 那么这种情况可能表明节点速度变慢或节点出现连接问题。&lt;/p&gt;
&lt;h3 id=&#34;cluster_size&#34;&gt;cluster_size&lt;/h3&gt;
&lt;p&gt;位置：Statistics&lt;br&gt;
说明：如果 &lt;a href=&#34;https://docs.aerospike.com/reference/metrics#cluster_size&#34;&gt;cluster_size&lt;/a&gt; 不等于预期的集群大小并且集群没有进行维护， 那么您的运营团队需要进行调查。&lt;/p&gt;
&lt;h3 id=&#34;fabric_connections_opened&#34;&gt;fabric_connections_opened&lt;/h3&gt;
&lt;p&gt;位置：Statistics&lt;br&gt;
版本：5.6&lt;br&gt;
说明：如果 &lt;code&gt;fabric_connections_opened&lt;/code&gt; 发生意外变化，应该发出警报，因为这种情况表明节点或集群更改存在连接问题。&lt;/p&gt;
&lt;h3 id=&#34;heartbeat_connections_opened&#34;&gt;heartbeat_connections_opened&lt;/h3&gt;
&lt;p&gt;位置：Statistics&lt;br&gt;
版本：5.6&lt;br&gt;
说明：如果 &lt;code&gt;heartbeat_connections_opened&lt;/code&gt; 发生意外变化，应该发出警报，因为这种情况表明节点或集群更改存在连接问题。&lt;/p&gt;
&lt;h3 id=&#34;system_free_mem_kbytes&#34;&gt;system_free_mem_kbytes&lt;/h3&gt;
&lt;p&gt;位置：Statistics&lt;br&gt;
说明：如果 &lt;code&gt;system_free_mem_kbytes&lt;/code&gt; 异常低， 那么这种情况表明服务器达​​到了可用 RAM 的限制。操作员应调查并可能需要添加节点或增加每个节点的 RAM。&lt;/p&gt;
&lt;h3 id=&#34;system_free_mem_pct&#34;&gt;system_free_mem_pct&lt;/h3&gt;
&lt;p&gt;位置：Statistics&lt;br&gt;
说明：如果 &lt;code&gt;system_free_mem_pct&lt;/code&gt; 异常低， 那么这种情况表明服务器达​​到了可用 RAM 的限制。操作员应调查并可能需要添加节点或增加每个节点的 RAM。&lt;/p&gt;
&lt;h3 id=&#34;lag&#34;&gt;lag&lt;/h3&gt;
&lt;p&gt;位置：XDR - DC&lt;br&gt;
版本：5.0.0&lt;br&gt;
说明：如果 &lt;a href=&#34;https://docs.aerospike.com/reference/metrics#lag&#34;&gt;lag&lt;/a&gt; 始终大于几秒， 那么这种情况可能表明网络连接问题或目标集群写入错误。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;其他监控指标&#34;&gt;其他监控指标&lt;/h2&gt;
&lt;h3 id=&#34;client_delete_error&#34;&gt;client_delete_error&lt;/h3&gt;
&lt;p&gt;位置：Namespace&lt;br&gt;
版本：3.9&lt;br&gt;
说明：&lt;code&gt;client_delete_error&lt;/code&gt; 与 &lt;code&gt;client_delete_success&lt;/code&gt; 比例。 如果比率高于可接受的， 然后警报操作员进行调查。&lt;/p&gt;
&lt;h3 id=&#34;client_read_error&#34;&gt;client_read_error&lt;/h3&gt;
&lt;p&gt;位置：Namespace&lt;br&gt;
版本：3.9&lt;br&gt;
说明：&lt;code&gt;client_read_error&lt;/code&gt; 与 &lt;code&gt;client_read_success&lt;/code&gt;  比例。 如果比率高于可接受的， 然后警报操作员进行调查。&lt;/p&gt;
&lt;h3 id=&#34;client_udf_error&#34;&gt;client_udf_error&lt;/h3&gt;
&lt;p&gt;位置：Namespace&lt;br&gt;
版本：3.9&lt;br&gt;
说明：&lt;code&gt;client_udf_error&lt;/code&gt; 与 &lt;code&gt;client_udf_complete&lt;/code&gt; 比例。 如果比率高于可接受的， 然后警报操作员进行调查。&lt;/p&gt;
&lt;h3 id=&#34;client_write_error&#34;&gt;client_write_error&lt;/h3&gt;
&lt;p&gt;位置：Namespace&lt;br&gt;
版本：3.9&lt;br&gt;
说明：&lt;code&gt;client_write_error&lt;/code&gt; 与 &lt;code&gt;client_write_success&lt;/code&gt; 比例。 如果比率高于可接受的， 然后警报操作员进行调查。有关更多详细信息，请参阅 &lt;a href=&#34;https://discuss.aerospike.com/t/understanding-client-write-errors/4442&#34;&gt;Understanding Client Write Errors&lt;/a&gt;。&lt;/p&gt;
&lt;h3 id=&#34;index_flash_alloc_pct&#34;&gt;index_flash_alloc_pct&lt;/h3&gt;
&lt;p&gt;位置：Namespace&lt;br&gt;
版本：5.6&lt;br&gt;
说明：如果 &lt;code&gt;index_flash_alloc_pct&lt;/code&gt; 接近或高于 100%，应该提醒操作员检查命名空间的大小。&lt;/p&gt;
&lt;h3 id=&#34;memory_used_bytes&#34;&gt;memory_used_bytes&lt;/h3&gt;
&lt;p&gt;位置：Namespace&lt;br&gt;
版本：3.9&lt;br&gt;
说明：&lt;a href=&#34;https://docs.aerospike.com/reference/metrics#used-bytes-memory&#34;&gt;used-bytes-memory&lt;/a&gt; 的趋势提现，可让操作员深入了解此命名空间的内存使用情况如何随时间变化。&lt;/p&gt;
&lt;h3 id=&#34;scan-aggr-error&#34;&gt;scan-aggr-error&lt;/h3&gt;
&lt;p&gt;位置：Namespace&lt;br&gt;
版本：3.9&lt;br&gt;
说明：&lt;code&gt;scan_aggr_error&lt;/code&gt; 和 &lt;code&gt;scan_aggr_complete&lt;/code&gt; 比例。如果比率高于可接受的， 然后警报操作员进行调查。&lt;/p&gt;
&lt;h3 id=&#34;scan_basic_error&#34;&gt;scan_basic_error&lt;/h3&gt;
&lt;p&gt;位置：Namespace&lt;br&gt;
版本：3.9&lt;br&gt;
说明：&lt;code&gt;scan_basic_error&lt;/code&gt; 和 &lt;code&gt;scan_basic_complete&lt;/code&gt; 比例。如果比率高于可接受的， 然后警报操作员进行调查。&lt;/p&gt;
&lt;h3 id=&#34;scan_ops_bg_error&#34;&gt;scan_ops_bg_error&lt;/h3&gt;
&lt;p&gt;位置：Namespace&lt;br&gt;
版本：4.7&lt;br&gt;
说明：&lt;code&gt;scan_udf_bg_error&lt;/code&gt; 和 &lt;code&gt;scan_udf_bg_complete&lt;/code&gt; 比例。如果比率高于可接受的， 然后警报操作员进行调查。&lt;/p&gt;
&lt;h3 id=&#34;storage-enginedeviceixdefrag_q&#34;&gt;storage-engine.device[ix].defrag_q&lt;/h3&gt;
&lt;p&gt;位置：Namespace&lt;br&gt;
版本：4.3&lt;br&gt;
说明：根据存储配置，按照设备或按文件测算。如果 &lt;code&gt;storage-engine.device[ix].defrag_q&lt;/code&gt; 或 &lt;code&gt;storage-engine.file[ix].defrag_q&lt;/code&gt; 随着时间的推移继续增加， 然后提醒操作人员调查原因。&lt;/p&gt;
&lt;h3 id=&#34;storage-enginefileixwrite_q&#34;&gt;storage-engine.file[ix].write_q&lt;/h3&gt;
&lt;p&gt;位置：Namespace&lt;br&gt;
版本：4.3&lt;br&gt;
说明：根据存储配置，按照设备或按文件测算。如果 &lt;code&gt;storage-engine.device[ix].write_q&lt;/code&gt; 或 &lt;code&gt;storage-engine.file[ix].write_q&lt;/code&gt; 大于 1， 然后提醒操作人员调查原因。&lt;/p&gt;
&lt;h3 id=&#34;batch_index_error&#34;&gt;batch_index_error&lt;/h3&gt;
&lt;p&gt;位置：Statistics&lt;br&gt;
版本：3.9&lt;br&gt;
说明：将 &lt;code&gt;batch_index_error&lt;/code&gt; 与 &lt;code&gt;batch_index_complete&lt;/code&gt; 进行比较，如果比率高于可接受的，应该警报操作员以进行调查。&lt;/p&gt;
&lt;h3 id=&#34;heap_efficiency_pct&#34;&gt;heap_efficiency_pct&lt;/h3&gt;
&lt;p&gt;位置：Statistics&lt;br&gt;
版本：3.10.1&lt;br&gt;
说明：如果 &lt;code&gt;heap_efficiency_pct&lt;/code&gt; 低于 60% 或 50%（取决于配置，然后建议您的运营小组进行调查。）&lt;/p&gt;
&lt;h3 id=&#34;rw_in_progress&#34;&gt;rw_in_progress&lt;/h3&gt;
&lt;p&gt;位置：Statistics&lt;br&gt;
版本：3.9&lt;br&gt;
说明：取决于预期的工作量。&lt;br&gt;
如果 &lt;code&gt;rw_in_progress&lt;/code&gt; 高于预期，或者如果随着时间的推移偏离预期值，超出可接受范围， 应该提醒操作人员调查原因。可能表示特定节点速度变慢或 fabric 过载。&lt;/p&gt;
&lt;h3 id=&#34;abandoned&#34;&gt;abandoned&lt;/h3&gt;
&lt;p&gt;位置：XDR - DC&lt;br&gt;
版本：5.0&lt;br&gt;
说明：如果 &lt;a href=&#34;https://docs.aerospike.com/reference/metrics#abandoned&#34;&gt;abandoned&lt;/a&gt; 一直高于预期，应该提醒操作人员进行调查。&lt;/p&gt;
&lt;h3 id=&#34;lap_us&#34;&gt;lap_us&lt;/h3&gt;
&lt;p&gt;位置：XDR - DC&lt;br&gt;
版本：5.0&lt;br&gt;
说明：如果 &lt;a href=&#34;https://docs.aerospike.com/reference/metrics#lap_us&#34;&gt;lap_us&lt;/a&gt; 一直高于预期，应该提醒操作人员进行调查。&lt;/p&gt;
&lt;h3 id=&#34;latency_ms&#34;&gt;latency_ms&lt;/h3&gt;
&lt;p&gt;位置：XDR - DC&lt;br&gt;
版本：5.0&lt;br&gt;
说明：根据配置，&lt;code&gt;latency_ms&lt;/code&gt; 应该在 DC 之间链路的延迟范围内。如果 &lt;code&gt;delay_ms&lt;/code&gt; 在集群之间的延迟（或已知的链路延迟）增加超过预期， 应该警报操作员进行调查。&lt;/p&gt;
&lt;h3 id=&#34;recoveries&#34;&gt;recoveries&lt;/h3&gt;
&lt;p&gt;位置：XDR - DC&lt;br&gt;
版本：5.0&lt;br&gt;
说明：如果 &lt;a href=&#34;https://docs.aerospike.com/reference/metrics#recoveries&#34;&gt;recoveries&lt;/a&gt; 持续增加 ，应该警报操作人员进行调查。&lt;/p&gt;
&lt;h3 id=&#34;recoveries_pending&#34;&gt;recoveries_pending&lt;/h3&gt;
&lt;p&gt;位置：XDR - DC&lt;br&gt;
版本：5.0&lt;br&gt;
说明：如果 &lt;a href=&#34;https://docs.aerospike.com/reference/metrics#recoveries_pending&#34;&gt;recovery_pending&lt;/a&gt; 增加超出预期 ，应该警报操作人员进行调查。&lt;/p&gt;
&lt;h3 id=&#34;retry_conn_reset&#34;&gt;retry_conn_reset&lt;/h3&gt;
&lt;p&gt;位置：XDR - DC&lt;br&gt;
版本：5.0&lt;br&gt;
说明：如果 &lt;a href=&#34;https://docs.aerospike.com/reference/metrics#retry_conn_reset&#34;&gt;retry_conn_reset&lt;/a&gt; 增加超出预期 ，应该警报操作人员进行调查。&lt;/p&gt;
&lt;h3 id=&#34;retry_dest&#34;&gt;retry_dest&lt;/h3&gt;
&lt;p&gt;位置：XDR - DC&lt;br&gt;
版本：5.0&lt;br&gt;
说明：如果 &lt;a href=&#34;https://docs.aerospike.com/reference/metrics#retry_dest&#34;&gt;retry_dest&lt;/a&gt; 增加超出预期 ，应该警报操作人员进行调查。&lt;/p&gt;
&lt;h3 id=&#34;retry_no_node&#34;&gt;retry_no_node&lt;/h3&gt;
&lt;p&gt;位置：XDR - DC&lt;br&gt;
版本：5.1&lt;br&gt;
说明：如果 &lt;a href=&#34;https://docs.aerospike.com/reference/metrics#retry_no_node&#34;&gt;retry_no_node&lt;/a&gt; 增加超出预期 ，应该警报操作人员进行调查。&lt;/p&gt;
&lt;h3 id=&#34;success&#34;&gt;success&lt;/h3&gt;
&lt;p&gt;位置：XDR - DC&lt;br&gt;
版本：5.0&lt;br&gt;
说明：如果 &lt;a href=&#34;https://docs.aerospike.com/reference/metrics#retry_no_node&#34;&gt;success&lt;/a&gt; 低于预期 ，应该警报操作人员进行调查。&lt;/p&gt;
">Aerospike 官方建议监控指标</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://wenbozhangw.github.io/post/aerospike-jiao-chong-yao-jian-kong-zhi-biao-hui-zong/"" data-c="
          &lt;p&gt;监控对于一个组件和系统来说是必不可少的，通常情况下，一个全面健康监控可以帮助我们在出现生产事故之前即时发现问题，并处理掉，下面汇总一些个人对 Aerospike 使用中关注的监控指标。&lt;/p&gt;
&lt;!-- more --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#client_delete_error&#34;&gt;client_delete_error&lt;/a&gt; ：客户端 delete transaction 错误失败的个数。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#client_delete_timeout&#34;&gt;client_delete_timeout&lt;/a&gt; ：客户端 delete transaction 超时个数。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#client_read_error&#34;&gt;client_read_error&lt;/a&gt; ：客户端 read transaction 错误个数。例如：无效 set 名称，不可用(SC模式)， predexp filter 失败，key 不存在，设备错误（I/O 错误），key busy（SC 重复解析），bitwise期间问题，HLL OR CDT。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#client_read_timeout&#34;&gt;client_read_timeout&lt;/a&gt; ：客户端 read transaction 超时个数。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#client_tsvc_error&#34;&gt;client_tsvc_error&lt;/a&gt; ：在尝试处理 transaction 之前，transaction service 中失败的客户端 transaction 个数。例如 协议错误 或 权限校验错误。在 &#39;strong-consistency&#39; 开启的命名空间，这包含 &#39;unavailable_partitions&#39; 和 &#39;dead_partitions&#39;。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#client_tsvc_timeout&#34;&gt;client_tsvc_timeout&lt;/a&gt; ：在尝试处理 transaction 之前，在 transaction service 中超时的客户端 transaction 个数。在这个阶段，transaction 还没有被识别为 read/write，但是 namespace 是已知的。4.7 之前的八本可能原因是 transaction 队列中阻塞（transaction 线程处理效率不够高）；4.7 及更高的版本中，可能没有足够的 service thread 来跟上工作负载。属于此类别的其他常见情况是在 rw-hash 中等待后必须重试的 transaction（例如热键）以及客户端设置的超时过于激进的用例。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#client_udf_error&#34;&gt;client_udf_error&lt;/a&gt; ：客户端发起的失败的 udf  transaction 数。不包括超时。有关错误的更多信息，请参阅服务器日志文件。请注意，错误也会返回给客户端。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#client_udf_timeout&#34;&gt;client_udf_timeout&lt;/a&gt; ：客户端发起的超时的 udf transaction 数。超时错误返回给客户端。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#client_write_error&#34;&gt;client_write_error&lt;/a&gt; ：客户端 write transaction 错误失败数量。将包括常见错误，如 fail_generation、fail_key_busy、fail_record_too_big、fail_xdr_forbidden 以及其他一些不太常见的错误。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#client_write_timeout&#34;&gt;client_write_timeout&lt;/a&gt; ：服务器上超时的客户端 write transaction 数。在没有正在进行迁移的稳定集群上，此指标将指示副本写入超时的数量。超时错误将返回给客户端。在启用强一致性的命名空间中，记录被标记为未复制并将重新复制。以下情况可能会导致此指标增加：每个写副本失败（master失败）最终都会增加 client_write_timeout 指标。如果为写入启用重复解析（默认），则在迁移期间，如果重复解析期间出现超时，并且可能在我们在 master 端应用写入之前发生超时，则 client_write_timeout 指标也会增加。有关服务器何时检查超时的详细信息，请参阅 transaction-max-ms 配置参数。transaction也可以在transaction flow中提前超时，在这种情况下，client_tsvc_timeout 统计数据会增加。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#clock_skew_stop_writes&#34;&gt;clock_skew_stop_writes&lt;/a&gt; ：namespace 将在客户端停止写入时为 true。对于启用了强一致性的命名空间，如果时钟偏差超出容限（通常为 20 秒），则为 true。对于运行 4.5.1 或更高版本并启用 nsup（即 nsup-period 不为零）的可用模式 (AP) 命名空间，如果集群时钟偏差超过 40 秒，则为真。在这种情况下，nsup 也不会运行，禁用记录过期和驱逐，直到时钟偏差回落到可容忍的范围内。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#device_available_pct&#34;&gt;device_available_pct&lt;/a&gt; ：测量命名空间中所有设备的最小连续磁盘空间。从 3.9 版开始替换 available_pct。如果此值低于 min-avail-pct，命名空间将是只读的（停止写入）。命名空间中所有配置的设备具有相同的大小很重要，否则，即使在其他设备之间有大量可用空间时，device_available_pct 也可能很低。不要与 device_free_pct 混淆，它表示命名空间中所有设备的可用空间量，并且不考虑碎片。下面是一个示例来表示 device_free_pct 和 device_available_pct 之间的区别。让我们假设给定命名空间有 5 个 100MB 的设备，其中每个设备有 25MB 的数据，分布在 50 个写入块中（假设写入块大小为 1MB）：device_free_pct 将是 75%。device_available_pct 将为 50%。如果分布不均匀（通常不是完全均匀），则 device_available_pct 将代表具有最少空闲块的设备。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#device_free_pct&#34;&gt;device_free_pct&lt;/a&gt; ：此命名空间的可用磁盘容量百分比。这是命名空间中所有设备的可用存储量。当所有设备的使用百分比（由 100 - device_free_pct 表示）超过配置的 high-water-disk-pct 时，将触发驱逐。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#effective_replication_factor&#34;&gt;effective_replication_factor&lt;/a&gt; ：命名空间的有效复制因子。配置的命名空间复制因子作为命名空间配置的一部分在服务器版本 3.15.1.3 及更高版本的 replication-factor 和早期版本的 repl-factor 下返回。如果集群大小小于设置的复制因子（在这种情况下，有效复制因子将与集群大小匹配）或达到 paxos-single-replica-limit 大小，则有效复制因子小于设置的复制因子（在这种情况下，有效复制因子为 1)。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#evict_ttl&#34;&gt;evict_ttl&lt;/a&gt; ：当前驱逐深度，或已驱逐记录的最高 ttl，以秒为单位。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#evict_void_time&#34;&gt;evict_void_time&lt;/a&gt; ：当前驱逐深度，表示为自 2010 年 1 月 1 日 UTC 以来的无效时间（以秒为单位）。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#evicted_objects&#34;&gt;evicted_objects&lt;/a&gt; ：自服务器启动以来，从该节点上的该命名空间逐出的对象数。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#expired_objects&#34;&gt;expired_objects&lt;/a&gt; ：自服务器启动以来，此节点上此命名空间中过期的对象数。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#fail_record_too_big&#34;&gt;fail_record_too_big&lt;/a&gt; ：由于记录太大而导致 write transaction失败的次数超过了写入块大小或最大记录大小。只计算主端的客户端写入失败。从 3.9 版开始替换 err_write_fail_record_too_big。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#hwm_breached&#34;&gt;hwm_breached&lt;/a&gt; ：如果为 true，则 Aerospike 已违反此命名空间的“high-water-[disk|memory]-pct”。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#memory_free_pct&#34;&gt;memory_free_pct&lt;/a&gt; ：此命名空间的可用内存容量百分比。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#memory_used_bytes&#34;&gt;memory_used_bytes&lt;/a&gt; ：此命名空间在此节点上使用的内存总字节数。这是针对 high-water-memory-pct 和 stop-writes-pct 阈值使用的指标。它代表以下值的总和： &lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html?show-removed=1#memory_used_data_bytes&#34;&gt;memory_used_data_bytes&lt;/a&gt; 、[memory_used_index_bytes] (https://docs.aerospike.com/docs/reference/metrics/index.html?show-removed=1#memory_used_index_bytes)、&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html?show-removed=1#memory_used_set_index_bytes&#34;&gt;memory_used_set_index_bytes&lt;/a&gt;(version 5.6+)、&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html?show-removed=1#memory_used_sindex_bytes&#34;&gt;memory_used_sindex_bytes&lt;/a&gt;。节点上分配的内存总量（企业版中的 primary index 共享内存除外）请参考 heap_allocated_kbytes。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#memory_used_data_bytes&#34;&gt;memory_used_data_bytes&lt;/a&gt; ：数据占用的内存量。有关命名空间占用的总内存，请参阅 memory_used_bytes。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#memory_used_index_bytes&#34;&gt;memory_used_index_bytes&lt;/a&gt; ：此命名空间的索引占用的内存量。默认情况下，这将在企业版的共享内存中分配\n（索引类型 shmem）。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#memory_used_set_index_bytes&#34;&gt;memory_used_set_index_bytes&lt;/a&gt; ：此节点上此命名空间的集合索引占用的内存量。该命名空间占用的总内存请参阅memory_used_bytes。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#non_expirable_objects&#34;&gt;non_expirable_objects&lt;/a&gt; ：此命名空间中具有不可过期 TTL（值 0 的 TTL）的记录数。从 3.9 版开始由 non_expirable_objects 替换。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#objects&#34;&gt;objects&lt;/a&gt; ：此节点在此命名空间中的记录数。不包括tombstones。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#stop_writes&#34;&gt;stop_writes&lt;/a&gt; ：如果为 true，则此命名空间当前不允许写入。将返回错误代码 22。请注意，仍然允许迁移写入以及配置文件写入。只有客户端发起的写入将被拒绝。如果违反以下任一条件，就会发生这种情况：min-avail-pct、stop-writes-pct 或 xdr-min-digestlog-free-pct。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;storage-engine.device[ix].defrag_q&lt;/code&gt; ：排队等待在设备 [ix] 上进行碎片整理的 wblock 的数量。 &#39;ix&#39; 是设备索引。例如，storage-engine.device[0]=/dev/xvd1 和 storage-engine.device[1]=/dev/xvc1 用于配置中指定的 2 个设备。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;storage-engine.device[ix].used_bytes&lt;/code&gt; ：用于设备 [ix] 上数据的字节数。 &#39;ix&#39; 是设备索引。例如，storage-engine.device[0]=/dev/xvd1 和 storage-engine.device[1]=/dev/xvc1 用于配置中指定的 2 个设备。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;storage-engine.file[ix].defrag_q&lt;/code&gt; ：排队等待在文件 [ix] 上进行碎片整理的 wblock 的数量。 &#39;ix&#39; 是文件索引。例如，storage-engine.file[0]=/opt/aerospike/test0.dat 和 storage-engine.file[1]=/opt/aerospike/test2.dat 用于配置中指定的 2 个文件。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;storage-engine.file[ix].used_bytes&lt;/code&gt; ：用于文件 [ix] 上数据的字节数。 &#39;ix&#39; 是文件索引。例如，storage-engine.file[0]=/opt/aerospike/test0.dat 和 storage-engine.file[1]=/opt/aerospike/test2.dat 用于配置中指定的 2 个文件。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#client_connections&#34;&gt;client_connections&lt;/a&gt; ：与此节点的活动客户端连接数。也可在 fds proto 代码行的日志中找到。&amp;lt;5.6&amp;gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#client_connections_opened&#34;&gt;client_connections_opened&lt;/a&gt; ：自节点启动以来创建到该节点的客户端连接数。应密切监视或警告 client_connections_opened 或 client_connections_closed 之一。也可在 fds proto 代码行的日志中找到。&amp;lt;5.6&amp;gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#cluster_clock_skew_ms&#34;&gt;cluster_clock_skew_ms&lt;/a&gt; ：集群中节点之间的当前最大时钟偏差（以毫秒为单位）。违反 cluster_clock_skew_stop_writes_sec 阈值时将触发clock_skew_stop_writes。对于任何 Aerospike 版本上的强一致性命名空间，此阈值通常为 20 秒，对于启用 nsup（即 nsup-period 不为零）且 Aerospike 版本为 4.5.1 或更高版本的 AP 命名空间，此阈值通常为 40 秒。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#cluster_integrity&#34;&gt;cluster_integrity&lt;/a&gt; ：如果为 false，则表示集群内部存在完整性问题，这意味着某些节点出现故障或死亡。如果该节点处于活动状态并且报告为孤立节点或属于某个其他集群的一部分，则该节点被视为有故障。故障节点的另一个条件是它处于活动状态，但具有与集群其余部分不匹配的集群协议标识符。当为 true 时，表示集群处于一个整体和完整的状态（就它看到的并且能够连接到所有相关的节点而言）。有关集群完整性故障的信息也会重复记录到服务器日志文件中。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#cluster_is_member&#34;&gt;cluster_is_member&lt;/a&gt; ：为false时，表示该节点未加入集群；也就是说，它是一个孤儿。如果为 true，则表示该节点已加入集群。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#fabric_connections&#34;&gt;fabric_connections&lt;/a&gt; ：与此节点的活动结构连接数。也可在 fds proto 代码行的日志中找到。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#fabric_connections_opened&#34;&gt;fabric_connections_opened&lt;/a&gt; ：自节点启动以来创建到该节点的结构连接数。也可在 fds proto 代码行的日志中找到。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#heap_efficiency_pct&#34;&gt;heap_efficiency_pct&lt;/a&gt; ：提供 jemalloc 堆碎片的指示。这表示 heap_allocated_kbytes / heap_mapped_kbytes 比率。较低的数字表示较高的碎片率。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#heartbeat_connections&#34;&gt;heartbeat_connections&lt;/a&gt; ：与此节点的活动心跳连接数。也可在 fds proto 代码行的日志中找到。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#heartbeat_connections_opened&#34;&gt;heartbeat_connections_opened&lt;/a&gt; ：自节点启动以来创建到该节点的心跳连接数。也可在 fds proto 代码行的日志中找到。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#process_cpu_pct&#34;&gt;process_cpu_pct&lt;/a&gt; ：asd 进程的 CPU 使用率百分比。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#query_long_running&#34;&gt;query_long_running&lt;/a&gt; ：在系统中尝试过的长时间运行的查询数（查询所选记录超过 query_threshold）。&lt;/li&gt;
&lt;/ul&gt;
">Aerospike较重要监控指标汇总</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://wenbozhangw.github.io/post/jdk8-zhi-stream-yu-han-shu-shi-bian-cheng/"" data-c="
          &lt;p&gt;Java 8 引入了 Stream 流式处理与 lambda 表达式，本文从 API 层面介绍相关使用。&lt;/p&gt;
&lt;!-- more --&gt;
&lt;h2 id=&#34;区别总览&#34;&gt;区别总览&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;名称&lt;/th&gt;
&lt;th&gt;参数&lt;/th&gt;
&lt;th&gt;返回值&lt;/th&gt;
&lt;th&gt;实例&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Consumer&lt;/td&gt;
&lt;td&gt;有&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;td&gt;Iterable上的forEach方法&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Function&lt;/td&gt;
&lt;td&gt;有&lt;/td&gt;
&lt;td&gt;有&lt;/td&gt;
&lt;td&gt;Optional的map方法&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Predicate&lt;/td&gt;
&lt;td&gt;有&lt;/td&gt;
&lt;td&gt;有(bool)&lt;/td&gt;
&lt;td&gt;Optional的filter方法&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Supplier&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;td&gt;有&lt;/td&gt;
&lt;td&gt;懒加载、惰性求值、Stream和generator(静态)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;详细解释&#34;&gt;详细解释&lt;/h2&gt;
&lt;h3 id=&#34;supplier&#34;&gt;Supplier&lt;/h3&gt;
&lt;p&gt;在开发中，我们经常会遇到一些需要延迟计算的情形，比如某些运算非常消耗资源，如果提前算出来却没有用到，会得不偿失。在计算机科学中，有个专门的术语形容：惰性求值。惰性求值是一种求值策略，也就是把求值延迟到真正需要的时候。在Java里，我们有一个专门的设计模式几乎就是为了处理这种情形而生的：Proxy。不过，现在我们有了新的选择：Supplier。&lt;br&gt;
简而言之，我们可以通过这个对象把耗资源运算放到get方法里，在程序里，我们传递的是Supplier对象，直到调用get方法时，运算才会执行，这就是所谓的惰性求值。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;static void randomZero(Integer[] coins, Supplier&amp;lt;Integer&amp;gt; randomSupplier){
  coins[randomSupplier.get()] = 0;
}
Integer[] coins = {10, 10, 10, 10, 10, 10, 10, 10, 10, 10};
randomZero(coins, () -&amp;gt; (int) (Math.random() * 10));
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;但是，通常实现Proxy模式，我们只会计算一次，反复计算是没有必要的。Guava给我们提供了一个函数：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Supplier&amp;lt;Object&amp;gt; memoize = Suppliers.memoize(new Supplier&amp;lt;Object&amp;gt;() {
  @Override
  public Object get() {
    return null;
  }
});
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;memoize()函数帮我们打点了前面所说的一些事情：第一次get()的时候，它会调用真正Supplier，得到结果并保存下来，下次再访问就返回这个保存下来的值。&lt;br&gt;
有时候，这个值只咋一段时间内是有效的，Guava还给我们提供了另外一个函数，让我们可以设定过期时间；&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;expirableUltimateAnswerSupplier = memoizeWithExpiration(target, 100, NANOSECONDS);
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;consumer&#34;&gt;Consumer&lt;/h3&gt;
&lt;p&gt;Consumer是一个函数式编程接口；Consumer意味着消费，即针对某个东西进行使用，因此它包含有一个输入而无输出的accept接口方法；&lt;br&gt;
除accept方法，它还包含有andThen这个方法&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;default Consumer&amp;lt;T&amp;gt; andThen(Consumer&amp;lt;? super T&amp;gt; after) {
    Objects.requireNonNull(after);
    return (T t) -&amp;gt; { accept(t); after.accept(t); };
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可见这个方法就是指定在调用当前Consumer后是否还要调用其他的Consumer&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public static void consumerTest() {
    Consumer f = System.out::println;
    Consumer f2 = n -&amp;gt; System.out.println(n + &amp;quot;-F2&amp;quot;);

    //执行完F后再执行F2的Accept方法
    f.andThen(f2).accept(&amp;quot;test&amp;quot;);

    //连续执行F的Accept方法
    f.andThen(f).andThen(f).andThen(f).accept(&amp;quot;test1&amp;quot;);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;function&#34;&gt;Function&lt;/h3&gt;
&lt;p&gt;Function也是一个函数式编程接口；它代表的含义是“函数”，而函数经常是有输入和输出的，因此它含有一个apply方法，包含一个输入与输出；&lt;br&gt;
除apply方法外，它还有compose与andThen及indentity方法。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * Function测试
 */
public static void functionTest() {
    Function&amp;lt;Integer, Integer&amp;gt; f = s -&amp;gt; s++;
    Function&amp;lt;Integer, Integer&amp;gt; g = s -&amp;gt; s * 2;

    /**
     * 下面表示在执行F时，先执行G，并且执行F时使用G的输出当作输入。
     * 相当于以下代码：
     * Integer a = g.apply(1);
     * System.out.println(f.apply(a));
     */
    System.out.println(f.compose(g).apply(1));

    /**
     * 表示执行F的Apply后使用其返回的值当作输入再执行G的Apply；
     * 相当于以下代码
     * Integer a = f.apply(1);
     * System.out.println(g.apply(a));
     */
    System.out.println(f.andThen(g).apply(1));

    /**
     * identity方法会返回一个不进行任何处理的Function，即输出与输入值相等； 
     */
    System.out.println(Function.identity().apply(&amp;quot;a&amp;quot;));
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;predicate&#34;&gt;Predicate&lt;/h3&gt;
&lt;p&gt;Predicate为函数式接口，predicate的中文意思是“断定”，即判断的意思，判断某个东西是否满足某种条件；因此它包含test方法，根据输入值来做逻辑判断，其结果为True或者False。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * Predicate测试
 */
private static void predicateTest() {
    Predicate&amp;lt;String&amp;gt; p = o -&amp;gt; o.equals(&amp;quot;test&amp;quot;);
    Predicate&amp;lt;String&amp;gt; g = o -&amp;gt; o.startsWith(&amp;quot;t&amp;quot;);

    /**
     * negate: 用于对原来的Predicate做取反处理；
     * 如当调用p.test(&amp;quot;test&amp;quot;)为True时，调用p.negate().test(&amp;quot;test&amp;quot;)就会是False；
     */
    Assert.assertFalse(p.negate().test(&amp;quot;test&amp;quot;));

    /**
     * and: 针对同一输入值，多个Predicate均返回True时返回True，否则返回False；
     */
    Assert.assertTrue(p.and(g).test(&amp;quot;test&amp;quot;));

    /**
     * or: 针对同一输入值，多个Predicate只要有一个返回True则返回True，否则返回False
     */
    Assert.assertTrue(p.or(g).test(&amp;quot;ta&amp;quot;));
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;函数式编程接口的使用&#34;&gt;函数式编程接口的使用&lt;/h2&gt;
&lt;p&gt;通过Stream以及Optional两个类，可以进一步利用函数式接口来简化代码。&lt;/p&gt;
&lt;h3 id=&#34;java8的三个编程概念&#34;&gt;Java8的三个编程概念&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;流处理
&lt;ul&gt;
&lt;li&gt;从输入流中一个一个读取数据项，然后以同样的方式将数据项写入输出流&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;用行为参数化把代码传递给方法
&lt;ul&gt;
&lt;li&gt;即函数作为第一公民，可以作为值传递&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;并行与共享可变数据&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;stream&#34;&gt;Stream&lt;/h3&gt;
&lt;p&gt;Stream可以对多个元素进行一系列操作，也可以支持对某些操作进行并发处理。&lt;br&gt;
Stream API和Collection API的行为差不多，但Collection API主要为了访问和存储数据，而Stream API主要用于描述对数据的计算。&lt;br&gt;
经典的Java程序只能利用单核进行计算，流提供了多核处理数据的能力。但前提是传递给Stream API的方法不会互动（即有可变的共享对象）时，才能多核工作。&lt;/p&gt;
&lt;h3 id=&#34;lambda&#34;&gt;Lambda&lt;/h3&gt;
&lt;p&gt;Lambda表达式由参数列表、箭头和主体组成。&lt;/p&gt;
&lt;h3 id=&#34;函数式接口&#34;&gt;函数式接口&lt;/h3&gt;
&lt;p&gt;Java8新引入了函数式编程方式，大大提高了编码效率。首先要清楚一个概念：函数式接口；&lt;br&gt;
它指的是有且只有一个未实现的方法的接口，一般通过FunctionalInterface这个注解来表名某个接口是一个函数式接口。函数式接口是Java支持函数式编程的基础。&lt;br&gt;
注：哪怕有再多默认方法，只要接口中之定义了一个抽象方法，它仍然是函数式接口。&lt;br&gt;
Lambda允许你直接以内联的形式为函数式接口的抽象方法提供实现，并把其作为函数式接口的实例。&lt;/p&gt;
&lt;h4 id=&#34;functionalinterface注解&#34;&gt;FunctionalInterface注解&lt;/h4&gt;
&lt;p&gt;@FunctionalInterface用于表示该接口为函数式接口。如果它不是函数式接口的话，编译器将返回一个提示原因的错误。&lt;br&gt;
@FunctionalInterface不是必须的，但最好为函数式接口都标注@FunctionalInterface.&lt;/p&gt;
&lt;h4 id=&#34;函数描述符&#34;&gt;函数描述符&lt;/h4&gt;
&lt;p&gt;函数式接口的抽象方法的基本签名 本质上就是Lambda表达式的签名。Java8将这种抽象方法叫做函数描述符。&lt;br&gt;
Runnable接口的run方法即不接受任何参数也不返回，其函数描述符为：() -&amp;gt; void。该函数描述符代表了函数类别为空且返回void函数。&lt;br&gt;
Scala、Kotlin等语言在其类型系统中提供显示的类型注释来描述函数的类型（即函数类型）&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;函数接口&lt;/th&gt;
&lt;th&gt;函数描述符&lt;/th&gt;
&lt;th&gt;基本类型特化&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Predicate&lt;T&gt;&lt;/td&gt;
&lt;td&gt;T -&amp;gt; boolean&lt;/td&gt;
&lt;td&gt;IntPredicate, &lt;br /&gt;LongPredicate,&lt;br /&gt;DoublePredicate&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Consumer&lt;T&gt;&lt;/td&gt;
&lt;td&gt;T -&amp;gt; void&lt;/td&gt;
&lt;td&gt;IntConsumer,&lt;br /&gt;LongConsumer,&lt;br /&gt;DoubleConsumer&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Function&amp;lt;T , R&amp;gt;&lt;/td&gt;
&lt;td&gt;T -&amp;gt; R&lt;/td&gt;
&lt;td&gt;IntFunction,IntToDoubleFunction,&lt;br /&gt;IntToLongFunction,&lt;br /&gt;... , ToIntFunction,ToDoubleFunction&lt;br /&gt;ToLongFunction&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Supplier&lt;T&gt;&lt;/td&gt;
&lt;td&gt;() -&amp;gt; T&lt;/td&gt;
&lt;td&gt;BooleanSupplier,IntSupplier,&lt;br /&gt;LongSupplier,DoubleSupplier&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;方法引用&#34;&gt;方法引用&lt;/h3&gt;
&lt;p&gt;方法引用可以把现有方法像Lambda一样传递。&lt;br&gt;
方法引用主要分三类：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;- 指向静态方法的方法引用。（例如Integer的parseInt方法,写作Integer::parseInt）
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;指向任意类型实例方法的方法引用。（例如String 的length，写作String::length）
&lt;ul&gt;
&lt;li&gt;适用于对象作为Lambda表达式的一个参数&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;指向现存对象或表达式实例方法的方法引用
&lt;ul&gt;
&lt;li&gt;适用于调用现存外部对象的方法
&lt;ul&gt;
&lt;li&gt;适用于内部的私有方法&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;注：构造函数、数组构造函数以及父类调用的方法引用形式比较特殊：&lt;br&gt;
利用类名和关键字new来生成构造方法的方法引用。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;对于默认构造函数，可以使用Supplier签名。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Supplier&amp;lt;Apple&amp;gt; c1 = Apple::new;
//等价于
Supplier&amp;lt;Apple&amp;gt; c1 = () -&amp;gt; new Apple();
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;对于存在参数的构造方法，可根据参数情况寻找适合的函数式接口的签名。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Function&amp;lt;Integer, Apple&amp;gt; c2 = Apple::new;
//等价于
Function&amp;lt;Integer, Apple&amp;gt; c2 = (weight) -&amp;gt; new Apple(weight); 
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;36-流&#34;&gt;3.6 流&lt;/h3&gt;
&lt;p&gt;从支持数据处理操作的源生成的元素序列——流&lt;br&gt;
流允许以声明性方式处理数据集合。还可以透明地并行处理，无需写任何多线程代码。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;流只遍历一次。遍历完之后，流就被消费了，需要重新从原始数据源那里再次获取一个新的流进行遍历。&lt;/li&gt;
&lt;li&gt;只有触发终端操作，中间操作才会被执行。&lt;/li&gt;
&lt;li&gt;中间操作一般都可以合并起来，在终端操作中一次性全部处理掉。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;筛选&#34;&gt;筛选&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;filter方法：接收一个谓词（一个返回boolean的函数）作为参数，并返回一个包括所有符合谓词的元素的流。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;//输出结果：[1, 3, 0]
List&amp;lt;Integer&amp;gt; numbers = Arrays.asList(1,3,8,6,0,7,5,6);
number.stream()
	.filter(i -&amp;gt; i &amp;lt; 4)
  .collect(Collectors.toList());
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dsitinct方法：依据流所生产元素的hashCode和equals方法，返回一个元素各异的流。（即返回一个没有重复元素的流）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;//输出结果[2, 4]
List&amp;lt;Integer&amp;gt; numbers = Arrays.asList(1,2,1,3,3,2,4);
number.stream()
	.filter(i -&amp;gt; i % 2 == 0)
  .distinct()
  .collect(Collectors.toList());
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;流的切片&#34;&gt;流的切片&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;takeWhile方法：在第一个不符合要求的元素时停止处理。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;//输出结果[1, 2, 3, 4]
List&amp;lt;Integer&amp;gt; numbers = Arrays.asList(1,2,3,3,4,4,5,6);
number.stream()
	.takeWhile(i -&amp;gt; i &amp;lt; 4)
  .collect(Collectors.toList());
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dropWhile方法：在一个符合要求的元素时停止处理，并返回所有剩余的元素。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;//输出结果：[4, 4, 5, 6]
//在初始列表中的数据已排序（由高到低）的情况下：
List&amp;lt;Integer&amp;gt; numbers = Arrays.asList(1,2,3,3,4,4,5,6);
number.stream()
  //当发现第一个i &amp;lt; 4 为 true的元素时，则停止处理，并返回所有剩余的元素
	.dropWhile(i -&amp;gt; i &amp;lt; 4)
  .collect(Collectors.toList());
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;limit方法：返回一个不超过给定长度的流。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果流是有序的（如：源是List），则按顺序返回前n个元素。&lt;/li&gt;
&lt;li&gt;如果流是无序的（如：源是set），则不会以任意顺序排序。&lt;/li&gt;
&lt;li&gt;对于无限流，可以使用limit将其变成有限流。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;//输出结果[1, 3]
List&amp;lt;Integer&amp;gt; numbers = Arrays.asList(1,3,8,6,0,7,5,6);
numbers.stream()
  .filter(i -&amp;gt; i &amp;lt; 4)
  //只返回前两个值
  .limit(2)
  .collect(Collectors.toList());
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;shkip方法：返回一个扔掉前n个元素的流。
&lt;ul&gt;
&lt;li&gt;如果流中元素不足 n 个，则返回一个空流。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;//输出结果[0]
List&amp;lt;Integer&amp;gt; numbers = Arrays.asList(1,3,8,6,0,7,5,6);
numbers.stream()
  .filter(i -&amp;gt; i &amp;lt; 4)
  //跳过前两个值
  .skip(2)
  .collect(Collectors.toList());
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;映射&#34;&gt;映射&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;map方法：将流中的每一个元素映射成一个新的元素。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;//输出结果：[6, 2, 4, 1]
List&amp;lt;String&amp;gt; languages = Arrays.asList(&amp;quot;Kotlin&amp;quot;, &amp;quot;Go&amp;quot;, &amp;quot;Java&amp;quot;, &amp;quot;C&amp;quot;);
List&amp;lt;Integer&amp;gt; collect = languages.stream()
  //将String转为int
  .map(String::length)
  .collect(Collectors.toList());
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;flatMap方法：把一个流中的每一个值转换成另一个流，然后把所有流连接起来成一个流。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;简单说就是：把流中的元素（如：列表，数组）化为新的流，或把流中的元素结合外部的列表（数组）化为新的流，再把新的流的元素整合到一个流中。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;//输出结果：[K, o, t, l, i, n, G, J, a, v, C]
List&amp;lt;String&amp;gt; languages = Arrays.asList(&amp;quot;Kotlin&amp;quot;, &amp;quot;Go&amp;quot;, &amp;quot;Ja
List&amp;lt;String&amp;gt; collect = languages.stream()                  
        .map(str -&amp;gt; str.split(&amp;quot;&amp;quot;))                         
        //Arrays::stream 将 str.split(&amp;quot;&amp;quot;)返回的字符数组转化为流，再由flat
        //flatMap本质也是对流的元素进行转换（map也是对流的元素进行转换）。将流的元素转换成新的流
        //等价于：flatMap(strArray -&amp;gt; Arrays.stream(strArray))
        .flatMap(Arrays::stream)                           
        .distinct()                                       
        .collect(Collectors.toList());                    
collect.stream().forEach(s -&amp;gt; System.out.print(s + &amp;quot;, &amp;quot;));
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;练习：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;List&amp;lt;Integer&amp;gt; numbers1 = Arrays.asList(1, 2, 3);
List&amp;lt;Integer&amp;gt; numbers2 = Arrays.asList(3, 4);
List&amp;lt;int[]&amp;gt; pairs = numbers1.stream()
  .flatMap(i -&amp;gt;
           numbers2.stream().map(j -&amp;gt; new int[]{i, j})
          ).collect(Collectors.toList());
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;查找与匹配&#34;&gt;查找与匹配&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;anyMatch方法：检查流中是否至少有一个元素匹配给定的谓词。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;//输出结果:true
List&amp;lt;Integer&amp;gt; numbers = Arrays.asList(1,2,3,5,6,8);
numbers.stream().anyMatch(i -&amp;gt; i &amp;gt; 3);
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;allMatch方法：检查流中全部元素都匹配给定的谓词。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;//输出结果:true
List&amp;lt;Integer&amp;gt; numbers = Arrays.asList(1,2,3,5,6,8);
numbers.stream().anyMatch(i -&amp;gt; i &amp;lt; 10);
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;noneMatch方法：检查流中全部元素都不匹配给定的谓词。（与allMatch相对）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;//输出结果:true
List&amp;lt;Integer&amp;gt; numbers = Arrays.asList(1,2,3,5,6,8);
numbers.stream().anyMatch(i -&amp;gt; i &amp;gt; 10);
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;findAny方法：返回当前流中的任意元素。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;//张三 17
List&amp;lt;User&amp;gt; users = Arrays.asList(
                new User(&amp;quot;张三&amp;quot;, 17),
                new User(&amp;quot;张三&amp;quot;, 18),
                new User(&amp;quot;王五&amp;quot;, 19));
        Optional&amp;lt;User&amp;gt; u = users.stream()
                .filter(user -&amp;gt; user.getName().equals(&amp;quot;张三&amp;quot;))
                .findAny();
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;findFirst方法：返回当前流中的第一个元素。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;List&amp;lt;User&amp;gt; users = Arrays.asList(
                new User(&amp;quot;张三&amp;quot;, 17),
                new User(&amp;quot;张三&amp;quot;, 18),
                new User(&amp;quot;王五&amp;quot;, 19));
        Optional&amp;lt;User&amp;gt; u = users.stream()
                .filter(user -&amp;gt; user.getName().equals(&amp;quot;张三&amp;quot;))
                .findFirst();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;注：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;anyMatch、allMatch和noneMatch都属于终端操作。&lt;/li&gt;
&lt;li&gt;anyMatch、allMatch、noneMatch、findFirst和findAny不用处理整个，只要找到一个元素，就可以得到结果。&lt;/li&gt;
&lt;li&gt;findAny和findFirst同时存在的原因是并行。findAny在并行流中限制较少。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;归约&#34;&gt;归约&lt;/h4&gt;
&lt;p&gt;将流中所有元素反复结合起来，从而得到一个值的查询，可以被归类为归约操作。（用函数式编程语言的术语来说，这成为折叠）。&lt;br&gt;
reduce方法：接收Lambda将列表中的所有元素进行处理并归约成一个新值。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;有初始值：&lt;/p&gt;
&lt;p&gt;接收一个初始值和一个BinaryOperator&lt;T&gt;将两个元素结合起来产生一个新值。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;T reduce(T identity, BinaryOperator&amp;lt;T&amp;gt; accumulator);
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;
&lt;p&gt;无初始值&lt;/p&gt;
&lt;p&gt;一个BinaryOperator&lt;T&gt; 将两个元素结合起来产生一个新值。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Optional&amp;lt;T&amp;gt; reduce(BinaryOperator&amp;lt;T&amp;gt; accumulator);
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;求和&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;List&amp;lt;Integer&amp;gt; numbers = Arrays.asList(1, 2, 3);
        Integer reduce = numbers.stream()
                //等价于reduce(0, (a,b) -&amp;gt; a + b)
                .reduce(0, Integer::sum);
        Optional&amp;lt;Integer&amp;gt; reduce1 = numbers.stream().reduce(Integer::sum);
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;最大值&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Optional&amp;lt;Integer&amp;gt; maxOptional = numbers.stream().reduce(Integer::max);
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;最小值&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Optional&amp;lt;Integer&amp;gt; maxOptional = numbers.stream().reduce(Integer::min);
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;数值流&#34;&gt;数值流&lt;/h4&gt;
&lt;p&gt;原先的归约求和代码中，Integer::sum暗含装箱和拆箱的成本。Stream API提供了原始类型流特化，专门支持处理数值流的方法。Java8引入原始类型特化接口解决数值流拆箱与装箱的问题：IntStream、DoubleStream和LongStream,分别将流中的元素特化为int、long和double。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;映射到数值流&lt;/p&gt;
&lt;p&gt;mapToInt、mapToDouble和mapToLong用于将流转换为特化流：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;List&amp;lt;Integer&amp;gt; numbers = Arrays.asList(1,2,3,4,5);
int sum = numbers.stream().mapToInt(Integer::intValue).sum();
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;转换回对象流&lt;/p&gt;
&lt;p&gt;当需要把原始流转换成对象流时（如：把int装箱回Integer），可以使用boxed。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;List&amp;lt;Integer&amp;gt; numbers = Arrays.asList(1,2,3,4,5);
IntStream intStream = numbers.stream().mapToInt(Integer::intValue);
Stream&amp;lt;Integer&amp;gt; stream = intStream.boxed();
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;默认值OptionalInt&lt;/p&gt;
&lt;p&gt;Optional也相应的提供原始类型特化版本：OptionalInt、OptionalLong和OptionalDouble。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;List&amp;lt;Integer&amp;gt; numbers = Arrays.asList(1,2,3,4,5);
OptionalInt maxNumber = numbers.stream().mapToInt(Integer::intValue).max();
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;数值范围&#34;&gt;数值范围&lt;/h4&gt;
&lt;p&gt;IntStream和LongStream提供产生生成数值范围的静态方法：range和rangeClosed。&lt;br&gt;
range方法生成半闭区间（左闭右开），rangeClosed方法生成闭区间。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;IntStream.range(1,100)
	.filter(n -&amp;gt; n % 2 == 0)
	.count();
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;构建流&#34;&gt;构建流&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;由值创建流&lt;/p&gt;
&lt;p&gt;静态方法Stream.of接收任意数量的参数，显示创建一个流。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Stream s = Stream.of(&amp;quot;test&amp;quot;);
Stream s1 = Stream.of(&amp;quot;a&amp;quot;,&amp;quot;b&amp;quot;,&amp;quot;c&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;静态方法Stream.empty创建一个空流。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Stream stream = Stream.empty();
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;由数组或集合创建流&lt;/p&gt;
&lt;p&gt;静态方法Arrays.stream将数组创建为一个流。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;//asList只能用于包装类型，基本类型会变为List&amp;lt;int[]&amp;gt;对象
List&amp;lt;String&amp;gt; list = Arrays.asList(arr);
//获取串行stream对象
Stream listStream = list.stream();
Arrays.stream(arr);
//获取串行stream对象
Stream parallelListStream = list.parallelStream();
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;由文件生成流&lt;/p&gt;
&lt;p&gt;java.nio.file.Files中很多静态方法会返回一个流，以便利用Stream API处理文件等I/O操作。&lt;br&gt;
如：Files.lines返回一个由指定文件中的各行构成的字符串流：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;long uniqueWords = 0;
//流会自动关闭，不需要额外try-finally操作
try {
  Stream&amp;lt;String&amp;gt; lines = Files.lines(Paths.get(&amp;quot;data.txt&amp;quot;), Charset.defaultCharset());
  uniqueWords = lines.flatMap(line -&amp;gt; Arrays.stream(line.split(&amp;quot; &amp;quot;)))
    .distinct()
    .count();
} catch (IOException e) {
  e.printStackTrace();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;由函数生成流：创建无限流&lt;/p&gt;
&lt;p&gt;Stream API提供了两个静态方法用来从函数生成流：Stream.iterate()和Stream.generate()，不同于从集合创建的流，这两个静态方法创建的流没有固定的大小，成为无限流。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;//since java1.8
public static &amp;lt;T&amp;gt; Stream&amp;lt;T&amp;gt; iterate(final T seed, final UnaryOperator&amp;lt;T&amp;gt; f);
static&amp;lt;T&amp;gt; Stream&amp;lt;T&amp;gt; generate(Supplier&amp;lt;? extends T&amp;gt; s);
//since java1.9
public static &amp;lt;T&amp;gt; Stream&amp;lt;T&amp;gt; iterate(T seed, Predicate&amp;lt;? super T&amp;gt; hasNext, UnaryOperator&amp;lt;T&amp;gt; next);
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;迭代&#34;&gt;迭代：&lt;/h5&gt;
&lt;p&gt;itreate 方法接收一个初始值（种子）作为流的一个元素。再接收一个Lambda一次应用在每一个产生的新值上。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Stream.iterate(0, n -&amp;gt; n + 2)
    .limit(10)
    .forEach(System.out::println);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;java9对iterate方法进行增加，接受多一个谓词作为判断迭代调用何时终止。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;IntStream.iterate(0, n -&amp;gt; n &amp;lt; 100, n -&amp;gt; n + 2)
    .forEach(System.out::println);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;也可以使用takeWhile对流执行短路操作（takeWhile函数Java9开始支持）:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;IntStream.iterate(0, n -&amp;gt; n + 2)
    .takeWhile(n -&amp;gt; n &amp;lt; 100)
    .forEach(System.out::println);
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;生成&#34;&gt;生成&lt;/h5&gt;
&lt;p&gt;generate 接受一个Supplier&lt;T&gt; 类型的Lambda提供新值。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Stream.generate(Math::random)
  .limit(5)
  .forEach(System.out::println);
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;用流收集数据&#34;&gt;用流收集数据&lt;/h3&gt;
&lt;p&gt;流支持两种类型的操作：中间操作 和 末端操作。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;中间操作可以相互链接起来，将一个流转换为另一个流。中间操作不会消耗流，目的是建立一个流水线。&lt;/li&gt;
&lt;li&gt;末端操作会消耗流，以产生一个最终结果。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;归约和汇总&#34;&gt;归约和汇总&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Collectors工厂类提供了很多归约的静态工厂方法。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Collectors.counting()用于统计总和。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;long count = menu.stream().collect(collections.countiong());
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Collectors.maxBy 和 Collectors.minBy用来计算流中的最大值和最小值。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;//张三 17
        List&amp;lt;User&amp;gt; users = Arrays.asList(
                new User(&amp;quot;张三&amp;quot;, 17),
                new User(&amp;quot;张三&amp;quot;, 18),
                new User(&amp;quot;王五&amp;quot;, 19));
        Optional&amp;lt;User&amp;gt; collect = users.stream().collect(
                Collectors.maxBy(
                        Comparator.comparingInt(User::getAge)
                )
        );
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;同时Collectors类专门汇总提供了一些工厂方法类。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Collectors.summingInt、Collectors.summingLong和Collectors.summingDouble分别用于对int、long、double进行求和。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Integer collect1 = users.stream().collect(Collectors.summingInt(User::getAge));
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Collectors.averagingInt、Collectors.averagingLong和Collectors.averagingDouble分别用于对int、long和double进行求平均值。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Double collect2 = users.stream().collect(Collectors.averagingInt(User::getAge));
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Collectors.joining工厂方法会对流中每一个对象应用toString方法得到所有字符串连接成一个字符串。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;String nameStr = users.stream().map(User::getName).collect(Collectors.joining());
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;分组&#34;&gt;分组&lt;/h4&gt;
&lt;p&gt;Collections的groupingBy()方法会把流中的元素分成不同的组。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1642493678915.png&#34; alt=&#34;用流收集数据-分组&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;操作分组的元素&#34;&gt;操作分组的元素&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;过滤&lt;/p&gt;
&lt;p&gt;如果在groupingBy()之前，使用filter()对流进行过滤操作，可能会造成键的丢失。&lt;br&gt;
例如：&lt;br&gt;
存在以下Map:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{ FISH = [prawns, salmon], OTHER = [french fries, rice], MEAT = [pork, beef, chicken]}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果在使用filter()后，再groupingBy()可能对某些键在结果映射中完全消失：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{ OTHER = [french fries, rice], MEAT = [pork, beef, chicken]}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;为此，Collectors类提供了filtering()静态工厂方法，它接受一个谓词对每一个分组中的元素执行过滤操作。最后不符合谓词条件的键将得到空的列表：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{FISH = [], OTHER = [french fries, rice], MEAT = [pork, beef, chicken]}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Map&amp;lt;Dish.Type, List&amp;lt;Dish&amp;gt;&amp;gt; caloricDishesByType = menu.stream().collect( groupingBy(Dish::getType), filtering(dish -&amp;gt; dish.getCalories() &amp;gt; 500, toList()) )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;注：&lt;/p&gt;
&lt;p&gt;使用重载的groupingBy()方法和filtering()方法：先分组再过滤；&lt;/p&gt;
&lt;p&gt;先使用filter()，再使用groupingBy()方法：先过滤再分组。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;映射&lt;/p&gt;
&lt;p&gt;Collectors提供mapping静态工厂方法，接受一个映射函数和另外一个Collectors函数作为参数。映射函数将分组中的元素进行转换，作为参数的Collectors函数会收集对每个元素执行该映射函数的结果。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;List&amp;lt;User&amp;gt; users = Arrays.asList(
                new User(&amp;quot;张三&amp;quot;, 17),
                new User(&amp;quot;张三&amp;quot;, 18),
                new User(&amp;quot;王五&amp;quot;, 19));
        Map&amp;lt;String, List&amp;lt;String&amp;gt;&amp;gt; collect = users.stream().collect(groupingBy(User::getName, mapping(User::getName, toList())));
        collect.forEach((k , v) -&amp;gt; {
            System.out.println(&amp;quot;k = &amp;quot; + k);
            v.forEach(System.out::println);
        });
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Collectors工具类也提供了flatMapping，跟flatMap类似的功能。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;多级分组&#34;&gt;多级分组&lt;/h4&gt;
&lt;p&gt;同时Collectors工具类也提供了可以嵌套分组的groupingBy，用于进行多级分组&lt;br&gt;
注：&lt;br&gt;
可以理解为在进行完第一次分组后，再对每一组元素进行再次分组。&lt;br&gt;
groupingBy(f)（f是分类函数）实际上是groupingBy(f, toList())的简便写法。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;List&amp;lt;User&amp;gt; users = Arrays.asList(
                new User(&amp;quot;张三&amp;quot;, 17),
                new User(&amp;quot;张三&amp;quot;, 18),
                new User(&amp;quot;王五&amp;quot;, 19));
        Map&amp;lt;String, Map&amp;lt;String, List&amp;lt;User&amp;gt;&amp;gt;&amp;gt; collect = users.stream().collect(
                groupingBy(
                        User::getName,
                        groupingBy(us -&amp;gt; {
                                    if (us.getAge() &amp;gt;= 18) {
                                        return &amp;quot;大于等于18&amp;quot;;
                                    } else if (us.getAge() &amp;lt; 18) {
                                        return &amp;quot;小于18&amp;quot;;
                                    } else {
                                        return &amp;quot;未知&amp;quot;;
                                    }
                                }
                        )
                )
        );

        collect.forEach((k , v) -&amp;gt; {
            System.out.println(&amp;quot;k = &amp;quot; + k);
            v.forEach((k1 , v1) -&amp;gt; {
                System.out.println(k1);
                v1.forEach(user -&amp;gt; System.out.println(user.getName()));
            });
        });
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;按子组收集数据&#34;&gt;按子组收集数据&lt;/h4&gt;
&lt;p&gt;groupingBy()的第二个收集器可以是任何类型。例如可以使用counting()收集器作为它的第二个参数，统计分组的数量：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;List&amp;lt;User&amp;gt; users = Arrays.asList(
                new User(&amp;quot;张三&amp;quot;, 17),
                new User(&amp;quot;张三&amp;quot;, 18),
                new User(&amp;quot;王五&amp;quot;, 19));
        Map&amp;lt;String, Long&amp;gt; collect = users.stream().collect(
                groupingBy(User::getName, counting())
        );

        collect.forEach((k , v) -&amp;gt; {
            System.out.println(&amp;quot;k = &amp;quot; + k);
            System.out.println(&amp;quot;v = &amp;quot; + v);
        });
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;得到{ &amp;quot;张三&amp;quot; = 2， &amp;quot;王五&amp;quot; = 1 }&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;List&amp;lt;User&amp;gt; users = Arrays.asList(
                new User(&amp;quot;张三&amp;quot;, 17),
                new User(&amp;quot;张三&amp;quot;, 17),
                new User(&amp;quot;王五&amp;quot;, 19));
        Map&amp;lt;Integer, User&amp;gt; collect = users.stream().collect(
                groupingBy(
                        User::getAge,
                        collectingAndThen(
                                //maxby返回的是Optional类型对象
                                maxBy(Comparator.comparingInt(User::getAge)),
                                //当找到最大值后，会执行get操作
                                Optional::get
                        )
                )
        );
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果users中没有某个年龄，该类型不会对应一个Optional.empty()值，而且根本不会在Map的键中。所以转换函数Optional::get的操作是安全的。&lt;/p&gt;
&lt;h4 id=&#34;分区&#34;&gt;分区&lt;/h4&gt;
&lt;p&gt;Collectors工具类提供partitionedMenu()静态工厂函数来实现分区，分区是分组的特殊情况。由谓词作为分类函数，这意味着得到的分组Map的键类型是Boolean，最多分为true和false两组。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Map&amp;lt;Boolean, List&amp;lt;User&amp;gt;&amp;gt; collect = users.stream().collect(
                partitioningBy(
                        u -&amp;gt; u.getAge() &amp;gt; 18
                ));
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;同时，partitionedMenu()也和groupingBy()类似，可以进行二级分区。&lt;/p&gt;
&lt;h4 id=&#34;收集器接口&#34;&gt;收集器接口&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public interface Collector&amp;lt;T, A, R&amp;gt;{
	//创建一个空的累加器
	Supplier&amp;lt;A&amp;gt; supplier();
	//将元素添加到结果容器
	BiConsumer&amp;lt;A, T&amp;gt; accumulator();
	//合并两个结果（定义了对流的各个子部分进行并行处理时，各个子部分归约所得的累加器如何并行）
	BinaryOperator&amp;lt;A&amp;gt; combiner();
	//对结果容器应用最终转换
	Function&amp;lt;A, R&amp;gt; finisher();
	//定义收集器的行为
	Set&amp;lt;Characteristics&amp;gt; characteristics;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;泛型的定义如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;T表示流中要收集的项目的泛型。&lt;/li&gt;
&lt;li&gt;A表示累加器的类型。（累加器是收集过程中用于累积部分结果的对象）&lt;/li&gt;
&lt;li&gt;R表示收集操作得到的对象的类型。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;以tolistcollector为例&#34;&gt;以ToListCollector为例&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class ToListCollector&amp;lt;T&amp;gt; implements Collector&amp;lt;T, List&amp;lt;T&amp;gt;, List&amp;lt;T&amp;gt;&amp;gt; {
	public ToListCollector(){}
  
  //创建ArrayList对象作为累加器
  public Supplier&amp;lt;List&amp;lt;T&amp;gt;&amp;gt; supplier(){
    return ArrayList::new;
  }
  
  //利用add函数将流中的元素添加到列表中
  public BiConsumer&amp;lt;List&amp;lt;T&amp;gt;, T&amp;gt; accumulator(){
    return List::add;
  }
  
  //两个累加器（即两个ArrayList对象）进行相加
  public BinaryOperator&amp;lt;List&amp;lt;T&amp;gt;&amp;gt; combiner(){
    return (list, list2) -&amp;gt; {
      list.addAll(list2);
      return list;
    };
  }
  
  //累加器进行最终的转换
  public Function&amp;lt;List&amp;lt;T&amp;gt;, List&amp;lt;T&amp;gt;&amp;gt; finisher(){
    //Function.identity()表示给什么返回什么，也就是不进行转换
    return Function.identity();
  }
  
  //定义收集器的行为
  public Set&amp;lt;Characteristics&amp;gt; characteristics(){
    return Collections.unmodifiableSet(EnumSet.of(Characteristics.IDENTITY_FINISH, Characteristics.CONCURRENT));
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Characteristics的三个枚举：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;UNORDERED——归约结果不受流中项目的遍历和累积顺序的影响。&lt;/li&gt;
&lt;li&gt;CONCURRENT——accumulator函数可以从多个线程同时调用，且该收集器可以并行归纳流。（仅仅只是数据源无序时才会并行处理）&lt;/li&gt;
&lt;li&gt;IDENTITY_FINISH——表明完成器方法返回的函数是一个恒等函数，可以跳过。累加器对象会直接用作归约过程的最终结果。这也意味着，将累加器A不加检查的转换为结果R是安全的。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;进行自定义收集而不去实现collector&#34;&gt;进行自定义收集，而不去实现Collector&lt;/h4&gt;
&lt;p&gt;对于IDENTITY_FINISH的收集操作，Stream重载的collect方法接收三个函数——supplier、accumulator和combiner。该collect方法创建的收集器的Characteristics永远是Characteristics.IDENTITY_FINISH和Characteristics.CONCURRENT。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;ArrayList&amp;lt;Object&amp;gt; collect = users.stream().collect(
  //创建累加容器
  ArrayList::new,
  //将流元素添加到累加容器中
  List::add,
  //合并累加容器
  List::addAll
);
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;并行数据处理与性能&#34;&gt;并行数据处理与性能&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;对顺序流调用parallel()方法并不意味着流本身有任何实际的变化，它仅仅在内部设置了一个boolean标志，表示你想让调用parallel()之后的所有操作都并行执行。对并行流调用sequential方法就可以把它变成顺序流。&lt;/li&gt;
&lt;li&gt;并行流默认的线程数量等于你处理器的核数。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;使用并行流时，考虑以下因素：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;留意自动装箱和拆箱。（应尽量将其转为原始类型流）&lt;/li&gt;
&lt;li&gt;对于较小数据量，无需使用并行流。&lt;/li&gt;
&lt;li&gt;考虑流背后的数据结构是否容易分解。&lt;/li&gt;
&lt;li&gt;部分操作本身在并行流上的性能比顺序流差。如limit和findFirst&lt;/li&gt;
&lt;li&gt;考虑合并步骤的代价是大是小。&lt;/li&gt;
&lt;li&gt;考虑操作流水线的总操作成本。当单个元素通过流水线的成本较高时，使用并行流比较好。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;流的数据源和可分解性：&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;源&lt;/th&gt;
&lt;th&gt;可分解性&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;ArrayList&lt;/td&gt;
&lt;td&gt;差&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;LinkedList&lt;/td&gt;
&lt;td&gt;差&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;IntStream.range&lt;/td&gt;
&lt;td&gt;极佳&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Stream.iterate&lt;/td&gt;
&lt;td&gt;差&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;HashSet&lt;/td&gt;
&lt;td&gt;好&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;TreeSet&lt;/td&gt;
&lt;td&gt;好&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;collection-api的增强功能&#34;&gt;Collection API的增强功能&lt;/h3&gt;
&lt;p&gt;Arrays.asList()创建一个固定大小的列表，列表的元素可以更新，但不可以增加或删除。&lt;br&gt;
Java9引入以下工厂方法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;List.of——创建一个只读列表，不可set、add等操作。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Set.of——创建一个只读的Set集合。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Map.of——接受的列表中，以键值交替的方式创建map的元素。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;当创建Map的键值对过多时，可以使用map.ofEntries()和Map.entry()来创建map。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Map.ofEntries(
  entry(&amp;quot;zhangsan&amp;quot;, 10),
  entry(&amp;quot;lisi&amp;quot;, 12),
);
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;重载与变参&#34;&gt;重载与变参&lt;/h4&gt;
&lt;p&gt;在 Java API中，List.of包含多个重载版本：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;static &amp;lt;E&amp;gt; List&amp;lt;E&amp;gt; of(E e1);
static &amp;lt;E&amp;gt; List&amp;lt;E&amp;gt; of(E e1, E e2);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;而不提供变参版本是因为需要额外的分配一个数组，这个数组被封装与列表中。使用变参版本的方法，就要负担分配数组、初始化以及最后进行垃圾回收的开销。（如果元素数量超过10个，实际调用的还是变参方法。）&lt;/p&gt;
&lt;h4 id=&#34;使用list-set和map&#34;&gt;使用List、Set和Map&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;removeIf——移除集合中匹配制定谓词的元素。（该方法由Collection接口提供默认方法，List和Set都可用）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;default boolean removeIf(Predicate&amp;lt;? super E&amp;gt; filter)
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;当使用for-each遍历列表，进行移除操作时，会导致ConcurrentModificationException。因为遍历使用的迭代器对象和集合对象的状态同步。我们只能显示调用迭代器对象（Iterator对象）的remove方法。因此Java8提供removeIf方法， 安全简便的删除符合谓词的元素。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;replaceAll()——使用一个函数替换List或Map中的元素。（该方法由List接口提供默认方法）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;default void replaceAll(UnaryOperator&amp;lt;E&amp;gt; operator)
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;该函数只是在列表内部进行同类型的转换，并没有创建新的列表。也就是说初始为List&lt;String&gt;，函数执行完还是List&lt;String&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;default void replaceAll(BiFunction&amp;lt; ? super K, ? super V, ? extends V&amp;gt; function)
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;sort()——对列表自身进行排序。（该方法由List接口提供默认方法）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;default void sort(Comparator&amp;lt;? super E&amp;gt; c)
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;forEach——List和Set，甚至是Map在Java8中都支持forEach方法。而遍历提供的便捷，特别是Map的遍历。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;default void forEach(Consumer&amp;lt;? super T&amp;gt; action)
default void forEach(BiConsumer&amp;lt;? super K, ? super V&amp;gt; action)
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Entry.comparingByValue()和Entry.comparingByKey()——对Map的值或键进行排序。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Map.compute——使用指定的键计算新的值，并将其存储到Map中，并返回新值。（指定一个key，再提供一个BiFunction，依据key和旧值，计算新值。如果新值为null，则不会加入到Map中并将旧值移除。）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;default V compute(K key, BiFunction&amp;lt;? super K, ? super V, ? extends V&amp;gt; remappingFunction)
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Map.computeIfAbsent——如果指定的键没有对应的值（没有该键或该键对应的值是空），使用该键计算新的值，并添加到Map中（如果新值为null，则不会加入到Map中并将旧值移除。），并返回新值。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;default V computeIfAbsent(K key, Function&amp;lt;? super K, ? extends V&amp;gt; mappingFunction)
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;该方法对值需要初始化时有用。比如Map&amp;lt;K, List&lt;V&gt;&amp;gt;添加一个元素（初始化对应的ArrayList，并返回该值）:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;map.computeIfAbsent(&amp;quot;daqi&amp;quot;, name -&amp;gt; new ArrayList&amp;lt;String&amp;gt;().add(&amp;quot;Java8&amp;quot;));
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Map.cumputeIfPresent——如果指定的键在Map中存在，依据该键的旧值计算该键的新值，并将其添加到Map中。(如果新值为null，则不会加入到Map中，并将旧值移除。)&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;default V computeIfPresent(K key, BiFunction&amp;lt;?  super K, ? super V, ? extends V&amp;gt; remappingFunction)
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Map.remove——重载版本的remove可以删除Map中某个键对应某个特定值的映射对。（即key和value都匹配上，才从Map中移除）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;default boolean remvoe(Object key, Object value) 
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Map.merge——如果指定的键在Map中存在，依据该键和旧值计算该键的新值，并将其添加到Map中；如果指定的键在Map中不存在，依据指定的value作为key的值，并将其添加到Map中。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;default V merge(K key, V value, BiFunction&amp;lt;? super V, ? super V, ? extends V&amp;gt; remappingFunction)
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;该函数可用于Map 的合并，或用于将Collector转换成Map。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Map&amp;lt;String, Integer&amp;gt; languages = new HashMap();
languages.put(&amp;quot;Java&amp;quot;, 8);
languages.put(&amp;quot;kotlin&amp;quot;, 1);
HashMap&amp;lt;String, Integer&amp;gt; languages2 = new HashMap();
languages2.put(&amp;quot;Java&amp;quot;, 11);
languages2.put(&amp;quot;Go&amp;quot;, 1);

languages.forEach((k , v) -&amp;gt; {
  if (v != null) {
    languages2.merge(k, v, Integer::sum);
  }
});
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;List&amp;lt;User&amp;gt; users = Arrays.asList(
                new User(&amp;quot;张三&amp;quot;, 17),
                new User(&amp;quot;张三&amp;quot;, 17),
                new User(&amp;quot;王五&amp;quot;, 19));
        Map&amp;lt;String, Integer&amp;gt; collect = users.stream().collect(toMap(User::getName, User::getAge, Integer::sum));
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;重构&#34;&gt;重构&lt;/h3&gt;
&lt;h4 id=&#34;改善代码可读性&#34;&gt;改善代码可读性&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;用lambda表达式取代匿名类&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;匿名类和lambda表达式中的this和super的含义不同。在匿名类中，this代表的是类自身；在lambda表达式中，this代表的是包含类。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;匿名类可屏蔽包含类的变量，而lambda表达式不能（编译报错）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;int a = 10;
//lambda 表达式
Runnable r1 = () -&amp;gt; {
  //报错，提示：改变了已在作用域中被定义
  int a = 1;
};

//匿名类
Runnbale r2 = new Runnable(){
  @Override
  public void run(){
    //编译正常
    int a = 2;
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;匿名内部类的类型是在初始化时确定的，lambda的类型取决于它的上下文。当出现两个或以上方法参数的函数描述符与lambda的函数描述符匹配时，需要显式的类型转换来解决。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;interface daqiRunnable{
	public void action();
}
//无论Runnbale还是daqiRunnable，其函数描述符为() -&amp;gt; void
public static void doSomething(Runnable r){}
public static void doSomething(daqiRunnable r){}

public static void main(String[] args){
  //显示类型转换
  doSomething((daqiRunnable) () -&amp;gt; {} );
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;用方法引用重构lambda表达式，提高代码的可读性。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;将较复杂的Lambda逻辑封装在方法中，使用方法引用代替该Lambda。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;尽量使用静态辅助方法。比如：comparing和maxBy&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;list.sort((a1, a2) -&amp;gt; a1.getWeight().compareTo(a2.getWeight()));
//替换成
list.sort(Comparator.comparing(Apple::getWeight));
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;很多通用的归约操作，都可以借助Collectors的辅助方法 + 方法引用代替。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;list.stream().map(Dish::getCalories)
				.reduce(0, (c1,c2) -&amp;gt; c1 + c2);
//替换成
list.stream()
		.collect(summingInt(Dish::getCalories));
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;用Stream API重构命令式的数据处理&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
">JDK8 之 Stream 与 函数式编程</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://wenbozhangw.github.io/post/aerospike-ji-ben-gai-nian/"" data-c="
          &lt;p&gt;本文介绍一下 aerospike 的基本概念以及相关数据类型。&lt;/p&gt;
&lt;!-- more --&gt;
&lt;h2 id=&#34;什么是-aerospike-as&#34;&gt;什么是 Aerospike （AS）&lt;/h2&gt;
&lt;p&gt;Aerospike是一个分布式，可扩展，高可用的K-V类型的Nosql数据库。提供类似传统数据库的ACID操作。&lt;/p&gt;
&lt;p&gt;采用混合架构，索引存储在RAM中，而数据存储在闪存/固态硬盘（SSD）上，自动感知集群，可以随意增加节点线性扩容，无需分片，无需人工干预（性能与节点成正比上升），支持多语言集成；与redis相比不会遇到性能瓶颈，客户端SQL介入对RDBMS支持友好。&lt;/p&gt;
&lt;h2 id=&#34;为什么要用-as&#34;&gt;为什么要用 AS&lt;/h2&gt;
&lt;p&gt;K-V类型的数据库必须要提的就是redis，redis数据完全存储在内存，虽然保证了查询的性能，但是成本太高。AS最大的卖点就是可以存储在SSD上，并且保证和redis相同的查询性能。AS内部在访问SSD屏蔽了文件系统层级，直接访问地址，保证了数据的读取速度。AS同时支持二级索引与聚合，支持简单的sql操作，相比于其他nosql数据库，有一定优势。&lt;/p&gt;
&lt;h2 id=&#34;基本概念&#34;&gt;基本概念&lt;/h2&gt;
&lt;h3 id=&#34;namespaces&#34;&gt;Namespaces&lt;/h3&gt;
&lt;p&gt;AS数据存储的最高层级，类比于传统数据库的库层级，一个namespace包含记录（records），索引（indexes）及策略（policies）。其中策略决定namespace的行为，包括：&lt;br&gt;
​		1.数据的存储位置是内存还是SSD。&lt;br&gt;
​		2.一条记录存储的副本个数。&lt;br&gt;
​		3.过期时间（TTL）：不同于redis的针对key设置TTL，AS可以在库的层级进行全局设置，并且支持对于已存在的数据进行TTL的设置，方便了使用。&lt;/p&gt;
&lt;h3 id=&#34;set&#34;&gt;Set&lt;/h3&gt;
&lt;p&gt;存储namespace，是一个逻辑分区，类比于传统数据库的表。set的存储策略继承自namespace，也可以为set设置单独的存储策略。&lt;/p&gt;
&lt;h3 id=&#34;records&#34;&gt;Records&lt;/h3&gt;
&lt;p&gt;类比于传统数据库的行，包含key，Bins（value）和Metadata（元数据）。key全局唯一，作为K-V数据库一般也是通过key去查询。Bins相当于列，存储具体的数据。元数据存储一些基本信息，例如TTL等。&lt;/p&gt;
&lt;h3 id=&#34;key&#34;&gt;Key&lt;/h3&gt;
&lt;p&gt;提到key，有一个和key伴生的概念是摘要（Digests），当key被存入数据库，key与set信息一起被哈希化成一个160位的摘要。数据库中，摘要为所有操作定位记录。key主要用于应用程序访问，而摘要主要用于数据库内部查找记录。&lt;/p&gt;
&lt;h3 id=&#34;metadata&#34;&gt;Metadata&lt;/h3&gt;
&lt;p&gt;每一条记录包含以下几条元数据：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;generation（代）：表示记录被修改的次数。该数字在程序读数据时返回，用来确认正在写入的数据从最后一次读开始未被修改过。&lt;/li&gt;
&lt;li&gt;time-to-live（TTL）：AS会自动根据记录的TTL使其过期。每次在对象上执行写操作TTL就会增加。3.10.1版本以上，可以通过设置策略，使更新记录时不刷新TTL。&lt;/li&gt;
&lt;li&gt;last-update-time（LUT）：上次更新时间，这是一个数据库内部的元数据，不会返回给客户端。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;bins&#34;&gt;Bins&lt;/h3&gt;
&lt;p&gt;在一条记录里，数据被存储在一个或多个bins里，bins由名称和值组成。bins不需要指定数据类型，数据类型有bins中的值决定。动态的数据类型提供了很好的灵活性。AS中每条记录可以由不同的bins组成。记录无模式，你可以记录的任何生命周期或删除bins。&lt;br&gt;
​在一个库中bins的名称最多包含32K，这是由内部字符串优化所致。（相比于HBase支持几百万列还是有一定差距，如果想直接将HBase表迁移到AS可能需要重新设计存储结构）&lt;/p&gt;
&lt;h3 id=&#34;数据类型&#34;&gt;数据类型&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;integer&lt;/li&gt;
&lt;li&gt;string&lt;/li&gt;
&lt;li&gt;bytes&lt;/li&gt;
&lt;li&gt;double&lt;/li&gt;
&lt;li&gt;list&lt;/li&gt;
&lt;li&gt;map&lt;/li&gt;
&lt;li&gt;GeoJson&lt;/li&gt;
&lt;li&gt;Native-language serialized（blobs）&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Aerospike&lt;/th&gt;
&lt;th&gt;RDBMS&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;namespace&lt;/td&gt;
&lt;td&gt;类似于数据库，最多可设置32个。一个namespace可关联多块SSD，一块SSD只关联一个namespace，每个namespace下包含4096个分片&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;set&lt;/td&gt;
&lt;td&gt;类似于数据库表，一个namespace最多1023个set&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;bin&lt;/td&gt;
&lt;td&gt;类似于数据库字段，支持Java基本数据类型：List、Map、Blob，一个namespace下最多32767个bin&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;record&lt;/td&gt;
&lt;td&gt;类似数据库中的一条记录，采用Schema-Less的方式&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;​		每个namespace包含多个set，每个set包含多条record，每个record包含多个bin(数据库列)，可通过索引key来查询record。不同的业务可以使用同一个集群的不同namespace来作做资源隔离，从而实现资源池化、最大化利用资源的目的。&lt;br&gt;
​		Redis和Aerospike对比：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;redis&lt;/th&gt;
&lt;th&gt;Aerospike&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;运维&lt;/td&gt;
&lt;td&gt;运维成本较高，扩容麻烦&lt;/td&gt;
&lt;td&gt;部署和扩容都比较容易&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;性能&lt;/td&gt;
&lt;td&gt;读写性能高&lt;/td&gt;
&lt;td&gt;读性能高，写性能中高&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;使用成本&lt;/td&gt;
&lt;td&gt;纯内存数据库，成本高&lt;/td&gt;
&lt;td&gt;内存+ssd，成本较低&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;其他方面&lt;/td&gt;
&lt;td&gt;内存浪费严重。数据结构丰富，应用场景广泛&lt;/td&gt;
&lt;td&gt;支持二级索引，满足场景需求，支持聚合&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;排序&lt;/td&gt;
&lt;td&gt;支持排序&lt;/td&gt;
&lt;td&gt;不支持排序&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;集群管理&lt;/td&gt;
&lt;td&gt;简单集群管理&lt;/td&gt;
&lt;td&gt;相当强大，多个平等的节点，平摊存储所有数据，&lt;br /&gt;并且相互备份。集群节点的失效及添&lt;br /&gt;加完全自动化处理，不影响用户请求。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;事务&lt;/td&gt;
&lt;td&gt;支持简单事务&lt;/td&gt;
&lt;td&gt;支持行事务&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Aerospike优点：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Aerospike是一个高性能、可扩展、可靠性强的NoSQL解决方案，支持RAM和SSD作为存储介质，并专门针对SSD特殊优化，广泛应用于实时竞价等实时计算领域。官方保证99%的操作在1ms内完成，并提供集群数据自动Rebalance、集群感知客户端等功能，且支持超大规模数据集(100T级别)的存储。&lt;/p&gt;
&lt;p&gt;作为KV存储，Aerospike提供多种数据类型，其操作方式和Redis比较类似。除基础功能之外，Aerospike还支持AMC控制台、API等多种监控方式，有集群QPS、健康度、负载等多项监控指标，对运维比较友好。支持集群内数据的自动Rebalance，和Redis集群方案相比，维护成本下降不少。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Aerospike缺点：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;只支持batch read，不支持batch writes&lt;/li&gt;
&lt;li&gt;记录大小有限制: &amp;lt;= 1M =&amp;gt; 有点小，不过对于我们的场景基本没问题&lt;/li&gt;
&lt;li&gt;bin name长度: &amp;lt;= 14 Chars =&amp;gt; 一般来说单字段不会超过，嵌套属性如果拼接就很容易超长&lt;/li&gt;
&lt;li&gt;没有内建的聚合函数(Aggregations: count, max, min, sum, group by, etc.)，通过UDFs可以支持（queryAggregate），但是使用方式不友好，效率也不高&lt;/li&gt;
&lt;li&gt;namespace 下的sets限制1024，二级索引限制256，唯一binname限制32K，一个namespace下最多4 billion记录&lt;/li&gt;
&lt;li&gt;范围查询只支持BETWEEN语句，没有小于，大于查询，并且RANGE结果只支持包含&lt;/li&gt;
&lt;li&gt;范围查询只支持整数类型，不支持浮点数&lt;/li&gt;
&lt;li&gt;Query不支持分页(no cursor or pagination..)&lt;/li&gt;
&lt;li&gt;Query不支持排序(no order by..)&lt;/li&gt;
&lt;li&gt;不支持动态创建namespace，只能通过修改配置文件、重启服务器&lt;/li&gt;
&lt;li&gt;只有清空set数据接口，但是并没有真正drop掉sets（会留下empty set，然后一个namespace下只有有1024个sets..）&lt;/li&gt;
&lt;/ul&gt;
">Aerospike 基本概念</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://wenbozhangw.github.io/post/zi-fu-bian-ma/"" data-c="
          &lt;p&gt;ASCII（（American Standard Code for Information Interchange）：美国信息交换标准代码）是基于拉丁字母的一套电脑编码系统，主要用于现代英语和其他西欧语言。&lt;/p&gt;
&lt;!-- more --&gt;
&lt;h2 id=&#34;ascii编码&#34;&gt;ASCII编码&lt;/h2&gt;
&lt;p&gt;ASCII（（American Standard Code for Information Interchange）：美国信息交换标准代码）是基于拉丁字母的一套电脑编码系统，主要用于现代英语和其他西欧语言。它是最通用的信息交换标准，并等同于国际标准 ISO/IEC 646。ASCII 第一次以规范标准的类型发表是在1967年，最后一次更新则是在1986年，到目前为止共定义了128个字符。&lt;/p&gt;
&lt;h3 id=&#34;产生原因&#34;&gt;产生原因&lt;/h3&gt;
&lt;p&gt;在计算机中，所有的数据在&lt;a href=&#34;https://baike.baidu.com/item/%E5%AD%98%E5%82%A8&#34;&gt;存储&lt;/a&gt;和运算时都要使用&lt;a href=&#34;https://baike.baidu.com/item/%E4%BA%8C%E8%BF%9B%E5%88%B6/361457&#34;&gt;二进制&lt;/a&gt;数表示（因为计算机用&lt;a href=&#34;https://baike.baidu.com/item/%E9%AB%98%E7%94%B5%E5%B9%B3/9753092&#34;&gt;高电平&lt;/a&gt;和&lt;a href=&#34;https://baike.baidu.com/item/%E4%BD%8E%E7%94%B5%E5%B9%B3/6946314&#34;&gt;低电平&lt;/a&gt;分别表示1和0），例如，像a、b、c、d这样的52个字母（包括大写）以及0、1等数字还有一些常用的符号（例如*、#、@等）在计算机中存储时也要使用&lt;a href=&#34;https://baike.baidu.com/item/%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%95%B0/108101&#34;&gt;二进制数&lt;/a&gt;来表示，而具体用哪些二进制数字表示哪个符号，当然每个人都可以约定自己的一套（这就叫&lt;a href=&#34;https://baike.baidu.com/item/%E7%BC%96%E7%A0%81&#34;&gt;编码&lt;/a&gt;），而大家如果要想互相通信而不造成混乱，那么大家就必须使用相同的编码规则，于是美国有关的标准化组织就出台了ASCII&lt;a href=&#34;https://baike.baidu.com/item/%E7%BC%96%E7%A0%81/80092&#34;&gt;编码&lt;/a&gt;，统一规定了上述常用符号用哪些二进制数来表示 [2] 。&lt;/p&gt;
&lt;p&gt;美国信息交换标准代码是由&lt;a href=&#34;https://baike.baidu.com/item/%E7%BE%8E%E5%9B%BD%E5%9B%BD%E5%AE%B6%E6%A0%87%E5%87%86%E5%AD%A6%E4%BC%9A/1351184&#34;&gt;美国国家标准学会&lt;/a&gt;(American National Standard Institute , ANSI )制定的，是一种标准的单字节字符&lt;a href=&#34;https://baike.baidu.com/item/%E7%BC%96%E7%A0%81&#34;&gt;编码&lt;/a&gt;方案，用于基于&lt;a href=&#34;https://baike.baidu.com/item/%E6%96%87%E6%9C%AC&#34;&gt;文本&lt;/a&gt;的数据。它最初是美国国家标准，供不同计算机在相互通信时用作共同遵守的西文&lt;a href=&#34;https://baike.baidu.com/item/%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81&#34;&gt;字符编码&lt;/a&gt;标准，后来它被&lt;a href=&#34;https://baike.baidu.com/item/%E5%9B%BD%E9%99%85%E6%A0%87%E5%87%86%E5%8C%96%E7%BB%84%E7%BB%87&#34;&gt;国际标准化组织&lt;/a&gt;（International Organization for Standardization, ISO）定为国际标准，称为ISO 646标准。适用于所有拉丁文字字母。&lt;/p&gt;
&lt;h3 id=&#34;表达方式&#34;&gt;表达方式&lt;/h3&gt;
&lt;p&gt;ASCII 码使用指定的7 位或8 位&lt;a href=&#34;https://baike.baidu.com/item/%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%95%B0&#34;&gt;二进制数&lt;/a&gt;组合来表示128 或256 种可能的&lt;a href=&#34;https://baike.baidu.com/item/%E5%AD%97%E7%AC%A6&#34;&gt;字符&lt;/a&gt;。标准ASCII 码也叫基础ASCII码，使用7 位&lt;a href=&#34;https://baike.baidu.com/item/%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%95%B0&#34;&gt;二进制数&lt;/a&gt;（剩下的1位二进制为0）来表示所有的大写和小写字母，数字0 到9、标点符号，以及在美式英语中使用的特殊&lt;a href=&#34;https://baike.baidu.com/item/%E6%8E%A7%E5%88%B6%E5%AD%97%E7%AC%A6&#34;&gt;控制字符&lt;/a&gt; [1] 。其中：&lt;/p&gt;
&lt;p&gt;**0～31及127(共33个)是&lt;a href=&#34;https://baike.baidu.com/item/%E6%8E%A7%E5%88%B6%E5%AD%97%E7%AC%A6&#34;&gt;控制字符&lt;/a&gt;或通信专用字符（其余为可显示字符），**如控制符：LF（换行）、CR（&lt;a href=&#34;https://baike.baidu.com/item/%E5%9B%9E%E8%BD%A6&#34;&gt;回车&lt;/a&gt;）、FF（换页）、DEL（&lt;a href=&#34;https://baike.baidu.com/item/%E5%88%A0%E9%99%A4/13020275&#34;&gt;删除&lt;/a&gt;）、BS（退格)、BEL（响铃）等；通信专用字符：SOH（文头）、EOT（文尾）、ACK（确认）等；ASCII值为8、9、10 和13 分别转换为&lt;a href=&#34;https://baike.baidu.com/item/%E9%80%80%E6%A0%BC&#34;&gt;退格&lt;/a&gt;、制表、换行和回车字符。它们并没有特定的图形显示，但会依不同的应用程序，而对&lt;a href=&#34;https://baike.baidu.com/item/%E6%96%87%E6%9C%AC&#34;&gt;文本&lt;/a&gt;显示有不同的影响 [1] 。&lt;/p&gt;
&lt;p&gt;32～126(共95个)是&lt;a href=&#34;https://baike.baidu.com/item/%E5%AD%97%E7%AC%A6&#34;&gt;字符&lt;/a&gt;(32是空格），其中48～57为0到9十个阿拉伯数字。&lt;/p&gt;
&lt;p&gt;65～90为26个大写英文字母，97～122号为26个小写英文字母，其余为一些标点符号、运算符号等。&lt;/p&gt;
&lt;p&gt;同时还要注意，在标准ASCII中，其最高位(b7)用作&lt;a href=&#34;https://baike.baidu.com/item/%E5%A5%87%E5%81%B6%E6%A0%A1%E9%AA%8C%E4%BD%8D&#34;&gt;奇偶校验位&lt;/a&gt;。所谓奇偶校验，是指在代码传送过程中用来检验是否出现错误的一种方法，一般分&lt;a href=&#34;https://baike.baidu.com/item/%E5%A5%87%E6%A0%A1%E9%AA%8C&#34;&gt;奇校验&lt;/a&gt;和偶校验两种。&lt;a href=&#34;https://baike.baidu.com/item/%E5%A5%87%E6%A0%A1%E9%AA%8C&#34;&gt;奇校验&lt;/a&gt;规定：正确的代码一个&lt;a href=&#34;https://baike.baidu.com/item/%E5%AD%97%E8%8A%82&#34;&gt;字节&lt;/a&gt;中1的个数必须是奇数，若非奇数，则在最高位b7添1；偶校验规定：正确的代码一个字节中1的个数必须是&lt;a href=&#34;https://baike.baidu.com/item/%E5%81%B6%E6%95%B0&#34;&gt;偶数&lt;/a&gt;，若非偶数，则在最高位b7添1 [1] 。&lt;/p&gt;
&lt;p&gt;后128个称为&lt;a href=&#34;https://baike.baidu.com/item/%E6%89%A9%E5%B1%95ASCII&#34;&gt;扩展ASCII&lt;/a&gt;码。许多基于&lt;a href=&#34;https://baike.baidu.com/item/x86&#34;&gt;x86&lt;/a&gt;的系统都支持使用扩展（或“高”）ASCII。扩展ASCII 码允许将每个字符的第8 位用于确定附加的128 个特殊符号字符、外来语字母和图形符号 [1] 。&lt;/p&gt;
&lt;h3 id=&#34;大小规则&#34;&gt;大小规则&lt;/h3&gt;
&lt;p&gt;常见ASCII码的大小规则：0~9&amp;lt;A~Z&amp;lt;a~z。&lt;/p&gt;
&lt;p&gt;1）数字比字母要小。如 “7”&amp;lt;“F”；&lt;/p&gt;
&lt;p&gt;2）数字0比数字9要小，并按0到9顺序递增。如 “3”&amp;lt;“8” ；&lt;/p&gt;
&lt;p&gt;3）字母A比字母Z要小，并按A到Z顺序递增。如“A”&amp;lt;“Z” ；&lt;/p&gt;
&lt;p&gt;4）同个字母的大写字母比小写字母要小32。如“A”&amp;lt;“a” 。&lt;/p&gt;
&lt;p&gt;几个常见字母的ASCII码大小： “A”为65；“a”为97；“0”为 48 [4] 。&lt;/p&gt;
&lt;h3 id=&#34;问题&#34;&gt;问题&lt;/h3&gt;
&lt;p&gt;在英语中，用128个符号编码便可以表示所有，但是用来表示其他语言，128个符号是不够的。比如，在&lt;a href=&#34;https://baike.baidu.com/item/%E6%B3%95%E8%AF%AD/660115&#34;&gt;法语&lt;/a&gt;中，字母上方有注音符号，它就无法用 ASCII 码表示。于是，一些欧洲国家就决定，利用字节中闲置的最高位编入新的符号。比如，法语中的é的编码为130（二进制10000010）。这样一来，这些欧洲国家使用的编码体系，可以表示最多256个符号 [5] 。&lt;/p&gt;
&lt;p&gt;但是，这里又出现了新的问题。不同的国家有不同的字母，因此，哪怕它们都使用256个符号的编码方式，代表的字母却不一样。比如，130在&lt;a href=&#34;https://baike.baidu.com/item/%E6%B3%95%E8%AF%AD/660115&#34;&gt;法语&lt;/a&gt;编码中代表了é，在&lt;a href=&#34;https://baike.baidu.com/item/%E5%B8%8C%E4%BC%AF%E6%9D%A5%E8%AF%AD/2612441&#34;&gt;希伯来语&lt;/a&gt;编码中却代表了字母Gimel (ג)，在&lt;a href=&#34;https://baike.baidu.com/item/%E4%BF%84%E8%AF%AD/315852&#34;&gt;俄语&lt;/a&gt;编码中又会代表另一个符号。但是不管怎样，所有这些编码方式中，0--127表示的符号是一样的，不一样的只是128--255的这一段 [5] 。&lt;/p&gt;
&lt;p&gt;至于&lt;a href=&#34;https://baike.baidu.com/item/%E4%BA%9A%E6%B4%B2/133681&#34;&gt;亚洲&lt;/a&gt;国家的文字，使用的符号就更多了，汉字就多达10万左右。一个字节只能表示256种符号，肯定是不够的，就必须使用多个字节表达一个符号。比如，简体中文常见的编码方式是 &lt;a href=&#34;https://baike.baidu.com/item/GB2312/483170&#34;&gt;GB2312&lt;/a&gt;，使用两个字节表示一个汉字，所以理论上最多可以表示 256 x 256 = 65536 个符号 [5] 。&lt;/p&gt;
&lt;h3 id=&#34;扩展&#34;&gt;扩展&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;1981年IBM PC ROM256个字符的字符集，即IBM扩展字符集 [5] 。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;1985年11&lt;a href=&#34;https://baike.baidu.com/item/Windows/165458&#34;&gt;Windows&lt;/a&gt;字符集被称作“&lt;a href=&#34;https://baike.baidu.com/item/ANSI/10401940&#34;&gt;ANSI&lt;/a&gt;字符集”，遵循了ANSI草案和&lt;a href=&#34;https://baike.baidu.com/item/ISO/10400&#34;&gt;ISO&lt;/a&gt;标准（ANSI/ISO&lt;a href=&#34;https://baike.baidu.com/item/8859-1&#34;&gt;8859-1&lt;/a&gt;-1987，简“Latin 1” [5] 。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;为了解决中国、日本和韩国的象形文字符和ASCII的某种兼容性，出现了双字节字符集（&lt;a href=&#34;https://baike.baidu.com/item/DBCS/4572615&#34;&gt;DBCS&lt;/a&gt;：double-byte character set）。DBCS从 第256 代码开始，就像ASCII一样，最初的128个代码是ASCII。然而，较高的128个代码中的某些总是跟随着第二个字节。这两个字节一起（称作首字节和跟随字节）定义一个字符，通常是一个复杂的象形文字 [6] 。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;汉字编码&#34;&gt;汉字编码&lt;/h3&gt;
&lt;p&gt;目前的文字编码标准主要有 ASCII、&lt;a href=&#34;https://baike.baidu.com/item/GB2312/483170&#34;&gt;GB2312&lt;/a&gt;、&lt;a href=&#34;https://baike.baidu.com/item/GBK/481954&#34;&gt;GBK&lt;/a&gt;、&lt;a href=&#34;https://baike.baidu.com/item/Unicode/750500&#34;&gt;Unicode&lt;/a&gt;等。ASCII 编码是最简单的西文编码方案。GB2312、GBK、GB18030 是汉字字符编码方案的国家标准。ISO/IEC 10646 和 Unicode 都是全球字符编码的国际标准 [4] 。下面对与汉字相关的编码方案GB2312，GBK与GB18030做简要的分析。&lt;/p&gt;
&lt;h4 id=&#34;gb2312-80-标准&#34;&gt;GB2312-80 标准&lt;/h4&gt;
&lt;p&gt;GB2312-80 是 1980 年制定的中国汉字编码国家标准。共收录 7445 个字符，其中汉字 6763 个。GB2312 兼容标准 ASCII码，采用扩展 ASCII 码的编码空间进行编码，一个汉字占用两个字节，每个字节的最高位为 1。具体办法是：收集了 7445 个字符组成 94*94 的方阵，每一行称为一个“区”，每一列称为一个“位”，区号位号的范围均为 01-94，区号和位号组成的代码称为“区位码”。区位输入法就是通过输入区位码实现汉字输入的。将区号和位号分别加上 20H，得到的 4 位&lt;a href=&#34;https://baike.baidu.com/item/%E5%8D%81%E5%85%AD%E8%BF%9B%E5%88%B6/4162457&#34;&gt;十六进制&lt;/a&gt;整数称为&lt;a href=&#34;https://baike.baidu.com/item/%E5%9B%BD%E6%A0%87%E7%A0%81/9886729&#34;&gt;国标码&lt;/a&gt;，编码范围为 0x2121～0x7E7E。为了兼容标准 ASCII 码，给国标码的每个字节加 80H，形成的编码称为&lt;a href=&#34;https://baike.baidu.com/item/%E6%9C%BA%E5%86%85%E7%A0%81/8481225&#34;&gt;机内码&lt;/a&gt;，简称内码，是汉字在机器中实际的存储代码GB2312-80 标准的内码范围是 0xA1A1～0xFEFE [7] 。&lt;/p&gt;
&lt;h4 id=&#34;gbk-编码标准&#34;&gt;GBK 编码标准&lt;/h4&gt;
&lt;p&gt;《汉字内码扩展规范》(&lt;a href=&#34;https://baike.baidu.com/item/GBK/481954&#34;&gt;GBK&lt;/a&gt;) 于1995年制定，兼容GB2312、GB13000-1、BIG5 编码中的所有汉字，使用双字节编码，编码空间为 0x8140～0xFEFE，共有 23940 个码位，其中 GBK1 区和 GBK2 区也是 GB2312 的编码范围。收录了 21003 个汉字。&lt;a href=&#34;https://baike.baidu.com/item/GBK/481954&#34;&gt;GBK&lt;/a&gt;向下与 GB 2312 编码兼容，向上支持 ISO 10646.1&lt;a href=&#34;https://baike.baidu.com/item/%E5%9B%BD%E9%99%85%E6%A0%87%E5%87%86/4495981&#34;&gt;国际标准&lt;/a&gt;，是前者向后者过渡过程中的一个承上启下的产物。ISO 10646 是&lt;a href=&#34;https://baike.baidu.com/item/%E5%9B%BD%E9%99%85%E6%A0%87%E5%87%86%E5%8C%96%E7%BB%84%E7%BB%87/779832&#34;&gt;国际标准化组织&lt;/a&gt;ISO 公布的一个编码标准，即 Universal Multilpe-Octet Coded Character Set（简称UCS），大陆译为《通用多八位编码字符集》，台湾译为《广用多八位元编码字元集》，它与 Unicode 组织的&lt;a href=&#34;https://baike.baidu.com/item/Unicode/750500&#34;&gt;Unicode&lt;/a&gt;编码完全兼容。ISO 10646.1 是该标准的第一部分《体系结构与基本多文种平面》。我国 1993 年以 GB 13000.1 国家标准的形式予以认可（即 GB 13000.1 等同于 ISO 10646.1） [7] 。&lt;/p&gt;
&lt;h4 id=&#34;gb18030编码标准&#34;&gt;GB18030编码标准&lt;/h4&gt;
&lt;p&gt;国家标准GB18030-2000《信息交换用汉字编码&lt;a href=&#34;https://baike.baidu.com/item/%E5%AD%97%E7%AC%A6%E9%9B%86/946585&#34;&gt;字符集&lt;/a&gt;基本集的补充》是我国继GB2312-1980和GB13000-1993之后最重要的汉字编码标准，是我国计算机系统必须遵循的基础性标准之一。GB18030-2000编码标准是由信息产业部和&lt;a href=&#34;https://baike.baidu.com/item/%E5%9B%BD%E5%AE%B6%E8%B4%A8%E9%87%8F%E6%8A%80%E6%9C%AF%E7%9B%91%E7%9D%A3%E5%B1%80/976606&#34;&gt;国家质量技术监督局&lt;/a&gt;在2000年 3月17日联合发布的，并且将作为一项国家标准在2001年的1月正式强制执行。GB18030-2005《信息技术中文编码字符集》是我国制订的以汉字为主并包含多种我国少数民族文字（如藏、蒙古、傣、彝、朝鲜、维吾尔文等）的超大型中文编码字符集强制性标准，其中收入汉字70000余个 [8] 。&lt;/p&gt;
&lt;h2 id=&#34;latin1编码&#34;&gt;Latin1编码&lt;/h2&gt;
&lt;p&gt;Latin1是ISO-8859-1的别名，有些环境下写作Latin-1。Latin1编码是单字节编码，向下兼容ASCII，其编码范围是0x00-0xFF，0x00-0x7F之间完全和ASCII一致，0x80-0x9F之间是控制字符，0xA0-0xFF之间是文字符号。&lt;/p&gt;
&lt;p&gt;ASCII编码是一个7位的容器，ISO-8859-1编码是一个8位的容器。&lt;/p&gt;
&lt;p&gt;因为Latin1编码范围使用了单字节内的所有空间，在支持Latin1编码的系统中传输和存储其他任何编码的字节流都不会被抛弃。换言之，把其他任何编码的字节流当作Latin1编码看待都没有问题。这是个很重要的特性，MySQL数据库默认编码是Latin1就是利用了这个特性。&lt;/p&gt;
&lt;h2 id=&#34;unicode编码&#34;&gt;Unicode编码&lt;/h2&gt;
&lt;p&gt;世界上存在着多种编码方式，同一个二进制数字可以被解释成不同的符号。因此，要想打开一个文本文件，就必须知道它的编码方式，否则用错误的编码方式解读，就会出现乱码。为什么电子邮件常常出现乱码？就是因为发信人和收信人使用的编码方式不一样。&lt;/p&gt;
&lt;p&gt;可以想象，如果有一种编码，将世界上所有的符号都纳入其中。每一个符号都给予一个独一无二的编码，那么乱码问题就会消失。这就是Unicode。&lt;/p&gt;
&lt;p&gt;Unicode当然是一个很大的集合，现在的规模可以容纳100多万个符号。每个符号的编码都不一样需要注意的是，Unicode只是一个符号集，它只规定了符号的二进制代码，却没有规定这个二进制代码应该如何存储&lt;/p&gt;
&lt;p&gt;如果所有字符都按照最大存储空间存储，那必然会浪费很大的空间，比如所有字符都按照3字节存储，但是英文字母只需要一个字节存储就够了，就等于说一个Unicode编码的英文文档是ASCII编码文档存储空间的三倍。&lt;br&gt;
所以，便有了变长编码—-UTF-8。&lt;/p&gt;
&lt;h2 id=&#34;utf-8编码&#34;&gt;UTF-8编码&lt;/h2&gt;
&lt;p&gt;UTF-8就是在互联网上使用最广的一种Unicode的实现方式。其他实现方式还包括UTF-16和UTF-32，不过在互联网上基本不用。&lt;/p&gt;
&lt;p&gt;UTF-8最大的一个特点，就是它是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。如ASCII编码的内容UTF-8中就是用一个字符存储的。&lt;/p&gt;
&lt;h2 id=&#34;gbk编码&#34;&gt;GBK编码&lt;/h2&gt;
&lt;p&gt;GBK编码是在GB2312-80(也称作GB2312，GB码)标准基础上的内码扩展规范，使用了双字节编码方案。&lt;/p&gt;
">字符编码</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://wenbozhangw.github.io/post/error-code-8-server-memory-error/"" data-c="
          &lt;p&gt;Java 项目在使用 Aerospike 缓存时，会有 Error Code 8 : Server memory error 报错，导致缓存数据无法正常写入。&lt;/p&gt;
&lt;!-- more --&gt;
&lt;h2 id=&#34;一-问题背景&#34;&gt;一、问题背景&lt;/h2&gt;
&lt;p&gt;在 Java 客户端出现 Error Code 8 : Server memory error 报错：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;com.aerospike.client.AerospikeClient : Error Code 8: Server memory error

com.aerospike.client.AerospikeException: Error Code 8: Server memory error
        at com.aerospike.client.command.WriteCommand.parseResult(WriteCommand.java:54)
        at com.aerospike.client.command.SyncCommand.execute(SyncCommand.java:84)
        at com.aerospike.client.Aerospike.put(AerospikeClient.java:378)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在 AMC 监控中发现 &lt;strong&gt;Avail&lt;/strong&gt; 过低：&lt;br&gt;
&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1642484946989.png&#34; alt=&#34;amc-low-avail&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;二-error-code-8-出现原因&#34;&gt;二、Error Code 8 出现原因&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;当 stop_write 触发时，出现
&lt;ol&gt;
&lt;li&gt;memory - stop-write-pct ，即当内存达到 SW（stop-write）时，默认 90%。&lt;/li&gt;
&lt;li&gt;disk - min-avail-pct，当为命名空间配置的 devices 之一 (或 pmem 文件) 上的 device_available_pct 低于此指定百分比时，禁止写入（删除，副本写入和迁移写入除外），默认 5%。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;如果不能再分配内存（但 stop_writes 通常应该先命中），也可能发生。&lt;/li&gt;
&lt;li&gt;命名空间将不再能够接受写入请求。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;三-如何恢复连续的空闲块即可用百分比available-percent&#34;&gt;三、如何恢复连续的空闲块，即可用百分比(available percent)&lt;/h2&gt;
&lt;h3 id=&#34;31-什么是-available-percent&#34;&gt;3.1 什么是 available percent?&lt;/h3&gt;
&lt;p&gt;可用百分比 (device_available_pct)是一个关键的 Aerospike 指标，用于测量最小连续可用磁盘空间（以块大小为单位 write-block-size）跨命名空间中的所有设备，即：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  Avail_pct = min(命名空间中所有磁盘的 contig_disk)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;32-当命名空间的可用百分比很低时会发生什么&#34;&gt;3.2 当命名空间的可用百分比很低时会发生什么？&lt;/h3&gt;
&lt;p&gt;从应用程序的角度来看，可用百分比低的主要表现是，当访问某个节点的名称空间在其某个设备上没有足够的连续空闲磁盘空间时，写入将会失败。在这种情况下返回给客户端的错误是：&lt;/p&gt;
&lt;p&gt;com.aerospike.client.AerospikeException: Error Code 8: Server memory error&lt;br&gt;
The server will log the following WARNING:&lt;/p&gt;
&lt;p&gt;WARNING (rw): (write.c:770) {namespaceid}: write_master: drives full&lt;br&gt;
更准确地说，当 device_available_pct 低于任何命名空间设备上的 min-avail-pct 配置阈值（默认为 5%）时，应用程序写入将开始失败。&lt;/p&gt;
&lt;h3 id=&#34;33-最常见的情况和补救措施&#34;&gt;3.3 最常见的情况和补救措施&lt;/h3&gt;
&lt;h4 id=&#34;331-容量过度使用或磁盘真的已满&#34;&gt;3.3.1 容量过度使用（或磁盘真的“已满”）&lt;/h4&gt;
&lt;p&gt;如果由于每个块的使用百分比高于容量是 defrag-lwm-pct 阈值，而没有符合碎片整理条件的块，则会发生这种情况。&lt;/p&gt;
&lt;p&gt;验证这种情况，可以检查每个设备的设备日志行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; INFO (drv_ssd): (drv_ssd.c:2115) {namespaceid} /dev/xvdb: used-bytes 1626239616 free-wblocks 28505 write-q 0 write (8203,23.0) defrag-q 0 defrag-read (7981,21.7) defrag-write (1490,3.0) shadow-write-q 0 tomb-raider-read (1615,59.6)
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;如果 defrag-q 较低或为 0，并且碎片整理写入速率也较低或为 0.0，则表明没有符合碎片整理条件的块。&lt;/li&gt;
&lt;li&gt;如果磁盘使用百分比 ( device_used_bytes / device_total_bytes x 100 ) 大于配置 defrag-lwm-pct，磁盘高于正常碎片整理的安全操作阈值。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以下是可能的补救措施：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;删除记录（例如使用 truncate 命令）。&lt;/li&gt;
&lt;li&gt;如果可接受，可以对数据进行驱逐。相关配置参数如下：&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;evict-tenths-pct：（增加）每次逐出的最大数据量，默认 5，逐出总数据的千分之五，如果配置为 100，则逐出数据的百分之十。&lt;/li&gt;
&lt;li&gt;high-water-disk-pct：（减少）磁盘高水位线，当磁盘使用率大于等于此值，将进行磁盘数据逐出，默认值 60。&lt;/li&gt;
&lt;li&gt;high-water-memory-pct：（减少）内存高水位线，当内存使用率大于等于此值，将进行内存数据逐出，默认值 50。（关于逐出，默认逐出最接近过期的数据）&lt;/li&gt;
&lt;li&gt;nsup-delete-sleep：（减少）在版本4.5.1中已删除，因为nsup不再用于 delete transactions 。生成 delete transactions 之间要休眠的微秒数。&lt;/li&gt;
&lt;li&gt;nsup-period：（减少）主 expiration/eviction 线程（称为 nsup, namespace supervisor）唤醒以处理命名空间的时间间隔。 nsup-period 0 的默认值禁用命名空间的 namespace supervisor 。默认情况下，该值以秒为单位。您还可以用分钟，小时或天为单位设置此值，其表示法为 1m or 1h or 1d 。如果在 nsup 工作时将其 nsup-period 动态设置为 0，则 nsup 将在完成其当前周期，然后进入休眠状态。确保时间在集群中的各个节点之间是同步的。对于 Aerospike 4.5.1 或更高版本，对于启用 nsup (即 nsup-period 不为零)的每个命名空间，如果集群始终偏斜超过 40s , 写入将被挂起。确保已安装，配置并正常运行网络时间协议（NTP）或其他时间同步机制。   在Aerospike 4.9版之前，默认值为120。   从 Aerospike 4.9 版本开始，如果 nsup-period 为 0（默认值）但 default-ttl 为非零，则服务器将不会启动，除非 allow-ttl-without-nsup 设置为 true。&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;添加额外容量（每个命名空间有更多节点或更多设备）。&lt;/li&gt;
&lt;li&gt;逐渐增加 defrag-lwm-pct 临界点。鉴于这将导致非线性写入放大增加，请监控性能影响。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;332-尺寸不匹配的设备&#34;&gt;3.3.2 尺寸不匹配的设备&lt;/h4&gt;
&lt;p&gt;鉴于整体可用百分比的定义 – Avail_pct = min(命名空间中所有磁盘的 contig_disk) ，当有一个非常小的尺寸的设备时，如果该设备触发 stop_writes，即使其他设备拥有很大的空闲空间，依旧会出现这种情况。&lt;/p&gt;
&lt;p&gt;检查用于使用字节和空闲 wblock 的设备特定日志行应该可以快速确定是否是这种情况。当然，验证每个设备或分区的物理大小也会产生信息。&lt;/p&gt;
&lt;h4 id=&#34;333-碎片整理没有跟上&#34;&gt;3.3.3 碎片整理没有跟上&lt;/h4&gt;
&lt;p&gt;在某些情况下，有块需要进行碎片整理，但碎片整理跟不上。将碎片整理率与每个设备日志行上的写入率进行比较。碎片整理队列 (defrag-q) 不断增加是碎片整理没有跟上的迹象：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;INFO (drv_ssd): (drv_ssd.c:2143) {namespaceid} /dev/nvme0n1: used-bytes 1182271397376 free-wblocks 1212517 write-q 0 write (1304972843,497.1) defrag-q 6743042 defrag-read (1309698931,609.4) defrag-write (639136010,191.8)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在这种情况下，可以增加碎片整理线程的速度。默认情况下，碎片整理线程在每次块读取之间休眠 1000 微秒。这可以通过 defrag-sleep 配置选项。建议逐渐减小该值，并观察对存储子系统（例如使用iostat）和应用程序性能的潜在影响。以下命令将使读取要进行碎片整理的块的默认速度加倍。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; $ asinfo -v &amp;quot;set-config:context=namespace;id=&amp;lt;namespace name&amp;gt;;defrag-sleep=500&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;334-过大的-post-write-queue&#34;&gt;3.3.4 过大的 post-write-queue&lt;/h4&gt;
&lt;p&gt;post-write-queue中的块（默认为每个设备 256 个块）不适合进行碎片整理。对于具有小设备和大 write-block-size的命名空间，post-write-queue可能是设备本身的重要部分，甚至更大。这显然会很快导致低的可用百分比情况。&lt;/p&gt;
&lt;p&gt;例如，在大小为 4GiB 的设备上， post-write-queue 512 和 write-block-size 8M ，对于该命名空间，此时队列占用的总大小将是 512 * 8MiB = 4096 MiB = 4GiB，并且没有进行碎片整理。&lt;/p&gt;
&lt;h4 id=&#34;335-碎片整理的块没有及时释放不常见&#34;&gt;3.3.5 碎片整理的块没有及时释放（不常见）&lt;/h4&gt;
&lt;p&gt;从 3.16.0.1 版本开始，碎片整理的块在新块上重写的数据被刷新之前不会被释放：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[AER-5776] - (STORAGE) 在清除碎片整理的所有数据之前不要释放碎片整理的写入块。&lt;br&gt;
在某些极端情况下，通常在记录非常少且持续更新的设备上，可能会因为碎片整理线程正在写入的新块需要很长时间才能填充大量释放的块。这在 4.3.1.5 版中得到解决：&lt;/li&gt;
&lt;li&gt;[AER-5950] - （STORAGE）当碎片整理负载极低时，定期刷新碎片整理缓冲区以释放源写入块。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;四-如何从可用百分比-0-中恢复&#34;&gt;四、如何从可用百分比 0 中恢复&lt;/h2&gt;
&lt;h3 id=&#34;41-调整碎片整理速度和阈值&#34;&gt;4.1 调整碎片整理速度和阈值&lt;/h3&gt;
&lt;p&gt;如果碎片整理没有跟上，可以使用以下 2 个设置调整碎片整理速度和密度：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; $ asinfo -v &amp;quot;set-config:context=namespace;id=&amp;lt;namespace name&amp;gt;;defrag-lwm-pct=50&amp;quot;
 $ asinfo -v &amp;quot;set-config:context=namespace;id=&amp;lt;namespace name&amp;gt;;defrag-sleep=500&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;42-增加对过期数据的驱逐&#34;&gt;4.2 增加对过期数据的驱逐&lt;/h3&gt;
&lt;p&gt;可能还需要增加驱逐以允许删除更多记录并允许更多块有资格进行碎片整理。&lt;/p&gt;
&lt;p&gt;驱逐可以通过设置进行调整：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;evict-tenths-pct（增加）&lt;/li&gt;
&lt;li&gt;high-water-disk-pct（减少）&lt;/li&gt;
&lt;li&gt;high-water-memory-pct（减少）&lt;/li&gt;
&lt;li&gt;nsup-delete-sleep （减少）&lt;/li&gt;
&lt;li&gt;nsup-period（减少）&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;43-通过添加新节点来增加容量&#34;&gt;4.3 通过添加新节点来增加容量&lt;/h3&gt;
&lt;p&gt;添加新节点以增加容量很简单。如果您的系统磁盘或分区上的可用连续空间已用完，则添加新节点允许当前节点卸载 1/（new cluster size）数据。这种方法的成功几率与集群的大小成反比。您可以通过停止应用程序层生成的新写入来进一步提高成功的机会。&lt;/p&gt;
&lt;h3 id=&#34;44-停止节点上的服务和零碎片持久存储&#34;&gt;4.4 停止节点上的服务和零碎片持久存储&lt;/h3&gt;
&lt;p&gt;如果您使用复制因子 1 运行，则“dd”方法通常是不可接受的，因为此方法需要从命名空间中删除 wblock，这会导致复制因子 1 的数据丢失。&lt;/p&gt;
&lt;p&gt;复制因子 2 可以从数据丢失中正常恢复，因为当节点恢复时，删除的数据将通过迁移（重新平衡）重新填充回节点。这种方法需要冷重启（它将是空的）并且是唯一可以保证一次性释放 wblock 的方法。&lt;/p&gt;
&lt;p&gt;这假设集群中的其他节点没有用完 avail pct 并且可以处理迁移。&lt;/p&gt;
&lt;p&gt;DD 命令可用于将驱动器归零 ：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;`sudo dd if=/dev/zero of=/dev/DEVICE bs =1M
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;使用 blkdiscard&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; sudo blkdiscard /dev/&amp;lt;INSERT DEVICE NAME HERE&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;删除持久存储文件&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; sudo rm &amp;lt;Aerospike persistent storage file&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;45-cold-start-evict-ttl-方法&#34;&gt;4.5 Cold-Start-Evict-TTL 方法&lt;/h3&gt;
&lt;p&gt;cold-start-evict-ttl告诉系统在冷启动期间将忽略 TTL 低于特定值的任何内容。这通常用于加速冷启动。当你知道你的驱逐深度很深时。要运行您的驱逐深度：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; $ asinfo -v &amp;quot;hist-dump:ns=&amp;lt;namespace name&amp;gt;;hist=ttl&amp;quot;
 value is &amp;lt;namespace name:ttl=100,51840,0,0,0,0,0,0,0,0,0,0,0, \
 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, \
 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,920023,10263488, \
 20000052,20319938,23861472,20052298,21612051,22163298, \
 24370589,34911006,27048399,29558473,27697235,21049529, \
 20300346,17539324,17954128,16932493,16265998,20131370, \
 15997368,18030184,17260295,16613023,21100184,18003700, \
 20814926,19660860,18829521,23601739,17515442,21490671, \
 19797821,19861895,24694092,11354573,14945634,14806583, \
 17064793,37144797;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;此直方图中的第一个数字表示此直方图包含多少个桶，第二个值是每个桶的宽度（以秒为单位），其余 100 个值是落在各种 ttl 范围内的记录数，最后一个是更大的记录比（100 * 宽度）。&lt;/p&gt;
&lt;p&gt;对于这个特定的直方图，我们可以看到每个桶是 51840 秒，14.4 小时，并且在宽度和第一个填充值之间有 60 个零。这意味着当前的驱逐深度是 (60 * 51840)。&lt;/p&gt;
&lt;p&gt;我们必须增加驱逐深度才能使这种方法起作用，成功的几率与您使用冷启动 evict-ttl 增加驱逐深度的量成正比。&lt;/p&gt;
&lt;h2 id=&#34;五-后记&#34;&gt;五、后记&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;在碎片整理速度成为问题的情况下，将 SSD 分区为多个分区可能是有益的。您将失去少量的存储空间，但会获得碎片整理线程。物理 SSD 及其分区都是&amp;quot;device&amp;quot;。每个设备有一个碎片整理线程。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在存储充满非过期对象 (TTL=0) 的情况下，碎片整理和逐出解决方案将无济于事。在这种情况下，我们建议与实施行方商议数据的最大保留时间，尽量不要设置default-ttl为零，防止数据无法逐出，并通过添加额外的存储或节点来增加容量。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;不管您使用的是 SDD or HDD，如果可以直接使用挂载设备，请直接配置挂载设备，这将比配置file使用文件句柄的方式效率更高。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果要保证应用可用，可暂时增加 max-write-cache ，不过这个只能暂时保证数据写入，如果写入速度一直很高，依旧会出现上述问题。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt; asinfo -v &#39;set-config:context=namespace;id=namespaceName;max-write-cache=128M&#39;
&lt;/code&gt;&lt;/pre&gt;
">Error Code 8 : Server memory error</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://wenbozhangw.github.io/post/elasticsearch-unassigned-shards/"" data-c="
          &lt;p&gt;在 Elasticsearch 中，一个健康的集群一定是平衡的：主分片(master)和副本分片(replica)分布在所有节点上，以便在节点发生故障时依旧保证可用性。&lt;/p&gt;
&lt;p&gt;当时当你看到分片在一个 &lt;code&gt;UNASSIGNED&lt;/code&gt; 状态中时，你应该怎么做？&lt;/p&gt;
&lt;!-- more --&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1642405625703.jpeg&#34; alt=&#34;1-too-many-shards-to-assign&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;在我们深入探究一些解决方案之前，让我们验证未分配(&lt;code&gt;UNASSIGNED&lt;/code&gt;)的分片是否包含我们需要保留的数据（如果没有，删除这些分片是解决问题的最直接方法）。如果您已经确认该分片存在有价值的数据，请跳转至解决方案：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#%E5%8E%9F%E5%9B%A0%E4%B8%80%E6%95%85%E6%84%8F%E5%BB%B6%E8%BF%9F%E5%88%86%E7%89%87%E5%88%86%E9%85%8D&#34;&gt;分片分配被故意延迟&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#%E5%8E%9F%E5%9B%A0%E4%BA%8C%E5%88%86%E7%89%87%E5%A4%AA%E5%A4%9A%E8%8A%82%E7%82%B9%E4%B8%8D%E5%A4%9F&#34;&gt;分片太多，节点不够&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#%E5%8E%9F%E5%9B%A0%E4%B8%89%E6%82%A8%E9%9C%80%E8%A6%81%E9%87%8D%E6%96%B0%E5%90%AF%E7%94%A8%E5%88%86%E7%89%87%E5%88%86%E9%85%8D&#34;&gt;您需要重新启用分片分配&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#%E5%8E%9F%E5%9B%A0%E5%9B%9B%E9%9B%86%E7%BE%A4%E4%B8%AD%E4%B8%8D%E5%86%8D%E5%AD%98%E5%9C%A8-shard-%E6%95%B0%E6%8D%AE&#34;&gt;分片数据不再存在于集群中&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#%E5%8E%9F%E5%9B%A0%E4%BA%94%E7%A3%81%E7%9B%98%E6%B0%B4%E4%BD%8D%E8%BF%87%E4%BD%8E&#34;&gt;低磁盘水位线&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#%E5%8E%9F%E5%9B%A0%E5%85%AD%E5%A4%9A%E4%B8%AA-elasticsearch-%E7%89%88%E6%9C%AC&#34;&gt;多个 Elasticsearch 版本&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;本文汇总的命令格式假设您在默认端口(9200)上运行每个 Elasticsearch 实例的 HTTP 服务。我们假设您在本地提交请求，所以它们被重定向到 &lt;code&gt;localhost&lt;/code&gt;；如果不是，您替换 &lt;code&gt;localhost&lt;/code&gt; 为您节点的 IP 地址。&lt;/p&gt;
&lt;h2 id=&#34;查明有问题的分片&#34;&gt;查明有问题的分片&lt;/h2&gt;
&lt;p&gt;Elasticsearch 的 &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/cat-shards.html&#34;&gt;cat shards API&lt;/a&gt; 会告诉您哪些分片未分配，以及未分配的原因：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -XGET localhost:9200/_cat/shards?h=index,shard,prirep,state,unassigned.reason| grep UNASSIGNED
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;每行列出索引的名称、分片编号、是主分片(p)还是副本(r)分片，以及未分配的原因：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;constant-updates 0 p UNASSIGNED NODE_LEFT node_left
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果您运行的是 Elasticsearch 5+ 版本，您还可以使用 &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-allocation-explain.html&#34;&gt;cluster allocation explain API&lt;/a&gt; 来尝试获取有关分片分配问题的更多信息：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -XGET localhost:9200/_cluster/allocation/explain?pretty
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;生成的输出将提供有用的详细信息，说明集群中的某些分配仍未分配：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{
  &amp;quot;index&amp;quot; : &amp;quot;testing&amp;quot;,
  &amp;quot;shard&amp;quot; : 0,
  &amp;quot;primary&amp;quot; : false,
  &amp;quot;current_state&amp;quot; : &amp;quot;unassigned&amp;quot;,
  &amp;quot;unassigned_info&amp;quot; : {
    &amp;quot;reason&amp;quot; : &amp;quot;INDEX_CREATED&amp;quot;,
    &amp;quot;at&amp;quot; : &amp;quot;2018-04-09T21:48:23.293Z&amp;quot;,
    &amp;quot;last_allocation_status&amp;quot; : &amp;quot;no_attempt&amp;quot;
  },
  &amp;quot;can_allocate&amp;quot; : &amp;quot;no&amp;quot;,
  &amp;quot;allocate_explanation&amp;quot; : &amp;quot;cannot allocate because allocation is not permitted to any of the nodes&amp;quot;,
  &amp;quot;node_allocation_decisions&amp;quot; : [
    {
      &amp;quot;node_id&amp;quot; : &amp;quot;t_DVRrfNS12IMhWvlvcfCQ&amp;quot;,
      &amp;quot;node_name&amp;quot; : &amp;quot;t_DVRrf&amp;quot;,
      &amp;quot;transport_address&amp;quot; : &amp;quot;127.0.0.1:9300&amp;quot;,
      &amp;quot;node_decision&amp;quot; : &amp;quot;no&amp;quot;,
      &amp;quot;weight_ranking&amp;quot; : 1,
      &amp;quot;deciders&amp;quot; : [
        {
          &amp;quot;decider&amp;quot; : &amp;quot;same_shard&amp;quot;,
          &amp;quot;decision&amp;quot; : &amp;quot;NO&amp;quot;,
          &amp;quot;explanation&amp;quot; : &amp;quot;the shard cannot be allocated to the same node on which a copy of the shard already exists&amp;quot;
        }
      ]
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在这种情况下，API 清楚地解释了为什么副本分配保持未分配：&amp;quot;the shard cannot be allocated to the same node on which a copy of the shard already exists（分片不能分配给已经存在分配副本的统一节点）&amp;quot;。要查看有关此特定问题的更多详细信息以及如何解决它，请 &lt;a href=&#34;#%E5%8E%9F%E5%9B%A0%E4%BA%8C%E5%88%86%E7%89%87%E5%A4%AA%E5%A4%9A%E8%8A%82%E7%82%B9%E4%B8%8D%E5%A4%9F&#34;&gt;跳转至&lt;/a&gt; 本文后面的部分。&lt;/p&gt;
&lt;p&gt;如果未分配的分片属于您认为已删除的索引，或者您不再需要的过时索引，则可以删除索引以将集群状态恢复绿色：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -XDELETE &#39;localhost:9200/index_name/&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果这不能解决问题，请继续阅读以尝试其他解决方案。&lt;/p&gt;
&lt;h2 id=&#34;原因一故意延迟分片分配&#34;&gt;原因一：故意延迟分片分配&lt;/h2&gt;
&lt;p&gt;当一个节点离开集群时，主节点会暂时延迟分片重新分配，以表面原始节点能够在一定时间内（&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/delayed-allocation.html&#34;&gt;默认为一分钟&lt;/a&gt;）恢复，如果在此期间重新平衡分片，会造成不必要的资源浪费。如果是这种情况，您的日志应如下所示：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[TIMESTAMP][INFO][cluster.routing] [PRIMARY NODE NAME] delaying allocation for [54] unassigned shards, next check in [1m]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;您可以像这样动态修改延迟时间：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -XPUT &amp;quot;localhost:9200/&amp;lt;INDEX_NAME&amp;gt;/_settings?pretty&amp;quot; -H &#39;Content-Type: application/json&#39; -d&#39;
{
  &amp;quot;settings&amp;quot;: {
    &amp;quot;index.unassigned.node_left.delayed_timeout&amp;quot;: &amp;quot;5m&amp;quot;
  }
}&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;替换 &lt;code&gt;&amp;lt;INDEX_NAME&amp;gt;&lt;/code&gt; 为 &lt;code&gt;_all&lt;/code&gt; 将更新集群中所有索引的阈值。&lt;/p&gt;
&lt;p&gt;延迟时间结束后，您应该开始看到主节点分配了这些分片。如果没有，请继续阅读以探索其他潜在原因的解决方案。&lt;/p&gt;
&lt;h2 id=&#34;原因二分片太多节点不够&#34;&gt;原因二：分片太多，节点不够&lt;/h2&gt;
&lt;p&gt;当节点加入和离开集群时，主节点会自动重新分配分片，确保一个分片的多个副本&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/2.4/_basic_concepts.html&#34;&gt;不会分配给同一个节点&lt;/a&gt;。换句话说，主节点不会将主分片分配给与其副本相同的节点，也不会将同一分片的两个副本分配给同一个节点。如果没有足够的节点来相应地分配分片，分配可能会停留在未分配状态。&lt;/p&gt;
&lt;p&gt;为避免此问题，请按照以下公式确保集群中的每个索引都初始化，且每个主分片的副本数少于集群中的节点数：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;N &amp;gt;= R + 1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其中 N 是集群中的节点数，R 是集群中所有索引的最大分片副本因子。&lt;/p&gt;
&lt;p&gt;在下面的屏幕截图中，&lt;code&gt;many-shards&lt;/code&gt; 索引存储在四个主分片上，每个主分片有四个副本。索引的 20 个分片中有 8 个未分配，因为我们的集群仅包含三个节点，每个主分片的两个副本尚未分配，因为三个节点中的每个都已包含该分片的副本。&lt;br&gt;
&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1642412584473.jpeg&#34; alt=&#34;1-too-many-shards-to-assign&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;p&gt;要解决此问题，您可以向集群添加更多数据节点或减少副本数量。在我们的示例中，无门需要在集群中至少再添加两个节点或者将副本因子较少到两个，如下所示：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -XPUT &amp;quot;localhost:9200/&amp;lt;INDEX_NAME&amp;gt;/_settings?pretty&amp;quot; -H &#39;Content-Type: application/json&#39; -d&#39; { &amp;quot;number_of_replicas&amp;quot;: 2 }&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;减少副本数量后，看看是否已分配所有分片&lt;br&gt;
&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1642417786150.jpeg&#34; alt=&#34;2-reduced-replicas-green&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;原因三您需要重新启用分片分配&#34;&gt;原因三：您需要重新启用分片分配&lt;/h2&gt;
&lt;p&gt;在下面的 Kopf 屏幕截图中，一个节点刚刚加入集群，但尚未分配任何分片。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1642471400721.jpeg&#34; alt=&#34;3-unassigned-allocation-disabled&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/7.5/shards-allocation.html&#34;&gt;默认情况下在所有节点上启用&lt;/a&gt; 分片分配，但您可能在某些时候禁用了分片分配（例如，为了执行 &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/guide/current/_rolling_restarts.html&#34;&gt;滚动重启&lt;/a&gt; ），并且忘记重启启用它。&lt;/p&gt;
&lt;p&gt;要启用分片分配，请更新&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-update-settings.html&#34;&gt;集群更新设置API&lt;/a&gt; ：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X PUT &amp;quot;localhost:9200/_cluster/settings?pretty&amp;quot; -H &#39;Content-Type: application/json&#39; -d&#39;
{
    &amp;quot;transient&amp;quot; : {
        &amp;quot;cluster.routing.allocation.enable&amp;quot; : &amp;quot;all&amp;quot;
    }
}
&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果这解决了问题，您的 &lt;a href=&#34;https://github.com/lmenezes/elasticsearch-kopf&#34;&gt;Kopf&lt;/a&gt; 或 &lt;a href=&#34;https://app.datadoghq.com/screen/integration/elasticsearch?_gl=1*1h3mwdy*_ga*MjA1NzQ5MzY1NS4xNjQxOTUxNjc2*_ga_KN80RDFSQK*MTY0MjQwNDAxMC41LjEuMTY0MjQwNDA1NC4w&amp;amp;_ga=2.82032019.409373510.1642404018-2057493655.1641951676&#34;&gt;Datadog dashboard&lt;/a&gt; 应显示未分配分片数量随着它们成功分配给节点而减少。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1642471844506.jpeg&#34; alt=&#34;4-unassigned-shards-datadog2&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;此 Datadog 时间序列图显示重新启用分片分配后未分配的分片数量减少。
&lt;/code&gt;&lt;/pre&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://wenbozhangw.github.io//post-images/1642471903524.jpeg&#34; alt=&#34;5-unassigned-after-allocation-enabled&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;更新后的 Kopf 仪表盘显示，在重新启用分片分配后，许多以前未分配的分片已被分配。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;看起来这解决了我们所有未分配的分片的问题，但有一个例外：&lt;code&gt;constant-updates&lt;/code&gt; 索引的分片 0。让我们探讨一下为什么分片仍未分配的其他可能原因。&lt;/p&gt;
&lt;h2 id=&#34;原因四集群中不再存在-shard-数据&#34;&gt;原因四：集群中不再存在 Shard 数据&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;constant-updates&lt;/code&gt; 在这种情况下，索引的主分片 0 未分配。它可能是在没有任何副本的节点上创建的（一种用于&lt;a href=&#34;https://www.datadoghq.com/blog/elasticsearch-performance-scaling-problems/&#34;&gt;加速初始索引&lt;/a&gt; 过程的技术），并且该节点在数据被复制之前就离开了集群。主节点在其全局集群状态文件中检测到分片，但无法在集群中定位分片的数据。&lt;/p&gt;
&lt;p&gt;另一种可能性是节点在重新启动时可能遇到了问题。通常，当一个节点恢复与集群的连接时，它会将有关其磁盘上的分片信息转发给主节点，然后主节点将这些分片从 &amp;quot;unassigned&amp;quot; 过渡到 &amp;quot;assigned/started&amp;quot;。当这个进程由于某种原因失败时（例如节点的存储以某种方式被破坏），分片可能仍然未分配。&lt;/p&gt;
&lt;p&gt;在这种情况下，您必须决定如何继续：尝试让原始节点恢复并重新加入集群（不要执行强制分配主分片），或使用 &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-reroute.html&#34;&gt;集群重路由API&lt;/a&gt;强制分配分片并使用原始数据源或备份文件重新索引丢失的数据。&lt;/p&gt;
&lt;p&gt;如果您决定使用后者（强制分配分片），需要注意的是您&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-reroute.html&#34;&gt;将分配一个&amp;quot;空&amp;quot;分片&lt;/a&gt;。如果包含原始主分片数据的节点稍后重新加入集群，则其数据&lt;a href=&#34;https://github.com/elastic/elasticsearch/issues/16113&#34;&gt;将被&lt;/a&gt;新创建的（空）主分片覆盖，因为它将被视为数据的&amp;quot;更新&amp;quot;版本。再继续此操作之前，您可能希望&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/6.8/cluster-reroute.html#_retrying_failed_allocations&#34;&gt;重新分配&lt;/a&gt;，这将允许您保留存储在该分片上的数据。&lt;/p&gt;
&lt;p&gt;如果您了解其中的含义，并且仍想强制分配未分配的主分片，则可以使用 &lt;code&gt;allocate_empty_primary&lt;/code&gt; 标志来执行此操作。以下命令将 &lt;code&gt;constant-updates&lt;/code&gt; 索引中的主分片 0 重新路由到特定节点：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -XPOST &amp;quot;localhost:9200/_cluster/reroute?pretty&amp;quot; -H &#39;Content-Type: application/json&#39; -d&#39;
{
    &amp;quot;commands&amp;quot; : [
        {
          &amp;quot;allocate_empty_primary&amp;quot; : {
                &amp;quot;index&amp;quot; : &amp;quot;constant-updates&amp;quot;, 
                &amp;quot;shard&amp;quot; : 0,
                &amp;quot;node&amp;quot; : &amp;quot;&amp;lt;NODE_NAME&amp;gt;&amp;quot;, 
                &amp;quot;accept_data_loss&amp;quot; : &amp;quot;true&amp;quot;
          }
        }
    ]
}
&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;请注意，您需要指定&lt;code&gt;&amp;quot;accept_data_loss&amp;quot;:&amp;quot;true&amp;quot;&lt;/code&gt;以确保您已准备好丢失分片上的数据。如果不包含此参数，您将看到如下错误：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{
  &amp;quot;error&amp;quot; : {
    &amp;quot;root_cause&amp;quot; : [
      {
        &amp;quot;type&amp;quot; : &amp;quot;remote_transport_exception&amp;quot;,
        &amp;quot;reason&amp;quot; : &amp;quot;[NODE_NAME][127.0.0.1:9300][cluster:admin/reroute]&amp;quot;
      }
    ],
    &amp;quot;type&amp;quot; : &amp;quot;illegal_argument_exception&amp;quot;,
    &amp;quot;reason&amp;quot; : &amp;quot;[allocate_empty_primary] allocating an empty primary for [constant-updates][0] can result in data loss. Please confirm by setting the accept_data_loss parameter to true&amp;quot;
  },
  &amp;quot;status&amp;quot; : 400
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-snapshots.html&#34;&gt;您现在需要重新索引丢失的数据，或使用 Snapshot and Restore API&lt;/a&gt; 从备份快照中尽可能多地恢复。&lt;/p&gt;
&lt;h2 id=&#34;原因五磁盘水位过低&#34;&gt;原因五：磁盘水位过低&lt;/h2&gt;
&lt;p&gt;如果没有足够的节点和足够的磁盘空间，主节点可能无法分配分片（它不会将分片分配给&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/disk-allocator.html&#34;&gt;磁盘使用率超过85%&lt;/a&gt;的节点）。一旦一个节点达到了这个磁盘使用水平，或者 Elasticsearch 称之为 &amp;quot;low disk watermark&amp;quot;，他就不会被分配更多的分片。&lt;/p&gt;
&lt;p&gt;您可以通过查询 &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/cat-allocation.html&#34;&gt;cat API&lt;/a&gt; 检查集群中每个节点上的磁盘空间（并查看每个节点上存储了哪些分片）：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -s &#39;localhost:9200/_cat/allocation?v&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果任何特定节点的磁盘空间不足（删除过时的数据并将其存储在集群外、添加更多节点、升级硬件等），请参阅&lt;a href=&#34;https://www.datadoghq.com/blog/elasticsearch-performance-scaling-problems/#toc-problem-2-help-data-nodes-are-running-out-of-disk-space1&#34;&gt;这篇文件以获取有关如何操作的选项&lt;/a&gt; 。&lt;/p&gt;
&lt;p&gt;如果您的节点具有较大的磁盘容量，则默认的低水位线（85%的磁盘使用率）可能太低。您可以使用&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-update-settings.html&#34;&gt;集群更新设置API&lt;/a&gt; 来更改 &lt;code&gt;cluster.routing.allocation.disk.watermark.low&lt;/code&gt; 和/或 &lt;code&gt;cluster.routing.allocation.disk.watermark.high&lt;/code&gt; 。例如，这个 &lt;a href=&#34;http://stackoverflow.com/questions/33369955/low-disk-watermark-exceeded-on&#34;&gt;Stack Overflow thread&lt;/a&gt; 指出，如果您的节点有 5TB 的磁盘容量，您可能可以安全地 &lt;strong&gt;增加低磁盘水位&lt;/strong&gt; 到 90%：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -XPUT &amp;quot;localhost:9200/_cluster/settings&amp;quot; -H &#39;Content-Type: application/json&#39; -d&#39;
{
  &amp;quot;transient&amp;quot;: {
    &amp;quot;cluster.routing.allocation.disk.watermark.low&amp;quot;: &amp;quot;90%&amp;quot;
  }
}&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果您希望配置更改在集群重新启动时保持不变，请将 &amp;quot;transient&amp;quot; 替换为 &amp;quot;persistent&amp;quot;，或在配置文件中更新这些值。您可以选择使用字节或百分比值来更新这些设置，但请务必记住&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/disk-allocator.html&#34;&gt;Elasticsearch文档&lt;/a&gt; 中的这一重要说明：“百分比值指 &lt;strong&gt;使用的&lt;/strong&gt; 磁盘空间，而字节值是指 &lt;strong&gt;剩余&lt;/strong&gt; 磁盘空间”。&lt;/p&gt;
&lt;h2 id=&#34;原因六多个-elasticsearch-版本&#34;&gt;原因六：多个 Elasticsearch 版本&lt;/h2&gt;
&lt;p&gt;这个entinel只出现在运行多个 Elasticsearch 版本的集群中（可能在&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/rolling-upgrades.html&#34;&gt;滚动升级&lt;/a&gt;的期间）。根据&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/rolling-upgrades.html&#34;&gt;Elasticsearch文档&lt;/a&gt;，主节点不会将主分片的副本分配给任何运行旧版本的节点。例如，如果主分片在 1.4 版本上运行，则主节点将无法将该分片的副本分配给运行 1.4 之前的任何版本的任何节点。&lt;/p&gt;
&lt;p&gt;如果您尝试手动将分片从较新版本的节点重新路由到较旧版本的节点，您将看到如下错误：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[NO(target node version [XXX] is older than source node version [XXX])]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Elasticsearch &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/setup-upgrade.html&#34;&gt;不支持回滚&lt;/a&gt; 到以前的版本，只支持升级。如果这确实是手头的问题，升级运行旧版本的节点应该可以解决问题。&lt;/p&gt;
&lt;h2 id=&#34;你试过把它关掉再打开吗&#34;&gt;你试过把它关掉再打开吗？&lt;/h2&gt;
&lt;p&gt;如果上述情况均不适用您的情况，您仍然可以选择从原始数据与重新索引丢失的数据，或从旧快照恢复受影响的索引，&lt;a href=&#34;https://www.elastic.co/blog/introducing-snapshot-restore&#34;&gt;参考链接&lt;/a&gt;。&lt;/p&gt;
">如何解决 Elasticsearch 中 unassigned shards</a>
      </div>
      
    </div>
  </div>
</div>
<script>
  // var escape = "[{&#34;content&#34;:&#34;&lt;h2 id=\&#34;一-背景\&#34;&gt;一、背景&lt;/h2&gt;\n&lt;p&gt;Java 在 1.5 版本引入了 &lt;code&gt;java.util.concurrent&lt;/code&gt;包，用以支持并发编程，降低并发编程的复杂性；而其中大部分的同步器（例如 &lt;code&gt;lock&lt;/code&gt;, &lt;code&gt;barriers&lt;/code&gt; 等等）都是基于 &lt;code&gt;AbstractQueuedSynchronizer&lt;/code&gt; 类，一般我们称为&lt;code&gt;AQS&lt;/code&gt;。 &lt;code&gt;java.util.concurrent.locks.AbstractQueuedSynchronizer&lt;/code&gt; 出自 &lt;code&gt;Doug Lea&lt;/code&gt; 带佬，他的 &lt;a href=\&#34;https://gee.cs.oswego.edu/\&#34;&gt;个人博客&lt;/a&gt; 上有一篇相关论文 &lt;a href=\&#34;https://gee.cs.oswego.edu/dl/papers/aqs.pdf\&#34;&gt;《The java.util.concurrent Synchronizer Framework》&lt;/a&gt;，在我们深入研究 &lt;code&gt;AQS&lt;/code&gt; 之前，有必要拜读一下该论文，翻译见笔者的另一篇博客&lt;a href=\&#34;https://wenbozhangw.github.io/post/lesslessthe-javautilconcurrent-synchronizer-frameworkgreatergreater-yuan-wen-fan-yi/\&#34;&gt;《The java.util.concurrent Synchronizer Framework》原文翻译&lt;/a&gt; 之后结合相关源码实现进行分析。&lt;/p&gt;\n&lt;!-- more --&gt;\n&lt;h2 id=\&#34;二-aqs概述\&#34;&gt;二、AQS概述&lt;/h2&gt;\n&lt;p&gt;&lt;code&gt;AQS&lt;/code&gt; 是 &lt;code&gt;j.u.c&lt;/code&gt; 包中用来构建同步组件（例如 &lt;code&gt;ReentrantLock&lt;/code&gt;、&lt;code&gt;Semaphore&lt;/code&gt;）的基础框架。从实现上来看，&lt;code&gt;AQS&lt;/code&gt; 提供了原子的同步状态管理、线程的阻塞及唤醒以及存储队列管理模型。基于 &lt;code&gt;AQS&lt;/code&gt; 提供的强大功能，我们可以很简单的构建属于自己的同步器组件。同时，&lt;code&gt;AQS&lt;/code&gt; 也提供了任务取消、阻塞超时以及&lt;code&gt;conditionObject&lt;/code&gt;提供的管程风格的 &lt;code&gt;await/signal/signalAll&lt;/code&gt;操作。并且根据所需策略的不同，&lt;code&gt;AQS&lt;/code&gt; 还提供了&lt;code&gt;公平&lt;/code&gt;/&lt;code&gt;非公平&lt;/code&gt;、&lt;code&gt;独占&lt;/code&gt;/&lt;code&gt;共享&lt;/code&gt; 等特性。&lt;/p&gt;\n&lt;h2 id=\&#34;三-同步器框架原理\&#34;&gt;三、同步器框架原理&lt;/h2&gt;\n&lt;p&gt;&lt;code&gt;AQS&lt;/code&gt; 框架用来实现加锁和解锁的核心是基于 &lt;code&gt;acquire&lt;/code&gt; 和 &lt;code&gt;release&lt;/code&gt; 方法，通过这两个方法，从而去进行原子操作修改同步器状态变量，从而实现对共享资源的并发访问。在 《The java.util.concurrent Synchronizer Framework》 原文中有提到 &lt;code&gt;AQS&lt;/code&gt; 的这两个核心操作实现的伪代码：&lt;/p&gt;\n&lt;p&gt;&lt;code&gt;acquire&lt;/code&gt; 操作如下：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;while(synchronization state does not allow acquire) {\n  enqueue current thread if not already queued;\n  possibly block current thread;\n}\ndequeue current thread if it was queued;\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;简单翻译一下：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;while(同步器状态获取失败) {\n  if (当前线程未进入等待队列) {\n    将当前线程入队；\n  }\n  可能尝试阻塞当前线程;\n}\nif (如果当前线程已经入队) {\n  当前线程出队;\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;&lt;code&gt;release&lt;/code&gt; 操作如下：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;update synchronization state;\nif(state may permit a blocked thread to acquire) \n  unblock one or more queued threads;\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;简单翻译一下：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;更新同步器状态;\nif (同步器状态可以允许一个阻塞线程获取) {\n  解除一个或多个队列线程的阻塞状态;\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;可以看到 &lt;code&gt;AQS&lt;/code&gt; 的核心思想是，如果请求资源空闲（即同步器状态修改成功），将共享资源设置为锁定状态；如果共享资源被占用（即同步器状态修改失败），就需要对当前线程进行入队操作，之后通过阻塞等待唤醒机制来保证锁的分配。这个队列机制主要是通过 CLH 队列的变体来实现的。我们会在下文中对 CLH 队列进行讲述。&lt;/p&gt;\n&lt;h3 id=\&#34;31同步器状态\&#34;&gt;3.1同步器状态&lt;/h3&gt;\n&lt;p&gt;&lt;code&gt;AQS&lt;/code&gt; 类内部定义了一个&lt;code&gt;volatile&lt;/code&gt;修饰的 &lt;code&gt;32&lt;/code&gt; 位 &lt;code&gt;int&lt;/code&gt; 类型的 &lt;code&gt;state&lt;/code&gt; 变量用于维护同步器的状态：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;    /**\n     * 同步状态值\n     */\n    private volatile int state;\n\n    /**\n     * 返回同步状态的当前值。\n     * 该操作的内存语义为{@code volatile} 读。\n     * @return 当前同步状态值\n     */\n    protected final int getState() {\n        return state;\n    }\n\n    /**\n     * 设置同步状态的值。\n     * 该操作具有 {@code volatile} 写的内存语义。\n     * @param newState 新状态值\n     */\n    protected final void setState(int newState) {\n        state = newState;\n    }\n\n    /**\n     * 如果当前状态值等于预期值，则自动将同步状态设置为\n     * 给定的更新值。该操作具有 {@code volatile} 读写\n     * 的内存语义。\n     *\n     * @param expect 期望值\n     * @param update 新值\n     * @return 如果成功，返回{@code true}. 返回 false 表示实际值\n     *\t       与期望值不相等。\n     */\n    protected final boolean compareAndSetState(int expect, int update) {\n        // 见下面的内部设置来支持这一点\n        return unsafe.compareAndSwapInt(this, stateOffset, expect, update);\n    }\n\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;同步器的状态 &lt;code&gt;state&lt;/code&gt; 在不同的实现中会有不同的作用和意义，需要结合具体的使用进行分析（比如说 &lt;code&gt;ReentrantReadWriteLock&lt;/code&gt; 中 &lt;code&gt;state&lt;/code&gt; 的前 16 位记录读锁的数量（共享），后 16 位记录写锁的数量（独占））。另外，我们可以看到，上面关于 &lt;code&gt;state&lt;/code&gt; 的几个方法都是 &lt;code&gt;final&lt;/code&gt; 修饰的，说明子类无法重写它们。我们可以通过修改 &lt;code&gt;state&lt;/code&gt; 字段来表示同步状态加锁的过程。&lt;/p&gt;\n&lt;h3 id=\&#34;32-clh-队列\&#34;&gt;3.2 CLH 队列&lt;/h3&gt;\n&lt;p&gt;&lt;code&gt;CLH&lt;/code&gt;队列：&lt;code&gt;Craig、Landin and Hagersten&lt;/code&gt;队列，基础的 CLH 对列是一个单向链表，而 &lt;code&gt;AQS&lt;/code&gt; 中是用的队列是 CLH 队列的变体——虚拟双向队列（FIFO），因此，该框架是不支持基于优先级的同步。使用同步队列的原因是，它是一种不需要使用低级锁来构造非阻塞数据结构。&lt;/p&gt;\n&lt;p&gt;CLH 队列实际上并不是很像队列，因为它的入队和出队操作都与其用途（作为锁）紧密相关。他通过两个字段 &lt;code&gt;tail&lt;/code&gt; 和 &lt;code&gt;head&lt;/code&gt; 来存取，同时这两个字段支持原子更新，两者在初始化时都指向的空节点。&lt;/p&gt;\n&lt;p&gt;当一个新节点通过原子操作入队：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;do {\n  pred = tail;\n} while (!tail.compareAndSet(pred, node));\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;同时， 每个节点的 &lt;code&gt;release&lt;/code&gt; 状态都保存在其前驱结点中。因此，当前节点可以通过自旋，直到前驱节点释放锁（但是，从实际上来看，过度的自旋会带来大量的 CPU 性能损耗）：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;while (pred.status != RELEASED); // spin\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;自旋后的出队操作只需将 &lt;code&gt;head&lt;/code&gt; 字段指向刚刚得到锁的节点：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;head = node\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;CLH 的优点是：它的入队和出队操作是快速的、无锁的、无阻塞的（即使在竞争的情况下，也只会有一个线程赢得插入的机会，从而能进行下去）。检测是否有线程在等待也很快（只需要检测 &lt;code&gt;head&lt;/code&gt; 和 &lt;code&gt;tail&lt;/code&gt; 是否相等）；同时，&lt;code&gt;release&lt;/code&gt; 是分散的，避免了一些不必要的内存竞争。&lt;/p&gt;\n&lt;p&gt;&lt;code&gt;AQS&lt;/code&gt;中的等待队列是 CLH 锁队列的变体。CLH 锁通常用于自旋锁。但是在 &lt;code&gt;AQS&lt;/code&gt; 中将其作为阻塞同步器，但是根据其基本思想，即在其节点的前驱节点中保存有关线程的控制信息。每个节点的“状态”字段跟踪线程是否应该阻塞。节点在其前驱节点释放时发出 &lt;code&gt;signal&lt;/code&gt; 。否则，队列中的每个节点都是持有单个线程的特定通知器。状态字段不用于控制线程是否持有锁。同时，线程可能会尝试获取队列中的第一个节点，但其并不保证一定成功，所以当前释放的竞争线程可能会重新被阻塞（如果没有获取到锁）。&lt;/p&gt;\n&lt;p&gt;&lt;code&gt;AQS&lt;/code&gt;使用的 CLH 变体中的 &amp;quot;prev&amp;quot; 连接（指向前驱节点）主要用于处理取消。如果一个节点被取消，它的后继节点（通常）需要重新连接到一个未取消的前驱节点。&lt;/p&gt;\n&lt;p&gt;&lt;code&gt;AQS&lt;/code&gt; 使用 CLH 的 &amp;quot;next&amp;quot; 连接（指向后继节点）来实现阻塞机制。每个节点的线程 id 保存在自身中，因此前驱节点通过遍历 next 连接来确定它是哪个线程来通知下一个节点的唤醒。设置当前节点的 next （后继节点）时，必须避免与新入队的节点竞争。当节点的后继节点为空时，通过从队列的 &lt;code&gt;tail&lt;/code&gt; 向后检查来解决这个问题。（&amp;quot;next&amp;quot; 本来就是一种优化，通常情况下是不需要向后扫描的。）&lt;/p&gt;\n&lt;p&gt;CLH 队列需要一个虚拟头节点。但是我们不会在构建时创建它们，因为如果从不存在竞争，那将是浪费精力。相反，在第一次出现竞争时构造节点并设置 &lt;code&gt;head&lt;/code&gt; 和 &lt;code&gt;tail&lt;/code&gt; 指针。&lt;/p&gt;\n&lt;p&gt;&lt;code&gt;Condition&lt;/code&gt; 等待队列中的阻塞线程使用的是相同的 &lt;code&gt;Node&lt;/code&gt; 结构，但是提供了另一个链表来存放，因此 &lt;code&gt;Condition&lt;/code&gt; 等待队列的实现会更加复杂。&lt;/p&gt;\n&lt;p&gt;关于 CLH 队列的实现如下：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;    static final class Node {\n        /** 标记节点处于共享模式下的等待 */\n        static final Node SHARED = new Node();\n        /** 标记节点处于独占模式下的等待 */\n        static final Node EXCLUSIVE = null;\n\n        /** waitStatus 值，表示线程已经取消 */\n        static final int CANCELLED =  1;\n        /** waitStatus 值，表示后继线程需要唤醒 */\n        static final int SIGNAL    = -1;\n        /** waitStatus 值，表示线程需要等待条件 */\n        static final int CONDITION = -2;\n        /**\n         * waitStatus 值，指示下一个 acquireShared 应该无条件传播\n         */\n        static final int PROPAGATE = -3;\n\n        /**\n         * Status 字段, 仅取以下值:\n         *   SIGNAL:     该节点的后继节点被（或即将）阻塞（通过 park），因此当前\n         *               节点在释放或取消时必须解除其后继节点的 park。为了避免\n         *               竞争，acquire 方法必须首先表明它们需要 signal，然后重试\n         *               原子获取，然后在失败时阻塞。\n         *   CANCELLED:  由于超时或中断，该节点被取消。节点永远不会离开这个状态。\n         *\t\t\t\t 特别的是，被取消的节点的线程永远不会再次阻塞。\n         *   CONDITION:  此节点当前位于条件队列中。在转换之前不会用作同步队列节点，\n         *               此时状态将设置为 0。（此处使用此值与该字段的其他用途无关，但简化的机制）\n         *   PROPAGATE:  releaseShared 应该传播到其他节点。这是在 doReleaseShared 中设置 \n         *               的（仅针对头结点），以确保传播继续进行，即使其他操作已经介入。\n         *   0:          以上都不是\n         *\n         * 这些值按数字排列以简化使用。非负值意味着节点不需要发出 signal。\n         * 因此，大多数代码不需要检查特定值，只需检查 sign 即可。\n         *\n         * 对于正常同步节点，该字段初始化为 0，对于 CONDITION 节点，该字段初始化为 CONDITION。\n         * 它使用 CAS 进行修改（或者在可能的情况下，无条件的 volatile 写入）\n         */\n        volatile int waitStatus;\n\n        /**\n         * 链接到当前节点/线程的前驱节点，用于检查 waitStatus。在入队时分配，\n         * 并且仅在出队时设置为 null（为了 GC）。此外，在前驱节点取消时，我们短路，同时\n         * 找到一个未取消的前驱节点（该前驱节点不会不存在），因为头结点不会被取消：一个节点\n         * 只有在 acquire 成功时才会成为头结点。被取消的线程永远不会获取成功，同时\n         * 一个线程只能取消自己，无法取消任何其他节点。\n         */\n        volatile Node prev;\n\n        /**\n         * 链接到当前节点/线程的后继节点，用于在 release 时 unpark 操作。在入队时分配，\n         * 前驱节点取消时，会进行绕过调整，在出队时清空（为了 GC）。enq 操作在建立链接之前\n         * 不会给前驱节点的 next 字段赋值，因此看到 next 字段为 null，并不一定意味着该节点在\n         * 队尾。然而，如果 next 字段看起来是 null，我们可以从 tail 扫描 prev 节点，从而\n         * 进行双重检查。取消的节点的 next 字段被设置为指向节点自身，而不是 null，\n         * 从而使 isOnSyncQueue 的工作更容易。\n         */\n        volatile Node next;\n\n        /**\n         * 将 thread 放入当前节点。构造时初始化，使用后清空。\n         */\n        volatile Thread thread;\n\n        /**\n         * 链接到等待条件的下一个节点，或特定的 SHARED 值。因为条件队列只有在\n         * 独占模式下被访问，所以我们只需要一个简单的链接队列来保存等待条件的节点。\n         * 然后，它们被转移到队列中进行重新 acquire。因为条件只能是独占的，所以\n         * 我们通过使用特殊值来保存特殊值，以表示共享模式。\n         */\n        Node nextWaiter;\n\n        /**\n         * 如果节点在共享模式下等待，则返回true。\n         */\n        final boolean isShared() {\n            return nextWaiter == SHARED;\n        }\n\n        /**\n         * 返回上一个节点，如果为空则抛出NullPointerException。\n         * 当前驱节点不能为空时使用。null 检查可以省略，但它的存在是为了帮助 VM。\n         *\n         * @return 当前节点的前驱节点\n         */\n        final Node predecessor() throws NullPointerException {\n            Node p = prev;\n            if (p == null)\n                throw new NullPointerException();\n            else\n                return p;\n        }\n\n        Node() {    // Used to establish initial head or SHARED marker\n        }\n\n        Node(Thread thread, Node mode) {     // Used by addWaiter\n            this.nextWaiter = mode;\n            this.thread = thread;\n        }\n\n        Node(Thread thread, int waitStatus) { // Used by Condition\n            this.waitStatus = waitStatus;\n            this.thread = thread;\n        }\n    }\n\n    /**\n     * 等待队列的头部，延迟初始化。除此之外，只能通过 setHead 方法进行修改，\n     * 注意：如果 head 存在，它的 waitStatus 保证不会被 CANCELLED。\n     */\n    private transient volatile Node head;\n\n  /**\n   * 等待队列的尾部，延迟初始化。仅通过方法 enq 修改以添加新的等待节点。\n   */\n  private transient volatile Node tail;\n\n  /**\n   * 设置以用于支持 compareAndSet. 我们需要在这里本地实现这一点：\n   * 为了允许未来的功能增强，我们不能显式地继承 AtomicInteger，不然这将是高效和有用的。\n   * 因此，作为少有的弊端，我们本地使用 hotspot 内在的 API 实现。但我们这样做的时候，\n   * 我们队其他 CASable 字段做同样的事情（否则可以用原子字段更新器来完成）。\n   */\n    private static final Unsafe unsafe = Unsafe.getUnsafe();\n    private static final long stateOffset;\n    private static final long headOffset;\n    private static final long tailOffset;\n    private static final long waitStatusOffset;\n    private static final long nextOffset;\n\n    static {\n        try {\n            stateOffset = unsafe.objectFieldOffset\n                (class.getDeclaredField(&amp;quot;state&amp;quot;));\n            headOffset = unsafe.objectFieldOffset\n                (class.getDeclaredField(&amp;quot;head&amp;quot;));\n            tailOffset = unsafe.objectFieldOffset\n                (class.getDeclaredField(&amp;quot;tail&amp;quot;));\n            waitStatusOffset = unsafe.objectFieldOffset\n                (Node.class.getDeclaredField(&amp;quot;waitStatus&amp;quot;));\n            nextOffset = unsafe.objectFieldOffset\n                (Node.class.getDeclaredField(&amp;quot;next&amp;quot;));\n\n        } catch (Exception ex) { throw new Error(ex); }\n    }\n\n    /**\n     * CAS head field. Used only by enq.\n     */\n    private final boolean compareAndSetHead(Node update) {\n        return unsafe.compareAndSwapObject(this, headOffset, null, update);\n    }\n\n    /**\n     * CAS tail field. Used only by enq.\n     */\n    private final boolean compareAndSetTail(Node expect, Node update) {\n        return unsafe.compareAndSwapObject(this, tailOffset, expect, update);\n    }\n\n    /**\n     * CAS waitStatus field of a node.\n     */\n    private static final boolean compareAndSetWaitStatus(Node node,\n                                                         int expect,\n                                                         int update) {\n        return unsafe.compareAndSwapInt(node, waitStatusOffset,\n                                        expect, update);\n    }\n\n    /**\n     * CAS next field of a node.\n     */\n    private static final boolean compareAndSetNext(Node node,\n                                                   Node expect,\n                                                   Node update) {\n        return unsafe.compareAndSwapObject(node, nextOffset, expect, update);\n    }\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;下面介绍一下 &lt;code&gt;Node&lt;/code&gt; 类中的几个属性：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;code&gt;waitStatus&lt;/code&gt;：当前 &lt;code&gt;Node&lt;/code&gt; 的等待状态，共有五个可选值：\n&lt;ul&gt;\n&lt;li&gt;&lt;code&gt;0&lt;/code&gt;：初始值，当前节点如果没有指定初始值，则默认为 &lt;code&gt;0&lt;/code&gt;。&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;CANCELLED(1)&lt;/code&gt;：表示当前节点因为超时或线程中断被取消。当节点被取消后，不会再转换为其他状态，被取消的节点的线程实例也不会阻塞。&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;SIGNAL(-1)&lt;/code&gt;：表示当前节点的后继节点通过 &lt;code&gt;park()&lt;/code&gt; 被阻塞，当前节点释放或取消时，必须 &lt;code&gt;unpark()&lt;/code&gt; 它的后继节点。&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;CONDITION(2)&lt;/code&gt;：表示当前节点是条件队列中的一个节点，当它转换为同步队列中节点时，&lt;code&gt;waitStatus&lt;/code&gt; 会被重新设置为 &lt;code&gt;0&lt;/code&gt;。&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;PROPAGATE(3)&lt;/code&gt;：当节点为头结点，调用 &lt;code&gt;doReleaseShared()&lt;/code&gt; 时，确保 &lt;code&gt;releaseShared()&lt;/code&gt; 可以传播到其他节点。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;prev&lt;/code&gt;：当前节点的前驱节点，用于检查 &lt;code&gt;waitStatus&lt;/code&gt;。当前驱节点被取消时，通过 &lt;code&gt;prev&lt;/code&gt; 找到一个未取消的前驱节点。&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;next&lt;/code&gt;：当前节点的后继节点，当节点被取消或释放时，用于 &lt;code&gt;unpark&lt;/code&gt; 取消后继节点的阻塞（会自动绕过取消的后继节点）。&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;thread&lt;/code&gt;：当前节点持有的线程实例引用。&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;nextWaiter&lt;/code&gt;：下一个等待节点，可能的取值有下面的几种情况：\n&lt;ul&gt;\n&lt;li&gt;当前实例为独占模式时，取值为 &lt;code&gt;Node.EXCLUSIVE&lt;/code&gt; （即 &lt;code&gt;null&lt;/code&gt;）。&lt;/li&gt;\n&lt;li&gt;当前实例为共享模式时，取值为 &lt;code&gt;Node.SHARED&lt;/code&gt;。&lt;/li&gt;\n&lt;li&gt;非上面两种情况时，代表条件队列中当前节点的下一个等待节点。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h3 id=\&#34;33-阻塞\&#34;&gt;3.3 阻塞&lt;/h3&gt;\n&lt;p&gt;在 JDK1.5 之前，线程的阻塞和唤醒只能依赖于 &lt;code&gt;Object&lt;/code&gt; 类提供的 &lt;code&gt;wait()&lt;/code&gt; 、&lt;code&gt;notify()&lt;/code&gt;、&lt;code&gt;notifyAll()&lt;/code&gt; 方法，它们都是由 JVM&lt;br&gt;\n提供实现，并且使用的时候需要获取监视器锁（即需要在 &lt;code&gt;synchronized&lt;/code&gt; 代码块中），没有 Java API 可以阻塞和唤醒线程。唯一可以选择的是 &lt;code&gt;Thread.suspend&lt;/code&gt; 和 &lt;code&gt;Thread.resume&lt;/code&gt;&lt;br&gt;\n，但是他们都有无法解决的竟态问题：当一个非阻塞线程在一个正准备阻塞的线程调用 &lt;code&gt;suspend&lt;/code&gt; 之前调用 &lt;code&gt;resume&lt;/code&gt;，&lt;code&gt;resume&lt;/code&gt;操作将不起作用。&lt;/p&gt;\n&lt;p&gt;&lt;code&gt;j.u.c&lt;/code&gt; 包引入了 &lt;code&gt;LockSupport&lt;/code&gt; 类，其底层是基于 &lt;code&gt;Unsafe&lt;/code&gt; 类的 &lt;code&gt;park()&lt;/code&gt; 和 &lt;code&gt;unpark()&lt;/code&gt; 方法，&lt;code&gt;LockSupport.park&lt;/code&gt;&lt;br&gt;\n阻塞当前线程，除非或直到发出 &lt;code&gt;LockSupport.unpark&lt;/code&gt;（虚假唤醒是允许的）。&lt;code&gt;park&lt;/code&gt; 方法同样支持可选的相对或绝对的超时设置，以及与&lt;br&gt;\nJVM 的 &lt;code&gt;Thread.interrupt&lt;/code&gt; 结合 —— 可通过中断来 &lt;code&gt;unpark&lt;/code&gt; 一个线程。&lt;/p&gt;\n&lt;h3 id=\&#34;34-条件队列\&#34;&gt;3.4 条件队列&lt;/h3&gt;\n&lt;p&gt;在 &lt;code&gt;AQS&lt;/code&gt; 中除了同步队列外，还提供了另一种更为复杂的条件队列，而条件队列是基于 &lt;code&gt;Condition&lt;/code&gt;接口实现的，下面我们先浏览一下 &lt;code&gt;Condition&lt;/code&gt; 接口的说明。&lt;/p&gt;\n&lt;h4 id=\&#34;341-condition-接口\&#34;&gt;3.4.1 Condition 接口&lt;/h4&gt;\n&lt;p&gt;&lt;code&gt;Condition&lt;/code&gt; 将 &lt;code&gt;Object&lt;/code&gt; 的监视器方法（&lt;code&gt;wait&lt;/code&gt;、&lt;code&gt;notify&lt;/code&gt; 和 &lt;code&gt;notifyAll&lt;/code&gt;） 分解到不同的对象，通过将它们与任意的 &lt;code&gt;Lock&lt;/code&gt;&lt;br&gt;\n实现相结合，可以使每个对象具有多个等待集合。&lt;code&gt;Lock&lt;/code&gt; 代替的 &lt;code&gt;synchronized&lt;/code&gt; 方法和语句的使用，&lt;code&gt;Condition&lt;/code&gt; 代替了 &lt;code&gt;Object&lt;/code&gt;&lt;br&gt;\n监视器方法的使用。&lt;/p&gt;\n&lt;p&gt;&lt;code&gt;Condition&lt;/code&gt;（也称为 &lt;em&gt;条件队列(condition queue)&lt;/em&gt; 或 &lt;em&gt;条件变量(condition variable)&lt;/em&gt;）为线程提供了一种暂停执行（“等待”）的方法，直到另外一个线程通知说某个状态条件现在可能为 &lt;code&gt;true&lt;/code&gt;&lt;br&gt;\n。由于对这种共享状态信息的访问会发生在多个不同线程中，所以它必须受到保护，因此需要某种形式的锁与条件相关联。等待条件提供的关键属性是它以 *&lt;br&gt;\n原子* 方式释放关联的锁并挂起当前线程，就像 &lt;code&gt;Object.wait&lt;/code&gt; 一样。&lt;/p&gt;\n&lt;p&gt;&lt;code&gt;Condition&lt;/code&gt; 实例本质上是需要绑定到锁。需要获取特定 &lt;code&gt;Lock&lt;/code&gt; 实例的 &lt;code&gt;Condition&lt;/code&gt; 实例，请使用其 &lt;code&gt;newCondition()&lt;/code&gt; 方法。&lt;/p&gt;\n&lt;p&gt;例如，假设我们有一个支持 put 和 take 方法的有界缓冲区。如果 take 在空缓冲区上尝试获取，则线程将阻塞，知道缓冲区变得可用；如果在一个满的缓冲区上调用 &lt;code&gt;put&lt;/code&gt;，则线程将阻塞，直到有空间可用。我们希望&lt;br&gt;\nput 线程继续等待，并且与 take线程隔开在另一个等待集合中，以便当我们的缓冲区可用或有空间发生变化时通知对应的单个线程。这可以使用量 &lt;code&gt;Condition&lt;/code&gt; 实例来实现。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;class BoundedBuffer {\n    final Lock lock = new ReentrantLock();\n    final Condition notFull = lock.newCondition();\n    final Condition notEmpty = lock.newCondition();\n    \n    final Object[] items = new Object[100];\n    int putptr, takeptr, count;\n    \n    public void put(Object x) throws InterruptedException {\n        lock.lock();\n        try {\n            while (count == items.length) \n                notFull.await();\n            items[putptr] = x;\n            if (++putptr == items.length) putptr = 0;\n            ++count;\n            notEmpty.signal();\n        } finally {\n            lock.unlock();\n        }\n    }\n    \n    public Object take() throws InterrputedException {\n        lock.lock();\n        try {\n            while (count == 0) \n                notEmpty.await();\n            Object x = items[takeptr];\n            if (++takeptr == items.length) takeptr = 0;\n            --count;\n            notFull.signal();\n            return x;\n        } finally {\n            lock.unlock;\n        }\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;(&lt;code&gt;java.util.concurrent.ArrayBlockingQueue&lt;/code&gt; 类提供了这个功能，所以没有理由使用这个实例类。)&lt;/p&gt;\n&lt;p&gt;&lt;code&gt;Condition&lt;/code&gt; 的实现可以提供与 &lt;code&gt;object&lt;/code&gt; 监视器方法不同的行为和语义，例如保证通知的顺序，或者在执行通知时不需要持有锁。如果实现提供了这种专门的语义，那么实现必须记录这些语义。&lt;/p&gt;\n&lt;p&gt;请注意，&lt;code&gt;Condition&lt;/code&gt; 实例只是普通对象，它们本身可以用作 &lt;code&gt;synchronized&lt;/code&gt; 语句中的目标，并且可以调用它们自己的监视器 &lt;code&gt;wait&lt;/code&gt; 和 &lt;code&gt;notification&lt;/code&gt; 方法。获取 &lt;code&gt;Condition&lt;/code&gt; 实例的监视器锁，或使用其监视器方法，与获取和该 &lt;code&gt;Condition&lt;/code&gt; 关联的 &lt;code&gt;Lock&lt;/code&gt; 或使用其 &lt;code&gt;wait()&lt;/code&gt; 和 &lt;code&gt;signal()&lt;/code&gt; 方法没有指定关系。为避免混淆，建议不要以这种方式使用 &lt;code&gt;Condition&lt;/code&gt; 实例，除非在它们自己的实现中。&lt;/p&gt;\n&lt;p&gt;除非另有说明，否则为任何参数传递 &lt;code&gt;null&lt;/code&gt; 值将导致 &lt;code&gt;NullPointerException&lt;/code&gt;。&lt;/p&gt;\n&lt;p&gt;实现注意事项：&lt;/p&gt;\n&lt;p&gt;在等待 &lt;code&gt;Condition &lt;/code&gt; 时，通常允许发生 &lt;em&gt;”虚假唤醒“&lt;/em&gt;&lt;br&gt;\n，作为对底层平台语义的让步。这对大多数应用程序几乎没有实际影响，因为应该始终在循环中等待 &lt;code&gt;Condition&lt;/code&gt;&lt;br&gt;\n，测试正在等待的状态谓词是否为 &lt;code&gt;true&lt;/code&gt;。一个实现可以自由地消除虚假唤醒的可能性，但建议应用程序的程序员总是假设它们可以发生，因此总是在循环中等待条件唤醒。&lt;/p&gt;\n&lt;p&gt;条件等待的三种形式（可中断、不可中断和定时）在某些平台上实现的难易程度和性能特征可能不同。特别是，可能难以提供这些功能并维护特定的语义，例如排序保证。此外，中断线程的实际挂起能力可能并不总是适用所有平台。&lt;/p&gt;\n&lt;p&gt;因次，实现不需要为所有三种等待形式定义完全相同的保证或语义，也不需要支持线程实际挂起的中断。&lt;/p&gt;\n&lt;p&gt;实现需要清楚地记录每个等待方法提供的语义和保证，并且当实现确实支持线程挂起的中断时，它必须遵守此接口中定义的中断语义。&lt;/p&gt;\n&lt;p&gt;由于中断通常意味着取消，并且对中断的检查通常不常见，因此实现可以倾向于响应中断而不是正常的方法返回。即使可以证明中断发生在另一个可能已经解除阻塞线程的操作之后也是如此。一个实现应该记录这个行为。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;public interface Condition {\n\n  /**\n   * 使当前线程等待，直到它被 signal 或中断。\n   *\n   * 直到以下四种情况之一发生时，与此 Condition 关联的锁会被自动释放，并且当前线程\n   * 由于线程调度会被禁用并处于休眠状态：\n   * - 其他某个线程为此 Condition 调用了 signal() 方法，而当前线程恰好被选为要被唤醒的线程；\n   * - 其他一些线程为此 Condition 调用了 signalAll() 方法；\n   * - 其他一些线程中断当前线程，支持中断线程挂起；\n   * - 发生“虚假唤醒”。\n   *\n   * 在所有情况下，在此方法可以返回之前，当前线程必须重新获取获取与此 Condition 关联的锁。\n   * 当前线程返回时，它保证持有这个锁。\n   *\n   * 如果当前线程：\n   * - 在进入此方法时设置其中断状态；或者，\n   * - 等待过程中被中断，支持线程挂起的中断。\n   *\n   * 然后抛出 InterruptedException 并清除当前线程的中断状态。在第一种情况下，没有规定是否\n   * 在释放锁之前进行中断判断。\n   *\n   * 实现注意事项：\n   *\n   * 调用此方法时，假定当前线程持有与此 Condition 关联的锁。由实现决定是否是这种情况，\n   * 如果不是，如何响应。通常，将抛出异常（例如，IllegalMonitorStateException）并且\n   * 实现必须记录该事实。\n   *\n   * 与响应 signal 的正常方法返回相比，实现更倾向于响应中断。在这种情况下，实现必须确保将\n   * 信号量重定向到另一个等待线程（如果有的话）。\n   *\n   * @throws InterruptedException - 如果当前线程被中断（并且支持线程挂起的中断）\n   */\n  void await() throws InterruptedException;\n\n  /**\n   * 使当前线程等待，直到它被 signal。\n   *\n   * 直到以下三种情况之一发生时，与此 Condition 关联的锁会被自动释放，并且当前线程\n   * 由于线程调度会被禁用并处于休眠状态：\n   * - 其他某个线程为此 Condition 调用了 signal() 方法，而当前线程恰好被选为要被唤醒的线程；\n   * - 其他一些线程为此 Condition 调用了 signalAll() 方法；\n   * - 发生“虚假唤醒”。\n   *\n   * 在所有情况下，在此方法可以返回之前，当前线程必须重新获取获取与此 Condition 关联的锁。\n   * 当前线程返回时，它保证持有这个锁。\n   *\n   * 如果当现场进入该方法时设置了中断状态，或者在等待过程中被中断，则继续等待直到被 signal 唤醒。\n   * 当它最终从这个方法返回时，它的中断状态会依旧存在。\n   *\n   *\n   * 实现注意事项：\n   *\n   * 调用此方法时，假定当前线程持有与此 Condition 关联的锁。由实现决定是否是这种情况，\n   * 如果不是，如何响应。通常，将抛出异常（例如，IllegalMonitorStateException）并且\n   * 实现必须记录该事实。\n   *\n   */\n  void awaitUninterruptibly();\n\n  /**\n   * 使当前线程等待，直到它被 signal 或 中断，或者达到指定的等待时间。\n   *\n   * 直到以下五种情况之一发生时，与此 Condition 关联的锁会被自动释放，并且当前线程\n   * 由于线程调度会被禁用并处于休眠状态：\n   * - 其他某个线程为此 Condition 调用了 signal() 方法，而当前线程恰好被选为要被唤醒的线程；\n   * - 其他一些线程为此 Condition 调用了 signalAll() 方法；\n   * - 其他一些线程中断当前线程，支持中断线程挂起；\n   * - 到达指定的等待时间；\n   * - 发生“虚假唤醒”。\n   *\n   * 在所有情况下，在此方法可以返回之前，当前线程必须重新获取获取与此 Condition 关联的锁。\n   * 当前线程返回时，它保证持有这个锁。\n   *\n   * 如果当前线程：\n   * - 在进入此方法时设置其中断状态；或者，\n   * - 等待过程中被中断，支持线程挂起的中断。\n   *\n   * 然后抛出 InterruptedException 并清除当前线程的中断状态。在第一种情况下，没有规定是否\n   * 在释放锁之前进行中断判断。\n   *\n   * 在返回时提供给定的 nanosTimeout 值，该方法返回对剩余等待纳秒数的预估，如果超时，则返回\n   * 小于或等于零的值。在等待返回但是等待的条件仍不成立的情况下，此值可用于确定是否重新等待以及\n   * 重新等待多长时间。此方法的典型用途如以下形式：\n   *\n   * boolean aMethod(long timeout, TimeUnit unit) {\n   *     long nanos = unit.toNanos(timeout);\n   *     lock.lock();\n   *     try {\n   *         while (!conditionBeingWaitedFor()) {\n   *             if (nanos &amp;lt;= 0L) \n   *                 return false;\n   *             nanos = theCondition.awaitNanos(nanos);\n   *         }\n   *         // ...\n   *     } finally {\n   *         lock.unlock();\n   *     }\n   * }\n   *\n   * 设计说明：此方法需要纳秒参数，以避免报告剩余时间时出现截断错误。这种精度损失将使程序员\n   * 难以确保总等待时间不会系统地短于重新等待发生时指定的时间。\n   *\n   * 实现注意事项：\n   *\n   * 调用此方法时，假定当前线程持有与此 Condition 关联的锁。由实现决定是否是这种情况，\n   * 如果不是，如何响应。通常，将抛出异常（例如，IllegalMonitorStateException）并且\n   * 实现必须记录该事实。\n   *\n   * 与响应 signal 的正常方法返回相比，实现更倾向于响应中断。在这种情况下，实现必须确保将\n   * 信号量重定向到另一个等待线程（如果有的话）。\n   *\n   * 参数： nanosTimeout - 等待的最长时间，以纳秒为单位。\n   * 返回： nanosTimeout值减去从该方法返回时等待的时间的估计值。正值表示可以用作对该方法的\n   *       后续调用以完成等待所需时间的参数。小于或等于零表示没有剩余的时间。\n   * @throws InterruptedException - 如果当前线程被中断（并且支持线程挂起的中断）\n   */\n  long awaitNanos(long nanosTimeout) throws InterruptedException;\n\n  /**\n   * 使当前线程等待，直到它被 signal 或 中断，或者达到指定的等待时间。此方法在行为上等效于：\n   *     awaitNanos(unit.toNanos(time)) &amp;gt; 0 \n   *\n   * 参数： time - 等待的最长时间\n   *       unit - time 参数的时间单位\n   * 返回： 如果从方法返回之前已经到达指定时间，则为 false，否则为 true。\n   * @throws InterruptedException - 如果当前线程被中断（并且支持线程挂起的中断）\n   */\n  boolean await(long time, TimeUnit unit) throws InterruptedException;\n\n  /**\n   * 使当前线程等待，直到它被 signal 或 中断，或者达到指定的等待时间。\n   *\n   * 直到以下五种情况之一发生时，与此 Condition 关联的锁会被自动释放，并且当前线程\n   * 由于线程调度会被禁用并处于休眠状态：\n   * - 其他某个线程为此 Condition 调用了 signal() 方法，而当前线程恰好被选为要被唤醒的线程；\n   * - 其他一些线程为此 Condition 调用了 signalAll() 方法；\n   * - 其他一些线程中断当前线程，支持中断线程挂起；\n   * - 到达指定的等待时间；\n   * - 发生“虚假唤醒”。\n   *\n   * 在所有情况下，在此方法可以返回之前，当前线程必须重新获取获取与此 Condition 关联的锁。\n   * 当前线程返回时，它保证持有这个锁。\n   *\n   * 如果当前线程：\n   * - 在进入此方法时设置其中断状态；或者，\n   * - 等待过程中被中断，支持线程挂起的中断。\n   *\n   * 然后抛出 InterruptedException 并清除当前线程的中断状态。在第一种情况下，没有规定是否\n   * 在释放锁之前进行中断判断。\n   *\n   * 返回值表示是否已经过了 deadline，可以如下使用：\n   *\n   * 实现注意事项：\n   *\n   * 调用此方法时，假定当前线程持有与此 Condition 关联的锁。由实现决定是否是这种情况，\n   * 如果不是，如何响应。通常，将抛出异常（例如，IllegalMonitorStateException）并且\n   * 实现必须记录该事实。\n   *\n   * 与响应 signal 的正常方法返回相比，实现更倾向于响应中断。在这种情况下，实现必须确保将\n   * 信号量重定向到另一个等待线程（如果有的话）。\n   * boolean aMethod(Date deadline) {\n   *     boolean stillWaiting = true;\n   *     lock.lock();\n   *     try {\n   *         while(!conditionBeingWaitedFor()) {\n   *             if (!stillWaiting)\n   *                 return false;\n   *             stillWaiting = theCondition.awaitUntil(deadline);\n   *         }\n   *         // ...\n   *     } finally {\n   *         lock.unlock();\n   *     }\n   * }\n   *\n   * 参数： deadline - 等待的绝对时间。\n   * 返回： 如果返回时已经超过最后期限，则为 false，否则为 true。\n   * @throws InterruptedException - 如果当前线程被中断（并且支持线程挂起的中断）\n   */\n  boolean awaitUntil(Date deadline) throws InterruptedException;\n\n  /**\n   * 唤醒一个等待线程。\n   *\n   * 如果有任何线程在此 Condition 下等待，则选择一个用于唤醒。然后，该线程必须在从\n   * await 返回之前重新获取锁。\n   *\n   * 实现注意事项\n   *\n   * 在调用此方法时，实现可能（并且通常确实）要求当前线程持有与此 Condition 关联的锁。\n   * 实现必须记录此前提条件以及未持有锁时采取的任何操作。通常，会抛出 IllegalMonitorStateException。\n   */\n  void signal();\n\n  /**\n   * 唤醒所有等待线程。\n   *\n   * 如果有任何线程在此 Condition 下等待，则它们全部都会被唤醒。然后，每个线程必须在从\n   * await 返回之前重新获取锁。\n   *\n   * 实现注意事项\n   *\n   * 在调用此方法时，实现可能（并且通常确实）要求当前线程持有与此 Condition 关联的锁。\n   * 实现必须记录此前提条件以及未持有锁时采取的任何操作。通常，会抛出 IllegalMonitorStateException。\n   */\n  void signalAll();\n}\n\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;&lt;code&gt;Condition&lt;/code&gt; 接口提供了与 JAVA 原生的监视器相同风格的 API，但是其并不依赖于 JVM 的实现，用户可以自定义实现 &lt;code&gt;Condition&lt;/code&gt;&lt;br&gt;\n接口，提供更加强大和更加灵活的功能，&lt;code&gt;Condition&lt;/code&gt; 在说明中建议和 &lt;code&gt;Lock&lt;/code&gt;&lt;br&gt;\n共同使用，可以使每个对象具有多个等待集合，我们下面了解一下 &lt;code&gt;Lock&lt;/code&gt; 接口 。&lt;/p&gt;\n&lt;h4 id=\&#34;342-lock-接口\&#34;&gt;3.4.2 Lock 接口&lt;/h4&gt;\n&lt;p&gt;与使用 &lt;code&gt;synchronized&lt;/code&gt; 方法和语句相比，&lt;code&gt;Lock&lt;/code&gt;&lt;br&gt;\n实现提供了更广泛的锁定操作。它们允许更灵活的结构，可能具有完全不同的属性，并且可能支持多个关联的 &lt;code&gt;Condition&lt;/code&gt; 对象。&lt;/p&gt;\n&lt;p&gt;&lt;code&gt;Lock&lt;/code&gt; 是一种控制多线程访问共享资源的工具。通常，&lt;code&gt;Lock&lt;/code&gt;&lt;br&gt;\n提供对共享资源的独占访问：一次只有一个线程可以获得锁，并且堆共享资源的所有访问都需要首先获取锁。但是，某些锁可能允许并发访问共享资源，例如 &lt;code&gt;ReadWriteLock&lt;/code&gt;&lt;br&gt;\n的读锁。&lt;/p&gt;\n&lt;p&gt;&lt;code&gt;synchronized&lt;/code&gt; 方法或语句的使用提供了对于每个对象关键的隐式监视器锁的访问，但强制所有锁的获取和释放必须在块结构内发生：当获取多个锁时，它们必须以相反的顺序释放，并且所有锁必须在获得它们的相同词法范围内释放。&lt;/p&gt;\n&lt;p&gt;虽然 &lt;code&gt;synchronized&lt;/code&gt;&lt;br&gt;\n方法和语句的作用域机制让使用监视器锁编程变得更加容易，并且有助于避免许多设计锁的常见编程错误，但在某些情况下，您需要以更加灵活的方式使用锁。例如，一些遍历并发访问的数据结构的算法需要使用 &lt;code&gt;hand-over-hand&lt;/code&gt;&lt;br&gt;\n或 &lt;code&gt;chain locking&lt;/code&gt;：你获取节点 A 的锁，然后获取节点 B 的锁，然后释放 A 并获取 C，然后释放 B 并获取 D 等等。&lt;code&gt;Lock&lt;/code&gt;&lt;br&gt;\n接口的实现通过允许在不同范围内获取和释放锁以及允许以任意顺序获取和释放多个锁，来启用此类技术。&lt;/p&gt;\n&lt;p&gt;随着这种灵活性的增加，额外的责任也随之而来。块结构锁定的缺失消除了 &lt;code&gt;synchronized&lt;/code&gt; 方法和语句发生的锁定和自动释放。在大多数情况下，应使用以下语句：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;Lock l=...;\nl.lock();\ntry{\n    // access the resource protected by this lock\n}finally{\n    l.unlock;\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;当锁定和解锁发生在不同范围内时，必须注意确保所有在持有锁时执行的代码都受到 &lt;code&gt;try-finally&lt;/code&gt; 或 &lt;code&gt;try-catch&lt;/code&gt; 的保护，以确保在必要时释放锁。&lt;/p&gt;\n&lt;p&gt;&lt;code&gt;Lock&lt;/code&gt; 实现通过提供非阻塞获取锁定方式（&lt;code&gt;tryLock()&lt;/code&gt;）、获取可中断锁的尝试（&lt;code&gt;lockInterruptibly()&lt;/code&gt;&lt;br&gt;\n，以及获取锁的尝试）、还提供了超过使用 &lt;code&gt;synchronized&lt;/code&gt; 方法和语句的附加功能 —— 可以超时（&lt;code&gt;tryLock(long, Timeunit)&lt;/code&gt;）。&lt;/p&gt;\n&lt;p&gt;&lt;code&gt;Lock&lt;/code&gt; 类还可以提供与隐式监视器锁完全不同的行为和语义，例如保证排序、不可重入使用或死锁检测。如果实现提供了这种专门的语义，那么实现必须用文档记录这些语义。&lt;/p&gt;\n&lt;p&gt;请注意，&lt;code&gt;Lock&lt;/code&gt; 实例只是普通对象，它们本身可以用作 &lt;code&gt;synchronized&lt;/code&gt; 语句中的目标。获取 &lt;code&gt;Lock&lt;/code&gt;&lt;br&gt;\n实例的监视器锁与调用该实例的任何 &lt;code&gt;lock() &lt;/code&gt;&lt;br&gt;\n方法没有指定关系。建议为避免混淆，除非在它们自己的实现中，否则不要以这种方式使用 &lt;code&gt;Lock&lt;/code&gt; 实例。&lt;/p&gt;\n&lt;p&gt;除非另有说明，否则任何参数传递 &lt;code&gt;null&lt;/code&gt; 将导致 &lt;code&gt;NullPointerException&lt;/code&gt;。&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;内存同步&lt;/strong&gt;：&lt;/p&gt;\n&lt;p&gt;所有 &lt;code&gt;Lock&lt;/code&gt; 实现&lt;em&gt;必须&lt;/em&gt;&lt;br&gt;\n强制执行与内置监视器锁提供的相同的内存同步语义。如 &lt;a href=\&#34;https://docs.oracle.com/javase/specs/jls/se7/html/jls-17.html#jls-17.4\&#34;&gt;《The Java Language Specification (17.4 Memory Model) 》&lt;/a&gt;&lt;br&gt;\n中所述：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;成功的 &lt;em&gt;Lock&lt;/em&gt; 动作与成功的 &lt;code&gt;lock()&lt;/code&gt; 操作具有相同的内存同步效果。&lt;/li&gt;\n&lt;li&gt;成功的 &lt;em&gt;Unlock&lt;/em&gt; 动作与成功的 &lt;code&gt;unlock()&lt;/code&gt; 操作具有相同的内存同步效果。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;不成功的 lock 和 unlock 操作，以及重入 lock/unlock 操作，不需要任何内存同步效果。&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;实现注意事项&lt;/strong&gt;：&lt;/p&gt;\n&lt;p&gt;三种形式的锁获取（可中断、不可中断和超时）可能在它们的性能特征、顺序保证或其他实现质量方面有所不同。此外，中断 &lt;em&gt;正在进行&lt;/em&gt;&lt;br&gt;\n的锁获取的能力在给定的 &lt;code&gt;Lock&lt;/code&gt;&lt;br&gt;\n类中可能不可用。因此，实现不需要为所有的三种形式的锁获取给定完全相同的保证或语义，也不需要支持正在进行的锁获取的中断。实现需要清楚地记录每个锁定方法提供的语义和保证。它们必须遵守此接口中定义的中断语义，一直吃获取锁的中断：完全或仅在方法入口上。&lt;/p&gt;\n&lt;p&gt;由于中断通常意味着取消，并且对中断的检查通常不常见，因此实现可以倾向于响应中断而不是正常的方法返回。即使可以证明在另一个操作可能已解除阻塞线程之后发生中断也是如此。实现应该用文档记录这个行为。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;public interface Lock {\n\n  /**\n   * 获取锁。\n   *\n   * 如果锁不可用，则当前线程处于线程调度的目的，将被禁用并处于休眠状态，直到获得锁为止。\n   *\n   * 实现注意事项\n   *\n   * Lock 实现可能能够检测到锁的错误使用，例如会导致死锁的调用，并且在这种情况下可能会抛出\n   * （未经检查）的异常。该 Lock 实现必须描述和记录情况以及异常类型。\n   */\n  void lock();\n\n  /**\n   * 除非当前线程被中断，否则获取锁。\n   *\n   * 如果可用，则获取锁并立即返回。\n   *\n   * 如果锁不可用，则当前线程处于线程调度的目的，将被禁用并处于休眠状态，直到发生以下两种情况之一：\n   * - 锁被当前线程获取；\n   * - 其他一些线程中断当前线程，当前线程支持获取锁的中断。\n   *\n   * 如果当前线程：\n   * - 在进入此方法时设置其中断状态；\n   * - 获取锁时中断，并支持获取锁中断。\n   *\n   * 然后会抛出 InterruptedException 并清除当前线程的中断状态。\n   *\n   *\n   * 实现注意事项\n   *\n   * 在某些实现中中断锁获取的能力可能是无法实现的，并且如果可能的话会是一个非常昂贵的操作。\n   * 程序员应该意识到可能是这种情况，并详细记录和描述这种情况。。\n   *\n   * 与正常方法返回相比，实现更倾向于响应中断。\n   *\n   * Lock 实现可能能够检测到锁的错误使用，例如会导致死锁的调用，并且在这种情况下可能会抛出\n   * （未经检查的）异常。该 Lock 实现必须详细记录情况和异常类型。\n   *\n   * @throws InterruptedException - 如果当前线程在获取锁时被中断（并且支持获取锁的中断）\n   */\n  void lockInterruptibly() throws InterruptedException;\n\n  /**\n   * 仅当调用时是空闲的，才获取到锁。\n   *\n   * 如果锁可用，则获取锁并立即返回 true。如果锁不可用，则此方法立即返回 false。\n   *\n   * 该方法的典型用法是：\n   *\n   * Lock lock = ...;\n   * if (lock.tryLock()) {\n   *     try {\n   *         // manipulate protected state\n   *     } finally {\n   *         lock.unlock();\n   *     }\n   * } else {\n   *     // perform alternative actions\n   * }\n   *\n   * 这种方法确保锁在获得的情况下才解锁，并且在未获得的时候不进行解锁操作。\n   *\n   * 返回： 如果获得了锁返回 true，否则为 false。\n   */\n  boolean tryLock();\n\n  /**\n   * 如果在给定的等待时间内锁空闲并且当前线程没有被中断，则获取锁。\n   *\n   * 如果锁可用，则获取锁并立即返回 true。如果锁不可用，则当前线程处于线程调度的目的，\n   * 将被禁用并处于休眠状态，直到发生以下三种情况之一：\n   * - 锁被当前线程获取；\n   * - 其他一些线程中断当前线程，当前线程支持获取锁的中断；\n   * - 指定的等待时间已过。\n   *\n   * 如果获得锁，则返回 true。\n   *\n   * 如果当前线程：\n   * - 在进入此方法时设置其为中断状态；或\n   * - 获取锁时中断，并支持获取锁中断。\n   *\n   * 然后会抛出 InterruptedException 并清除当前线程的中断状态。\n   *\n   * 如果经过了指定的等待时间，则返回 false。如果时间小于或等于 0，则该方法不会等待。\n   *\n   * 实现注意事项\n   *\n   * 在某些实现中中断锁获取的能力可能是无法实现的，并且如果可能的话会是一个非常昂贵的操作。\n   * 程序员应该意识到可能是这种情况，并详细记录和描述这种情况。。\n   *\n   * 与正常方法返回相比，实现更倾向于响应中断。\n   *\n   * Lock 实现可能能够检测到锁的错误使用，例如会导致死锁的调用，并且在这种情况下可能会抛出\n   * （未经检查的）异常。该 Lock 实现必须详细记录情况和异常类型。\n   *\n   * 参数： time - 等待锁的最长时间\n   *       unit - time 参数的时间单位\n   * 返回： 如果获得了锁，返回 true；如果在获得锁之前超过了等待时间，返回 false\n   * @throws InterruptedException - 如果当前线程在获取锁时被中断（并且支持获取锁的中断）\n   */\n  boolean tryLock(long time, TimeUnit unit) throws InterruptedException;\n\n  /**\n   * 释放锁。\n   *\n   * 实现注意事项\n   *\n   * Lock 实现通常会对哪个线程可以释放锁施加限制（通常只有锁的持有者可以释放它），\n   * 并且如果违反限制可能会抛出（未经检查的）异常。该 Lock 实现必须详细记录情况和异常类型。\n   */\n  void unlock();\n\n  /**\n   * 返回绑定到此 Lock 实例的新 Condition 实例。\n   *\n   * 在等待条件之前，锁必须由当前线程持有。调用 Condition.await() 将在等待之前自动释放\n   * 锁，并在等待返回之前重新获取锁。\n   *\n   * 实现注意事项\n   *\n   * Condition 实例的确切操作取决于 Lock 实现，并且必须由该实现描述。\n   *\n   *\n   * 返回：此 Lock 实例的新 Condition 实例\n   * @throws UnsupportedOperationException - 如果 Lock 实现不支持 Condition\n   */\n  Condition newCondition();\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h2 id=\&#34;四-aqs-的独占与共享\&#34;&gt;四、AQS 的独占与共享&lt;/h2&gt;\n&lt;p&gt;在 &lt;code&gt;AQS&lt;/code&gt; 的设计中，为我们保留的扩展的能力，我们可以使用 &lt;code&gt;ConditionObject&lt;/code&gt; 和 &lt;code&gt;AQS&lt;/code&gt;&lt;br&gt;\n去实现共享资源的独占和共享，就和 &lt;code&gt;ReadWriteLock&lt;/code&gt; 一样，下面我们根据 &lt;code&gt;AQS&lt;/code&gt; 的源码来解析这两种模式是如何实现的。&lt;/p&gt;\n&lt;h3 id=\&#34;41-独占模式\&#34;&gt;4.1 独占模式&lt;/h3&gt;\n&lt;p&gt;独占模式：意味着同一时刻，共享资源只有唯一的单个节点可以获取访问，此时获取到锁的节点的线程是独享的，获取到锁的线程也就从阻塞状态可以继续运行，而同步队列的其他节点则需要继续阻塞。&lt;/p&gt;\n&lt;p&gt;独占模式的实现主要由 &lt;code&gt;AQS&lt;/code&gt; 在初始化时， &lt;code&gt;status&lt;/code&gt; 值来确定允许申请资源的数量上限，而对共享资源的获取和释放主要由以下方法进行操作：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;code&gt;acquire(int)&lt;/code&gt; ：获取 int 数量的资源，也就是原子修改 &lt;code&gt;status&lt;/code&gt;。&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;acquireInterruptibly(int)&lt;/code&gt;：获取 int 数量的资源，可以响应线程中断。&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;tryAcquireNanos(int, long)&lt;/code&gt; ：在指定 long 时间内，获取 int 数量的资源。&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;release(int)&lt;/code&gt; ：释放 int 数量的资源。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h4 id=\&#34;411-acquire\&#34;&gt;4.1.1 acquire&lt;/h4&gt;\n&lt;p&gt;下面我们根据源码，了解一下独占模式是如何运行的，首先是 &lt;code&gt;acquire&lt;/code&gt;：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;/**\n * 以独占模式获取锁，忽略中断。  通过调用至少一次 tryAcquire() 方法来实现，成功就返回。\n * 否则线程排队，调用 tryAcquire() 成功之前，可能重复阻塞和解除阻塞。此方法可用于实现\n * Lock.lock()。\n *\n * 参数：arg - acquire 参数。这个值被传递给 tryAcquire，你可以用此代表你喜欢的任何东西。\n */\npublic final void acquire(int arg){\n    // 只有当加锁成功或以独占类型节点入队（同步队列，非条件队列）成功时返回，\n    if(!tryAcquire(arg) &amp;amp;&amp;amp;\n       // 加锁失败，则进行入队操作\n       acquireQueued(addWaiter(Node.EXCLUSIVE), arg))\n         // 加锁失败，入队失败，则中断线程\n         selfInterrupt();\n}\n\n/**\n * 尝试以独占模式 acquire。此方法应查询对象的状态，判断是否允许以独占模式获取它。\n *\n * 此方法始终由执行 acquire 的线程调用。如果此方法报告失败，且该线程尚未入队，\n * 则 acquire 方法可以将该线程排队，知道某个其他线程 release 并 signal。这\n * 可用于实现 Lock.tryLock 方法。\n *\n * 默认实现抛出 UnsupportedOperationException 。\n *\n * 参数：arg - acquire 参数.。该值始终是传递给 acquire 方法的值，或者是在进入条件等待时\n 保存的值。该值可以表示你喜欢的任何东西。\n * 返回：如果成功，返回 true。成功后，该对象已 acquire。\n * @throws IllegalMonitorStateException  如果获取会将此同步器置于非法状态。\n *                                       必须以一致的方式抛出此异常，同步才能正常工作。\n * @throws UnsupportedOperationException 如果不支持独占模式\n */\nprotected boolean tryAcquire(int arg){\n    throw new UnsupportedOperationException();\n}\n\n\n/**\n * 为当前线程和给定模式创建节点并入队节点。\n *\n * 参数：mode - Node.EXCLUSIVE 用于独占，Node.SHARED 用于共享\n * 返回：新节点\n */\nprivate Node addWaiter(Node mode){\n    // 创建当前线程和模式的新节点，此时 waitStatus 为 0\n    Node node = new Node(Thread.currentThread(), mode);\n    // 先尝试直接入队，当且仅当 tail 不为空时，直接将当前节点追加到 tail 后面\n    Node pred = tail;\n    if(pred != null){\n        // 当前节点的前驱节点为 pred\n        node.prev = pred;\n        // 原子修改 tail 为当前节点\n        if(compareAndSetTail(pred, node)){\n            // pred 的后继节点指向当前节点\n            pred.next = node;\n            return node;\n        }\n    }\n    // tail 为空，或入队失败，则进行自旋 enq 入队\n    enq(node);\n    return node;\n}\n\n/**\n * 将节点插入队列，必要时进行初始化。\n * 参数： node - 插入的节点\n * 返回： 节点的前驱节点\n */\nprivate Node enq(final Node node){\n    // 自旋进行插入操作\n    for(;;){\n        // 获取队列的 tail\n        Node t = tail;\n        // t 为空，说明队尾没有节点，说明还没有初始化\n        if(t == null){ // Must initialize\n            // 初始化操作，创建 head 节点\n            if(compareAndSetHead(new Node()))\n                // 将 tail 也指向 head\n            tail = head;\n        } else {\n            // 将队尾指向当前节点的前驱节点\n            node.prev = t;\n            // 设置当前节点为队尾\n            if(compareAndSetTail(t, node)){\n                // 设置 t 的后继节点为当前节点\n                t.next = node;\n                return t;\n            }\n        }\n    }\n}\n\n\n/**\n * 以独占模式且不中断，acquire 队列中的线程。由 condition 的 wait 和 acquire 方法使用。\n *\n * 参数：node - 节点\n *      arg - acquire 参数\n * 返回：如果在等待时被中断，返回 true\n */\nfinal boolean acquireQueued(final Node node,int arg){\n    // acquire 是否失败\n    boolean failed = true;\n    try {\n        // 是否中断\n        boolean interrupted = false;\n        // 自旋尝试获取资源，每次自旋都会调用 tryAcquire 尝试获取资源，获取资源失败，则进入阻塞状态\n        // 成功则跳出自旋\n        for(;;){\n            // 当前新入队节点的前驱节点\n            final Node p = node.predecessor();\n            // 前驱节点为头节点时，尝试获取资源。\n            if(p == head &amp;amp;&amp;amp; tryAcquire(arg)){\n                // 获取资源成功，将当前节点设置为头结点\n                setHead(node);\n                // 断开前一个节点的链接，帮助 GC\n                p.next = null; // help GC\n                // 获取成功\n                failed = false;\n                // 返回是否中断\n                return interrupted;\n            }\n            // 判断在 acquire 失败后是否需要阻塞当前节点中的线程\n            if(shouldParkAfterFailedAcquire(p,node)&amp;amp;&amp;amp;\n                parkAndCheckInterrupt())\n                interrupted =true;\n            }\n    } finally {\n        if(failed)\n            cancelAcquire(node);\n    }\n}\n\n/**\n * 检查并更新 acquire 失败的节点的状态。如果线程应该阻塞，则返回 true。\n * 这是所有循环 acquire 获取资源的主要 signal 控制方法。要求 pred == node.prev。\n *\n * 参数：pred - 节点的前驱节点持有的状态\n *      node - 当前节点\n * 返回：如果线程应该阻塞，返回 true。\n */\nprivate static boolean shouldParkAfterFailedAcquire(Node pred,Node node){\n    // 前驱节点的等待状态\n    int ws=pred.waitStatus;\n    // 前驱结点状态为 SIGNAL，说明当前节点可以阻塞，pred 在完成后需要调用 release\n    if(ws == Node.SIGNAL)\n        /*\n         * 前驱节点状态设置为 Node.SIGNAL，等待被 release 调用释放，后继节点可以安全地进入阻塞。\n         */\n        return true;\n    if(ws &amp;gt; 0) {\n        /*\n         * 前驱节点为 CANCELLED，尝试把所有 CANCELLED 的前驱节点移除，找到一个\n         * 非取消的前驱节点。\n         */\n        do {\n            node.prev = pred = pred.prev;\n        } while (pred.waitStatus &amp;gt; 0);\n        pred.next=node;\n    } else {\n        /*\n         * waitStatus 为 0 或 PROPAGATE.  表示我们需要一个 signal，\n         * 而不是阻塞。调用者需要重试以确保在阻塞前无法 acquire。\n         */\n        compareAndSetWaitStatus(pred,ws,Node.SIGNAL);\n    }\n    return false;\n}\n\n/**\n * park 后检查是否中断的便捷方法\n *\n * 返回：如果中断，返回true\n */\nprivate final boolean parkAndCheckInterrupt(){\n    // park 当前线程\n    LockSupport.park(this);\n    // 判断是否中断\n    return Thread.interrupted();\n}\n\n\n/**\n * 将队列 head 设置为 node，从而使之前的节点出队。仅由 acquire 方法调用。\n * 为了 GC 和抑制不必要的 signal 和遍历，同时也清空无用的字段。\n *\n * 参数：node - 节点\n */\nprivate void setHead(Node node){\n    head=node;\n    node.thread=null;\n    node.prev=null;\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;依旧使用上面的例子，当 &lt;code&gt;thread-1&lt;/code&gt; 入队时，此时队列为空，需要初始化一个空节点，之后将调用 &lt;code&gt;addWaiter()&lt;/code&gt; 将  &lt;code&gt;thread-1&lt;/code&gt; 入队：&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;1\&#34;&gt;&lt;img src=\&#34;/Users/wenbo.zhang/Desktop/images/AQS-thread-1-enq.png\&#34; alt=\&#34;aqs-thread-1-enq\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;此时，在 &lt;code&gt;thread-1&lt;/code&gt; 等待过程中，将 &lt;code&gt;thread-2&lt;/code&gt; 进行入队操作：&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;2\&#34;&gt;&lt;img src=\&#34;/Users/wenbo.zhang/Desktop/images/AQS-thread-2-enq.png\&#34; alt=\&#34;aqs-thread-2-enq\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;以上就是 &lt;code&gt;tryAcquire&lt;/code&gt; 失败后的入队逻辑，可以看到，在节点进行入队时，会修改前驱节点的 waitStatus，当前驱节点 &lt;code&gt;release&lt;/code&gt;&lt;br&gt;\n时，会进行哪些操作呢？下面我们对 &lt;code&gt;release&lt;/code&gt; 操作进行解析。&lt;/p&gt;\n&lt;h4 id=\&#34;412-release\&#34;&gt;4.1.2 release&lt;/h4&gt;\n&lt;p&gt;在独占模式中，&lt;code&gt;release()&lt;/code&gt; 用来释放资源，下面我们根据源码来解读 &lt;code&gt;AQS&lt;/code&gt; 如何进行释放操作。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;/**\n * 释放独占模式。如果 tryRelease 返回 true，则通过解锁一个或多个线程实现。此方法可以\n * 用来实现方法 Lock.unlock.\n *\n * 参数：arg - release 参数。这个值被传递给 tryRelease，你可以用它表示任何你喜欢的东西。\n * 返回：tryRelease 返回的值\n */\npublic final boolean release(int arg){\n    // 尝试释放资源\n    if(tryRelease(arg)){\n        Node h=head;\n        // head 不为空，且 waitStatus 不为 0 的情况下，唤醒后继节点\n        if(h!=null&amp;amp;&amp;amp;h.waitStatus!=0)\n        // 后继节点解除阻塞\n        unparkSuccessor(h);\n        return true;\n    }\n    return false;\n}\n\n/**\n * 尝试设置状态，以体现独占模式下的 release。\n *\n * 该方法总是由执行 release 的线程调用。\n *\n * 默认实现抛出 UnsupportedOperationException。\n *\n * 参数：arg - release 参数。此值始终是传递给 release 方法的值，或者是进入条件等待时的\n *            当前状态值。该值是未解释的，可以表示任何你想要的内容。\n * 返回：如果当前对象现在完全释放，则返回 true，以便任何等待的线程都可以尝试 acquire；否则 false。\n * @throws IllegalMonitorStateException - 如果 release 会将此同步器置于非法状态。\n *                                        必须以一致的方式抛出此异常，同步器才能正常工作。\n * @throws UnsupportedOperationException - 如果不支持独占模式\n */\nprotected boolean tryRelease(int arg){\n    throw new UnsupportedOperationException();\n}\n\n/**\n * 如果节点存在后继节点，则唤醒后继节点。\n *\n * 参数：node - 节点\n */\nprivate void unparkSuccessor(Node node){\n    /*\n     * 如果状态为负数（即可能需要 signal），尝试 clear 以等待 signal。\n     * 允许失败或等待线程更改状态。\n     */\n    int ws = node.waitStatus;\n    if(ws &amp;lt; 0)\n        // 将当前节点的 waitStatus 置为 0\n        compareAndSetWaitStatus(node, ws, 0);\n\n    /*\n     * 当前线程的后继节点 unpark ，通常只是下一个节点。但如果下个节点为空或\n     * 已经取消，则从 tail 向后遍历以找到实际未取消的后继节点。\n     */\n    Node s=node.next;\n    // 后继节点为空，或后继节点是 CANCELLED\n    if(s == null || s.waitStatus &amp;gt; 0){\n        s = null;\n    // 从 tail 开始，向 head 遍历，找到最接近 当前节点的不为空且未取消的节点\n    for(Node t = tail;t != null &amp;amp;&amp;amp; t != node; t = t.prev)\n        if(t.waitStatus &amp;lt;= 0)\n            s = t;\n    }\n    // 找到之后，unpark 节点线程阻塞状态\n    if(s != null)\n        LockSupport.unpark(s.thread);\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;当 &lt;code&gt;release&lt;/code&gt; 操作成功 &lt;code&gt;unpark&lt;/code&gt; 一个线程后，该线程在通过 &lt;code&gt;acquireQueued&lt;/code&gt; 进行 &lt;code&gt;tryAcquire&lt;/code&gt;&lt;br&gt;\n成功后，就会将头结点设置为当前节点，并将之前的头结点以及线程字段置空，以方便 GC 回收，&lt;code&gt;thread-1&lt;/code&gt; 获取到锁在执行过程中，状态如下：&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;3\&#34;&gt;&lt;img src=\&#34;/Users/wenbo.zhang/Desktop/images/AQS-thread-1-release.png\&#34; alt=\&#34;aqs-thread-1-release\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;&lt;code&gt;thread-1&lt;/code&gt; 执行完成后，对 &lt;code&gt;thread-2&lt;/code&gt; 进行 unpark 后，状态如下：&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;4\&#34;&gt;&lt;img src=\&#34;/Users/wenbo.zhang/Desktop/images/AQS-thread-2-release.png\&#34; alt=\&#34;aqs-thread-2-release\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;h4 id=\&#34;413-acquireinterruptibly\&#34;&gt;4.1.3 acquireInterruptibly&lt;/h4&gt;\n&lt;p&gt;下面我们对 &lt;code&gt;acquire&lt;/code&gt; 的变体，即带有响应中断版本的 &lt;code&gt;acquireInterruptibly&lt;/code&gt; 方法进行解析：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;/**\n * 以独占模式 acquire，如果线程中断则终止操作。通过首先检查中断状态，然后\n * 至少调用一次 tryAcquire，成功则直接返回。否则线程排队，可能会在 tryAcquire\n * 成功或线程被中断之前，多次重复阻塞和解除阻塞。该方法可用于实现 \n * Lock.lockInterruptibly 方法。\n *\n * 参数：arg - acquire 参数。这个值被传递给 tryAcquire，但并没有进行解释，\n *            你可以将其表示为任何你想要的值。  \n * @throws InterruptedException - 如果当前线程被中断\n */\npublic final void acquireInterruptibly(int arg)\n        throws InterruptedException{\n     // 判断当前线程是否中断，并清空线程中断标记位，中断直接抛出异常\n    if(Thread.interrupted())\n        throw new InterruptedException();\n    // 尝试加锁，加锁失败则进行自旋阻塞 acquire\n    if(!tryAcquire(arg))\n        doAcquireInterruptibly(arg);\n}\n\n/**\n * 以独占且可中断模式 acquire。\n * 参数：arg - acquire 参数\n */\nprivate void doAcquireInterruptibly(long arg)\n        throws InterruptedException {\n    // 新增当前线程节点并入队\n    final Node node = addWaiter(Node.EXCLUSIVE);\n    boolean failed = true;\n    try {\n        for (;;) {\n            // 前驱节点\n            final Node p = node.predecessor();\n            // 前驱节点为头节点，且 acquire 成功，则将当前节点置为头节点\n            if (p == head &amp;amp;&amp;amp; tryAcquire(arg)) {\n                setHead(node);\n                p.next = null; // help GC\n                failed = false;\n                return;\n            }\n            // 获取资源失败则进入阻塞状态\n            if (shouldParkAfterFailedAcquire(p, node) &amp;amp;&amp;amp;\n                    // park 当前线程，并判断是否中断\n                    parkAndCheckInterrupt())\n                throw new InterruptedException();\n        }\n    } finally {\n        if (failed)\n            cancelAcquire(node);\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;可以看到，&lt;code&gt;acquireInterruptibly&lt;/code&gt; 方法与 &lt;code&gt;acquire&lt;/code&gt; 方法基本一致，区别在于在线程中断时是否抛出 &lt;code&gt;InterruptedException&lt;/code&gt;。&lt;/p&gt;\n&lt;h4 id=\&#34;414-tryacquirenanos\&#34;&gt;4.1.4  tryAcquireNanos&lt;/h4&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;/**\n * 尝试以独占模式进行 acquire, 如果线程中断则终止操作, 如果超过给定的超时时间\n * 则返回 false。通过首先检查线程中断状态，然后至少调用一次 tryAcquire 方法，\n * 成功则返回 true。否则，线程排队，在调用 tryAcquire 直到成功、或线程被中断、\n * 或到达超时时间，可能重复多次阻塞和解除阻塞。此方法可用于实现 Lock.tryLock(long, TimeUnit)。\n *\n * 参数：arg - release 参数。此值始终是传递给 release 方法的值，或者是进入条件等待时的\n *            当前状态值。该值是未解释的，可以表示任何你想要的内容。\n *      nanosTimeout - 等待的最大纳秒数\n * 返回：如果成功 acquire，则返回 true；如果超时则返回 false\n * @throws InterruptedException 如果线程被中断\n */\npublic final boolean tryAcquireNanos(long arg, long nanosTimeout)\n        throws InterruptedException {\n    // 如果当前线程中断，清除中断状态，并抛出异常\n    if (Thread.interrupted())\n        throw new InterruptedException();\n    // 首次先尝试获取资源，失败后以指定超时时间阻塞获取\n    return tryAcquire(arg) ||\n            doAcquireNanos(arg, nanosTimeout);\n}\n\n/**\n * 以独占且支持超时模式进行 acquire。\n *\n * 参数：arg - acquire 参数\n *      nanosTimeout - 最大等待时间\n * 返回：如果 acquire 成功，返回 true\n */\nprivate boolean doAcquireNanos(long arg, long nanosTimeout)\n        throws InterruptedException {\n    // 如果超时时间小于等于 0，则直接加锁失败返回\n    if (nanosTimeout &amp;lt;= 0L)\n        return false;\n    // 最终超时时间线 = 当前系统时间的纳秒数 + 指定的超时纳秒数\n    final long deadline = System.nanoTime() + nanosTimeout;\n    // 以独占模式添加新节点并入队\n    final Node node = addWaiter(Node.EXCLUSIVE);\n    boolean failed = true;\n    try {\n        // 自旋进行 acquire 操作\n        for (;;) {\n            // 当前节点的前驱节点\n            final Node p = node.predecessor();\n            // 前驱节点为 head，尝试 acquire 操作，成功后，将当前节点设为 head，并清空节点无用字段\n            if (p == head &amp;amp;&amp;amp; tryAcquire(arg)) {\n                setHead(node);\n                p.next = null; // help GC\n                failed = false;\n                return true;\n            }\n            // 获取本次循环的超时时间\n            nanosTimeout = deadline - System.nanoTime();\n            // 本次自旋超时到达，直接返回\n            if (nanosTimeout &amp;lt;= 0L)\n                return false;\n            // 当前节点在 acquire 失败后如果需要阻塞，且\n            if (shouldParkAfterFailedAcquire(p, node) &amp;amp;&amp;amp;\n                    // 当前超时时间大于 1000 纳秒，小于等于 1000 纳秒将会进入下一轮自旋获取锁\n                    nanosTimeout &amp;gt; spinForTimeoutThreshold)\n                // 指定超时时间并 park\n                LockSupport.parkNanos(this, nanosTimeout);\n            // 如果线程中断，则抛出异常\n            if (Thread.interrupted())\n                throw new InterruptedException();\n        }\n    } finally {\n        if (failed)\n            cancelAcquire(node);\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;&lt;code&gt;tryAcquireNanos&lt;/code&gt; 方法与 &lt;code&gt;doAcquireInterruptibly&lt;/code&gt; 方法在对超时中断处理上是保持一致的，都会在线程中断后抛出 &lt;code&gt;InterruptedException&lt;/code&gt;。&lt;code&gt;tryAcquireNanos&lt;/code&gt; 在每轮的自旋加锁失败后，都会重新计算超时时间，当超时时间小于 &lt;code&gt;spinForTimeoutThreshold&lt;/code&gt; 后，则会进入自旋进行 &lt;code&gt;acquire&lt;/code&gt; 操作。&lt;/p&gt;\n&lt;h4 id=\&#34;415-独占模式的实现\&#34;&gt;4.1.5 独占模式的实现&lt;/h4&gt;\n&lt;p&gt;基于上述对独占模式的源码的解析，在 &lt;code&gt;j.u.c&lt;/code&gt;  包中提供的独占模式的同步器有：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;code&gt;ReentrantLock&lt;/code&gt;可重入锁；&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;ReentrantReadWriteLock&lt;/code&gt; 中的 &lt;code&gt;WriteLock&lt;/code&gt;；&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;ThreadPoolExecutor&lt;/code&gt; 中的 &lt;code&gt;Worker&lt;/code&gt;。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h3 id=\&#34;42-共享模式\&#34;&gt;4.2 共享模式&lt;/h3&gt;\n&lt;p&gt;共享模式：即同一时刻，共享资源可以被多个线程获取，&lt;code&gt;status&lt;/code&gt; 的状态大于或等于 0。共享模式在 &lt;code&gt;AQS&lt;/code&gt; 中的体现为，如果有一个节点持有的线程 &lt;code&gt;acquire&lt;/code&gt; 操作 &lt;code&gt;status&lt;/code&gt; 成功，那么它会被解除阻塞，并且会把解除阻塞状态 &lt;code&gt;PROPAGATE&lt;/code&gt; 给所有有效的后继节点。&lt;/p&gt;\n&lt;p&gt;共享模式的功能主要由以下四个方法提供，与独占模式相比，在方法命名上由 &lt;code&gt;Shared&lt;/code&gt; 区分：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;code&gt;acquireShared(int)&lt;/code&gt; ：获取 int 数量的资源，也就是原子修改 &lt;code&gt;status&lt;/code&gt;。&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;acquireSharedInterruptibly(int)&lt;/code&gt;：获取 int 数量的资源，可以响应线程中断。&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;tryAcquireSharedNanos(int, long)&lt;/code&gt; ：在指定 long 时间内，获取 int 数量的资源。&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;releaseShared(int)&lt;/code&gt; ：释放 int 数量的资源。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h4 id=\&#34;421-acquireshared\&#34;&gt;4.2.1 acquireShared&lt;/h4&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;/**\n * 以共享模式 acquire，并忽略线程中断。通过首先最少调用一次 tryAcquireShared 实现，\n * 成功则直接返回。否则线程排队，在调用 tryAcquireShared 成功之前，可能会多次重复\n * 阻塞和解除阻塞。\n *\n * 参数：arg - acquire 参数。该值被传递给 tryAcquireShared，但并没有进行解释，\n *            你可以将其表示为任何你想要的值。  \n */\npublic final void acquireShared(long arg) {\n    // 获取失败，返回负值；此时需要加入同步等待队列\n    if (tryAcquireShared(arg) &amp;lt; 0)\n        doAcquireShared(arg);\n}\n\n/**\n * 尝试以共享模式 acquire。此方法应查询对象的状态是否允许以共享模式获取它，\n * 如果允许，则可以获取。\n *\n * 此方法始终由执行 acquire 的线程调用。如果此方法返回失败，且该线程尚未排队，\n * 则 acquire 方法可以将该线程入队，直到某个其他线程释放发出 signal。\n *\n * 默认实现抛出 UnsupportedOperationException。\n *\n * 参数：arg - acquire 参数。该值始终是传递给 acquire 方法的值，或者是在进入条件等待\n *            时保存的值。该值并没有进行解释，你可以将其表示为任何你想要的值。  \n * 返回：失败返回负值；如果以共享模式获取成功但后续的共享模式 acquire 不能成功，则为 0；\n *      如果在共享模式下获取成功并且后续共享模式也可能成功，则为正值，在这种情况下，后续等待\n *      线程必须检查可用性。（对于三种不同返回值的支持使此方法可以仅在 acquire 可用时的独占上下文中使用。）\n *      成功后，此对象已被获取。\n * @throws IllegalMonitorStateException - 如果 acquire 会将此同步器置于非法状态。\n *                                        必须以一致的方式抛出此异常，同步器才能正常工作。\n * @throws UnsupportedOperationException - 如果不支持共享模式\n */\nprotected long tryAcquireShared(long arg) {\n    throw new UnsupportedOperationException();\n}\n\n/**\n * 以共享且不中断模式进行 acquire。\n * 参数：arg - acquire 的参数\n */\nprivate void doAcquireShared(long arg) {\n    // 为当前线程创建一个新的共享节点并入队\n    final Node node = addWaiter(Node.SHARED);\n    boolean failed = true;\n    try {\n        boolean interrupted = false;\n        for (;;) {\n            // 该节点的前驱节点\n            final Node p = node.predecessor();\n            // 如果前驱节点为 head\n            if (p == head) {\n                // 调用 tryAcquireShared 获取资源，只有在大于等于 0 时，才获取到资源，此时唤醒其他节点 \n                long r = tryAcquireShared(arg);\n                if (r &amp;gt;= 0) {\n                    // 设置头结点，并设置 `PROPAGATE 状态，确保唤醒传播到可用的后继节点\n                    // 当任意等待节点晋升为 head，也会进行此操作，以此来进行链式唤醒\n                    setHeadAndPropagate(node, r);\n                    p.next = null; // help GC\n                    if (interrupted)\n                        selfInterrupt();\n                    failed = false;\n                    return;\n                }\n            }\n            // acquire 失败判断是否需要 park，并校验线程中断\n            if (shouldParkAfterFailedAcquire(p, node) &amp;amp;&amp;amp;\n                    parkAndCheckInterrupt())\n                interrupted = true;\n        }\n    } finally {\n        if (failed)\n            cancelAcquire(node);\n    }\n}\n\n/**\n * 设置队列的 head，并检查后继节点是否可能在共享模式下等待，如果是这样，且设置了\n * propagate &amp;gt; 0，则进行传播。\n *\n * 参数：node - 节点\n *      propagate - tryAcquireShared 的返回值\n *\n * 如果是共享模式下，在设置头结点后，会判断 propagate &amp;gt; 0 || head.waiteStatus &amp;lt; 0 情况下，\n * 进行共享模式下的资源释放操作。\n */\nprivate void setHeadAndPropagate(Node node, long propagate) {\n    Node h = head; // 记录旧 head 以供检查\n    // 设置当前处理节点为 head\n    setHead(node);\n    /*\n     * 如果出现以下情况，请尝试 signal 下一个排队节点：\n     *  - 调用着指定了传播；\n     *  - or 有先前的操作记录（在 setHead 之前或之后作为 h.waitStatus）（注意：这是用了 waitStatus 的符号检查，因为 PROPAGATE 状态可能会转换为 SIGNAL）。\n     * and\n     *  - 下一个节点在共享模式中等待，或者我们并不清楚，因为它显示为 null\n     * \n     *\n     * 这两种检查的保守性可能会导致不必要的唤醒，但只有在多个竞争的 acquires 和 releases 时才会这样，\n     * 所以大多数节点无论如何都需要现在或很快得到 signal。\n     */\n    // 入参 propagate &amp;gt; 0 || head 为 null || head 的状态为非 CANCELLED 和 0 || 再次校验 head 为空 || 再次校验 head 状态不为 CANCELLED 和 0\n    if (propagate &amp;gt; 0 || h == null || h.waitStatus &amp;lt; 0 ||\n            (h = head) == null || h.waitStatus &amp;lt; 0) {\n        Node s = node.next;\n        // 当前节点（已经是头节点）的后继节点为 null，且为共享模式\n        if (s == null || s.isShared())\n            doReleaseShared();\n    }\n}\n\n/**\n * 共享模式的 release 操作 -- signal 后继节点并保证 propagation。\n * （在独占模式下，如果需要 signal，release 就相当于调用 head 的 unparkSuccessor）。\n */\nprivate void doReleaseShared() {\n    /*\n     * 确保 release 可以传播，即使还有其他正在进行的 acquire/release。\n     * 如果需要 signal，这会以常用的方式尝试对 head 进行 unparkSuccessor。\n     * 但如果没没有，则将状态设置为 &amp;quot;PROPAGATE&amp;quot; 确保在 release 时继续传播。\n     * 此外，我们必须在循环中进行，以防止在我们执行此操作时，链表中添加新节点。\n     * 此外，与 unparkSuccessor 的其他用法不同，我们需要知道 CAS 重置状态\n     * 是否失败，如果是则重新检查。\n     */\n    for (;;) {\n        Node h = head;\n        // 头节点不为空，且头节点同时不是尾结点\n        if (h != null &amp;amp;&amp;amp; h != tail) {\n            // 头节点的 waitStatus\n            int ws = h.waitStatus;\n            // 如果为 SIGNAL，则 CAS 将其更新为 0，更新成功后唤醒其后继节点的阻塞\n            if (ws == Node.SIGNAL) {\n                // 更新失败，是因为会有并发情况，唤醒的线程也会调用 doReleaseShared\n                // 如果更新失败，则跳过进行重新检查\n                if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))\n                    continue;            // loop to recheck cases\n                unparkSuccessor(h);\n            }\n            // 头节点 waitStatus 已经为 0，则 CAS 将其更新为 -3\n            // 此时可以分析 waitStatus 值为 0 的情况如下：\n            // 1. 如果 head 节点没有及时被更新，另一个线程被唤醒后获得锁，此时另一个线程已经执行了\n            // setHead，将头节点更新为了自己，（因为如果在下面的 h == head 判断中，头节点没有变化，\n            // 会直接跳出循环）；此时，通过 unparkSuccessor 将 waitStatus 更新为 0。\n            else if (ws == 0 &amp;amp;&amp;amp;\n                    !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))\n                continue;                // loop on failed CAS\n        }\n        // 1. head 没有变更，说明被唤醒的线程还没有执行完 setHead 操作，跳出循环。\n        // 等新的节点执行 setHeadAndPropagate 操作后，也会调用 doReleaseShared\n        // 2. 如果 head  变更了，那就可能会有多个线程（在当前循环被唤醒）都来执行\n        // doReleaseShared，此时这个方法的 compareAndSetWaitStatus 就可能\n        // 修改失败（当然，也可能会因为其他线程的 acquire/release 的竞争），那此时会\n        // 自旋做重新检查。\n        if (h == head)                   // loop if head changed\n            break;\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;我们对 &lt;code&gt;doReleaseShared&lt;/code&gt; 进行一个说明：&lt;/p&gt;\n&lt;ol&gt;\n&lt;li&gt;\n&lt;p&gt;首先，该方法是一个死循环，每次循环中都会重新获取 &lt;code&gt;head&lt;/code&gt;，只有当 &lt;code&gt;h == head&lt;/code&gt; 时，才会&lt;strong&gt;跳出&lt;/strong&gt;循环。而 &lt;code&gt;head&lt;/code&gt; 发生变化一定是由于队列中的节点在 &lt;code&gt;acquire&lt;/code&gt; 阻塞过程中被唤醒，之后成功获得锁资源，然后在调用 &lt;code&gt;setHeadAndPropagate&lt;/code&gt; 方法中的 &lt;code&gt;setHead&lt;/code&gt; 方法修改 &lt;code&gt;head&lt;/code&gt;。&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;判断 &lt;code&gt;h != null &amp;amp;&amp;amp; h != tail&lt;/code&gt; 说明队列中至少要存在两个节点，如果队列并没有因为竞争而初始化为 &lt;code&gt;head&lt;/code&gt; 设置过值（&lt;code&gt;head&lt;/code&gt; 为 &lt;code&gt;null&lt;/code&gt;），或队列仅有一个节点（&lt;code&gt;head&lt;/code&gt; 和 &lt;code&gt;tail&lt;/code&gt; 指向同一个节点），那么将不进行操作，直接到最后去判断 &lt;code&gt;head&lt;/code&gt; 是否发生了变化。&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;如果步骤 2 中的条件满足，说明队列有两个及以上节点，那么此时会根据 &lt;code&gt;h&lt;/code&gt; 的 &lt;code&gt;waitStatus&lt;/code&gt; 字段判断：&lt;/p&gt;\n&lt;ol&gt;\n&lt;li&gt;如果状态为 &lt;code&gt;signal&lt;/code&gt;，说明 &lt;code&gt;h&lt;/code&gt; 节点的后继节点需要被通知，此时进行 CAS 操作 &lt;code&gt;compareAndSetWaitStatus(h, Node.SIGNAL, 0)&lt;/code&gt;:\n&lt;ol&gt;\n&lt;li&gt;如果 CAS 操作成功，即将 &lt;code&gt;h&lt;/code&gt; 的状态由 &lt;code&gt;SIGNAL&lt;/code&gt; 改为 &lt;code&gt;0&lt;/code&gt;，此时通过 &lt;code&gt;unparkSuccessor&lt;/code&gt; 方法唤醒后继节点。&lt;/li&gt;\n&lt;li&gt;如果 CAS 操作失败，说明当前线程在修改时存在竞争（可能其他线程也在进行 &lt;code&gt;release/acquire&lt;/code&gt; 操作，或者同样在进行 &lt;code&gt;doReleaseShared&lt;/code&gt;），此时我们进行重新检查。&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/li&gt;\n&lt;li&gt;如果状态为 &lt;code&gt;0&lt;/code&gt; ，说明 &lt;code&gt;h&lt;/code&gt; 节点的后继节点已经被唤醒或在唤醒的过程中了，因为当前为共享模式的释放，所以我们使用 CAS 操作将状态更新为 &lt;code&gt;PROPAGATE&lt;/code&gt;传播唤醒其他节点。&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/li&gt;\n&lt;/ol&gt;\n&lt;p&gt;下面我们分析一下 &lt;code&gt;h&lt;/code&gt; 的 &lt;code&gt;waitStatus&lt;/code&gt; 为 &lt;code&gt;0&lt;/code&gt; 的情况：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;如果队列中只有一个节点，那么它的状态肯定为 0，此时 &lt;code&gt;head&lt;/code&gt; 和 &lt;code&gt;tail&lt;/code&gt; 都指向这个节点。&lt;/li&gt;\n&lt;li&gt;如果队列中有一个节点（它的状态为 0），此时另外一个线程由于 &lt;code&gt;acquire&lt;/code&gt; 失败，那么失败线程会调用 &lt;code&gt;addWaiter&lt;/code&gt; 方法将自己入队，此时队列中有两个节点，此时还没有来得及执行 &lt;code&gt;shouldParkAfterFailedAcquire&lt;/code&gt; 中的 &lt;code&gt;compareAndSetWaitStatus(pred, ws, Node.SIGNAL);&lt;/code&gt; 将第一个节点的状态改为 &lt;code&gt;signal&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;队列中有多个节点，此时，刚好有线程释放了锁，调用了 &lt;code&gt;releaseShared() -&amp;gt; doReleaseShared() -&amp;gt; unparkSuccessor() &lt;/code&gt;  方法的 &lt;code&gt;compareAndSetWaitStatus(node, ws, 0)&lt;/code&gt; 一行，将节点状态设置为了 0，之后唤醒 &lt;code&gt;head&lt;/code&gt; 节点的后继节点，&lt;code&gt;head&lt;/code&gt; 的后继节点将自己设置为队列的 &lt;code&gt;head&lt;/code&gt; 的过程中（还没有设置为 &lt;code&gt;head&lt;/code&gt;），当前 &lt;code&gt;head&lt;/code&gt; 节点的状态为 0。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;综上，如果在释放共享锁的过程中，会执行 &lt;code&gt;doReleaseShared&lt;/code&gt; 方法，而此时会对 &lt;code&gt;PROPAGATE&lt;/code&gt; 状态进行传播，唤醒其后继节点，而后继节点唤醒后，也会执行相同的步骤，如果在 &lt;code&gt;if(h == head)&lt;/code&gt; 判断前后继节点调用 &lt;code&gt;setHeadAndPropagte&lt;/code&gt; 方法将 &lt;code&gt;head&lt;/code&gt; 修改为自己，那就会可能有多个线程同时并发执行 &lt;code&gt;doReleaseShared&lt;/code&gt; 方法，以此达到传播的目的，当 &lt;code&gt;head&lt;/code&gt; 不发生变化时，唤醒的后继节点也会对后续的各个节点进行唤醒，直到全部唤醒完成或无共享资源可用（此时 &lt;code&gt;head&lt;/code&gt; 节点不再发生变化）。&lt;/p&gt;\n&lt;p&gt;与独占模式的 &lt;code&gt;acquire&lt;/code&gt; 方法相比，共享模式在当前节点获取资源成功后，除了会将自身设置为 &lt;code&gt;head&lt;/code&gt; 之外，还会通过 CAS 将自身的 &lt;code&gt;waitStatus&lt;/code&gt; 设置为 &lt;code&gt;PROPAGATE&lt;/code&gt;，从而传播去唤醒其他等待节点。&lt;/p&gt;\n&lt;h4 id=\&#34;422-releaseshared\&#34;&gt;4.2.2 releaseShared&lt;/h4&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;/**\n * 以共享模式进行 release 操作。如果 tryReleaseShared 返回 true，则通过解锁一个或\n * 多个线程来实现。\n *\n * 参数：arg - release 参数。该值被传递给 tryReleaseShared，但并没有进行解释，\n *            你可以将其表示为任何你想要的值。 \n * 返回：tryReleaseShared 的返回值\n */\npublic final boolean releaseShared(int arg) {\n    // 尝试释放资源\n    if (tryReleaseShared(arg)) {\n        // 进行 doReleaseShared 以传播方式唤醒其他节点\n        doReleaseShared();\n        return true;\n    }\n    return false;\n}\n\n/**\n * 尝试设置状态，以体现共享模式下的 release。\n *\n * 该方法总是由执行 release 的线程调用。\n *\n * 默认实现抛出 UnsupportedOperationException。\n *\n * 参数：arg - release 参数。此值始终是传递给 release 方法的值，或者是进入条件等待时的\n *            当前状态值。该值是未解释的，可以表示任何你想要的内容。\n * 返回：如果此共享模式的 release 可能允许等待 acquire 的其他线程成功（共享或独占）；否则 false。\n * @throws IllegalMonitorStateException - 如果 release 会将此同步器置于非法状态。\n *                                        必须以一致的方式抛出此异常，同步器才能正常工作。\n * @throws UnsupportedOperationException - 如果不支持独占模式\n */\nprotected boolean tryReleaseShared(int arg) {\n    throw new UnsupportedOperationException();\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;可以看到，&lt;code&gt;releaseShared&lt;/code&gt; 其实就是在 &lt;code&gt;tryReleaseShared&lt;/code&gt; 返回 &lt;code&gt;true&lt;/code&gt; 后，去调用 &lt;code&gt;doReleaseShared&lt;/code&gt; 传播唤醒状态。&lt;/p&gt;\n&lt;h4 id=\&#34;423-acquiresharedinterruptibly\&#34;&gt;4.2.3 acquireSharedInterruptibly&lt;/h4&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;/**\n * 以共享模式 acquire，如果线程中断则终止操作。通过首先检查中断状态，然后\n * 至少调用一次 tryAcquireShared，成功则直接返回。否则线程排队，可能会在 \n * tryAcquireShared 成功或线程被中断之前，多次重复阻塞和解除阻塞。\n *\n * 参数：arg - acquire 参数。这个值被传递给 tryAcquire，但并没有进行解释，\n *            你可以将其表示为任何你想要的值。  \n * @throws InterruptedException - 如果当前线程被中断\n */\npublic final void acquireSharedInterruptibly(int arg)\n        throws InterruptedException {\n    // 判断线程中断并清除中断标志，如果中断，直接抛出异常终止\n    if (Thread.interrupted())\n        throw new InterruptedException();\n    // 尝试加锁，小于 0 说明加锁失败，需要入队操作\n    if (tryAcquireShared(arg) &amp;lt; 0)\n        doAcquireSharedInterruptibly(arg);\n}\n\n/**\n * 以共享且可中断模式 acquire。\n * 参数：arg - acquire 参数\n */\nprivate void doAcquireSharedInterruptibly(int arg)\n        throws InterruptedException {\n    // 创建共享模式节点并入队\n    final Node node = addWaiter(Node.SHARED);\n    boolean failed = true;\n    try {\n        for (;;) {\n            // 当前节点的前驱节点\n            final Node p = node.predecessor();\n            if (p == head) {\n                // 加锁操作\n                int r = tryAcquireShared(arg);\n                if (r &amp;gt;= 0) {\n                    // 设置头结点并传播状态\n                    setHeadAndPropagate(node, r);\n                    p.next = null; // help GC\n                    failed = false;\n                    return;\n                }\n            }\n            // 加锁失败后进行阻塞操作，如果线程中断，则抛出异常\n            if (shouldParkAfterFailedAcquire(p, node) &amp;amp;&amp;amp;\n                    parkAndCheckInterrupt())\n                throw new InterruptedException();\n        }\n    } finally {\n        if (failed)\n            cancelAcquire(node);\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h4 id=\&#34;424-tryacquiresharednanos\&#34;&gt;4.2.4 tryAcquireSharedNanos&lt;/h4&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;/**\n * 尝试以共享模式进行 acquire, 如果线程中断则终止操作, 如果超过给定的超时时间\n * 则返回 false。通过首先检查线程中断状态，然后至少调用一次 tryAcquireShared 方法，\n * 成功则返回 true。否则，线程排队，在调用 tryAcquireShared 直到成功、或线程被中断、\n * 或到达超时时间，可能重复多次阻塞和解除阻塞。\n *\n * 参数：arg - release 参数。此值始终是传递给 release 方法的值，或者是进入条件等待时的\n *            当前状态值。该值是未解释的，可以表示任何你想要的内容。\n *      nanosTimeout - 等待的最大纳秒数\n * 返回：如果成功 acquire，则返回 true；如果超时则返回 false\n * @throws InterruptedException 如果线程被中断\n */\npublic final boolean tryAcquireSharedNanos(int arg, long nanosTimeout)\n        throws InterruptedException {\n    if (Thread.interrupted())\n        throw new InterruptedException();\n    // 首次尝试，如果 tryAcquireShared &amp;gt;= 0 说明加锁成功，可以直接返回\n    return tryAcquireShared(arg) &amp;gt;= 0 ||\n            // 需要入队操作\n            doAcquireSharedNanos(arg, nanosTimeout);\n}\n\n/**\n * 以共享且支持超时模式进行 acquire。\n *\n * 参数：arg - acquire 参数\n *      nanosTimeout - 最大等待时间\n * 返回：如果 acquire 成功，返回 true\n */\nprivate boolean doAcquireSharedNanos(int arg, long nanosTimeout)\n        throws InterruptedException {\n    // 小于零不需要阻塞了，直接返回\n    if (nanosTimeout &amp;lt;= 0L)\n        return false;\n    // 计算当前线程的超时线\n    final long deadline = System.nanoTime() + nanosTimeout;\n    // 新增共享节点并入队\n    final Node node = addWaiter(Node.SHARED);\n    boolean failed = true;\n    try {\n        // 自旋并休眠，这段代码和 doAcquireShared 一致\n        for (;;) {\n            final Node p = node.predecessor();\n            if (p == head) {\n                int r = tryAcquireShared(arg);\n                if (r &amp;gt;= 0) {\n                    setHeadAndPropagate(node, r);\n                    p.next = null; // help GC\n                    failed = false;\n                    return true;\n                }\n            }\n            // 自旋过程中，每次都重新计算新的超时时间\n            nanosTimeout = deadline - System.nanoTime();\n            // 超时则直接跳出，返回 false\n            if (nanosTimeout &amp;lt;= 0L)\n                return false;\n             // 当前节点在 acquire 失败后如果需要阻塞，且\n            if (shouldParkAfterFailedAcquire(p, node) &amp;amp;&amp;amp;\n                    // 当前超时时间大于 1000 纳秒，小于等于 1000 纳秒将会进入下一轮自旋获取锁\n                    nanosTimeout &amp;gt; spinForTimeoutThreshold)\n                // 以自旋过程中计算的 nanosTimeout 阻塞\n                LockSupport.parkNanos(this, nanosTimeout);\n            // 线程中断直接退出\n            if (Thread.interrupted())\n                throw new InterruptedException();\n        }\n    } finally {\n        if (failed)\n            // 加锁失败，退出节点\n            cancelAcquire(node);\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h4 id=\&#34;425-共享模式的实现\&#34;&gt;4.2.5 共享模式的实现&lt;/h4&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;code&gt;ReentrantReadWriteLock&lt;/code&gt; 中的 &lt;code&gt;ReadLock&lt;/code&gt;;&lt;/li&gt;\n&lt;li&gt;信号量 &lt;code&gt;Semaphore&lt;/code&gt;;&lt;/li&gt;\n&lt;li&gt;闭锁 &lt;code&gt;CountDownLatch&lt;/code&gt;。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 id=\&#34;五-条件队列之-conditionobject\&#34;&gt;五、条件队列之 ConditionObject&lt;/h2&gt;\n&lt;p&gt;在 &lt;code&gt;AQS&lt;/code&gt; 内部也存在这 &lt;code&gt;Condition&lt;/code&gt; 接口的实现类，即 &lt;code&gt;ConditionObject&lt;/code&gt;，它是 &lt;code&gt;AQS&lt;/code&gt;的共有内部类，并且它是 &lt;code&gt;Lock&lt;/code&gt;&lt;br&gt;\n实现的基础。&lt;code&gt;ConditionObject&lt;/code&gt; 提供的条件队列的入队的方法如下。&lt;/p&gt;\n&lt;h3 id=\&#34;51-条件队列的入队和出队\&#34;&gt;5.1 条件队列的入队和出队&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;public class ConditionObject implements Condition, java.io.Serializable {\n    private static final long serialVersionUID = 1173984872572414699L;\n    /**\n     * 条件队列的第一个节点\n     */\n    private transient Node firstWaiter;\n    /**\n     * 条件队列的最后一个节点\n     */\n    private transient Node lastWaiter;\n\n    /**\n     * Creates a new {@code ConditionObject} instance.\n     */\n    public ConditionObject() {\n    }\n\n    /**\n     * 为等待队列添加一个新的等待节点\n     *\n     * @return 新的等待节点\n     */\n    private Node addConditionWaiter() {\n        // 本地变量保存 lastWaiter\n        Node t = lastWaiter;\n        // 如果 lastWaiter 不为条件等待状态，则说明 lastWaiter 是取消状态，清理\n        if (t != null &amp;amp;&amp;amp; t.waitStatus != Node.CONDITION) {\n            // 解除所有取消的等待节点的连接\n            unlinkCancelledWaiters();\n            t = lastWaiter;\n        }\n        // 创建当前线程的新节点，类型为 CONDITION\n        Node node = new Node(Thread.currentThread(), Node.CONDITION);\n        // 在首次创建 Condition 时，lastWaiter 为 null，则把当前节点设置为 firstWaiter \n        if (t == null)\n            firstWaiter = node;\n        else\n            // lastWaiter 不为空，则连接新节点\n            t.nextWaiter = node;\n        // 当前新增节点为 lastWaiter\n        lastWaiter = node;\n        return node;\n    }\n\n    /**\n     * 从条件队列中取消连接已取消的等待节点。仅在持有锁时调用。当前方法会在条件等待期间\n     * 发生取消时被调用，并且在 lastWaiter 已被取消时插入新的等待节点时调用。需要这种\n     * 方法来避免在没有 signal 的情况下保留垃圾。因此，即使它可能需要完全遍历，它也只有\n     * 在没有被 signal 的情况下发生超时或取消时才发挥作用。它遍历所有节点，而不是在特定\n     * 目标处停止以取消连接到垃圾节点的所有指针，因此不会在取消风暴期间进行多次重新遍历。\n     * &amp;lt;p&amp;gt;\n     * 简单来说，此方法就是更新队列，移除所有 CANCELLED 的节点，期间会 firstWaiter 和\n     * lastWaiter 的引用\n     */\n    private void unlinkCancelledWaiters() {\n        // 保存当前的 firstWaiter \n        Node t = firstWaiter;\n        // 跟踪节点，用于最后找到 lastWaiter\n        Node trail = null;\n        while (t != null) {\n            // 从 firstWaiter 开始往后遍历\n            Node next = t.nextWaiter;\n            // 当前节点不是 CONDITION，那么就是 CANCELLED\n            if (t.waitStatus != Node.CONDITION) {\n                // 取消当前节点的引用\n                t.nextWaiter = null;\n                // trail 为空，说明当前还未遇到第一个 CONDITION 状态的节点\n                if (trail == null)\n                    // 将 firstWaiter 暂时设置为 下个节点\n                    firstWaiter = next;\n                else\n                    // 将 next 链接到追踪节点\n                    trail.nextWaiter = next;\n                // 遍历结束\n                if (next == null)\n                    // lastWaiter 即 trail 的最后一个节点\n                    lastWaiter = trail;\n            } else\n                // CONDITION 节点，记录当前节点\n                trail = t;\n            // 更新当前节点为 next\n            t = next;\n        }\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;我们在观察 &lt;code&gt;ConditionObject&lt;/code&gt; 类后可以发现，所有的 &lt;code&gt;await&lt;/code&gt; 方法及其变体都会调用 &lt;code&gt;addConditionWaiter()&lt;/code&gt;&lt;br&gt;\n方法，将阻塞线程添加到添加队列中。我们下面演示一下条件队列入队的情况下，假设存在两个线程 &lt;code&gt;thread-1&lt;/code&gt; 和 &lt;code&gt;thread-2&lt;/code&gt;&lt;br&gt;\n需要阻塞入队，首先是 &lt;code&gt;thread-1&lt;/code&gt; 入队：&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;5\&#34;&gt;&lt;img src=\&#34;/Users/wenbo.zhang/Desktop/images/condition-queue-thread-1-enq.png\&#34; alt=\&#34;thread-1-enq\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;在 &lt;code&gt;thread-1&lt;/code&gt; 入队后等待过程中，&lt;code&gt;thread-2&lt;/code&gt; 入队：&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;6\&#34;&gt;&lt;img src=\&#34;/Users/wenbo.zhang/Desktop/images/condition-queue-thread-2-enq.png\&#34; alt=\&#34;thread-2-enq\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;之后线程入队就如上面操作一样，只需修改 lastWaiter 和 nextWaiter 指向新节点即可。&lt;/p&gt;\n&lt;h3 id=\&#34;52-condition-之-await\&#34;&gt;5.2 Condition 之 await&lt;/h3&gt;\n&lt;p&gt;实现 &lt;code&gt;Condition&lt;/code&gt; 接口的 &lt;code&gt;await&lt;/code&gt; 方法，主要用于条件等待操作。下面是关于接口中方法的说明：&lt;/p&gt;\n&lt;p&gt;使当前线程等待，直到它被 signal 或中断。&lt;/p&gt;\n&lt;p&gt;直到以下四种情况之一发生时，与此 Condition 关联的锁会被自动释放，并且当前线程由于线程调度会被禁用并处于休眠状态：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;其他某个线程为此 Condition 调用了 signal() 方法，而当前线程恰好被选为要被唤醒的线程；&lt;/li&gt;\n&lt;li&gt;其他一些线程为此 Condition 调用了 signalAll() 方法；&lt;/li&gt;\n&lt;li&gt;其他一些线程中断当前线程，支持中断线程挂起；&lt;/li&gt;\n&lt;li&gt;发生“虚假唤醒”。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;在所有情况下，在此方法可以返回之前，当前线程必须重新获取获取与此 Condition 关联的锁。当前线程返回时，它保证持有这个锁。&lt;/p&gt;\n&lt;p&gt;如果当前线程：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;在进入此方法时设置其中断状态；或者，&lt;/li&gt;\n&lt;li&gt;等待过程中被中断，支持线程挂起的中断。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;然后抛出 InterruptedException 并清除当前线程的中断状态。在第一种情况下，没有规定是否在释放锁之前进行中断判断。&lt;/p&gt;\n&lt;p&gt;实现注意事项：&lt;/p&gt;\n&lt;p&gt;调用此方法时，假定当前线程持有与此 Condition 关联的锁。由实现决定是否是这种情况，如果不是，如何响应。通常，将抛出异常（例如，IllegalMonitorStateException）并且实现必须记录该事实。&lt;/p&gt;\n&lt;p&gt;与响应 signal 的正常方法返回相比，实现更倾向于响应中断。在这种情况下，实现必须确保将信号量重定向到另一个等待线程（如果有的话）。&lt;/p&gt;\n&lt;p&gt;throws InterruptedException - 如果当前线程被中断（并且支持线程挂起的中断）&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;/** 该模式意味着退出等待时重新中断 */\nprivate static final int REINTERRUPT =  1;\n/** 该模式意味着在退出等待时抛出 InterruptedException */\nprivate static final int THROW_IE    = -1;\n\n\n/**\n * 实现支持中断的条件等待。\n * 1. 如果当前线程被中断，抛出 InterruptedException。\n * 2. 保存 getState 返回的锁状态。\n * 3. 使用保存状态作为参数调用 release，如果失败抛出 IllegalMonitorStateException。\n * 4. 线程入队阻塞，直到 signal 或 线程中断\n * 5. 通过使用保存状态作为参数调用特定的 acquire 方法来重新加锁。\n * 6. 如果在步骤 4 中被阻塞过程中被其他线程中断，则抛出 IntrrputedException。\n */\npublic final void await() throws InterruptedException {\n    // 判断线程中断，清理中断标志\n    if (Thread.interrupted())\n        throw new InterruptedException();\n    // 新增条件等待节点并进入条件等待队列\n    Node node = addConditionWaiter();\n    // 释放当前 AQS 的所有资源，并返回资源的 state\n    int savedState = fullyRelease(node);\n    // 中断模式\n    int interruptMode = 0;\n    // 如果新增节点不在同步队列，对当前节点线程进行阻塞。\n    // 这里是个循环判断，当前节点被唤醒后，会将节点从条件队列转换到同步队列，\n    // 所以在节点被唤醒后，如果加锁成功，将会被放入同步队列跳出循环\n    while (!isOnSyncQueue(node)) {\n        LockSupport.park(this);\n        // 线程中断，转移当前节点\n        if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)\n            break;\n    }\n    // 节点进入同步队列后，如果此时线程没有中断，则以独占方式进入同步队列阻塞\n    // 这里在 acquireQueued 中进行 tryAcquire 时使用的参数为 savedState\n    if (acquireQueued(node, savedState) &amp;amp;&amp;amp; interruptMode != THROW_IE)\n        interruptMode = REINTERRUPT;\n    // 当前节点的 nextWaiter 不为空，则从等待队列中移除所有 CANCELLED 节点\n    if (node.nextWaiter != null) // clean up if cancelled\n        unlinkCancelledWaiters();\n    // 根据 interruptMode 对中断进行对应处置\n    if (interruptMode != 0)\n        reportInterruptAfterWait(interruptMode);\n}\n\n/**\n * 使用当前的状态值调用 release；返回保存的状态值。\n * 失败则取消节点，并抛出异常。\n * \n * 参数：node - 当前等待的条件节点\n * 返回：之前的同步状态\n */\nfinal int fullyRelease(Node node) {\n    boolean failed = true;\n    try {\n        int savedState = getState();\n        // 释放资源，也就是解锁\n        if (release(savedState)) {\n            failed = false;\n            return savedState;\n        } else {\n            throw new IllegalMonitorStateException();\n        }\n    } finally {\n        if (failed)\n            // 失败则取消节点\n            node.waitStatus = Node.CANCELLED;\n    }\n}\n\n/**\n * 如果一个节点（从最初就是放在条件队列中的节点）现在正在同步队列中等待 acquire 操作，\n * 则返回 true。\n * \n * 参数：node - 节点\n * 返回：如果在同步队列中 acquire，返回 true\n */\nfinal boolean isOnSyncQueue(Node node) {\n    // 在同步队列，则说明当前节点肯定不是条件等待节点\n    // 如果不是条件等待节点，但是节点的 prev 为空，说明节点可能在同步队列已出队\n    if (node.waitStatus == Node.CONDITION || node.prev == null)\n        return false;\n    // 节点不是等待节点，且存在后继节点，说明一定在同步队列上\n    if (node.next != null) // If has successor, it must be on queue\n        return true;\n    /*\n     * node.prev 可以是非空的，但尚未在队列中，因为将其放入队列的 CAS 可能会失败。\n     * 所以我们必须从队列 tail 遍历，以确保它确实成功了。在调用这个方法时，它总是在\n     * tail 附近，除非 CAS 失败（这不太可能），所以我们几乎不会有太多的遍历。\n     */\n    // 从同步队列往前遍历查找节点\n    return findNodeFromTail(node);\n}\n\n/**\n * 如果节点通过从 tail 向前搜索，出现在了同步队列上，则返回 true。\n * 仅在 isOnSyncQueue 需要调用。\n * \n * 返回：如果存在，返回 true\n */\nprivate boolean findNodeFromTail(Node node) {\n    Node t = tail;\n    for (;;) {\n        if (t == node)\n            return true;\n        if (t == null)\n            return false;\n        t = t.prev;\n    }\n}\n\n/**\n * 检查线程中断，如果在 signal 之前中断，则返回 THROW_IE，\n * 如果在 signal 之后中断，返回 REINTERRUPT，如果没有中断，\n * 返回 0。\n */\nprivate int checkInterruptWhileWaiting(Node node) {\n    return Thread.interrupted() ?\n            // 如果是当前入队成功了，当前线程抛出异常\n            (transferAfterCancelledWait(node) ? THROW_IE : REINTERRUPT) :\n            // 线程未中断\n            0;\n}\n\n/**\n * 如果有必要，在取消等待后将节点转移到同步队列。如果是在 signal 之前被\n * 取消等待，则返回 true。\n *\n * 参数：node - 节点。\n * 返回：如果在 signal 之前取消等待，返回 true。\n */\nfinal boolean transferAfterCancelledWait(Node node) {\n    // CAS 尝试将当前节点状态修改为 0\n    if (compareAndSetWaitStatus(node, Node.CONDITION, 0)) {\n        // 修改成功，转移到同步队列\n        enq(node);\n        return true;\n    }\n    /*\n     * 如果我们由于竞争 CAS 修改失败，那在它完成 enq() 入队之前，我们不能继续。\n     * 在传输未完成之前取消，这个很少见也很短暂，所以我们只需要自旋。\n     */\n    // 等待其他线程将节点加入同步队列\n    while (!isOnSyncQueue(node))\n        // 让出 CPU\n        Thread.yield();\n    return false;\n}\n\n/**\n * 根据 interruptMode 选择抛出 InterruptedException、重新中断、或不执行任何操作。\n */\nprivate void reportInterruptAfterWait(int interruptMode)\n        throws InterruptedException {\n    // 抛出异常\n    if (interruptMode == THROW_IE)\n        throw new InterruptedException();\n    else if (interruptMode == REINTERRUPT)\n        selfInterrupt();\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;可以看到，当一个节点加入条件队列时，如果当前节点是同步队列的节点，首先会释放 &lt;code&gt;AQS&lt;/code&gt; 同步队列的资源（此时线程是独占模式，因此不存在竞争），只有持有锁的线程可以进行 &lt;code&gt;fullyRelease&lt;/code&gt;，此时这个节点就从同步队列转移到了条件队列（其实本质是将节点从同步队列移除，然后在条件队列新增一个节点）。之后，该节点就会在条件队列上阻塞，直到有其他线程调用 &lt;code&gt;signal&lt;/code&gt; 或 &lt;code&gt;signal&lt;/code&gt; 唤醒当前线程，当前线程就会从条件队列转移到同步队列中，当 &lt;code&gt;await&lt;/code&gt; 方法被唤醒，并且当前节点成功转移到同步队列中，之后的操作就属于 &lt;code&gt;AQS&lt;/code&gt; 中的同步队列阻塞及唤醒操作。&lt;/p&gt;\n&lt;h3 id=\&#34;53-condtion-之-signalsignalall\&#34;&gt;5.3 Condtion 之 signal/signalAll&lt;/h3&gt;\n&lt;p&gt;&lt;code&gt;Condition&lt;/code&gt; 接口的 &lt;code&gt;signal&lt;/code&gt; 方法，主要用来唤醒阻塞的条件队列中的线程，其方法说明如下：&lt;/p&gt;\n&lt;p&gt;唤醒一个等待线程。&lt;/p&gt;\n&lt;p&gt;如果有任何线程在此 Condition 下等待，则选择一个用于唤醒。然后，该线程必须在从await 返回之前重新获取锁。&lt;/p&gt;\n&lt;p&gt;实现注意事项：&lt;/p&gt;\n&lt;p&gt;在调用此方法时，实现可能（并且通常确实）要求当前线程持有与此 Condition 关联的锁。实现必须记录此前提条件以及未持有锁时采取的任何操作。通常，会抛出 IllegalMonitorStateException。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;/*\n * 将等待时间最长的线程（如果存在）从该条件队列转换到拥有锁的等待队列。\n *\n * @throws IllegalMonitorStateException 如果 isHeldExclusively 返回 false\n */\npublic final void signal() {\n  // 当前同步器持有的线程是否是当前线程\n  if (!isHeldExclusively())\n    throw new IllegalMonitorStateException();\n  // 等待时间最长的就是第一个入队的 fistWaiter\n  Node first = firstWaiter;\n  if (first != null)\n    // 唤醒节点\n    doSignal(first);\n}\n\n/**\n * 删除并转换节点，直到命中未取消的节点或 null。从 signal 中分离出来部分是为了\n * 编译器内联没有等待节点的情况。\n *\n * 参数：first - (非空) 条件队列中的第一个节点\n */\n// 该方法目的就是唤醒成功一个节点，或条件队列为空时，执行结束\nprivate void doSignal(Node first) {\n  do {\n    // 第一个节点的 nextWaiter 为空，说明目前只有一个等待节点\n    if ((firstWaiter = first.nextWaiter) == null)\n      lastWaiter = null;\n    // 将当前处理节点从条件队列移除\n    first.nextWaiter = null;\n    // 转换当前节点\n  } while (!transferForSignal(first) &amp;amp;&amp;amp;\n          // 转换失败，此时的 firstWaiter 是 first 的 nextWaiter 节点\n          (first = firstWaiter) != null);\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;下面是 &lt;code&gt;signalAll&lt;/code&gt; 方法，与 &lt;code&gt;signal&lt;/code&gt; 不同的是，&lt;code&gt;signalAll&lt;/code&gt; 方法会唤醒所有等待节点：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;/**\n * 将所有线程从该条件等待队列转换到拥有锁的等待队列。\n *\n * @throws IllegalMonitorStateException 如果 isHeldExclusively 返回 false\n */\npublic final void signalAll() {\n  // // 当前同步器持有的线程是否是当前线程\n    if (!isHeldExclusively())\n      throw new IllegalMonitorStateException();\n    Node first = firstWaiter;\n    if (first != null)\n        // 唤醒所有节点\n        doSignalAll(first);\n}\n\n/**\n * 移除并转换所有节点\n * @param first (非空) 条件队列中的第一个节点\n */\nprivate void doSignalAll(Node first) {\n    // 全部转换，则将 lastWaiter 和 firstWaiter 置空\n    lastWaiter = firstWaiter = null;\n    do {\n        // 获取下一个等待节点\n        Node next = first.nextWaiter;\n        // 下一个等待节点移除\n        first.nextWaiter = null;\n        // 处理当前节点\n        transferForSignal(first);\n        // 更新下个节点为处理节点\n        first = next;\n    } while (first != null);\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;可以看到，&lt;code&gt;signal&lt;/code&gt; 和 &lt;code&gt;signalAll&lt;/code&gt; 方法会将节点转换到同步队列，并将节点的状态修改为 &lt;code&gt;SINGAL&lt;/code&gt;，之后解除节点线程阻塞状态。唯一不同的地方是，&lt;code&gt;signal&lt;/code&gt; 方法只唤醒单个节点，而 &lt;code&gt;signalAll&lt;/code&gt; 方法会唤醒全部节点。&lt;/p&gt;\n&lt;h3 id=\&#34;54-await-方法的几种变体\&#34;&gt;5.4 await 方法的几种变体&lt;/h3&gt;\n&lt;p&gt;下面我们简单看一下 &lt;code&gt;await&lt;/code&gt; 方法的几种变体。&lt;/p&gt;\n&lt;h4 id=\&#34;541-awaituninterruptibly\&#34;&gt;5.4.1 awaitUninterruptibly&lt;/h4&gt;\n&lt;p&gt;使当前线程等待，直到它被 &lt;code&gt;signal&lt;/code&gt;。&lt;/p&gt;\n&lt;p&gt;直到以下三种情况之一发生时，与此 &lt;code&gt;Condition&lt;/code&gt; 关联的锁会被自动释放，并且当前线程由于线程调度会被禁用并处于休眠状态：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;其他某个线程为此 &lt;code&gt;Condition&lt;/code&gt; 调用了 &lt;code&gt;signal()&lt;/code&gt; 方法，而当前线程恰好被选为要被唤醒的线程；&lt;/li&gt;\n&lt;li&gt;其他一些线程为此 &lt;code&gt;Condition&lt;/code&gt; 调用了 &lt;code&gt;signalAll()&lt;/code&gt; 方法；&lt;/li&gt;\n&lt;li&gt;发生“虚假唤醒”。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;在所有情况下，在此方法可以返回之前，当前线程必须重新获取获取与此 &lt;code&gt;Condition&lt;/code&gt; 关联的锁。当前线程返回时，它保证持有这个锁。&lt;/p&gt;\n&lt;p&gt;如果当现场进入该方法时设置了中断状态，或者在等待过程中被中断，则继续等待直到被 &lt;code&gt;signal&lt;/code&gt; 唤醒。当它最终从这个方法返回时，它的中断状态会依旧存在。&lt;/p&gt;\n&lt;p&gt;实现注意事项：&lt;/p&gt;\n&lt;p&gt;调用此方法时，假定当前线程持有与此 &lt;code&gt;Condition&lt;/code&gt; 关联的锁。由实现决定是否是这种情况，如果不是，如何响应。通常，将抛出异常（例如，IllegalMonitorStateException）并且实现必须记录该事实。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;/**\n * 实现非中断的条件等待。\n *\n * 1. 保存 getStatus() 返回的锁定状态。\n * 2. 使用保存的状态作为参数调用 release()，如果失败抛出 IllegalMonitorStateException。\n * 3. 阻塞直到 signal。\n * 4. 将保存的状态作为参数调用特定版本的 acquire() 来重新获取锁。\n */\npublic final void awaitUninterruptibly() {\n    // 添加新的等待节点\n    Node node = addConditionWaiter();\n    // release 当前 AQS 的所有资源，并返回资源的 state\n    int savedState = fullyRelease(node);\n    // 是否中断\n    boolean interrupted = false;\n    // 判断当前节点是否是同步队列节点，理论上新增的应当是不在同步队列，当被唤醒时，如果加锁成功则会在同步队列\n    while (!isOnSyncQueue(node)) {\n        // 阻塞当前节点\n        LockSupport.park(this);\n        // 判断当前线程是否中断\n        if (Thread.interrupted())\n            interrupted = true;\n    }\n    // 如果当前线程被中断，或在加锁过程中中断，则对当前线程进行中断操作\n    if (acquireQueued(node, savedState) || interrupted)\n        selfInterrupt();\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h4 id=\&#34;542-awaitnanos\&#34;&gt;5.4.2 awaitNanos&lt;/h4&gt;\n&lt;p&gt;使当前线程等待，直到它被 signal 或 中断，或者达到指定的等待时间。&lt;/p&gt;\n&lt;p&gt;直到以下五种情况之一发生时，与此 Condition 关联的锁会被自动释放，并且当前线程由于线程调度会被禁用并处于休眠状态：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;其他某个线程为此 Condition 调用了 signal() 方法，而当前线程恰好被选为要被唤醒的线程；&lt;/li&gt;\n&lt;li&gt;其他一些线程为此 Condition 调用了 signalAll() 方法；&lt;/li&gt;\n&lt;li&gt;其他一些线程中断当前线程，支持中断线程挂起；&lt;/li&gt;\n&lt;li&gt;到达指定的等待时间；&lt;/li&gt;\n&lt;li&gt;发生“虚假唤醒”。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;在所有情况下，在此方法可以返回之前，当前线程必须重新获取获取与此 Condition 关联的锁。当前线程返回时，它保证持有这个锁。&lt;/p&gt;\n&lt;p&gt;如果当前线程：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;在进入此方法时设置其中断状态；或者，&lt;/li&gt;\n&lt;li&gt;等待过程中被中断，支持线程挂起的中断。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;然后抛出 InterruptedException 并清除当前线程的中断状态。在第一种情况下，没有规定是否在释放锁之前进行中断判断。&lt;/p&gt;\n&lt;p&gt;在返回时提供给定的 nanosTimeout 值，该方法返回对剩余等待纳秒数的预估，如果超时，则返回小于或等于零的值。在等待返回但是等待的条件仍不成立的情况下，此值可用于确定是否重新等待以及重新等待多长时间。此方法的典型用途如以下形式：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;boolean aMethod(long timeout, TimeUnit unit) {\n    long nanos = unit.toNanos(timeout);\n    lock.lock();\n    try {\n        while (!conditionBeingWaitedFor()) {\n            if (nanos &amp;lt;= 0L)\n                return false;\n            nanos = theCondition.awaitNanos(nanos);\n        }\n        // ...\n    } finally {\n        lock.unlock();\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;设计说明：此方法需要纳秒参数，以避免报告剩余时间时出现截断错误。这种精度损失将使程序员难以确保总等待时间不会系统地短于重新等待发生时指定的时间。&lt;/p&gt;\n&lt;p&gt;实现注意事项：&lt;/p&gt;\n&lt;p&gt;调用此方法时，假定当前线程持有与此 Condition 关联的锁。由实现决定是否是这种情况，如果不是，如何响应。通常，将抛出异常（例如，IllegalMonitorStateException）并且实现必须记录该事实。&lt;/p&gt;\n&lt;p&gt;与响应 signal 的正常方法返回相比，实现更倾向于响应中断。在这种情况下，实现必须确保将信号量重定向到另一个等待线程（如果有的话）。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;/**\n * 实现超时条件等待。\n * 1. 如果当前线程被中断，抛出 InterruptedException。\n * 2. 保存 getState 返回的锁状态。\n * 3. 使用保存状态作为参数调用 release，如果失败抛出 IllegalMonitorStateException。\n * 4. 线程入队阻塞，直到 signal、线程中断或超时。\n * 5. 通过使用保存状态作为参数调用特定的 acquire 方法来重新加锁。\n * 6. 如果在步骤 4 中被阻塞过程中被其他线程中断，则抛出 IntrrputedException。\n */\npublic final long awaitNanos(long nanosTimeout)\n        throws InterruptedException {\n    if (Thread.interrupted())\n        throw new InterruptedException();\n    // 增加条件等待节点，并加入条件等待队列\n    Node node = addConditionWaiter();\n    // 是否 AQS 中的全部资源\n    int savedState = fullyRelease(node);\n    // 计算超时的时间线\n    final long deadline = System.nanoTime() + nanosTimeout;\n    int interruptMode = 0;\n    // 阻塞直到超时，或中断抛出异常、或同步入队成功\n    while (!isOnSyncQueue(node)) {\n        // 节点超时\n        if (nanosTimeout &amp;lt;= 0L) {\n            // 移除条件等待队列，放入同步队列中\n            transferAfterCancelledWait(node);\n            break;\n        }\n        // 如果当前实现剩余比较多，这里是 1000 纳秒，那么阻塞\n        if (nanosTimeout &amp;gt;= spinForTimeoutThreshold)\n            LockSupport.parkNanos(this, nanosTimeout);\n        // 中断则跳出循环\n        if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)\n            break;\n        // 重新计算剩余时间\n        nanosTimeout = deadline - System.nanoTime();\n    }\n    // 节点在超时、中断、或 signal 出队后，会加入同步队列，这里在同步队列操作\n    if (acquireQueued(node, savedState) &amp;amp;&amp;amp; interruptMode != THROW_IE)\n        interruptMode = REINTERRUPT;\n    // 下个节点不为空，则断开取消的节点\n    if (node.nextWaiter != null)\n        unlinkCancelledWaiters();\n    // 根据中断模式进行中断处理\n    if (interruptMode != 0)\n        reportInterruptAfterWait(interruptMode);\n    // 返回剩余时间\n    return deadline - System.nanoTime();\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h4 id=\&#34;543-awaituntil\&#34;&gt;5.4.3 awaitUntil&lt;/h4&gt;\n&lt;p&gt;使当前线程等待，直到它被 signal 或 中断，或者达到指定的等待时间。&lt;/p&gt;\n&lt;p&gt;直到以下五种情况之一发生时，与此 Condition 关联的锁会被自动释放，并且当前线程由于线程调度会被禁用并处于休眠状态：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;其他某个线程为此 Condition 调用了 signal() 方法，而当前线程恰好被选为要被唤醒的线程；&lt;/li&gt;\n&lt;li&gt;其他一些线程为此 Condition 调用了 signalAll() 方法；&lt;/li&gt;\n&lt;li&gt;其他一些线程中断当前线程，支持中断线程挂起；&lt;/li&gt;\n&lt;li&gt;到达指定的等待时间；&lt;/li&gt;\n&lt;li&gt;发生“虚假唤醒”。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;在所有情况下，在此方法可以返回之前，当前线程必须重新获取获取与此 Condition 关联的锁。当前线程返回时，它保证持有这个锁。&lt;/p&gt;\n&lt;p&gt;如果当前线程：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;在进入此方法时设置其中断状态；或者，&lt;/li&gt;\n&lt;li&gt;等待过程中被中断，支持线程挂起的中断。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;然后抛出 InterruptedException 并清除当前线程的中断状态。在第一种情况下，没有规定是否在释放锁之前进行中断判断。&lt;/p&gt;\n&lt;p&gt;返回值表示是否已经过了 deadline，可以如下使用：&lt;/p&gt;\n&lt;p&gt;实现注意事项：&lt;/p&gt;\n&lt;p&gt;调用此方法时，假定当前线程持有与此 Condition 关联的锁。由实现决定是否是这种情况，如果不是，如何响应。通常，将抛出异常（例如，IllegalMonitorStateException）并且实现必须记录该事实。&lt;/p&gt;\n&lt;p&gt;与响应 signal 的正常方法返回相比，实现更倾向于响应中断。在这种情况下，实现必须确保将信号量重定向到另一个等待线程（如果有的话）。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;boolean aMethod(Date deadline) {\n    boolean stillWaiting = true;\n    lock.lock();\n    try {\n        while(!conditionBeingWaitedFor()) {\n            if (!stillWaiting)\n                return false;\n            stillWaiting = theCondition.awaitUntil(deadline);\n        }\n        // ...\n    } finally {\n        lock.unlock();\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;参数： deadline - 等待的绝对时间。&lt;/p&gt;\n&lt;p&gt;返回： 如果返回时已经超过最后期限，则为 false，否则为 true。&lt;/p&gt;\n&lt;p&gt;@throws InterruptedException - 如果当前线程被中断（并且支持线程挂起的中断）&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;/**\n * 实现绝对超时时间的条件等待。\n * 1. 如果当前线程被中断，抛出 InterruptedException。\n * 2. 保存 getState 返回的锁状态。\n * 3. 使用保存状态作为参数调用 release，如果失败抛出 IllegalMonitorStateException。\n * 4. 线程入队阻塞，直到 signal、线程中断或超时。\n * 5. 通过使用保存状态作为参数调用特定的 acquire 方法来重新加锁。\n * 6. 如果在步骤 4 中被阻塞过程中被其他线程中断，则抛出 IntrrputedException。\n * 7. 如果在步骤 4 中被阻塞过程中超时，则返回 false，否则返回 true。\n */\npublic final boolean awaitUntil(Date deadline)\n        throws InterruptedException {\n    // 获取绝对时间的时间戳\n    long abstime = deadline.getTime();\n    if (Thread.interrupted())\n        throw new InterruptedException();\n    // 当前线程加入添加条件队列\n    Node node = addConditionWaiter();\n    // 释放 AQS 的全部资源\n    int savedState = fullyRelease(node);\n    boolean timedout = false;\n    int interruptMode = 0;\n    // 阻塞直到超时，或中断抛出异常、或同步入队成功\n    while (!isOnSyncQueue(node)) {\n        // 判断当前循环是否超时\n        if (System.currentTimeMillis() &amp;gt; abstime) {\n            // 取消条件等待，跳出循环\n            timedout = transferAfterCancelledWait(node);\n            break;\n        }\n        // 阻塞\n        LockSupport.parkUntil(this, abstime);\n        // 中断则跳出循环\n        if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)\n            break;\n    }\n    // 节点在超时、中断、或 signal 出队后，会加入同步队列，这里在同步队列操作\n    if (acquireQueued(node, savedState) &amp;amp;&amp;amp; interruptMode != THROW_IE)\n        interruptMode = REINTERRUPT;\n    if (node.nextWaiter != null)\n        unlinkCancelledWaiters();\n    if (interruptMode != 0)\n        reportInterruptAfterWait(interruptMode);\n    return !timedout;\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h4 id=\&#34;544-awaitlong-time-timeunit-unit\&#34;&gt;5.4.4 await(long time, TimeUnit unit)&lt;/h4&gt;\n&lt;p&gt;使当前线程等待，直到它被 signal 或 中断，或者达到指定的等待时间。此方法在行为上等效于：&lt;code&gt;awaitNanos(unit.toNanos(time)) &amp;gt; 0 &lt;/code&gt;。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;/**\n * 实现超时条件等待。\n * 1. 如果当前线程被中断，抛出 InterruptedException。\n * 2. 保存 getState 返回的锁状态。\n * 3. 使用保存状态作为参数调用 release，如果失败抛出 IllegalMonitorStateException。\n * 4. 线程入队阻塞，直到 signal、线程中断或超时。\n * 5. 通过使用保存状态作为参数调用特定的 acquire 方法来重新加锁。\n * 6. 如果在步骤 4 中被阻塞过程中被其他线程中断，则抛出 IntrrputedException。\n * 7. 如果在步骤 4 中被阻塞过程中超时，则返回 false，否则返回 true。\n */\npublic final boolean await(long time, TimeUnit unit)\n        throws InterruptedException {\n    // 转为纳秒书剑\n    long nanosTimeout = unit.toNanos(time);\n    // 判断线程中断，并清空状态，中断则抛出异常\n    if (Thread.interrupted())\n        throw new InterruptedException();\n    // 当前线程加入添加条件队列\n    Node node = addConditionWaiter();\n    // 释放所有 AQS 资源\n    int savedState = fullyRelease(node);\n    // 计算超时时间先\n    final long deadline = System.nanoTime() + nanosTimeout;\n    boolean timedout = false;\n    int interruptMode = 0;\n    while (!isOnSyncQueue(node)) {\n        if (nanosTimeout &amp;lt;= 0L) {\n            timedout = transferAfterCancelledWait(node);\n            break;\n        }\n        if (nanosTimeout &amp;gt;= spinForTimeoutThreshold)\n            LockSupport.parkNanos(this, nanosTimeout);\n        if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)\n            break;\n        nanosTimeout = deadline - System.nanoTime();\n    }\n    if (acquireQueued(node, savedState) &amp;amp;&amp;amp; interruptMode != THROW_IE)\n        interruptMode = REINTERRUPT;\n    if (node.nextWaiter != null)\n        unlinkCancelledWaiters();\n    if (interruptMode != 0)\n        reportInterruptAfterWait(interruptMode);\n    return !timedout;\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h2 id=\&#34;七-aqs-中的-cancelacquire\&#34;&gt;七、AQS 中的 cancelAcquire&lt;/h2&gt;\n&lt;p&gt;当节点在下列几种状态时，会触发 &lt;code&gt;AQS&lt;/code&gt; 进行 &lt;code&gt;cancelAcquire&lt;/code&gt; 操作，具体如下：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;节点在队列自旋 &lt;code&gt;acquire&lt;/code&gt;  过程中触发异常，如 &lt;code&gt;acquireQueue&lt;/code&gt;、&lt;code&gt;doAcquireShared&lt;/code&gt; 等方法；&lt;/li&gt;\n&lt;li&gt;节点在队列自旋 &lt;code&gt;acquire&lt;/code&gt; 过程中触发线程中断，如 &lt;code&gt;doAcquireInterruptibly&lt;/code&gt;、&lt;code&gt;doAcquireNanos&lt;/code&gt; 、&lt;code&gt;doAcquireSharedInterruptibly&lt;/code&gt;、&lt;code&gt;doAcquireSharedNanos&lt;/code&gt; 等方法&lt;/li&gt;\n&lt;li&gt;节点在带有超时参数的 &lt;code&gt;acquire&lt;/code&gt; 变体方法调用中，到达超时时间，且未成功 &lt;code&gt;acquire&lt;/code&gt;，如 &lt;code&gt;doAcquireNanos&lt;/code&gt; 、&lt;code&gt;doAcquireSharedNanos&lt;/code&gt; 等方法。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;总的来说，当线程在 acquire 过程中触发各种异常，或带超时的接口调用触发超时时，就会在 &lt;code&gt;finally&lt;/code&gt; 中调用 &lt;code&gt;cancelAcquire&lt;/code&gt; 方法，用于取消该节点，将该节点从队列中移除。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;/**\n* 取消正在进行尝试的 acquire。\n*\n* 参数：node - 节点\n*/\nprivate void cancelAcquire(Node node) {\n    // 当前节点不存在，直接忽略\n    if (node == null)\n        return;\n\t// 将当前节点持有的线程置空，释放资源\n    node.thread = null;\n\n    // 跳过取消的前驱节点，将当前节点的前驱节点和 pred 指向一个未被 CANCELLED 的节点\n    Node pred = node.prev;\n    // 从当前节点到找到节点之前，都为 CANCELLED 节点，全部需要断开\n    // 此后，当前节点的前驱节点为非 CANCELLED 节点\n    while (pred.waitStatus &amp;gt; 0)\n        node.prev = pred = pred.prev;\n\n    // 很明显 predNext 是要断开链接的节点。如果不是，下面 CAS 将失败，\n    // 在这种情况下，我们可能在竞争中输给了另一个 cancel 或 signal，\n    // 我们不需要采取其他行动。\n    Node predNext = pred.next;\n\n    // 可以在这里使用无条件写入，而不是 CAS 操作。\n    // 在这个原子步骤之后，其他节点可以跳过我们。\n    // 在此之前，我们不受其他线程影响。\n    // 将当前节点状态设置为 CANCELLED\n    node.waitStatus = Node.CANCELLED;\n\n    // 如果当前节点为 tail，直接移除当前节点，将 tail 置为 pred（当前节点的前驱节点，非CANCELLED）\n    if (node == tail &amp;amp;&amp;amp; compareAndSetTail(node, pred)) {\n        compareAndSetNext(pred, predNext, null);\n    } else {\n        // 当前节点的前驱节点非 head，需要将当前节点从同步队列中移除\n        int ws;\n        if (pred != head &amp;amp;&amp;amp;\n                // 前驱节点状态为 SIGNAL\n                ((ws = pred.waitStatus) == Node.SIGNAL ||\n                        // 前驱节点状态为 0，将其置为 SIGNAL\n                        (ws &amp;lt;= 0 &amp;amp;&amp;amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;amp;&amp;amp;\n                pred.thread != null) {\n            Node next = node.next;\n            // 将当前节点从队列移除，即将 pred 节点（当前节点的前驱节点）的 next 指向当前节点的后继节点\n            if (next != null &amp;amp;&amp;amp; next.waitStatus &amp;lt;= 0)\n                compareAndSetNext(pred, predNext, next);\n        } else {\n            // 当前节点的前驱节点为 head，则说明从 head 到 当前节点之间全部为 CANCELLED 节点，\n            // 直接唤醒当前节点的后继节点\n            unparkSuccessor(node);\n        }\n\n        // 断开当前节点引用\n        node.next = node; // help GC\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h2 id=\&#34;八-aqs-的锁实现\&#34;&gt;八、AQS 的锁实现&lt;/h2&gt;\n&lt;p&gt;&lt;code&gt;AQS&lt;/code&gt; 作为同步器框架，其提供的基础的功能给并发组件，下面我们将根据 &lt;code&gt;j.u.c&lt;/code&gt; 包内置的同步组件，来了解 &lt;code&gt;AQS&lt;/code&gt; 的使用。&lt;/p&gt;\n&lt;h3 id=\&#34;81-reentrantlock\&#34;&gt;8.1 ReentrantLock&lt;/h3&gt;\n&lt;p&gt;一种可重入的互斥 &lt;code&gt;Lock&lt;/code&gt;，其基本行为和语义与使用 &lt;code&gt;synchronized&lt;/code&gt; 方法和语句访问的隐式监视器锁相同，但具有扩展功能。&lt;/p&gt;\n&lt;p&gt;&lt;code&gt;ReentrantLock&lt;/code&gt; 被上次成功锁定但尚未解锁的线程 &lt;em&gt;持有&lt;/em&gt;。当锁不被另一个线程持有时，调用 &lt;code&gt;lock&lt;/code&gt; 的线程将返回，并成功获取锁。如果当前线程已经持有锁，该方法将立即返回。这可以使用方&lt;code&gt;isHeldByCurrentThread&lt;/code&gt; 和 &lt;code&gt;getHoldCount&lt;/code&gt; 方法来检查。&lt;/p&gt;\n&lt;p&gt;此类的构造函数接受一个可选的 &lt;em&gt;fair&lt;/em&gt; 番薯。当设置为 &lt;code&gt;true&lt;/code&gt; 时，在竞争情况下，锁会优先授予给等待时间最长的线程的访问。否则，锁将无法保证获得顺序。如果在多线程情况下使用公平锁，可能会比非公平锁的吞吐量低（即，会更慢；通常情况下会慢得多），但在获得锁和确保不会出现线程饥饿的情况会有更好的效果。但是请注意，锁的公平性并不能保证线程调度的公平性。因此，使用公平锁的多线程中，可能会有单个线程连续多次获得它，而其他活动线程无法获得锁，因此也无法执行。另请注意，没有超时参数的 &lt;code&gt;tryLock()&lt;/code&gt; 方法不遵守公平设置。如果锁可用，即使其他线程正在等待，他也会成功。&lt;/p&gt;\n&lt;p&gt;推荐的做法是在 &lt;code&gt;lock&lt;/code&gt; 加锁之后立即调用&lt;code&gt;try&lt;/code&gt; 块，最常见的用法如下：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;class X {\n    private final ReentrantLock lock = new ReentrantLock();\n    // ...\n    \n    public void m() {\n        lock.lock(); // block until condition holds\n        try {\n            // ... method body\n        } finally {\n            lock.unlock();\n        }\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;除了实现 &lt;code&gt;Lock&lt;/code&gt; 接口之外，该类还定义了许多 &lt;code&gt;public&lt;/code&gt; 和 &lt;code&gt;protected&lt;/code&gt; 的方法来检查锁的状态。其中一些方法仅对 instrumentation 和 monitoring 有用。&lt;/p&gt;\n&lt;p&gt;此类的序列化与内置锁的行为方式相同：反序列化锁处于未锁定状态，无论其在序列化时的状态如何。&lt;/p&gt;\n&lt;p&gt;此锁最多支持同一线程的 2147483647 个递归锁。尝试超过此限制会导致锁定方法抛出 &lt;code&gt;Error&lt;/code&gt; 。&lt;/p&gt;\n&lt;h4 id=\&#34;811-sync\&#34;&gt;8.1.1 Sync&lt;/h4&gt;\n&lt;p&gt;&lt;code&gt;ReentratLock&lt;/code&gt; 的抽象类 &lt;code&gt;Sync&lt;/code&gt; 作为 &lt;code&gt;AQS&lt;/code&gt;框架实现类，用于同步控制的基础。可用于实现公平锁和非公平锁。主要通过使用 &lt;code&gt;AQS&lt;/code&gt; 的状态来表示持有锁的次数，当 &lt;code&gt;AQS&lt;/code&gt; 状态为 &lt;code&gt;0&lt;/code&gt;，说明当前可能没有其他线程持有锁，&lt;code&gt;ReentrantLock&lt;/code&gt;的每次获取锁都会讲 &lt;code&gt;AQS&lt;/code&gt; 状态加一。下面是 &lt;code&gt;Sync&lt;/code&gt; 的源码：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;/**\n * 此锁的同步控制的基础。下面分为公平和非公平版本。使用 AQS 状态来表示\n * 持有锁的次数。\n */\nabstract static class Sync extends AbstractQueuedSynchronizer {\n    private static final long serialVersionUID = -5179523762034025860L;\n\n    /**\n     * 执行 Lock.lock。抽象方法的原因主要是非公平版本提供快速路径。\n     */\n    abstract void lock();\n\n    /**\n     * 执行非公平的 tryLock。tryAcquire 在子类中实现，但两者都需要对\n     * tryLock 方法进行非公平尝试。\n     */\n    final boolean nonfairTryAcquire(int acquires) {\n        // 获取当前执行线程\n        final Thread current = Thread.currentThread();\n        // 获取 AQS 当前状态\n        int c = getState();\n        // 当前状态为 0，说明锁可能没有被其他线程获取\n        if (c == 0) {\n            // cas 尝试加锁，将 AQS 状态修改为 acquires，成功后直接返回\n            if (compareAndSetState(0, acquires)) {\n                // 设置当前线程为独占\n                setExclusiveOwnerThread(current);\n                return true;\n            }\n        }\n        // 如果当前线程已经持有了锁，即当前线程就是独占锁的线程\n        else if (current == getExclusiveOwnerThread()) {\n            // 将状态直接加上 acquires\n            int nextc = c + acquires;\n            // 状态溢出\n            if (nextc &amp;lt; 0) // overflow\n                throw new Error(&amp;quot;Maximum lock count exceeded&amp;quot;);\n            // 当前线程就是持有锁的线程，所以直接设置 AQS 状态\n            setState(nextc);\n            return true;\n        }\n        // 既不是独占线程，状态也不为 0，说明当前锁被其他线程持有\n        return false;\n    }\n\n    /**\n     * 释放资源操作\n     */\n    protected final boolean tryRelease(int releases) {\n        // 计算释放后的状态值\n        int c = getState() - releases;\n        // 当前线程不是锁的持有者，抛出异常\n        if (Thread.currentThread() != getExclusiveOwnerThread())\n            throw new IllegalMonitorStateException();\n        // 是否完全释放\n        boolean free = false;\n        // 释放后状态值为 0，说明当前线程已经完全释放资源\n        // 如果不为 0，说明当前线程是重入操作的释放，还需要等执行完再次释放\n        if (c == 0) {\n            // 设置释放 flag\n            free = true;\n            // 取消当前线程的独占\n            setExclusiveOwnerThread(null);\n        }\n        // 设置 AQS 状态值\n        setState(c);\n        return free;\n    }\n\n    /**\n     * 当前线程是否是该独占锁的持有者\n     */\n    protected final boolean isHeldExclusively() {\n        // 虽然我们通常必须在拥有锁之前读取状态值，但是我们不需要\n        // 检查这样检查当前线程是否是持有者\n        return getExclusiveOwnerThread() == Thread.currentThread();\n    }\n\n    /**\n     * Condition 实例，用于和 Lock 一起使用\n     */\n    final ConditionObject newCondition() {\n        return new ConditionObject();\n    }\n\n// 从外部类中集成的方法\n\n    // 获取当前锁的独占线程\n    final Thread getOwner() {\n        return getState() == 0 ? null : getExclusiveOwnerThread();\n    }\n\n    // 获取当前 AQS 的状态值\n    final int getHoldCount() {\n        return isHeldExclusively() ? getState() : 0;\n    }\n\n    // 是否被锁定\n    final boolean isLocked() {\n        return getState() != 0;\n    }\n\n    /**\n     * 从流中重构实例（即反序列化）。\n     * 返回的实例为非锁定状态\n     */\n    private void readObject(java.io.ObjectInputStream s)\n            throws java.io.IOException, ClassNotFoundException {\n        s.defaultReadObject();\n        setState(0); // reset to unlocked state\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h4 id=\&#34;812-公平锁和非公平锁\&#34;&gt;8.1.2 公平锁和非公平锁&lt;/h4&gt;\n&lt;p&gt;公平锁和非公平锁在源码的实现中，差异很小，唯一的区别是公平锁会在加锁时，判断在自己之前是否有其他线程在等待，只有当自己是头结点（等待时间最长），之后才会尝试加锁。下面我们通过源码来了解一下，以下是非公平锁的实现：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;/**\n * Sync 对象的非公平锁\n */\nstatic final class NonfairSync extends Sync {\n    private static final long serialVersionUID = 7316153563782823691L;\n\n    /**\n     * 执行锁定操作。尝试直接修改 AQS 状态加锁（快速路径），失败时恢复正常 acquire。\n     */\n    final void lock() {\n        // CAS 尝试直接加锁，成功后将当前线程设置为独占线程\n        if (compareAndSetState(0, 1))\n            setExclusiveOwnerThread(Thread.currentThread());\n        else\n            // CAS 操作失败，正常进行 acquire 操作 \n            acquire(1);\n    }\n\n    /**\n     * tryAcquire 进行加锁操作，实现自 AQS，调用 Sync 进行非公平 tryAcquire\n     */\n    protected final boolean tryAcquire(int acquires) {\n        return nonfairTryAcquire(acquires);\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;下面是公平锁的实现：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;/**\n * Sync 对象的公平锁\n */\nstatic final class FairSync extends Sync {\n    private static final long serialVersionUID = -3000897897090466540L;\n\n    // 公平锁，直接 acquire，不尝试快速路径\n    final void lock() {\n        acquire(1);\n    }\n\n    /**\n     * tryAcquire 的公平锁版本。除非递归调用，或者在没有等待节点时是第一个，否则不应该具有访问锁权限。\n     */\n    protected final boolean tryAcquire(int acquires) {\n        // 获取当前线程\n        final Thread current = Thread.currentThread();\n        // 获取 AQS 状态\n        int c = getState();\n        // 可能没有加锁\n        if (c == 0) {\n            // 先判断队列中是否有在自己之前的节点\n            if (!hasQueuedPredecessors() &amp;amp;&amp;amp;\n                    // 自己就是第一个节点，CAS 尝试加锁\n                    compareAndSetState(0, acquires)) {\n                // 设置独占\n                setExclusiveOwnerThread(current);\n                return true;\n            }\n        }\n        else if (current == getExclusiveOwnerThread()) {\n            int nextc = c + acquires;\n            if (nextc &amp;lt; 0)\n                throw new Error(&amp;quot;Maximum lock count exceeded&amp;quot;);\n            setState(nextc);\n            return true;\n        }\n        return false;\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;可以看到，在 &lt;code&gt;tryAcquire&lt;/code&gt; 时，公平锁会调用 &lt;code&gt;hasQueuedPredecessors()&lt;/code&gt; 方法，先判断自己是否是头结点（头结点没有前驱节点），我们看下这个方法的源码：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;/**\n * 查询是否有任何线程其他线程在队列中的等待时间大于当前线程。\n *\n * 调用此方法等效于（但是可能有更高效）：\n * getFirstQueuedThread() != Thread.currentThread() &amp;amp;&amp;amp;\n * hasQueuedThreads()\n *\n * 请注意，由于中断和超时可能随时会发生，从而导致节点取消，因此返回 true 并不代表着\n * 某些其他线程会在当前线程之获取到锁。同样，由于队列为空，在此方法返回 false 时，\n * 另一个线程可能会在竞争中先入队成功。\n *\n * 本方法目的在于供公平同步器的使用，从而避免”闯入“。如果一个同步器的 tryAcquire \n * 方法应该返回 false，并且他的 tryAcquireShared 方法应该返回一个负值，这个方法\n * 返回 true（除非是可重入的获取）。\n *\n * protected boolean tryAcquire(int arg) {\n *   if (isHeldExclusively()) {\n *     // A reentrant acquire; increment hold count\n *     return true;\n *   } else if (hasQueuedPredecessors()) {\n *     return false;\n *   } else {\n *     // try to acquire normally\n *   }\n * }\n *\n * @return 如果当前线程之前有一个排队线程，则为true ，如果当前线程位于队列的头部或队列为空，则为false\n * @since 1.7\n */\npublic final boolean hasQueuedPredecessors() {\n    // 之所以这么做是因为 head 在 tail 之前被初始化，\n    // 先 tail 后 head，h.next 操作一定能获取到值。\n    // 如果按照先 h 再 t 的方式取值，可能会发生这样的情况：\n    // 此时队列为空 head 为 null，在 h 赋值完成后，其他线程\n    // 入队，此时 head 和 tail 都不为空，就造成了 h 不存在，\n    // 但是 t 却存在的情况。这种情况 h.next 就会抛出空指针了\n    Node t = tail; // 以相反的顺序读取字段\n    Node h = head;\n    Node s;\n    return h != t &amp;amp;&amp;amp;\n            ((s = h.next) == null || s.thread != Thread.currentThread());\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h4 id=\&#34;813-reentrantlock-类的其他方法\&#34;&gt;8.1.3 ReentrantLock 类的其他方法&lt;/h4&gt;\n&lt;p&gt;除了核心的加锁和解锁方法外，&lt;code&gt;ReentrantLock&lt;/code&gt; 还提供了其他的一些监控手段的方法，如下说明：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;public class ReentrantLock implements Lock, java.io.Serializable {\n    private static final long serialVersionUID = 7373984872572414699L;\n    /** 提供实现所有机制的同步器 */\n    private final Sync sync;\n\n    /**\n     * 创建 ReentrantLock 的实例。这相当于 ReentrantLock(false)。\n     */\n    public ReentrantLock() {\n        sync = new NonfairSync();\n    }\n\n    /**\n     * 使用给定的公平策略创建 ReentrantLock 实例。\n     *\n     * 参数：fair - 如果当前锁应该使用公平排序策略，则为 true\n     */\n    public ReentrantLock(boolean fair) {\n        sync = fair ? new FairSync() : new NonfairSync();\n    }\n\n    /**\n     * 获取锁。\n     *\n     * 如果没有被另一个线程持有，则获取锁并立即返回，将锁持有计数设置为 1。\n     *\n     * 如果当前线程已经持有锁，则持有次数加 1 并立即返回。\n     *\n     * 如果锁被另一个线程持有，那么当前线程出于线程调度的目的，将会被禁用并处于休眠状态，\n     * 直到当前线程获得锁为止，此时锁持有计数设置为 1.\n     */\n     public void lock() {\n         sync.lock();\n     }\n\n    /**\n     * 除非当前线程被中断，否则一直 acquire 直到获取锁。\n     *\n     * 如果没有被另一个线程持有，则获取锁并立即返回，将锁持有计数设置为 1。\n     *\n     * 如果当前线程已经持有锁，则持有次数加 1 并立即返回。\n     *\n     * 如果锁被另一个线程持有，那么当前线程出于线程调度的目的，将会被禁用并处于休眠状态，\n     * 直到发生以下两种情况之一：\n     * - 当前线程获取锁成功；或者\n     * - 其他线程中断当前线程。\n     *\n     * 如果当前线程获取到了锁，则锁持有计数设置为 1。\n     *\n     * 如果当前线程：\n     * - 在进入此方法时设置其中断状态；或者\n     * - 在获取锁过程中被中断，\n     * 然后会抛出 InterruptedException 并清除当前线程的中断状态。\n     *\n     * 在此实现中，由于此方法明显表示出中断能力，因此优先响应中断而不是\n     * 正常执行或可重入获取锁。\n     *\n     * @throws InterruptedException - 如果当前线程被中断\n     */\n    public void lockInterruptibly() throws InterruptedException {\n        sync.acquireInterruptibly(1);\n    }\n\n    /**\n     * 仅当调用时没有另一个线程持有时才获取锁。\n     *\n     * 如果锁没有被另一个线程持有，则获取锁，并立即返回 true，将锁持有计数设置为 1。\n     * 即使此锁已设置为使用公平排队策略，调用 tryLock() 也会立即获取锁（如果可用），\n     * 无论其他线程当前是否正在等待该锁。这种 “闯入” 行为在某些情况下可能很有用，\n     * 即使它破坏了公平性。如果您想完全遵循公平设置，请使用几乎等效的 tryLock(9, TimeUnit.SECONDS)\n     * （它也检测中断）。\n     *\n     * 如果当前线程已经持有了锁，那么持有计数加 1 并返回 true。\n     * \n     * 如果锁被其他线程持有，则此方法立即返回 false。\n     *\n     * 返回：如果锁空闲并被当前线程获取成功，或锁已经被当前线程持有，则返回 true，否则返回 false。\n     */\n    public boolean tryLock() {\n        return sync.nonfairTryAcquire(1);\n    }\n\n    /**\n     * 如果在给定的等待时间内没有被其他线程持有锁，且当前线程没有被中断，则获取锁。\n     *\n     * 如果锁没有被另一个线程持有，则获取锁，并立即返回 true，且会将锁持有的计数设置为 1。如果\n     * 此锁已设置为使用公平排序策略，则在该线程之前排队任何其他线程正在等待该锁，则不会获取到锁。\n     * 这与 tryLock() 方法形成对比。如果你想要一个允许 “闯入” 公平锁的可超时 tryLock，则可以\n     * 将超时和非超时方法相结合使用：\n     *\n     * if (lock.tryLock() ||\n     *     lock.tryLock(timeout, unit)) {\n     *     ...\n     * }\n     *\n     *\n     * 如果没有被另一个线程持有，则获取锁并立即返回，将锁持有计数设置为 1。\n     *\n     * 如果当前线程已经持有锁，则持有次数加 1 并立即返回。\n     *\n     * 如果锁被另一个线程持有，那么当前线程出于线程调度的目的，将会被禁用并处于休眠状态，\n     * 直到发生以下三种情况之一：\n     * - 当前线程获取锁成功；或者\n     * - 其他线程中断当前线程；或者\n     * - 达到了指定的超时等待时间。\n     *\n     * 如果当前线程获取到了锁，则锁持有计数设置为 1。\n     *\n     * 如果当前线程：\n     * - 在进入此方法时设置其中断状态；或者\n     * - 在获取锁过程中被中断，\n     * 然后会抛出 InterruptedException 并清除当前线程的中断状态。\n     *\n     * 如果到达了指定的超时时间，则返回 false。如果时间小于或等于零，则该方法不会等待。\n     *\n     * 在此实现中，由于此方法明显表示出中断能力，因此优先响应中断而不是\n     * 正常执行或可重入获取锁，同时也优先于报告超过等待时间。\n     *\n     *\n     * 参数：timeout - 等待锁的时间\n     *      unit - timeout 参数的时间单位\n     * 返回：如果锁是空闲的并被当前线程获取到，或者锁已经被当前线程持有，则返回true；\n     *      如果在获得锁之前达到了超时时间，则返回 false\n     * @throws InterruptedException - 如果当前线程被中断\n     * @throws NullPointerException - 如果时间单位为空\n     */\n    public boolean tryLock(long timeout, TimeUnit unit)\n            throws InterruptedException {\n        return sync.tryAcquireNanos(1, unit.toNanos(timeout));\n    }\n\n    /**\n     * 尝试释放此锁。\n     *\n     * 如果当前线程是这个锁的持有者，那么持有计数就会递减。如果持有计数现在为 0，则直接释放锁。\n     * 如果当前线程不是该锁的持有者，则抛出 IllegalMonitorStateException。\n     *\n     * @throws IllegalMonitorStateException - 如果当前线程没有持有这个锁。\n     */\n    public void unlock() {\n        sync.release(1);\n    }\n\n    /**\n     * 返回与当前 Lock 实例一起使用的 Condition 实例。\n     *\n     * 当与内置的监视器锁一起使用时，返回的 Condition 实例支持与 Object 监视器方法\n     * （wait、notify 和 notifyAll） 相同的用法。\n     *\n     * - 如果在调用任何 Condition 的 await 和 signal 方法时，未持有锁，则会引发 \n     *   IllegalMonitorStateException。\n     * - 当 Condition 的 await 方法被调用时，锁被释放，在该线程返回前，锁会被其他线程\n     *   重新获得，锁持有计数会恢复到调用方法时的状态。\n     * - 如果线程在等待过程中被中断，则等待终止，并抛出 InterruptedException，并清除\n     *   线程的中断状态。\n     * - 以 FIFO 顺序 signal 等待线程。\n     * - 从 await 方法返回的线程重新获取锁的顺序与最初获取锁的线程顺序相同，在默认情况下，\n     *   非公平锁，未指定顺序；但对于公平锁，优先考虑那些等待时间长的线程。\n     *\n     * 返回：Condition 对象\n     */\n    public Condition newCondition() {\n        return sync.newCondition();\n    }\n\n    /**\n     * 查询当前线程持有该锁的次数。\n     *\n     * 如果解锁的次数和加锁的次数不匹配，那么该线程会持有该锁。\n     *\n     * 持有计数信息通常仅用于测试和调试目的。例如，如果某段代码不应该在已经持有锁的情况下输入，\n     * 那么我们可以断言这个事实：\n     * \n     * class X {\n     *     ReentrantLock lock = new ReentrantLock();\n     *     // ...\n     *     public void m() {\n     *         assert lock.getHoldCount() == 0;\n     *         lock.lock();\n     *         try {\n     *             // ... method body\n     *         } finally {\n     *             lock.unlock();\n     *         }\n     *     }\n     * }\n     *\n     * 返回：当前线程持有锁的次数，如果当前线程未持有锁，则为零\n     */\n    public int getHoldCount() {\n        return sync.getHoldCount();\n    }\n\n    /**\n     * 查询当前线程是否持有该锁。\n     *\n     * 类似于内置监视器锁的 Thread.holdsLock(Object) 方法，此方法通常用于调试和测试。\n     * 例如，如果一个线程只有在持有锁时，才调用该方法，可以这样断言：\n     *\n     * class X{\n     *     ReentrantLock lock = new ReentrantLock();\n     *     // ...\n     *     \n     *     public void m(){\n     *         assert lock.isHeldByCurrentThread();\n     *         // ... method body\n     *     }\n     * }\n     *\n     * 它还可以用于确保以不可重入方式使用可重入锁，例如：\n     *\n     * class X{\n     *     ReentrantLock lock = new ReentrantLock();\n     *     // ...\n     *     \n     *     public void m(){\n     *         assert !lock.isHeldByCurrentThread();\n     *         lock.lock();\n     *         try {\n     *             // ... method body\n     *         } finally {\n     *             lock.unlock;\n     *         }\n     *     }\n     * }\n     *\n     * 返回：如果当前线程持有该锁，返回 true；否则返回 false\n     */\n    public boolean isHeldByCurrentThread() {\n        return sync.isHeldExclusively();\n    }\n\n    /**\n     * 查询当前锁是否被持有。此方法设计用于监控系统状态，而不用于同步控制。\n     *\n     * 返回：任何线程持有此锁，返回 true；否则返回 false。\n     */\n    public boolean isLocked() {\n        return sync.isLocked();\n    }\n\n    /**\n     * 如果此锁的公平性设置为 true，则返回 true。\n     *\n     * 返回：如果此锁的公平性设置为 true，则返回 true。\n     */\n    public final boolean isFair() {\n        return sync instanceof FairSync;\n    }\n\n    /**\n     * 返回拥有此锁的线程，如果锁没有被持有，返回 null。如果当前线程不是锁的持有者，\n     * 调用此方法会返回当前锁定状态的近似值。例如，即使有线程在尝试获取锁，但还没有\n     * 获取成功，所有者也可能暂时为 null。此方法主要目的在于促进提供更广泛的锁监视\n     * 设施的子类的构建。\n     *\n     * 返回：锁的持有者，如果没有，返回 null。\n     */\n    protected Thread getOwner() {\n        return sync.getOwner();\n    }\n\n    /**\n     * 查询是否有线程正在等待获取此锁。请注意，由于取消可能随时发生，因此返回 true，\n     * 并不意味着其他线程就会获取锁。此方法主要设计用于监控系统状态。\n     *\n     * 返回：如果可能有其他线程等待获取锁，则为true。\n     */\n    public final boolean hasQueuedThreads() {\n        return sync.hasQueuedThreads();\n    }\n\n    /**\n     * 查询给定线程是否正在等待获取此锁。请注意，由于取消可能随时发生，因此返回 true，\n     * 并不意味着该线程就会获取锁。此方法主要设计用于监控系统状态。\n     *\n     * 参数：thread - 线程\n     * 返回：如果给定线程可能等待获取锁，则为true。\n     * @throws NullPointerException thread 为 null\n     */\n    public final boolean hasQueuedThread(Thread thread) {\n        return sync.isQueued(thread);\n    }\n\n    /**\n     * 返回等待获取该锁的线程数的近似值。该值为一个预估值，因为在该方法遍历内部\n     * 数据结构时，线程数可能会动态发生变化。此方法主要设计用于监控系统状态，而不\n     * 是用于同步控制。\n     *\n     * 返回：等待此锁的预估线程数\n     */\n    public final int getQueueLength() {\n        return sync.getQueueLength();\n    }\n\n    /**\n     * 返回一个集合，其中包含正在等待获取此锁的线程。因为在构造这个结果时，实际的\n     * 线程集合可能会动态变化，所以返回的集合只是预估值。返回集合的元素没有特定顺序。\n     * 此方法主要目的在于促进提供更广泛的锁监视设施的子类的构建。\n     *\n     * 返回：线程集合。\n     */\n    protected Collection&amp;lt;Thread&amp;gt; getQueuedThreads() {\n        return sync.getQueuedThreads();\n    }\n\n    /**\n     * 查询是否有线程正在等待与当前锁关联的 Condition。请注意，\n     * 由于超时和中断可能随时发生，因此返回 true，并不意味着将来 signal 无法唤醒等待线程。\n     * 此方法主要设计用于监控系统状态。\n     * \n     * 参数：condition - condition\n     * 返回：如果有任何等待线程，返回 true\n     * @throws IllegalMonitorStateException - 如果没有持有这个锁\n     * @throws IllegalArgumentException - 如果给定条件与此锁没有关联\n     * @throws NullPointerException - condition 为 null\n     */\n    public boolean hasWaiters(Condition condition) {\n        if (condition == null)\n            throw new NullPointerException();\n        if (!(condition instanceof AbstractQueuedSynchronizer.ConditionObject))\n            throw new IllegalArgumentException(&amp;quot;not owner&amp;quot;);\n        // 判断当前 condition 是否存在等待节点\n        return sync.hasWaiters((AbstractQueuedSynchronizer.ConditionObject)condition);\n    }\n\n    /**\n     * 返回等待与当前锁关联的给定 condtion 的线程数的估计值。请注意，\n     * 由于超时和中断可能随时发生，因此此值进作为实际等待节点的上限。\n     * 此方法主要设计用于监控系统状态，不用来做同步控制。\n     * \n     * 参数：condition - condition\n     * 返回：预估的等待线程数\n     * @throws IllegalMonitorStateException - 如果没有持有这个锁\n     * @throws IllegalArgumentException - 如果给定条件与此锁没有关联\n     * @throws NullPointerException - condition 为 null\n     */\n    public int getWaitQueueLength(Condition condition) {\n        if (condition == null)\n            throw new NullPointerException();\n        if (!(condition instanceof AbstractQueuedSynchronizer.ConditionObject))\n            throw new IllegalArgumentException(&amp;quot;not owner&amp;quot;);\n        return sync.getWaitQueueLength((AbstractQueuedSynchronizer.ConditionObject)condition);\n    }\n\n    /**\n     * 返回线程集合，其中包含可能正在等待与此锁相关联的指定 condition 的线程。因为在\n     * 构造这个结果时，实际的线程集合可能会动态变化，所以该集合返回的只是一个近似值。\n     * 返回集合的元素没有特定顺序。此方法主要目的在于促进提供更广泛的锁监视设施的子类的构建。\n     *\n     * 参数：condition - condition\n     * 返回：线程集合\n     * @throws IllegalMonitorStateException - 如果没有持有这个锁\n     * @throws IllegalArgumentException - 如果给定条件与此锁没有关联\n     * @throws NullPointerException - condition 为 null\n     */\n    protected Collection&amp;lt;Thread&amp;gt; getWaitingThreads(Condition condition) {\n        if (condition == null)\n            throw new NullPointerException();\n        if (!(condition instanceof AbstractQueuedSynchronizer.ConditionObject))\n            throw new IllegalArgumentException(&amp;quot;not owner&amp;quot;);\n        return sync.getWaitingThreads((AbstractQueuedSynchronizer.ConditionObject)condition);\n    }\n\n    /**\n     * 返回标识此锁的字符串及其锁状态。。括号中的状态包括字符串 &amp;quot;Unlocked&amp;quot; 或字符串\n     * &amp;quot;Locked by&amp;quot; 后跟拥有锁的线程的名称。\n     *\n     * 返回：一个标识这个锁的字符串，以及它的锁状态\n     */\n    public String toString() {\n        Thread o = sync.getOwner();\n        return super.toString() + ((o == null) ?\n                                   &amp;quot;[Unlocked]&amp;quot; :\n                                   &amp;quot;[Locked by thread &amp;quot; + o.getName() + &amp;quot;]&amp;quot;);\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;82-reentantreadwritelock\&#34;&gt;8.2 ReentantReadWriteLock&lt;/h3&gt;\n&lt;p&gt;该锁实现了 &lt;code&gt;ReadWriteLock&lt;/code&gt; 接口，并支持和 &lt;code&gt;ReentrantLock&lt;/code&gt; 相似的语义。&lt;/p&gt;\n&lt;p&gt;此类具有以下属性：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;&lt;strong&gt;顺序加锁&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;此类不会为读锁和写锁的访问强加优先级顺序。但是，它支持可选的 &lt;em&gt;公平&lt;/em&gt; 策略。&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;&lt;strong&gt;非公平模式（默认）&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;当构造非公平（默认）锁时，进入读写锁的顺序是未指定的，并受到重入的约束。一直存在竞争的非公平锁可能会无限期地推迟一个或多个读锁或写锁线程，但通常比公平锁具有更高的吞吐量。&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;&lt;strong&gt;公平模式&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;当构造为公平锁时，线程使用近似到达顺序策略竞争入队。如果当前持有的锁被释放，要么为等待时间最长的单个写入线程分配写锁，要么如果有一组读取线程等待时间比写入线程长，则为读取线程分配读锁。&lt;/p&gt;\n&lt;p&gt;如果持有写锁或存在等待写入线程，则尝试获取公平锁（不可重入）的线程将阻塞。直到当前等待时间最长的写入线程获得写锁并释放之后，该线程才会获得读锁。当然，在没有线程获取写锁的情况下，如果一个等待的写入线程放弃等待，剩下的一个或多个读取线程将作为队列中等待时间最长的，被分配读锁。&lt;/p&gt;\n&lt;p&gt;除非读锁和写锁都空闲（这意味着没有等待的线程），否则试图获取公平写锁（不可重入）的线程将阻塞。（请注意，非阻塞 &lt;code&gt;ReentrantReadWriteLock.ReadLock.tryLock()&lt;/code&gt; 和 &lt;code&gt;ReentrantReadWriteLock.WriteLock.tryLock()&lt;/code&gt; 方法不遵守此公平设置，如果可能，将立即获取锁，而不管等待线程。）&lt;/p&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;&lt;strong&gt;重入&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;此锁允许读取线程和写入线程以 &lt;code&gt;ReentrantLock&lt;/code&gt; 一样的方式重新获取读锁或写锁。在写入线程持有的所有写锁都被释放之前，不允许非重入的读取线程。&lt;/p&gt;\n&lt;p&gt;此外，写入线程可以获取读锁，但反之则不行。在其他应用程序中，当对在读锁下执行读取操作的方法在调用或回调期间持有写锁时，可重入性可能很有用。如果一个读取线程试图获得写锁，它将永远不会成功。&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;&lt;strong&gt;锁降级&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;重入还允许从写锁降级为读锁，方法是获取写锁，然后获取读锁，然后释放写锁。但是，&lt;strong&gt;无法&lt;/strong&gt; 从读锁升级为写锁。&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;&lt;strong&gt;锁获取中断&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;读锁和写锁都支持获取锁过程中的中断。&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;&lt;strong&gt;Condition 支持&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;写锁提供了一个 &lt;code&gt;Condition&lt;/code&gt; 实现，就写锁而言，它的行为方式与 &lt;code&gt;ReentrantLock.newCondition&lt;/code&gt; 提供的实现的行为方式相同。当然，这个 &lt;code&gt;Condition&lt;/code&gt; 只能与写锁一起使用。读锁不支持 &lt;code&gt;Condition&lt;/code&gt; 并且 &lt;code&gt;readLock().newCondition()&lt;/code&gt; 抛出 &lt;code&gt;UnsupportedOperationException&lt;/code&gt;。&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;&lt;strong&gt;Instrumentation&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;此类支持确定锁是否被持有或竞争的方法。这些方法是为监控系统状态而设计的，而不是为同步控制而设计的。&lt;/p&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;此类的序列化与内置锁的行为方式相同：反序列化锁将处于未锁定状态，无论其在序列化时的状态如何。&lt;/p&gt;\n&lt;p&gt;示例用法。这是一个代码草图，展示了如果在更新缓存后执行锁降级（以非嵌套方式处理多个锁时，异常处理特别棘手）：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;class CachedData {\n    Object data;\n    volatile boolean cacheVaild;\n    final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();\n\n    void processCachedData() {\n        rwl.readLock().lock();\n        if (!cacheVaild) {\n            // Must release read lock before acquiring write lock\n            rwl.readLock().unlock();\n            rwl.writeLock().lock();\n            try {\n                // Recheck state because another thread might have\n                // acquired write lock and changed state before we did.\n                if (!cacheVaild) {\n                    data = ...\n                    cacheVaild = true;\n                }\n                // Downgrade by acquiring read lock before releasing write lock\n                rwl.readLock().lock();\n            } finally {\n                rwl.writeLock().unlock(); // Unlock write, still hold read\n            }\n        }\n        \n        try {\n            use(data);\n        } finally {\n            rwl.readLock().unlock();\n        }\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;&lt;code&gt;ReentrantReadWriteLock&lt;/code&gt; 可以用于在某些集合的某些用途中提高并发性能。通常，只有当集合预计很大、被很多线程读取，但对写入很少时，并且开销要超过同步开销的操作时，才值得这么做。例如，这里有一个使用 &lt;code&gt;TreeMap&lt;/code&gt; 的类，该类预计会很大，并且可以并发访问。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;class RWDictionary {\n    private final Map&amp;lt;String, Data&amp;gt; m = new TreeMap&amp;lt;String, Data&amp;gt;();\n    private final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();\n    private final Lock r = rwl.readLock();\n    private final Lock w = rwl.writeLock();\n\n    public Data get(String key) {\n        r.lock();\n        try {\n            return m.get(key);\n        } finally {\n            r.unlock();\n        }\n    }\n\n    public String[] allKeys() {\n        r.lock();\n        try {\n            return m.keySet().toArray();\n        } finally {\n            r.unlock();\n        }\n    }\n\n    public Data put(String key, Data value) {\n        w.lock();\n        try {\n            return m.put(key, value);\n        } finally {\n            w.unlock();\n        }\n    }\n\n    public void clear() {\n        w.lock();\n        try {\n            m.clear();\n        } finally {\n            w.unlock();\n        }\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;&lt;strong&gt;实现注意事项&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;该锁最多支持 65535 个重入写锁和 65535 个读锁。如果超出这些限制会导致 &lt;code&gt;lock&lt;/code&gt; 方法引发 &lt;code&gt;Error&lt;/code&gt;。&lt;/p&gt;\n&lt;h4 id=\&#34;821-sync\&#34;&gt;8.2.1  Sync&lt;/h4&gt;\n&lt;p&gt;和 &lt;code&gt;ReentrantLock&lt;/code&gt; 相似，在 &lt;code&gt;ReentrantReadWriteLock&lt;/code&gt; 类中同样有基于 &lt;code&gt;AQS&lt;/code&gt; 框架实现的内部类 &lt;code&gt;Sync&lt;/code&gt;。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;/**\n * ReentrantReadWriteLock 的同步实现。\n * 分为公平和非公平版本。\n */\nabstract static class Sync extends AbstractQueuedSynchronizer {\n    private static final long serialVersionUID = 6317671515068378041L;\n\n    /*\n     * 读锁和写锁计数提取常量和函数。\n     * 锁的状态在逻辑上分为两个无符号 short：\n     * 较低的表示独占（写锁）锁持有计数，\n     * 较高的表示共享（读锁）锁持有计数。\n     */\n\n    // 共享锁（读锁）的偏移量\n    static final int SHARED_SHIFT   = 16;\n    /**\n     * 我们每次在进行读锁数量增加 +1 时，只需直接将 SHARED_UNIT 加上 state 即可。\n     * 举个例子，在十进制中，如果我们只有四位，读锁只能操作高位的2个数字，写锁只能操作\n     * 低位的两个数字，那么如果想要让读锁加一，那我们就需要加上 100，此时数字就是 01 | 00。\n     * 如果我们还想要再次加一，此时同样是加上 100，就是 02 | 00，这样就实现了读锁加一的效果，\n     * 而写锁，只需要直接加一即可。而这个 100 其实就是我们位数的偏移量，100 就是 1 左移 2 位即可，\n     * 因为写锁占了低位，所以我们要偏移后，这个 SHARED_UNIT 就是我们每次增减的值。\n     */\n    static final int SHARED_UNIT    = (1 &amp;lt;&amp;lt; SHARED_SHIFT);\n    // 读/写锁的最大数量，为什么减一，以上面的例子来说，两位只能是 00 ~ 99，\n    // 也就是 1 &amp;lt;&amp;lt; SJARED_SHIFT - 1，因为再加的话，就溢出到高位了\n    static final int MAX_COUNT      = (1 &amp;lt;&amp;lt; SHARED_SHIFT) - 1;\n    // 低 16 位全部为 1，高 16 位全部是 0，当我们想要计算独占锁（读锁，占低 16 位）\n    // 的数量时（因为可能会有重入），将 state &amp;amp; EXCLUSIVE_MARK，进行 &amp;amp; 操作，\n    // （都为 1 才保留，其余全部为 0），高位数字会被清掉，所以就计算出了低 16 位.\n    // 也就是写锁的数量\n    static final int EXCLUSIVE_MASK = (1 &amp;lt;&amp;lt; SHARED_SHIFT) - 1;\n\n    /** 返回读锁的数量  */\n    static int sharedCount(int c)    { return c &amp;gt;&amp;gt;&amp;gt; SHARED_SHIFT; }\n    /** 返回写锁的数量  */\n    static int exclusiveCount(int c) { return c &amp;amp; EXCLUSIVE_MASK; }\n\n    /**\n     * 每个线程的读锁持有数量，维护为 ThreadLocal，缓存在 cachedHoldCounter\n     */\n    static final class HoldCounter {\n        int count = 0;\n        // 使用线程 id，而不是引用，避免垃圾滞留\n        final long tid = getThreadId(Thread.currentThread());\n    }\n\n    /**\n     * ThreadLocal 子类，为了反序列化，使用最简单明确的定义。\n     */\n    static final class ThreadLocalHoldCounter\n        extends ThreadLocal&amp;lt;HoldCounter&amp;gt; {\n        public HoldCounter initialValue() {\n            return new HoldCounter();\n        }\n    }\n\n    /**\n     * 当前线程持有的可重入读锁数量。仅在构造函数和 readObject 中初始化。\n     * 每当线程的读取计数减为 0 时删除。\n     */\n    private transient ThreadLocalHoldCounter readHolds;\n\n    /**\n     * 最后一个线程成功获取 readLock 的持有计数。这节省了 ThreadLocal\n     * 查找，在通常情况下，下一个要 release 的线程是最后一个 acquire 的线程。\n     * 这是非 volatile 的，因为它只是作为一种试探，对线程进行缓存有利。\n     *\n     * 该读取计数缓存的生命周期可能比线程更长，因为内部使用线程 id，而不是\n     * 线程引用，来避免垃圾回收保留。\n     *\n     * 通过良性数据竞争访问；依赖于内存模型的 final 字段和 out-of-thin-air 的保证。\n     */\n    private transient HoldCounter cachedHoldCounter;\n\n    /**\n     * firstReader 是第一个获得读锁的线程。firstReaderHoldCount 是 first\n     * 的持有计数。\n     *\n     * 更准确的说，firstReader 是最后一次将共享计数从 0 改为 1 的唯一线程，\n     * 此后一直没有释放读锁；如果没有这样的线程，则为 null。\n     *\n     * 除非线程在没有放弃读锁的情况下终止，否则不会导致垃圾保留，因为 tryReleaseShared\n     * 会将其设置为 null。\n     *\n     * 通过良性数据竞争访问；依赖于内存模型对引用的 out-of-thin-air 保证。\n     *\n     * 这使得对非竞争读锁的持有计数保存跟踪非常简单。\n     */\n    private transient Thread firstReader = null;\n    private transient int firstReaderHoldCount;\n\n    Sync() {\n        // 初始化读锁的持有计数 ThreadLocal\n        readHolds = new ThreadLocalHoldCounter();\n        setState(getState()); // 确保 readHolds 的内存可见性\n    }\n\n    /*\n     * 公平锁和非公平锁使用相同的 acquires 和 releases 代码，但在队列非空时，\n     * 它们在是否允许插入方面会有所不同。\n     */\n\n    /**\n     * 该方法返回当前线程请求获得读锁是否应该被阻塞，在公平和非公平策略下实现不同。\n     * 在公平锁中，如果队列中当前线程之前 有 其他线程排队，则返回 true，当在队列头部\n     * 或者队列为空则返回 false。\n     * 在非公平锁中，如果队列头部的等待节点是写入线程，则返回 true，避免写入线程无限等待；\n     * 如果写入线程不在队头，则返回 false，不影响其他线程进行读取。\n     */\n    abstract boolean readerShouldBlock();\n\n    /**\n     * 返回当前线程请求获得写锁是否应该被阻塞，在公平锁中，行为和 reader 一样，都会检查在\n     * 自己之前是否有其他线程排队；在非公平锁中，总是返回 false，不阻塞。\n     */\n    abstract boolean writerShouldBlock();\n\n    /*\n     * 注意 tryRelease 和 tryAcquire 可以被 Condition 调用。因此，\n     * 它们的参数可能会是包含所有的读锁计数和写锁计数，在条件等待期间全部释放并\n     * tryAcquire 重新建立读锁和写锁持有计数。\n     */\n    // 读锁释放\n    protected final boolean tryRelease(int releases) {\n        // 判断当前线程是否是独占线程\n        if (!isHeldExclusively())\n            throw new IllegalMonitorStateException();\n        // 读锁模式下是单线程，计算释放后的值\n        int nextc = getState() - releases;\n        // 判断是否全部释放\n        boolean free = exclusiveCount(nextc) == 0;\n        if (free)\n            // 清空独占线程\n            setExclusiveOwnerThread(null);\n        // 写入新的 state\n        setState(nextc);\n        return free;\n    }\n\n    // 读锁获取\n    protected final boolean tryAcquire(int acquires) {\n        /*\n         * 步骤：\n         * 1. 如果读锁计数不为 0 或写锁计数不为 0，且当前线程不是锁持有者，失败。\n         * 2. 如果计数饱和（溢出），失败（只有在计数不为 0 时才会出现）。\n         * 3. 否则，如果该线程是可重入加锁或队列策略允许（非公平锁可以抢占，\n         * 即 writerShouldBlock 返回 false），则该线程有资格获取锁。如果是这样，\n         * CAS更新状态并设置独占线程。\n         */\n        Thread current = Thread.currentThread();\n        int c = getState();\n        // 独占（写）锁数量\n        int w = exclusiveCount(c);\n        // c 不为零，即存在读锁或写锁被持有（也可能是自己）\n        if (c != 0) {\n            // (注意: 如果 c != 0 且 w == 0 那么共享（读）锁数量不为 0)\n            // 如果 w == 0 说明读锁不为零，读锁有则加锁失败。\n            // 如果 w == 0 没有满足，说明现在写锁不为零，判断当前线程是不是\n            // 独占线程，如果是，则尝试重入，如果不是则失败\n            if (w == 0 || current != getExclusiveOwnerThread())\n                return false;\n            // 独占线程重入，检查是否超过最大重入数量\n            if (w + exclusiveCount(acquires) &amp;gt; MAX_COUNT)\n                throw new Error(&amp;quot;Maximum lock count exceeded&amp;quot;);\n            // 重入计数\n            setState(c + acquires);\n            return true;\n        }\n        // 判断当前写锁是否需要阻塞，如果需要阻塞，失败\n        // 如果不需要阻塞，则 CAS 修改持有计数，加锁并设置独占线程\n        if (writerShouldBlock() ||\n                !compareAndSetState(c, c + acquires))\n            return false;\n        setExclusiveOwnerThread(current);\n        return true;\n    }\n\n    // 共享（写）锁释放\n    protected final boolean tryReleaseShared(int unused) {\n        Thread current = Thread.currentThread();\n        // 当前线程是否是 firstReader，在没有竞争的情况下，这个变量可以帮助我们\n        // 更加简单快速的去确认读取所的持有数量\n        if (firstReader == current) {\n            // assert firstReaderHoldCount &amp;gt; 0;\n            // 如果只有一个读取锁持有数量，直接释放锁，并将 firstReader 置空\n            if (firstReaderHoldCount == 1)\n                firstReader = null;\n            else\n                // 将持有数量 -1\n                firstReaderHoldCount--;\n        } else {\n            // 如果不是当前线程，说明现在有多个线程持有读锁\n            // 如果缓存是 null 或者 缓存线程不是当前线程，说明当前线程不是最后一次获取\n            // 持有读锁的线程，则从 threadLocal 读取\n            HoldCounter rh = cachedHoldCounter;\n            if (rh == null || rh.tid != getThreadId(current))\n                rh = readHolds.get();\n            // 当前的读锁计数\n            int count = rh.count;\n            // 如果当前持有的读锁计数小于等于 1，直接删除 ThreadLocal 值\n            if (count &amp;lt;= 1) {\n                readHolds.remove();\n                // 如果还没开始释放就 &amp;lt;= 0，这说明有逻辑问题，抛出异常\n                if (count &amp;lt;= 0)\n                    throw unmatchedUnlockException();\n            }\n            // 计数器减一\n            --rh.count;\n        }\n        // 自旋 CAS 修改共享锁计数\n        for (;;) {\n            int c = getState();\n            // c - SHARED_UNIT(共享锁的一个单元)，也就是对高 16 位进行减一操作\n            int nextc = c - SHARED_UNIT;\n            if (compareAndSetState(c, nextc))\n                // 释放读锁对写锁没有影响，但如果读锁和写锁都空闲（nextc 为 0），\n                // 则表示可以唤醒后面等待的线程\n                return nextc == 0;\n        }\n    }\n\n    private IllegalMonitorStateException unmatchedUnlockException() {\n        return new IllegalMonitorStateException(\n                &amp;quot;attempt to unlock read lock, not locked by current thread&amp;quot;);\n    }\n\n    // 共享（写）锁的获取\n    protected final int tryAcquireShared(int unused) {\n        /*\n         * 步骤：\n         * 1. 如果写锁被另一个线程持有，则失败。\n         * 2. 否则，该线程有资格获得锁定状态，因此请询问它是否应该\n         *    因为队列策略而阻塞。如果没有，请尝试通过 CAS 更新 state\n         *    并更新计数。注意，该步骤不检查可重入 acquire，它被推迟\n         *    在 fullTryAcquireShared 中，从而避免在更典型的\n         *    不可重入的场景下，检查持有计数。\n         * 3. 如果由于线程不符合条件或 CAS 失败或计数已经饱和，\n         *    则步骤 2 失败，然后将会进行 fullTryAcquireShared 方法。\n         */\n        Thread current = Thread.currentThread();\n        int c = getState();\n        // 写锁数量不为 0，并且当前线程不为独占线程\n        // 这一步就是我们进行锁降级时，持有写锁然后去获取读锁的基础\n        if (exclusiveCount(c) != 0 &amp;amp;&amp;amp;\n                getExclusiveOwnerThread() != current)\n            return -1;\n        // 获取读锁数量\n        int r = sharedCount(c);\n        // 判断读锁是否应该阻塞\n        if (!readerShouldBlock() &amp;amp;&amp;amp;\n                // 判断当前是否溢出\n                r &amp;lt; MAX_COUNT &amp;amp;&amp;amp;\n                // CAS 尝试加锁\n                compareAndSetState(c, c + SHARED_UNIT)) {\n            // 加锁成功后，判断是否是首个获取读锁的线程\n            if (r == 0) {\n                // 将 firstReader 和 firstReaderHoldCount 赋值\n                firstReader = current;\n                firstReaderHoldCount = 1;\n              // 当前线程是否是首个获取读锁的线程重入了\n            } else if (firstReader == current) {\n                // 持有计数递增\n                firstReaderHoldCount++;\n            } else {\n                // 非首个线程，判断自己是否是上次来访问 AQS 加锁的线程\n                HoldCounter rh = cachedHoldCounter;\n                // 当自己也不是上次加锁的线程，那只能从 threadLocal 中读取\n                if (rh == null || rh.tid != getThreadId(current))\n                    // 更新 rh 和 cachedHoldCounter，因为自己是最后一次获取\n                    // 读锁成功的线程\n                    cachedHoldCounter = rh = readHolds.get();\n                else if (rh.count == 0)\n                    // 读锁数量为零，说明是同一个线程之前全部释放后，再次加锁\n                    // 由于当线程释放完后，会清空 threadLocal，但是并不会清理\n                    // cachedHoldCounter，所以，当同一个线程释放完，再次过来\n                    // 获取（中间没有其他线程过来加锁），那 cachedHoldCounter 持有的\n                    // 计数是仍然存在的，所以只需要将计数重新放回 threadLocal 即可\n                    readHolds.set(rh);\n                // 持有计数递增\n                rh.count++;\n            }\n            return 1;\n        }\n        // 需要阻塞，或读锁移除，或 CAS 失败\n        return fullTryAcquireShared(current);\n    }\n\n    /**\n     * 读锁进行 acquire 的完整版本，它处理 CAS 失败和在 tryAcquireShared\n     * 中未处理的重入获取\n     */\n    final int fullTryAcquireShared(Thread current) {\n        /*\n         * 此代码与 tryAcquireShared 中的代码部分冗余，但总体上更简单，\n         * 因为不会使 tryAcquireShared 与重试和延迟读取持有计数之间的交互\n         * 复杂化。\n         */\n        HoldCounter rh = null;\n        // 自旋加锁\n        for (;;) {\n            int c = getState();\n            // 独占锁数量不为零，则判断当前线程是否是独占线程，非独占则失败\n            if (exclusiveCount(c) != 0) {\n                if (getExclusiveOwnerThread() != current)\n                    return -1;\n                // 否则我们持有独占锁；如果我们在持有写锁的情况下，在这里阻塞会导致死锁。\n                // 所以我们直接放行\n              \n              // 下面判断没有线程持有写锁，排队的情况\n            } else if (readerShouldBlock()) {\n                // 在这里面说明我们获取 readLock 需要阻塞的，说明在我们之前可能有其他排队线程\n                // 确保我们没有以可重入的方式获取读锁\n                // 如果当前线程是已经获取过读锁，再次重入的，直接放行\n                if (firstReader == current) {\n                    // assert firstReaderHoldCount &amp;gt; 0;\n                } else {\n                    // 到这里，我们不是首次获取读锁的\n                    // 首次自旋 rh 是 null，那需要给 rh 赋值\n                    if (rh == null) {\n                        // 先给 rh 赋为 cachedHoldCounter，即假设我们是最后一个获取的\n                        rh = cachedHoldCounter;\n                        // 如果 rh 为空，或者 rh 的线程并不是自己，则从 threadLocal 查找\n                        if (rh == null || rh.tid != getThreadId(current)) {\n                            // 查找获取 threadLocal 的值，如果我们没有持有锁，是首次获取\n                            // 那这一步会导致 threadLocal 实例化 HoldCounter，实例化后\n                            // 的 count 为 0，由于我们需要阻塞，所以肯定是失败的，目的就是\n                            // 检查我们是不是重入，重入的话就成功，失败需要把 threadLocal\n                            // 值清理掉\n                            rh = readHolds.get();\n                            // threadLocal 中的持有计数，如果为空，则移除 threadLocal\n                            if (rh.count == 0)\n                                readHolds.remove();\n                        }\n                    }\n                    // 如果我们没有持有锁，并且需要阻塞，则失败\n                    if (rh.count == 0)\n                        return -1;\n                }\n            }\n            // 如果限制持有锁数量达到最大，则失败\n            if (sharedCount(c) == MAX_COUNT)\n                throw new Error(&amp;quot;Maximum lock count exceeded&amp;quot;);\n            // CAS 尝试加写锁\n            if (compareAndSetState(c, c + SHARED_UNIT)) {\n                // 加锁成功，判断加锁前读锁数量是不是为 0，为 0 说明自己是第一个加锁的\n                if (sharedCount(c) == 0) {\n                    // 设置 firstReader 和 firstReaderHoldCount 主要为了提高性能\n                    firstReader = current;\n                    firstReaderHoldCount = 1;\n                // 不为零，判断当前线是否是 firstReader 重入\n                } else if (firstReader == current) {\n                    // 持有计数增加\n                    firstReaderHoldCount++;\n                } else {\n                    // 如果非 firstReader，则获取 threadLocal 值\n                    if (rh == null)\n                        // 先假设我们是最后一个加锁的\n                        rh = cachedHoldCounter;\n                    // 如果我们不是最后一个加锁的，则从 threadLocal 查找\n                    if (rh == null || rh.tid != getThreadId(current))\n                        rh = readHolds.get();\n                    // 我们是最后一个加锁的，则设置一下 threadLocal，因为\n                    // 随时会有其他线程在加锁成功后将 cachedHoldCounter 更新掉，\n                    // 这时候我们的计数就丢失了\n                    else if (rh.count == 0)\n                        readHolds.set(rh);\n                    // 增加持有读锁计数\n                    rh.count++;\n                    // 将自己更新为最后一个获取读锁的线程，缓存下来，提高性能\n                    cachedHoldCounter = rh; // cache for release\n                }\n                return 1;\n            }\n        }\n    }\n\n    /**\n     * 对写锁执行 tryLock，在两种策略（公平和非公平）下都会“闯入”。\n     * 这在效果上与 tryAcquire 相同，只是缺少对 writeShouldBlock\n     * 的调用。\n     */\n    final boolean tryWriteLock() {\n        Thread current = Thread.currentThread();\n        int c = getState();\n        // 说明有线程持有读/写锁\n        if (c != 0) {\n            // 判断读锁数量是否为 0，为 0 说明有其他线程持有写锁，那我们肯定失败\n            // 不为 0，则判断当前线程是否是重入，非重入，则直接失败\n            int w = exclusiveCount(c);\n            if (w == 0 || current != getExclusiveOwnerThread())\n                return false;\n            if (w == MAX_COUNT)\n                throw new Error(&amp;quot;Maximum lock count exceeded&amp;quot;);\n        }\n        // CAS 加锁\n        if (!compareAndSetState(c, c + 1))\n            return false;\n        // 成功后更新独占线程\n        setExclusiveOwnerThread(current);\n        return true;\n    }\n\n    /**\n     * 对读锁执行 tryLock，在两种策略下都会“闯入”。这在效果上与 \n     * tryAcquireShared 相同，只是缺少对 readerShouldBlock 的调用。\n     */\n    final boolean tryReadLock() {\n        Thread current = Thread.currentThread();\n        // 自旋尝试获取读锁\n        for (;;) {\n            int c = getState();\n            // 独占锁数量不为空，并且当前线程不是独占线程，则直接失败\n            if (exclusiveCount(c) != 0 &amp;amp;&amp;amp;\n                    getExclusiveOwnerThread() != current)\n                return false;\n            // 获取写锁数量\n            int r = sharedCount(c);\n            // 判断写锁数量是否已满\n            if (r == MAX_COUNT)\n                throw new Error(&amp;quot;Maximum lock count exceeded&amp;quot;);\n            // CAS 尝试加锁\n            if (compareAndSetState(c, c + SHARED_UNIT)) {\n                // 加锁成功，判断当前线程是不是首个获得读锁的\n                if (r == 0) {\n                    // 设置 firstReader 和 firstReaderCount\n                    firstReader = current;\n                    firstReaderHoldCount = 1;\n                // 读锁不为空，看看当前线程是否是 firstReader 重入，是的话直接增加计数\n                } else if (firstReader == current) {\n                    firstReaderHoldCount++;\n                } else {\n                    // 先从缓存中找，如果不是，则从 threadLocal 找\n                    HoldCounter rh = cachedHoldCounter;\n                    if (rh == null || rh.tid != getThreadId(current))\n                        cachedHoldCounter = rh = readHolds.get();\n                    else if (rh.count == 0)\n                        readHolds.set(rh);\n                    // 计数\n                    rh.count++;\n                }\n                return true;\n            }\n        }\n    }\n\n    // 是否是独占线程\n    protected final boolean isHeldExclusively() {\n        // While we must in general read state before owner,\n        // we don&#39;t need to do so to check if current thread is owner\n        return getExclusiveOwnerThread() == Thread.currentThread();\n    }\n\n    // Methods relayed to outer class\n\n    // 获取 condition\n    final ConditionObject newCondition() {\n        return new ConditionObject();\n    }\n\n    // 获取独占线程\n    final Thread getOwner() {\n        // Must read state before owner to ensure memory consistency\n        return ((exclusiveCount(getState()) == 0) ?\n                null :\n                getExclusiveOwnerThread());\n    }\n\n    // 获取读锁数量\n    final int getReadLockCount() {\n        return sharedCount(getState());\n    }\n\n    // 写锁是否被占有\n    final boolean isWriteLocked() {\n        return exclusiveCount(getState()) != 0;\n    }\n\n    // 获取当前线程持有的写锁数量\n    final int getWriteHoldCount() {\n        return isHeldExclusively() ? exclusiveCount(getState()) : 0;\n    }\n\n    // 获取当前线程持有读锁数量\n    final int getReadHoldCount() {\n        if (getReadLockCount() == 0)\n            return 0;\n\n        // 先从 firstReader 里面找\n        Thread current = Thread.currentThread();\n        if (firstReader == current)\n            return firstReaderHoldCount;\n\n        // 再从 cachedHoldCounter 找，没有则从 threadLocal 找\n        HoldCounter rh = cachedHoldCounter;\n        if (rh != null &amp;amp;&amp;amp; rh.tid == getThreadId(current))\n            return rh.count;\n\n        int count = readHolds.get().count;\n        if (count == 0) readHolds.remove();\n        return count;\n    }\n\n    /**\n     * 从流中读取对象（即反序列化）\n     */\n    private void readObject(java.io.ObjectInputStream s)\n            throws java.io.IOException, ClassNotFoundException {\n        s.defaultReadObject();\n        readHolds = new ThreadLocalHoldCounter();\n        setState(0); // reset to unlocked state\n    }\n\n    // 获取全部计数\n    final int getCount() { return getState(); }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h4 id=\&#34;822-公平锁和非公平锁\&#34;&gt;8.2.2 公平锁和非公平锁&lt;/h4&gt;\n&lt;p&gt;非公平锁：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;static final class NonfairSync extends Sync {\n    private static final long serialVersionUID = -8159625535654395037L;\n    final boolean writerShouldBlock() {\n        return false; // 非公平锁写入不需要阻塞\n    }\n    // \n    final boolean readerShouldBlock() {\n        /* 作为避免写入线程饿死的启发式方法，如果队列头部暂时显示为写入线程，则阻塞。\n         * 这只是一种概率效应，引入如果在写入线程之前有其他读取线程没有超时，则\n         * 读取线程不会阻塞。\n         */\n        // 判断队列头部线程是否是独占线程\n        return apparentlyFirstQueuedIsExclusive();\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;公平锁：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;static final class FairSync extends Sync {\n    private static final long serialVersionUID = -2274990926593161451L;\n    final boolean writerShouldBlock() {\n        return hasQueuedPredecessors();\n    }\n    final boolean readerShouldBlock() {\n        return hasQueuedPredecessors();\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h4 id=\&#34;823-读锁和写锁\&#34;&gt;8.2.3 读锁和写锁&lt;/h4&gt;\n&lt;h5 id=\&#34;8231-readlock\&#34;&gt;8.2.3.1  ReadLock&lt;/h5&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;public static class ReadLock implements Lock, java.io.Serializable {\n    private static final long serialVersionUID = -5992448646407690164L;\n    private final Sync sync;\n\n    /**\n     * 子类使用的构造器\n     *\n     * 参数：lock - 外部锁对象\n     * 参数：NullPointerException - 如果 lock 为空\n     */\n    protected ReadLock(ReentrantReadWriteLock lock) {\n        sync = lock.sync;\n    }\n\n    /**\n     * 获取读锁。\n     *\n     * 如果写锁没有被另一个线程持有，则获取读锁并立即返回。\n     *\n     * 如果写锁被另一个线程持有，那么当前线程处于调度目的将被禁用并处于休眠状态，\n     * 直到获得读锁为止。\n     */\n    public void lock() {\n        sync.acquireShared(1);\n    }\n\n    /**\n     * 获取读锁，线程中断则终止。\n     *\n     * 如果写锁没有被另一个线程持有，则获取读锁并立即返回。\n     *\n     * 如果写锁被另一个线程持有，那么出于调度的目的，该线程将被禁用并\n     * 进入休眠状态，直到发生以下两种状态之一：\n     * - 该线程获取到读锁；或者\n     * - 其他一些线程中断当前线程。\n     *\n     * 如果当前线程：\n     * - 进入此方法时设置中断状态；或者\n     * - 在线程获取读锁时被中断。\n     *\n     * 然后抛出InterruptedException并清除当前线程的中断状态。\n     *\n     * 在此实现中，由于此方法明显表示出中断能力，因此优先响应中断而不是\n     * 正常执行或可重入获取锁。\n     *\n     * @throws InterruptedException - 如果当前线程被中断\n     */\n    public void lockInterruptibly() throws InterruptedException {\n        sync.acquireSharedInterruptibly(1);\n    }\n\n    /**\n     * 仅当调用时另一个线程未持有写锁时才获取锁。\n     *\n     * 如果写锁没有被另一个线程持有，则获取读锁，并返回 true。即使此锁已设置为\n     * 使用公平排序策略，调用 tryLock() 将立即获取读锁（如果可用），无论其他\n     * 线程当前是否正在等待。这种“闯入”行为在某些情况下可能很有用，即便它会破坏\n     * 公平性。如果您想要要求此锁保证公平性设置，请使用与此几乎等效的 \n     * tryLock(0, TimeUnit.SECONDS)（它也会检测线程中断）。\n     *\n     * 如果写锁被另一个线程持有，则此方法立即返回 false。\n     *\n     * 返回：如果获得了锁，则返回 true\n     */\n    public boolean tryLock() {\n        return sync.tryReadLock();\n    }\n\n    /**\n     * 如果在给定的等待时间内获取写锁没有超时、或当前线程没有中断，则获取读锁。\n     *\n     * 如果写锁没有被另一个线程持有，则获取读锁，并返回 true。如果此锁已设置为\n     * 使用公平排序策略，则在此线程之前有任何其他线程等待锁，则不会获取锁。这与\n     * tryLock() 方法形成对比。如果你想要一个允许 “闯入” 公平锁的可超时 tryLock\n     * ，则可以将超时和非超时方法相结合使用：\n     *\n     * if (lock.tryLock() ||\n     *     lock.tryLock(timeout, unit)) {\n     *   ...\n     * }\n     *\n     * 如果写锁被另一个线程持有，那么出于调度的目的，该线程将被禁用并\n     * 进入休眠状态，直到发生以下三种状态之一：\n     * - 该线程获取到读锁；或者\n     * - 其他一些线程中断当前线程；或者\n     * - 超过指定的等待时间。\n     *\n     * 如果当前线程：\n     * - 进入此方法时设置中断状态；或者\n     * - 在线程获取读锁时被中断。\n     *\n     * 然后抛出InterruptedException并清除当前线程的中断状态。\n     *\n     * 在此实现中，由于此方法明显表示出中断能力，因此优先响应中断而不是\n     * 正常执行或可重入获取锁，以及报告等待超时。\n     *\n     * 参数：timeout - 等待读锁的时间\n     *      unit - timeout 参数的时间单位\n     * 返回：如果获得了读锁，则为 true\n     * @throws InterruptedException - 如果当前线程被中断\n     * @throws NullPointerException - 如果时间单位为空\n     */\n    public boolean tryLock(long timeout, TimeUnit unit)\n            throws InterruptedException {\n        return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout));\n    }\n\n    /**\n     * 尝试释放此锁。\n     *\n     * 如果读锁的数量为零，则写锁可以尝试获取。\n     */\n    public void unlock() {\n        sync.releaseShared(1);\n    }\n\n    /**\n     * 抛出 UnsupportedOperationException，因为 ReadLock 不支持 Cindition。\n     *\n     * @throws UnsupportedOperationException 总是\n     */\n    public Condition newCondition() {\n        throw new UnsupportedOperationException();\n    }\n\n    /**\n     * 返回标识此锁的字符串及其锁状态。括号中的状态包括字符串&amp;quot;Read locks =&amp;quot; ，后跟持有的读锁数。\n     *\n     * 返回：一个标识这个锁的字符串，以及它的锁状态\n     */\n    public String toString() {\n        int r = sync.getReadLockCount();\n        return super.toString() +\n                &amp;quot;[Read locks = &amp;quot; + r + &amp;quot;]&amp;quot;;\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h5 id=\&#34;8232-writelock\&#34;&gt;8.2.3.2 WriteLock&lt;/h5&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;public static class WriteLock implements Lock, java.io.Serializable {\n    private static final long serialVersionUID = -4992448646407690164L;\n    private final Sync sync;\n\n    /**\n     * 子类使用的构造器\n     *\n     * 参数：lock - 外部锁对象\n     * 参数：NullPointerException - 如果 lock 为空\n     */\n    protected WriteLock(ReentrantReadWriteLock lock) {\n        sync = lock.sync;\n    }\n\n    /**\n     * 获取写锁。\n     * \n     * 如果其他线程既没有持有读锁也没有持有写锁，则获取写锁并立即返回，将写锁持有\n     * 计数设置为 1。\n     * \n     * 如果当前线程已经持有写锁，则持有计数加一并立即返回。\n     *\n     * 如果锁被另一个线程持有，那么当前线程处于调度目的将被禁用并处于休眠状态，\n     * 直到获得写锁为止，此时写锁持有计数设置为 1。\n     */\n    public void lock() {\n        sync.acquire(1);\n    }\n\n    /**\n     * 获取写锁，线程中断则终止。\n     *\n     * 如果其他线程既没有持有读锁也没有持有写锁，则获取写锁并立即返回，\n     * 将写锁持有计数设置为 1。\n     *\n     * 如果当前线程已经持有写锁，则持有计数加一并立即返回。\n     *\n     * 如果锁被另一个线程持有，那么出于调度的目的，该线程将被禁用并\n     * 进入休眠状态，直到发生以下两种情况之一：\n     * - 该线程获取到写锁；或者\n     * - 其他一些线程中断当前线程。\n     *\n     * 如果当前线程获取到了写锁，则锁持有计数设置为 1。\n     *\n     * 如果当前线程：\n     * - 进入此方法时设置中断状态；或者\n     * - 在线程获取读锁时被中断。\n     *\n     * 然后抛出InterruptedException并清除当前线程的中断状态。\n     *\n     * 在此实现中，由于此方法明显表示出中断能力，因此优先响应中断而不是\n     * 正常执行或可重入获取锁。\n     *\n     * @throws InterruptedException - 如果当前线程被中断\n     */\n    public void lockInterruptibly() throws InterruptedException {\n        sync.acquireInterruptibly(1);\n    }\n\n    /**\n     * 仅当调用时没有其他线程未持有锁时才获取写锁。\n     *\n     * 如果其他线程既没有持有读锁也没有持有写锁，则获取写锁并立即返回，将写锁持有\n     * 计数设置为 1。即使此锁已设置为使用公平排序策略，调用 tryLock() 将立即获\n     * 取该锁（如果可用），无论其他线程当前是否正在等待。这种“闯入”行为在某些情况\n     * 下可能很有用，即便它会破坏公平性。如果您想要要求此锁保证公平性设置，请使用\n     * 与此几乎等效的  tryLock(0, TimeUnit.SECONDS)（它也会检测线程中断）。\n     *\n     * 如果当前线程已经持有写锁，则持有计数加一并立即返回。\n     * \n     * 如果锁被另一个线程持有，则此方法立即返回 false。\n     *\n     * 返回：如果获得了锁，则返回 true\n     */\n    public boolean tryLock( ) {\n        return sync.tryWriteLock();\n    }\n\n    /**\n     *\n     * 如果在给定的等待时间内获取锁没有超时、或当前线程没有中断，则获取读锁。\n     *\n     * 如果其他线程既没有持有读锁也没有持有写锁，则获取写锁并立即返回，将写锁持有\n     * 计数设置为 1。如果此锁已设置为使用公平排序策略，则在此线程之前有任何其他\n     * 线程等待锁，则不会获取锁。这与 tryLock() 方法形成对比。如果你想要一个\n     * 允许 “闯入” 公平锁的可超时 tryLock，则可以将超时和非超时方法相结合使用：\n     *\n     * if (lock.tryLock() ||\n     *     lock.tryLock(timeout, unit)) {\n     *   ...\n     * }\n     *\n     * 如果当前线程已经持有写锁，则持有计数加一并立即返回。\n     * \n     * 如果锁被另一个线程持有，那么出于调度的目的，该线程将被禁用并\n     * 进入休眠状态，直到发生以下三种状态之一：\n     * - 该线程获取到读锁；或者\n     * - 其他一些线程中断当前线程；或者\n     * - 超过指定的等待时间。\n     *\n     * 如果当前线程获取到了写锁，则锁持有计数设置为 1。\n     *\n     * 如果当前线程：\n     * - 进入此方法时设置中断状态；或者\n     * - 在线程获取读锁时被中断。\n     *\n     * 然后抛出InterruptedException并清除当前线程的中断状态。\n     *\n     * 在此实现中，由于此方法明显表示出中断能力，因此优先响应中断而不是\n     * 正常执行或可重入获取锁，以及报告等待超时。\n     *\n     * 参数：timeout - 等待读锁的时间\n     *      unit - timeout 参数的时间单位\n     * 返回：如果获得了读锁，则为 true\n     * @throws InterruptedException - 如果当前线程被中断\n     * @throws NullPointerException - 如果时间单位为空\n     */\n    public boolean tryLock(long timeout, TimeUnit unit)\n            throws InterruptedException {\n        return sync.tryAcquireNanos(1, unit.toNanos(timeout));\n    }\n\n    /**\n     * 尝试释放此锁。\n     *\n     * 如果当前线程是这个锁的持有者，那么持有计数就会递减。如果持有计数为零，\n     * 则释放锁。如果当前线不是该锁的持有者，则抛出 IllegalMonitorStateException。\n     *\n     * @throws IllegalMonitorStateException - 如果当前线程没有持有该锁\n     */\n    public void unlock() {\n        sync.release(1);\n    }\n\n    /**\n     * 返回与此 Lock 实例一起使用的 Condition 实例。\n     *\n     * 当与内置监视器锁一起使用时，返回的 Condition 实例支持与 Object 监视器\n     * 方法（wait、notify 和 notifyAll）相同的用法。\n     *\n     * - 如果在调用任何 Condition 方法时未持有此锁的写锁，则会抛出 \n     *   IllegalMonitorStateException。（写锁和读锁持有是独立的，因此不会被\n     *   检查或影响。但是，当前线程在持有写锁时，又获取读锁，同时调用条件等待方法本质上\n     *   是错误的，因为其他可以解除阻塞的线程无法获取写锁。）\n     * - 当 condition await 方法被调用时，写锁将被释放，在它们返回之前，写锁\n     *   将被重新获得，所持有计数恢复到调用方法时的状态。\n     * - 如果线程在等待过程中被中断，则等待将终止，将抛出 InterruptedException，\n     *   并清除线程的中断状态。\n     * - 等待线程以 FIFO 顺序 signal。\n     * - 从 await 方法返回的线程重新获取锁的顺序与最初获取锁的线程顺序相同，在默认情况下\n     *   未指定，但对于公平锁，会优先考虑哪些等待时间最长的线程。\n     *\n     * 返回：condition 对象\n     */\n    public Condition newCondition() {\n        return sync.newCondition();\n    }\n\n    /**\n     * 返回标识此锁的字符串及其锁状态。括号中的状态包括字符串&amp;quot;Unlocked&amp;quot;或\n     * 字符串&amp;quot;Locked by&amp;quot;后跟拥有线程的名称。\n     *\n     * 返回：一个标识这个锁的字符串，以及它的锁状态\n     */\n    public String toString() {\n        Thread o = sync.getOwner();\n        return super.toString() + ((o == null) ?\n                &amp;quot;[Unlocked]&amp;quot; :\n                &amp;quot;[Locked by thread &amp;quot; + o.getName() + &amp;quot;]&amp;quot;);\n    }\n\n    /**\n     * 查询当前线程是否持有该写锁。与 ReentrantReadWriteLock#isWriteLockedByCurrentThread \n     * 效果相同。\n     *\n     * 返回：如果当前线程持有此锁，则为true；否则为 false。\n     * @since 1.6\n     */\n    public boolean isHeldByCurrentThread() {\n        return sync.isHeldExclusively();\n    }\n\n    /**\n     * 查询当前线程持有该写锁的次数。对于解锁操作不匹配的每个锁定操作，\n     * 线程都持有一个锁。与 ReentrantReadWriteLock#getWriteHoldCount 的效果相同。\n     *\n     * 返回：当前线程持有此锁的次数，如果当前线程未持有此锁，则为零\n     * @since 1.6\n     */\n    public int getHoldCount() {\n        return sync.getWriteHoldCount();\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h4 id=\&#34;823-其他方法\&#34;&gt;8.2.3 其他方法&lt;/h4&gt;\n&lt;p&gt;下面我们看一下 &lt;code&gt;ReentrantReadWriteLock&lt;/code&gt; 中使用的线程 id 如何获取：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;/**\n * 返回给定线程的 thread ID。我们必须直接访问它，因为通过方法 Thread.getId() 返回的\n * 并不是最终的，并且已知会以不保留唯一映射的方式被覆盖。\n */\nstatic final long getThreadId(Thread thread) {\n    return UNSAFE.getLongVolatile(thread, TID_OFFSET);\n}\n\n// Unsafe mechanics\nprivate static final sun.misc.Unsafe UNSAFE;\nprivate static final long TID_OFFSET;\nstatic {\n    try {\n        UNSAFE = sun.misc.Unsafe.getUnsafe();\n        Class&amp;lt;?&amp;gt; tk = Thread.class;\n        TID_OFFSET = UNSAFE.objectFieldOffset\n                (tk.getDeclaredField(&amp;quot;tid&amp;quot;));\n    } catch (Exception e) {\n        throw new Error(e);\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;其他一些关于 ReentrantReadWriteLock 的基础监控方法，这里不在做描述。&lt;/p&gt;\n&lt;h3 id=\&#34;83-samphora\&#34;&gt;8.3 Samphora&lt;/h3&gt;\n&lt;p&gt;计数信号量。从概念上讲，信号量维护一组 permit（许可）。如果需要，每个 &lt;code&gt;acquire&lt;/code&gt; 都会阻塞，直到 permit 可用，然后获得它。每个 &lt;code&gt;release&lt;/code&gt; 都会添加一个 permit，可能会释放一个阻塞的获取者。但是，没有使用实际的 permit 对象；&lt;code&gt;Semaphore&lt;/code&gt; 只是对可用数量进行计数并采取相应的措施。&lt;/p&gt;\n&lt;p&gt;&lt;code&gt;Semaphore&lt;/code&gt; 通常用于限制可以访问某些（物理或逻辑）资源的线程数。例如，这是一个使用 &lt;code&gt;Semaphore&lt;/code&gt; 来控制对资源池访问的类：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;class Pool {\n  private static final int MAX_AVAILABLE = 100;\n  private final Semaphore available = new Semaphore(MAX_AVAILABLE, true);\n  \n  public Object getItem() throws InterruptedException {\n    available.acquire();\n    return getNextAvailableItem();\n  }\n  \n  public void putItem(Object x) {\n    if (markAsUnused(x)) {\n      available.release();\n    }\n  }\n  \n  // Not a particularly efficient data structure; just for demo\n  \n  protected Object[] items = ... whatever kinds of items being managed\n  protected boolean[] used = new boolean[MAX_AVAILABLE];\n  \n  protected synchronized Object getNextAvailableItem(){\n    for (int i = 0; i &amp;lt; MAX_AVAILABLE; ++i) {\n      if (!used[i]) {\n        used[i] = true;\n        return items[i];\n      }\n    }\n    return null;// not reached\n  }\n  \n  protected synchronized boolean markAsUnused(Object item) {\n    for (int i = 0; i &amp;lt; MAX_AVAILABLE; ++i) {\n      if (item == items[i]) {\n        if (used[i]) {\n          used[i] = false;\n          return true;\n        } else {\n          return false;\n        }\n      }\n    }\n    return false;\n  }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;在获取一个 item 之前，每个线程必须从 &lt;code&gt;Semaphore&lt;/code&gt; 中获得一个 permit，保证一个 item 可供使用。当线程处理完该 tiem 时，它被返回到池中，一个 permit 返回给 &lt;code&gt;Semaphore&lt;/code&gt;，允许另一个线程获取该 item。请注意，当调用 &lt;code&gt;acquire&lt;/code&gt; 时，不会持有同步锁，因为这将阻塞 item 返回池中。&lt;code&gt;Semaphore&lt;/code&gt; 封装了限制对池的访问所需的同步，与维护池本身的一致性所需的同步是分开的。&lt;/p&gt;\n&lt;p&gt;初始化为 1 的 &lt;code&gt;Semaphore&lt;/code&gt;，使用时最多只有一个 permit 可用，可以作为互斥锁。这通常称为二进制信号量（binary semaphore），因为它只有两种状态：1 个 permit 可用，或 0 个 permit 可用。当以这种方式使用时，二进制信号量具有这样的属性（与许多 &lt;code&gt;java.util.concurrent.locks.Lock&lt;/code&gt; 实现不同），即 “锁” 可以由所有者以外的线程释放（因为信号量没有所有权的概念）。这在一些专门的上下文中很有用，比如死锁恢复。&lt;/p&gt;\n&lt;p&gt;此类的构造函数可以选择接受一个 &lt;em&gt;公平&lt;/em&gt; 参数。当设置为 false 时，此类不保证线程获取 permit 的顺序。特别是，允许“闯入”，也就是说，调用 &lt;code&gt;acquire&lt;/code&gt; 的线程可以在一个一直等待的线程之前被允许分配一个 permit —— 从逻辑上来说，就是新线程将自己置于等待队列的头部。当 &lt;code&gt;fairness&lt;/code&gt; 设置为 true时，信号量保证调用任何 &lt;code&gt;acquire&lt;/code&gt; 方法的线程会按照这些线程被 &lt;code&gt;acquire&lt;/code&gt; 方法处理的顺序获得 permit（先进先出；FIFO）。请注意，FIFO 排序必然适用于这些方法中的特定内部执行点。因此，一个线程可以在另一个线程之前调用 &lt;code&gt;acquire&lt;/code&gt;，但在另一个线程之后到达排序点，并且从方法返回时类似。另外请注意，没有超时参数的 &lt;code&gt;tryAcquire&lt;/code&gt; 方法不遵循公平设置，会直接获取任何可用的 permit。&lt;/p&gt;\n&lt;p&gt;通常，用于控制资源访问的信号量应该被初始化公平的，以确保没有线程因访问资源而被饿死。当使用信号量进行其他类型的同步控制时，非公平排序的吞吐量优势通常超过公平性考虑。&lt;/p&gt;\n&lt;p&gt;该类还提供了一次获取和释放多个 permit 的方便方法。当使用这些方法且不设置公平性时，要注意线程有无限延迟被饿死的风险会增加。&lt;/p&gt;\n&lt;p&gt;内存一致性影响：线程中调用“释放”方法（比如 &lt;code&gt;release()&lt;/code&gt;）之前的操作 happen-before 另一线程中紧跟在成功的“获取”方法（比如 acquire()）之后的操作。&lt;/p&gt;\n&lt;h4 id=\&#34;831-sync\&#34;&gt;8.3.1 Sync&lt;/h4&gt;\n&lt;p&gt;信号量的同步实现。使用 &lt;code&gt;AQS&lt;/code&gt; 的 &lt;code&gt;state&lt;/code&gt; 来表示 permit。分为公平和非公平版本。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;abstract static class Sync extends AbstractQueuedSynchronizer {\n    private static final long serialVersionUID = 1192457210091910933L;\n\n    Sync(int permits) {\n        setState(permits);\n    }\n\n    final int getPermits() {\n        return getState();\n    }\n\n    // 非公平尝试获取资源，注意此方法会自旋直到获取成功，或可用资源不够用，直接返回相减后的数量\n    final int nonfairTryAcquireShared(int acquires) {\n        // 自旋获取 permit\n        for (;;) {\n            // 获取当前可用的 permit 数量\n            int available = getState();\n            // 获取后的剩余数量\n            int remaining = available - acquires;\n            // remaining 大于等于 0 时，尝试 CAS 获取，成功则直接返回\n            if (remaining &amp;lt; 0 ||\n                    compareAndSetState(available, remaining))\n                return remaining;\n        }\n    }\n\n    // 归还资源，同样，此方法会自旋直至成功\n    protected final boolean tryReleaseShared(int releases) {\n        // 自旋释放 permit\n        for (;;) {\n            // 获取当前的 permit 数量\n            int current = getState();\n            // 归还 permit\n            int next = current + releases;\n            // 判断归还后是否溢出\n            if (next &amp;lt; current) // overflow\n                throw new Error(&amp;quot;Maximum permit count exceeded&amp;quot;);\n            // CAS 归还\n            if (compareAndSetState(current, next))\n                return true;\n        }\n    }\n\n    // 获取资源，注意此方法在 CAS 修改后直接返回。\n    // 此方法在使用信号量来跟踪那些变为不可用资源的子类中很有用。\n    // 此方法与 acquire 的不同之处在于它不会阻塞，等待 permit 可用。\n    final void reducePermits(int reductions) {\n        // 自旋减少 permit \n        for (;;) {\n            int current = getState();\n            int next = current - reductions;\n            if (next &amp;gt; current) // underflow\n                throw new Error(&amp;quot;Permit count underflow&amp;quot;);\n            if (compareAndSetState(current, next))\n                return;\n        }\n    }\n\n    // 获取全部可用资源\n    final int drainPermits() {\n        for (;;) {\n            int current = getState();\n            if (current == 0 || compareAndSetState(current, 0))\n                return current;\n        }\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h4 id=\&#34;832-公平和非公平\&#34;&gt;8.3.2 公平和非公平&lt;/h4&gt;\n&lt;p&gt;非公平版：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;static final class NonfairSync extends Semaphore.Sync {\n    private static final long serialVersionUID = -2694183684443567898L;\n\n    NonfairSync(int permits) {\n        super(permits);\n    }\n\n    protected int tryAcquireShared(int acquires) {\n        return nonfairTryAcquireShared(acquires);\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;公平版：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;static final class FairSync extends Sync {\n    private static final long serialVersionUID = 2014338818796000944L;\n\n    FairSync(int permits) {\n        super(permits);\n    }\n\n    // 返回负数说明资源不够用\n    protected int tryAcquireShared(int acquires) {\n        // 自旋获取资源\n        for (;;) {\n            // 先判断队列中是否有等待阻塞的前驱节点\n            if (hasQueuedPredecessors())\n                return -1;\n            int available = getState();\n            int remaining = available - acquires;\n            if (remaining &amp;lt; 0 ||\n                    compareAndSetState(available, remaining))\n                return remaining;\n        }\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h4 id=\&#34;833-acquire-release\&#34;&gt;8.3.3 acquire &amp;amp; release&lt;/h4&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;public class Semaphore implements java.io.Serializable {\n    private static final long serialVersionUID = -3222578661600680210L;\n    /** All mechanics via AbstractQueuedSynchronizer subclass */\n    private final Sync sync;\n\n    /**\n     * 使用给定数量的 permit 创建信号量，并设置为非公平。\n     *\n     * 参数：permits - 可用的 permit 的初始数量。该值可能为负数，在\n     *                这种情况下，必须在任何 acquire 之前进行 release。\n     */\n    public Semaphore(int permits) {\n        sync = new NonfairSync(permits);\n    }\n\n    /**\n     * 创建具有给定 permit 数量和给定公平设置的 Semaphore 。\n     *\n     * 参数：permits - 可用的 permit 的初始数量。该值可能为负数，在\n     *                这种情况下，必须在任何 acquire 之前进行 release。\n     *      fair - 此信号量保证竞争 permit 的 acquire 为先进先出，则为 true；否则为 false\n     */\n    public Semaphore(int permits, boolean fair) {\n        sync = fair ? new FairSync(permits) : new NonfairSync(permits);\n    }\n\n    /**\n     * 从信号量获取一个 permit，阻塞直到获取一个可用，线程被中断则终止。\n     * \n     * 获得一个 permit，如果有可用则立即返回，并将可用 permit 数量减一。\n     *\n     * 如果没有可用的 permit，则处于线程调度目的，当前线程将被禁用并处于休眠状态，直到\n     * 发生以下两种情况下之一：\n     * - 其他一些线程调用此信号量的 release 方法，并且当前线接下来获得一个 permit；或者\n     * - 其他线程中断当前线程。\n     *\n     * 如果当前线程：\n     * - 在进入此方法时设置其中断状态；或者\n     * - 在等待过程中被中断。\n     *\n     * 然后抛出InterruptedException并清除当前线程的中断状态。\n     *\n     * @throws InterruptedException - 如果当前线程被中断。\n     */\n    public void acquire() throws InterruptedException {\n        sync.acquireSharedInterruptibly(1);\n    }\n\n    /**\n     * 从信号量获取一个 permit，阻塞直至获取一个可用。\n     *\n     * 获取一个 permit，如果存在可用会立即返回，并将可用 permit 减一。\n     *\n     * 如果没有可用的 permit，则处于线程调度目的，当前线程将被禁用并处于休眠状态，直到\n     * 某个其他线程调用此信号量的 release 方法并且当前线程被分配到可用的 permit。\n     *\n     * 如果当前线程在等待 permit 时发生中断，那么它将继续等待，但线程被分配 permit 的\n     * 时间与它在没有中断发生时收到 permit 的时间相比可能会发生变化。当线程从此方法返回\n     * 时，将设置其中断状态。\n     */\n    public void acquireUninterruptibly() {\n        sync.acquireShared(1);\n    }\n\n    /**\n     * 仅当在调用时有可用的 permit 时，才从此信号量获取 permit。\n     *\n     * 获取一个 permit，如果存在一个可用则立即返回 true，并将可用 permit 的数量减一。\n     *\n     * 如果没有可用的 permit，则此方法将立即返回 false。\n     *\n     * 即使次信号量已设置为公平排序策略，对于 tryAcquire() 的调用也会立即获得\n     * permit（如果可用），无论其他线程当前是否正在等待。这种“闯入”行为在某些情况下\n     * 可能很有用，即使它破坏了公平性。如果要尊重公平设置，请使用几乎等效的\n     * tryAcquire(0, TimeUnit.SECONDS)（它也会检测中断）。\n     *\n     * 返回：如果获得了 permit，则为 true；否则为 false。\n     */\n    public boolean tryAcquire() {\n        return sync.nonfairTryAcquireShared(1) &amp;gt;= 0;\n    }\n\n    /**\n     * 如果在给定超时时间内没有中断，且 permit 可用，则从信号量中获取一个 permit。\n     *\n     * 获取一个 permit，如果存在一个可用则立即返回 true，并将可用 permit 的数量减一。\n     *\n     * 如果没有可用的 permit，则处于线程调度目的，当前线程将被禁用并处于休眠状态，直到\n     * 发生以下三种情况下之一：\n     * - 其他一些线程调用此信号量的 release 方法，并且当前线接下来获得一个 permit；或者\n     * - 其他线程中断当前线程；或者\n     * - 超过指定的超时时间。\n     *\n     * 如果获得 permit，则返回 true。\n     *\n     * 如果当前线程：\n     * - 在进入此方法时设置其中断状态；或者\n     * - 在等待过程中被中断。\n     *\n     * 然后抛出InterruptedException并清除当前线程的中断状态。\n     *\n     * 如果经过指定的等待时间，则返回 false。如果时间小于等于零，则该方法不会等待。\n     * 参数：timeout - 等待 permit 的最大时间\n     *      unit - timeout 参数的时间单位\n     * 返回：如果已经获得 permit，则为 true；如果获得之前超过等待时间，则为 false。\n     * @throws InterruptedException - 如果当前线程被中断\n     */\n    public boolean tryAcquire(long timeout, TimeUnit unit)\n            throws InterruptedException {\n        return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout));\n    }\n\n    /**\n     * 释放 permit，将其返回给信号量。\n     *\n     * 释放 permit，将可用 permit 数量加一。如果任何线程试图获取 permit，则选择一个\n     * 线程给予刚释放的 permit。出于线程调度目的，该线程（重新）启用。\n     *\n     * 不要求线程必须先调用 acquire 获得 permit，之后才能 release 释放 permit。\n     * 信号量的正确使用是通过应用程序中的编程约定建立的。\n     */\n    public void release() {\n        sync.releaseShared(1);\n    }\n\n    /**\n     * 从信号量中获取给定数量的 permits，阻塞直到有足够数量的 permits 可用，线程中断\n     * 则终止。\n     *\n     * 获取给定数量的 permits，如果可用则立即返回 true，并将可用 permits 的数量减去\n     * 给定的数量。\n     *\n     * 如果没有可用的 permits，或可用 permits 数量不足，则处于线程调度目的，当前线程将\n     * 被禁用并处于休眠状态，直到发生以下量种情况下之一：\n     * - 其他一些线程调用此信号量的 release 方法，并且当前线接下来获得足够数量的 permits；或者\n     * - 其他线程中断当前线程。\n     *\n     * 如果当前线程：\n     * - 在进入此方法时设置其中断状态；或者\n     * - 在等待过程中被中断。\n     *\n     * 然后抛出InterruptedException并清除当前线程的中断状态。将分配给当前线程的 permits\n     * 改为分配给尝试获取 permit 的其他线程，就好像通过调用 release() 使 permits 可用\n     * 一样。\n     *\n     * 参数：permits - 获得的 permits 数量\n     * @throws InterruptedException - 如果当前线程被中断\n     * @throws IllegalArgumentException – 如果permits是负数\n     */\n    public void acquire(int permits) throws InterruptedException {\n        if (permits &amp;lt; 0) throw new IllegalArgumentException();\n        sync.acquireSharedInterruptibly(permits);\n    }\n\n    /**\n     * 从信号量获取给定数量的 permits，阻塞直至所有的 permits 可用。\n     *\n     * 获取给定数量的 permits，如果存在可用会立即返回，并将可用 permits 减去给定数量。\n     *\n     * 如果没有可用的 permits，或可用的 permits 不足则处于线程调度目的，当前线程将被禁\n     * 用并处于休眠状态，直到某个其他线程调用此信号量的 release 方法并且当前线程被分配\n     * 到足够数量可用的 permits。\n     *\n     * 如果当前线程在等待 permits 时发生中断，那么它将继续等待，并且它在队列中的位置不受\n     * 影响。当线程确实从此方法返回时，将设置其中断状态。\n     *\n     * 参数：permits - permits 数量\n     * @throws IllegalArgumentException - 如果 permits 为负数\n     */\n    public void acquireUninterruptibly(int permits) {\n        if (permits &amp;lt; 0) throw new IllegalArgumentException();\n        sync.acquireShared(permits);\n    }\n\n    /**\n     * 仅当调用时有给定数量的 permits 可用时，才从此信号量中获取到给定数量的 permits。\n     *\n     * 获取给定数量的 permits，如果存在可用会立即返回，并将可用 permit 减去给定数量。\n     * \n     * 如果可用的 permits 不足，则此方法立即返回 false，并且可用 permits 数量不变。\n     *\n     * 即使次信号量已设置为公平排序策略，对于 tryAcquire() 的调用也会立即获得\n     * permit（如果可用），无论其他线程当前是否正在等待。这种“闯入”行为在某些情况下\n     * 可能很有用，即使它破坏了公平性。如果要尊重公平设置，请使用几乎等效的\n     * tryAcquire(permits, 0, TimeUnit.SECONDS)（它也会检测中断）。\n     *\n     * 参数：permits - 获取的 permits 数量\n     * 返回：如果获得了 permit，则为 true，否则为 false\n     * @throws IllegalArgumentException - 如果 permits 为负数\n     */\n    public boolean tryAcquire(int permits) {\n        if (permits &amp;lt; 0) throw new IllegalArgumentException();\n        return sync.nonfairTryAcquireShared(permits) &amp;gt;= 0;\n    }\n\n    /**\n     * 如果在给定超时时间内没有中断，且有足够的 permits 可用，则从信号量中获取 permits。\n     *\n     * 获取给定数量的 permits，如果存在足够数量可用则立即返回 true，并将可用 permits 的\n     * 数量减去给定数值。\n     *\n     * 如果没有足够可用的 permits，则处于线程调度目的，当前线程将被禁用并处于休眠状态，直到\n     * 发生以下三种情况下之一：\n     * - 其他一些线程调用此信号量的 release 方法，并且当前线接下来获得足够数量 permits；或者\n     * - 其他线程中断当前线程；或者\n     * - 超过指定的超时时间。\n     *\n     * 如果获得 permits，则返回 true。\n     *\n     * 如果当前线程：\n     * - 在进入此方法时设置其中断状态；或者\n     * - 在等待过程中被中断。\n     *\n     * 然后抛出InterruptedException并清除当前线程的中断状态。将分配给当前线程的 permits\n     * 改为分配给尝试获取 permit 的其他线程，就好像通过调用 release() 使 permits 可用\n     * 一样。\n     *\n     * 如果经过指定的等待时间，则返回 false。如果时间小于等于零，则该方法不会等待。\n     * 参数：permits - 获得的 permits 数量\n     *      timeout - 等待 permit 的最大时间\n     *      unit - timeout 参数的时间单位\n     * 返回：如果已经获得 permits，则为 true；如果获得之前超过等待时间，则为 false。\n     * @throws InterruptedException - 如果当前线程被中断\n     * @throws IllegalArgumentException - 如果 permits 为负数\n     */\n    public boolean tryAcquire(int permits, long timeout, TimeUnit unit)\n            throws InterruptedException {\n        if (permits &amp;lt; 0) throw new IllegalArgumentException();\n        return sync.tryAcquireSharedNanos(permits, unit.toNanos(timeout));\n    }\n\n    /**\n     * 释放给定数量的 permits，将其返回给信号量。\n     *\n     * 释放给定数量的 permits，将可用 permits 数量加上改数量。如果任何线程试图获取\n     * permit，则选择一个线程给予刚释放的 permits。如果可用 permits 的数量满足该\n     * 线程的要求，处于线程调度目的，该线程（重新）启用；否则线程将等待直到有足够的\n     * permits 可用。如果在满足该线程的请求后仍然有可用的 permits，则这些 permits\n     * 将依次分配给试图获取 permits 的线程。\n     *\n     * 不要求线程必须先调用 acquire 获得 permits 之后才能 release 释放 permits。\n     * 信号量的正确使用是通过应用程序中的编程约定建立的。\n     *\n     * 参数：permits - 释放的 permits 数量\n     * @throws IllegalArgumentException - permits 为负数\n     */\n    public void release(int permits) {\n        if (permits &amp;lt; 0) throw new IllegalArgumentException();\n        sync.releaseShared(permits);\n    }\n\n    /**\n     * 返回此信号量当前可用的 permits 数量。\n     *\n     * 此方法通常用于调试和测试。\n     *\n     * 返回：此信号量中可用的 permit 数量\n     */\n    public int availablePermits() {\n        return sync.getPermits();\n    }\n\n    /**\n     * 获取并返回当前所有的 permits。\n     *\n     * 返回：获得的 permits 数量\n     */\n    public int drainPermits() {\n        return sync.drainPermits();\n    }\n\n    /**\n     * 按照指定的 reduction 减少可用 permits 数量。此方法在使用信号量来跟踪\n     * 子类中资源变得不可用情况会很有用。此方法与 acquire 的不同之处在于它不会\n     * 阻塞等待 permits 可用。\n     *\n     * 参数：reduction - 移除的 permits 数量\n     * @throws IllegalArgumentException - 如果 reduction 为负数\n     */\n    protected void reducePermits(int reduction) {\n        if (reduction &amp;lt; 0) throw new IllegalArgumentException();\n        sync.reducePermits(reduction);\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;其他一些用于监控的非核心方法不再展示。&lt;/p&gt;\n&lt;h3 id=\&#34;84-countdownlatch\&#34;&gt;8.4 CountDownLatch&lt;/h3&gt;\n&lt;p&gt;一种同步辅助工具，允许一个或多个线程等待，知道在其他线程中执行的一组操作完成。&lt;/p&gt;\n&lt;p&gt;&lt;code&gt;CountDownLatch&lt;/code&gt; 使用给定的 &lt;em&gt;计数（count）&lt;/em&gt; 进行初始化。调用 &lt;code&gt;await&lt;/code&gt; 方法将会一直阻塞，直到调用 &lt;code&gt;countDown&lt;/code&gt; 方法将当前计数减少到零，只有所有等待的线程都被释放，任何后续的 &lt;code&gt;await&lt;/code&gt; 方法调用将会立即返回。这是一次性使用的现象——计数是无法重置的。如果你需要能够重置计数的版本，请考虑使用 &lt;code&gt;CyclicBarrier&lt;/code&gt;。&lt;/p&gt;\n&lt;p&gt;&lt;code&gt;CountDownLatch&lt;/code&gt; 是一种多功能同步工具，可用于多种用途。使用计数 1 初始化的 &lt;code&gt;CountDownLatch&lt;/code&gt; 可以用作简单的开/关闩锁：所有调用 &lt;code&gt;await&lt;/code&gt; 方法的线程都将在门处等待，直到它被调用 &lt;code&gt;countDown&lt;/code&gt; 方法线程打开门。初始化为 N 的 &lt;code&gt;CountDownLatch&lt;/code&gt;  可用于使一个线程等待，直到 N 个线程完成某个动作，或某个动作完成 N 次。&lt;/p&gt;\n&lt;p&gt;&lt;code&gt;CountDownLatch&lt;/code&gt; 的一个有用属性是它不需要调用 &lt;code&gt;countDown&lt;/code&gt; 的线程等待计数变为零才能继续，它只是阻塞调用 &lt;code&gt;await&lt;/code&gt; 方法的线程，直到所有线程都可以通过。&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;示例用法：&lt;/strong&gt; 这是一对类，其中一组工作线程使用两个 &lt;code&gt;CountDownLatch&lt;/code&gt;：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;第一个是启动信号，它阻塞任何 worker 继续前进，直到 driver 准备好让他们继续。&lt;/li&gt;\n&lt;li&gt;第二个是完成信号，允许 driver 程序等待所有 worker 完成。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;class Driver {\n  void main() throws InterruptedException {\n    CountDownLatch startSignal = new CountDownLatch(1);\n    CountDownLatch doneSignal = new CountDownLatch(N);\n    \n    for (int i = 0; i &amp;lt; N; ++i) { // create and start threads\n      new Thread(new Worker(startSignal, doneSignal)).start();\n    }\n    \n    doSomethingElse(); // don&#39;t let run yet\n    startSignal.countDown(); // let all threads proceed\n    doSomethingElse(); \n    doSignal.await(); // wait for all to finish\n  }\n}\n\nclass Worker implements Runnable {\n  private final CountDownLatch startSignal;\n  private final CountDownLatch doneSignal;\n  Worker(CountDownLatch startSignal, CountDownLatch doneSignal) {\n    this.startSignal = startSignal;\n    this.doneSignal = doneSignal;\n  }\n  \n  public void run() {\n    try {\n      startSignal.await();\n      doWork();\n      doneSignal.countDown();\n    } catch (InterruptedException ex) {} //return;\n  }\n  \n  void doWork() { ... }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;另一个典型的用法是将一个问题分成 N 个部分，用一个 &lt;code&gt;Runnable&lt;/code&gt; 描述每个部分，该 &lt;code&gt;Runnable&lt;/code&gt; 执行该部分并在完成后进行 &lt;code&gt;countDown&lt;/code&gt; 操作，并将所有 &lt;code&gt;Runnables&lt;/code&gt; 排队到一个 &lt;code&gt;Executor&lt;/code&gt;。当所有的子任务执行完成后，协调线程就可以在 &lt;code&gt;await&lt;/code&gt; 状态中被释放。（当线程必须以这种方式重复使用 &lt;code&gt;countDown&lt;/code&gt; 时，请改用 &lt;code&gt;CyclicBarrier&lt;/code&gt;）&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;class Driver2 { // ...\n  void main() throws InterruptedException {\n    CountDownLatch doneSignal = new CountDownLatch(N);\n    Executor e = ...\n    \n    for (int i = 0; i &amp;lt; N; ++i) { // create and start threads\n      e.execute(new WorkerRunnable(doneSignal, i));\n    }\n    \n    doneSignal.await(); // wait for all to finish\n  }\n}\n\nclass WorkRunnable implements Runnable {\n  private final CountDownLatch doneSignal;\n  private final int i;\n  WorkerRunnable(CountDownLatch doneSignal, int i) {\n    this.doneSignal = doneSignal;\n    this.i = i;\n  }\n  \n  public void run() {\n    try {\n      doWork(i);\n      doneSignal.countDown();\n    } catch (InterruptedException ex) {} // return;\n  }\n  \n  void doWork() { ... }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;内存一致性影响：直到计数到达零，调用 &lt;code&gt;countDown()&lt;/code&gt; 之前的线程中的动作 &lt;code&gt;happen-before&lt;/code&gt; 在另一个线程中从相应的 &lt;code&gt;await()&lt;/code&gt; 成功返回之后的动作。&lt;/p&gt;\n&lt;h4 id=\&#34;841-sync\&#34;&gt;8.4.1 Sync&lt;/h4&gt;\n&lt;p&gt;&lt;code&gt;CountDownLatch&lt;/code&gt; 的同步控制。使用 &lt;code&gt;AQS&lt;/code&gt; 状态来表示计数&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;private static final class Sync extends AbstractQueuedSynchronizer {\n    private static final long serialVersionUID = 4982264981922014374L;\n\n    Sync(int count) {\n        setState(count);\n    }\n\n    int getCount() {\n        return getState();\n    }\n\n    protected int tryAcquireShared(int acquires) {\n        return (getState() == 0) ? 1 : -1;\n    }\n\n    protected boolean tryReleaseShared(int releases) {\n        // Decrement count; signal when transition to zero\n        for (;;) {\n            int c = getState();\n            if (c == 0)\n                return false;\n            int nextc = c-1;\n            // CAS 递减，为零返回 true\n            if (compareAndSetState(c, nextc))\n                return nextc == 0;\n        }\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h4 id=\&#34;842-await-countdown\&#34;&gt;8.4.2 await &amp;amp; countDown&lt;/h4&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;public class CountDownLatch {\n    private final Sync sync;\n\n    /**\n     * 使用给定的计数初始化 CountDownLatch。\n     *\n     * 参数：count - 在线程可以通过 await 之前必须调用 countDown 的次数\n     * @throws IllegalArgumentException - 如果 count 为负数\n     */\n    public CountDownLatch(int count) {\n        if (count &amp;lt; 0) throw new IllegalArgumentException(&amp;quot;count &amp;lt; 0&amp;quot;);\n        this.sync = new Sync(count);\n    }\n\n    /**\n     * 阻塞当前线程，使其等待，直到 CountDownLatch 计数器为零，线程中断则终止。\n     *\n     * 如果当前计数为零，则此方法立即返回。\n     *\n     * 如果当前计数大于零，出于线程调度目的，当前线程将被禁用并处于休眠状态，直到以下\n     * 两种情况下之一发生：\n     * - 由于调用了 countDown 方法，计数达到零；或者\n     * - 其他一些线程中断当前线程。\n     *\n     * 如果当前线程：\n     * - 在进入此方法时设置其中断状态；或者\n     * - 等待过程中被中断。\n     *\n     * 然后抛出InterruptedException并清除当前线程的中断状态。\n     *\n     * @throws InterruptedException - 如果当前线程在等待中被中断\n     */\n    public void await() throws InterruptedException {\n        sync.acquireSharedInterruptibly(1);\n    }\n\n    /**\n     *\n     * 阻塞当前线程，使其等待，直到 CountDownLatch 计数器为零，或到达指定的等待时间，\n     * 线程中断则终止。\n     *\n     * 如果当前计数为零，则此方法立即返回 true。\n     *\n     * 如果当前计数大于零，出于线程调度目的，当前线程将被禁用并处于休眠状态，直到以下\n     * 三种情况下之一发生：\n     * - 由于调用了 countDown 方法，计数达到零；或者\n     * - 其他一些线程中断当前线程；或者\n     * - 达到指定的等待时间。\n     * \n     * 如果计数到达零，则该方法返回 true。\n     *\n     * 如果当前线程：\n     * - 在进入此方法时设置其中断状态；或者\n     * - 等待过程中被中断。\n     *\n     * 然后抛出InterruptedException并清除当前线程的中断状态。\n     * \n     * 如果经过了指定的等待时间，则返回 false。如果时间小于或等于零，则该方法不会等待。\n     * \n     * \n     * 参数：timeout - 等待的最长时间\n     *      unit - timeout参数的单位\n     * 返回：如果计数到达零，则返回 true；如果在计数到达零之前超过的等待时间，则返回 false\n     * @throws InterruptedException - 如果当前线程在等待中被中断\n     */\n    public boolean await(long timeout, TimeUnit unit)\n            throws InterruptedException {\n        return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout));\n    }\n\n    /**\n     * 减少 CountDownLatch 的计数，如果计数达到零，则释放所有等待线程。\n     *\n     * 如果当前计数大于零，则递减。如果新计数为零，出于线程调度重启所有等待线程。\n     *\n     * 如果当前计数为零，则不会发生任何事情。\n     */\n    public void countDown() {\n        sync.releaseShared(1);\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;85-cyclicbarrier\&#34;&gt;8.5 CyclicBarrier&lt;/h3&gt;\n&lt;p&gt;一种同步辅助工具，它允许一组线程相互等待以达到共同的障碍点。&lt;code&gt;CyclicBarriers&lt;/code&gt; 在涉及固定大小的线程组的程序中很有用，这些线程组必须偶尔相互等待。屏障被称为 &lt;code&gt;循环（Cyclic）&lt;/code&gt; 的，因为它们可以在等待线程被释放后重新使用。&lt;/p&gt;\n&lt;p&gt;&lt;code&gt;CyclicBarrier&lt;/code&gt; 支持一个可选的 &lt;code&gt;Runnable&lt;/code&gt; 命令，该命令在每个屏障点运行一次，在最后一个线程到达之后，但是在任何线程被释放之前。此屏障操作对于在任何一方继续执行之前更新共享状态很有用。&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;示例用法：&lt;/strong&gt; 以下是在并行分解设计中使用屏障的示例：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;class Solver {\n  final int N;\n  final float[][] data;\n  final CyclicBarrier barrier;\n  \n  class Worker implements Runnable {\n    int myRow;\n    Worker(int row) { myRow = row; }\n    public void run() {\n      while (!done()) {\n        processRow(myRow);\n        \n        try {\n          barrier.await();\n        } catch (InterruptedException ex) {\n          return;\n        } catch (BrokenBarrierException ex) {\n          return;\n        }\n      }\n    }\n  }\n  \n  public Solver(float[][] matrix) {\n    data = matrix;\n    N = matrix.length;\n    Runnable barrierAction = new Runnable() {\n      public void run() {\n        margeRows(...);\n      }\n    };\n    barrier = new CyclicBarrier(N, barrierAction);\n    \n    List&amp;lt;Thread&amp;gt; threads = new ArrayList&amp;lt;Thread&amp;gt;(N);\n    for (int i = 0; i &amp;lt; N; i++) {\n      Thread thread = new Thread(new Worker(i));\n      threads.add(thread);\n      thread.start();\n    }\n    \n    // wait until done\n    for (Thread thread : threads) {\n      thread.join();\n    }\n  }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;在这里，每个工作线程处理矩阵的一行，然后在屏障处等待，直到处理完所有行。处理完所有行后，将执行提供的 &lt;code&gt;Runnable&lt;/code&gt; 屏障操作，合并矩阵行。如果合并已经确定完成，那 &lt;code&gt;done()&lt;/code&gt; 方法会返回 true ，每个工作线程将会终止。&lt;/p&gt;\n&lt;p&gt;如果 barrier action 在执行时不依赖于被挂起的各个线程，那么该方法中的任何线程都可以在它被释放时执行该动作。为了方便起见，每次调用 &lt;code&gt;await&lt;/code&gt; 都会返回该线程在屏障处到达的索引。然后，您可以选择那个线程应该执行 barrier action，例如：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;if (barrier.await() == 0) {\n  // log the completion of this iteration\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;&lt;code&gt;CyclicBarrier&lt;/code&gt; 对失败的同步尝试使用 &lt;code&gt;all-or-none&lt;/code&gt; 模型：如果线程由于中断、故障或超时而过早地离开屏障点，则在该屏障点等待的所有其他线程也会通过 &lt;code&gt;BrokenBarrierException&lt;/code&gt;（或者如果它们也在同时被中断，抛出&lt;code&gt;InterruptedException&lt;/code&gt; ）。&lt;/p&gt;\n&lt;p&gt;内存一致性效果：在调用 &lt;code&gt;await()&lt;/code&gt; 之前线程中的操作 happen-before 作为 barrier action 的一部分的操作，而这些操作又 happen-before 从其他线程中的相应 &lt;code&gt;await()&lt;/code&gt; 成功返回之后的操作。&lt;/p&gt;\n&lt;h4 id=\&#34;851-generation\&#34;&gt;8.5.1 Generation&lt;/h4&gt;\n&lt;p&gt;屏障的每次使用都会表现为 &lt;code&gt;generation&lt;/code&gt; 实例。每当屏障被触发或重置时，&lt;code&gt;generation&lt;/code&gt; 就会发生变化。可能有许多 &lt;code&gt;generation&lt;/code&gt; 与使用屏障的线程相关联 —— 由于锁定可能会以不确定的方式分配给等待线程 —— 但一次只能使其中一个 &lt;code&gt;generation&lt;/code&gt; 处于活动状态（count 使用的那个）并且所有其余的线程要么 broken，要么 trip（可能是指阻塞？）。如果有中断带没有后续重置，则不需要活动的 &lt;code&gt;generation&lt;/code&gt;。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;private static class Generation {\n    boolean broken = false;\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h4 id=\&#34;852-实现详解\&#34;&gt;8.5.2 实现详解&lt;/h4&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;public class CyclicBarrier {\n\n    // 忽略 Generation Class\n\n    /** 用户保护屏障入口的锁 */\n    private final ReentrantLock lock = new ReentrantLock();\n    /** 等待直到 triped 的 condition */\n    private final Condition trip = lock.newCondition();\n    /** 分片数量 */\n    private final int parties;\n    /* tripped 时执行的命令 */\n    private final Runnable barrierCommand;\n    /** 当前 generation */\n    private Generation generation = new Generation();\n\n    /**\n     * 仍在等待的 parties 数量。每个 generation 都会讲 parties 减少到 0。\n     * 每次生成新的 generation 或 broken 时会重置。\n     */\n    private int count;\n\n    /**\n     * 更新屏障 trip 状态，并唤醒全部。只有当持有锁才可以调用。\n     */\n    private void nextGeneration() {\n        // signal completion of last generation\n        trip.signalAll();\n        // set up next generation\n        count = parties;\n        generation = new Generation();\n    }\n\n    /**\n     * 设置当前的 generation 为 broken，并唤醒全部。只有当持有锁才可以调用。\n     */\n    private void breakBarrier() {\n        generation.broken = true;\n        count = parties;\n        trip.signalAll();\n    }\n\n    /**\n     * 屏障的主要代码，涵盖各种策略。\n     */\n    private int dowait(boolean timed, long nanos)\n        throws InterruptedException, BrokenBarrierException,\n               TimeoutException {\n        // 屏障入口，先获得锁\n        final ReentrantLock lock = this.lock;\n        lock.lock();\n        try {\n            // 获取当前的 generation\n            final Generation g = generation;\n\n            // 判断当前是否 broken，抛出异常\n            if (g.broken)\n                throw new BrokenBarrierException();\n\n            // 判断线程是否中断\n            if (Thread.interrupted()) {\n                breakBarrier();\n                throw new InterruptedException();\n            }\n\n            // 获取当前索引\n            int index = --count;\n            // 当最后一个任务到达 await 屏障点时，则执行 command\n            if (index == 0) {  // tripped\n                // 是否执行命令，执行失败（抛出异常）则跳出等待\n                boolean ranAction = false;\n                try {\n                    final Runnable command = barrierCommand;\n                    if (command != null)\n                        command.run();\n                    ranAction = true;\n                    // 下一个 generation，也就是重置屏障\n                    nextGeneration();\n                    return 0;\n                } finally {\n                    if (!ranAction)\n                        breakBarrier();\n                }\n            }\n\n            // 说明不是最后一个到达屏障的任务，需要阻塞\n            // loop until tripped, broken, interrupted, or timed out\n            for (;;) {\n                try {\n                    // 如果没有超时，则直接阻塞；存在超时时间使用超时阻塞\n                    // condition 的 await 会进行 fullyRelease，释放持有的锁\n                    if (!timed)\n                        trip.await();\n                    else if (nanos &amp;gt; 0L)\n                        nanos = trip.awaitNanos(nanos);\n                } catch (InterruptedException ie) {\n                    // 如果当前 generation 没有被其他线程改变，且中断\n                    if (g == generation &amp;amp;&amp;amp; ! g.broken) {\n                        // 中断屏障\n                        breakBarrier();\n                        throw ie;\n                    } else {\n                        // 即使我们没有被中断，我们也即将完成等待，所以这个中断\n                        // 被认为是 “属于” 后续执行的。\n                        Thread.currentThread().interrupt();\n                    }\n                }\n\n                if (g.broken)\n                    throw new BrokenBarrierException();\n\n                // generation 已经更换\n                if (g != generation)\n                    return index;\n\n                // 超时则中断屏障\n                if (timed &amp;amp;&amp;amp; nanos &amp;lt;= 0L) {\n                    breakBarrier();\n                    throw new TimeoutException();\n                }\n            }\n        } finally {\n            lock.unlock();\n        }\n    }\n\n    /**\n     * 创建一个新的 CyclicBarrier，当给定数量的 parties （线程）正在等待它时，\n     * 它将触发继续执行，他将执行给定的 barrierAction，由最后一个进入屏障的线程\n     * 执行。\n     *\n     * 参数：parties - 在屏障被触发之前必须调用 await 的线程数\n     *      barrierAction - 当屏障被触发时执行的命令，如果没有动作则为 null\n     * @throws IllegalArgumentException - 如果 parties 小于 1\n     */\n    public CyclicBarrier(int parties, Runnable barrierAction) {\n        if (parties &amp;lt;= 0) throw new IllegalArgumentException();\n        this.parties = parties;\n        this.count = parties;\n        this.barrierCommand = barrierAction;\n    }\n\n    /**\n     * 创建一个新的 CyclicBarrier，当给定数量的 parties （线程）正在等待它时，\n     * 它将触发继续执行，在触发屏障继续执行时不执行预定义操作。\n     *\n     * 参数：parties - 在屏障被触发之前必须调用 await 的线程数\n     *      barrierAction - 当屏障被触发时执行的命令，如果没有动作则为 null\n     * @throws IllegalArgumentException - 如果 parties 小于 1\n     */\n    public CyclicBarrier(int parties) {\n        this(parties, null);\n    }\n\n    /**\n     * 返回触发次屏障所需的 parties 数量。\n     *\n     * 返回：打破此屏障需要的 parties 数量。\n     */\n    public int getParties() {\n        return parties;\n    }\n\n    /**\n     * 等到所有 parties 都在此屏障上调用 await。\n     *\n     * 如果当前线程不是最后到达的，处于线程调度目的，将其禁用并处于休眠状态，\n     * 直到发生以下情况之一：\n     * - 最后一个线程到达；或者\n     * - 其他线程中断当前线程；或者\n     * = 其他线程中断了任意等待线程；或者\n     * - 其他线程在等待屏障时超时；或者\n     * - 其他一些线程调用此屏障的 reset 方法。\n     *\n     * 如果当前线程：\n     * - 在进入此方法时设置其中断状态；或者\n     * - 等待过程中被中断\n     *\n     * 然后抛出 InterruptedException 并清除当前线程的中断状态。\n     *\n     * 如果在任何线程等待时调用屏障的 reset 方法，或者在调用 await 或在任何线程\n     * 在等待时屏障时，isBroken() 为 true，则抛出 BrokenBarrierException。\n     *\n     * 如果任何线程在等待时被中断，那么所有其他等待的线程都会抛出 BrokenBarrierException\n     * 并将屏障的 generation 的 broken 状态设置为 true。\n     *\n     * 如果当前线程是最后到达的线程，并且在构造函数中提供了非空的 barrierAction，则允许当前\n     * 在继续之前先执行 barrierAction 操作。如果在屏障操作期间发生了异常，则该异常将在当前\n     * 线程中传播，并且屏障处于 broken 状态。\n     *\n     * 返回：当前线程的到达索引，其中索引 getParties - 1 表示第一个到达，0表示最后一个到达\n     * @throws InterruptedException - 如果当前线程在等待时被中断\n     * @throws BrokenBarrierException - 如果另一个线程在当前线程等待时中断或超时，或者\n     *                                  屏障被重置，或者在调用 await 时屏障被破坏，或者\n     *                                  barrierAction （如果存在） 由于异常失败\n     */\n    public int await() throws InterruptedException, BrokenBarrierException {\n        try {\n            return dowait(false, 0L);\n        } catch (TimeoutException toe) {\n            throw new Error(toe); // cannot happen\n        }\n    }\n\n    /**\n     * 等到所有 parties 都在此屏障上调用 await，或达到指定的超时时间。\n     *\n     * 如果当前线程不是最后到达的，处于线程调度目的，将其禁用并处于休眠状态，\n     * 直到发生以下情况之一：\n     * - 最后一个线程到达；或者\n     * - 到达指定的超时时间；或者\n     * - 其他线程中断当前线程；或者\n     * = 其他线程中断了任意等待线程；或者\n     * - 其他线程在等待屏障时超时；或者\n     * - 其他一些线程调用此屏障的 reset 方法。\n     *\n     * 如果当前线程：\n     * - 在进入此方法时设置其中断状态；或者\n     * - 等待过程中被中断\n     *\n     * 然后抛出 InterruptedException 并清除当前线程的中断状态。\n     *\n     * 如果到达指定的超时时间，则抛出 TimeoutException。如果时间小于或等于零，则\n     * 该方法不会等待。\n     *\n     * 如果在任何线程等待时调用屏障的 reset 方法，或者在调用 await 或在任何线程\n     * 在等待时屏障时，isBroken() 为 true，则抛出 BrokenBarrierException。\n     *\n     * 如果任何线程在等待时被中断，那么所有其他等待的线程都会抛出 BrokenBarrierException\n     * 并将屏障的 generation 的 broken 状态设置为 true。\n     *\n     * 如果当前线程是最后到达的线程，并且在构造函数中提供了非空的 barrierAction，则允许当前\n     * 在继续之前先执行 barrierAction 操作。如果在屏障操作期间发生了异常，则该异常将在当前\n     * 线程中传播，并且屏障处于 broken 状态。\n     *\n     * 参数：timeout - 等待屏障的时间\n     *       unit - timeout 的单位\n     * 返回：当前线程的到达索引，其中索引 getParties - 1 表示第一个到达，0表示最后一个到达\n     * @throws InterruptedException - 如果当前线程在等待时被中断\n     * @throws TimeoutException - 如果到达指定的超时时间。在这种情况下，屏障将被 broken。\n     * @throws BrokenBarrierException - 如果另一个线程在当前线程等待时中断或超时，或者\n     *                                  屏障被重置，或者在调用 await 时屏障被破坏，或者\n     *                                  barrierAction （如果存在） 由于异常失败\n     */\n    public int await(long timeout, TimeUnit unit)\n        throws InterruptedException,\n               BrokenBarrierException,\n               TimeoutException {\n        return dowait(true, unit.toNanos(timeout));\n    }\n\n    /**\n     * 查询当前屏障是否处于 broken 状态。\n     *\n     * 返回：一个或多个 parties 在上次屏障重置后，由于超时或中断而使此屏障 broken，\n     *      或者由于异常而导致 barrierAction 失败，则为 true；否则为 false。\n     */\n    public boolean isBroken() {\n        final ReentrantLock lock = this.lock;\n        lock.lock();\n        try {\n            return generation.broken;\n        } finally {\n            lock.unlock();\n        }\n    }\n\n    /**\n     * 将屏障重置为初始状态。如果任何 parties 在当前屏障处等待，他们将返回 BrokenBarrierException。\n     * 请注意，由于其他原因发生 broken 后的重置可能会很复杂；线程需要以其他方式重新同步，并选择一个\n     * 线程执行 reset 操作。相反，最好为后续使用创建一个新的屏障。\n     */\n    public void reset() {\n        final ReentrantLock lock = this.lock;\n        lock.lock();\n        try {\n            breakBarrier();   // break the current generation\n            nextGeneration(); // start a new generation\n        } finally {\n            lock.unlock();\n        }\n    }\n\n    /**\n     * 返回当前在屏障处等待的 parties 数量。此方法主要用于调试和断言。\n     *\n     * 返回，当前在 await 中被阻塞的 parties 数量\n     */\n    public int getNumberWaiting() {\n        final ReentrantLock lock = this.lock;\n        lock.lock();\n        try {\n            return parties - count;\n        } finally {\n            lock.unlock();\n        }\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&#34;,&#34;fileName&#34;:&#34;li-jie-tong-bu-qi-kuang-jia-abstractqueuedsynchronizer&#34;,&#34;abstract&#34;:&#34;&lt;h2 id=\&#34;一-背景\&#34;&gt;一、背景&lt;/h2&gt;\n&lt;p&gt;Java 在 1.5 版本引入了 &lt;code&gt;java.util.concurrent&lt;/code&gt;包，用以支持并发编程，降低并发编程的复杂性；而其中大部分的同步器（例如 &lt;code&gt;lock&lt;/code&gt;, &lt;code&gt;barriers&lt;/code&gt; 等等）都是基于 &lt;code&gt;AbstractQueuedSynchronizer&lt;/code&gt; 类，一般我们称为&lt;code&gt;AQS&lt;/code&gt;。 &lt;code&gt;java.util.concurrent.locks.AbstractQueuedSynchronizer&lt;/code&gt; 出自 &lt;code&gt;Doug Lea&lt;/code&gt; 带佬，他的 &lt;a href=\&#34;https://gee.cs.oswego.edu/\&#34;&gt;个人博客&lt;/a&gt; 上有一篇相关论文 &lt;a href=\&#34;https://gee.cs.oswego.edu/dl/papers/aqs.pdf\&#34;&gt;《The java.util.concurrent Synchronizer Framework》&lt;/a&gt;，在我们深入研究 &lt;code&gt;AQS&lt;/code&gt; 之前，有必要拜读一下该论文，翻译见笔者的另一篇博客&lt;a href=\&#34;https://wenbozhangw.github.io/post/lesslessthe-javautilconcurrent-synchronizer-frameworkgreatergreater-yuan-wen-fan-yi/\&#34;&gt;《The java.util.concurrent Synchronizer Framework》原文翻译&lt;/a&gt; 之后结合相关源码实现进行分析。&lt;/p&gt;\n&#34;,&#34;title&#34;:&#34;理解同步器框架AbstractQueuedSynchronizer&#34;,&#34;tags&#34;:[{&#34;index&#34;:-1,&#34;name&#34;:&#34;AQS&#34;,&#34;slug&#34;:&#34;o7NFbw6wG&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://wenbozhangw.github.io/tag/o7NFbw6wG/&#34;},{&#34;index&#34;:-1,&#34;name&#34;:&#34;JDK&#34;,&#34;slug&#34;:&#34;WiGwDpD94&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://wenbozhangw.github.io/tag/WiGwDpD94/&#34;}],&#34;date&#34;:&#34;2022-09-14 22:32:26&#34;,&#34;dateFormat&#34;:&#34;2022-09-14&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://wenbozhangw.github.io/post/li-jie-tong-bu-qi-kuang-jia-abstractqueuedsynchronizer/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;178 min read&#34;,&#34;time&#34;:10678000,&#34;words&#34;:46293,&#34;minutes&#34;:178},&#34;description&#34;:&#34;一、背景\nJava 在 1.5 版本引入了 java.util.concurrent包，用以支持并发编程，降低并发编程的复杂性；而其中大部分的同步器（例如 lock, barriers 等等）都是基于 AbstractQueuedSynch...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%B8%80-%E8%83%8C%E6%99%AF\&#34;&gt;一、背景&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%BA%8C-aqs%E6%A6%82%E8%BF%B0\&#34;&gt;二、AQS概述&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%B8%89-%E5%90%8C%E6%AD%A5%E5%99%A8%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86\&#34;&gt;三、同步器框架原理&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#31%E5%90%8C%E6%AD%A5%E5%99%A8%E7%8A%B6%E6%80%81\&#34;&gt;3.1同步器状态&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#32-clh-%E9%98%9F%E5%88%97\&#34;&gt;3.2 CLH 队列&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#33-%E9%98%BB%E5%A1%9E\&#34;&gt;3.3 阻塞&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#34-%E6%9D%A1%E4%BB%B6%E9%98%9F%E5%88%97\&#34;&gt;3.4 条件队列&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#341-condition-%E6%8E%A5%E5%8F%A3\&#34;&gt;3.4.1 Condition 接口&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#342-lock-%E6%8E%A5%E5%8F%A3\&#34;&gt;3.4.2 Lock 接口&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%9B%9B-aqs-%E7%9A%84%E7%8B%AC%E5%8D%A0%E4%B8%8E%E5%85%B1%E4%BA%AB\&#34;&gt;四、AQS 的独占与共享&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#41-%E7%8B%AC%E5%8D%A0%E6%A8%A1%E5%BC%8F\&#34;&gt;4.1 独占模式&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#411-acquire\&#34;&gt;4.1.1 acquire&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#412-release\&#34;&gt;4.1.2 release&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#413-acquireinterruptibly\&#34;&gt;4.1.3 acquireInterruptibly&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#414-tryacquirenanos\&#34;&gt;4.1.4  tryAcquireNanos&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#415-%E7%8B%AC%E5%8D%A0%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%AE%9E%E7%8E%B0\&#34;&gt;4.1.5 独占模式的实现&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#42-%E5%85%B1%E4%BA%AB%E6%A8%A1%E5%BC%8F\&#34;&gt;4.2 共享模式&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#421-acquireshared\&#34;&gt;4.2.1 acquireShared&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#422-releaseshared\&#34;&gt;4.2.2 releaseShared&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#423-acquiresharedinterruptibly\&#34;&gt;4.2.3 acquireSharedInterruptibly&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#424-tryacquiresharednanos\&#34;&gt;4.2.4 tryAcquireSharedNanos&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#425-%E5%85%B1%E4%BA%AB%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%AE%9E%E7%8E%B0\&#34;&gt;4.2.5 共享模式的实现&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%BA%94-%E6%9D%A1%E4%BB%B6%E9%98%9F%E5%88%97%E4%B9%8B-conditionobject\&#34;&gt;五、条件队列之 ConditionObject&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#51-%E6%9D%A1%E4%BB%B6%E9%98%9F%E5%88%97%E7%9A%84%E5%85%A5%E9%98%9F%E5%92%8C%E5%87%BA%E9%98%9F\&#34;&gt;5.1 条件队列的入队和出队&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#52-condition-%E4%B9%8B-await\&#34;&gt;5.2 Condition 之 await&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#53-condtion-%E4%B9%8B-signalsignalall\&#34;&gt;5.3 Condtion 之 signal/signalAll&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#54-await-%E6%96%B9%E6%B3%95%E7%9A%84%E5%87%A0%E7%A7%8D%E5%8F%98%E4%BD%93\&#34;&gt;5.4 await 方法的几种变体&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#541-awaituninterruptibly\&#34;&gt;5.4.1 awaitUninterruptibly&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#542-awaitnanos\&#34;&gt;5.4.2 awaitNanos&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#543-awaituntil\&#34;&gt;5.4.3 awaitUntil&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#544-awaitlong-time-timeunit-unit\&#34;&gt;5.4.4 await(long time, TimeUnit unit)&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%B8%83-aqs-%E4%B8%AD%E7%9A%84-cancelacquire\&#34;&gt;七、AQS 中的 cancelAcquire&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%85%AB-aqs-%E7%9A%84%E9%94%81%E5%AE%9E%E7%8E%B0\&#34;&gt;八、AQS 的锁实现&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#81-reentrantlock\&#34;&gt;8.1 ReentrantLock&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#811-sync\&#34;&gt;8.1.1 Sync&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#812-%E5%85%AC%E5%B9%B3%E9%94%81%E5%92%8C%E9%9D%9E%E5%85%AC%E5%B9%B3%E9%94%81\&#34;&gt;8.1.2 公平锁和非公平锁&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#813-reentrantlock-%E7%B1%BB%E7%9A%84%E5%85%B6%E4%BB%96%E6%96%B9%E6%B3%95\&#34;&gt;8.1.3 ReentrantLock 类的其他方法&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#82-reentantreadwritelock\&#34;&gt;8.2 ReentantReadWriteLock&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#821-sync\&#34;&gt;8.2.1  Sync&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#822-%E5%85%AC%E5%B9%B3%E9%94%81%E5%92%8C%E9%9D%9E%E5%85%AC%E5%B9%B3%E9%94%81\&#34;&gt;8.2.2 公平锁和非公平锁&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#823-%E8%AF%BB%E9%94%81%E5%92%8C%E5%86%99%E9%94%81\&#34;&gt;8.2.3 读锁和写锁&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#8231-readlock\&#34;&gt;8.2.3.1  ReadLock&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#8232-writelock\&#34;&gt;8.2.3.2 WriteLock&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#823-%E5%85%B6%E4%BB%96%E6%96%B9%E6%B3%95\&#34;&gt;8.2.3 其他方法&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#83-samphora\&#34;&gt;8.3 Samphora&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#831-sync\&#34;&gt;8.3.1 Sync&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#832-%E5%85%AC%E5%B9%B3%E5%92%8C%E9%9D%9E%E5%85%AC%E5%B9%B3\&#34;&gt;8.3.2 公平和非公平&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#833-acquire-release\&#34;&gt;8.3.3 acquire &amp;amp; release&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#84-countdownlatch\&#34;&gt;8.4 CountDownLatch&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#841-sync\&#34;&gt;8.4.1 Sync&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#842-await-countdown\&#34;&gt;8.4.2 await &amp;amp; countDown&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#85-cyclicbarrier\&#34;&gt;8.5 CyclicBarrier&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#851-generation\&#34;&gt;8.5.1 Generation&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#852-%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3\&#34;&gt;8.5.2 实现详解&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;h2 id=\&#34;摘要\&#34;&gt;摘要&lt;/h2&gt;\n&lt;p&gt;在 J2SE1.5 的 &lt;code&gt;java.util.concurrent&lt;/code&gt;包（下面简称为 &lt;code&gt;j.u.c&lt;/code&gt; 包 ）中，大多数的同步器（例如锁、栅栏等。）都是使用基于 &lt;code&gt;AbstractQueuedSynchronizer&lt;/code&gt;类（下面简称为 &lt;code&gt;AQS&lt;/code&gt; 类），这个简单的小型框架构建的。这个框架提供了原子管理同步状态、线程的阻塞和解除阻塞、以及排队的通用机制。本文描述了该框架的基本原理、设计、实现、使用和性能。&lt;/p&gt;\n&lt;!-- more --&gt;\n&lt;h2 id=\&#34;类别和主题描述符\&#34;&gt;类别和主题描述符&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;D.1.3 [编程技术]&lt;/strong&gt;：并发编程 —— 并行编程&lt;/p&gt;\n&lt;h2 id=\&#34;一般术语\&#34;&gt;一般术语&lt;/h2&gt;\n&lt;p&gt;算法、策略、性能、设计。&lt;/p&gt;\n&lt;h2 id=\&#34;关键字\&#34;&gt;关键字&lt;/h2&gt;\n&lt;p&gt;同步，Java&lt;/p&gt;\n&lt;h2 id=\&#34;1-介绍\&#34;&gt;1. 介绍&lt;/h2&gt;\n&lt;p&gt;Java&lt;sup&gt;TM&lt;/sup&gt; 发布版本 J2SE-1.5 引入了 &lt;code&gt;j.u.c&lt;/code&gt; 包，这是通过 JCP （Java社区进程）的 JSR（Java规范请求）166 规范创建的，这个包提供了支持中等并发成都的并发类合集。这些组件包括一组&lt;em&gt;同步器&lt;/em&gt;——维护内部&lt;em&gt;同步状态&lt;/em&gt;（例如，表示锁的状态是获取还是释放）的抽象数据类型（ADT）类、更新和检查该状态的操作。以及至少会有一个方法会导致调用现存在同步状态被获取时阻塞，并在其他线程更改同步状态时解除阻塞。实例包括各种形式的互斥锁、读写锁、信号量、屏障、Future、时间指示器和传送队列等（exclusion locks, read-write locks, semaphores, barriers, futures, event indicators, and handoff queues）。&lt;/p&gt;\n&lt;p&gt;众所周知，几乎任何同步器都可以用于实现其他形式的同步器。例如，可以用可重入锁实现信号量，反之亦然。然而，这样做通常会增加复杂性、开销和不灵活性，使其至多只能是个二流工程。且缺乏吸引力。此外，它在概念上没有吸引力。如果任何这样的构造方式不能在本质上比其他形式更简洁，那么开发者就不应该随意地选择其中的某个来作为基础构建另一个同步器。取而代之，JSR166 建立了一个以 &lt;code&gt;AQS&lt;/code&gt; 类为中心的小型框架，它为用户自定构造器以及&lt;code&gt;j.u.c&lt;/code&gt; 包中大多数提供的同步器提供了一种通用的机制。&lt;/p&gt;\n&lt;p&gt;本文的其余部分将讨论该框架的需求、设计和实现背后的主要思想、示例用法以及一些性能指标的测量。&lt;/p&gt;\n&lt;h2 id=\&#34;2-需求\&#34;&gt;2 需求&lt;/h2&gt;\n&lt;h3 id=\&#34;21-功能\&#34;&gt;2.1 功能&lt;/h3&gt;\n&lt;p&gt;同步器有一般包含两种方法：一种是 &lt;code&gt;acquire&lt;/code&gt; 操作 ，用于阻塞调用的线程，除非/直到同步状态允许它继续；另一种是 &lt;code&gt;release&lt;/code&gt; 操作，用于通过某种方式改变同步状态，以允许一个或多个被 &lt;code&gt;acquire&lt;/code&gt; 的线程解除阻塞。&lt;/p&gt;\n&lt;p&gt;&lt;code&gt;j.u.c&lt;/code&gt; 包没有为同步器定义一个统一的 API。有些是通过公共接口定义的（例如，Lock），而另外一些则定义了其特有的版本。因此，在不同的类中，&lt;code&gt;acquire&lt;/code&gt; 和 &lt;code&gt;release&lt;/code&gt; 操作的名字和形式会有不同。例如：&lt;code&gt;Lock.lock&lt;/code&gt;、&lt;code&gt;Semaphore.acquire&lt;/code&gt;、&lt;code&gt;CountDownLatch.await&lt;/code&gt; 和 &lt;code&gt;FutureTask.get&lt;/code&gt;，在这个框架里，这些方法都是 &lt;code&gt;acquire&lt;/code&gt; 操作。但是，&lt;code&gt;j.u.c&lt;/code&gt;包确实保持了跨类的一致约定，以支持一系列常见的使用选项。如果有意义，每个同步器都支持以下操作：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;非阻塞同步尝试（例如，&lt;code&gt;tryLock&lt;/code&gt;）以及阻塞版本。&lt;/li&gt;\n&lt;li&gt;可选超时，因此应用程序可以放弃等待。&lt;/li&gt;\n&lt;li&gt;通过中断实现任务取消，通常分为可取消的 &lt;code&gt;acquire&lt;/code&gt; 版本和不可取消的 &lt;code&gt;acquire&lt;/code&gt; 版本。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;同步器可能根据它们是否管理  &lt;em&gt;exclusive&lt;/em&gt; 状态 （一次只有一个线程可以通过阻塞点）和可能的 &lt;em&gt;shared&lt;/em&gt; 状态（多个线程至少在某些情况下可以继续）而有所不同。当然，常规的锁类往往只维护 &lt;em&gt;exclusive&lt;/em&gt; 状态，但是计数信号量在数量许可的情况下，允许多个线程同时执行。为了使框架使用能够更加广泛，这两种模式都要支持。&lt;/p&gt;\n&lt;p&gt;&lt;code&gt;j.u.c&lt;/code&gt; 包还定义了 &lt;code&gt;Condition&lt;/code&gt; 接口，用于支持监控形式的 await/singal 操作，这些操作可能与独占的 &lt;code&gt;Lock&lt;/code&gt; 类相关联，并且其本质上与其相关 &lt;code&gt;Lock&lt;/code&gt; 类交织在一起。&lt;/p&gt;\n&lt;h3 id=\&#34;22-性能目标\&#34;&gt;2.2 性能目标&lt;/h3&gt;\n&lt;p&gt;Java 内置锁（使用 &lt;code&gt;synchronized&lt;/code&gt; 的方法或代码块）的性能问题长期以来一直被人们关注，有关它们的构造有相当多的文献（例如，[&lt;a href=\&#34;#1\&#34;&gt;1&lt;/a&gt;]、[&lt;a href=\&#34;#3\&#34;&gt;3&lt;/a&gt;] ）。然而，大部分的研究主要关注的是在单核处理器上，大部分时间使用与单线程上下文环境中，如何尽量降低其空间（因为任何 Java 对象都可以充当锁）和时间的开销。对于同步器来说，这两个都不是特别重要的问题：程序员仅在需要的时候才会使用同步器，因此并不需要压缩空间来避免浪费，并且同步器几乎只用于多线程设计（特别是在多核处理器上），在这种设计下，偶尔的竞争是在意料之中的。因此，常规的 JVM 锁优化策略主要是针对零竞争的场景，而其他场景则使用缺乏可预测的”慢速路径（slow paths）“[&lt;a href=\&#34;#12\&#34;&gt;12&lt;/a&gt;]，对于严重依赖 &lt;code&gt;j.u.c&lt;/code&gt; 的典型多线程服务器应用程序来说，这不是正确的策略选择。&lt;/p&gt;\n&lt;p&gt;相反，这里的主要性能目标是可伸缩性：即使在同步器发生竞争的情况下，也要可预测地保持效率。理想情况下，不管有多少线程试图通过同步点，通过同步点所需的开销应该是恒定的。其中一个主要目标是，在某一线程被允许通过同步点但还没有通过的情况下，使其耗费的总时间最少。但是，者必须与资源考虑相平衡，包括总的 CPU 时间需求、内存流量和线程调度开销。例如，自旋锁通常比阻塞锁所需要的时间更短，但是通常也会浪费 CPU 时钟周期，并且造成内存竞争，因此通常不适用。&lt;/p&gt;\n&lt;p&gt;实现同步器的这些目标包含了两种不同的使用类型。大多数应用程序应该最大限度地提高总吞吐量和容错性，并且最好保证尽量减少接的情况。然而，对于那些控制资源分配的程序来说，更重要的是去维持多线程读取的公平性，可以接受较差的总吞吐量。没有框架能够代表用户在这些冲突的目标之前做出决定；相反，必须适应不同的公平策略。&lt;/p&gt;\n&lt;p&gt;无论同步器内部设计得多么好，在某些应用程序中都会产生性能瓶颈。因此，框架必须能够监控和检查基本操作，以允许用户发现和缓解瓶颈。这至少（也是最有用的）需要提供一种方法来确定有多少线程被阻塞。&lt;/p&gt;\n&lt;h2 id=\&#34;3-设计和实现\&#34;&gt;3. 设计和实现&lt;/h2&gt;\n&lt;p&gt;同步器背后的基本思想非常简单。&lt;code&gt;acquire&lt;/code&gt; 操作如下：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;while(synchronization state does not allow acquire) {\n  enqueue current thread if not already queued;\n  possibly block current thread;\n}\ndequeue current thread if it was queued;\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;&lt;code&gt;release&lt;/code&gt; 操作如下：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;update synchronization state;\nif(state may permit a blocked thread to acquire) \n  unblock one or more queued threads;\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;为了支持上述操作，需要下面三个基本组件相互协作：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;同步状态的原子性原理；&lt;/li&gt;\n&lt;li&gt;线程的阻塞与解除阻塞；&lt;/li&gt;\n&lt;li&gt;队列的管理；&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;也许可以创建一个框架，允许这三个部分各自独立变化。然而，这既不高效也不实用。例如，保存在队列节点中的信息必须与解除阻塞所需要的信息一致，而暴露出的方法签名必须依赖于同步状态的特性。&lt;/p&gt;\n&lt;p&gt;同步器框架中的核心设计决策是这三个组件选择一个具体实现，同时在使用方式上仍然有大量的选择可用。这有意地限制了其适用范围，但是提供了足够的效率，是的实际上没有理由在合适的情况下不用这个框架而去重新造一个。&lt;/p&gt;\n&lt;h3 id=\&#34;31-同步状态\&#34;&gt;3.1 同步状态&lt;/h3&gt;\n&lt;p&gt;&lt;code&gt;AQS&lt;/code&gt;类仅使用单个 &lt;code&gt;int&lt;/code&gt;（32 bit）来保存同步状态，并暴露出 &lt;code&gt;getState&lt;/code&gt;、&lt;code&gt;setState&lt;/code&gt; 以及 &lt;code&gt;compareAndSet&lt;/code&gt; 操作来读取和更新这个状态。这些方法都依赖于 &lt;code&gt;java.util.concurrent.atomic&lt;/code&gt; 支持，这个包提供了兼容 JSR133 中 &lt;code&gt;volatile&lt;/code&gt; 在读和写上的语义，并且通过使用本地的 compare-and-swap 或 load-linked/store-conditional 指令来实现 &lt;code&gt;compareAndSetState&lt;/code&gt;，只有当它持有给定的期望值时，才会自动将状态设置为给定的新值。&lt;/p&gt;\n&lt;p&gt;将同步状态限定为 32 位 &lt;code&gt;int&lt;/code&gt; 是出于实践上的考量。虽然 JSR166 也提供了 64 位 &lt;code&gt;long&lt;/code&gt; 字段的原子操作，但是这些操作在很多平台上还是使用内部锁的方式来模拟实现的，以至于会使同步器的性能不佳。将来，很可能会添加第二个基类，专门用于 64 位状态（使用 &lt;code&gt;long&lt;/code&gt; 控制参数）。然而，现在还没有一个令人信服的理由将其纳入计划。目前，32 位足以满足大多数应用，只有一个 &lt;code&gt;j.u.c&lt;/code&gt; 同步器类 &lt;code&gt;CyclicBarrier&lt;/code&gt; 需要更多的位来维护状态，所以它使用了锁（该包中大多数更高层次的 工具也是如此）。&lt;/p&gt;\n&lt;p&gt;基于 &lt;code&gt;AQS&lt;/code&gt; 的具体类必须根据这些暴露出的状态相关的方法定义 &lt;code&gt;tryAcquire&lt;/code&gt; 和 &lt;code&gt;tryRelease&lt;/code&gt; 方法，以控制 &lt;code&gt;acquire&lt;/code&gt; 和 &lt;code&gt;release&lt;/code&gt; 操作。当同步状态满足时，&lt;code&gt;tryAcquire&lt;/code&gt; 方法必须返回 &lt;code&gt;true&lt;/code&gt;，而当新的同步状态允许后续 &lt;code&gt;acquire&lt;/code&gt; 时，&lt;code&gt;tryRelease&lt;/code&gt; 方法也必须返回 &lt;code&gt;true&lt;/code&gt;。这些方法都接受一个 &lt;code&gt;int&lt;/code&gt; 类型的参数，该参数可用于传递想要的状态。例如：可重入锁，当某个线程从条件等待中返回，然后重新获取锁时，为了重新建立循环计数的场景。很多同步器并不需要这样的参数，因此忽略它即可。&lt;/p&gt;\n&lt;h3 id=\&#34;32-阻塞\&#34;&gt;3.2 阻塞&lt;/h3&gt;\n&lt;p&gt;在 JSR166 之前，除了创建基于内置监视器的同步器，没有 Java API 可以阻塞和解锁线程。唯一可以选择的是 &lt;code&gt;Thread.suspend&lt;/code&gt; 和 &lt;code&gt;Thread.resume&lt;/code&gt;，但是它们都有无法解决的竟态问题，所以也没办法使用：当一个非阻塞线程在一个正准备阻塞的线程调用 &lt;code&gt;suspend&lt;/code&gt; 之前调用 &lt;code&gt;resume&lt;/code&gt;，&lt;code&gt;resume&lt;/code&gt;操作将不起作用。&lt;/p&gt;\n&lt;p&gt;&lt;code&gt;java.util.concurrent.locks&lt;/code&gt; 包包含一个 &lt;code&gt;LockSupport&lt;/code&gt; 类，其中包含解决这个问题的方法。方法 &lt;code&gt;LockSupport.park&lt;/code&gt; 阻塞当前线程，除非或直到发出 &lt;code&gt;LockSupport.unpark&lt;/code&gt;（虚假唤醒也是允许的） 。对 &lt;code&gt;unpark&lt;/code&gt; 的调用是不 ”计数“的，所以一个 &lt;code&gt;park&lt;/code&gt; 之前的多个 &lt;code&gt;unpark&lt;/code&gt; 只会解除一个 &lt;code&gt;park&lt;/code&gt; 操作。此外，这适用于每个线程，而不是每个同步器。一个线程在一个新的同步器上调用 &lt;code&gt;park&lt;/code&gt; 操作可能会立即返回，因为在此之前可能有“剩余的” &lt;code&gt;unpark&lt;/code&gt; 操作。但是，在缺少一个 &lt;code&gt;unpark&lt;/code&gt; 操作时，下一次调用 &lt;code&gt;park&lt;/code&gt; 就会阻塞。虽然可以显式地消除这个状态，但并不值得这样做。在需要的时候多次调用 &lt;code&gt;park&lt;/code&gt; 会更高效。&lt;/p&gt;\n&lt;p&gt;这个简单的机制在某种程度上类似于 Solaris-9 的线程库 [&lt;a href=\&#34;#11\&#34;&gt;11&lt;/a&gt;]，WIN32的 “可消费事件”，以及 Linux 中的 NPTL 线程库，因此最常见的运行 Java 的平台上都有相对应的有效实现，（但目前 Solaris 和 Linux 上的 Sun Hotspot JVM 参考实现实际上是使用一个 pthread 的 condvar 来适应目前的运行时设计的）。&lt;code&gt;park&lt;/code&gt; 方法同样支持可选的相对或绝对的超时设置，以及与 JVM 的 &lt;code&gt;Thread.interrupt&lt;/code&gt; 结合 —— 可通过中断来 &lt;code&gt;unpark&lt;/code&gt; 一个线程。&lt;/p&gt;\n&lt;h3 id=\&#34;33-队列\&#34;&gt;3.3 队列&lt;/h3&gt;\n&lt;p&gt;整个框架的核心是维护阻塞线程的队列，这里仅限于 FIFO 队列。因此，该框架不支持基于优先级的同步。&lt;/p&gt;\n&lt;p&gt;如今，对于同步队列最合适的选择是不需要使用低级锁来构造的非阻塞数据结构，这一点几乎没有争议。其中，有两个主要的候选：一个是 Mellor-Crummey 和 Scott锁（MCS锁）[&lt;a href=\&#34;#9\&#34;&gt;9&lt;/a&gt;] 的变体，另一个是Craig，Landin 和 Hagersten锁（CLH锁）[&lt;a href=\&#34;#5\&#34;&gt;5&lt;/a&gt;] [&lt;a href=\&#34;#8\&#34;&gt;8&lt;/a&gt;] [&lt;a href=\&#34;#10\&#34;&gt;10&lt;/a&gt;]的变体。一直以来，CLH 锁只用于旋转锁。然而，它们似乎比 MCS 更适合在同步框架器中使用，因为它们更容易处理取消和超时，所以作为实现的基础。最终的设计与最初的 CLH 结构相差甚远，因此下文将对此做出解释。&lt;/p&gt;\n&lt;p&gt;CLH 队列实际上并不是很像队列，因为它的入队和出队操作都与它的用途（即用作锁）紧密相关。他是一个链表队列，通过两个字段 &lt;code&gt;head&lt;/code&gt; 和 &lt;code&gt;tail&lt;/code&gt; 来存取，这两个字段支持原子更新，两者在初始化时都指向了空节点。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;1\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1662043146964.png\&#34; alt=\&#34;CLHNode\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;一个新节点，&lt;code&gt;node&lt;/code&gt;，通过一个原子操作入队：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;do {\n    pred = tail;\n} while (!tail.compareAndSet(pred, node));\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;每一个节点的 &lt;code&gt;release&lt;/code&gt; 状态都保存在其前驱节点中。因此，自旋锁的“自旋”操作如下：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;while (pred.status != RELEASED); // spin\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;自旋后的出队操作只需将 &lt;code&gt;head&lt;/code&gt; 字段指向刚刚得到锁的节点：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;head = node\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;CLH 锁的优点之一是：其入队和出队操作是快速的、无锁的、无阻塞的（即使在竞争情况下，也只会有一个线程赢得插入机会，从而能继续进行）；检测是否有线程在等待也很快（只需要检测 &lt;code&gt;head&lt;/code&gt; 和 &lt;code&gt;tail&lt;/code&gt; 是否相等）；同时，&lt;code&gt;release&lt;/code&gt; 是分散的，避免了一些不必要的内存竞争。&lt;/p&gt;\n&lt;p&gt;在 CLH 锁的原始版本中，节点之间甚至都没有链接。在自旋锁中，&lt;code&gt;pred&lt;/code&gt; 变量可以作为局部变量保存。然而，Scott 和 Scherer [&lt;a href=\&#34;#10\&#34;&gt;10&lt;/a&gt;] 证明，通过在节点中显式的维护 &lt;code&gt;pred&lt;/code&gt; 字段，CLH 锁可以处理超时和各种形式的取消：如果节点的前驱结点取消，节点可以滑动去使用前一个节点的状态字段。&lt;/p&gt;\n&lt;p&gt;使用 CLH 队列阻塞同步器，需要做的主要修改是提供一种高效的方式定位某个节点的后继节点。在自旋锁中，一个节点只需要改变其状态，下一次自旋中其后继节点就能注意到这个改变，所有节点间的链接操作并不是必须的。但是在阻塞同步器中，一个节点需要显式地唤醒（&lt;code&gt;unpark&lt;/code&gt;）其后继节点。&lt;/p&gt;\n&lt;p&gt;&lt;code&gt;AQS&lt;/code&gt; 队列的节点包含一个 &lt;code&gt;next&lt;/code&gt; 链接到它的后继节点。但是，由于没有针对双向链表节点的类似 &lt;code&gt;compareAndSet&lt;/code&gt; 的原子性无锁插入指令，因此这个 &lt;code&gt;next&lt;/code&gt; 链接的设置并非作为原子性插入操作的一部分，而仅是在节点被插入后简单赋值：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;pred.next = node;\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;这反映在所有的用法中。&lt;code&gt;next&lt;/code&gt; 链接仅是一种优化。如果一个节点的后继节点通过它的 &lt;code&gt;next&lt;/code&gt; 字段看起来不存在（或看起来被取消了），总是可以从尾部开始，使用 &lt;code&gt;pred&lt;/code&gt; 字段向前遍历来检查是否真的有后继节点。&lt;/p&gt;\n&lt;p&gt;第二组修改是使用保存在每个节点中的状态字段来控制阻塞，而非自旋。在同步器框架中，仅在线程调用具体子类的 &lt;code&gt;tryAcquire&lt;/code&gt; 方法返回 &lt;code&gt;true&lt;/code&gt; 时，队列中的线程才能从 &lt;code&gt;acquire&lt;/code&gt; 操作中返回；而单个 &lt;code&gt;release&lt;/code&gt; 位是不够的。但是仍然需要控制，以确保活动线程只允许在队列的头部调用 &lt;code&gt;tryAcquire&lt;/code&gt;；在这种情况下，&lt;code&gt;acquire&lt;/code&gt; 可能会失败，然后（重新）阻塞。这种情况不需要读取状态标识，因为可以通过检查当前节点的前驱是否为 &lt;code&gt;head&lt;/code&gt; 来确定权限。与自旋锁不同，这里会读取 &lt;code&gt;head&lt;/code&gt;  的副本以保证不会有太多的内存竞争。但是，取消状态必须仍然存在于状态字段中。&lt;/p&gt;\n&lt;p&gt;队列节点的状态字段还用于避免不必要的 &lt;code&gt;park&lt;/code&gt; 和 &lt;code&gt;unpark&lt;/code&gt; 调用。虽然这些方法相对于阻塞原语来说比较快，但是它们在跨 Java 和 JVM 运行时和/或操作系统边界时仍有可避免的开销。在调用 &lt;code&gt;park&lt;/code&gt; 之前，线程设置一个 “唤醒（signal me）” 位，然后再次检查同步和节点状态。一个释放的线程会清空其自身状态。这样线程就不必频繁地尝试阻塞，尤其对于锁类，在这些锁类中，等待下一个合格线程获取锁的时间会加重其他竞争。除非后继线程已经设置了 &lt;code&gt;signal&lt;/code&gt; 位，否则这也可以避免正在 &lt;code&gt;release&lt;/code&gt; 的线程去判断其后继节点。这也消除了除非 &lt;code&gt;signal&lt;/code&gt; 和 &lt;code&gt;cancel&lt;/code&gt; 一起发生，否则必须遍历多个节点来处理明显为空的 &lt;code&gt;next&lt;/code&gt; 字段的情况。&lt;/p&gt;\n&lt;p&gt;同步器框架中使用的 CLH 锁的变体与其他语言中使用的变体之间的主要区别可能是，依靠垃圾收集来挂你节点的存储回收，这避免了复杂性和开销。然而，即使依赖 GC，也仍然需要在确定链接字段永远不会被需要时，将其置为 null。这往往可以与出队操作一起完成。否则，无用的节点仍然可达，就导致它们不可回收。&lt;/p&gt;\n&lt;p&gt;J2SE1.5 版本的源代码文档中描述了一些更进一步的微调，包括 CLH 队列在第一次争用时所需的初始空节点的延迟初始化等。&lt;/p&gt;\n&lt;p&gt;抛开这些细节，基本的 &lt;code&gt;acquire&lt;/code&gt; 操作的最终实现的一般形式如下（互斥，非中断，无超时）：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;if (!tryAcquire(arg)) {\n    node = create and enqueue new node;\n    pred = node&#39;s effective predecessor;\n    while (pred is not head node || !tryAcquire(arg)) {\n        if (pred&#39;s signal bit is set)\n            park()\n        else \n            compareAndSet pred&#39;s signal bit to true;\n        pred = node&#39;s effective predecessor;\n    }\n    head = node;\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;&lt;code&gt;release&lt;/code&gt; 操作：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;if (tryRelease(arg) &amp;amp;&amp;amp; head node&#39;s signal bit is set) {\n\tcompareAndSet head&#39;s signal bit to false;\n    unpark head&#39;s successor, if one exists\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;&lt;code&gt;acquire&lt;/code&gt; 操作的主循环次数依赖于具体实现类中 &lt;code&gt;tryAcquire&lt;/code&gt; 的实现方式。另一方面，在没有 &lt;code&gt;cancel&lt;/code&gt; 操作的情况下，每一个组件的 &lt;code&gt;acquire&lt;/code&gt; 和 &lt;code&gt;cancel&lt;/code&gt; 都是在一个 O(1) 常数时间内操作，不考虑 &lt;code&gt;park&lt;/code&gt; 中发生的所有操作系统线程调度。&lt;/p&gt;\n&lt;p&gt;支持 &lt;code&gt;cancel&lt;/code&gt; 操作主要是要在 &lt;code&gt;acquire&lt;/code&gt; 循环里的 &lt;code&gt;park&lt;/code&gt; 返回时检查中断或超时。由于超时或中断而被取消等待的线程会设置其节点状态，然后 &lt;code&gt;unpark&lt;/code&gt; 其后继节点。在有 &lt;code&gt;cancel&lt;/code&gt; 的情况下，判断其前驱结点和后继节点以及重置状态可能需要 O(n) 的遍历（n 是队列的长度）。由于 &lt;code&gt;cancel&lt;/code&gt; 操作，该线程再也不会被阻塞，节点的连接和状态字段可以被快速重建。&lt;/p&gt;\n&lt;h3 id=\&#34;34-条件队列\&#34;&gt;3.4 条件队列&lt;/h3&gt;\n&lt;p&gt;同步器框架提供了一个 &lt;code&gt;ConditionObject&lt;/code&gt; 类，给维护独占同步的类以及实现 &lt;code&gt;Lock&lt;/code&gt; 接口的类使用。一个锁对象可以管理任意数量的 &lt;code&gt;ConditionObject&lt;/code&gt;，可以提供典型的监视器风格的 &lt;code&gt;await&lt;/code&gt;、&lt;code&gt;signal&lt;/code&gt; 和 &lt;code&gt;singalAll&lt;/code&gt; 操作，包括那些带有超时的操作，以及一些检测和监控的方法。&lt;/p&gt;\n&lt;p&gt;同样是通过修正一些设计决策，&lt;code&gt;ConditionObject&lt;/code&gt; 类使条件能够与其他同步操作有效地集成。该类仅支持 Java 风格的监视器访问规则，在这些规则中，只有当拥有条件的锁被当前线程持有时，条件操作才是合法的（参见 [&lt;a href=\&#34;#4\&#34;&gt;4&lt;/a&gt;] 对替代方法的讨论）。因此，一个 &lt;code&gt;ConditionObject&lt;/code&gt; 关联到一个 &lt;code&gt;ReentrantLock&lt;/code&gt; 上就表现的跟内置监视器的行为方式相同（通过 &lt;code&gt;Object.await&lt;/code&gt; 等），不同之处仅在与方法名、额外的功能以及用户可以为每个锁声明多个条件。&lt;/p&gt;\n&lt;p&gt;&lt;code&gt;ConditionObject&lt;/code&gt; 使用与同步器相同的内部队列节点，但在单独的条件队列中维护它们。&lt;code&gt;signal&lt;/code&gt;操作是通过将节点从条件队列转移到锁队列中来实现的，而没有必要在需要唤醒的线程重新获取到锁之前将其唤醒。&lt;/p&gt;\n&lt;p&gt;基本的 &lt;code&gt;await&lt;/code&gt; 操作如下：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;create and add new node to condition queue;\nrelease lock;\nblock until node is on lock queue;\nre-acquire lock;\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;&lt;code&gt;signal&lt;/code&gt; 操作如下：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;transfer the first node from condition queue to lock queue;\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;因为这些操作仅在持有锁时执行，所以它们可以使用顺序链表队列操作（在节点中使用 &lt;code&gt;nextWaiter&lt;/code&gt; 字段）来维护条件队列。转移操作仅仅把第一个节点从条件队列中的链接移除，然后通过 CLH 插入操作将其插入到锁队列上。&lt;/p&gt;\n&lt;p&gt;实现这些操作的主要复杂性是处理由于超时或 &lt;code&gt;Thread.interrupt&lt;/code&gt; 而导致的条件等待的取消。&lt;code&gt;cancel&lt;/code&gt; 和 &lt;code&gt;signal&lt;/code&gt;几乎同时发生就会有竞争问题，最终的结果遵照内置监视器的规范。JSR133 修订后，就要求如果中断发生在 &lt;code&gt;signal&lt;/code&gt; 操作之前，&lt;code&gt;await&lt;/code&gt; 方法必须在重新获取到锁后，抛出 &lt;code&gt;InterruptedException&lt;/code&gt;。但是，如果中断发生在 &lt;code&gt;signal&lt;/code&gt; 后，&lt;code&gt;await&lt;/code&gt; 必须返回且不抛异常，同时设置线程的中断状态。&lt;/p&gt;\n&lt;p&gt;为了保持正确的顺序，队列节点状态变量中的一个位记录了该节点是否已经（或正在）被转移。&lt;code&gt;cancel&lt;/code&gt; 和 &lt;code&gt;signal&lt;/code&gt; 相关的代码都会尝试用 &lt;code&gt;compareAndSet&lt;/code&gt; 修改这个状态。如果某次 &lt;code&gt;signal&lt;/code&gt; 操作修改失败，就会转移队列中的下一个节点（如果存在的话）。如果某次 &lt;code&gt;cancel&lt;/code&gt; 操作修改失败，就必须终止此次转移，然后等待重新获得锁。后面的情况采用了一个潜在的无限的自旋等待。在节点成功的被插入到锁队列之前，被 &lt;code&gt;cancel&lt;/code&gt; 的等待不能重新获得锁，所以必须自旋等待 CLH 队列插入（即 &lt;code&gt;compareAndSet&lt;/code&gt; ）成功，被 &lt;code&gt;signal&lt;/code&gt; 线程成功执行。这里很少需要自旋，并且使用 &lt;code&gt;Thread.yield&lt;/code&gt; 来提供一个调度提示其他线程（理想情况下是发出 &lt;code&gt;signal&lt;/code&gt; 的线程）应该运行。虽然在这里可以为 &lt;code&gt;cancel&lt;/code&gt; 实现一个帮助策略来插入节点，但是这种情况非常罕见，以至于无法证明这样做所带来的额外开销是合理的。在所有其他情况下，这里和其他地方的基本机制不使用自旋或&lt;code&gt;yield&lt;/code&gt;，在因此在但处理器上保持了合理的性能。&lt;/p&gt;\n&lt;h2 id=\&#34;4-用例\&#34;&gt;4. 用例&lt;/h2&gt;\n&lt;p&gt;&lt;code&gt;AQS&lt;/code&gt; 类将上述功能组合在一起，并作为同步器的“模板方法模式”[&lt;a href=\&#34;#6\&#34;&gt;6&lt;/a&gt;]基类。子类只需定义状态的检查和更新的相关方法，实现控制 &lt;code&gt;acquire&lt;/code&gt; 和 &lt;code&gt;release&lt;/code&gt;  操作。然而，&lt;code&gt;AQS&lt;/code&gt; 的子类本身用作同步器 ADT 并不合适，因为该类必须暴露出内部内部控制 &lt;code&gt;acquire&lt;/code&gt; 和 &lt;code&gt;release&lt;/code&gt; 的规则，这些都不应该对用户可见。所有 &lt;code&gt;j.u.c&lt;/code&gt; 包中的同步器类都声明了一个 &lt;code&gt;private&lt;/code&gt; 且继承 &lt;code&gt;AQS&lt;/code&gt;的内部类，并且把所有同步方法都委托给这个内部类。这样，各个同步器类的公开方法就可以使用适合自己的名称。&lt;/p&gt;\n&lt;p&gt;例如，这里有一个最简单的 &lt;code&gt;Mutex&lt;/code&gt; 类，它使用同步状态 &lt;code&gt;0&lt;/code&gt; 表示未锁定，使用同步状态 &lt;code&gt;1&lt;/code&gt; 表示锁定。这个类不需要同步方法中的参数，因此这里在调用的时候使用 &lt;code&gt;0&lt;/code&gt; 作为实参，方法实现里将其忽略。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;class Mutex {\n  class Sync extends AbstractQueuedSynchronizer {\n    public boolean tryAcquire(int ingore) {\n      return compareAndSetState(0, 1);\n    }\n    public boolean tryRelease(int ignore) {\n      setState(0);\n      return true;\n    }\n  }\n  \n  private final Sync sync = new Sync();\n  \n  public void lock(){\n    sync.acquire(0);\n  }\n  public void unlock(){\n    sync.release(0);\n  }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;这个例子的完整版本，以及其他使用指南可以在 J2SE 文档中找到。还有可以有一些其他变体。例如，&lt;code&gt;tryAcquire&lt;/code&gt; 可以使用 “test-and-test-and-set” 策略，即在改变状态值之前先对状态进行校验。&lt;/p&gt;\n&lt;p&gt;令人诧异的是，像互斥锁这样对性能敏感的东西，也打算通过委托和虚方法结合的方式来定义。然而，这正是现代动态编译器长期关注的面向对象设计结构。它们往往擅长优化掉这种开销，起码会优化频繁调用同步器的哪些代码。&lt;/p&gt;\n&lt;p&gt;&lt;code&gt;AQS&lt;/code&gt; 类还提供了许多方法来帮助同步器类进行策略控制。例如，基础的 &lt;code&gt;acquire&lt;/code&gt; 方法有可超时和可中断的版本。虽然到目前为止的讨论都集中在独占模式的同步器上（如锁），但 &lt;code&gt;AQS&lt;/code&gt; 类也包含一组并行的方法（如&lt;code&gt;acquireShared&lt;/code&gt;），不同之处在于 &lt;code&gt;tryAcquireShared&lt;/code&gt; 和 &lt;code&gt;tryReleaseShared&lt;/code&gt; 方法可以通知框架（同步它们的返回值）可以接受更多的请求，最终框架会通过级联的 &lt;code&gt;signal&lt;/code&gt; 唤醒多个线程。&lt;/p&gt;\n&lt;p&gt;虽然序列化（持久存储或传输）同步器通常来说没有太大意义，但这些类经常被用来构造其他类，如线程安全的集合，它们通常是可序列化的。&lt;code&gt;AQS&lt;/code&gt; 和 &lt;code&gt;ConditionObject&lt;/code&gt; 类提供了序列化同步状态的方法，但不会序列化潜在的被阻塞的线程，也不会序列化其他内部暂时性的 bookkeeping。即使如此，在反序列化时，大部分同步器类也只是仅将同步状态重置为初始值，这与内置锁的隐式策略一直 —— 总是反序列化到一个解锁状态。这相当于一个空操作，但仍必须显式地支持以便 ·&lt;code&gt;final&lt;/code&gt; 字段能够反序列化。&lt;/p&gt;\n&lt;h3 id=\&#34;41-公平调度的控制\&#34;&gt;4.1 公平调度的控制&lt;/h3&gt;\n&lt;p&gt;即使它们基于 FIFO 队列，同步器也不一定是公平的。请注意，在基础的 &lt;code&gt;acquire&lt;/code&gt; 算法（第 3.3 节）中，&lt;code&gt;tryAcquire&lt;/code&gt; 检查是在排队之前执行的。因此，新的 &lt;code&gt;acquire&lt;/code&gt; 线程可以“窃取”本该属于队列头部第一个线程通过同步器的机会。&lt;/p&gt;\n&lt;p&gt;可 &lt;em&gt;闯入的FIFO&lt;/em&gt; 策略通常比其他技术提供更高的总吞吐量。当一个存在竞争的锁已经空闲，而下一个准备获取锁的线程正在解除阻塞的过程中，此时没有线程可以获取到这个锁，如果使用&lt;em&gt;闯入策略&lt;/em&gt;，则可以减少这之间的时间。与此同时，这种策略还可以避免过多的、无效的竞争（只允许一个（第一个）排队的线程被唤醒，然后尝试 &lt;code&gt;acquire&lt;/code&gt; 操作导致）。如果是短时间持有同步器的场景，创建同步器的开发人员在可以通过定义 &lt;code&gt;tryAcquire&lt;/code&gt; ，在控制权返回之前重复调用自己若干次，来进一步凸显&lt;em&gt;闯入&lt;/em&gt;效果。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;2\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1662043201211.png\&#34; alt=\&#34;fifo\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;可闯入的 FIFO 同步器只有概率性的公平属性。在锁队列的头部一个解除了阻塞的线程拥有一次无偏向的机会来赢得与闯入线程之间的竞争，如果竞争失败，那么要么重新阻塞，要么进行重试。然而，如果闯入的线程到达的速度比队头的线程解除阻塞更快，俺么在队列中的第一个线程将会很难赢得竞争，以及于几乎总是要重新阻塞，并且它的后继节点也会一直保持阻塞。对于短暂持有的同步器来说，在队列中第一个线程被解除阻塞的期间，多处理器上很可能发生过多次闯入和 &lt;code&gt;release&lt;/code&gt;。如下文所述，最终结果就是保持一个或多个线程的高速进展的同时，在一定概率是避免了饥饿的发生。&lt;/p&gt;\n&lt;p&gt;当需要更高的公平性需求时，实现起来也很简单。如果需要严格的公平性，程序员可以定义 &lt;code&gt;tryAcquire&lt;/code&gt; 为：如果当前线程不是队列的头结点（可以通过 &lt;code&gt;getFirstQueuedThread&lt;/code&gt;方法检查这一点，这是框架提供的为数不多的几个检测方法之一），则立即返回失败（返回 &lt;code&gt;false&lt;/code&gt;）。&lt;/p&gt;\n&lt;p&gt;一种更快、不太严格的方法是，如果队列（暂时）为空，也允许 &lt;code&gt;tryAcquire&lt;/code&gt; 成功。在这种情况下，遇到空队列的多个线程可能会争取第一个获得锁，这样，通常至少有一个线程是不需要放入队列的。所有支持 &lt;code&gt;fair&lt;/code&gt; 模式的 &lt;code&gt;j.u.c&lt;/code&gt; 同步器都采用这种策略。&lt;/p&gt;\n&lt;p&gt;尽管公平性设置在实践中很有用，当时它们并没有保障，因为 Java Language Specification 没有提供这样的调度保证。例如：即使是严格公平的同步器，如果一组线程永远不需要阻塞来达到相互等待，那么 JVM 也可以决定完全按照顺序方式运行它们。实际上，在单处理上，在抢占式上下文切换之前，这样的线程有可能是各自运行了一段时间。如果这样的线程正持有某个互斥锁，它将很快被切换回来，仅仅是为了释放其持有的锁，然后会继续阻塞，因为它知道有另一个线程需要这把锁，这更增加了同步器可用但没有线程能来获取直接的间隔。同步器公平性设置在多处理器上的影响可能会更大，因为在这种环境中会产生更多的交错，因此一个线程就会有更多的机会发现锁被另一个线程请求。&lt;/p&gt;\n&lt;p&gt;在高度竞争的情况下，当保护短暂持有的代码体时，尽管可能性能不佳，但公平锁仍然能有效地工作。例如，当公平锁保护的是相对长的代码体和/或具有相对较长的锁间（inter-lock）间隔时，在这种情况下，闯入只能带来很小的性能优势，但却可能会大大增加无限等待的风险。同步器框架将这些工程决策留给用户来确定。&lt;/p&gt;\n&lt;h3 id=\&#34;42-同步器\&#34;&gt;4.2 同步器&lt;/h3&gt;\n&lt;p&gt;下面是 &lt;code&gt;j.u.c&lt;/code&gt; 包中同步器定义方式的概述：&lt;/p&gt;\n&lt;p&gt;&lt;code&gt;ReentrantLock&lt;/code&gt; 类使用同步状态来保存锁（重复）持有的次数。当锁被一个线程获取时，&lt;code&gt;ReentrantLock&lt;/code&gt; 也会记录下当前获得锁的线程标识，以便检查是否是重复获取，以及当前错误的线程试图进行解锁操作时检测是否存在非法状态异常。&lt;code&gt;ReentrantLock&lt;/code&gt; 还是用了 &lt;code&gt;AQS&lt;/code&gt; 提供的 &lt;code&gt;ConditionObject&lt;/code&gt;，并向外暴露了其他监控和检查的方法。&lt;code&gt;ReentrantLock&lt;/code&gt; 通过在内部声明的两个不同的 &lt;code&gt;AQS&lt;/code&gt; 实现类（提供公平模式的那个回禁用 &lt;em&gt;闯入&lt;/em&gt; 策略 ）来实现可选的公平模式，在创建 &lt;code&gt;ReentrantLock&lt;/code&gt; 实例的时候根据配置使用相应的 &lt;code&gt;AQS&lt;/code&gt; 实现类。&lt;/p&gt;\n&lt;p&gt;&lt;code&gt;ReentrantReadWriteLock&lt;/code&gt; 类使用同步状态的 16 位来保存写锁计数，剩余的 16 位保存读锁计数。&lt;code&gt;WriteLock&lt;/code&gt; 在其他方面的结构与 &lt;code&gt;ReentrantLock&lt;/code&gt; 相同。&lt;code&gt;ReadLock&lt;/code&gt; 使用 &lt;code&gt;acquireShared&lt;/code&gt; 方法来启用多个读线程。&lt;/p&gt;\n&lt;p&gt;&lt;code&gt;Semaphore&lt;/code&gt; 类（计数信号量）使用同步状态来保存当前计数。它里面定义的 &lt;code&gt;acquireShared&lt;/code&gt; 方法会减少计数，或当计数为非正值时阻塞线程；&lt;code&gt;tryRelease&lt;/code&gt; 方法会增加计数，如果计数现在是正数，可能还要解除线程的阻塞。&lt;/p&gt;\n&lt;p&gt;&lt;code&gt;CountDownLatch&lt;/code&gt; 类使用同步状态来表示计数。当它达到零时，所有 &lt;code&gt;acquire&lt;/code&gt; 都通过。&lt;/p&gt;\n&lt;p&gt;&lt;code&gt;FutureTask&lt;/code&gt; 类使用同步状态来表示未来的运行状态（初始化、运行、取消、完成）。设置或取消一个 &lt;code&gt;FutureTask&lt;/code&gt; 时，会调用 &lt;code&gt;AQS&lt;/code&gt; 的 &lt;code&gt;release&lt;/code&gt; 操作；等待计算结果的线程解除阻塞是通过 &lt;code&gt;AQS&lt;/code&gt; 的 &lt;code&gt;acquire&lt;/code&gt; 操作。&lt;/p&gt;\n&lt;p&gt;&lt;code&gt;SynchronousQueue&lt;/code&gt; 类（一种 CSP（Communication Sequential Processes）形式的传递）使用了内部的等待节点，这些节点可以用于协调生产者和消费者。同时，它使用 &lt;code&gt;AQS&lt;/code&gt;  同步状态来控制当某个消费者消费前一项时，允许一个生产者继续生产，反之亦然。&lt;/p&gt;\n&lt;p&gt;&lt;code&gt;j.u.c&lt;/code&gt; 包的用户当然可以为自定义的应用定义自己的同步器。例如，那些曾考虑到过的，但没有采纳进这个包的同步器包括提供 WIN32 事件风格的语义类，binary latches、集中管理的锁以及基于树的屏障。&lt;/p&gt;\n&lt;h2 id=\&#34;5-性能\&#34;&gt;5. 性能&lt;/h2&gt;\n&lt;p&gt;尽管同步器框架除了互斥锁之外，还支持许多其他类型的同步方式，但锁的性能是最容易测量和比较的。即便如此，仍由许多不同的测量方法。这里的实验主要目的在于展示开销和吞吐量。&lt;/p&gt;\n&lt;p&gt;在每个测试中，所有线程都重复的更新一个伪随机数，该随机数由 &lt;code&gt;nextRandom(int seed)&lt;/code&gt; 方法计算：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;int t = (seed % 127773) * 16807 - (seed / 127773) * 2836;\nreturn (t &amp;gt; 0) ? t : t + 0x7fffffff;\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;在每次迭代中，线程以概率 S 在一个互斥锁下更新共享的生成器，否则更新其自己局部的生成器，此时是不需要锁的。因此，锁的占用是短暂的，这就会导致线程在持有锁期间被抢占时的外界干扰降到了最小。这个函数的随机性主要为了两个目的：确定是否需要使用锁（这个生成器足以应付这里的需求），以及使用循环中的代码不可能被轻易的优化掉。&lt;/p&gt;\n&lt;p&gt;这里比较了四种锁：内置的，用的是 &lt;code&gt;synchronized&lt;/code&gt; 块；互斥锁，使用一个简单的 &lt;code&gt;Mutex&lt;/code&gt; 类，如第四节所示；可重入锁，用的是 &lt;code&gt;ReentrantLock&lt;/code&gt;；以及公平锁，用的是 &lt;code&gt;ReentrantLock&lt;/code&gt; 的公平模式。所有测试都运行在 J2SE1.5 JDK build46（大致与beta2相同）的 server 模式下。在收集测试数据之前，测试程序执行了 20 次无竞争运行，以消除预热效应。除了公平模式测试只运行了一百万次迭代，其他每个线程测试运行一千万次迭代。&lt;/p&gt;\n&lt;p&gt;该测试运行在四台 X86 机器和四台 UltraSparc 机器上。所有 X86 机器都运行的是 RedHat 基于 NPTL 2.4 内核和库的 Linux 系统。所有的 UltraSparc 机器都运行的是 Solaris-9。测试时所有系统的负载都很轻。根据该测试的特征，并不要求操作系统完全空闲。“4P” 这个名字反映出双核超线程的 Xeon 更像是 4 路处理器，而不是 2 路处理器。这里没有将测试数据规范化。如下所示，同步的相对开销与处理器的数量、类型、速度之间不具备简单的关系。&lt;/p&gt;\n&lt;center&gt;&lt;b&gt;表1 测试的平台&lt;/b&gt;&lt;/center&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;名字&lt;/th&gt;\n&lt;th&gt;处理器数量&lt;/th&gt;\n&lt;th&gt;类型&lt;/th&gt;\n&lt;th&gt;速度（Mhz）&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;1P&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;Pentium3&lt;/td&gt;\n&lt;td&gt;900&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;2P&lt;/td&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;td&gt;Pentium3&lt;/td&gt;\n&lt;td&gt;1400&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;2A&lt;/td&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;td&gt;Athlon&lt;/td&gt;\n&lt;td&gt;2000&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;4P&lt;/td&gt;\n&lt;td&gt;2HT&lt;/td&gt;\n&lt;td&gt;Pentium4/Xeon&lt;/td&gt;\n&lt;td&gt;2400&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;1U&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;UltraSparc2&lt;/td&gt;\n&lt;td&gt;650&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;4U&lt;/td&gt;\n&lt;td&gt;4&lt;/td&gt;\n&lt;td&gt;UltraSparc2&lt;/td&gt;\n&lt;td&gt;450&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;8U&lt;/td&gt;\n&lt;td&gt;8&lt;/td&gt;\n&lt;td&gt;UltraSparc3&lt;/td&gt;\n&lt;td&gt;750&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;24U&lt;/td&gt;\n&lt;td&gt;24&lt;/td&gt;\n&lt;td&gt;UltraSparc3&lt;/td&gt;\n&lt;td&gt;750&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;h3 id=\&#34;51-开销\&#34;&gt;5.1 开销&lt;/h3&gt;\n&lt;p&gt;通过只只运行一个线程，从 S=1 时的每次迭代时间减去 S=0 （访问共享内存的概率为零）时的每次迭代时间得到的。表 2 显示了在非竞争的场景下每次锁操作的开销（以纳秒为单位）。&lt;code&gt;Metux&lt;/code&gt; 类最接近于框架的基本耗时，可重入锁的额外开销是记录当前所有者线程和错误检查时的耗时，对于公平锁来说还会包含开始时检查队列是否为空的耗时。&lt;/p&gt;\n&lt;p&gt;表 2 还显示了 &lt;code&gt;tryAcquire&lt;/code&gt; 与内置锁的“快速路径（fast path）”的耗时对比。这里的差异主要反映了各种锁和机器中使用的不同的原子指令以及内存屏障的耗时。在多处理器上，这些指令常常是完全优于所有其他指令的。内置锁和同步器类之间的主要差别，显然是由于 Hotspot 锁使用 &lt;code&gt;compareAndSet&lt;/code&gt; 锁定和解锁，而同步器的 &lt;code&gt;acquire&lt;/code&gt; 操作使用了一次 &lt;code&gt;compareAndSet&lt;/code&gt;，但 &lt;code&gt;release&lt;/code&gt; 操作用的是一次 &lt;code&gt;volatile&lt;/code&gt; 写（即，多处理器上的一次内存屏障以及所有处理器上的重排序限制）。每个锁的绝对和相对耗时因机器的不同而不同。&lt;/p&gt;\n&lt;center&gt;&lt;b&gt;表2 无竞争时的单锁开销（单位：纳秒）&lt;/b&gt;&lt;/center&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;机器&lt;/th&gt;\n&lt;th&gt;内置&lt;/th&gt;\n&lt;th&gt;互斥&lt;/th&gt;\n&lt;th&gt;可重入&lt;/th&gt;\n&lt;th&gt;公平可重入&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;1P&lt;/td&gt;\n&lt;td&gt;18&lt;/td&gt;\n&lt;td&gt;9&lt;/td&gt;\n&lt;td&gt;31&lt;/td&gt;\n&lt;td&gt;37&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;2P&lt;/td&gt;\n&lt;td&gt;58&lt;/td&gt;\n&lt;td&gt;71&lt;/td&gt;\n&lt;td&gt;77&lt;/td&gt;\n&lt;td&gt;81&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;2A&lt;/td&gt;\n&lt;td&gt;13&lt;/td&gt;\n&lt;td&gt;21&lt;/td&gt;\n&lt;td&gt;31&lt;/td&gt;\n&lt;td&gt;30&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;4P&lt;/td&gt;\n&lt;td&gt;116&lt;/td&gt;\n&lt;td&gt;95&lt;/td&gt;\n&lt;td&gt;109&lt;/td&gt;\n&lt;td&gt;117&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;1U&lt;/td&gt;\n&lt;td&gt;90&lt;/td&gt;\n&lt;td&gt;40&lt;/td&gt;\n&lt;td&gt;58&lt;/td&gt;\n&lt;td&gt;67&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;4U&lt;/td&gt;\n&lt;td&gt;122&lt;/td&gt;\n&lt;td&gt;82&lt;/td&gt;\n&lt;td&gt;100&lt;/td&gt;\n&lt;td&gt;115&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;8U&lt;/td&gt;\n&lt;td&gt;160&lt;/td&gt;\n&lt;td&gt;83&lt;/td&gt;\n&lt;td&gt;103&lt;/td&gt;\n&lt;td&gt;123&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;24U&lt;/td&gt;\n&lt;td&gt;161&lt;/td&gt;\n&lt;td&gt;84&lt;/td&gt;\n&lt;td&gt;108&lt;/td&gt;\n&lt;td&gt;119&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;p&gt;在另一个极端，表 3 显示了在 S=1 的情况下，运行 256 个并发线程时产生了大规模的锁竞争下每个锁的开销。在完全饱和的情况下，可闯入的 FIFO 锁比内置锁的开销少了一个数量级（相当于更大的吞吐量），比公平锁少了两个数量级。这证明了即使在极端争用的情况下，可闯入FIFO策略在保持线程进度方面的有效性。&lt;/p&gt;\n&lt;p&gt;表 3 也说明了即使在内部开销比较低的情况下，公平锁的性能也完全是由上下文切换的时间所决定的。列出的时间大致上都与各平台上线程阻塞和解除线程阻塞的时间成比例。&lt;/p&gt;\n&lt;p&gt;此外，后续增加的一个实验（仅使用机器 4P）显示，对于这里使用的非常短暂的锁，公平性设置对总体方差只有很小的影响。这里将线程终止时间的差异被记录为可变性的粗粒度度量。在机器 4P 上，公平锁的时间度量的标准差平均为 0.7%，可重入锁平均为 6.0%。作为对比，为模拟一个产时间持有锁的场景，测试中使每个线程在持有锁的情况下计算了 16K 次随机数。这时，总运行时间几乎是相同的（公平锁：9.79s，可重入锁：9.72s）。公平模式下的差异依然很小，标准差平均为 0.1%，而可重入锁上升到了平均 29.5%。&lt;/p&gt;\n&lt;center&gt;&lt;b&gt;表格3 饱和时的单锁开销（单位：纳秒）&lt;/b&gt;&lt;/center&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;机器&lt;/th&gt;\n&lt;th&gt;内置&lt;/th&gt;\n&lt;th&gt;互斥&lt;/th&gt;\n&lt;th&gt;可重入&lt;/th&gt;\n&lt;th&gt;公平可重入&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;1P&lt;/td&gt;\n&lt;td&gt;521&lt;/td&gt;\n&lt;td&gt;46&lt;/td&gt;\n&lt;td&gt;67&lt;/td&gt;\n&lt;td&gt;8327&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;2P&lt;/td&gt;\n&lt;td&gt;930&lt;/td&gt;\n&lt;td&gt;108&lt;/td&gt;\n&lt;td&gt;132&lt;/td&gt;\n&lt;td&gt;14967&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;2A&lt;/td&gt;\n&lt;td&gt;748&lt;/td&gt;\n&lt;td&gt;79&lt;/td&gt;\n&lt;td&gt;84&lt;/td&gt;\n&lt;td&gt;33910&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;4P&lt;/td&gt;\n&lt;td&gt;1146&lt;/td&gt;\n&lt;td&gt;188&lt;/td&gt;\n&lt;td&gt;247&lt;/td&gt;\n&lt;td&gt;15328&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;1U&lt;/td&gt;\n&lt;td&gt;879&lt;/td&gt;\n&lt;td&gt;153&lt;/td&gt;\n&lt;td&gt;177&lt;/td&gt;\n&lt;td&gt;41394&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;4U&lt;/td&gt;\n&lt;td&gt;2590&lt;/td&gt;\n&lt;td&gt;347&lt;/td&gt;\n&lt;td&gt;368&lt;/td&gt;\n&lt;td&gt;30004&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;8U&lt;/td&gt;\n&lt;td&gt;1274&lt;/td&gt;\n&lt;td&gt;157&lt;/td&gt;\n&lt;td&gt;174&lt;/td&gt;\n&lt;td&gt;31084&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;24U&lt;/td&gt;\n&lt;td&gt;1983&lt;/td&gt;\n&lt;td&gt;160&lt;/td&gt;\n&lt;td&gt;182&lt;/td&gt;\n&lt;td&gt;32291&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;h3 id=\&#34;52-吞吐量\&#34;&gt;5.2 吞吐量&lt;/h3&gt;\n&lt;p&gt;大多数同步器的使用范围在无竞争和饱和竞争这两个极端之间。这可以用实验在两个方面进行检查，通过修改固定数量线程的竞争概率，和/或通过向一组具有固定竞争概率的线程添加更多的线程。为了说明这些影响，测试运行在不同的竞争概率和不同的线程数目下，都用的是可重入锁。附图使用了一个 &lt;em&gt;slowdown&lt;/em&gt; 度量标准：&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;3\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1662043242519.jpg\&#34; alt=\&#34;formula\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;这里，t 是总运行时间，b 是一个线程在没有竞争或同步的情况下的基线时间，n 是线程的数量，p 是处理器的数量，S 是共享访问的比例。计算结果是实际执行时间与理想执行时间（通常是无法达到的）的比率，理想执行时间是通过使用 Amdahl&#39;s 定律对顺序和并行任务的混合计算得到。理想的时间模型是在没有任何同步开销的情况下，没有线程因为与其他线程冲突而阻塞。即便如此，在竞争非常少的情况下，一些测试结果显示，与理想情况相比，有些测试结果表现出了很小的速度增长，大概是由于基线和测试之间的优化、流水线等方面有着轻微的差别。&lt;/p&gt;\n&lt;p&gt;图中用以 2 为底的对数为比例进行了缩放。例如，值为 1 表示实际时间是理想时间的两倍，4 表示慢 16 倍。使用对数就不需要依赖一个随意的基线时间（这里是计算随机数的时间），因此，基于不同底数的计算结果表现出的趋势应该是类似的。这些测试使用的竞争概率从 1/128（标识为 “0.008”）到 1，以 2 的幂为步长，线程的数量从 1 到 1024，以 2 的幂的一半为步长。&lt;/p&gt;\n&lt;p&gt;在单处理器上（1P 和 1U），性能会随着竞争的增加而降低，但通常不会随着线程数量的增加而降低。多处理器在竞争的情况下，通常会遇到更糟糕的性能下降。根据多处理器相关的图表显示，开始出现的峰值处虽然只有几个线程的竞争，但相对性能通常却最差。这反映出了一个性能的 &lt;em&gt;过渡区域&lt;/em&gt;，在这里闯入的线程和被唤醒的线程都准备获取锁，这会让它们频繁的迫使对方阻塞。在大部分时候，过渡区域后面会紧接着一个 &lt;em&gt;平滑区域&lt;/em&gt;，因为此时几乎没有空闲的锁，所以会与单处理器上的顺序执行模式差不多；在多处理器上会较早进入平滑区域。例如，请注意，在处理器数量较少的机器上，满竞争（标记为 “1.000”）表现出相对较差的速度下降。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;4\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1662043305229.jpg\&#34; alt=\&#34;slowndown-1\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;5\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1662043318498.jpg\&#34; alt=\&#34;slowndown-2\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;6\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1662043328452.jpg\&#34; alt=\&#34;slowndown-3\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;7\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1662043337590.jpg\&#34; alt=\&#34;slowndown-4\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;基于这些结果，进一步调整阻塞（&lt;code&gt;park/unpark&lt;/code&gt;）以减少上下文切换和相关的开销，这会给本框架带来小但显著的提升。此外，在多处理上为短时间持有的但高竞争的锁采用某种形式的适应性自旋，可以避免这里看到的一些波动，这对同步器类有很大好处。虽然在跨不同上下文时适应性自旋很难很好的工作，但可以使用本框架为遇到这类使用配置的特定应用构建一个自定义形式的锁。&lt;/p&gt;\n&lt;h2 id=\&#34;6-结论\&#34;&gt;6. 结论&lt;/h2&gt;\n&lt;p&gt;在撰写本文时，&lt;code&gt;j.u.c&lt;/code&gt;同步器框架还太新，无法在实践中进行使用。因此在 J2SE 1.5 最终发布之前，它不太可能被广泛使用，而且他的设计、API 实现以及性能肯定还有无法预料的后果。但是，此时，这个框架明显能胜任其基本目标，即为创建新的同步器提供一个高效的基础。&lt;/p&gt;\n&lt;h2 id=\&#34;7-致谢\&#34;&gt;7. 致谢&lt;/h2&gt;\n&lt;p&gt;Thanks to Dave Dice for countless ideas and advice during the development of this framework, to Mark Moir and Michael Scott for urging consideration of CLH queues, to David Holmes for critiquing early versions of the code and API, to Victor Luchangco and Bill Scherer for reviewing previous incarnations of the source code, and to the other members of the JSR166 Expert Group (Joe Bowbeer, Josh Bloch, Brian Goetz, David Holmes, and Tim Peierls) as well as Bill Pugh, for helping with design and specifications and commenting on drafts of this paper. Portions of this work were made possible by a DARPA PCES grant, NSF grant EIA-0080206 (for access to the 24way Sparc) and a Sun Collaborative Research Grant.&lt;/p&gt;\n&lt;h2 id=\&#34;8-引用\&#34;&gt;8. 引用&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;span id=\&#34;1\&#34;&gt;[1]&lt;/span&gt; Agesen, O., D. Detlefs, A. Garthwaite, R. Knippel, Y. S.Ramakrishna, and D. White. An Efficient Meta-lock for Implementing Ubiquitous Synchronization. ACM OOPSLA Proceedings, 1999.&lt;/li&gt;\n&lt;li&gt;&lt;span id=\&#34;2\&#34;&gt;[2]&lt;/span&gt; Andrews, G. Concurrent Programming. Wiley, 1991.&lt;/li&gt;\n&lt;li&gt;&lt;span id=\&#34;3\&#34;&gt;[3]&lt;/span&gt; Bacon, D. Thin Locks: Featherweight Synchronization for Java. ACM PLDI Proceedings, 1998.&lt;/li&gt;\n&lt;li&gt;&lt;span id=\&#34;4\&#34;&gt;[4]&lt;/span&gt; Buhr, P. M. Fortier, and M. Coffin. Monitor Classification,ACM Computing Surveys, March 1995.&lt;/li&gt;\n&lt;li&gt;&lt;span id=\&#34;5\&#34;&gt;[5]&lt;/span&gt; Craig, T. S. Building FIFO and priority-queueing spin locks from atomic swap. Technical Report TR 93-02-02,Department of Computer Science, University of Washington, Feb. 1993.&lt;/li&gt;\n&lt;li&gt;&lt;span id=\&#34;6\&#34;&gt;[6]&lt;/span&gt; Gamma, E., R. Helm, R. Johnson, and J. Vlissides. Design Patterns, Addison Wesley, 1996.&lt;/li&gt;\n&lt;li&gt;&lt;span id=\&#34;7\&#34;&gt;[7]&lt;/span&gt; Holmes, D. Synchronisation Rings, PhD Thesis, Macquarie University, 1999.&lt;/li&gt;\n&lt;li&gt;&lt;span id=\&#34;8\&#34;&gt;[8]&lt;/span&gt; Magnussen, P., A. Landin, and E. Hagersten. Queue locks on cache coherent multiprocessors. 8th Intl. Parallel Processing Symposium, Cancun, Mexico, Apr. 1994.&lt;/li&gt;\n&lt;li&gt;&lt;span id=\&#34;9\&#34;&gt;[9]&lt;/span&gt; Mellor-Crummey, J.M., and M. L. Scott. Algorithms for Scalable Synchronization on Shared-Memory Multiprocessors. ACM Trans. on Computer Systems,February 1991&lt;/li&gt;\n&lt;li&gt;&lt;span id=\&#34;10\&#34;&gt;[10]&lt;/span&gt; M. L. Scott and W N. Scherer III. Scalable Queue-Based Spin Locks with Timeout. 8th ACM Symp. on Principles and Practice of Parallel Programming, Snowbird, UT, June 2001.&lt;/li&gt;\n&lt;li&gt;&lt;span id=\&#34;11\&#34;&gt;[11]&lt;/span&gt; Sun Microsystems. Multithreading in the Solaris Operating Environment. White paper available at http://wwws.sun.com/software/solaris/whitepapers.html 2002.&lt;/li&gt;\n&lt;li&gt;&lt;span id=\&#34;12\&#34;&gt;[12]&lt;/span&gt; Zhang, H., S. Liang, and L. Bak. Monitor Conversion in a Multithreaded Computer System. United States Patent 6,691,304. 2004.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 id=\&#34;9-参考\&#34;&gt;9. 参考&lt;/h2&gt;\n&lt;p&gt;&lt;a href=\&#34;https://gee.cs.oswego.edu/dl/papers/aqs.pdf\&#34;&gt;《The java.util.concurrent Synchronizer Framework》&lt;/a&gt;&lt;/p&gt;\n&#34;,&#34;fileName&#34;:&#34;lesslessthe-javautilconcurrent-synchronizer-frameworkgreatergreater-yuan-wen-fan-yi&#34;,&#34;abstract&#34;:&#34;&lt;h2 id=\&#34;摘要\&#34;&gt;摘要&lt;/h2&gt;\n&lt;p&gt;在 J2SE1.5 的 &lt;code&gt;java.util.concurrent&lt;/code&gt;包（下面简称为 &lt;code&gt;j.u.c&lt;/code&gt; 包 ）中，大多数的同步器（例如锁、栅栏等。）都是使用基于 &lt;code&gt;AbstractQueuedSynchronizer&lt;/code&gt;类（下面简称为 &lt;code&gt;AQS&lt;/code&gt; 类），这个简单的小型框架构建的。这个框架提供了原子管理同步状态、线程的阻塞和解除阻塞、以及排队的通用机制。本文描述了该框架的基本原理、设计、实现、使用和性能。&lt;/p&gt;\n&#34;,&#34;title&#34;:&#34;《The java.util.concurrent Synchronizer Framework》原文翻译&#34;,&#34;tags&#34;:[{&#34;index&#34;:-1,&#34;name&#34;:&#34;AQS&#34;,&#34;slug&#34;:&#34;o7NFbw6wG&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://wenbozhangw.github.io/tag/o7NFbw6wG/&#34;}],&#34;date&#34;:&#34;2022-09-01 22:31:43&#34;,&#34;dateFormat&#34;:&#34;2022-09-01&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://wenbozhangw.github.io/post/lesslessthe-javautilconcurrent-synchronizer-frameworkgreatergreater-yuan-wen-fan-yi/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;41 min read&#34;,&#34;time&#34;:2448000,&#34;words&#34;:11146,&#34;minutes&#34;:41},&#34;description&#34;:&#34;摘要\n在 J2SE1.5 的 java.util.concurrent包（下面简称为 j.u.c 包 ）中，大多数的同步器（例如锁、栅栏等。）都是使用基于 AbstractQueuedSynchronizer类（下面简称为 AQS 类），这...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%91%98%E8%A6%81\&#34;&gt;摘要&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E7%B1%BB%E5%88%AB%E5%92%8C%E4%B8%BB%E9%A2%98%E6%8F%8F%E8%BF%B0%E7%AC%A6\&#34;&gt;类别和主题描述符&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%B8%80%E8%88%AC%E6%9C%AF%E8%AF%AD\&#34;&gt;一般术语&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%85%B3%E9%94%AE%E5%AD%97\&#34;&gt;关键字&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#1-%E4%BB%8B%E7%BB%8D\&#34;&gt;1. 介绍&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#2-%E9%9C%80%E6%B1%82\&#34;&gt;2 需求&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#21-%E5%8A%9F%E8%83%BD\&#34;&gt;2.1 功能&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#22-%E6%80%A7%E8%83%BD%E7%9B%AE%E6%A0%87\&#34;&gt;2.2 性能目标&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#3-%E8%AE%BE%E8%AE%A1%E5%92%8C%E5%AE%9E%E7%8E%B0\&#34;&gt;3. 设计和实现&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#31-%E5%90%8C%E6%AD%A5%E7%8A%B6%E6%80%81\&#34;&gt;3.1 同步状态&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#32-%E9%98%BB%E5%A1%9E\&#34;&gt;3.2 阻塞&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#33-%E9%98%9F%E5%88%97\&#34;&gt;3.3 队列&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#34-%E6%9D%A1%E4%BB%B6%E9%98%9F%E5%88%97\&#34;&gt;3.4 条件队列&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#4-%E7%94%A8%E4%BE%8B\&#34;&gt;4. 用例&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#41-%E5%85%AC%E5%B9%B3%E8%B0%83%E5%BA%A6%E7%9A%84%E6%8E%A7%E5%88%B6\&#34;&gt;4.1 公平调度的控制&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#42-%E5%90%8C%E6%AD%A5%E5%99%A8\&#34;&gt;4.2 同步器&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#5-%E6%80%A7%E8%83%BD\&#34;&gt;5. 性能&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#51-%E5%BC%80%E9%94%80\&#34;&gt;5.1 开销&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#52-%E5%90%9E%E5%90%90%E9%87%8F\&#34;&gt;5.2 吞吐量&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#6-%E7%BB%93%E8%AE%BA\&#34;&gt;6. 结论&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#7-%E8%87%B4%E8%B0%A2\&#34;&gt;7. 致谢&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#8-%E5%BC%95%E7%94%A8\&#34;&gt;8. 引用&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#9-%E5%8F%82%E8%80%83\&#34;&gt;9. 参考&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;p&gt;本章描述了本规范中用于定义程序词法和语法结构的上下文无关语法（context-free grammars）。&lt;/p&gt;\n&lt;!-- more --&gt;\n&lt;h2 id=\&#34;21-context-free-grammars\&#34;&gt;2.1 Context-Free Grammars&lt;/h2&gt;\n&lt;p&gt;一个上下文无关的语法由许多 &lt;em&gt;productions&lt;/em&gt; 组成。每一个 productions 都有一个称为 &lt;em&gt;nonterminal&lt;/em&gt; 的抽象符号在它 &lt;em&gt;left-hand side&lt;/em&gt;，一个或多个 nonterminal 和 &lt;em&gt;terminal&lt;/em&gt; 符号的序列在他的 &lt;em&gt;right-hand side&lt;/em&gt;。对于每种语法，终止符号都是从指定的 &lt;em&gt;alphabet&lt;/em&gt; 中抽取的。&lt;/p&gt;\n&lt;p&gt;从由单个可识别的非终结符（称为 &lt;em&gt;goal symbol&lt;/em&gt;）组成的句子开始，给定的与上下文无关的语法指定了一种语言，即，通过将序列中的任何非终止符重复替换为以非终止符为左边的 productions 的右手边而产生的可能的终止符序列集。&lt;/p&gt;\n&#34;,&#34;fileName&#34;:&#34;chapter-2-grammars&#34;,&#34;abstract&#34;:&#34;&lt;p&gt;本章描述了本规范中用于定义程序词法和语法结构的上下文无关语法（context-free grammars）。&lt;/p&gt;\n&#34;,&#34;title&#34;:&#34;Chapter 2. Grammars&#34;,&#34;tags&#34;:[],&#34;date&#34;:&#34;2022-08-11 16:52:42&#34;,&#34;dateFormat&#34;:&#34;2022-08-11&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://wenbozhangw.github.io/post/chapter-2-grammars/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;1 min read&#34;,&#34;time&#34;:44000,&#34;words&#34;:203,&#34;minutes&#34;:1},&#34;description&#34;:&#34;本章描述了本规范中用于定义程序词法和语法结构的上下文无关语法（context-free grammars）。\n\n2.1 Context-Free Grammars\n一个上下文无关的语法由许多 productions 组成。每一个 produ...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#21-context-free-grammars\&#34;&gt;2.1 Context-Free Grammars&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;p&gt;Java® 编程语言是一种通用的、并发的、基于类的、面向对象的语言。它被设计得足够简单，以至于许多程序员都能熟练使用该语言。Java 编程语言与 C 和 C++ 有关，但其组织方式却截然不同，它省略了 C 和 C++ 的许多方面，并包含了其他语言的一些思想。它是一种生产语言，而不是一种研究语言，因此，正如 C. A. R. Hoare 在他关于语言设计的经典论文中建议的那样，设计避免包含新的和未经测试的功能。&lt;/p&gt;\n&lt;!-- more --&gt;\n&lt;p&gt;Java 编程语言是强类型和静态类型的。该规范清楚地区分了编译时错误（可以且必须在编译时检测到）和运行时发生的错误、编译时通常包括将程序装换为与机器无关的字节码表示形式。运行时活动包括加载和链接执行程序所需的类、可选的机器底阿妈生成和程序的动态优化、以及实际的程序执行。&lt;/p&gt;\n&lt;p&gt;Java 编程语言是一种相对高级的语言，因为通过该语言无法获得机器表示的细节。它包括自动存储管理，通常使用垃圾收集器以避免显式释放的安全问题（如 C 的 &lt;code&gt;free&lt;/code&gt; 或 C++ 的 &lt;code&gt;delete&lt;/code&gt; ）。高性能的垃圾收集实现可以有有限的暂停，以支持系统编程和实施应用程序。该语言不包括任何不安全的结构，例如不进行索引检查的数组访问，因为这种不安全的结构将导致程序以未指定的方式运行。&lt;/p&gt;\n&lt;p&gt;Java 编程语言通常被编译成* Java 虚拟机规范 Java SE 8 版* 定义的字节码指令集和二进制格式。&lt;/p&gt;\n&lt;h2 id=\&#34;11-organization-of-the-specification\&#34;&gt;1.1 Organization of the Specification&lt;/h2&gt;\n&lt;p&gt;第 2 章描述了语法和用来表示语言的词汇语法和句法语法的符号。&lt;/p&gt;\n&lt;p&gt;第 3 章描述了基于 C 和 C++ 的 Java 编程语言的词法结构。该语言是用 Unicode 字符集编写的、它支持在只支持 ASCII 的系统上编写 Unicode 字符。&lt;/p&gt;\n&lt;p&gt;第 4 章描述了类型、值和变量、类型被细分为基本类型（primitive types）和引用类型（reference types）。&lt;/p&gt;\n&lt;p&gt;基本类型被定义为在所有机器和所有实现中是相同的，并且是各种大小的二进制补码整数、单精度和双精度 IEEE 754 标准浮点数、布尔类型和 Unicode 字符 char 类型。基本类型的值不共享状态。&lt;/p&gt;\n&lt;p&gt;引用类型是类（class）类型、接口（interface）类型和数组（array）类型。引用类型由动态创建的对象实现，这些对象可以是类或数组的实例。可以存在对每个对象的许多引用。所有对象（包括数组）都支持类对象的方法，类对象是类层次结构的（单一）根。预定义的字符串（&lt;code&gt;String&lt;/code&gt;）类支持 Unicode 字符串。存在用于在对象内部包装原始值的类。在许多情况下，包装和解包是由编译器自动执行的（在这种情况想，包装称为装箱（boxing），解包成为拆箱（unboxing））。类和接口声明可以是泛型的，也就是说，它们可以被其他引用类型参数化。然后可以用特定的类型参数来调用这样的声明。&lt;/p&gt;\n&lt;p&gt;变量是类型化的存储位置。一个原始类型的变量保存该原始类型的值。一个类类型的变量可以包含一个空引用或一个对象的引用，该对象的类型是该类类型或该类类型的任何子类。接口类型的变量可以包含一个空引用或对实现该接口的任何类的实例的引用。数组类型的变量可以包含空引用或对数组的引用。&lt;code&gt;Object&lt;/code&gt; 类类型的变量可以包含一个空引用或对任何对象的引用，无论是类实例还是数组。&lt;/p&gt;\n&lt;p&gt;第 5 章描述了转换和数字提升（numeric promotions）。转换会改变编译时类型，有时还会改变表达式的值。这些转换包括基本类型和引用类型之间的装箱和拆箱转换。数值提升用于将数值运算符的操作数转换为可执行运算的通用类型。语言上没有漏洞；在运行时检查引用类型的强制转换，以确保类型安全。&lt;/p&gt;\n&lt;p&gt;第 6 章描述了声明和命名，以及如何确定名字的含义。语言不要求在使用类型或其成员变量之前声明它们。声明顺序只对局部变量、局部类以及类或接口中字段的初始值设定项的顺序有意义。&lt;/p&gt;\n&lt;p&gt;Java 编程语言提供了对命名作用域的控制，并支持对包、类和接口成员的外部访问的限制。这对于大型项目中区分类型的用户和谁能扩展类型提供了很大的帮助。同时这里也给出了更加具有可读性程序的命名习惯。&lt;/p&gt;\n&lt;p&gt;第 7 章描述了程序的结构，程序的结构被组织成了各种包，这就像模块化概念中的各种模块。包的成员是类、接口和子包。每个包都是一个编译单元。每个编译单元包含类型声明的短名称和从其他包里导入的类型的短名称。包是以一个层次性命名空间进行命名的，因特网域名系统通常被用来组成唯一的包名。&lt;/p&gt;\n&lt;p&gt;第 8 章描述了类。类的成员包括类、接口、字段（变量）和方法。类方法的调用可以不使用对象的引用。实例变量是在作为类实例的对象中动态创建的。实例方法在类的实例上被调用；在方法执行期间实例就成为当前对象 this，以此支持面向对象的编程风格。&lt;/p&gt;\n&lt;p&gt;类支持单个实现继承，其中每个实现类派生于单个父类，最终都派生于类 &lt;code&gt;Object&lt;/code&gt;。类类型的遍历可以引用该类或该类的任何子类的实例，允许新类型以多种形式与现有方法一起使用。&lt;/p&gt;\n&lt;p&gt;类支持使用同步方法进行并发编程。方法声明了在执行过程中可能出现的检查异常，这允许编译时检查以确保异常情况得到处理。对象可以声明一个 &lt;code&gt;finalize&lt;/code&gt; 方法，该对象将在对象被垃圾收集器丢弃之前被调用，从而允许对象清理它们的状态。&lt;/p&gt;\n&lt;p&gt;为了简单起见，Java 语言没有将声明头文件（C 和 C++ 用头文件提前声明类名，函数名）和类的实现分开，也没有分开的类型和类层次结构。&lt;/p&gt;\n&lt;p&gt;一种特殊形式的类，枚举，支持小型值集的定义，以及以类型安全的方式对它们进行操作。与其他语言中的枚举不同，枚举是对象，可能有自己的方法。&lt;/p&gt;\n&lt;p&gt;第 9 章描述了接口类型，它声明了一组抽象方法、成员类型和常量。在其他方面不相关的类可以实现相同的接口类型。接口类型的变量可以包含对实现该接口的任何对象的引用。支持多接口继承。&lt;/p&gt;\n&lt;p&gt;注解类型属于特殊接口用来做注解声明。Java 程序语言中这种注解任何方面都不会影响程序的语义。然而，注解给各种工具提供了非常有用的输入。&lt;/p&gt;\n&lt;p&gt;第 10 章描述了数组。数组访问包括边界检查。数组是动态创建的对象，可以赋值给 &lt;code&gt;Object&lt;/code&gt; 类型的变量。Java 语言支持数组的数组，而不是多维数组。&lt;/p&gt;\n&lt;p&gt;第 11 章描述了异常，它是不可恢复的，并与语言的语义和并发机制完全集成。Java 语言提供了三种类型的异常：收件异常（checked exception）、运行时异常（run-time exception）、错误（error）。编译器只保证方法和构造器上具有受检异常声明的哪些异常会被合适的处理。者提供了编译使其检查异常处理器的存在，极大的保证了程序正常。大多数用户定义的异常都应该是受检异常。Java 虚拟机检测到的程序中的无效操作会导致运行时异常，例如 &lt;code&gt;NullPointerException&lt;/code&gt;。错误是由 Java 虚拟机检测到的错误导致的，比如 &lt;code&gt;OutOfMemoryError&lt;/code&gt;。大多数简单的程序不会去处理错误异常。&lt;/p&gt;\n&lt;p&gt;第 12 章描述了在程序执行过程中发生的活动。程序通常存储为已编译类和接口的二进制文件。这些二进制文件可以加载到 Java 虚拟机中，链接到其他类和接口，并进行初始化。&lt;/p&gt;\n&lt;p&gt;在初始化后，可以使用类方法和类变量。可以实例化一些类以创建类类型的新对象。作为类实例的对象还包含类的每个父类的一个实例，对象的创建涉及到这些父类实例的递归创建。&lt;/p&gt;\n&lt;p&gt;当一个对象不再被引用时，他可能会被垃圾收集器回收。如果对象声明了终结器（finalizer），则在对象被回收之前会执行终结器，以给对象最后一次机会来清理，否则那些资源无法被释放。当不再需要某个类时，可以将其卸载。&lt;/p&gt;\n&lt;p&gt;第 13 章描述了二进制兼容性，说明了对于那些还没有重新编译，但是引用了修改类的类的影响。这些考虑因素是开发人员感兴趣的，开发人员通常会通过 Internet 在一系列连续的版本中广泛分发这些类型的产品。好的程序开发环境会在类型改变时自动重新编译相关代码，所以大多数程序员不需要关心这些细节。&lt;/p&gt;\n&lt;p&gt;第 14 章描述了基于 C 和 C++ 的块（block）和语句（statements）。该语言没有 &lt;code&gt;goto&lt;/code&gt; 语句，但是有带标签的 &lt;code&gt;break&lt;/code&gt; 和 &lt;code&gt;continue&lt;/code&gt; 语句。与 C 不同，Java 编程语言要求在控制流语句中使用布尔（或布尔）表达式，并且不隐式地将类型转换为布尔（除了通过拆箱），希望在编译时捕捉更多的错误。&lt;code&gt;synchronized&lt;/code&gt; 语句提供基本的对象级监视器锁定。&lt;code&gt;try&lt;/code&gt; 语句可以包含 &lt;code&gt;catch&lt;/code&gt; 和 &lt;code&gt;finally&lt;/code&gt; 子句，以防止非本地控制转移（内部 Exception 会直接打断当前代码执行的流程）。&lt;/p&gt;\n&lt;p&gt;第 15 章描述了表达式。为了增加确定性和可移植性，这个文档明确了表达式求值的（明显的）顺序。重载的方法和构造函数会在编译时被解析到合适的而且最具体的方法和构造函数上。&lt;/p&gt;\n&lt;p&gt;第 16 章描述了语言确保局部变量在使用前被明确设置的精确方式。虽然所有其他变量都自动初始化为默认值，但 Java 编程语言不会自动初始化局部变量，以避免掩盖程序错误。&lt;/p&gt;\n&lt;p&gt;第 17 章描述了线程和锁的语义，这些都是基于源自 Mesa 程序语言提出的 monitor-based 并发性。Java 编程语言为支持高性能实现的共享内存多处理器指定了内存模型。&lt;/p&gt;\n&lt;p&gt;第 18 章描述了各种类型推断算法，用于测试泛型方法的实用性和推断泛型方法调用中的类型。&lt;/p&gt;\n&lt;p&gt;第 19 张介绍了 Java 语言的语法。&lt;/p&gt;\n&lt;h2 id=\&#34;12-example-programs\&#34;&gt;1.2 Example Programs&lt;/h2&gt;\n&lt;p&gt;正文中给出的大多数示例程序都可以执行，并且在形式上类似于：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;class Test {\n    public static void main(String[] args) {\n        for (int i = 0; i &amp;lt; args.length; i++)\n            System.out.print(i == 0 ? args[i] : &amp;quot; &amp;quot; + args[i]);\n        System.out.println();\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;在安装了 Oracle JDK 的机器上，可以通过给出以下命令来编译和执行这个存储在文件 &lt;code&gt;Test.java&lt;/code&gt; 中的类：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;javac Test.java\njava Test Hello, world.\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;产生输出：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;Hello, world.\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h2 id=\&#34;13-notation\&#34;&gt;1.3 Notation&lt;/h2&gt;\n&lt;p&gt;在本规范中，我们只的是来自 Java SE 平台 API 的类和接口。每当我们使用单个标识符 &lt;code&gt;N&lt;/code&gt; 引用一个类或接口（除了在实例中声明的那些）时，意图引用的是 &lt;code&gt;java.lang&lt;/code&gt; 包中名为 &lt;code&gt;N&lt;/code&gt; 的类或接口。对于 &lt;code&gt;java.lang&lt;/code&gt; 之外的包中的类或接口，我们使用规范名称（canonical name，&lt;a href=\&#34;https://docs.oracle.com/javase/specs/jls/se8/html/jls-6.html#jls-6.7\&#34;&gt;§6.7&lt;/a&gt; ）。&lt;/p&gt;\n&lt;p&gt;旨在阐明规范的非规范性信息以较小的缩进文本给出。&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;这是非规范性信息。它提供直觉、基本原理、建议、例子等。&lt;/em&gt;&lt;/p&gt;\n&lt;p&gt;Java 编程语言的类型系统有时依赖于&lt;em&gt;替换&lt;/em&gt;的概念。符号 [F&lt;sub&gt;1&lt;/sub&gt;:=T&lt;sub&gt;1&lt;/sub&gt;, ..., F&lt;sub&gt;n&lt;/sub&gt;:=T&lt;sub&gt;n&lt;/sub&gt;] 表示 1 ≤ i ≤ n 是 T&lt;sub&gt;i&lt;/sub&gt; 对 F&lt;sub&gt;i&lt;/sub&gt; 的替换。&lt;/p&gt;\n&lt;h2 id=\&#34;14-relationship-to-predefined-classes-and-interfaces\&#34;&gt;1.4 Relationship to Predefined Classes and Interfaces&lt;/h2&gt;\n&lt;p&gt;如上所述，该规范经常引用 Java SE 平台 API 的类。特别是，有些类与 Java 编程语言有着特殊的关系。例如 &lt;code&gt;Object&lt;/code&gt;、&lt;code&gt;Class&lt;/code&gt;、&lt;code&gt;ClassLoader&lt;/code&gt;、&lt;code&gt;String&lt;/code&gt;、&lt;code&gt;Thread&lt;/code&gt; 等类，以及 &lt;code&gt;java.lang.reflect&lt;/code&gt; 包中的类和接口等。改规范约束了这些类和接口的行为，但没有为它们提供完整的规范。读者可以参考 Java SE 平台 API 文档。&lt;/p&gt;\n&lt;p&gt;因此，本规范没有详细描述反射。许多语言结构在核心反射 API（&lt;code&gt;java.lang.reflect&lt;/code&gt;）和语言模型 API（&lt;code&gt;javax.lang.model&lt;/code&gt;）中都有类似的内容，但这里一般不讨论这些内容。例如，当我们列出创建一个对象的方法时，我们通常不包括核心反射 API 完成这个任务的方法。读者应该知道这些额外的机制，即使它们在正文中没有提到。&lt;/p&gt;\n&lt;h2 id=\&#34;15-feedback\&#34;&gt;1.5 Feedback&lt;/h2&gt;\n&lt;p&gt;欢迎读者向 jls-jvms-spec-comments@openjdk.java.net 报告 Java 语言规范中的技术错误和歧义。&lt;/p&gt;\n&lt;p&gt;有关 &lt;code&gt;javac&lt;/code&gt; （Java 编程语言的参考编译器） 的行为，特别是它是否符合本规范的问题，可以发送给 compiler-dev@openjdk.java.net。&lt;/p&gt;\n&lt;h2 id=\&#34;16-references\&#34;&gt;1.6 References&lt;/h2&gt;\n&lt;h3 id=\&#34;bibliography\&#34;&gt;Bibliography&lt;/h3&gt;\n&lt;p&gt;Apple Computer. &lt;em&gt;Dylan Reference Manual.&lt;/em&gt; Apple Computer Inc., Cupertino, California. September 29, 1995.&lt;/p&gt;\n&lt;p&gt;Bobrow, Daniel G., Linda G. DeMichiel, Richard P. Gabriel, Sonya E. Keene, Gregor Kiczales, and David A. Moon.* Common Lisp Object System Specification*, X3J13 Document 88-002R, June 1988; appears as Chapter 28 of Steele, Guy. &lt;em&gt;Common Lisp: The Language&lt;/em&gt;, 2nd ed. Digital Press, 1990, ISBN 1-55558-041-6, 770-864.&lt;/p&gt;\n&lt;p&gt;Ellis, Margaret A., and Bjarne Stroustrup. &lt;em&gt;The Annotated C++ Reference Manual&lt;/em&gt;. Addison-Wesley, Reading, Massachusetts, 1990, reprinted with corrections October 1992, ISBN 0-201-51459-1.&lt;/p&gt;\n&lt;p&gt;Goldberg, Adele and Robson, David. &lt;em&gt;Smalltalk-80: The Language&lt;/em&gt;. Addison-Wesley, Reading, Massachusetts, 1989, ISBN 0-201-13688-0.&lt;/p&gt;\n&lt;p&gt;Harbison, Samuel. &lt;em&gt;Modula-3&lt;/em&gt;. Prentice Hall, Englewood Cliffs, New Jersey, 1992, ISBN 0-13-596396.&lt;/p&gt;\n&lt;p&gt;Hoare, C. A. R. &lt;em&gt;Hints on Programming Language Design&lt;/em&gt;. Stanford University Computer Science Department Technical Report No. CS-73-403, December 1973. Reprinted in SIGACT/SIGPLAN Symposium on Principles of Programming Languages. Association for Computing Machinery, New York, October 1973.&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;IEEE Standard for Binary Floating-Point Arithmetic&lt;/em&gt;. ANSI/IEEE Std. 754-1985. Available from Global Engineering Documents, 15 Inverness Way East, Englewood, Colorado 80112-5704 USA; 800-854-7179.&lt;/p&gt;\n&lt;p&gt;Kernighan, Brian W., and Dennis M. Ritchie. &lt;em&gt;The C Programming Language&lt;/em&gt;, 2nd ed. Prentice Hall, Englewood Cliffs, New Jersey, 1988, ISBN 0-13-110362-8.&lt;/p&gt;\n&lt;p&gt;Madsen, Ole Lehrmann, Birger Møller-Pedersen, and Kristen Nygaard. &lt;em&gt;Object-Oriented Programming in the Beta Programming Language&lt;/em&gt;. Addison-Wesley, Reading, Massachusetts, 1993, ISBN 0-201-62430-3.&lt;/p&gt;\n&lt;p&gt;Mitchell, James G., William Maybury, and Richard Sweet. &lt;em&gt;The Mesa Programming Language, Version 5.0&lt;/em&gt;. Xerox PARC, Palo Alto, California, CSL 79-3, April 1979.&lt;/p&gt;\n&lt;p&gt;Stroustrup, Bjarne. &lt;em&gt;The C++ Progamming Language&lt;/em&gt;, 2nd ed. Addison-Wesley, Reading, Massachusetts, 1991, reprinted with corrections January 1994, ISBN 0-201-53992-6.&lt;/p&gt;\n&lt;p&gt;Unicode Consortium, The. &lt;em&gt;The Unicode Standard, Version 6.2.0&lt;/em&gt;. Mountain View, California, 2012, ISBN 978-1-936213-07-8.&lt;/p&gt;\n&#34;,&#34;fileName&#34;:&#34;chapter-1-interduction&#34;,&#34;abstract&#34;:&#34;&lt;p&gt;Java® 编程语言是一种通用的、并发的、基于类的、面向对象的语言。它被设计得足够简单，以至于许多程序员都能熟练使用该语言。Java 编程语言与 C 和 C++ 有关，但其组织方式却截然不同，它省略了 C 和 C++ 的许多方面，并包含了其他语言的一些思想。它是一种生产语言，而不是一种研究语言，因此，正如 C. A. R. Hoare 在他关于语言设计的经典论文中建议的那样，设计避免包含新的和未经测试的功能。&lt;/p&gt;\n&#34;,&#34;title&#34;:&#34;Chapter 1. Interduction&#34;,&#34;tags&#34;:[{&#34;index&#34;:-1,&#34;name&#34;:&#34;Java SE 8 Language Specification&#34;,&#34;slug&#34;:&#34;nB3cU2iF3&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://wenbozhangw.github.io/tag/nB3cU2iF3/&#34;}],&#34;date&#34;:&#34;2022-07-12 17:41:16&#34;,&#34;dateFormat&#34;:&#34;2022-07-12&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://wenbozhangw.github.io/post/chapter-1-interduction/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;15 min read&#34;,&#34;time&#34;:883000,&#34;words&#34;:3932,&#34;minutes&#34;:15},&#34;description&#34;:&#34;Java® 编程语言是一种通用的、并发的、基于类的、面向对象的语言。它被设计得足够简单，以至于许多程序员都能熟练使用该语言。Java 编程语言与 C 和 C++ 有关，但其组织方式却截然不同，它省略了 C 和 C++ 的许多方面，并包含了其...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#11-organization-of-the-specification\&#34;&gt;1.1 Organization of the Specification&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#12-example-programs\&#34;&gt;1.2 Example Programs&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#13-notation\&#34;&gt;1.3 Notation&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#14-relationship-to-predefined-classes-and-interfaces\&#34;&gt;1.4 Relationship to Predefined Classes and Interfaces&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#15-feedback\&#34;&gt;1.5 Feedback&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#16-references\&#34;&gt;1.6 References&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#bibliography\&#34;&gt;Bibliography&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;p&gt;&lt;strong&gt;Alex Buckley&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;1996 年，James Gosling、Bill Joy 和 Guy Steele 为 &lt;em&gt;Java® 语言规范&lt;/em&gt; 的第一版写了：&lt;br&gt;\n“我们相信 Java 编程语言是一种成熟的语言，可以广泛使用。尽管如此，我们预计未来几年该语言会发生一些演变。我们打算以与现在应用程序完全兼容的方式管理这种演变。”&lt;/p&gt;\n&lt;p&gt;Java SE 8 代表了 Java 语言历史上最大的一次金华。相对较少的特性 —— lambda 表达式、方法引用和函数式接口 —— 结合起来提供了一个融合面向对象和函数式风格的编程模型。在 Brian Goetz 的领导下，这种融合以一种鼓励最佳实践的方式完成 —— 不变性、无状态、组合性 —— 同时保留“Java的感觉” —— 可读性、简单性、通用性。&lt;/p&gt;\n&lt;p&gt;至关重要的是，Java SE 平台的库与 Java 语言共同发展。这意味着使用 lambda 表达式和方法引用来表示行为 —— 例如，应用于列表中每个元素的操作 —— 是 &amp;quot;开箱即用&amp;quot; 的高效和高性能。以类似的方式，Java 虚拟机与 Java 语言共同进化，以确保在独立编译的约束条件下， default 方法在编译时和运行时尽可能一致地支持库的发展。&lt;/p&gt;\n&lt;p&gt;自 20 世纪 90 年代以来，向 Java 语言添加一级函数的计划就已经出现了。2007 年左右的 BGGA 和 CICE 提案为这个话题带来了新的活力，而 2009 年左右在 OpenJDK 中创建的项目 Lambda 吸引了前所未有的兴趣。Java SE 7 中向 JVM 添加的方法句柄为新的实现技术打开了大门，同时保留了“一次编写，随处运行”的原则。随着时间的过去，语言的变化由 JSR 335 —— Java编程语言的Lambda表达式 —— 监督，其专家组包括 Joshua Bloch、Kevin Bourrillion、Andrey Breslav、Rémi Forax、Dan Heidinga、Doug Lea、Bob Lee、David Lloyd、Sam Pullara、Srikanth Sankaran 和 Vladimir Zakharov。&lt;/p&gt;\n&lt;p&gt;编程语言设计通常涉及处理完全不为语言用户所知的复杂程度。（因此，它经常被比作冰山：它 90% 的部分是看不见的。）在 JSR 335 中，最大的复杂性隐藏在隐式类型 lambda 表达式与重载解析的交互中。在这一领域和许多其他领域，Oracle 的 Dan Smith 做了一项出色的工作，彻底地指定了所需的行为。他的话可以在整个规范中找到，包括一个关于类型推断的全新章节。&lt;/p&gt;\n&lt;p&gt;Java SE 8 中的另一个举措是增强注解的实用性，这是 Java 语言最流行的特性之一。首先，Java 语法已经扩展到允许在许多语言结构中对类型进行注解，从而形成了新的静态分析工具（如 Checker 框架）的基础。这个特性由 JSR 308 “Java类型注解” 指定，由 Michael Ernst 和我自己、Doug Lea 和 Srikanth Sankaran 组成的专家组负责。该规范中涉及的变化是广泛的，Michael Ernst 和 Werner Dietl 多年来的不懈努力得到了热烈的认可。其次，注解可以在语言构造上“重复”，这对用注解类型建模特定领域配置的 api 有很大的好处。Java EE 的 Michael Keith 和 Bill Shannon 发起并指导了这个特性。&lt;/p&gt;\n&lt;p&gt;Oracle Java 平台组的许多同事已经为该规范提供了宝贵的支持：Leonid Arbouzov, Mandy Chung, Joe Darcy, Robert Field, Joel Borggrén-Franck, Sonali Goel, Jon Gibbons, Jeannette Hung, Stuart Marks, Eric McCorkle, Matherey Nunez, Mark Reinhold, Vicente Romero, John Rose, Georges Saab, Steve Sides, Bernard Traversat和Michel Trudeau。&lt;/p&gt;\n&lt;p&gt;也许最应该感谢的是编译器工程师，他们把规范变成了真正的软件。Oracle 的 Maurizio Cimadamore 从最早开始就英勇地致力于 lambda 表达式的设计和在 javac 中的实现。Eclipse 中对 Java SE 8 特性的支持由 Jayaprakash Arthanareeswaran、Shankha Banerjee、Anirban Chakraborty、Andrew Clement、Stephan Herrmann、Markus Keller、Jesper Møller、Manoj Palat、Srikanth Sankaran 和 Olivier Thomann 贡献；Anna Kozlova, Alexey Kudravtsev 和 Roman Shevchenko 合著的 IntelliJ 。他们值得整个 Java 社区的感谢。&lt;/p&gt;\n&lt;p&gt;Java SE 8 是 Java 语言的复兴。虽然有些人在寻找“下一个伟大的语言”，但我们相信，用 Java 编程比以往任何时候都更令人兴奋和高效。我们希望它继续适合你。&lt;/p&gt;\n&#34;,&#34;fileName&#34;:&#34;preface-to-the-java-se-8-edition&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;Preface to the Java SE 8 Edition&#34;,&#34;tags&#34;:[{&#34;index&#34;:-1,&#34;name&#34;:&#34;Java SE 8 Language Specification&#34;,&#34;slug&#34;:&#34;nB3cU2iF3&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://wenbozhangw.github.io/tag/nB3cU2iF3/&#34;}],&#34;date&#34;:&#34;2022-07-12 17:11:16&#34;,&#34;dateFormat&#34;:&#34;2022-07-12&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://wenbozhangw.github.io/post/preface-to-the-java-se-8-edition/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;5 min read&#34;,&#34;time&#34;:249000,&#34;words&#34;:1088,&#34;minutes&#34;:5},&#34;description&#34;:&#34;Alex Buckley\n1996 年，James Gosling、Bill Joy 和 Guy Steele 为 Java® 语言规范 的第一版写了：\n“我们相信 Java 编程语言是一种成熟的语言，可以广泛使用。尽管如此，我们预计未来几...&#34;,&#34;toc&#34;:&#34;&#34;},{&#34;content&#34;:&#34;&lt;p&gt;在中银消金三方服务平台，数据源配置中可以配置数据源调用的&lt;strong&gt;超时时间&lt;/strong&gt;，代码中使用这个用户配置的&lt;strong&gt;超时时间&lt;/strong&gt;作为 &lt;code&gt;connectionRequestTimeout&lt;/code&gt;、&lt;code&gt;connectionTimeout&lt;/code&gt; 和 &lt;code&gt;socketTimeout&lt;/code&gt; 参数。在数据源调用明细中，明显可以看出数据源的调用时长有远大于配置的&lt;strong&gt;超时时间&lt;/strong&gt;，客户提出不符合预期，要求数据源的调用时间在超过配置的&lt;strong&gt;超时时间&lt;/strong&gt;后能够终止。&lt;/p&gt;\n&lt;!-- more --&gt;\n&lt;h2 id=\&#34;httpclient-超时参数\&#34;&gt;httpclient 超时参数&lt;/h2&gt;\n&lt;p&gt;上面提到，代码中使用配置的超时时间作为 httpclient 的 &lt;code&gt;connectionRequestTimeout&lt;/code&gt;、&lt;code&gt;connectionTimeout&lt;/code&gt; 和 &lt;code&gt;socketTimeout&lt;/code&gt; 参数，下面简单介绍一下这三个参数的含义。&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;code&gt;connectionRequestTimeout&lt;/code&gt;：指从连接池获取连接的超时时间（当请求并发数量大于连接池中的连接数量时，则获取不到连接的请求会被放入 pending 队列等待，如果超过设定的时间，则抛出超时异常）。&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;connectionTimeout&lt;/code&gt;：指客户端和服务器建立连接的超时时间。（当客户端和服务器在建立链接时，如果在指定时间内无法成功建立链接，则抛出 &lt;code&gt;ConnectionTimeoutException&lt;/code&gt;）。&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;socketTimeout&lt;/code&gt;：指客户端从服务器读取数据的超时时间，即客户端和服务器 socket 通信的超时时间，其实这个时间是客户端两次读取数据的最长时间，如果客户端在网络抖动的情况下，每次返回部分数据，两次数据包的时间在设定时间之内，也是不会超时的。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 id=\&#34;问题背景\&#34;&gt;问题背景&lt;/h2&gt;\n&lt;p&gt;为了保证计时的准确性，我们采用异步提交线程池，用 &lt;code&gt;Future.get(timeout)&lt;/code&gt; 的方式保证任务可以在超过设定时间后，计时的准确性，大致代码如下：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;public class Main {\n\n    private static final Logger logger = LoggerFactory.getLogger(Main.class);\n\n    private static final ThreadPoolExecutor executor = new ThreadPoolExecutor(10, 10, 60,\n            java.util.concurrent.TimeUnit.SECONDS, new java.util.concurrent.LinkedBlockingQueue&amp;lt;&amp;gt;(10), new ThreadPoolExecutor.CallerRunsPolicy());\n\n    public static void main(String[] args) throws IOException, InterruptedException {\n\n        for (int i = 0; i &amp;lt; 10; i++) {\n            // 请求一个阻塞接口，不会返回数据，必定超时\n            HttpGet httpGet = new HttpGet(&amp;quot;*****&amp;quot;);\n            CloseableHttpResponse response = null;\n            Future&amp;lt;CloseableHttpResponse&amp;gt; future = null;\n            try {\n                future = executor.submit(() -&amp;gt; {\n                    try {\n                        return HttpClientUtil.execute(httpGet);\n                    } catch (Exception e) {\n                        logger.error(&amp;quot;&amp;quot;, e);\n                        return null;\n                    }\n                });\n                response = future.get(5, TimeUnit.SECONDS);\n                System.out.println(&amp;quot;response = &amp;quot; + response);\n            } catch (Exception e) {\n                if (e instanceof TimeoutException &amp;amp;&amp;amp; future != null) {\n                    logger.info(Thread.currentThread().getName() + &amp;quot; start cancel future&amp;quot;);\n                    logger.error(&amp;quot;&amp;quot;, e);\n                }\n            } finally {\n                httpGet.abort();\n                httpGet.releaseConnection();\n                if (null != response) {\n                    EntityUtils.consume(response.getEntity());\n                }\n            }\n        }\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;在功能上线的两周后，现场反馈说有大量超时，导致大量调用返回超时异常，出现异常&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;org.apache.http.conn.ConnectionPoolTimeoutException: Timeout waiting for connection from pool\n        at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.leaseConnection(PoolingHttpClientConnectionManager.java:313)\n        at org.apache.http.impl.conn.PoolingHttpClientConnectionManager$1.get(PoolingHttpClientConnectionManager.java:279)\n        at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:191)\n        at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:185)\n        at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)\n        at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:110)\n        at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)\n        at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)\n        at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108)\n        at cn.tongdun.freyr.http.SimpleGetRequestExecutor.lambda$execute$0(SimpleGetRequestExecutor.java:56)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n        at java.lang.Thread.run(Thread.java:748)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;出现大量异常后，服务就无法使用了，即任何接口的调用都是超时状态。此时通过 debug 发现，即使没有调用，连接也依旧处于 &lt;code&gt;lease&lt;/code&gt; 状态。&lt;/p&gt;\n&lt;h3 id=\&#34;问题排查\&#34;&gt;问题排查&lt;/h3&gt;\n&lt;p&gt;首先，出现 &lt;code&gt;Timeout waiting for connection from pool&lt;/code&gt; 是由于 httpclient 在从连接池获取连接时，在 &lt;code&gt;connectionRequectTimeout&lt;/code&gt; 时间内没有获取到连接，而抛出的异常信息，从连接池获取连接的流程如下。&lt;/p&gt;\n&lt;h4 id=\&#34;httpclient-从连接池获取连接\&#34;&gt;httpclient 从连接池获取连接&lt;/h4&gt;\n&lt;p&gt;首先，根据请求的路由和 token 构建 &lt;code&gt;ConnectionRequest&lt;/code&gt; 对象，此对象保存了获取从连接池获取连接的 &lt;code&gt;get&lt;/code&gt; 方法，代码如下：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;@Override\n    public CloseableHttpResponse execute(\n            final HttpRoute route,\n            final HttpRequestWrapper request,\n            final HttpClientContext context,\n            final HttpExecutionAware execAware) throws IOException, HttpException {\n        // ......\n        Object userToken = context.getUserToken();\n\n        final ConnectionRequest connRequest = connManager.requestConnection(route, userToken);\n        if (execAware != null) {\n            if (execAware.isAborted()) {\n                connRequest.cancel();\n                throw new RequestAbortedException(&amp;quot;Request aborted&amp;quot;);\n            } else {\n                execAware.setCancellable(connRequest);\n            }\n        }\n\n        // .....\n}        \n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;我们可以看到，此时使用的超时时间就是我们传入配置的 &lt;code&gt;connectionRequestTimeout&lt;/code&gt;，下面我们看下 &lt;code&gt;ConnectionRequest&lt;/code&gt; 对象的构建。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;    @Override\n    public ConnectionRequest requestConnection(\n            final HttpRoute route,\n            final Object state) {\n        Args.notNull(route, &amp;quot;HTTP route&amp;quot;);\n        if (this.log.isDebugEnabled()) {\n            this.log.debug(&amp;quot;Connection request: &amp;quot; + format(route, state) + formatStats(route));\n        }\n        final Future&amp;lt;CPoolEntry&amp;gt; future = this.pool.lease(route, state, null);\n        return new ConnectionRequest() {\n\n            @Override\n            public boolean cancel() {\n                return future.cancel(true);\n            }\n\n            @Override\n            public HttpClientConnection get(\n                    final long timeout,\n                    final TimeUnit tunit) throws InterruptedException, ExecutionException, ConnectionPoolTimeoutException {\n                final HttpClientConnection conn = leaseConnection(future, timeout, tunit);\n                if (conn.isOpen()) {\n                    final HttpHost host;\n                    if (route.getProxyHost() != null) {\n                        host = route.getProxyHost();\n                    } else {\n                        host = route.getTargetHost();\n                    }\n                    final SocketConfig socketConfig = resolveSocketConfig(host);\n                    conn.setSocketTimeout(socketConfig.getSoTimeout());\n                }\n                return conn;\n            }\n\n        };\n\n    }\n\n    protected HttpClientConnection leaseConnection(\n            final Future&amp;lt;CPoolEntry&amp;gt; future,\n            final long timeout,\n            final TimeUnit tunit) throws InterruptedException, ExecutionException, ConnectionPoolTimeoutException {\n        final CPoolEntry entry;\n        try {\n            entry = future.get(timeout, tunit);\n            if (entry == null || future.isCancelled()) {\n                throw new InterruptedException();\n            }\n            Asserts.check(entry.getConnection() != null, &amp;quot;Pool entry with no connection&amp;quot;);\n            if (this.log.isDebugEnabled()) {\n                this.log.debug(&amp;quot;Connection leased: &amp;quot; + format(entry) + formatStats(entry.getRoute()));\n            }\n            return CPoolProxy.newProxy(entry);\n        } catch (final TimeoutException ex) {\n            throw new ConnectionPoolTimeoutException(&amp;quot;Timeout waiting for connection from pool&amp;quot;);\n        }\n    }\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;我们可以看到，代码中捕获了 &lt;code&gt;TimeoutException&lt;/code&gt;，并重新构建 &lt;code&gt;ConnectionPoolTimeoutException&lt;/code&gt;，也就是说，&lt;code&gt;future.get&lt;/code&gt; 会在超时的时候抛出 &lt;code&gt;TimeoutException&lt;/code&gt;，然后被外层的 &lt;code&gt;catch&lt;/code&gt; 捕获，下面我们看 &lt;code&gt;final Future&amp;lt;CPoolEntry&amp;gt; future = this.pool.lease(route, state, null);&lt;/code&gt; 中的 &lt;code&gt;Future&lt;/code&gt; 是如何实现的：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;    /**\n     * {@inheritDoc}\n     * &amp;lt;p&amp;gt;\n     * Please note that this class does not maintain its own pool of execution\n     * {@link Thread}s. Therefore, one &amp;lt;b&amp;gt;must&amp;lt;/b&amp;gt; call {@link Future#get()}\n     * or {@link Future#get(long, TimeUnit)} method on the {@link Future}\n     * returned by this method in order for the lease operation to complete.\n     */\n    @Override\n    public Future&amp;lt;E&amp;gt; lease(final T route, final Object state, final FutureCallback&amp;lt;E&amp;gt; callback) {\n        Args.notNull(route, &amp;quot;Route&amp;quot;);\n        Asserts.check(!this.isShutDown, &amp;quot;Connection pool shut down&amp;quot;);\n\n        return new Future&amp;lt;E&amp;gt;() {\n\n            private final AtomicBoolean cancelled = new AtomicBoolean(false);\n            private final AtomicBoolean done = new AtomicBoolean(false);\n            private final AtomicReference&amp;lt;E&amp;gt; entryRef = new AtomicReference&amp;lt;E&amp;gt;(null);\n\n            @Override\n            public boolean cancel(final boolean mayInterruptIfRunning) {\n                if (cancelled.compareAndSet(false, true)) {\n                    done.set(true);\n                    lock.lock();\n                    try {\n                        condition.signalAll();\n                    } finally {\n                        lock.unlock();\n                    }\n                    if (callback != null) {\n                        callback.cancelled();\n                    }\n                    return true;\n                } else {\n                    return false;\n                }\n            }\n\n            @Override\n            public boolean isCancelled() {\n                return cancelled.get();\n            }\n\n            @Override\n            public boolean isDone() {\n                return done.get();\n            }\n\n            @Override\n            public E get() throws InterruptedException, ExecutionException {\n                try {\n                    return get(0L, TimeUnit.MILLISECONDS);\n                } catch (final TimeoutException ex) {\n                    throw new ExecutionException(ex);\n                }\n            }\n\n            @Override\n            public E get(final long timeout, final TimeUnit tunit) throws InterruptedException, ExecutionException, TimeoutException {\n                final E entry = entryRef.get();\n                if (entry != null) {\n                    return entry;\n                }\n                synchronized (this) {\n                    try {\n                        for (;;) {\n                            final E leasedEntry = getPoolEntryBlocking(route, state, timeout, tunit, this);\n                            if (validateAfterInactivity &amp;gt; 0)  {\n                                if (leasedEntry.getUpdated() + validateAfterInactivity &amp;lt;= System.currentTimeMillis()) {\n                                    if (!validate(leasedEntry)) {\n                                        leasedEntry.close();\n                                        release(leasedEntry, false);\n                                        continue;\n                                    }\n                                }\n                            }\n                            entryRef.set(leasedEntry);\n                            done.set(true);\n                            onLease(leasedEntry);\n                            if (callback != null) {\n                                callback.completed(leasedEntry);\n                            }\n                            return leasedEntry;\n                        }\n                    } catch (final IOException ex) {\n                        done.set(true);\n                        if (callback != null) {\n                            callback.failed(ex);\n                        }\n                        throw new ExecutionException(ex);\n                    }\n                }\n            }\n\n        };\n    }\n\n private E getPoolEntryBlocking(\n            final T route, final Object state,\n            final long timeout, final TimeUnit tunit,\n            final Future&amp;lt;E&amp;gt; future) throws IOException, InterruptedException, TimeoutException {\n\n        Date deadline = null;\n        if (timeout &amp;gt; 0) {\n            deadline = new Date (System.currentTimeMillis() + tunit.toMillis(timeout));\n        }\n        this.lock.lock();\n        try {\n            final RouteSpecificPool&amp;lt;T, C, E&amp;gt; pool = getPool(route);\n            E entry;\n            for (;;) {\n                Asserts.check(!this.isShutDown, &amp;quot;Connection pool shut down&amp;quot;);\n                for (;;) {\n                    entry = pool.getFree(state);\n                    if (entry == null) {\n                        break;\n                    }\n                    if (entry.isExpired(System.currentTimeMillis())) {\n                        entry.close();\n                    }\n                    if (entry.isClosed()) {\n                        this.available.remove(entry);\n                        pool.free(entry, false);\n                    } else {\n                        break;\n                    }\n                }\n                if (entry != null) {\n                    this.available.remove(entry);\n                    this.leased.add(entry);\n                    onReuse(entry);\n                    return entry;\n                }\n\n                // New connection is needed\n                final int maxPerRoute = getMax(route);\n                // Shrink the pool prior to allocating a new connection\n                final int excess = Math.max(0, pool.getAllocatedCount() + 1 - maxPerRoute);\n                if (excess &amp;gt; 0) {\n                    for (int i = 0; i &amp;lt; excess; i++) {\n                        final E lastUsed = pool.getLastUsed();\n                        if (lastUsed == null) {\n                            break;\n                        }\n                        lastUsed.close();\n                        this.available.remove(lastUsed);\n                        pool.remove(lastUsed);\n                    }\n                }\n\n                if (pool.getAllocatedCount() &amp;lt; maxPerRoute) {\n                    final int totalUsed = this.leased.size();\n                    final int freeCapacity = Math.max(this.maxTotal - totalUsed, 0);\n                    if (freeCapacity &amp;gt; 0) {\n                        final int totalAvailable = this.available.size();\n                        if (totalAvailable &amp;gt; freeCapacity - 1) {\n                            if (!this.available.isEmpty()) {\n                                final E lastUsed = this.available.removeLast();\n                                lastUsed.close();\n                                final RouteSpecificPool&amp;lt;T, C, E&amp;gt; otherpool = getPool(lastUsed.getRoute());\n                                otherpool.remove(lastUsed);\n                            }\n                        }\n                        final C conn = this.connFactory.create(route);\n                        entry = pool.add(conn);\n                        this.leased.add(entry);\n                        return entry;\n                    }\n                }\n\n                boolean success = false;\n                try {\n                    if (future.isCancelled()) {\n                        throw new InterruptedException(&amp;quot;Operation interrupted&amp;quot;);\n                    }\n                    pool.queue(future);\n                    this.pending.add(future);\n                    if (deadline != null) {\n                        success = this.condition.awaitUntil(deadline);\n                    } else {\n                        this.condition.await();\n                        success = true;\n                    }\n                    if (future.isCancelled()) {\n                        throw new InterruptedException(&amp;quot;Operation interrupted&amp;quot;);\n                    }\n                } finally {\n                    // In case of &#39;success&#39;, we were woken up by the\n                    // connection pool and should now have a connection\n                    // waiting for us, or else we&#39;re shutting down.\n                    // Just continue in the loop, both cases are checked.\n                    pool.unqueue(future);\n                    this.pending.remove(future);\n                }\n                // check for spurious wakeup vs. timeout\n                if (!success &amp;amp;&amp;amp; (deadline != null &amp;amp;&amp;amp; deadline.getTime() &amp;lt;= System.currentTimeMillis())) {\n                    break;\n                }\n            }\n            throw new TimeoutException(&amp;quot;Timeout waiting for connection&amp;quot;);\n        } finally {\n            this.lock.unlock();\n        }\n    }\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;通过代码，我们可以看到 lease 方法返回了 &lt;code&gt;Future&lt;/code&gt; 接口的匿名内部类实现，其中 &lt;code&gt;get(final long timeout, final TimeUnit tunit)&lt;/code&gt; 方法会在同步代码块下循环从连接池获取连接，即 &lt;code&gt;getPoolEntryBlocking&lt;/code&gt; 方法。&lt;/p&gt;\n&lt;p&gt;在 &lt;code&gt;getPoolEntryBlocking&lt;/code&gt; 方法中，会在加锁情况下，循环获取连接，当获取连接为空时（即连接池中没有 &lt;code&gt;available&lt;/code&gt; 的连接），会执行 &lt;code&gt;success = this.condition.awaitUntil(deadline)&lt;/code&gt;，即阻塞到超时的死亡时间线，如果在阻塞过程中，有其他连接释放（释放的代码后面我们会看到），则会把 &lt;code&gt;success&lt;/code&gt; 置为 &lt;code&gt;true&lt;/code&gt;，如果没有在死亡线达到之前获取到连接，则 &lt;code&gt;success&lt;/code&gt; 为 &lt;code&gt;false&lt;/code&gt;，在最后，&lt;code&gt;(!success &amp;amp;&amp;amp; (deadline != null &amp;amp;&amp;amp; deadline.getTime() &amp;lt;= System.currentTimeMillis())&lt;/code&gt; 会跳出循环，抛出 &lt;code&gt; throw new TimeoutException(&amp;quot;Timeout waiting for connection&amp;quot;)&lt;/code&gt;，被外层捕获。&lt;/p&gt;\n&lt;p&gt;这就是 httpclient 从连接池获取连接的过程，以及在超时情况下抛出的异常信息。&lt;/p&gt;\n&lt;h4 id=\&#34;httpclient-归还连接\&#34;&gt;httpclient 归还连接&lt;/h4&gt;\n&lt;p&gt;我们看到在使用 httpclient 的时候，在 &lt;code&gt;finally&lt;/code&gt; 代码块中，我们调用了 &lt;code&gt;abort&lt;/code&gt; 和 &lt;code&gt;releaseConnection&lt;/code&gt; 方法，用来释放 httpclient 连接，下面我们分析下如何释放连接归还连接池。&lt;/p&gt;\n&lt;h5 id=\&#34;abort-释放连接\&#34;&gt;abort 释放连接&lt;/h5&gt;\n&lt;p&gt;首先看 &lt;code&gt;abort&lt;/code&gt; 方法：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;    @Override\n    public void abort() {\n        if (this.aborted.compareAndSet(false, true)) {\n            final Cancellable cancellable = this.cancellableRef.getAndSet(null);\n            if (cancellable != null) {\n                cancellable.cancel();\n            }\n        }\n    }\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;代码中，将 &lt;code&gt;abort&lt;/code&gt; 变量从 &lt;code&gt;false&lt;/code&gt; 置为 &lt;code&gt;true&lt;/code&gt;，之后获取 &lt;code&gt;Cancellable&lt;/code&gt;，并将其置空，调用 &lt;code&gt;cancel&lt;/code&gt; 方法，我们看下在何处会放入 &lt;code&gt;Cancellable&lt;/code&gt;：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;    @Override\n    public CloseableHttpResponse execute(\n            final HttpRoute route,\n            final HttpRequestWrapper request,\n            final HttpClientContext context,\n            final HttpExecutionAware execAware) throws IOException, HttpException {\n       //  ......\n        Object userToken = context.getUserToken();\n\n        final ConnectionRequest connRequest = connManager.requestConnection(route, userToken);\n        if (execAware != null) {\n            if (execAware.isAborted()) {\n                connRequest.cancel();\n                throw new RequestAbortedException(&amp;quot;Request aborted&amp;quot;);\n            } else {\n                // ① 将 ConnectionRequest 放入 Cancellable\n                execAware.setCancellable(connRequest);\n            }\n        }\n\n        final RequestConfig config = context.getRequestConfig();\n\n        final HttpClientConnection managedConn;\n        try {\n            final int timeout = config.getConnectionRequestTimeout();\n            managedConn = connRequest.get(timeout &amp;gt; 0 ? timeout : 0, TimeUnit.MILLISECONDS);\n        } catch(final InterruptedException interrupted) {\n            Thread.currentThread().interrupt();\n            throw new RequestAbortedException(&amp;quot;Request aborted&amp;quot;, interrupted);\n        } catch(final ExecutionException ex) {\n            Throwable cause = ex.getCause();\n            if (cause == null) {\n                cause = ex;\n            }\n            throw new RequestAbortedException(&amp;quot;Request execution failed&amp;quot;, cause);\n        }\n\n        context.setAttribute(HttpCoreContext.HTTP_CONNECTION, managedConn);\n\n        if (config.isStaleConnectionCheckEnabled()) {\n            // validate connection\n            if (managedConn.isOpen()) {\n                this.log.debug(&amp;quot;Stale connection check&amp;quot;);\n                if (managedConn.isStale()) {\n                    this.log.debug(&amp;quot;Stale connection detected&amp;quot;);\n                    managedConn.close();\n                }\n            }\n        }\n\n        final ConnectionHolder connHolder = new ConnectionHolder(this.log, this.connManager, managedConn);\n        try {\n            if (execAware != null) {\n                // ② 将 ConnectionHolder 放入 Cancellable\n                execAware.setCancellable(connHolder);\n            }\n    // .....\n    }\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;第一处，将 &lt;code&gt;ConnectionRequest&lt;/code&gt; 放入。也就是说，如果此时是在执行从连接池获取连接之前调用了 &lt;code&gt;Cancellable.cancel&lt;/code&gt;，则会在构建好请求后，直接释放请求，抛出 &lt;code&gt;throw new RequestAbortedException(&amp;quot;Request aborted&amp;quot;);&lt;/code&gt; 异常；如果此时在连接获取过程中，在 &lt;code&gt;getPoolEntryBlocking&lt;/code&gt; 中调用 &lt;code&gt;Cancellable.cancel&lt;/code&gt;，在循环中会调用 &lt;code&gt;future.isCancelled()&lt;/code&gt; 判断是否取消任务，抛出 &lt;code&gt;throw new InterruptedException(&amp;quot;Operation interrupted&amp;quot;)&lt;/code&gt; 。&lt;/p&gt;\n&lt;p&gt;第二处，即获取到连接后，将 &lt;code&gt;HttpClientConnection&lt;/code&gt; 的持有者 &lt;code&gt;ConnectionHolder&lt;/code&gt; 放入。此时，我们看 &lt;code&gt;ConnectionHolder&lt;/code&gt; 的 &lt;code&gt;cancel&lt;/code&gt; 方法的实现：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;    @Override\n    public boolean cancel() {\n        final boolean alreadyReleased = this.released.get();\n        log.debug(&amp;quot;Cancelling request execution&amp;quot;);\n        abortConnection();\n        return !alreadyReleased;\n    }\n\n    @Override\n    public void abortConnection() {\n        if (this.released.compareAndSet(false, true)) {\n            synchronized (this.managedConn) {\n                try {\n                    this.managedConn.shutdown();\n                    log.debug(&amp;quot;Connection discarded&amp;quot;);\n                } catch (final IOException ex) {\n                    if (this.log.isDebugEnabled()) {\n                        this.log.debug(ex.getMessage(), ex);\n                    }\n                } finally {\n                    this.manager.releaseConnection(\n                            this.managedConn, null, 0, TimeUnit.MILLISECONDS);\n                }\n            }\n        }\n    }\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;&lt;code&gt;ConnectionHolder&lt;/code&gt; 的 &lt;code&gt;cancel&lt;/code&gt; 方法调用了 &lt;code&gt;abortConnection&lt;/code&gt; 方法，在此方法中，首先将 &lt;code&gt;release&lt;/code&gt; 置为 &lt;code&gt;true&lt;/code&gt;，之后在同步代码块情况下，先调用 &lt;code&gt;this.managedConn.shutdown()&lt;/code&gt; 以下是该方法的源码：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;    @Override\n    public void shutdown() throws IOException {\n        final Socket socket = this.socketHolder.getAndSet(null);\n        if (socket != null) {\n            // force abortive close (RST)\n            try {\n                socket.setSoLinger(true, 0);\n            } catch (final IOException ex) {\n            } finally {\n                socket.close();\n            }\n        }\n    }\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;主要功能是为了将 &lt;code&gt;Connection&lt;/code&gt; 的 Socket 对象置空，之后将 &lt;code&gt;socket&lt;/code&gt; 关闭。&lt;/p&gt;\n&lt;p&gt;之后，在 &lt;code&gt;finally&lt;/code&gt; 中，调用 &lt;code&gt;manager.releaseConnection&lt;/code&gt; 方法，源码如下：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;    @Override\n    public void releaseConnection(\n            final HttpClientConnection managedConn,\n            final Object state,\n            final long keepalive, final TimeUnit tunit) {\n        Args.notNull(managedConn, &amp;quot;Managed connection&amp;quot;);\n        synchronized (managedConn) {\n            final CPoolEntry entry = CPoolProxy.detach(managedConn);\n            if (entry == null) {\n                return;\n            }\n            final ManagedHttpClientConnection conn = entry.getConnection();\n            try {\n                if (conn.isOpen()) {\n                    final TimeUnit effectiveUnit = tunit != null ? tunit : TimeUnit.MILLISECONDS;\n                    entry.setState(state);\n                    entry.updateExpiry(keepalive, effectiveUnit);\n                    if (this.log.isDebugEnabled()) {\n                        final String s;\n                        if (keepalive &amp;gt; 0) {\n                            s = &amp;quot;for &amp;quot; + (double) effectiveUnit.toMillis(keepalive) / 1000 + &amp;quot; seconds&amp;quot;;\n                        } else {\n                            s = &amp;quot;indefinitely&amp;quot;;\n                        }\n                        this.log.debug(&amp;quot;Connection &amp;quot; + format(entry) + &amp;quot; can be kept alive &amp;quot; + s);\n                    }\n                    conn.setSocketTimeout(0);\n                }\n            } finally {\n                this.pool.release(entry, conn.isOpen() &amp;amp;&amp;amp; entry.isRouteComplete());\n                if (this.log.isDebugEnabled()) {\n                    this.log.debug(&amp;quot;Connection released: &amp;quot; + format(entry) + formatStats(entry.getRoute()));\n                }\n            }\n        }\n    }\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;在 &lt;code&gt;finally&lt;/code&gt; 中的 &lt;code&gt;pool.release&lt;/code&gt; 方法中：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;    @Override\n    public void release(final E entry, final boolean reusable) {\n        this.lock.lock();\n        try {\n            if (this.leased.remove(entry)) {\n                final RouteSpecificPool&amp;lt;T, C, E&amp;gt; pool = getPool(entry.getRoute());\n                pool.free(entry, reusable);\n                if (reusable &amp;amp;&amp;amp; !this.isShutDown) {\n                    this.available.addFirst(entry);\n                } else {\n                    entry.close();\n                }\n                onRelease(entry);\n                Future&amp;lt;E&amp;gt; future = pool.nextPending();\n                if (future != null) {\n                    this.pending.remove(future);\n                } else {\n                    future = this.pending.poll();\n                }\n                if (future != null) {\n                    this.condition.signalAll();\n                }\n            }\n        } finally {\n            this.lock.unlock();\n        }\n    }\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;我们可以看到，连接对象从 &lt;code&gt;lease&lt;/code&gt; 队列移除，并调用 &lt;code&gt;pool.free&lt;/code&gt; 方法，将连接重新放回 &lt;code&gt;available&lt;/code&gt; 队列的第一个：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;    public void free(final E entry, final boolean reusable) {\n        Args.notNull(entry, &amp;quot;Pool entry&amp;quot;);\n        final boolean found = this.leased.remove(entry);\n        Asserts.check(found, &amp;quot;Entry %s has not been leased from this pool&amp;quot;, entry);\n        if (reusable) {\n            this.available.addFirst(entry);\n        }\n    }\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;注意，此处分别是 &lt;code&gt;ConnectionPool&lt;/code&gt; 和 &lt;code&gt;RouteSpecificPool&lt;/code&gt;，&lt;code&gt;ConnectionPool&lt;/code&gt; 包含了 &lt;code&gt;RouteSpecificPool&lt;/code&gt;。&lt;/p&gt;\n&lt;p&gt;在将连接放回 &lt;code&gt;available&lt;/code&gt; 队列后，&lt;code&gt;pool.nexPending&lt;/code&gt; 获取待获取连接的挂起队列，移除一个获取连接，之后 &lt;code&gt;condition.signalAll()&lt;/code&gt; 通知所有的等待的 &lt;code&gt;future&lt;/code&gt; 获取连接。&lt;/p&gt;\n&lt;h5 id=\&#34;releaseconnection-释放连接\&#34;&gt;releaseConnection 释放连接&lt;/h5&gt;\n&lt;p&gt;我们来看 &lt;code&gt;releaseConnection&lt;/code&gt; 的代码：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;    /**\n     * A convenience method to simplify migration from HttpClient 3.1 API. This method is\n     * equivalent to {@link #reset()}.\n     *\n     * @since 4.2\n     */\n    public void releaseConnection() {\n        reset();\n    }\n\n    /**\n     * Resets internal state of the request making it reusable.\n     *\n     * @since 4.2\n     */\n    public void reset() {\n        final Cancellable cancellable = this.cancellableRef.getAndSet(null);\n        if (cancellable != null) {\n            cancellable.cancel();\n        }\n        this.aborted.set(false);\n    }\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;我们可以看到，此处也是使用和 &lt;code&gt;abort&lt;/code&gt; 一样的方式调用 &lt;code&gt;Cancellable.cancel&lt;/code&gt; 方法，但是，在方法最后，将 &lt;code&gt;aborted&lt;/code&gt; 设置为了 &lt;code&gt;false&lt;/code&gt;。&lt;/p&gt;\n&lt;p&gt;简单翻一下方法注释，&lt;code&gt;Resets internal state of the request making it reusable.&lt;/code&gt;，即重置请求的内部状态，使其可以重新使用。 我们发现，&lt;code&gt;releaseConnection&lt;/code&gt; 的作用是使请求可以重用，所以将 &lt;code&gt;aborted&lt;/code&gt; 重新置为了 &lt;code&gt;false&lt;/code&gt;。&lt;/p&gt;\n&lt;h2 id=\&#34;问题处理\&#34;&gt;问题处理&lt;/h2&gt;\n&lt;p&gt;通过上面分析，我们发现，调用 &lt;code&gt;abort&lt;/code&gt; 方法时，将请求的 &lt;code&gt;aborted&lt;/code&gt; 标志设为了 &lt;code&gt;true&lt;/code&gt;，而调用 &lt;code&gt;releaseConnection&lt;/code&gt; 后，请求的 &lt;code&gt;aborted&lt;/code&gt; 标志被重置为了 &lt;code&gt;false&lt;/code&gt;。而在代码中，会通过 &lt;code&gt;aborted&lt;/code&gt; 标志判断当前请求是否可用：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;    @Override\n    public CloseableHttpResponse execute(\n            final HttpRoute route,\n            final HttpRequestWrapper request,\n            final HttpClientContext context,\n            final HttpExecutionAware execAware) throws IOException, HttpException {\n        // 使用 aborted 判断是否需要取消 ConnectionRequest\n        final ConnectionRequest connRequest = connManager.requestConnection(route, userToken);\n        if (execAware != null) {\n            if (execAware.isAborted()) {\n                connRequest.cancel();\n                throw new RequestAbortedException(&amp;quot;Request aborted&amp;quot;);\n            } else {\n                execAware.setCancellable(connRequest);\n            }\n        }\n\n        // ......\n      \n        final ConnectionHolder connHolder = new ConnectionHolder(this.log, this.connManager, managedConn);\n        try {\n            if (execAware != null) {\n                execAware.setCancellable(connHolder);\n            }\n\n            HttpResponse response;\n            for (int execCount = 1;; execCount++) {\n\n                if (execCount &amp;gt; 1 &amp;amp;&amp;amp; !RequestEntityProxy.isRepeatable(request)) {\n                    throw new NonRepeatableRequestException(&amp;quot;Cannot retry request &amp;quot; +\n                            &amp;quot;with a non-repeatable request entity.&amp;quot;);\n                }\n\n        // 使用 aborted 判断请求是否丢弃\n                if (execAware != null &amp;amp;&amp;amp; execAware.isAborted()) {\n                    throw new RequestAbortedException(&amp;quot;Request aborted&amp;quot;);\n                }\n\n                // ......\n\n                final int timeout = config.getSocketTimeout();\n                if (timeout &amp;gt;= 0) {\n                    managedConn.setSocketTimeout(timeout);\n                }\n\n                // 使用 aborted 判断请求是否丢弃\n                if (execAware != null &amp;amp;&amp;amp; execAware.isAborted()) {\n                    throw new RequestAbortedException(&amp;quot;Request aborted&amp;quot;);\n                }\n\n                if (this.log.isDebugEnabled()) {\n                    this.log.debug(&amp;quot;Executing request &amp;quot; + request.getRequestLine());\n                }\n\n                if (this.log.isDebugEnabled()) {\n                    this.log.debug(&amp;quot;Executing request &amp;quot; + request.getRequestLine());\n                }\n\n                if (!request.containsHeader(AUTH.WWW_AUTH_RESP)) {\n                    if (this.log.isDebugEnabled()) {\n                        this.log.debug(&amp;quot;Target auth state: &amp;quot; + targetAuthState.getState());\n                    }\n                    this.authenticator.generateAuthResponse(request, targetAuthState, context);\n                }\n                if (!request.containsHeader(AUTH.PROXY_AUTH_RESP) &amp;amp;&amp;amp; !route.isTunnelled()) {\n                    if (this.log.isDebugEnabled()) {\n                        this.log.debug(&amp;quot;Proxy auth state: &amp;quot; + proxyAuthState.getState());\n                    }\n                    this.authenticator.generateAuthResponse(request, proxyAuthState, context);\n                }\n\n                response = requestExecutor.execute(request, managedConn, context);\n\n                // The connection is in or can be brought to a re-usable state.\n                if (reuseStrategy.keepAlive(response, context)) {\n                    // Set the idle duration of this connection\n                    final long duration = keepAliveStrategy.getKeepAliveDuration(response, context);\n                    if (this.log.isDebugEnabled()) {\n                        final String s;\n                        if (duration &amp;gt; 0) {\n                            s = &amp;quot;for &amp;quot; + duration + &amp;quot; &amp;quot; + TimeUnit.MILLISECONDS;\n                        } else {\n                            s = &amp;quot;indefinitely&amp;quot;;\n                        }\n                        this.log.debug(&amp;quot;Connection can be kept alive &amp;quot; + s);\n                    }\n                    connHolder.setValidFor(duration, TimeUnit.MILLISECONDS);\n                    connHolder.markReusable();\n                } else {\n                    connHolder.markNonReusable();\n                }\n\n                if (needAuthentication(\n                        targetAuthState, proxyAuthState, route, response, context)) {\n                    // Make sure the response body is fully consumed, if present\n                    final HttpEntity entity = response.getEntity();\n                    if (connHolder.isReusable()) {\n                        EntityUtils.consume(entity);\n                    } else {\n                        managedConn.close();\n                        if (proxyAuthState.getState() == AuthProtocolState.SUCCESS\n                                &amp;amp;&amp;amp; proxyAuthState.isConnectionBased()) {\n                            this.log.debug(&amp;quot;Resetting proxy auth state&amp;quot;);\n                            proxyAuthState.reset();\n                        }\n                        if (targetAuthState.getState() == AuthProtocolState.SUCCESS\n                                &amp;amp;&amp;amp; targetAuthState.isConnectionBased()) {\n                            this.log.debug(&amp;quot;Resetting target auth state&amp;quot;);\n                            targetAuthState.reset();\n                        }\n                    }\n                    // discard previous auth headers\n                    final HttpRequest original = request.getOriginal();\n                    if (!original.containsHeader(AUTH.WWW_AUTH_RESP)) {\n                        request.removeHeaders(AUTH.WWW_AUTH_RESP);\n                    }\n                    if (!original.containsHeader(AUTH.PROXY_AUTH_RESP)) {\n                        request.removeHeaders(AUTH.PROXY_AUTH_RESP);\n                    }\n                } else {\n                    break;\n                }\n            }\n\n            if (userToken == null) {\n                userToken = userTokenHandler.getUserToken(context);\n                context.setAttribute(HttpClientContext.USER_TOKEN, userToken);\n            }\n            if (userToken != null) {\n                connHolder.setState(userToken);\n            }\n\n            // check for entity, release connection if possible\n            final HttpEntity entity = response.getEntity();\n            if (entity == null || !entity.isStreaming()) {\n                // connection not needed and (assumed to be) in re-usable state\n                connHolder.releaseConnection();\n                return new HttpResponseProxy(response, null);\n            } else {\n                return new HttpResponseProxy(response, connHolder);\n            }\n        } catch (final ConnectionShutdownException ex) {\n            final InterruptedIOException ioex = new InterruptedIOException(\n                    &amp;quot;Connection has been shut down&amp;quot;);\n            ioex.initCause(ex);\n            throw ioex;\n        } catch (final HttpException ex) {\n            connHolder.abortConnection();\n            throw ex;\n        } catch (final IOException ex) {\n            connHolder.abortConnection();\n            if (proxyAuthState.isConnectionBased()) {\n                proxyAuthState.reset();\n            }\n            if (targetAuthState.isConnectionBased()) {\n                targetAuthState.reset();\n            }\n            throw ex;\n        } catch (final RuntimeException ex) {\n            connHolder.abortConnection();\n            if (proxyAuthState.isConnectionBased()) {\n                proxyAuthState.reset();\n            }\n            if (targetAuthState.isConnectionBased()) {\n                targetAuthState.reset();\n            }\n            throw ex;\n        } catch (final Error error) {\n            connManager.shutdown();\n            throw error;\n        }\n    }\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;在同步状态下，由于调用 &lt;code&gt;abort&lt;/code&gt; 和 &lt;code&gt;releaseConnection&lt;/code&gt; 时，此时客户端请求已经结束，所以修改状态不会造成问题（由于项目中每次都是重新构建请求，所以也没有重用请求）。但是当请求在异步执行时，在执行请求的同时如果丢弃连接（执行 &lt;code&gt;finally&lt;/code&gt; 的 &lt;code&gt;abort&lt;/code&gt; 和 &lt;code&gt;releaseConnection&lt;/code&gt;），此时可能在连接获取的阻塞阶段，&lt;code&gt;cancel&lt;/code&gt; 可能取消的是 &lt;code&gt;future&lt;/code&gt;，而如果此时 &lt;code&gt;future&lt;/code&gt; 已经获取并返回连接，由于后面调用 &lt;code&gt;releaseConnection&lt;/code&gt; 将请求的 &lt;code&gt;aborted&lt;/code&gt; 置为 &lt;code&gt;false&lt;/code&gt;，判断中断失效，不会抛出异常，那么已获取的连接就不会被释放。&lt;/p&gt;\n&lt;h3 id=\&#34;修复方法\&#34;&gt;修复方法&lt;/h3&gt;\n&lt;h4 id=\&#34;删除-releaseconnection\&#34;&gt;删除 releaseConnection&lt;/h4&gt;\n&lt;p&gt;如果在使用中不会复用请求，那么我们可以不再调用 &lt;code&gt;releaseConnection&lt;/code&gt;，因为 &lt;code&gt;abort&lt;/code&gt; 已经调用了 &lt;code&gt;Cancellable&lt;/code&gt; 的 &lt;code&gt;cancel&lt;/code&gt; 方法，因此，相当于 &lt;code&gt;releaseConnection&lt;/code&gt; 只会执行 &lt;code&gt;this.aborted.set(false)&lt;/code&gt;，而这会导致执行请求的线程在判断时不抛出异常，也就不会被捕获然后释放连接。&lt;/p&gt;\n&lt;h4 id=\&#34;将-abort-和-releaseconnection-放入异步方法的-finally-执行\&#34;&gt;将 abort 和 releaseConnection 放入异步方法的 finally 执行&lt;/h4&gt;\n&lt;p&gt;当我们想要复用连接时，我们可以将外面的释放连接方法放入异步方法的 &lt;code&gt;finally&lt;/code&gt; 中执行，如下：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;            try {\n                future = executor.submit(() -&amp;gt; {\n                    try {\n                        return HttpClientUtil.execute(httpGet);\n                    } catch (Exception e) {\n                        logger.error(&amp;quot;&amp;quot;, e);\n                        return null;\n                    } finally {\n                        httpGet.abort();\n                        httpGet.releaseConnection();\n                    }\n                });\n                response = future.get(5, TimeUnit.SECONDS);\n                System.out.println(&amp;quot;response = &amp;quot; + response);\n            } catch (Exception e) {\n                if (e instanceof TimeoutException &amp;amp;&amp;amp; future != null) {\n                    logger.info(Thread.currentThread().getName() + &amp;quot; start cancel future&amp;quot;);\n                    logger.error(&amp;quot;&amp;quot;, e);\n                    }\n                }\n            } finally {\n                if (null != response) {\n                    EntityUtils.consume(response.getEntity());\n                }\n            }\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;注意，在 &lt;code&gt;Future.get&lt;/code&gt; 方法超时后，不会终止任务，而是丢弃任务执行的结果，因此，当调用结束时，方法依旧会执行 &lt;code&gt;finally&lt;/code&gt; 释放连接，但是要通过 &lt;code&gt;Futrue.isDone&lt;/code&gt; 判断 &lt;code&gt;Future&lt;/code&gt; 是否执行结束，才能重新复用请求对象。&lt;/p&gt;\n&#34;,&#34;fileName&#34;:&#34;httpclient-lian-jie-wu-fa-shi-fang-wen-ti&#34;,&#34;abstract&#34;:&#34;&lt;p&gt;在中银消金三方服务平台，数据源配置中可以配置数据源调用的&lt;strong&gt;超时时间&lt;/strong&gt;，代码中使用这个用户配置的&lt;strong&gt;超时时间&lt;/strong&gt;作为 &lt;code&gt;connectionRequestTimeout&lt;/code&gt;、&lt;code&gt;connectionTimeout&lt;/code&gt; 和 &lt;code&gt;socketTimeout&lt;/code&gt; 参数。在数据源调用明细中，明显可以看出数据源的调用时长有远大于配置的&lt;strong&gt;超时时间&lt;/strong&gt;，客户提出不符合预期，要求数据源的调用时间在超过配置的&lt;strong&gt;超时时间&lt;/strong&gt;后能够终止。&lt;/p&gt;\n&#34;,&#34;title&#34;:&#34;HttpClient连接无法释放问题&#34;,&#34;tags&#34;:[{&#34;index&#34;:-1,&#34;name&#34;:&#34;httpclient&#34;,&#34;slug&#34;:&#34;4XvgcyWmH&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://wenbozhangw.github.io/tag/4XvgcyWmH/&#34;}],&#34;date&#34;:&#34;2022-06-08 12:28:12&#34;,&#34;dateFormat&#34;:&#34;2022-06-08&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://wenbozhangw.github.io/post/httpclient-lian-jie-wu-fa-shi-fang-wen-ti/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;23 min read&#34;,&#34;time&#34;:1345000,&#34;words&#34;:4441,&#34;minutes&#34;:23},&#34;description&#34;:&#34;在中银消金三方服务平台，数据源配置中可以配置数据源调用的超时时间，代码中使用这个用户配置的超时时间作为 connectionRequestTimeout、connectionTimeout 和 socketTimeout 参数。在数据源调用...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#httpclient-%E8%B6%85%E6%97%B6%E5%8F%82%E6%95%B0\&#34;&gt;httpclient 超时参数&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E9%97%AE%E9%A2%98%E8%83%8C%E6%99%AF\&#34;&gt;问题背景&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5\&#34;&gt;问题排查&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#httpclient-%E4%BB%8E%E8%BF%9E%E6%8E%A5%E6%B1%A0%E8%8E%B7%E5%8F%96%E8%BF%9E%E6%8E%A5\&#34;&gt;httpclient 从连接池获取连接&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#httpclient-%E5%BD%92%E8%BF%98%E8%BF%9E%E6%8E%A5\&#34;&gt;httpclient 归还连接&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#abort-%E9%87%8A%E6%94%BE%E8%BF%9E%E6%8E%A5\&#34;&gt;abort 释放连接&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#releaseconnection-%E9%87%8A%E6%94%BE%E8%BF%9E%E6%8E%A5\&#34;&gt;releaseConnection 释放连接&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86\&#34;&gt;问题处理&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%BF%AE%E5%A4%8D%E6%96%B9%E6%B3%95\&#34;&gt;修复方法&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%88%A0%E9%99%A4-releaseconnection\&#34;&gt;删除 releaseConnection&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%B0%86-abort-%E5%92%8C-releaseconnection-%E6%94%BE%E5%85%A5%E5%BC%82%E6%AD%A5%E6%96%B9%E6%B3%95%E7%9A%84-finally-%E6%89%A7%E8%A1%8C\&#34;&gt;将 abort 和 releaseConnection 放入异步方法的 finally 执行&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;p&gt;此章节规定了程序执行期间发生的活动。他围绕 Java 虚拟机以及构成程序的类、接口和对象的声明周期进行组织编写。&lt;/p&gt;\n&lt;p&gt;Java 虚拟机通过加载指定的类然后调用该类中的 &lt;code&gt;main&lt;/code&gt; 方法来启动。第 &lt;a href=\&#34;#121-java-virtual-machine-startup\&#34;&gt;12.1&lt;/a&gt; 节概述了执行 main 所涉及的加载、链接和初始化步骤，作为本章节的概念的介绍。下一个部分讲述了加载 &lt;a href=\&#34;#122-loading-of-classes-and-interfaces\&#34;&gt;12.2&lt;/a&gt; 、链接  &lt;a href=\&#34;#123-linking-of-classes-and-interfaces\&#34;&gt;12.3&lt;/a&gt; 和初始化  &lt;a href=\&#34;#124-initialization-of-classes-and-interfaces\&#34;&gt;12.4&lt;/a&gt;  的细节。&lt;/p&gt;\n&lt;p&gt;本章后续部分说明创建新类实例的过程（第 &lt;a href=\&#34;#125-creation-of-new-class-instances\&#34;&gt;12.5&lt;/a&gt; 节 ）；和类实例的最终确定（ &lt;a href=\&#34;#126-finalization-of-class-instances\&#34;&gt;12.6&lt;/a&gt; ）。它通过描述类的卸载（第 &lt;a href=\&#34;#127-unloading-of-classes-and-interfaces\&#34;&gt;12.7&lt;/a&gt; 节 ）和程序退出时遵循的过程（第 &lt;a href=\&#34;#128-program-exit\&#34;&gt;12.8&lt;/a&gt; 节 ）来结束。&lt;/p&gt;\n&lt;!-- more --&gt;\n&lt;h2 id=\&#34;121-java-virtual-machine-startup\&#34;&gt;12.1 Java Virtual Machine Startup&lt;/h2&gt;\n&lt;p&gt;Java 虚拟机通过调用某个指定类的 &lt;code&gt;main&lt;/code&gt; 方法开始执行，并传递给它一个参数，该参数是一个字符串数组。在本规范的示例中，这个特定类通常称为 &lt;code&gt;Test&lt;/code&gt;。&lt;/p&gt;\n&lt;p&gt;Java 虚拟机启动的精确语义在 &lt;em&gt;Java Virtual Machine Specification, Java SE 8 Edition&lt;/em&gt;  的第 5 章中给出。在这里，我们从 Java 编程语言的角度概述了该过程。&lt;/p&gt;\n&lt;p&gt;将初始类指定给 Java 虚拟的方式超出了本规范的范围，但在使用命令行的主机环境中，这是典型的，对于作为命令行参数指定的类的全限定名，以及将后面的命令参数作为字符串提供给方法 &lt;code&gt;main&lt;/code&gt; 。&lt;/p&gt;\n&lt;p&gt;例如，在 UNIX 实现中，命令行：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;java Test reboot Bob Dot Enzo\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;通常会通过调用类 &lt;code&gt;Test&lt;/code&gt;（未命名包中的类）的方法 &lt;code&gt;main&lt;/code&gt; 类启动 Java 虚拟机，并向其传递包含四个字符串 &amp;quot;reboot&amp;quot;、&amp;quot;Bob&amp;quot;、&amp;quot;Dot&amp;quot; 和 &amp;quot;Enzo&amp;quot; 的数组。&lt;/p&gt;\n&lt;p&gt;我们现在概述 Java 虚拟机执行 &lt;code&gt;Test&lt;/code&gt; 可能采取的步骤，作为加载、连接和初始化过程的例子，这些过程将在后面的部分中进一步描述。&lt;/p&gt;\n&lt;h3 id=\&#34;1211-load-the-class-test\&#34;&gt;12.1.1 Load the Class Test&lt;/h3&gt;\n&lt;p&gt;最初尝试执行类 &lt;code&gt;Test&lt;/code&gt; 和 &lt;code&gt;main&lt;/code&gt; 方法时，发现没有加载类 &lt;code&gt;Test&lt;/code&gt; —— 也就是说，Java 虚拟机当前不包含这个类的二进制表示。然后，Java 虚拟机使用类加载器来尝试找到这样的二进制表示。如果这个过程失败，就会抛出一个错误。该加载张将在 &lt;a href=\&#34;#122-loading-of-classes-and-interfaces\&#34;&gt;12.2&lt;/a&gt; 中进一步描述。&lt;/p&gt;\n&lt;h3 id=\&#34;1212-link-test-verify-prepare-optionally-resolve\&#34;&gt;12.1.2 Link Test: Verify, Prepare, (Optionally) Resolve&lt;/h3&gt;\n&lt;p&gt;加载 &lt;code&gt;Test&lt;/code&gt; 后，必须调用 &lt;code&gt;main&lt;/code&gt; 之前对其进行初始化。和所有（类或接口）类型一样，&lt;code&gt;Test&lt;/code&gt; 在初始化之前必须被连接。连接包括&lt;strong&gt;验证&lt;/strong&gt;、&lt;strong&gt;准备&lt;/strong&gt; 和 &lt;strong&gt;（可选）解析&lt;/strong&gt; 。链接将在 &lt;a href=\&#34;#123-linking-of-classes-and-interfaces\&#34;&gt;12.3&lt;/a&gt; 中进一步描述。&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;验证&lt;/strong&gt;会检查 &lt;code&gt;Test&lt;/code&gt; 的加载表示是否格式良好，是否有正确的符号表。验证还检查实现 &lt;code&gt;Test&lt;/code&gt; 的代码是否符合 Java 编程语言和 Java 虚拟机的语义要求。如果在验证过程中检测到问题，就会抛出一个错误。&lt;a href=\&#34;#1231-verification-of-the-binary-representation\&#34;&gt;12.3.1&lt;/a&gt; 中进一步描述了验证。&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;准备&lt;/strong&gt;包括静态存储和 Java 虚拟机实现内部使用的任何数据结构的分配，比如方法表。&lt;a href=\&#34;#1232-preparation-of-a-class-or-interface-type\&#34;&gt;12.3.2&lt;/a&gt; 中进一步描述了准备工作。&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;解析&lt;/strong&gt;是检查从 &lt;code&gt;Test&lt;/code&gt; 到其他类和接口的符号引用的过程，通过加载提到的其他类和接口并检查引用使用正常。&lt;/p&gt;\n&lt;p&gt;在初始化连接时，解析步骤是可选的。一种实现可以从很早就被链接的类或接口中解析符号引用，甚至可以从被引用的类和接口中进一步递归解析所有符号引用。（该解决方案可能会导致这些进一步加载和链接步骤的错误。）这种实现选择代表了一个极端，类似于在 C 语言的简单实现中已经做了多年的这种“静态”链接。。（在这些实现中，编译后的程序通常被表示为 “a.out” 文件，改文件包含该程序的完全链接版本，包括到该程序所使用的程序例程的完全解析的连接。这些库例程的副本包含在 “a.out” 文件中。）&lt;/p&gt;\n&lt;p&gt;一种实现可以选择仅在符号引用被主动使用时解析它；对所有符号引用一致使用这种策略将代表的是“最懒惰”的解决方式。在这种情况下，如果 Test 有几个对另一个类的符号引用，那么这些引用可能会在使用时一次解析一个，或者如果这些引用的程序执行期间从未使用过，则可能根本不解析。&lt;/p&gt;\n&lt;p&gt;对何时执行解析的唯一要求是，在解析过程中检测到的任何错误都必须在程序中的某个点抛出，在该点上，程序将采用一些可能直接或间接地采取一些操作，这些操作可能需要链接到设计错误的类或接口。使用上面描述的 “静态” 示例实现选择，如果加载和链接错误涉及类 Test 或任何进一步递归引用的类和接口中提到的类和接口，那么它们可能在程序执行之前发生。在实现“最懒惰”解析的系统中，只有在积极使用不正确的符号引用时才会抛出这些错误。&lt;/p&gt;\n&lt;p&gt;解析过程在第 &lt;a href=\&#34;#1233-resolution-of-symbolic-references\&#34;&gt;12.3.3&lt;/a&gt; 节中进一步描述。&lt;/p&gt;\n&lt;h3 id=\&#34;1213-initialize-test-execute-initializers\&#34;&gt;12.1.3 Initialize Test: Execute Initializers&lt;/h3&gt;\n&lt;p&gt;在我们接下来的示例中，Java 虚拟机仍在尝试执行 &lt;code&gt;Test&lt;/code&gt; 类的 &lt;code&gt;main&lt;/code&gt; 方法。仅当类已初始化时才允许这样做（第 &lt;a href=\&#34;#1241-when-initialization-occurs\&#34;&gt;12.4.1&lt;/a&gt; 节 ）。&lt;/p&gt;\n&lt;p&gt;初始化包括按文本顺序执行类 &lt;code&gt;Test&lt;/code&gt; 的任何类变量初始化程序和静态初始化程序。但是在初始化 &lt;code&gt;Test&lt;/code&gt; 之前，它的直接超类必须被初始化，以及它的直接超类的直接超类，以此递归类推。在最简单的情况下，&lt;code&gt;Test&lt;/code&gt; 将 &lt;code&gt;Object&lt;/code&gt; 作为其隐式直接超类；如果类 &lt;code&gt;Object&lt;/code&gt; 尚未初始化，则必须初始化 &lt;code&gt;Test&lt;/code&gt; 之前对齐进行初始化。类 &lt;code&gt;Object&lt;/code&gt; 没有超类，所以递归在这里终止。&lt;/p&gt;\n&lt;p&gt;如果类 &lt;code&gt;Test&lt;/code&gt; 有另一个类 &lt;code&gt;Super&lt;/code&gt; 作为它的父类，那么 &lt;code&gt;Super&lt;/code&gt; 必须在 &lt;code&gt;Test&lt;/code&gt; 之前初始化。这需要加载、验证和准备 &lt;code&gt;Super&lt;/code&gt; （如果还没有这样做的话），根据实现的不同，可能涉及递归地解析来自 &lt;code&gt;Super&lt;/code&gt; 的符号引用等等。&lt;/p&gt;\n&lt;p&gt;因此，初始化可能会导致加载、连接和初始化错误，包括涉及其他类型的此类错误。&lt;/p&gt;\n&lt;p&gt;初始化过程在第 &lt;a href=\&#34;#124-initialization-of-classes-and-interfaces\&#34;&gt;12.4&lt;/a&gt; 节中进一步描述。&lt;/p&gt;\n&lt;h3 id=\&#34;1214-invoke-testmain\&#34;&gt;12.1.4 Invoke Test.main&lt;/h3&gt;\n&lt;p&gt;最后，在 &lt;code&gt;Test&lt;/code&gt; 类的初始化完成后（在此期间可能发生了其他相应的加载、连接和初始化），调用 &lt;code&gt;Test&lt;/code&gt; 的 &lt;code&gt;main&lt;/code&gt; 方法。&lt;/p&gt;\n&lt;p&gt;方法 &lt;code&gt;main&lt;/code&gt; 必须声明为 &lt;code&gt;public&lt;/code&gt;、&lt;code&gt;static&lt;/code&gt; 和 &lt;code&gt;void&lt;/code&gt;。它必须指定一个声明类型为字符串数组 的形式参数（第 8.4.1 节）。因此，可以接受以下任一声明：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;public static void main(String[] args)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;public static void main(String... args)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;122-loading-of-classes-and-interfaces\&#34;&gt;12.2 Loading of Classes and Interfaces&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;加载&lt;/strong&gt; 指的是找到具有特定名称的类和接口类型的二进制形式的过程，可能是通过即时计算，但更常见的是通过检索 Java 编译器先前从源代码计算的二进制表示，并根据该二进制形式构造表示类或接口的 &lt;code&gt;Class&lt;/code&gt; 对象。&lt;/p&gt;\n&lt;p&gt;*Java Virtual Machine Specification, Java SE 8 Edition * 的第 5 章给出了加载的精确语义。在这里，我们从 Java 编程语言的角度概述了该过程。&lt;/p&gt;\n&lt;p&gt;类或接口的二进制格式通常是上面引用的 *Java Virtual Machine Specification, Java SE 8 Edition *  中描述的类文件格式，但是其他格式也是可能的，只要它们满足 13.1 中指定的要求。&lt;code&gt;ClassLoader&lt;/code&gt; 类的 &lt;code&gt;defineClass&lt;/code&gt; 方法可用于从 &lt;code&gt;class&lt;/code&gt; 文件格式的二进制表示中构造 &lt;code&gt;Class&lt;/code&gt; 对象。&lt;/p&gt;\n&lt;p&gt;行为良好的类加载器维护以下属性：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;给定相同的名称，一个好的类加载器总是返回相同的类对象。&lt;/li&gt;\n&lt;li&gt;如果一个类加载器 &lt;code&gt;L1&lt;/code&gt; 将类 &lt;code&gt;C&lt;/code&gt; 的加载委托给另一个加载器 &lt;code&gt;L2&lt;/code&gt;，那么对于 &lt;code&gt;C&lt;/code&gt; 的直接超类或直接超接口，或者作为 &lt;code&gt;C&lt;/code&gt; 中的字段类型，或者作为 &lt;code&gt;C&lt;/code&gt; 中的方法或构造函数的形参类型，或者作为 &lt;code&gt;C&lt;/code&gt; 中方法的返回类型出现的任何 &lt;code&gt;T&lt;/code&gt; 类型，&lt;code&gt;L1&lt;/code&gt; 和 &lt;code&gt;L2&lt;/code&gt; 应该返回相同的 &lt;code&gt;Class&lt;/code&gt; 对象。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;恶意的类加载器可能会破坏这些属性。然而，它不能破坏类型系统的安全性，因为 Java 虚拟机防止了这一点。&lt;/p&gt;\n&lt;p&gt;进一步讨论这些问题，请参阅 &lt;em&gt;Java Virtual Machine Specification, Java SE 8 Edition and the paper Dynamic Class Loading in the Java Virtual Machine, by Sheng Liang and Gilad Bracha, in Proceedings of OOPSLA &#39;98, published as ACM SIGPLAN Notices, Volume 33, Number 10, October 1998, pages 36-44&lt;/em&gt; 。Java 编程语言设计的一个基本原则是，运行时类型系统不能被用 Java 编程语言编写的代码破坏，甚至不能被诸如 &lt;code&gt;ClassLoader&lt;/code&gt; 和 &lt;code&gt;SecurityManager&lt;/code&gt; 之类的敏感系统类的实现破坏。&lt;/p&gt;\n&lt;h3 id=\&#34;1221-the-loading-process\&#34;&gt;12.2.1 The Loading Process&lt;/h3&gt;\n&lt;p&gt;加载过程由 &lt;code&gt;ClassLoader&lt;/code&gt; 类及其子类实现。&lt;/p&gt;\n&lt;p&gt;&lt;code&gt;ClassLoader&lt;/code&gt; 的不同子类可以实现不同的加载策略。特别是，类加载器可以缓存类和接口的二进制表示，根据预期的使用情况预读取它们，或者一起加载一组相关的类。这些活动对于正在运行的应用程序可能不是完全透明的，例如，如果因为类加载器缓存了旧版本而找不到类的新编译版本。然而，类加载器的责任是旨在程序中没有预读取或分组加载的地方反映加载错误。&lt;/p&gt;\n&lt;p&gt;如果在类加载过程中出现错误，则在程序中（直接或间接）使用该类型的任何点都会引发 &lt;code&gt;LinkageError&lt;/code&gt; 类的子类之一的实例：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;code&gt;ClassCircularityError&lt;/code&gt;：无法加载类或接口，因为它将是其自己的超类或超接口（第 8.1.4 节、第 9.1.3 节、第 13.4.4 节）。&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;ClassFormatError&lt;/code&gt;：声明指定所请求的编译类或接口的二进制数据格式不正确。&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;NoClassDefFoundError&lt;/code&gt;：相关的类加载器找不到请求的类或接口的定义。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;因为加载涉及新数据结构的分配，所以它可能会因 &lt;code&gt;OutOfMemoryError&lt;/code&gt; 而失败。&lt;/p&gt;\n&lt;h2 id=\&#34;123-linking-of-classes-and-interfaces\&#34;&gt;12.3 Linking of Classes and Interfaces&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;链接&lt;/strong&gt; 是获取类或接口类型的二进制形式，并将其组合到 Java 虚拟机的运行时状态中，以便可以执行的过程。类或接口类型总是在连接之前加载。&lt;/p&gt;\n&lt;p&gt;链接设计三种不同的活动：验证、准备和解析符号引用。&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;Java Virtual Machine Specification, Java SE 8 Edition&lt;/em&gt; 的第 5 章中给出了链接的精确语义。在这里，我们从 Java 编程语言的角度概述了这个过程。&lt;/p&gt;\n&lt;p&gt;如果考虑到 Java 编程语言的语义，类或接口在初始化之前就被完全验证和准备，并且在链接期间检测到的错误在程序中的某个点被抛出，在该点处程序采取了可能需要链接到错误中涉及的类或接口的一些动作，则该规范允许关于链接活动（以及由于递归，加载）何时发生的实现灵活性。&lt;/p&gt;\n&lt;p&gt;例如，一个实现可以选择仅当一个类或接口被使用时（惰性或延迟解析），单独解析它当的每个符号引用，或者在类被验证时一次性解析它们（静态解析）。这意味着，在一些实现中，在类或接口被初始化之后，解析过程可以继续。&lt;/p&gt;\n&lt;p&gt;因为链接涉及新数据结构的分配，所以它可能会因 &lt;code&gt;OutOfMemoryError&lt;/code&gt; 而失败。&lt;/p&gt;\n&lt;h3 id=\&#34;1231-verification-of-the-binary-representation\&#34;&gt;12.3.1 Verification of the Binary Representation&lt;/h3&gt;\n&lt;p&gt;&lt;strong&gt;验证&lt;/strong&gt;确保类或接口的二进制表示在接口上是正确的。例如，它检查每条指令都有一个有效的操作码；每个分支指令都分支到其他指令的开始，而不是一条指令的中间；每个方法都具有结构正确的签名；并且每条指令都遵守 Java 虚拟机语言的类型规则。&lt;/p&gt;\n&lt;p&gt;如果在验证过程中出现错误，那么将在程序中导致该类在被验证的点处抛出 &lt;code&gt;LinkageError&lt;/code&gt; 类的以下子类的实例：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;code&gt;VerifyError&lt;/code&gt;：类或接口的二进制定义未能通过一组必须的检查，以验证它符合 Java 虚拟机语言的语义，并且不会破坏 Java 虚拟机的完整性。（一些示例见 13.4.2、13.4.4、13.4.9 和 13.4.17。 ）&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h3 id=\&#34;1232-preparation-of-a-class-or-interface-type\&#34;&gt;12.3.2 Preparation of a Class or Interface Type&lt;/h3&gt;\n&lt;p&gt;&lt;strong&gt;准备&lt;/strong&gt;工作包括为类或接口创建 &lt;code&gt;static&lt;/code&gt; 字段（类变量和常量），并将这些字段初始化为默认值（4.12.5）。这不需要执行任何源代码；静态字段的显式初始化器作为初始化（12.4）的一部分执行，而不是准备。&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;Java 虚拟机的实现可以在准备时预先计算额外的数据结构，以便使以后对类或接口的操作更有效。一种特别有用的数据结构是“方法表”或其他数据结构，它允许在一个类的实例上调用任何方法，而不需要在调用时搜索超类。&lt;/em&gt;&lt;/p&gt;\n&lt;h3 id=\&#34;1233-resolution-of-symbolic-references\&#34;&gt;12.3.3 Resolution of Symbolic References&lt;/h3&gt;\n&lt;p&gt;类或接口的二进制表示引用其他类和接口（13.1）的二进制名称（13.1），象征性地引用其他类和接口及其字段、方法和构造函数。对于字段和方法，这些符号引用包括字段或方法所属的类或接口类型的名称，以及字段或方法本身的名称，以及适当的类型信息。&lt;/p&gt;\n&lt;p&gt;在符号引用可以被使用之前，它必须经过解析，其中符号引用被检查为正确的，并且通常被替换为直接引用，如果引用被重复使用，则直接引用可以被更有效地处理。&lt;/p&gt;\n&lt;p&gt;如果在解析过程中出现错误，那么将会抛出一个错误。最典型的情况是，这将是 &lt;code&gt;IncompatibleClassChangeError&lt;/code&gt; 类的下列子类之一的实例，但也可能是 &lt;code&gt;IncompatibleClassChangeError&lt;/code&gt; 的其他子类的实例，甚至是 &lt;code&gt;IncompatibleClassChangeError&lt;/code&gt; 类本身的实例。此错误可能在程序中直接或间接使用对该类型的符号引用的任何位置引发：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;code&gt;IllegalAccessError&lt;/code&gt;：遇到了指定字段的使用或赋值、方法的调用或类实例的创建的符号引用，而包含该引用的代码无权访问这些引用，因为该字段 &lt;code&gt;private&lt;/code&gt; 、&lt;code&gt;protected&lt;/code&gt; 或 &lt;code&gt;package&lt;/code&gt; 访问权限（非 &lt;code&gt;public&lt;/code&gt;）声明的，或者因为该类未声明为 &lt;code&gt;public&lt;/code&gt;。&lt;br&gt;\n例如，如果一个最初声明为 &lt;code&gt;public&lt;/code&gt; 的字段在另一个引用该字段的类被编译后被更改为 &lt;code&gt;private&lt;/code&gt;，就会发生这种情况（13.4.7）。&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;InstantiationError&lt;/code&gt;：遇到了在类创建表达式中使用的符号引用，但无法创建实例，因为该引用引用了接口或抽象类。&lt;br&gt;\n例如，如果一个原本不是抽象的类在另一个引用该类的类被编译后变成了抽象的，就会发生这种情况（13.4.1）。&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;NoSuchFieldError&lt;/code&gt;：遇到了引用特定类或接口的特定字段的符号引用，但该类或接口不包含该名称的字段。&lt;br&gt;\n例如，如果在编译了引用某个字段的另一个类之后，从该类中删除了该字段声明，就会出现这种情况(13.4.8)。&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;NoSuchMethodError&lt;/code&gt;：遇到了引用特定类或接口的特定方法的符号引用，但该类或接口不包含该签名的方法。&lt;br&gt;\n例如，如果在编译了引用某个方法的另一个类之后，从该类中删除了该方法声明，就会出现这种情况(13.4.12)。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;此外，如果某个类声明了一个无法找到实现的 &lt;code&gt;native&lt;/code&gt; 方法，则可能会引发 &lt;code&gt;UnsatisfiedLinkError&lt;/code&gt;，&lt;code&gt;LinkageError&lt;/code&gt;的子类。根据 Java 虚拟机（12.3）的实现所使用的解析策略的类型，如果使用了方法，或者更早，就会出现错误。&lt;/p&gt;\n&lt;h2 id=\&#34;124-initialization-of-classes-and-interfaces\&#34;&gt;12.4 Initialization of Classes and Interfaces&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;初始化&lt;/strong&gt;类包括执行它的静态初始化器和在类中声明的 &lt;code&gt;static&lt;/code&gt; 字段（类变量）的初始化器。&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;初始化&lt;/strong&gt;接口包括为接口中声明的字段（常量）执行初始化器。&lt;/p&gt;\n&lt;h3 id=\&#34;1241-when-initialization-occurs\&#34;&gt;12.4.1 When Initialization Occurs&lt;/h3&gt;\n&lt;p&gt;类或接口类型 T 将在第一次出现以下任何一种情况之前立即初始化：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;T 是一个类并且创建了 T 的一个实例。&lt;/li&gt;\n&lt;li&gt;调用由 T 声明的 &lt;code&gt;static&lt;/code&gt; 方法。&lt;/li&gt;\n&lt;li&gt;分配一个由 T 声明的 &lt;code&gt;static&lt;/code&gt; 字段。&lt;/li&gt;\n&lt;li&gt;使用由 T 声明的 &lt;code&gt;static&lt;/code&gt; 字段，并且该字段不是常量变量（4.12.4）。&lt;/li&gt;\n&lt;li&gt;T 是顶级类（7.6），并且执行了断言语句（14.10），它在词法上嵌套在 T （8.1.3）中。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;当一个类被初始化时，它的超类（如果它们之前没有被初始化），以及声明任何默认方法的超接口（8.1.5）（如果它们之前没有被初始化）也会被初始化。接口的初始化本身不会导致它的任何超接口的初始化。&lt;/p&gt;\n&lt;p&gt;引用 &lt;code&gt;static&lt;/code&gt; 字段（8.3.1.1）只会初始化实际声明静态字段的类或接口，即使它可能通过子类，子接口或实现接口的类的名称被引用。&lt;/p&gt;\n&lt;p&gt;在类 &lt;code&gt;Class&lt;/code&gt; 和包 &lt;code&gt;java.lang.reflect&lt;/code&gt; 中调用某些反射方法也会导致类或接口初始化。&lt;/p&gt;\n&lt;p&gt;类或接口在任何其他情况下都不会初始化。&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;注意，编译器可以在接口中生成合成的默认方法，也就是说，既没有显示声明也没有隐式声明的默认方法（13.1）。这些方法将触发接口的初始化，尽管源代码没有给出应该初始化接口的指示。&lt;/em&gt;&lt;/p&gt;\n&lt;p&gt;目的是一个类或接口类型有一组初始化器，使它处于一致的状态，并且这个状态是其他类观察到的第一个状态。静态初始值设定项和类变量初始值设定项是按文本顺序执行的，可能不会引用在勒种声明的类变量，这些类变量的声明在使用后以文本形式出现，即使这些类变量在作用域内（8.3.3）。这种限制旨在编译时检测大多数循环或错误的初始化。&lt;/p&gt;\n&lt;p&gt;初始化代码是不受限制的，这一事实允许构造这样的例子，其中在评估初始化表达式之前，当类变量仍然具有其初始默认值时，可以观察到类变量的值，但是这样的例子在实践中很少。（这样的例子也可以构造为变量初始化（&lt;a href=\&#34;#125-creation-of-new-class-instances\&#34;&gt;12.5&lt;/a&gt;）。）Java 编程语言的全部功能都可以在这些初始化器中获得；程序员必须小心谨慎。这种能力给代码生成器带来了额外的负担，但是这种负担在任何情况下都会出现，因为 Java 编程语言是并发的（&lt;a href=\&#34;#1242-detailed-initialization-procedure\&#34;&gt;12.4.2&lt;/a&gt;）。&lt;/p&gt;\n&lt;p&gt;例子 12.4.1-1，超类在子类之前初始化：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;class Super {\n    static { System.out.print(&amp;quot;Super &amp;quot;); }\n}\nclass One {\n    static { System.out.print(&amp;quot;One &amp;quot;); }\n}\nclass Two extends Super {\n    static { System.out.print(&amp;quot;Two &amp;quot;); }\n}\nclass Test {\n    public static void main(String[] args) {\n        One o = null;\n        Two t = new Two();\n        System.out.println((Object)o == (Object)t);\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;此程序输出：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;Super Two false\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;类 &lt;code&gt;One&lt;/code&gt; 永远不会被初始化，因为它没有被主动使用，因此永远不会被链接到。类 &lt;code&gt;Two&lt;/code&gt; 仅在其超类 &lt;code&gt;Super&lt;/code&gt; 被初始化后才被初始化。&lt;/p&gt;\n&lt;p&gt;例子 12.4.1-2，只有声明 &lt;code&gt;static&lt;/code&gt; 字段的类被初始化：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;class Super {\n    static int taxi = 1729;\n}\nclass Sub extends Super {\n    static { System.out.print(&amp;quot;Sub &amp;quot;); }\n}\nclass Test {\n    public static void main(String[] args) {\n        System.out.println(Sub.taxi);\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;此程序输出：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;1729\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;因为 &lt;code&gt;Sub&lt;/code&gt; 类从未初始化；对 &lt;code&gt;Sub.taxi&lt;/code&gt; 的引用是对 &lt;code&gt;Super&lt;/code&gt; 类中实际声明的字段的引用，不会触发 &lt;code&gt;Sub&lt;/code&gt; 类的初始化。&lt;/p&gt;\n&lt;p&gt;例子 12.4.1-3，接口初始化不初始化超接口：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;interface I {\n    int i = 1, ii = Test.out(&amp;quot;ii&amp;quot;, 2);\n}\ninterface J extends I {\n    int j = Test.out(&amp;quot;j&amp;quot;, 3), jj = Test.out(&amp;quot;jj&amp;quot;, 4);\n}\ninterface K extends J {\n    int k = Test.out(&amp;quot;k&amp;quot;, 5);\n}\nclass Test {\n    public static void main(String[] args) {\n        System.out.println(J.i);\n        System.out.println(K.j);\n    }\n    static int out(String s, int i) {\n        System.out.println(s + &amp;quot;=&amp;quot; + i);\n        return i;\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;该程序产生输出：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;1\nj=3\njj=4\n3\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;对 &lt;code&gt;J.i&lt;/code&gt; 的引用是对作为常量变量的字段引用（4.12.4）；因此，他不会导致 &lt;code&gt;I&lt;/code&gt; 被初始化（13.4.9）。&lt;/p&gt;\n&lt;p&gt;对 &lt;code&gt;K.j&lt;/code&gt; 的引用是对接口 &lt;code&gt;J&lt;/code&gt;  中实际声明的不是常量变量的字段的引用；这导致接口 &lt;code&gt;J&lt;/code&gt; 的字段初始化，但不初始化其超接口 &lt;code&gt;I&lt;/code&gt; 的字段，也不初始化接口 &lt;code&gt;K&lt;/code&gt; 的字段。&lt;/p&gt;\n&lt;p&gt;尽管名称 &lt;code&gt;K&lt;/code&gt; 用于引用接口 &lt;code&gt;J&lt;/code&gt; 的字段 &lt;code&gt;j&lt;/code&gt;，但接口 &lt;code&gt;K&lt;/code&gt; 并未初始化。&lt;/p&gt;\n&lt;h3 id=\&#34;1242-detailed-initialization-procedure\&#34;&gt;12.4.2 Detailed Initialization Procedure&lt;/h3&gt;\n&lt;p&gt;因为 Java 编程语言是多线程的，所以类或接口的初始化需要小心的同步，因为其他一些线程可能同时视图初始化相同的类或接口。还存在这样的可能性，即类或接口的初始化可以作为该类或接口初始化的一部分被递归地请求；例如，类 A 中的变量初始化器可能会调用不相关的类 B 的方法，这有可能会调用类 A 的方法。&lt;/p&gt;\n&lt;p&gt;该过程假设 &lt;code&gt;Class&lt;/code&gt; 对象已经被验证和准备，并且该对象包含指示四种情况之一的状态：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;该 &lt;code&gt;Class&lt;/code&gt; 对象已经过验证和准备，但尚未初始化。&lt;/li&gt;\n&lt;li&gt;该 &lt;code&gt;Class&lt;/code&gt; 对象正在被某个特定的线程 &lt;code&gt;T&lt;/code&gt; 初始化。&lt;/li&gt;\n&lt;li&gt;该 &lt;code&gt;Class&lt;/code&gt; 对象已经完全初始化，可以使用了。&lt;/li&gt;\n&lt;li&gt;该 &lt;code&gt;Class&lt;/code&gt; 对象处于错误状态，可能是因为初始化尝试失败。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;对于每个类或接口 &lt;code&gt;C&lt;/code&gt;，都有一个唯一的初始化锁 &lt;code&gt;LC&lt;/code&gt;。从 &lt;code&gt;C&lt;/code&gt; 到 &lt;code&gt;LC&lt;/code&gt; 的映射由 Java 虚拟机实现决定。初始化 &lt;code&gt;C&lt;/code&gt; 的过程如下：&lt;/p&gt;\n&lt;ol&gt;\n&lt;li&gt;对 &lt;code&gt;C&lt;/code&gt; 的初始化锁 &lt;code&gt;LC&lt;/code&gt; 进行同步，这包括等待，直到当前线程可以获取 &lt;code&gt;LC&lt;/code&gt;。&lt;/li&gt;\n&lt;li&gt;如果 &lt;code&gt;C&lt;/code&gt; 的 &lt;code&gt;Class&lt;/code&gt; 对象指示某个其他线程正在对 &lt;code&gt;C&lt;/code&gt; 进行初始化，那么释放 &lt;code&gt;LC&lt;/code&gt; 并阻塞当前线程，直到通知正在进行的初始化已经完成，此时重复该步骤。&lt;/li&gt;\n&lt;li&gt;如果 &lt;code&gt;C&lt;/code&gt; 的 &lt;code&gt;Class&lt;/code&gt; 对象指示当前线程正在对 &lt;code&gt;C&lt;/code&gt; 进行初始化，那么这一定是一个递归的初始化请求。释放 &lt;code&gt;LC&lt;/code&gt; 并正常完成。&lt;/li&gt;\n&lt;li&gt;如果 &lt;code&gt;C&lt;/code&gt; 的 &lt;code&gt;Class&lt;/code&gt; 对象指示 &lt;code&gt;C&lt;/code&gt; 已经被初始化，那么不需要进一步的动作。释放 &lt;code&gt;LC&lt;/code&gt; 并正常完成。&lt;/li&gt;\n&lt;li&gt;如果 &lt;code&gt;C&lt;/code&gt; 的 &lt;code&gt;Class&lt;/code&gt; 对象处于错误状态，那么初始化是不可能的。释放 &lt;code&gt;LC&lt;/code&gt; 并抛出一个 &lt;code&gt;NoClassDefFoundError&lt;/code&gt;。&lt;/li&gt;\n&lt;li&gt;否则，记录当前线程正在初始化 &lt;code&gt;C&lt;/code&gt; 的 &lt;code&gt;Class&lt;/code&gt; 对象，并释放 &lt;code&gt;LC&lt;/code&gt;。&lt;/li&gt;\n&lt;/ol&gt;\n&lt;p&gt;然后，初始化 &lt;code&gt;C&lt;/code&gt; 的 &lt;code&gt;static&lt;/code&gt; 字段，它们是常量变量（4.12.4，8.3.2，9.3.1）。&lt;/p&gt;\n&lt;ol start=\&#34;7\&#34;&gt;\n&lt;li&gt;接下来，如果 &lt;code&gt;C&lt;/code&gt; 是一个类而不是一个接口，它的超类还没有初始化，那么设 &lt;code&gt;SC&lt;/code&gt; 是它的超类，设 SI&lt;sub&gt;1&lt;/sub&gt;，... ...，SI&lt;sub&gt;n&lt;/sub&gt;是声明了至少一个默认方法的 &lt;code&gt;C&lt;/code&gt; 的所有超接口。超接口的顺序由 C 直接实现的每个接口的超接口层次结构上的递归枚举给出（按照 &lt;code&gt;C&lt;/code&gt; 的 &lt;code&gt;implements&lt;/code&gt; 子句从左到右的顺序 ）。对于 &lt;code&gt;C&lt;/code&gt; 直接实现的每个接口 &lt;code&gt;I&lt;/code&gt; ，枚举在返回 &lt;code&gt;I&lt;/code&gt; 之前在 &lt;code&gt;I&lt;/code&gt; 的超接口上递归（按照 &lt;code&gt;I&lt;/code&gt; 的 &lt;code&gt;extends&lt;/code&gt; 子句从左到右的顺序）。&lt;/li&gt;\n&lt;/ol&gt;\n&lt;p&gt;对于列表 [SC，SI&lt;sub&gt;1&lt;/sub&gt;，... ...，SI&lt;sub&gt;n&lt;/sub&gt;]，递归地对 &lt;code&gt;S&lt;/code&gt; 执行整个过程，如有必要，首先验证并准备 &lt;code&gt;S&lt;/code&gt;。&lt;/p&gt;\n&lt;p&gt;如果 &lt;code&gt;S&lt;/code&gt; 的初始化因为一个抛出的异常而突然完成，那么获取 &lt;code&gt;LC&lt;/code&gt;，将 &lt;code&gt;C&lt;/code&gt; 的类对象标记为错误，通知所有等待的线程，释放 &lt;code&gt;LC&lt;/code&gt;，然后突然完成，抛出与初始化 &lt;code&gt;S&lt;/code&gt; 相同的异常。&lt;/p&gt;\n&lt;ol start=\&#34;8\&#34;&gt;\n&lt;li&gt;接下来，通过查询 &lt;code&gt;C&lt;/code&gt; 的定义类加载器来确定 &lt;code&gt;C&lt;/code&gt; 是否启用了断言（14.10）。&lt;/li&gt;\n&lt;li&gt;接下来，按照文本顺序执行类的类变量初始值设定项和静态初始值设定项，或者接口的字段初始值设定项，就好像它们是单个块一样。&lt;/li&gt;\n&lt;li&gt;如果初始化器的执行正常完成，那么获取 &lt;code&gt;LC&lt;/code&gt;， 将 &lt;code&gt;C&lt;/code&gt; 的 &lt;code&gt;Class&lt;/code&gt; 对象标记为完全初始化，通知所有等待的线程，释放 &lt;code&gt;LC&lt;/code&gt;，然后正常完成这个过程。&lt;/li&gt;\n&lt;li&gt;否则，初始值设定项一定是通过抛出某个异常 &lt;code&gt;E&lt;/code&gt; 而突然完成的，如果 &lt;code&gt;E&lt;/code&gt; 的类不是 &lt;code&gt;Error&lt;/code&gt; 或它的某个子类，则创建 &lt;code&gt;ExceptionInInitializerError&lt;/code&gt; 类的新实例，使用 &lt;code&gt;E&lt;/code&gt; 作为参数，并在下面的步骤中使用此对象代替 &lt;code&gt;E&lt;/code&gt;。如果由于发生 &lt;code&gt;OutOfMemoryError&lt;/code&gt; 而无法创建 &lt;code&gt;ExceptionInInitializerError&lt;/code&gt; 的新实例，则在下面的步骤中使用 &lt;code&gt;OutOfMemoryError&lt;/code&gt; 对象代替 &lt;code&gt;E&lt;/code&gt;。&lt;/li&gt;\n&lt;li&gt;获取 &lt;code&gt;LC&lt;/code&gt;，将 &lt;code&gt;C&lt;/code&gt; 的 &lt;code&gt;Class&lt;/code&gt; 对象标记为错误，通知所有等待的线程，释放 &lt;code&gt;LC&lt;/code&gt;，并突然完成此过程，原因为 &lt;code&gt;E&lt;/code&gt; 或其替换，如前一步骤中所确定的。&lt;/li&gt;\n&lt;/ol&gt;\n&lt;p&gt;&lt;em&gt;当实现可以确定类的初始化已经完成时，它可以通过取消步骤 1 中的锁获取（以及步骤 4/5 中的释放）来优化该过程，前提是，就存储器模型而言，如果锁被获取，则所有的 happens-before 排序在执行优化时仍然存在。&lt;/em&gt;&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;代码生成器需要保留类或接口的可能初始化点，插入刚才描述的初始化过程的调用。如果这个初始化过程正常完成，并且 * &lt;code&gt;Class&lt;/code&gt; * 对象被完全初始化并准备好使用，那么初始化过程的调用不再是必要的，并且它可以从代码中消除——例如，通过修补它或以其他方式重新生成代码。&lt;/em&gt;&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;在某些情况下，如果可以确定一组相关类型的初始化顺序，编译时分析可能能够从生成代码中消除许多类型已初始化的检查。然而，这种分析必须充分考虑到并发性和初始化代码不受限制的事实。&lt;/em&gt;&lt;/p&gt;\n&lt;h2 id=\&#34;125-creation-of-new-class-instances\&#34;&gt;12.5 Creation of New Class Instances&lt;/h2&gt;\n&lt;p&gt;当对一个类实例创建表达式求值（15.9）导致一个类被实例化时，一个新的类实例被显示地创建。&lt;/p&gt;\n&lt;p&gt;在以下情况下可以隐式创建一个新的类实例：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;加载一个包含 &lt;code&gt;String&lt;/code&gt; 字面量（3.10.5）的类或接口可能会创建一个新的 &lt;code&gt;String&lt;/code&gt; 对象来表示该字面量。（如果同一个 &lt;code&gt;String&lt;/code&gt; 之前已经被保留，这可能不会发生（3.10.5）。）&lt;/li&gt;\n&lt;li&gt;导致装箱转换的操作的执行（5.1.7）。装箱转换可以创建于原语类型之一相关联的包装类的新对象。&lt;/li&gt;\n&lt;li&gt;执行不属于常量表达式（15.28）的字符串连接运算符 &lt;code&gt;+&lt;/code&gt; （15.18.1）时，总是会创建一个新的字符串来表示结果。字符串串联运算也可以为原始类型的值创建临时包装对象。&lt;/li&gt;\n&lt;li&gt;评估方法引入表达式（15.13.3）或 lambda 表达式（15.27.4）可能需要创建实现函数式接口类型的类的新实例。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;作为类实例创建过程的一部分，这些情况中的每一种都标识了一个特定的构造函数（8.8），改构造函数将使用指定的参数（可能没有）来调用。&lt;/p&gt;\n&lt;p&gt;每当一个新的类实例被创建时，内存空间被分配给它，其中包括在类类型中声明所有实例变量，以及在类类型的每个超类中声明的所有实例变量，包括所有可能隐藏的实例变量（8.3）。&lt;/p&gt;\n&lt;p&gt;如果没有足够的可用空间分配内存，那么类实例的创建就会突然结束，并发出 &lt;code&gt;OutOfMemoryError&lt;/code&gt;。否则，新对象中的所有实例变量，包括在超类中声明的实例变量，都被初始位它们的默认值（4.12.5）。&lt;/p&gt;\n&lt;p&gt;就在返回新创建对象的引用作为结果之前，处理指定的构造函数，使用以下过程初始化新对象：&lt;/p&gt;\n&lt;ol&gt;\n&lt;li&gt;将构造函数的参数赋给为这个构造函数调用新创建的参数变量。&lt;/li&gt;\n&lt;li&gt;如果这个构造函数是从同一个类中的另一个构造函数的显式构造函数调用（8.8.7.1）开始的（使用 &lt;code&gt;this&lt;/code&gt;），那么使用这五个步骤计算参数并递归地处理构造函数调用。如果构造函数调用突然完成，那么这个过程也会因为同样的原因而突然完成；否则，继续执行步骤 5。&lt;/li&gt;\n&lt;li&gt;此构造函数不以同一个类中的另一个构造函数的显式构造函数调用开始（使用 &lt;code&gt;this&lt;/code&gt;）。如果这个构造函数是针对 &lt;code&gt;Object&lt;/code&gt; 之外的类，那么这个构造函数将以一个超类构造函数的显式或隐式调用开始（使用 &lt;code&gt;super&lt;/code&gt;）。使用相同的五个步骤评估参数并递归处理超类构造函数调用。如果构造函数调用突然完成，那么这个过程也会因同样的原因而突然完成。否则，继续执行步骤 4。&lt;/li&gt;\n&lt;li&gt;执行该类的实例初始值设定项和实例变量初始值设定项，将实例变量初始值设定项的值分配给相应的实例变量，按照它们在该类的源代码中以文本形式出现的从左到右的顺序。如果这些初始化器中的任何一个执行导致了异常，俺么就不再处理进一步的初始化器，并且这个过程以同样的异常突然结束。否则，继续执行步骤 5。&lt;/li&gt;\n&lt;li&gt;执行该构造函数体的其余部分。如果该执行突然完成，那么该过程也由于同样的原因而突然完成。否则，此过程正常完成。&lt;/li&gt;\n&lt;/ol&gt;\n&lt;p&gt;与 C++ 不同，Java 编程语言在创建新的类实例期间没有为方法分派指定更改规则。如果调用的方法在被初始化的对象的子类中被重写，那么这些重写的方法将被使用，甚至在新对象被完全初始化之前。&lt;/p&gt;\n&lt;p&gt;例子 12.5-1，实例创建评估：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;class Point {\n    int x, y;\n    Point() { x = 1; y = 1; }\n}\nclass ColoredPoint extends Point {\n    int color = 0xFF00FF;\n}\nclass Test {\n    public static void main(String[] args) {\n        ColoredPoint cp = new ColoredPoint();\n        System.out.println(cp.color);\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;这里，创建了一个新的 &lt;code&gt;ColoredPoint&lt;/code&gt; 实例。首先，为新的 &lt;code&gt;ColoredPoint&lt;/code&gt; 分配空间，以保存字段 &lt;code&gt;x&lt;/code&gt;、&lt;code&gt;y&lt;/code&gt; 和 &lt;code&gt;color&lt;/code&gt;。然后将所有这些字段初始化为它们的默认值（在本例中，每个字段为 0）。接下来，首先调用没有参数的 &lt;code&gt;ColoredPoint&lt;/code&gt; 构造函数。由于 &lt;code&gt;ColoredPoint&lt;/code&gt; 没有声明构造函数，因此隐式声明了一下形势的默认构造函数：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;ColoredPoint() { super(); }\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;然后，这个构造函数调用不带参数的 &lt;code&gt;Point&lt;/code&gt; 构造函数。&lt;code&gt;Point&lt;/code&gt; 构造函数并不以调用构造函数开始，因此 Java 编译器提供了对其超类构造函数的隐式调用，不带参数，就像已经编写的那样：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;Point() { super(); x = 1; y = 1; }\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;因此，将调用不带参数的 &lt;code&gt;Object&lt;/code&gt; 构造函数。&lt;/p&gt;\n&lt;p&gt;类 &lt;code&gt;Object&lt;/code&gt; 没有父类，因此递归到此结束。接下来，调用 &lt;code&gt;Object&lt;/code&gt; 的任何实例初始化器和实例变量的初始化器。接下来，执行不带参数的 &lt;code&gt;Object&lt;/code&gt; 构造函数体。&lt;code&gt;Object&lt;/code&gt; 中没有声明这样的构造函数，所以 Java 编译器提供了一个默认构造函数，在这个特殊情况下是：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;Object() { }\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;此构造函数执行无效并返回。&lt;/p&gt;\n&lt;p&gt;接下来，执行类 &lt;code&gt;Point&lt;/code&gt; 的实例变量的所有初始化器。当它发送时，&lt;code&gt;x&lt;/code&gt; 和 &lt;code&gt;y&lt;/code&gt; 的声明不提供任何初始化值，因此示例的这一步不需要任何操作。然后执行 &lt;code&gt;Point&lt;/code&gt; 构造函数体，将 &lt;code&gt;x&lt;/code&gt; 设为 &lt;code&gt;1&lt;/code&gt;，将 &lt;code&gt;y&lt;/code&gt; 设为 &lt;code&gt;1&lt;/code&gt;。&lt;/p&gt;\n&lt;p&gt;接下来，执行 &lt;code&gt;ColoredPoint&lt;/code&gt; 类的实例变量和初始化器。这一步将值 &lt;code&gt;0xFF00FF&lt;/code&gt; 分配给 &lt;code&gt;color&lt;/code&gt;。最后，执行 &lt;code&gt;ColoredPoint&lt;/code&gt; 构造函数体的其余部分（调用 &lt;code&gt;super&lt;/code&gt; 之后的部分）；在主题的其他部分中碰巧没有语句，因此不需要进一步操作，初始化完成。&lt;/p&gt;\n&lt;p&gt;例子 12.5-2，实例创建期间的动态调度：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;class Super {\n    Super() { printThree(); }\n    void printThree() { System.out.println(&amp;quot;three&amp;quot;); }\n}\nclass Test extends Super {\n    int three = (int)Math.PI;  // That is, 3\n    void printThree() { System.out.println(three); }\n\n    public static void main(String[] args) {\n        Test t = new Test();\n        t.printThree();\n    }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;该程序产生输出：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;0\n3\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;这表明在类 &lt;code&gt;Super&lt;/code&gt; 的构造函数中调用 &lt;code&gt;printThree&lt;/code&gt; 并没有调用类 &lt;code&gt;Super&lt;/code&gt; 中 &lt;code&gt;printThree&lt;/code&gt; 的定义，而是调用了类 &lt;code&gt;Test&lt;/code&gt; 中 &lt;code&gt;printThree&lt;/code&gt; 的覆盖定义。因此，该方法在 &lt;code&gt;Test&lt;/code&gt; 的字段初始化器执行之前允许，这就是为什么第一个输出值是 0，&lt;code&gt;Test&lt;/code&gt; 的字段 &lt;code&gt;three&lt;/code&gt; 初始化的默认值。之后在方法 &lt;code&gt;main&lt;/code&gt; 中对 &lt;code&gt;printThree&lt;/code&gt; 的调用，调用了 &lt;code&gt;printThree&lt;/code&gt; 的相同的定义，但此时已经执行了实例变量 &lt;code&gt;three&lt;/code&gt; 的初始化器，因此输出了值 &lt;code&gt;3&lt;/code&gt;。&lt;/p&gt;\n&lt;h2 id=\&#34;126-finalization-of-class-instances\&#34;&gt;12.6 Finalization of Class Instances&lt;/h2&gt;\n&lt;p&gt;&lt;code&gt;Object&lt;/code&gt; 类有一个 &lt;code&gt;protected&lt;/code&gt; 的方法 &lt;code&gt;finalize&lt;/code&gt;；这个方法可以被其他类重写。可为对象调用的 &lt;code&gt;finalize&lt;/code&gt; 的特定定义成为该对象的&lt;em&gt;终结器(finalizer)&lt;/em&gt;。在垃圾收集器回收对象的存储之前，Java 虚拟机将调用该对象的 finalizer 。&lt;/p&gt;\n&lt;p&gt;finalizer 提供了释放自动存储管理器无法自动释放的资源的机会。在这种情况下，仅仅回收对象使用的内存并不能保证回收对象所持有的资源。&lt;/p&gt;\n&lt;p&gt;Java 编程语言没有指定调用 finalizer 的时间，只是说将在重用对象的存储志强调用 finalizer。&lt;/p&gt;\n&lt;p&gt;Java 编程语言没有指定哪个线程将为任何给定对象调用 finalizer。&lt;/p&gt;\n&lt;p&gt;*重要的是 要注意，许多 finalizer 线程可能是活动的（在大型共享内存多处理器上有时需要这样），如果一个大型连接的数据结构变成垃圾，那么该数据结构中每个对象的所有 *  &lt;code&gt;finalize&lt;/code&gt; &lt;em&gt;方法都可能同时被调用，每个 finalizer 调用在不同的线程中运行。&lt;/em&gt;&lt;/p&gt;\n&lt;p&gt;Java 编程语言没有对 &lt;code&gt;finalize&lt;/code&gt; 方法调用进行排序。finalizer 可以按任何顺序调用，甚至可以并发调用。&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;例如，如果循环链接的未终结对象组变得不可达（或 finalizer 可达），则所有对象可以一起变得可终结。最终，这些对象的 finalizer 可以以任何顺序调用，甚至可以使用多线程并发调用。如果自动存储管理器来发现对象不可达，那么它们的存储可以被回收。&lt;/em&gt;&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;实现一个类是很简单的，当所有对象都变得不可访问时，它将导致一组类似 finalizer 的方法以指定的顺序为一组对象调用。定义这样一个类留给读者作为练习。&lt;/em&gt;&lt;/p&gt;\n&lt;p&gt;保证在调用 finalizer 时，调用该 finalizer 的线程不会持有任何用户可见的同步锁。&lt;/p&gt;\n&lt;p&gt;如果在终结期间引发了未捕获异常，则该异常将被忽略，该对象的终结将终止。&lt;/p&gt;\n&lt;p&gt;一个对象的构造函数的完成发生在（17.4.5）它的 &lt;code&gt;finalize&lt;/code&gt; 方法的执行之前（在 happens-before 的正式意义上）。&lt;/p&gt;\n&lt;p&gt;在类对象中声明的 &lt;code&gt;finalize&lt;/code&gt; 方法不执行任何操作。&lt;code&gt;Object&lt;/code&gt; 类声明 &lt;code&gt;finalize&lt;/code&gt; 方法的事实意味着任何类的 &lt;code&gt;finalize&lt;/code&gt; 方法都可以调用其超类的 &lt;code&gt;finalize&lt;/code&gt; 方法。除非程序员有意使超类中 finalizer 的动作无效，否则应该总是这样做。（与构造函数不同，finalizer 不会自动调用超类的 finalizer；这种调用必须显式编码。）&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;为了提高效率，实现可以跟踪哪些不覆盖&lt;/em&gt;  &lt;code&gt;Object&lt;/code&gt;&lt;em&gt;类的&lt;/em&gt; &lt;code&gt;finalize&lt;/code&gt; &lt;em&gt;方法的类对象，或者以一种简单 方式覆盖它。&lt;/em&gt;&lt;/p&gt;\n&lt;p&gt;例如：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;protected void finalize() throws Throwable {\n    super.finalize();\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;如 &lt;a href=\&#34;#1261-implementing-finalization\&#34;&gt;12.6.1&lt;/a&gt; 所述，我们鼓励实现将这一的对象视为具有未被覆盖的 finalizer，并更有效的终结它们。&lt;/p&gt;\n&lt;p&gt;可以显示调用 finalizer，就像任何其他方法一样。&lt;/p&gt;\n&lt;p&gt;&lt;code&gt;java.lang.ref&lt;/code&gt; 包描述了弱引用，它与垃圾收集和终结进行交互。与任何与 Java 编程语言有特殊交互的 API 一样，实现者必须了解 &lt;code&gt;java.lang.ref&lt;/code&gt; API 提出的任何要求。本规范不以任何方式讨论弱引用。读者可以参考 API 文档了解详细信息。&lt;/p&gt;\n&lt;h3 id=\&#34;1261-implementing-finalization\&#34;&gt;12.6.1 Implementing Finalization&lt;/h3&gt;\n&lt;p&gt;每个对象都可以用两个属性来描述：它可以是 &lt;em&gt;可到达的（reachable）&lt;/em&gt;，&lt;em&gt;终结器可到达的（finalizer-reachable）&lt;/em&gt; 或 &lt;em&gt;不可到达的（unreachable）&lt;/em&gt;，也可以是 &lt;em&gt;未终结的（unfinalized）&lt;/em&gt;，&lt;em&gt;可终结的（finalizable）&lt;/em&gt; 或 &lt;em&gt;终结的（finalized）&lt;/em&gt;。&lt;/p&gt;\n&lt;p&gt;**可达（reachable）**对象是可以在任何潜在的持续计算中从任何活动线程访问的任何对象。&lt;/p&gt;\n&lt;p&gt;**终结器可访问（finalizer-reachable）**的对象可以通过某个引用链从某个可终结的对象访问，但不能从任何活动线程访问。&lt;/p&gt;\n&lt;p&gt;**不可达（unreachable）**对象无论用哪种方法都不可达。&lt;/p&gt;\n&lt;p&gt;**未终结（unfinalized）**对象从未自动调用其 finalizer。&lt;/p&gt;\n&lt;p&gt;**终结（finalized）**对象已经自动调用了它的 finalizer。&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;可终结（finalizable）&lt;/strong&gt; 对象从未自动调用其终结器，但 Java 虚拟机最终可能会自动调用其终结器。&lt;/p&gt;\n&lt;p&gt;直到对象 &lt;code&gt;o&lt;/code&gt; 的构造函数调用了 &lt;code&gt;o&lt;/code&gt; 上层的 &lt;code&gt;Object&lt;/code&gt; 的构造函数，并且该调用成功完成（即没有引发异常），对象 &lt;code&gt;o&lt;/code&gt; 才是 &lt;strong&gt;可终结的（finaliable）&lt;/strong&gt;。对一个对象的字段的每一个预终结（pre-finalization）写入必须对该对象的终结（finalization）可见。此外，对该对象的字段的预终结（pre-finalization）读取都会看到在该对象的终结被启动之后发生的写入。&lt;/p&gt;\n&lt;p&gt;程序的优化转换可以设计成减少可到达对象的数量，使之少于那些天真地认为可到达的对象的数量。例如，Java 编译器或代码生成器可能会选择将一个不再使用的变量或参数设置为 &lt;code&gt;null&lt;/code&gt;，从而使此类对象的存储可能更快速地被回收。&lt;/p&gt;\n&lt;p&gt;另一个例子是对象字段中的值存储在寄存器中。然后程序可以访问寄存器而不是对象，并且不在访问该对象。这意味着该对象是垃圾。注意，只有当引用在栈上，而不是存储在堆中时，才允许这种优化。&lt;/p&gt;\n&lt;p&gt;例如，考虑 Finalizer Guardian 模式：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;class Foo {\n    private final Object finalizerGuardian = new Object() {\n        protected void finalize() throws Throwable {\n            /* finalize outer Foo object */\n        }\n    }\n} \n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;如果子类重写 &lt;code&gt;finalize&lt;/code&gt; 并且没有显示调用 &lt;code&gt;super.finalize&lt;/code&gt;，finalizer guardian 会强制调用 &lt;code&gt;super.finalize&lt;/code&gt;。&lt;/p&gt;\n&lt;p&gt;如果允许对存储在堆上的引用进行这些优化，那么 Java 编译器可以检测到 &lt;code&gt;finalizerGuardian&lt;/code&gt; 字段从未被读取，将其清空，理解回收对象，并提前调用 finalizer。这与初衷背道而驰：当 &lt;code&gt;Foo&lt;/code&gt; 实例变得不可访问时，程序员可能想调用 &lt;code&gt;Foo&lt;/code&gt; 的 finalizer。因此，这种转换是不合法的：只要外部类对象是可达的，内部类对象就应该是可达的。&lt;/p&gt;\n&lt;p&gt;这种类型的转换可能会导致 &lt;code&gt;finalizer&lt;/code&gt; 方法的调用比预期的要早。为了允许用户防止这种情况，我们强调了同步可以保持对象存活的概念。如果一个对象的 finalizer 可以导致该对象上的同步，那么该对象必须是活动的，并且在它被锁定时被认为是可访问的。&lt;/p&gt;\n&lt;p&gt;请注意，这并不妨碍同步消除：只有当 finalizer 可能对一个对象进行同步时，同步才会使该对象保持活动状态。由于终结器出现在另一个线程中，因此许多情况下，无论如何都无法移除同步。&lt;/p&gt;\n&lt;h3 id=\&#34;1262-interaction-with-the-memory-model\&#34;&gt;12.6.2 Interaction with the Memory Model&lt;/h3&gt;\n&lt;p&gt;内存模型（17.4）必须能够决定何时提交发生在 finalizer 中的操作。本节描述 finalization 与内存模型的交互。&lt;/p&gt;\n&lt;p&gt;每个执行都与许多可达性决策点，标记为 &lt;code&gt;di&lt;/code&gt;。每个动作要么发生在 &lt;code&gt;di&lt;/code&gt;之前，要么发生在 &lt;code&gt;di&lt;/code&gt; 之后。除了明确提到的以外，本节中描述的先来后到排序与内存模型中的所有其他排序无关。&lt;/p&gt;\n&lt;p&gt;如果 &lt;code&gt;r&lt;/code&gt; 是看到写 &lt;code&gt;w&lt;/code&gt; 的读，并且 &lt;code&gt;r&lt;/code&gt; 在 &lt;code&gt;di&lt;/code&gt; 之前，那么 &lt;code&gt;w&lt;/code&gt; 必须在 &lt;code&gt;di&lt;/code&gt; 之前。&lt;/p&gt;\n&lt;p&gt;如果 &lt;code&gt;x&lt;/code&gt; 和 &lt;code&gt;y&lt;/code&gt; 是对同一变量或监视器的同步操作，使得 &lt;code&gt;so(x, y)&lt;/code&gt; （17.4.4）和 &lt;code&gt;y&lt;/code&gt; 在 &lt;code&gt;di&lt;/code&gt; 之前，那么 &lt;code&gt;x&lt;/code&gt; 必须在 &lt;code&gt;di&lt;/code&gt; 之前。&lt;/p&gt;\n&lt;p&gt;在每个可达性决策点，一些对象集被标记为不可达，而这些对象的一些子集被标记为可终结。这些可达性决策点也是根据 &lt;code&gt;java.lang.ref&lt;/code&gt; 包的 API 文件中提供的规则检查、加入队列和清除引用的点。&lt;/p&gt;\n&lt;p&gt;唯一被认为在 &lt;code&gt;di&lt;/code&gt; 点绝对可达的对象是那些可以通过应用这些规则证明可达的对象：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;如果存在对类 &lt;code&gt;C&lt;/code&gt; 的 &lt;code&gt;static&lt;/code&gt; 字段 &lt;code&gt;v&lt;/code&gt; 的写入 &lt;code&gt;w1&lt;/code&gt;，使得 &lt;code&gt;w1&lt;/code&gt; 写入的值是对 &lt;code&gt;B&lt;/code&gt; 的引用，类 &lt;code&gt;C&lt;/code&gt; 有可到达的类加载器加载，并且不存在对 &lt;code&gt;v&lt;/code&gt; 的写入 &lt;code&gt;w2&lt;/code&gt;，使得 &lt;code&gt;hb(w2, w1)&lt;/code&gt; 不为 true，并且 &lt;code&gt;w1&lt;/code&gt; 和 &lt;code&gt;w2&lt;/code&gt; 都在 &lt;code&gt;di&lt;/code&gt; 之前，则对象 &lt;code&gt;B&lt;/code&gt; 在 &lt;code&gt;di&lt;/code&gt; 处肯定是可达的。&lt;/li&gt;\n&lt;li&gt;如果存在对 &lt;code&gt;A&lt;/code&gt; 的元素 &lt;code&gt;v&lt;/code&gt; 的写 &lt;code&gt;w1&lt;/code&gt;，使得由 &lt;code&gt;w1&lt;/code&gt; 写的值是对 &lt;code&gt;B&lt;/code&gt; 的引用，并且不存在对 &lt;code&gt;v&lt;/code&gt; 的写 &lt;code&gt;w2&lt;/code&gt; ，使得 &lt;code&gt;hb(w2, w1)&lt;/code&gt; 不为 true，并且 &lt;code&gt;w1&lt;/code&gt; 和 &lt;code&gt;w2&lt;/code&gt; 都在 &lt;code&gt;di&lt;/code&gt; 之前，则对象 &lt;code&gt;B&lt;/code&gt; 在 &lt;code&gt;di&lt;/code&gt; 处肯定是从 &lt;code&gt;A&lt;/code&gt; 可达的。&lt;/li&gt;\n&lt;li&gt;如果一个对象 &lt;code&gt;C&lt;/code&gt; 从一个对象 &lt;code&gt;B&lt;/code&gt; 肯定是可达的，并且对象 &lt;code&gt;B&lt;/code&gt; 从一个对象 &lt;code&gt;A&lt;/code&gt; 肯定是可达的，那么 &lt;code&gt;C&lt;/code&gt; 从 &lt;code&gt;A&lt;/code&gt; 肯定是可达的。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;如果对象 &lt;code&gt;X&lt;/code&gt; 在 &lt;code&gt;di&lt;/code&gt; 被标记位不可达，则：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;从 &lt;code&gt;static&lt;/code&gt; 字段到 &lt;code&gt;di&lt;/code&gt;， &lt;code&gt;X&lt;/code&gt; 一定不可达；以及&lt;/li&gt;\n&lt;li&gt;线程 &lt;code&gt;t&lt;/code&gt; 中所有在 &lt;code&gt;di&lt;/code&gt; 之后对 &lt;code&gt;X&lt;/code&gt; 的所有活动使用必须发生在 &lt;code&gt;X&lt;/code&gt; 的 finalizer 调用中，或者线程 &lt;code&gt;t&lt;/code&gt; 在 &lt;code&gt;di&lt;/code&gt; 之后执行对 &lt;code&gt;X&lt;/code&gt; 的引用的读取的结果；以及&lt;/li&gt;\n&lt;li&gt;所有在 &lt;code&gt;di&lt;/code&gt; 之后的读操作，如果看到对 &lt;code&gt;X&lt;/code&gt; 的引用，就必须看到在 &lt;code&gt;di&lt;/code&gt; 处不可达的对象元素的写操作，或者在 &lt;code&gt;di&lt;/code&gt; 之后看到对象的写操作。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;动作 &lt;code&gt;a&lt;/code&gt; 是对 &lt;code&gt;X&lt;/code&gt; 的主动使用，当且仅当以下至少有一个为 true：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;读取或写入 &lt;code&gt;X&lt;/code&gt; 的元素&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;a&lt;/code&gt; 锁定或解锁 &lt;code&gt;X&lt;/code&gt;，并且在调用 &lt;code&gt;X&lt;/code&gt; 的 finalizer 之后，会在 &lt;code&gt;X&lt;/code&gt; 上发生一个锁定操作&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;a&lt;/code&gt; 写入一个对 &lt;code&gt;X&lt;/code&gt; 的引用&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;a&lt;/code&gt; 是一个对象 &lt;code&gt;Y&lt;/code&gt; 的主动使用，&lt;code&gt;X&lt;/code&gt; 从 &lt;code&gt;Y&lt;/code&gt; 肯定是可达的&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;如果对象 &lt;code&gt;X&lt;/code&gt; 在 &lt;code&gt;di&lt;/code&gt; 被标记为可终结，则：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;code&gt;X&lt;/code&gt; 必须在 &lt;code&gt;di&lt;/code&gt; 处被标记为不可达；以及&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;di&lt;/code&gt; 必须是 &lt;code&gt;X&lt;/code&gt; 被标记为可终结的唯一位置；以及&lt;/li&gt;\n&lt;li&gt;在 finalizer 调用之后发生的动作必须在 &lt;code&gt;di&lt;/code&gt; 之后。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;127-unloading-of-classes-and-interfaces\&#34;&gt;12.7 Unloading of Classes and Interfaces&lt;/h2&gt;\n&lt;p&gt;Java 编程语言的实现可以&lt;strong&gt;卸载&lt;/strong&gt;类。&lt;/p&gt;\n&lt;p&gt;当前仅当类或接口的定义类加载可以被垃圾回收期回收时，类或接口才可以被卸载，如 &lt;a href=\&#34;#126-finalization-of-class-instances\&#34;&gt;12.6&lt;/a&gt; 中所讨论的。&lt;/p&gt;\n&lt;p&gt;Bootstrap loader 加载的类和接口不能被卸载。&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;类卸载是一种优化，有助于减少内存使用。显然，程序的语义不应该依赖于系统是否以及如何选择实现优化，比如类卸载。否则会损害程序的可移植性。因此，一个类或接口是否被卸载对程序来说应该是透明的。&lt;/em&gt;&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;然而，如果一个类或接口&lt;/em&gt; &lt;code&gt;C&lt;/code&gt; &lt;em&gt;在它的定义加载器潜在地可达时被卸载，那么&lt;/em&gt; &lt;code&gt;C&lt;/code&gt; &lt;em&gt;可能被重新装载。谁也不能保证这不会发生。即使该类没有被任何其他当前加载的类引用，他也可能被尚未加载的某个类或接口&lt;/em&gt; &lt;code&gt;D&lt;/code&gt; &lt;em&gt;引用。当&lt;/em&gt; &lt;code&gt;D&lt;/code&gt; &lt;em&gt;被&lt;/em&gt; &lt;code&gt;C&lt;/code&gt; &lt;em&gt;的定义加载器加载时，它的执行可能会导致&lt;/em&gt; &lt;code&gt;C&lt;/code&gt; &lt;em&gt;的重新加载。&lt;/em&gt;&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;例如，如果类有&lt;/em&gt;  &lt;code&gt;static&lt;/code&gt; &lt;em&gt;变量（其状态会丢失），静态初始值设定项（可能有副作用）或&lt;/em&gt; &lt;code&gt;native&lt;/code&gt; &lt;em&gt;方法（可能保留静态状态），则重新加载可能不透明。此外，类对象的哈希值依赖它的身份。因此，一般来说，以完全透明的方式重新加载一个类或接口是不可能的。&lt;/em&gt;&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;因为我们永远不能保证卸载一个类或接口（其加载器是潜在可达的）不会导致重新加载，重新加载从来都不是透明的，但是卸载必须是透明的，所以当一个类或接口加载器是潜在可达的时候，我们不能卸载它。类似的推理可以用来推断由 Bootstrap loader 装载的类和加快永远不能被卸载。&lt;/em&gt;&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;人们还必须讨论为什么卸载一个类&lt;/em&gt; &lt;code&gt;C&lt;/code&gt; &lt;em&gt;是安全的，如果它的定义类加载器可以被回收的话。如果定义类加载器可以被回收，那么永远不会有对它的任何活动引用（这包括不活动的引用，但可能被 finalizer 复活）。反过来，只有当加载器定义的任何类（包括）&lt;/em&gt; &lt;code&gt;C&lt;/code&gt; &lt;em&gt;都不能有任何活动引用时，这种情况才会发送，无论是从它们的实例还是从代码。&lt;/em&gt;&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;类卸载是一种优化，它仅在对加载大量类并在一段时间后停止使用这些类的应用程序有意义。这种应用程序的一个主要例子是 web 浏览器，但还有其他应用程序。这种应用程序的一个特点是，它们通过显式使用类加载器来管理类。因此，上述政策对他们来说非常有效。&lt;/em&gt;&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;严格来说，本规范并没有讨论类卸载的问题，因为类卸载仅仅是一种优化。然而，这个问题非常精妙，因此在此作为澄清提及。&lt;/em&gt;&lt;/p&gt;\n&lt;h2 id=\&#34;128-program-exit\&#34;&gt;12.8 Program Exit&lt;/h2&gt;\n&lt;p&gt;当发生以下两种情况之一时，程序终止其所有活动并退出：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;所有不是守护线程的线程都会终止。&lt;/li&gt;\n&lt;li&gt;某线程调用类 &lt;code&gt;Runtime&lt;/code&gt; 或类 &lt;code&gt;System&lt;/code&gt; 的 &lt;code&gt;exit&lt;/code&gt; 方法，安全管理器不禁止 &lt;code&gt;exit&lt;/code&gt; 操作。&lt;/li&gt;\n&lt;/ul&gt;\n&#34;,&#34;fileName&#34;:&#34;chapter-12-execution&#34;,&#34;abstract&#34;:&#34;&lt;p&gt;此章节规定了程序执行期间发生的活动。他围绕 Java 虚拟机以及构成程序的类、接口和对象的声明周期进行组织编写。&lt;/p&gt;\n&lt;p&gt;Java 虚拟机通过加载指定的类然后调用该类中的 &lt;code&gt;main&lt;/code&gt; 方法来启动。第 &lt;a href=\&#34;#121-java-virtual-machine-startup\&#34;&gt;12.1&lt;/a&gt; 节概述了执行 main 所涉及的加载、链接和初始化步骤，作为本章节的概念的介绍。下一个部分讲述了加载 &lt;a href=\&#34;#122-loading-of-classes-and-interfaces\&#34;&gt;12.2&lt;/a&gt; 、链接  &lt;a href=\&#34;#123-linking-of-classes-and-interfaces\&#34;&gt;12.3&lt;/a&gt; 和初始化  &lt;a href=\&#34;#124-initialization-of-classes-and-interfaces\&#34;&gt;12.4&lt;/a&gt;  的细节。&lt;/p&gt;\n&lt;p&gt;本章后续部分说明创建新类实例的过程（第 &lt;a href=\&#34;#125-creation-of-new-class-instances\&#34;&gt;12.5&lt;/a&gt; 节 ）；和类实例的最终确定（ &lt;a href=\&#34;#126-finalization-of-class-instances\&#34;&gt;12.6&lt;/a&gt; ）。它通过描述类的卸载（第 &lt;a href=\&#34;#127-unloading-of-classes-and-interfaces\&#34;&gt;12.7&lt;/a&gt; 节 ）和程序退出时遵循的过程（第 &lt;a href=\&#34;#128-program-exit\&#34;&gt;12.8&lt;/a&gt; 节 ）来结束。&lt;/p&gt;\n&#34;,&#34;title&#34;:&#34;Chapter 12. Execution&#34;,&#34;tags&#34;:[{&#34;index&#34;:-1,&#34;name&#34;:&#34;Java SE 8 Language Specification&#34;,&#34;slug&#34;:&#34;nB3cU2iF3&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://wenbozhangw.github.io/tag/nB3cU2iF3/&#34;}],&#34;date&#34;:&#34;2022-06-02 14:37:24&#34;,&#34;dateFormat&#34;:&#34;2022-06-02&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://wenbozhangw.github.io/post/chapter-12-execution/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;44 min read&#34;,&#34;time&#34;:2593000,&#34;words&#34;:11873,&#34;minutes&#34;:44},&#34;description&#34;:&#34;此章节规定了程序执行期间发生的活动。他围绕 Java 虚拟机以及构成程序的类、接口和对象的声明周期进行组织编写。\nJava 虚拟机通过加载指定的类然后调用该类中的 main 方法来启动。第 12.1 节概述了执行 main 所涉及的加载、链...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#121-java-virtual-machine-startup\&#34;&gt;12.1 Java Virtual Machine Startup&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#1211-load-the-class-test\&#34;&gt;12.1.1 Load the Class Test&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#1212-link-test-verify-prepare-optionally-resolve\&#34;&gt;12.1.2 Link Test: Verify, Prepare, (Optionally) Resolve&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#1213-initialize-test-execute-initializers\&#34;&gt;12.1.3 Initialize Test: Execute Initializers&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#1214-invoke-testmain\&#34;&gt;12.1.4 Invoke Test.main&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#122-loading-of-classes-and-interfaces\&#34;&gt;12.2 Loading of Classes and Interfaces&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#1221-the-loading-process\&#34;&gt;12.2.1 The Loading Process&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#123-linking-of-classes-and-interfaces\&#34;&gt;12.3 Linking of Classes and Interfaces&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#1231-verification-of-the-binary-representation\&#34;&gt;12.3.1 Verification of the Binary Representation&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#1232-preparation-of-a-class-or-interface-type\&#34;&gt;12.3.2 Preparation of a Class or Interface Type&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#1233-resolution-of-symbolic-references\&#34;&gt;12.3.3 Resolution of Symbolic References&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#124-initialization-of-classes-and-interfaces\&#34;&gt;12.4 Initialization of Classes and Interfaces&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#1241-when-initialization-occurs\&#34;&gt;12.4.1 When Initialization Occurs&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#1242-detailed-initialization-procedure\&#34;&gt;12.4.2 Detailed Initialization Procedure&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#125-creation-of-new-class-instances\&#34;&gt;12.5 Creation of New Class Instances&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#126-finalization-of-class-instances\&#34;&gt;12.6 Finalization of Class Instances&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#1261-implementing-finalization\&#34;&gt;12.6.1 Implementing Finalization&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#1262-interaction-with-the-memory-model\&#34;&gt;12.6.2 Interaction with the Memory Model&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#127-unloading-of-classes-and-interfaces\&#34;&gt;12.7 Unloading of Classes and Interfaces&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#128-program-exit\&#34;&gt;12.8 Program Exit&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;h2 id=\&#34;51-引言\&#34;&gt;5.1 引言&lt;/h2&gt;\n&lt;p&gt;IP是 TCP/IP 协议族中的核心协议。所有 TCP、 UDP、 ICMP 和 IGMP 数据都通过 IP 数据报传输。 IP 提供了一种尽力而为、无连接的数据报交付服务。 “尽力而为”的含义是不保证 IP 数据报能成功到达目的地。虽然 IP 不是简单丢弃所有不必要流量，但它也不对自己尝试交付的数据报提供保证。当某些错误发生时，例如一台路由器临时用尽缓冲区， IP 提供一个简单的错误处理方法： 丢弃一些数据（通常是最后到达的数据报）。任何可靠性必须由上层（例如 TCP）提供。 IPv4 和 IPv6 都使用这种尽力而为的基本交付模式。&lt;/p&gt;\n&lt;p&gt;“&lt;strong&gt;无连接&lt;/strong&gt;”意味着 IP 不维护网络单元（即路由器）中数据报相关的任何链接状态信息，每个数据报独立于其他数据报来处理。这也意味着 IP 数据报可不按顺序交付。如果一个源主机向同一目的地发送两个连续的数据报（第一个为 A，第二个为 B），每个数据报可以独立路由，通过不同路径，并且 B 可能在 A 之前到达。 IP 数据报也可能发生其他问题：它们可能在传输过程中被复制，可能改变内容从而导致错误。此外， IP 之上的一些协议（通常是 TCP）需要处理这些潜在问题，以便为应用提供无差错的交付。&lt;/p&gt;\n&lt;!-- more --&gt;\n&lt;p&gt;本章我们首先看一下 IPv4 （见图 5-1）和 IPv6 （见图 5-2）头部中的字段，然后描述 IP 如何转发。[&lt;a href=\&#34;#RFC0791\&#34;&gt;RFC0791&lt;/a&gt;] 是针对 IPv4 的正式规范。描述 IPv6 的一系列 RFC 从 [&lt;a href=\&#34;#RFC2460\&#34;&gt;RFC2460&lt;/a&gt;] 开始。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;1\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1653556210920.png\&#34; alt=\&#34;图 5-1\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 5-1   IPv4 数据报。头部大小可变， 4 位的 IHL 字段被限制为 15 个 32 位字（60字节）。一个典型的 IPv4 头部包含 20 字节（没有选项）。源地址和目的地址的长度为 32 位。第二个 32 位字的大部分用于 IPv4 分片功能。头部校验和有助于确保头部字段被正确发送到目的地，但不保护数据内容&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;2\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1653556327941.png\&#34; alt=\&#34;图 5-2\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 5-2    IPv6 头部大小固定（40 字节），并包含 128 位源地址和目的地址。下一个头部字段用于说明 IPv6 头部之后其他扩展头部的存在和类型，它们形成一条包括特殊扩展或处理指令的头部链。应用数据跟在这条头部链之后，通常紧跟着是一个传输层头部&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;52-ipv4-头部和-ipv6-头部\&#34;&gt;5.2 IPv4 头部和 IPv6 头部&lt;/h2&gt;\n&lt;p&gt;图 5-1 显示了 IPv4 数据报格式。正常的 IPv4 头部大小为 20 字节，除非存在选项（这种情况很少见）。 IPv6 头部长度是它的两倍，但没有任何选项。它可以有扩展头部，可提供类似的功能，我们将在后面看到。在关于 IP 头部和数据报的印象中，最高有效位在左侧且编号为 0，一个 32 位值的最低有效位在右侧且编号为 31。&lt;/p&gt;\n&lt;p&gt;一个 32 位值的 4 字节按以下顺序传输：首先是 0 ~ 7 位，然后是 8 ~ 15 位，接着是 16 ~ 23 位，最后是 24 ~ 31 位。这就是所谓的&lt;strong&gt;高位优先&lt;/strong&gt;字节序，它是 TCP/IP 头部中所有二进制整数在网络中传输时所需的字节顺序。它也被称为网络字节序。计算机的 CPU 使用其他格式存储二进制整数，例如大多数 PC 使用低位优先字节序，在传输时必须将头部值转换为网络字节序，并在接收时再转换回来。&lt;/p&gt;\n&lt;h3 id=\&#34;521-ip-头部字段\&#34;&gt;5.2.1 IP 头部字段&lt;/h3&gt;\n&lt;p&gt;第一个字段（只有 4 位或半个字节）是版本字段。它包含 IP 数据报的版本号：IPv4 为 4， IPv6 为 6。IPv4 头部和 IPv6 头部除版本字段位置相同外再无其他是一样的。因此，这两个协议不能直接互操作，主机或路由器必须分别处理 IPv4 或 IPv6 （或两者，称为&lt;strong&gt;双栈&lt;/strong&gt;）。虽然也提出并发展了其他 IP 版本，但只有版本 4 和 6 经常使用。 IANA 负责保存这些版本号的正式注册信息 [&lt;a href=\&#34;#IV\&#34;&gt;IV&lt;/a&gt;]。&lt;/p&gt;\n&lt;p&gt;**Internet 头部长度（IHL）**字段保存 IPv4 头部中 32 位字的数量，包括任何选项。由于它是一个 4 位的字段，所以 IPv4 头部被限制为最多 15 个 32 位字，即 60 字节。后面，我们将看到，这种限制使一些选项（例如“记录路由”选项）当前几乎无法使用。这个字段的正常值（当没有选项时）是 5。 IPv6 中不存在这个字段，其头部长度固定为 40 字节。&lt;/p&gt;\n&lt;p&gt;在头部长度之后， IPv4 [&lt;a href=\&#34;#RFC0791\&#34;&gt;RFC0791&lt;/a&gt;] 的最初规范指定了一个&lt;strong&gt;服务类型（ToS）&lt;strong&gt;字段，IPv6 [&lt;a href=\&#34;#RFC2460\&#34;&gt;RFC2460&lt;/a&gt;] 指定了一个等效的&lt;/strong&gt;通信类型&lt;/strong&gt;字段。由于它们从来没被广泛使用，因此最终这个 8 位长的字段被分为两个部分，并由一组 RFC（ [&lt;a href=\&#34;#RFC3260\&#34;&gt;RFC3260&lt;/a&gt;] [&lt;a href=\&#34;#RFC3168\&#34;&gt;RFC3168&lt;/a&gt;] [&lt;a href=\&#34;#RFC2474\&#34;&gt;RFC2474&lt;/a&gt;] 和其他 RFC）重新定义。目前，前 6 位被称为&lt;strong&gt;区分服务&lt;/strong&gt;字段（DS字段），后 2 位是**显式拥塞通知（ECN）**字段或指示位。现在，这些 RFC 适用于 IPv4 和 IPv6。这些字段被用于数据报转发时的特殊处理。我们将在 5.2.3 节中详细讨论它们。&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;总长度&lt;/strong&gt;字段是 IPv4 数据报的总长度（以字节为单位）。通过这个字段和 IHL 字段，我们知道数据报的数据部分从哪里开始，以及它的长度。由于它是一个 16 位的字段，所以 IPv4 数据报的最大长度（包括头部）为 65535 字节。由于一些携带 IPv4 数据报的低层协议不能（精确）表达自己封装的数据报大小，所以需要在头部中给出总长度字段。例如，以太网会将短帧填充到最小长度（64 字节）。虽然以太网最小有效载荷为 46 字节（见第 3 章），但一个 IPv4 数据报也可能会更小（20 字节）。如果没有提供总长度字段， IPv4 实现将无法知道一个 46 字节的以太网帧是一个 IP 数据报，还是经过填充的 IP 数据报，这样可能会导致混淆。&lt;/p&gt;\n&lt;p&gt;尽管可发送一个 65535 字节的IP数据报，但大多数链路层（例如以太网）不能携带这么大的数据，除非将它分（拆）成更小的片。另外，主机不需要接收大于 576 字节的 IPv4 数据报。 （在 IPv6 中，主机需要能处理所连接链路 MTU 大小的数据报，而最小链路 MTU 为 1280 字节。）很多使用 UDP 协议（见第 10 章）传输数据（例如 DNS、DHCP 等）的应用程序，限制为使用 512 字节大小的数据，以避免 576 字节的 IPv4 限制。 TCP 根据额外信息（见第 15 章）选择自己的数据报大小。&lt;/p&gt;\n&lt;p&gt;当一个 IPv4 数据报被分为多个更小的分片时，每个分片自身仍是一个独立的 IP 数据报，总长度字段反映具体的分片长度。第 10 章中将详细介绍分片和 UDP。IPv6 头部不支持分片，其长度可由&lt;strong&gt;负载长度&lt;/strong&gt;字段获得。这个字段提供 IPv6 数据报长度，不包括头部长度，但扩展头部包括在&lt;strong&gt;负载长度&lt;/strong&gt;中。对于 IPv4，这个 16 位的字段限制其最大值为 65535。对于 IPv6，&lt;strong&gt;负载长度&lt;/strong&gt;被限制为 64KB，而不是整个数据报。另外， IPv6 还支持一个超长数据报选项（见 5.3.1.2 节），它至少在理论上提供了可能性，即单个分组的有效载荷可达到 4GB （4294967295 字节）!&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;标识&lt;/strong&gt;字段帮助标识由 IPv4 主机发送的数据报。为了避免将一个数据报分片和其他数据报分片混淆，发送主机通常在每次（从它的一个 IP 地址）发送数据报时都将一个内部计数器加 1，并将该计数器值复制到 &lt;strong&gt;IPv4 标识&lt;/strong&gt; 字段。这个字段对实现分片很重要，因此我们将在第 10 章中进一步讨论，另外还会讨论标志和分片偏移字段。在 IPv6 中，这个字段显示在分片扩展头部中，我们将在 5.3.3 节中讨论。&lt;/p&gt;\n&lt;p&gt;**生存期（TTL）**字段用于设置一个数据报可经过的路由器数量的上限。发送方将它初始化为某个值（[&lt;a href=\&#34;#RFC1122\&#34;&gt;RFC1122&lt;/a&gt;] 建议为 64，但 128 或 255 也不少见），每台路由器在转发数据报时将该值减 1。当这个字段值达到 0 时，该数据报被丢弃，并使用一个 ICMP 消息通知发送方（见第 8 章）。.这可以防止由于出现不希望的路由环路而导致数据报在网络中永远循环。&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;注意    TTL 字段最初指定 IP 数据报的最大生存期在几秒钟内，但路由器总需要将\n这个值至少减 1。 实际上，当前路由器在正常操作下通常不会持有数据报超过 1 秒\n钟，因此较早的规则现在已被忽略或遗忘，这个字段在 IPv6 中根据实际用途已被\n重新命名为跳数限制。\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;IPv4 头部中的&lt;strong&gt;协议&lt;/strong&gt;字段包含一个数字，表示数据报有效载荷部分的数据类型。最常用的值为 17 （UDP）和 6 （TCP）。这提供了多路分解的功能，以便 IP 协议可用于携带多种协议类型的有效载荷。虽然该字段最初仅用于指定数据报封装的传输层协议，但它现在用于识别其中封装的协议是否为一种传输层协议。其他封装也是可能的，例如 IPv4-in-IPv4 （值为 4）。数字分配页面 [&lt;a href=\&#34;#AN\&#34;&gt;AN&lt;/a&gt;] 给出了可能的协议字段值的正式列表。 IPv6 头部中的下一个&lt;strong&gt;头部&lt;/strong&gt;字段给出了 IPv4 中的协议字段。它用于指出 IPv6 头部之后的头部类型。这个字段可能包含由 IPv4 协议字段定义的任何值，或 5.3 节中描述的 IPv6 扩展头部的相关值。&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;头部校验和&lt;/strong&gt;字段仅计算 IPv4 头部。理解这一点很重要，因为这意味着 IP 协议不检查 IPv4 数据报有效载荷（例如 TCP 或 UDP 数据）的正确性。为了确保 IP 数据报的有效载荷部分已正确传输，其他协议必须通过自己的数据完整性检验机制来检查重要数据。我们看到，封装在 IP 中的几乎所有协议（ICMP、 IGMP、 UDP 和 TCP）在自己头部中都有一个涵盖其头部和数据的校验和，也涵盖它们认为重要的 IP 头部的某些部分（一种“违反分层”的形式）。令人惊讶的是， IPv6 头部没有任何校验和字段。&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;注意    IPv6 头部省略校验和字段是一个有争议的决定。这个行动背后的理由大致\n如下：在 IP 头部中，更高层协议为确定正确性，必须计算它们自己的校验和，这\n需要涵盖它们认为重要的数据。 IP 头部中的错误带来的后果是：数据被投递到错误\n的目的地、指示数据来源错误，或在交付过程中错位。由于位错误比较少见（受益\n于 Internet 流量的光纤传输），而且其他字段提供了更有力的确保正确性的机制（更\n高层次的校验和或其他检查），因此决定从 IPv6 头部中删除这个字段。\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;大多数使用校验和的其他 Internet 相关协议也使用该校验和计算算法，因此有时称之为 &lt;strong&gt;Internet 校验和&lt;/strong&gt;。注意，当一个 IPv4 数据报经过一台路由器时， TTL 字段减 1 带来的结果是其头部校验和必须改变。找们将在 5.2.2 节详细讨论校验和计算方法。&lt;/p&gt;\n&lt;p&gt;每个 IP 数据报包含发送者的&lt;strong&gt;源 IP 地址&lt;/strong&gt;和接收者的&lt;strong&gt;目的 IP 地址&lt;/strong&gt;。这些针对 IPv4 的 32 位地址和针对 IPv6 的 128 位地址，通常标识一台计算机的一个接口，但组播地址和广播地址（见第 2 章）不符合本规则。虽然一个 32 位地址可容纳看似很多 Internet 实体（2&lt;sup&gt;32&lt;/sup&gt; 个），但一个广泛的共识是这个数字仍不够，这是向 IPv6 迁移的一个主要动机。 IPv6 的 128 位地址可容纳数量庞大的 Internet 实体。 [&lt;a href=\&#34;#H05\&#34;&gt;H05&lt;/a&gt;] 进行了重新统计， IPv6 拥有 3.4 × 10&lt;sup&gt;38&lt;/sup&gt; 个地址。引用 [&lt;a href=\&#34;#H05\&#34;&gt;H05&lt;/a&gt;]  和其他人的话：“乐观估计将使地球上每平方米表面拥有 3 911 873 538 269 506 102 个地址。”这确实看起来可持续很长一段时间。&lt;/p&gt;\n&lt;h3 id=\&#34;522-internet-校验和\&#34;&gt;5.2.2 Internet 校验和&lt;/h3&gt;\n&lt;p&gt;Internet 校验和是一个 16 位的数字和，它能以相当高的概率确定接收的消息或其中的部分内容是否与发送的相匹配。注意，Internet 校验和算法与常见的&lt;strong&gt;循环冗余校验（CRC）&lt;/strong&gt;[&lt;a href=\&#34;#PB61\&#34;&gt;PB61&lt;/a&gt;] 不同，后者提供了更强的保护功能。&lt;/p&gt;\n&lt;p&gt;为了给输出的数据报计算 IPv4 头部校验和，首先将数据报的校验和字段值设置为 0。然后，对头部（整个头部被认为是一个 16 位字的序列）计算 16 位二进制反码和。这个 16 位二进制反码和被存储在&lt;strong&gt;校验和&lt;/strong&gt;字段中。二进制反码加法可通过“循环进位（end-round-carry）加法”实现：当使用传统（二进制补码）加法产生一个进位时，这个进位以二进制值 1 加在高位。图 5-3 显示了这个例子，消息内容使用十六进制表示。&lt;/p&gt;\n&lt;p&gt;图 5-3    Internet 校验和是一个被校验数据（如果被计算的字节数为奇数，用 0 填充）的 16 位反码和的反码。如果被计算数据包括一个校验和字段，该字段在计算校验和运算之前被设置为 0，然后将计算出的校验和填充到该字段。为了检查一个包含校验和字段（头部、有效载荷等）的数据输入是否有效，需要对整个数据块（包含校验和字段）同样计算校验和。由于校验和字段本质上是其余数据校验和的反码，对正确接收的数据计算校验和应产生一个值 0&lt;/p&gt;\n&lt;p&gt;当一个 IPv4 数据报被接收时，对整个头部计算出一个校验和，包括校验和字段自身的值。假设这里没有错误，计算出的校验和值为 0 （值 FFFF 的反码）。注意，对于任何不正常的分组或头部，分组中的校验和字段值不为 FFFF。如果是这样，这个和（在发送方的最后一次反码运算之前）将为 0。通过反码加法得到的和不能永远为 0，除非所有字节都是 0，这在任何合法 IPv4 头部中都不可能出现。当发现一个头部出错（计算的校验和不为 0）时， IPv4 实现将丢弃接收到的数据报。但是，不会生成差错信息。更高层以某种方式检测丢失的数据报，并在必要时重新传输。&lt;/p&gt;\n&lt;h4 id=\&#34;5221-internet-校验和数学性质\&#34;&gt;5.2.2.1 Internet 校验和数学性质&lt;/h4&gt;\n&lt;p&gt;在数学上， 16 位的十六进制值集合 V = {0001， …， FFFF} 与其反码和运算“+”共同形成一个阿贝尔群。将一个集合和一个运算符组合到一组时，必须符合以下性质：闭包、结合性、存在一个恒等元素，以及存在可逆。要形成一个阿贝尔（可交换的）群，还必须满足交换性。如果我们仔细观察，可看到所有特性实际上都服从：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;对于 V 中的任何 X、Y、（X + Y） 在 V 中  [闭包]&lt;/li&gt;\n&lt;li&gt;对于 V 中的任何 X、Y、Z，X +（Y + Z） = （X + Y） + Z                 [结合性]&lt;/li&gt;\n&lt;li&gt;对于 V 中的任何 X，e + X = X + e = X，其中 e = FFFF                 [恒等]&lt;/li&gt;\n&lt;li&gt;对于 V 中的任何 X，有一个 X&#39; 在 V 中，使得 X + X&#39; = e                  [可逆]&lt;/li&gt;\n&lt;li&gt;对于 V 中的任何 X、Y，（X + Y）=（Y +X）                      [交换性]&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;关于集合 V 和组 &amp;lt;V， +&amp;gt;，有趣的是我们已删除 0000。如果我们将数字 0000 放入集合 V，这时 &amp;lt;V， +&amp;gt; 不再是一个组。为了看清这点，我们首先观察 0000 和 FFFF 作为 0 （加性恒等）出现在使用“+”的运算中的情况。例如，AB12 + 0000= AB1 2= AB12+FFFF。但是，在一个组中只能有一个恒等元素。如果我们包含元素 12AB，并假设恒等元素为 0000，那么我们就需要某个可逆数 X′ 使得 （12AB  + X′）= 0000，但我们发现，在 V 中没有满足此条件的 X&#39; 存在。因此，我们需要排除 0000 作为&amp;lt;V， +&amp;gt; 中的恒等元素，通过将它从集合 V 中删除，使得这种结构成为一个满足要求的组。这里仅对抽象代数做一个简单介绍，读者若希望详细阅读这方面内容，可参考 Pinter [&lt;a href=\&#34;#P90\&#34;&gt;P90&lt;/a&gt;] 的畅销书。&lt;/p&gt;\n&lt;h3 id=\&#34;523-ds-字段和-ecn-以前称为-tos-字节或-ipv6-流量类别\&#34;&gt;5.2.3 DS 字段和 ECN （以前称为 ToS 字节或 IPv6 流量类别）&lt;/h3&gt;\n&lt;p&gt;IPv4 头部的第 3 和第 4 字段（IPv6 头部的第 2 和第 3 字段）分别是&lt;strong&gt;区分服务（称为 DS 字段）&lt;strong&gt;和 &lt;strong&gt;ECN 字段&lt;/strong&gt;。区分服务（称为 DiffServ）是一个框架和一组标准，用于支持 Internet [&lt;a href=\&#34;#RFC2474\&#34;&gt;RFC2474&lt;/a&gt;] [&lt;a href=\&#34;#RFC2475\&#34;&gt;RFC2475&lt;/a&gt;] [&lt;a href=\&#34;#RFC3260\&#34;&gt;RFC3260&lt;/a&gt;] 上不同类型的服务（即不只是尽力而为服务）。 IP 数据报以某种方式（通过预定义模式设置某些位）被标记，使它们的转发不同于（例如以更高的优先级）其他数据报。这样做可能导致网络中排队延时的增加或减少，以及出现其他特殊效果（可能与 ISP 收取的特殊费用相关）。 &lt;strong&gt;DS 字段&lt;/strong&gt;中的数字称为&lt;/strong&gt;区分服务代码点（DSCP）&lt;/strong&gt;。 “代码点”指的是预定义的具有特定含义的位。在通常情况下，如果数据报拥有一个分配的 DSCP，它在通过网络基础设施交付过程中会保持不变。但是，某些策略（例如在一段时间内可发送多少个高优先级的分组）可能导致一个数据报中的 DSCP 在交付过程中改变。&lt;/p&gt;\n&lt;p&gt;当通过一台具有内部排队流量的路由器时，头部中的 2 位 ECN 位用于为数据报标记&lt;strong&gt;拥塞标识符&lt;/strong&gt;。一台持续拥塞的具有 ECN 感知能力的路由器在转发分组时会设置这两位。这种功能的设计思路是，当一个被标记的分组被目的节点接收时，有些协议（例如 TCP）会发现分组被标记并将这种情况通知发送方，发送方随后会降低发送速度，这样可在路由器因过载而被迫丢弃流量之前缓解拥塞。这种机制是避免或处理网络拥塞的方法之一，我们将在第 16 章中详细探讨。虽然 &lt;strong&gt;DS 字段&lt;/strong&gt;和 &lt;strong&gt;ECN 字段&lt;/strong&gt;并不密切相关，但它们被用作代替以前定义的** IPv4 服务类型&lt;strong&gt;和&lt;/strong&gt; IPv6 流量类别**字段。因此，它们经常被放在一起讨论，术语“ToS 字节”和“流量类别字节”仍在广泛使用。&lt;/p&gt;\n&lt;p&gt;尽管原来的 ToS 和流量类别字节没得到广泛支持，但 DS 字段结构仍提供了一些对它们的兼容能力。为了对其如何工作有更清楚的了解，我们首先回顾服务类型字段 [&lt;a href=\&#34;#RFC0791\&#34;&gt;RFC0791&lt;/a&gt;] 的原始结构，如图 5-4 所示。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;3\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1653567934848.png\&#34; alt=\&#34;图 5-4\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 5-4    原来的 &lt;strong&gt;IPv4 服务类型&lt;/strong&gt; 和 &lt;strong&gt;IPv6 流量类别&lt;/strong&gt; 字段结构。&lt;strong&gt;优先级&lt;/strong&gt;子字段用于表示哪些分组具有更高优先级（较大的值意味着更高的优先级）。D、T 和 R 子字段分别用于表示延时、吞吐量和可靠性。如果这些字段值为 1，分别对应于低延时、高吞吐量和高可靠性&lt;/p&gt;\n&lt;p&gt;D、 T 和 R 子字段表示数据报在延时、吞吐量和可靠性方面得到良好的处理。相应值为 1 表示更好的处理（分别为低延时、高吞吐量和高可靠性）。优先级取值范围是从 000 （常规）到 111 （网络控制），表示优先级依次递增（见表 5-1）。它们都基于一个称为**多级优先与抢占（MLPP）**的方案，该方案可追溯到美国国防部的 AUTOVON 电话系统 [&lt;a href=\&#34;#A92\&#34;&gt;A92&lt;/a&gt;]，其中较低优先级的呼叫可被更高优先级的呼叫抢占。这些术语仍在使用，并被纳入 VoIP 系统中。&lt;/p&gt;\n&lt;center&gt; 表 5-1    原来的 IPv4 服务类型和 IPv6 流量类别 的优先级子字段值 &lt;/center&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;值&lt;/th&gt;\n&lt;th&gt;优先级名称&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;000&lt;/td&gt;\n&lt;td&gt;常规&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;001&lt;/td&gt;\n&lt;td&gt;优先级&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;010&lt;/td&gt;\n&lt;td&gt;立即&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;011&lt;/td&gt;\n&lt;td&gt;瞬间&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;100&lt;/td&gt;\n&lt;td&gt;瞬间覆盖&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;101&lt;/td&gt;\n&lt;td&gt;严重&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;110&lt;/td&gt;\n&lt;td&gt;网间控制&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;111&lt;/td&gt;\n&lt;td&gt;网络控制&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;p&gt;在定义 &lt;strong&gt;DS 字段&lt;/strong&gt;时，优先级的值已定义在 [&lt;a href=\&#34;#RFC2474\&#34;&gt;RFC2474&lt;/a&gt;] 中，以提供有限的兼容性。在图 5-5 中， 6 位 &lt;strong&gt;DS 字段&lt;/strong&gt;用于保存 DSCP，提供对 64 个代码点的支持。特定 DSCP 值可通知路由器对接收的数据报进行转发或特殊处理。不同类型的转发处理表示为&lt;strong&gt;每跳行为（PHB）&lt;/strong&gt;，因此 DSCP 值可有效通知路由器哪种 PHB 被应用于数据报。 DSCP 的默认值通常为 0，对应于常规的尽力而为的 Internet 流量。 64 个可能的 DSCP 值分为不同用途，它们可从 [&lt;a href=\&#34;#DSCPREG\&#34;&gt;DSCPREG&lt;/a&gt;] 中获得，如表 5-2 所示。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;4\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1653568463910.png\&#34; alt=\&#34;图 5-5\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 5-5    &lt;strong&gt;DS 字段&lt;/strong&gt;包含 6 位（其中 5 位当前是标准的，表示当前接收的数据报应转发时，可由一台兼容的路由器转发）。后面 2 位用作 ECN，当数据报通过持续拥塞的路由器时设置。当这些数据报到达目的地时，稍后发送一个包含拥塞指示的数据报给发送方，通知该数据报经过一台或多台拥塞的路由器&lt;/p&gt;\n&lt;center&gt; 表 5-2    DSCP 值被分成 3 个池：标准的、实验/本地用途的（EXP/LU）和最终打算标准化的实验/本地用途的（*） &lt;/center&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;池&lt;/th&gt;\n&lt;th&gt;代码店前缀&lt;/th&gt;\n&lt;th&gt;策略&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;xxxxx0&lt;/td&gt;\n&lt;td&gt;标准的&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;td&gt;xxxx11&lt;/td&gt;\n&lt;td&gt;EXP/LU&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;3&lt;/td&gt;\n&lt;td&gt;xxxx01&lt;/td&gt;\n&lt;td&gt;EXP/LU（*）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;p&gt;这个方案供研究人员和操作人员用于实验或本地用途。以 0 作为结尾的 DSCP 用于标准用途，以 1 作为结尾的 DSCP 用于实验或本地用途。以 01 作为结尾的 DSCP 最初打算用于实验或本地用途，但最终会走向标准化。&lt;/p&gt;\n&lt;p&gt;在图 5-5 中， &lt;strong&gt;DS 字段&lt;/strong&gt;中的类别部分包含前 3 位，并基于较早定义的&lt;strong&gt;服务类型&lt;/strong&gt;的优先级子字段。路由器通常先将流量分为不同类别。常见类别的流量可能有不同的丢弃概率，如果路由器被迫丢弃流量，允许路由器确定首先丢弃哪些流量。 3 位的类别选择器提供了 8 个定义的代码点（称为&lt;strong&gt;类别选择代码点&lt;/strong&gt;），它们对应于一个指定最小功能集的 PHB，提供与早期的 IP 优先级相似的功能。它们称为&lt;strong&gt;类别选择兼容的 PHB&lt;/strong&gt;，目的是支持部分兼容的最初定义的 IP 优先级子字段 [&lt;a href=\&#34;#RFC0791\&#34;&gt;RFC0791&lt;/a&gt;] 。 &lt;code&gt;xxx000&lt;/code&gt; 形式的代码点总被映射为这种 PHB，但是其他值也可映射到相同 PHB。&lt;/p&gt;\n&lt;p&gt;表 5-3 给出了类别选择器的 DSCP 值，以及 [&lt;a href=\&#34;#RFC0791\&#34;&gt;RFC0791&lt;/a&gt;] 定义的 IP 优先级字段的相应术语。&lt;strong&gt;保证转发（AF）&lt;strong&gt;组对固定数量的独立 AF 类别的 IP 分组提供转发，它有效地概括了优先级的概念。某个类别的流量与其他类别的流量分别转发。在一个流量类别中，数据报被分配一个&lt;/strong&gt;丢弃优先级&lt;/strong&gt;。在一个类别中，较高丢弃优先级的数据报优先于那些较低丢弃优先级的数据报处理（即以较高优先级转发）。结合流量类别和丢弃优先级，名称 AFij 对应于保证转发类别 i 的丢弃优先级 j。例如，一个标记为 AF32 的数据报的流量类别为 3，丢弃优先级为 2。&lt;/p&gt;\n&lt;center&gt;表 5-3 DS 字段值设计为兼容服务类型和 IPv6 流量类别字段中指定的 IP 优先级字段。 AF 和 EF 提供比简单的“尽力而为”更好的服务&lt;/center&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;名称&lt;/th&gt;\n&lt;th&gt;值&lt;/th&gt;\n&lt;th&gt;参考文献&lt;/th&gt;\n&lt;th&gt;描述&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;CS0&lt;/td&gt;\n&lt;td&gt;000000&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2474\&#34;&gt;RFC2474&lt;/a&gt;]&lt;/td&gt;\n&lt;td&gt;类别选择（尽力而为/常规）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;CS1&lt;/td&gt;\n&lt;td&gt;001000&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2474\&#34;&gt;RFC2474&lt;/a&gt;]&lt;/td&gt;\n&lt;td&gt;类别选择（优先）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;CS2&lt;/td&gt;\n&lt;td&gt;010000&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2474\&#34;&gt;RFC2474&lt;/a&gt;]&lt;/td&gt;\n&lt;td&gt;类别选择（立即）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;CS3&lt;/td&gt;\n&lt;td&gt;011000&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2474\&#34;&gt;RFC2474&lt;/a&gt;]&lt;/td&gt;\n&lt;td&gt;类别选择（瞬间）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;CS4&lt;/td&gt;\n&lt;td&gt;100000&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2474\&#34;&gt;RFC2474&lt;/a&gt;]&lt;/td&gt;\n&lt;td&gt;类别选择（瞬间覆盖）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;CS5&lt;/td&gt;\n&lt;td&gt;101000&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2474\&#34;&gt;RFC2474&lt;/a&gt;]&lt;/td&gt;\n&lt;td&gt;类别选择（CRITIC/ECP）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;CS6&lt;/td&gt;\n&lt;td&gt;110000&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2474\&#34;&gt;RFC2474&lt;/a&gt;]&lt;/td&gt;\n&lt;td&gt;类别选择（网间控制）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;CS7&lt;/td&gt;\n&lt;td&gt;111000&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2474\&#34;&gt;RFC2474&lt;/a&gt;]&lt;/td&gt;\n&lt;td&gt;类别选择（控制）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;AF11&lt;/td&gt;\n&lt;td&gt;001010&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2597\&#34;&gt;RFC2597&lt;/a&gt;]&lt;/td&gt;\n&lt;td&gt;保证转发（1，1）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;AF12&lt;/td&gt;\n&lt;td&gt;001100&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2597\&#34;&gt;RFC2597&lt;/a&gt;]&lt;/td&gt;\n&lt;td&gt;保证转发（1，2）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;AF13&lt;/td&gt;\n&lt;td&gt;001110&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2597\&#34;&gt;RFC2597&lt;/a&gt;]&lt;/td&gt;\n&lt;td&gt;保证转发（1，3）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;AF21&lt;/td&gt;\n&lt;td&gt;010010&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2597\&#34;&gt;RFC2597&lt;/a&gt;]&lt;/td&gt;\n&lt;td&gt;保证转发（2，1）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;AF22&lt;/td&gt;\n&lt;td&gt;010100&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2597\&#34;&gt;RFC2597&lt;/a&gt;]&lt;/td&gt;\n&lt;td&gt;保证转发（2，2）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;AF23&lt;/td&gt;\n&lt;td&gt;010110&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2597\&#34;&gt;RFC2597&lt;/a&gt;]&lt;/td&gt;\n&lt;td&gt;保证转发（2，3）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;AF31&lt;/td&gt;\n&lt;td&gt;011010&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2597\&#34;&gt;RFC2597&lt;/a&gt;]&lt;/td&gt;\n&lt;td&gt;保证转发（3，1）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;AF32&lt;/td&gt;\n&lt;td&gt;011100&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2597\&#34;&gt;RFC2597&lt;/a&gt;]&lt;/td&gt;\n&lt;td&gt;保证转发（3，2）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;AF33&lt;/td&gt;\n&lt;td&gt;011110&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2597\&#34;&gt;RFC2597&lt;/a&gt;]&lt;/td&gt;\n&lt;td&gt;保证转发（3，3）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;AF41&lt;/td&gt;\n&lt;td&gt;100010&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2597\&#34;&gt;RFC2597&lt;/a&gt;]&lt;/td&gt;\n&lt;td&gt;保证转发（4，1）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;AF42&lt;/td&gt;\n&lt;td&gt;100100&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2597\&#34;&gt;RFC2597&lt;/a&gt;]&lt;/td&gt;\n&lt;td&gt;保证转发（4，2）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;AF43&lt;/td&gt;\n&lt;td&gt;100110&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2597\&#34;&gt;RFC2597&lt;/a&gt;]&lt;/td&gt;\n&lt;td&gt;保证转发（4，3）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;EF PHB&lt;/td&gt;\n&lt;td&gt;101110&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC3246\&#34;&gt;RFC3246&lt;/a&gt;]&lt;/td&gt;\n&lt;td&gt;加速转发&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;VOICE-ADMIT&lt;/td&gt;\n&lt;td&gt;101100&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC5865\&#34;&gt;RFC5865&lt;/a&gt;]&lt;/td&gt;\n&lt;td&gt;容量许可的流量&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;p&gt;**加速转发（EF）**提供了非拥塞的网络服务，也就是说， EF 流量应享受较低的延时、抖动和丢包率。直观地说， EF 流量要求路由器的输出速率至少比输入速率大。因此，在一台路由器的队列中， EF 流量仅排在其他 EF 流量之后。&lt;/p&gt;\n&lt;p&gt;为了在 Internet 中提供差异化服务，目前已持续进行十多年的努力。虽然大部分机制的标准化开始于 20 世纪 90 年代末，但其中有些功能直到 21 世纪才被实现。 [&lt;a href=\&#34;#RFC4594\&#34;&gt;RFC4594&lt;/a&gt;] 给出了一些关于如何配置系统以利用该功能的指导。差异化服务的复杂性在于：差异化服务和假设的差异化定价结构之间的联系，以及由此产生的公平问题。这种经济关系是复杂的，并且不在我们讨论的范围内。关于这个问题和相关主题的更多信息，详见 [&lt;a href=\&#34;#MB97\&#34;&gt;MB97&lt;/a&gt;] 和 [&lt;a href=\&#34;#W03\&#34;&gt;W03&lt;/a&gt;] 。&lt;/p&gt;\n&lt;h3 id=\&#34;524-ip-选项\&#34;&gt;5.2.4 IP 选项&lt;/h3&gt;\n&lt;p&gt;IP 支持一些可供数据报选择的选项。 [&lt;a href=\&#34;#RFC0791\&#34;&gt;RFC0791&lt;/a&gt;] 介绍了大多数的选项，当时处于 IPv4 设计阶段， Internet 的规模相当小，对来自恶意用户的威胁关注较少。由于 IPv4 头部大小的限制以及相关的安全问题，因此很多选项不再是实用或可取的。在 IPv6 中，大部分选项已被删除或改变，不再是 IPv6 基本头部的一部分，而被放在 IPv6 头部之后的一个或多个扩展头部中。 IP 路由器接收到一个包含选项的数据报，通常需要对该数据报进行特殊处理。在某些情况下，尽管 IPv6 路由器可以处理扩展头部，但很多头部被设计为仅由终端主机处理。在有些路由器中，带选项或扩展的数据报不会像普通数据报那样被快速转发。作为相关的背景知识，我们简要讨论 IPv4 选项，以及 IPv6 如何实现扩展头部和选项。表 5-4 显示了经过多年标准化的 IPv4 选项。&lt;/p&gt;\n&lt;p&gt;表 5-4 给出了保留的 IPv4 选项，它们可在描述性的 RFC 中找到。这个完整的列表会定期更新，并可在 [&lt;a href=\&#34;#IPPARAM\&#34;&gt;IPPARAM&lt;/a&gt;] 中在线查看。选项的范围总是以 32 位为界。如果有必要，数值 0 作为填充字节被添加。这确保 IPv4 头部始终是 32 位的倍数（IHL 字段的要求）。表 5-4 中的“编号”列是选项编号。 “值”列给出了放在&lt;strong&gt;类型&lt;/strong&gt;字段中的编号，以表示该选项的存在。由于&lt;strong&gt;类型&lt;/strong&gt;字段有另外的结构，所以这两列中的相应值不必相同。特别指出的是，第 1 （高序）位表示如果相关数据报被分片，该选项是否被复制到分片中。后面 2 位表示该选项的类别。目前，除了“时间戳”和“跟踪”使用类别 2 （调试和测量）外，表 5-4 中的所有选项使用类别 0 （控制）。类别 1 和 3 被保留。&lt;/p&gt;\n&lt;center&gt;表 5-4    如果选项存在，它在 IPv4 分组中紧跟在基本 IPv4 头部之后。选项由一个 8 位的类型字段标识。这个字段被细分为 3 个子字段：复制（1 位）、类别（2 位）和编号（5 位）。选项 0 和 1 的长度是 1 字节，多数的其他选项长度可变。可变选项包括 1 字节的类型标识符、1 字节的长度以及选项自身&lt;/center&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;名称&lt;/th&gt;\n&lt;th&gt;编号&lt;/th&gt;\n&lt;th&gt;值&lt;/th&gt;\n&lt;th&gt;长度&lt;/th&gt;\n&lt;th&gt;描述&lt;/th&gt;\n&lt;th&gt;参考文献&lt;/th&gt;\n&lt;th&gt;注释&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;列表结尾&lt;/td&gt;\n&lt;td&gt;0&lt;/td&gt;\n&lt;td&gt;0&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;表示没有更多选项&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC0791\&#34;&gt;RFC0791&lt;/a&gt;]&lt;/td&gt;\n&lt;td&gt;如果需要&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;没有操作&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;表示没有操作执行（用于填充）&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC0791\&#34;&gt;RFC0791&lt;/a&gt;]&lt;/td&gt;\n&lt;td&gt;如果需要&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;源路由&lt;/td&gt;\n&lt;td&gt;3 &lt;br/&gt;9&lt;/td&gt;\n&lt;td&gt;131 &lt;br/&gt;137&lt;/td&gt;\n&lt;td&gt;可变&lt;/td&gt;\n&lt;td&gt;发送方列出分组转发时遍历的路由器“航点”。松散意味着其他路由器可以包含在航点（3，131）中。严格意味着（9，137）中的所有航点都有按顺序遍历&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC1108\&#34;&gt;RFC1108&lt;/a&gt;]&lt;/td&gt;\n&lt;td&gt;很少，经常被过滤&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;安全和处理标签&lt;/td&gt;\n&lt;td&gt;2 &lt;br/&gt;5&lt;/td&gt;\n&lt;td&gt;130 &lt;br/&gt;133&lt;/td&gt;\n&lt;td&gt;11&lt;/td&gt;\n&lt;td&gt;在美国军事环境下如何为 IP 数据包指定安全标签和处理闲置&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC0791\&#34;&gt;RFC0791&lt;/a&gt;]&lt;/td&gt;\n&lt;td&gt;很少&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;记录路由&lt;/td&gt;\n&lt;td&gt;7&lt;/td&gt;\n&lt;td&gt;7&lt;/td&gt;\n&lt;td&gt;可变&lt;/td&gt;\n&lt;td&gt;在分组的头部中记录经过的路由器&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC0791\&#34;&gt;RFC0791&lt;/a&gt;]&lt;/td&gt;\n&lt;td&gt;很少&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;时间戳&lt;/td&gt;\n&lt;td&gt;4&lt;/td&gt;\n&lt;td&gt;68&lt;/td&gt;\n&lt;td&gt;可变&lt;/td&gt;\n&lt;td&gt;在分组的源和目的地记录日期和时间&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC0791\&#34;&gt;RFC0791&lt;/a&gt;]&lt;/td&gt;\n&lt;td&gt;很少&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;流 ID&lt;/td&gt;\n&lt;td&gt;8&lt;/td&gt;\n&lt;td&gt;136&lt;/td&gt;\n&lt;td&gt;4&lt;/td&gt;\n&lt;td&gt;携带 16 位的 SATNET 流标识符&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC0791\&#34;&gt;RFC0791&lt;/a&gt;]&lt;/td&gt;\n&lt;td&gt;历史的&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;EIP&lt;/td&gt;\n&lt;td&gt;17&lt;/td&gt;\n&lt;td&gt;145&lt;/td&gt;\n&lt;td&gt;可变&lt;/td&gt;\n&lt;td&gt;扩展 Internet 协议（20 世纪 90 年代早期的一个实验）&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC1385\&#34;&gt;RFC1385&lt;/a&gt;]&lt;/td&gt;\n&lt;td&gt;历史的&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;跟踪&lt;/td&gt;\n&lt;td&gt;18&lt;/td&gt;\n&lt;td&gt;82&lt;/td&gt;\n&lt;td&gt;可变&lt;/td&gt;\n&lt;td&gt;增加一个路由跟踪选项和 ICMP 报文（20 世纪 90 年代早期的一个实验）&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC1393\&#34;&gt;RFC1393&lt;/a&gt;]&lt;/td&gt;\n&lt;td&gt;历史的&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;路由器警告&lt;/td&gt;\n&lt;td&gt;20&lt;/td&gt;\n&lt;td&gt;148&lt;/td&gt;\n&lt;td&gt;4&lt;/td&gt;\n&lt;td&gt;表示一个路由器需要解释数据报的内容&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2113\&#34;&gt;RFC2113&lt;/a&gt;] [&lt;a href=\&#34;#RFC5350\&#34;&gt;RFC5350&lt;/a&gt;]&lt;/td&gt;\n&lt;td&gt;偶然&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;快速启动&lt;/td&gt;\n&lt;td&gt;25&lt;/td&gt;\n&lt;td&gt;25&lt;/td&gt;\n&lt;td&gt;8&lt;/td&gt;\n&lt;td&gt;表示启动快速传输协议（实验性的）&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC4782\&#34;&gt;RFC4782&lt;/a&gt;]&lt;/td&gt;\n&lt;td&gt;很少&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;p&gt;目前，多数标准化选项在 Internet 中很少或从未使用。例如，源路由和记录路由选项需要将 IPv4 地址放在 IPv4 头部中。由于头部（总计 60 字节，其中 20 字节是基本 IPv4 头部）空间有限，这些选项在当前基于 IPv4 的 Internet 中用处不大，其中一条 Internet 路径的平均路由器跳步数约为 15 [&lt;a href=\&#34;#LFS07\&#34;&gt;LFS07&lt;/a&gt;]。另外，这些选项主要用于诊断目的，它们为防火墙的构建带来麻烦和风险。因此， IPv4 选项通常在企业网络边界处被防火墙拒绝或剥离（见第 7 章）。&lt;/p&gt;\n&lt;p&gt;在企业网络内部，路径的平均长度更小，对恶意用户的防护可能考虑得更少，这些选项仍然可以使用。另外，&lt;strong&gt;路由器警告&lt;/strong&gt;选项提示可能由于在 Internet 上使用其他选项而有异常问题。由于它的设计目标主要是优化性能，并不会改变路由器的基本行为，所以该选项通常比其他选项更常用。正如前面所提到的，有些路由器会实现高度优化的内部路径，用于那些不包含选项的 IP 流量转发。路由器警告选项用于通知路由器，一个分组需使用超出常规的转发算法来处理。在表 5-4 的结尾处，实验性的“快速启动”选项适用于 IPv4 和 IPv6 ，我们将在下一节讨论 IPv6 扩展头部和选项时介绍它。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;53-ipv6-扩展头部\&#34;&gt;5.3 IPv6 扩展头部&lt;/h2&gt;\n&lt;p&gt;在 IPv6 中，那些由 IPv4 选项提供的特殊功能，通过在 IPv6 头部之后增加扩展头部实现。IPv4 路由和时间戳功能都采用这种方式，其他功能（例如分片和超大分组）很少在 IPv6 中使用（但仍需要），因此没有为它们在 IPv6 头部分配相应的位。基于这种设计， IPv6 头部固定为 40 字节，扩展头部仅在需要时添加。在选择 IPv6 头部为固定大小时，要求扩展头部仅由终端主机（仅有一个例外）处理， IPv6 设计者简化了高性能路由器的设计和实现，这是因为 IPv6 路由器处理分组所需的命令比 IPv4 简单。实际上，分组处理性能受很多因素影响，包括协议复杂性、路由器硬件和软件功能，以及流量负载等。&lt;/p&gt;\n&lt;p&gt;扩展头部和更高层协议（例如 TCP 或 UDP）头部与 IPv6 头部链接起来构成级联的头部（见图 5-6）。每个头部中的下一个头部字段表示紧跟着的头部的类型，它可能是一个 IPv6 扩展头部或其他类型。值 59 表示这个头部链的结尾。下一个头部字段的可能值定义在 [&lt;a href=\&#34;#IP6PARAM\&#34;&gt;IP6PARAM&lt;/a&gt;] 中，并在表 5-5 中列出了其中的大多数。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;5\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1653631363785.png\&#34; alt=\&#34;图 5-6\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 5-6    IPv6 头部使用下一个头部字段形成一个链。链中的头部可以是 IPv6 扩展头部或传输层头部。 IPv6 头部出现在数据报的开头，并且长度始终为 40 字节&lt;/p&gt;\n&lt;center&gt;表 5-5    IPv6 下一个头部字段值可能表示扩展头部或其他协议头部。在适当情况下，它与 IPv4 协议字段使用相同值&lt;/center&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;头部类型&lt;/th&gt;\n&lt;th&gt;顺序&lt;/th&gt;\n&lt;th&gt;值&lt;/th&gt;\n&lt;th&gt;参考文献&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;IPv6 头部&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;41&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2460\&#34;&gt;RFC2460&lt;/a&gt;] [&lt;a href=\&#34;#RFC2473\&#34;&gt;RFC2473&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;逐跳选项（HOPOPT）&lt;/td&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;td&gt;0&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2460\&#34;&gt;RFC2460&lt;/a&gt;]，紧跟在 IPv6 头部之后&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;目的地选项&lt;/td&gt;\n&lt;td&gt;3，8&lt;/td&gt;\n&lt;td&gt;60&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2460\&#34;&gt;RFC2460&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;路由&lt;/td&gt;\n&lt;td&gt;4&lt;/td&gt;\n&lt;td&gt;43&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2460\&#34;&gt;RFC2460&lt;/a&gt;] [&lt;a href=\&#34;#RFC5095\&#34;&gt;RFC5095&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;分片&lt;/td&gt;\n&lt;td&gt;5&lt;/td&gt;\n&lt;td&gt;44&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2460\&#34;&gt;RFC2460&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;封装安全载荷（ESP）&lt;/td&gt;\n&lt;td&gt;7&lt;/td&gt;\n&lt;td&gt;50&lt;/td&gt;\n&lt;td&gt;（见第 18 章）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;认证（AH）&lt;/td&gt;\n&lt;td&gt;6&lt;/td&gt;\n&lt;td&gt;51&lt;/td&gt;\n&lt;td&gt;（见第 18 章）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;移动（MIPv6）&lt;/td&gt;\n&lt;td&gt;9&lt;/td&gt;\n&lt;td&gt;135&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC6275\&#34;&gt;RFC6275&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;（无——没有下一个头部）&lt;/td&gt;\n&lt;td&gt;最后&lt;/td&gt;\n&lt;td&gt;59&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2460\&#34;&gt;RFC2460&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ICMPv6&lt;/td&gt;\n&lt;td&gt;最后&lt;/td&gt;\n&lt;td&gt;58&lt;/td&gt;\n&lt;td&gt;（见第 8 章）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;UDP&lt;/td&gt;\n&lt;td&gt;最后&lt;/td&gt;\n&lt;td&gt;17&lt;/td&gt;\n&lt;td&gt;（见第 10 章）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;TCP&lt;/td&gt;\n&lt;td&gt;最后&lt;/td&gt;\n&lt;td&gt;6&lt;/td&gt;\n&lt;td&gt;（见第 13 ~ 17 章）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;各种其他高层协议&lt;/td&gt;\n&lt;td&gt;最后&lt;/td&gt;\n&lt;td&gt;——&lt;/td&gt;\n&lt;td&gt;见 [&lt;a href=\&#34;#AN\&#34;&gt;AN&lt;/a&gt;] 中的完整列表&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;p&gt;我们从表 5-5 中可以看到， IPv6 扩展头部机制将一些功能（例如路由和分片）与选项加以区分。除了“逐跳选项”的位置之外（它是强制性的），扩展头部的顺序是建议性的，因此一个 IPv6 实现必须按接收的顺序处理扩展头部。只有“目的地选项”头部可以使用两次，第一次是指出包含在 IPv6 头部中的目的 IPv6 地址，第二次（位置 8）是关于数据报的最终目的地。在某些情况下（例如使用路由头部），当数据报被转发到最终目的地时， IPv6 头部中的&lt;strong&gt;目的 IP 地址&lt;/strong&gt;字段将会改变。&lt;/p&gt;\n&lt;h3 id=\&#34;531-ipv6-选项\&#34;&gt;5.3.1 IPv6 选项&lt;/h3&gt;\n&lt;p&gt;我们已经看到，相对于 IPv4， IPv6 提供了一种更灵活和可扩展的方式，将扩展和选项相结合。由于 IPv4 头部空间的限制，那些来自 IPv4 的选项已停止使用，而 IPv6 可变长度的扩展头部或编码在特殊扩展头部中的选项可适应当前更大的 Internet。如果选项存在，可放入&lt;strong&gt;逐跳选项&lt;/strong&gt;（与一个数据报传输路径上的每个路由器相关）或&lt;strong&gt;目的地选项&lt;/strong&gt;（仅与接收方相关）。逐跳选项（称为HOPOPT）是唯一由分组经过的每个路由器处理的选项。逐跳选项和目的地选项的编码格式一样。&lt;/p&gt;\n&lt;p&gt;逐跳选项和目的地选项头部的出现可以超过一次。这些选项均被编码为 &lt;strong&gt;类型 - 长度 - 值（TLV）&lt;/strong&gt; 集合，对应于 图5-7 中所示格式。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;6\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1653638926599.png\&#34; alt=\&#34;图 5-7\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 5-7    逐跳选项和目的地选项编码为 TLV 集合。第一字节给出了选项类型，包括一些子字段，在选项没被识别时指示一个 IPv6 节点如何动作，以及在数据报转发时选项数据是否改变。&lt;strong&gt;选项数据长度&lt;/strong&gt;字段给出了选项数据的字节长度&lt;/p&gt;\n&lt;p&gt;TLV 结构如图 5-7 所示，它的长度为 2 字节，后面是可变长度的数据字节。第一字节表示选项类型，其中包括 3 个子字段。当 5 位的&lt;strong&gt;类型子字段&lt;/strong&gt;无法由选项识别时，第一个子字段给出了一个 IPv6 节点尝试执行的动作。表 5-6 显示了所有可能的值。&lt;/p&gt;\n&lt;center&gt;表 5-6    一个 IPv6 的 TLV 选项类型的 2 个高序位，表示如果这个选项没有被识别，一个 IPv6 节点是转发还是丢弃该数据报，以及是否向发送方返回一个消息，提示这个数据报的处理结果&lt;/center&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;值&lt;/th&gt;\n&lt;th&gt;动作&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;00&lt;/td&gt;\n&lt;td&gt;跳过选项，继续处理&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;01&lt;/td&gt;\n&lt;td&gt;丢弃这个数据报（沉默）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;10&lt;/td&gt;\n&lt;td&gt;丢弃这个数据报，并向原地址发送一个“ICMPv6 参数问题”消息&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;11&lt;/td&gt;\n&lt;td&gt;与 10 相同，但仅在分组的目的地不是组播时，发送这个 ICMPv6 消息&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;p&gt;如果一个发往组播目的地的数据报中包括一个未知选项，那么大量节点将生成返回源节点的流量。这可通过将&lt;strong&gt;动作子字段&lt;/strong&gt;设置为 11 来避免。&lt;strong&gt;动作子字段&lt;/strong&gt;的灵活性在开发新的选项时是有用的。一个新的选项可携带在一个数据报中，并被那些无法理解它的路由器所忽略，这样有助于促进新选项的增量部署。当选项数据可能在数据报转发过程改变时，&lt;strong&gt;改变&lt;/strong&gt;位字段（图 5-7 中的 Chg）设置为 1。表 5-7 中所示的选项已被 IPv6 定义。&lt;/p&gt;\n&lt;center&gt;表 5-7    IPv6 选项携带在逐跳（H）选项或目的地（D）选项扩展头部中。选项类型字段包含来自“类型”列以及动作和改变子字段中的二进制值。“长度”列包含来自图 5-7 的选项数据长度字节中的值。填充 1 是唯一没有该字节的选项&lt;/center&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;选项名&lt;/th&gt;\n&lt;th&gt;头部&lt;/th&gt;\n&lt;th&gt;动作&lt;/th&gt;\n&lt;th&gt;改变&lt;/th&gt;\n&lt;th&gt;类型&lt;/th&gt;\n&lt;th&gt;长度&lt;/th&gt;\n&lt;th&gt;参考文献&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;填充 1&lt;/td&gt;\n&lt;td&gt;HD&lt;/td&gt;\n&lt;td&gt;00&lt;/td&gt;\n&lt;td&gt;0&lt;/td&gt;\n&lt;td&gt;0&lt;/td&gt;\n&lt;td&gt;N/A&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2460\&#34;&gt;RFC2460&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;填充 N&lt;/td&gt;\n&lt;td&gt;HD&lt;/td&gt;\n&lt;td&gt;00&lt;/td&gt;\n&lt;td&gt;0&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;可变&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2460\&#34;&gt;RFC2460&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;超大有效载荷&lt;/td&gt;\n&lt;td&gt;H&lt;/td&gt;\n&lt;td&gt;11&lt;/td&gt;\n&lt;td&gt;0&lt;/td&gt;\n&lt;td&gt;194&lt;/td&gt;\n&lt;td&gt;4&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2675\&#34;&gt;RFC2675&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;隧道封装限制&lt;/td&gt;\n&lt;td&gt;D&lt;/td&gt;\n&lt;td&gt;00&lt;/td&gt;\n&lt;td&gt;0&lt;/td&gt;\n&lt;td&gt;4&lt;/td&gt;\n&lt;td&gt;4&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2473\&#34;&gt;RFC2473&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;路由器警告&lt;/td&gt;\n&lt;td&gt;H&lt;/td&gt;\n&lt;td&gt;00&lt;/td&gt;\n&lt;td&gt;0&lt;/td&gt;\n&lt;td&gt;5&lt;/td&gt;\n&lt;td&gt;4&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2711\&#34;&gt;RFC2711&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;快速启动&lt;/td&gt;\n&lt;td&gt;H&lt;/td&gt;\n&lt;td&gt;00&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;5&lt;/td&gt;\n&lt;td&gt;8&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC4782\&#34;&gt;RFC4782&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;CALIPSO&lt;/td&gt;\n&lt;td&gt;H&lt;/td&gt;\n&lt;td&gt;00&lt;/td&gt;\n&lt;td&gt;0&lt;/td&gt;\n&lt;td&gt;7&lt;/td&gt;\n&lt;td&gt;8+&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC5570\&#34;&gt;RFC5570&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;家乡地址&lt;/td&gt;\n&lt;td&gt;D&lt;/td&gt;\n&lt;td&gt;11&lt;/td&gt;\n&lt;td&gt;0&lt;/td&gt;\n&lt;td&gt;201&lt;/td&gt;\n&lt;td&gt;16&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC6275\&#34;&gt;RFC6275&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;h4 id=\&#34;5311-填充-1-和填充-n\&#34;&gt;5.3.1.1 填充 1 和填充 N&lt;/h4&gt;\n&lt;p&gt;由于 IPv6 选项需要与 8 字节的偏移量对齐，因此较小的选项用 0 填充到长度为 8 字节。这里有两个填充选项，分别称为填充 1 和填充 N。填充 1 选项（类型 0）是唯一缺少&lt;strong&gt;长度&lt;/strong&gt;字段和&lt;strong&gt;值&lt;/strong&gt;字段的选项。它仅有 1 字节长，取值为 0。填充 N 选项（类型 1）向头部的选项区域填充 2 字节或更多字节，它使用图 5-7 所示格式。对于″个填充字节，&lt;strong&gt;选项数据长度&lt;/strong&gt;字段包含的值为（n - 2）。&lt;/p&gt;\n&lt;h4 id=\&#34;5312-ipv6-超大有效载荷\&#34;&gt;5.3.1.2 IPv6 超大有效载荷&lt;/h4&gt;\n&lt;p&gt;在某些 TCP/IP 网络中，例如那些用于互连超级计算机的网络，由于正常的 64KB 的 IP 数据报大小限制，在传输大量数据时会导致不必要的开销。 IPv6 超大有效载荷选项指定了一种有效载荷大于 65535 字节的 IPv6 数据报，称为&lt;strong&gt;超大报文&lt;/strong&gt;。这个选项无法由 MTU 小于 64KB 的链路连接的节点来实现。超大有效载荷选项提供了一个 32 位的字段，用于携带有效载荷在 65535 ~ 4294967295 字节之间的数据报。&lt;/p&gt;\n&lt;p&gt;当一个用于传输的超大报文形成时，其正常&lt;strong&gt;负载长度&lt;/strong&gt;字段被设置为 0。我们将在后面看到， TCP 协议使用&lt;strong&gt;负载长度&lt;/strong&gt;字段，计算由前面所述的 Internet 校验和算法得到的校验和。当使用超大有效载荷选项时， TCP 必须使用来自选项的长度值，而不是基本头部中的长度字段值。虽然这个过程并不困难，但更大有效载荷使得未检测出错误的可能性增大 [&lt;a href=\&#34;#RFC2675\&#34;&gt;RFC2675&lt;/a&gt;]。&lt;/p&gt;\n&lt;h4 id=\&#34;5313-隧道封装限制\&#34;&gt;5.3.1.3 隧道封装限制&lt;/h4&gt;\n&lt;p&gt;&lt;strong&gt;隧道&lt;/strong&gt;是指将一个协议封装在另一个协议中（见第 1 章和第 3 章）。例如， IP 数据报可能被封装在另一个 IP 数据报的有效载荷部分。隧道可用于形成虚拟的覆盖网络，在覆盖网络中，一个网络（例如 Internet）可作为另一个 IP 的链路层使用 [&lt;a href=\&#34;#TWEF03\&#34;&gt;TWEF03&lt;/a&gt;]。隧道可以嵌套，从这个意义上来说，一条隧道中的数据报本身也可采用递归方式封装在另一条隧道中。&lt;/p&gt;\n&lt;p&gt;在发送一个 IP 数据报时，发送者通常无法控制最终用于封装的隧道层次。发送者可使用这个选项设置一个限制。一台路由器打算将一个 IPv6 数据报封装在一条隧道中，它首先检查&lt;strong&gt;隧道封装限制&lt;/strong&gt;选项是否存在并置位。如果这个限制选项的值为 0，该数据报被丢弃，并将一个“ICMPv6 参数间题”消息（见第 8 章）发送到数据报源端（即之前的隧道入口点）。如果这个限制选项的值不为 0，该数据报可进行隧道封装，但新形成（封装）的 IPv6 数据报必须包括一个&lt;strong&gt;隧道封装限制&lt;/strong&gt;选项，其值比封装之前的数据报中的封装限制选项值减 1。实际上，封装限制行动类似于 IPv4 的 TTL 和 IPv6 的&lt;strong&gt;跳数限制&lt;/strong&gt;字段，只不过采用隧道封装层次代替转发跳步。&lt;/p&gt;\n&lt;h4 id=\&#34;5314-路由器警告\&#34;&gt;5.3.1.4 路由器警告&lt;/h4&gt;\n&lt;p&gt;&lt;strong&gt;路由器警告&lt;/strong&gt;选项指出数据报包含需要路由器处理的信息。它与 IPv4 的路由器警告选项的目的相同。 [&lt;a href=\&#34;#RAOPTS\&#34;&gt;RAOPTS&lt;/a&gt;] 给出了这个选项的当前设置值。&lt;/p&gt;\n&lt;h4 id=\&#34;5315-快速启动\&#34;&gt;5.3.1.5 快速启动&lt;/h4&gt;\n&lt;p&gt;**快速启动（QS）**选项和 [&lt;a href=\&#34;#RFC4782\&#34;&gt;RFC4782&lt;/a&gt;] 定义的 TCP/IP 实验性“快速启动”程序配合使用。它适用于 IPv4 和 IPv6，但目前建议仅用于专用网络，而不是全球性的 Internet。选项包括发送者需要的以比特/秒为单位的传输速率的编码值、 QS TTL 值和一些额外信息。如果沿途的路由器认为可以接受所需的速率，在这种情况下它们将递减 QS TTL，并在转发数据报时保持所需的速率不变。如果路由器不同意（即其支持的速率较低），它将该速率减小到一个可接受的速率。如果路由器不能识别 QS 选项，它将不递减 QS TTL。接收方将向发送方提供反馈，包括接收到的数据报的 IPv4 TTL 或 &lt;strong&gt;IPv6 跳数限制&lt;/strong&gt;字段和自己的 QS TTL 之间的差异，以及获得的速率可能被沿途的路由器所调整。这个信息被发送方用于确定发送速率（否则可能超出 TCP 使用的速率）。对 TTL 值进行比较的目的是确保沿途每台路由器参与 QS 谈判。如果发现任何路由器递减 IPv4 TTL （或 &lt;strong&gt;IPv6 跳数限制&lt;/strong&gt;）字段，但没有修改 QS TTL 值，则说明它没有启用 QS。&lt;/p&gt;\n&lt;h4 id=\&#34;5316-calipso\&#34;&gt;5.3.16 CALIPSO&lt;/h4&gt;\n&lt;p&gt;这个选项用于在某些专用网络中支持&lt;strong&gt;通用体系结构标签 IPv6 安全选项（CALIPSO）&lt;/strong&gt; [&lt;a href=\&#34;#RFC5570\&#34;&gt;RFC5570&lt;/a&gt;]。它提供了一种为数据报做标记的方法，包括一个安全级别标识符和一些额外的信息。需要注意的是，它用于多级安全网络环境（例如，政府、军队和银行），其中所有数据的安全级别必须以某种形式的标签注明。&lt;/p&gt;\n&lt;h4 id=\&#34;5317-家乡地址\&#34;&gt;5.3.1.7 家乡地址&lt;/h4&gt;\n&lt;p&gt;当使用 IPv6 移动选项时，这个选项保存发送数据报的 IPv6 节点的“家乡”地址。移动 IP （见 5.5 节）规定了 IP 节点的一系列处理过程，这些节点可能改变自已的网络接入点，同时不会断开自已的高层网络连接。这里存在一个节点的“家乡”的概念，它来自其典型位置的地址前缀。当远离家乡漫游时，通常为该节点分配一个不同的 IP 地址。该选项允许这个节点提供自己正常的家乡地址，以及它在漫游时的新地址（通常是临时分配）。当其他 IPv6 节点需要与移动节点通信时，它可以使用该节点的家乡地址。如果&lt;strong&gt;家乡地址&lt;/strong&gt;选项存在，包含它的&lt;strong&gt;目的地选项头部&lt;/strong&gt;必须出现在路由头部之后，并且在&lt;strong&gt;分片、认证&lt;/strong&gt;和 &lt;strong&gt;ESP 头部&lt;/strong&gt;（见第 18 章）之前（如果这些头部也存在）。我们将在移动 IP 中详细讨论这个选项。&lt;/p&gt;\n&lt;h3 id=\&#34;532-路由头部\&#34;&gt;5.3.2 路由头部&lt;/h3&gt;\n&lt;p&gt;IPv6 路由头部为发送方提供了一种 IPv6 数据报控制机制，以控制（至少部分控制）数据报通过网络的路径。目前，路由扩展头部有两个不同版本，分别称为类型 0 （RH0）和类型 2 （RH2）。 RH0 出于安全方面的考虑已被否决 [&lt;a href=\&#34;#RFC5095\&#34;&gt;RFC5095&lt;/a&gt;]， RH2 被定义为与移动 IP 共同使用。为了更好地理解路由头部，我们首先讨论 RH0，然后研究它为什么被放弃，以及它和 RH2 的不同之处。 RH0 规定了数据报转发时可“访问”的一个或多个 IPv6 节点。图 5-8 显示了这个头部。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;7\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1653651957371.png\&#34; alt=\&#34;图 5-8\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 5-8    目前已废弃的路由头部类型 0（RH0）涵盖了 IPv4 的宽松和严格的&lt;strong&gt;源路由&lt;/strong&gt;和&lt;strong&gt;记录路由&lt;/strong&gt;选项。它在数据报转发时由发送方构造，其中包括转发路径上的 IPv6 节点地址。每个地址可指定为一个宽松或严格的地址。一个严格的地址必须经过一个 IPv6 跳步到达，而一个松散的地址可能经过一个或多个其他跳步到达。在 IPv6 基本头部中，&lt;strong&gt;目的 IP 地址&lt;/strong&gt;字段修改为包含数据报转发的下一个转发地址&lt;/p&gt;\n&lt;p&gt;图 5-8 所示的 IPv6 路由头部涵盖了来自 IPv4 的&lt;strong&gt;宽松源路由&lt;/strong&gt;和&lt;strong&gt;记录路由&lt;/strong&gt;选项。它还支持采用 IPv6 地址之外的其他标识符路由的可能性，这个功能是不规范的，这里没有进一步讨论。对于标准化的 IPv6 地址的路由， RH0 允许发送方指定一个指向目的地址的向量。&lt;/p&gt;\n&lt;p&gt;这个头部包含一个 8 位的&lt;strong&gt;路由类型&lt;/strong&gt;标识符和一个 8 位的&lt;strong&gt;剩余部分&lt;/strong&gt;字段。对于 RH0， IPv6 地址类型标识符为 0 ；对于 RH2，该标识符为 2。&lt;strong&gt;剩余部分&lt;/strong&gt;字段指出还有多少段路由需要处理，也就是说，在到达最终目的地之前仍需访问的中间节点数。它是一个 32 位的从保留字段开始的地址块，由发送方设置为 0，并由接收方忽略。在数据报转发时，这些地址并非可访问的组播 IPv6 地址。&lt;/p&gt;\n&#34;,&#34;fileName&#34;:&#34;lesslesstcpip-xiang-jie-juan-yi-xie-yi-greatergreater-di-wu-zhang-internet-xie-yi&#34;,&#34;abstract&#34;:&#34;&lt;h2 id=\&#34;51-引言\&#34;&gt;5.1 引言&lt;/h2&gt;\n&lt;p&gt;IP是 TCP/IP 协议族中的核心协议。所有 TCP、 UDP、 ICMP 和 IGMP 数据都通过 IP 数据报传输。 IP 提供了一种尽力而为、无连接的数据报交付服务。 “尽力而为”的含义是不保证 IP 数据报能成功到达目的地。虽然 IP 不是简单丢弃所有不必要流量，但它也不对自己尝试交付的数据报提供保证。当某些错误发生时，例如一台路由器临时用尽缓冲区， IP 提供一个简单的错误处理方法： 丢弃一些数据（通常是最后到达的数据报）。任何可靠性必须由上层（例如 TCP）提供。 IPv4 和 IPv6 都使用这种尽力而为的基本交付模式。&lt;/p&gt;\n&lt;p&gt;“&lt;strong&gt;无连接&lt;/strong&gt;”意味着 IP 不维护网络单元（即路由器）中数据报相关的任何链接状态信息，每个数据报独立于其他数据报来处理。这也意味着 IP 数据报可不按顺序交付。如果一个源主机向同一目的地发送两个连续的数据报（第一个为 A，第二个为 B），每个数据报可以独立路由，通过不同路径，并且 B 可能在 A 之前到达。 IP 数据报也可能发生其他问题：它们可能在传输过程中被复制，可能改变内容从而导致错误。此外， IP 之上的一些协议（通常是 TCP）需要处理这些潜在问题，以便为应用提供无差错的交付。&lt;/p&gt;\n&#34;,&#34;title&#34;:&#34;《TCP/IP 详解 卷一：协议》第五章：Internet 协议&#34;,&#34;tags&#34;:[],&#34;date&#34;:&#34;2022-05-26 15:34:07&#34;,&#34;dateFormat&#34;:&#34;2022-05-26&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://wenbozhangw.github.io/post/lesslesstcpip-xiang-jie-juan-yi-xie-yi-greatergreater-di-wu-zhang-internet-xie-yi/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;45 min read&#34;,&#34;time&#34;:2642000,&#34;words&#34;:12192,&#34;minutes&#34;:45},&#34;description&#34;:&#34;5.1 引言\nIP是 TCP/IP 协议族中的核心协议。所有 TCP、 UDP、 ICMP 和 IGMP 数据都通过 IP 数据报传输。 IP 提供了一种尽力而为、无连接的数据报交付服务。 “尽力而为”的含义是不保证 IP 数据报能成功到达...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#51-%E5%BC%95%E8%A8%80\&#34;&gt;5.1 引言&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#52-ipv4-%E5%A4%B4%E9%83%A8%E5%92%8C-ipv6-%E5%A4%B4%E9%83%A8\&#34;&gt;5.2 IPv4 头部和 IPv6 头部&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#521-ip-%E5%A4%B4%E9%83%A8%E5%AD%97%E6%AE%B5\&#34;&gt;5.2.1 IP 头部字段&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#522-internet-%E6%A0%A1%E9%AA%8C%E5%92%8C\&#34;&gt;5.2.2 Internet 校验和&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#5221-internet-%E6%A0%A1%E9%AA%8C%E5%92%8C%E6%95%B0%E5%AD%A6%E6%80%A7%E8%B4%A8\&#34;&gt;5.2.2.1 Internet 校验和数学性质&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#523-ds-%E5%AD%97%E6%AE%B5%E5%92%8C-ecn-%E4%BB%A5%E5%89%8D%E7%A7%B0%E4%B8%BA-tos-%E5%AD%97%E8%8A%82%E6%88%96-ipv6-%E6%B5%81%E9%87%8F%E7%B1%BB%E5%88%AB\&#34;&gt;5.2.3 DS 字段和 ECN （以前称为 ToS 字节或 IPv6 流量类别）&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#524-ip-%E9%80%89%E9%A1%B9\&#34;&gt;5.2.4 IP 选项&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#53-ipv6-%E6%89%A9%E5%B1%95%E5%A4%B4%E9%83%A8\&#34;&gt;5.3 IPv6 扩展头部&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#531-ipv6-%E9%80%89%E9%A1%B9\&#34;&gt;5.3.1 IPv6 选项&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#5311-%E5%A1%AB%E5%85%85-1-%E5%92%8C%E5%A1%AB%E5%85%85-n\&#34;&gt;5.3.1.1 填充 1 和填充 N&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#5312-ipv6-%E8%B6%85%E5%A4%A7%E6%9C%89%E6%95%88%E8%BD%BD%E8%8D%B7\&#34;&gt;5.3.1.2 IPv6 超大有效载荷&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#5313-%E9%9A%A7%E9%81%93%E5%B0%81%E8%A3%85%E9%99%90%E5%88%B6\&#34;&gt;5.3.1.3 隧道封装限制&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#5314-%E8%B7%AF%E7%94%B1%E5%99%A8%E8%AD%A6%E5%91%8A\&#34;&gt;5.3.1.4 路由器警告&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#5315-%E5%BF%AB%E9%80%9F%E5%90%AF%E5%8A%A8\&#34;&gt;5.3.1.5 快速启动&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#5316-calipso\&#34;&gt;5.3.16 CALIPSO&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#5317-%E5%AE%B6%E4%B9%A1%E5%9C%B0%E5%9D%80\&#34;&gt;5.3.1.7 家乡地址&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#532-%E8%B7%AF%E7%94%B1%E5%A4%B4%E9%83%A8\&#34;&gt;5.3.2 路由头部&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;h2 id=\&#34;41-引言\&#34;&gt;4.1 引言&lt;/h2&gt;\n&lt;p&gt;IP 协议的设计目标是为跨越不同类型物理网络的分组交换提供互操作。这需要网络层软件使用的地址和底层网络硬件使用的地址之间进行转换。网络接口硬件通常有一个主要的硬件地址（例如以太网或 802.11 无线接口的 48 位地址）。由硬件交换的帧需要使用正确的硬件地址定位到正确的接口；否则，无法传输数据。但是，一个传统 IPv4 网络需要使用自己的地址：32 位的 IPv4 地址。如果一台主机要将一个帧发送到另一台主机，仅知道这台主机的 IP 地址是不够的，还需要知道主机在网络中的有效硬件地址。操作系统软件（即以太网驱动程序）必须知道目的主机的硬件地址，以便直接向它发送数据。对于 TCP/IP 网络，&lt;strong&gt;地址解析协议（ARP）&lt;/strong&gt; [&lt;a href=\&#34;#RFC0826\&#34;&gt;RFC0826&lt;/a&gt;] 提供了一种在 IPv4 地址和各种网络技术使用的硬件地址之间的映射。 ARP 仅用于 IPv4， IPv6 使用邻居发现协议，它被合并入 ICMPv6 （见第 8 章）。&lt;/p&gt;\n&lt;!-- more --&gt;\n&lt;p&gt;这里需要注意的是，网络层地址和链路层地址是由不同部门分配的。对于网络硬件，主地址是由设备制造商定义的，并存储在设备的永久性内存中，所以它不会改变。因此，工作在特定硬件技术上的任意协议族，必须利用特定类型的地址。这允许不同协议族中的网络层协议&lt;strong&gt;同时运行&lt;/strong&gt;。另一方面，网络接口的 IP 地址是由用户或网络管理员分配的，并且可以接需选择。为便携设备分配的 IP 地址可能改变，例如设备移动时。 IP 地址通常从维护附近网络连接点的地址池中获得，它在系统启用或配置时分配（见第 6 章）。当两个局域网的主机之间传输的以太网帧包含 IP 数据报时，由 48 位以太网地址确定该帧的目的接口。&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;地址解析&lt;/strong&gt;是发现两个地址之间的映射关系的过程。对于使用 IPv4 的 TCP/IP 协议族，这是由运行的 ARP 来实现的。 ARP 是一个通用的协议，从这个意义上来看，它被设计为支持多种地址之间的映射。实际上， ARP 几乎总是用于 32 位 IPv4 地址和以太网的 48 位 MAC 地址之间的映射。这种情况在 [&lt;a href=\&#34;#RFC0826\&#34;&gt;RFC0826&lt;/a&gt;] 中进行描述，它也是我们感兴趣的。在本章中，我们将互换使用以太网地址和 MAC 地址。&lt;/p&gt;\n&lt;p&gt;ARP 提供从网络层地址到相关硬件地址的动态映射。我们使用动态这个术语是因为它会自动执行和随时间变化，而不需要系统管理员重新配置。也就是说，如果一台主机改变它的网络接口卡，从而改变了它的硬件地址（但保留其分配的 IP 地址）， ARP 可以在一定延时后继续正常运作。 ARP 操作通常与用户或系统管理员无关。&lt;/p&gt;\n&lt;p&gt;注意    提供 ARP 反向映射的协议称为 RARP，它用于缺少磁盘驱动器（通常是无盘工作站或 X 终端）的系统。它在当前已很少使用，而且需要系统管理员手功配置。详情见 [&lt;a href=\&#34;#RFC0903\&#34;&gt;RFC0903&lt;/a&gt;] 。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;42-一个例子\&#34;&gt;4.2 一个例子&lt;/h2&gt;\n&lt;p&gt;当我们使用 Internet 服务时，例如在浏览器中打开一个网页，本地计算机必须确定如何与相关的服务器联系。它首先是判断该服务位于本地（同一 IP 子网的一部分）还是远程。如果是远程的，需要一台可到达目的地的路由器。仅在到达位于同一 IP 子网的系统时，ARP 才能工作。那么对于这个例子，我们假设使用 Web 浏览器打开以下网址：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;http://10.0.0.1\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;注意，这个 URL 包含一个 IPv4 地址，而不是更常见的域名或主机名。这里使用地址的原因是要强调一个事实，例子中是共享相同 IPv4 前缀的相关系统（见第 2 章）。这里，我们使用包含地址的 URL，以确定一个本地的 Web 服务器，并探索 &lt;strong&gt;直接交付&lt;/strong&gt; 的运行原理。随着嵌入式设备（例如打印机和 VoIP 适配器）使用内置 Web 服务器进行配置，这种本地服务器越来越常见。&lt;/p&gt;\n&lt;h3 id=\&#34;421-直接交付和-arp\&#34;&gt;4.2.1 直接交付和 ARP&lt;/h3&gt;\n&lt;p&gt;在本节中，我们列出了直接交付的步骤，重点集中在 ARP 的运行上。直接交付发生在一个 IP 数据报被发送到一个 IP 地址，而该地址与发送方具有相同 IP 前缀的情况下。在 IP 数据报转发（见第 5 章）的常见方式中，它扮演着一个重要角色。下面用前面的例子列出 IPv4 直接交付的基本操作：&lt;/p&gt;\n&lt;ol&gt;\n&lt;li&gt;在这种情况下，应用程序是一个 Web 浏览器，调用一个特殊函数来解析 URL，看它是否包含主机名。这里不是，应用程序使用 32 位 IPv4 地址 &lt;code&gt;10.0.0.1&lt;/code&gt;。&lt;/li&gt;\n&lt;li&gt;应用程序要求 TCP 协议建立一条到 &lt;code&gt;10.0.0.1&lt;/code&gt; 的连接。&lt;/li&gt;\n&lt;li&gt;通过向 &lt;code&gt;10.0.0.1&lt;/code&gt; 发送一个 IPv4 数据报，TCP 尝试向远程主机发送一个连接请求（第 15 章将介绍细节）。&lt;/li&gt;\n&lt;li&gt;我们假设地址 &lt;code&gt;10.0.0.1&lt;/code&gt; 使用与发送主机相同的网络前缀，数据报可被直接发送到这个地址而不经过任何路由器。&lt;/li&gt;\n&lt;li&gt;假设以太网兼容地址被用于 IPv4 子网，发送主机必须将 32 位的 IPv4 目的地址转换为 48 位的以太网地址。使用 [&lt;a href=\&#34;#RFC0826\&#34;&gt;RFC0826&lt;/a&gt;] 的术语，就是需要从 &lt;strong&gt;逻辑 Internet&lt;/strong&gt; 地址向对应 &lt;strong&gt;物理&lt;/strong&gt; 硬件地址进行转换。这是 ARP 功能。ARP 工作在正常模式下，仅适用于 &lt;strong&gt;广播网络&lt;/strong&gt;，链路层能将一个消息交付到它连接的所有网络设备。这是 ARP 运行的一个重要要求。在非广播网络（有时被称为 &lt;strong&gt;非广播多路访问（NBMA）&lt;/strong&gt;）中，可能需要更复杂的映射协议 [&lt;a href=\&#34;#RFC2332\&#34;&gt;RFC2332&lt;/a&gt;] 。&lt;/li&gt;\n&lt;li&gt;在一个共享的链路层网段上，ARP 向所有主机发送一个称为 &lt;strong&gt;ARP 请求&lt;/strong&gt; 的以太网帧。这被称为 &lt;strong&gt;链路层广播&lt;/strong&gt;。图 4-1 的斜线阴影中显示了一个&lt;strong&gt;广播域&lt;/strong&gt;。ARP 请求包含目的主机的 IPv4 地址（&lt;code&gt;10.0.0.1&lt;/code&gt;），并寻找以下问题的答案：“如果你将 IPv4 地址 &lt;code&gt;10.0.0.1&lt;/code&gt; 配置为自己的地址，请向我回应你的 MAC 地址。”&lt;/li&gt;\n&lt;li&gt;通过 ARP，同一广播域中的所有系统可接收 ARP 请求。这包括可能根本不允许 IPv4 或 IPv6 协议的系统，但不包括位于不同 VLAN 中的系统，即使支持它们（VLAN 详细信息见第 3 章）。如果某个系统使用请求中指出的 IPv4 地址，它仅需要响应一个 &lt;strong&gt;ARP 应答&lt;/strong&gt;。这个应答包含 IPv4 地址（与请求相匹配）和对应的 MAC 地址。这个应答通常不是广播，而是仅直接发送给请求的发送方。同时，接收 ARP 请求的主机学习 IPv4 到 MAC 地址的映射，并记录在内存中供以后使用（见 4.3 节）。&lt;/li&gt;\n&lt;li&gt;ARP 应答被原始请求的发送方接收，现在可发送引起这次 ARP 请求/应答交换过程的数据报。&lt;/li&gt;\n&lt;li&gt;发送方可将数据报封装在以太网帧中直接发送到目的主机，并使用由 ARP 交换学到的以太网地址作为目的地址。由于这个以太网地址仅指向正确的目的主机，所有其他主机或路由器不会接收到这个数据报。因此，当仅使用直接交付时，并不需要经过路由器。&lt;/li&gt;\n&lt;/ol&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;1\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1653399568330.png\&#34; alt=\&#34;图 4-1\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 4-1    以太网主机在同一广播域中。ARP 查询使用链路层广播帧发送，并被所有主机接收。 IP 地址匹配的主机直接向请求主机返回响应。 IP 地址不匹配的主机主动丢弃 ARP 查询&lt;/p&gt;\n&lt;p&gt;ARP 用于运行 IPv4 的多接入链路层网络，每个主机都有自己首选的硬件地址。点到点链路（例如 PPP）不使用 ARP （见第 3 章）。当这些链路被建立后（通常是由用户或系统来发起创建），在链路两端通知正在使用的地址。由于不涉及硬件地址，因此不需要地址解析或 ARP。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;43-arp-缓存\&#34;&gt;4.3 ARP 缓存&lt;/h2&gt;\n&lt;p&gt;ARP 高效运行的关键是维护每个主机和路由器上的 &lt;strong&gt;ARP 缓存&lt;/strong&gt;（或表）。该缓存使用地址解析为每个接口维护从网络层地址到硬件地址的最新映射。当 IPv4 地址映射到硬件地址时，它对应于高速缓存中的一个条目，其正常到期时间是条目创建开始后的20分钟，这在 [&lt;a href=\&#34;#RFC1122\&#34;&gt;RFC1122&lt;/a&gt;] 中描述。&lt;/p&gt;\n&lt;p&gt;我们可在 Linux 或 Windows 中使用 arp 命令查看 ARP 缓存。选项 -a 用于显示这两个系统的缓存中的所有条目。在 Linux 中，运行 arp 会产生以下输出：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;Linux% arp\nAddress                  HWtype  HWaddress           Flags Mask            Iface\ngw.home            ether   00:0D:66:4F:60:00   C                     eth0\nprinter.home              ether   00:0A:95:87:38:6A   C                     eth0\nLinux% arp -a\nprinter.home (10.0.0.4) at 00:0A:95:87:38:6A [ether] on eth1\ngw.home (10.0.0.1) at 00:0D:66:4F:60:00 [ether] on eth1\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;在 Windows 中，运行 arp 会产生以下类似的输出：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;c:\\&amp;gt; arp -a\nInterface: 10.0.0.56 --- 0x2\n  Internet Address         Physical Address              Type\n  10.0.0.1            00-0d-66-4f-60-00     dynamic\n  10.0.0.4            00-0a-95-87-38-6a     dynamic\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;这里，我们看到的是 IPv4 到硬件地址的缓存。在第一个（Linux）例子中，每个映射是一个包含 5 个元素的条目：主机名（对应一个 IP 地址）、硬件地址类型、硬件地址、标志和本地网络接口（它对于这个映射是活跃的）。&lt;strong&gt;标志&lt;/strong&gt;列包含一个符号：C、 M 或 P。 C 类条目由 ARP 协议动态学习， M 类条目通过手工输入（arp -s ；见 4.9 节），而 P 类条目的含义是“发布”。也就是说，对于任何 P 类条目，主机对输入的 ARP 请求返回一个 ARP 应答。这个选项用于配置代理 ARP（见 4.7 节）。第二个 Linux 的例子显示了使用“BSD 风格”的类似信息。这里，给出了主机名和地址，对应的地址类型（[&lt;a href=\&#34;#ether\&#34;&gt;ether&lt;/a&gt;] 表示一个以太网类型的地址），以及映射活跃在哪个接口上。&lt;/p&gt;\n&lt;p&gt;Windows 的 arp 程序显示了接口的 IPv4 地址，它的接口号是十六进制数（这里的 &lt;code&gt;0x2&lt;/code&gt;）。Windows 版本还指出地址是手动输入还是 ARP 学习。在这个例子中，两个条目都是动态的，这意味着它们来自 ARP 学习（如果通过手工输入，它们是静态的）。注意， 48 位 MAC 地址被显示为 6 个十六进制数，在 Linux 中使用冒号分隔，在 Windows 中使用短杠（dash）分隔。在传统上， UNIX 系统一直使用冒号，而 IEEE 标准和其他操作系统倾向于使用短杠。我们在 4.9 节中讨论 arp 命令的附加功能和其他选项。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;44-arp-帧格式\&#34;&gt;4.4 ARP 帧格式&lt;/h2&gt;\n&lt;p&gt;图 4-2 显示了在以太网中转换一个 IPv4 地址时常用的 ARP 请求和应答分组的格式（正如前面所说， ARP 通常也能用于 IPv4 以外的地址，虽然这是非常少见的）。前 14 字节构成标准的以太网头部，假设没有 802.1p/q 或其他标记，其余部分由 ARP 协议来定义。 ARP 帧的前 8 个字节是通用的，这个例子中的剩余部分专门用于将 IPv4 地址映射到 48 位的以太网地址。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;2\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1653401432482.png\&#34; alt=\&#34;图 4-2\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 4-2    IPv4 地址映射到 48 位的 MAC（以太网）地址时使用的 ARP 帧格式&lt;/p&gt;\n&lt;p&gt;在图 4-2 所示的 ARP 帧的以太网头部中，前两个字段包含目的和源以太网地址。对于 ARP 请求，目的以太网地址 &lt;code&gt;ff:ff:ff:ff:ff:ff&lt;/code&gt; （全部为 1）是广播地址，在同一广播域中的所有以太网接口可接收这些帧。在以太网帧中，对于 ARP （请求或应答）， 2 字节的&lt;strong&gt;长度&lt;/strong&gt;或&lt;strong&gt;类型&lt;/strong&gt;字段必须为 &lt;code&gt;0x0806&lt;/code&gt;。&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;长度/类型&lt;/strong&gt;字段之后的前 4 个字段指定了最后 4 个字段的类型和大小。这些值由 IANA [&lt;a href=\&#34;#RFC5494\&#34;&gt;RFC5494&lt;/a&gt;] 来指定。 术语&lt;strong&gt;硬件&lt;/strong&gt;和&lt;strong&gt;协议&lt;/strong&gt;用于描述 ARP 分组中的字段。例如，一个 ARP 请求询问协议地址（在这种情况下是 IPv4 地址）对应的硬件地址（在这种情况下是以太网地址）。这些术讳很少被用于 ARP 之外。相对来说，硬件地址的常见术语有 MAC、&lt;strong&gt;物理&lt;/strong&gt;或&lt;strong&gt;链路层地址&lt;/strong&gt;（或&lt;strong&gt;以太网&lt;/strong&gt;地址，当网络基于 IEEE 802.3/以太网的一系列规范时）。 &lt;strong&gt;硬件类型&lt;/strong&gt;字段指出硬件地址类型。 对于以太网，该值为 1。 &lt;strong&gt;协议类型&lt;/strong&gt;字段指出映射的协议地此类型。 对于 IPv4 地址，该值为 &lt;code&gt;0x0800&lt;/code&gt;。 当以太网帧包含 IPv4 数据报时，这可能与以太网帧的&lt;strong&gt;类型&lt;/strong&gt;字段值一致。对于下面两个 1 字节的字段，&lt;strong&gt;硬件大小&lt;/strong&gt;和&lt;strong&gt;协议大小&lt;/strong&gt;分别指出硬件地址和协议地址的字节数。对于以太网中使用 IPv4 地此的 ARP 请求或应答，它们的值分别为 6 和 4。 Op 字段指出该操作是 ARP 请求（值为 1）、 ARP 应答（2）、 RARP 请求（3）或 RARP应答（4）。由于 ARP 请求和 ARP 应答的&lt;strong&gt;长度/类型&lt;/strong&gt;字段相同，因此这个字段是必需的。&lt;/p&gt;\n&lt;p&gt;紧跟在后面的 4 个字段是&lt;strong&gt;发送方硬件地址&lt;/strong&gt;（在这个例子中是以太网 MAC 地址）、&lt;strong&gt;发送方协议地址&lt;/strong&gt;（lPv4 地址）、&lt;strong&gt;目的硬件地址&lt;/strong&gt;（MAC/以太网地址）和&lt;strong&gt;目的协议地址&lt;/strong&gt;（IPv4 地址）。注意，这里存在一些重复的信息：以太网头部和 ARP 消息都包含发送方硬件地址。对于一个 ARP 请求，除了&lt;strong&gt;目的硬件地址&lt;/strong&gt;（设为 0）之外，其他字段都需要填充。当一个系统接收到一个 ARP 请求，它填充自己的硬件地址，将两个发送方地址和两个接收方地址互换，将 Op 字段设置为 2，然后发送生成的应答。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;45-arp-例子\&#34;&gt;4.5 ARP 例子&lt;/h2&gt;\n&lt;p&gt;在本节中，我们将使用 tcpdump 命令查看在执行一个正常 TCP/IP 应用（例如 Telnet）时运行 ARP 所实际发生的过程。Telnet 是一个简单的应用程序，可用于在两个系统之间建立一条 TCP/IP 连接。&lt;/p&gt;\n&lt;h3 id=\&#34;451-正常的例子\&#34;&gt;4.5.1 正常的例子&lt;/h3&gt;\n&lt;p&gt;为了查看 ARP 运行，我们将执行 telnet 命令，使用 TCP 端口 80 （称为 www）连接到主机 10.0.0.3 上的 Web 服务器。&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;C:\\&amp;gt; arp -a                    // 验证 arp 缓存为空\nNo ARP Entries Found\nC:\\&amp;gt; telnet 10.0.0.3 www                    // 连接到 Web 服务器 [端口80]\nConnecting to 10.0.0.3...\nEscape character is &#39;^]&#39;.\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;按下 CTRL + 右括号键获得 Telnet 客户机的提示。&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;Welcome to Microsoft Telnet Client\nEscape Character is &#39;CTRL+]&#39;\nMicrosoft Telnet&amp;gt; quit\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;指令 quit 用于退出程序。&lt;/p&gt;\n&lt;p&gt;在这些命令执行的同时，我们在另一个系统上预习呢 tcpdump 命令，并观察交换的流量信息。使用 -e 选项可以显示 MAC 地址（这个例子中是 48 位以太网地址）。&lt;/p&gt;\n&lt;p&gt;下面列出的内容包含来自 tcpdump 的输出。我们删除了输出的最后 4 行，它们用于终止连接（我们将在第 13 章中详细讨论），但与这里的讨论无关。注意，不同系统中的 tcpdump 版本提供的输出细节可能稍有不同。&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;Linux# tcpdump -e\n1       0.0    0:0:c0:6f:2d:40    ff:ff:ff:ff:ff:ff    arp   60:\n        arp    who-has    10.0.0.3    tell   10.0.0.56\n2        0.002174    (0.0022)0:0:c0:c2:9b:26    0:0:c0:6f:2d:40    arp    60:\n        arp    reply    10.0.0.3    is-at    0:0:c0:c2:9b:26\n\n3       0.002831    (0.0007)0:0:c0:6f:2d:40    0:0:c0:c2:9b:26    ip    60:\n        10.0.0.56.1030    &amp;gt;    10.0.0.3.www:    S    596459521:596459521(0)\n        win    4096    &amp;lt;ms    1024&amp;gt;    [tos    0x10]\n4       0.007834    (0.0050)0:0:c0:c2:9b:26    0:0:c0:6f:2d:40    ip    60:\n        10.0.0.3.www    &amp;gt;    10.0.0.56.1030:    S    3562228225:3562228225(0)\n        ack    596459522    win    4096    &amp;lt;mss    1024&amp;gt;\n5       0.009615    (0.0018)0:0:c0:6f:2d:40    0:0:c0:c2:9b:26    ip    60:\n        10.0.0.56.1030    &amp;gt;    10.0.0.3.discard:    .    ack    1    win    [tos    0x10]\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;在分组 1 中，源硬件地址为 &lt;code&gt;0:0:c0:6f:2d:40&lt;/code&gt;。 目的硬件地址为&lt;code&gt;ff:ff:ff:ff:ff:ff&lt;/code&gt;。 它是一个以太网广播地址。同一广播域（在同一局域网或 VLAN 中的所有主机，无论它们是否运行 TCP/IP）中的所有以太网接口接收并处理该帧，如图 4-1 所示。分组 1 的下一个输出字段为 arp，意味着帧类型字段为 &lt;code&gt;0x0806&lt;/code&gt;。表明它是 ARP 请求或 ARP 应答。在前 5 个分组中， arp 和 ip 后面打印的值 60 是以太网帧的长度。 ARP 请求或 ARP 应答的大小是 42 字节（ARP 消息为 28 字节，以太网头部为 14 字节）。每个帧均填充为最小以太网帧：60 字节数据和 4 字节 CRC （见第 3 章）。&lt;/p&gt;\n&lt;p&gt;分组 1 的下一部分（即 arp who-has）用于标识该帧是 ARP 请求，目的地址是 IPv4 地址 &lt;code&gt;10.0.0.3&lt;/code&gt;，源地址是 IPv4 地址 &lt;code&gt;10.0.0.56&lt;/code&gt;。tcpdump 显示默认 IP 地址对应的主机名，但在这里没有显示（由于没有为它们建立反向 DNS 映射；第 11 章介绍 DNS 的细节）。接下来，我们使用 -n 选项查看 ARP 请求中的 IP 地址，无论它们是否进行 DNS 映射。&lt;/p&gt;\n&lt;p&gt;我们从分组 2 中看到，虽然 ARP 请求是广播的，但 ARP 应答的目的地址是（单播）MAC 地址 &lt;code&gt;0:0:c0:6f:2d:40&lt;/code&gt;。因此，ARP 应答是直接发送到请求主机，它并不是通常的广播（在 4.8 节的一些情况下，这个规则可能会改变）。tcpdump 显示出该帧的 ARP 应答，以及响应者的 IPv4 地址和硬件地址。第 3 行是请求建立的第一个 TCP 段。其目的硬件地址属于目的主机（&lt;code&gt;10.0.0.3&lt;/code&gt;）。我们将在第 13 章涉及这部分的细节。&lt;/p&gt;\n&lt;p&gt;对于每个分组，分组号后面的数字是 tcpdump 接收分组的相对时间（秒）。除第一个之外的每个分组都包含从前一段时间到现在的时间差（秒），该值放在括号中。我们可以看到发送 ARP 请求和接受 ARP 应答之间的时间约为 2.2ms。第一个 TCP 段在此后 0.7ms 发送。在这个例子中，ARP 动态地址解析的开销少于 3ms。注意，如果主机 10.0.0.3 的 ARP 表项在 10.0.0.56 的 ARP 缓存中是有效的，最初的 ARP 交换并不会发生，最初的 TCP 段可能已使用目的以太网地址立即发送。&lt;/p&gt;\n&lt;p&gt;有关 tcpdump 输出的一个微妙问题是，在向 &lt;code&gt;10.0.0.56&lt;/code&gt; （第 4 行）发送自己的第一个 TCP 段之前，我们没看到来自 &lt;code&gt;10.0.0.3&lt;/code&gt; 的 ARP 请求。&lt;code&gt;10.0.0.3&lt;/code&gt; 在自己的 ARP 缓存中可能已有一个 &lt;code&gt;10.0.0.56&lt;/code&gt; 的条目，通常当系统接收到发送给它的 ARP 请求时，除了发送 ARP 应答外，它还会在 ARP 缓存中保存请求者的硬件地址和 IP 地址。这是一个基于逻辑假设的优化，如果请求者发送一个数据报，该数据报的接收者可能发送一个应答。&lt;/p&gt;\n&lt;h3 id=\&#34;452-对一个不存在的主机的-arp-请求\&#34;&gt;4.5.2 对一个不存在的主机的 ARP 请求&lt;/h3&gt;\n&lt;p&gt;如果 ARP 请求中指定的主机关闭或不存在，将会发生什么？为了查看这种情况，我们尝试访问一个不存在的本地 IPv4 地址，其前缀对应本地子网，但没有主机使用该地址。在这个例子中，我们使用 IPv4 地址  &lt;code&gt;10.0.0.99&lt;/code&gt;。&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;Linux% date ; telnet 10.0.0.99 ; date\nFri Jan 29 14:46:33 PST 2010\nTrying 10.0.0.99...\ntelnet: connect to address 10.0.0.99: No route to host\nFri Jan 29 14:46:36 PST 2010               // 3s after previous date\n\nLinux% arp -a\n? (10.0.0.99) at &amp;lt;incomplete&amp;gt; on eth0\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;这是 tcpdump 的输出：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;1    21:12:07.440845 arp who-has 10.0.0.99 tell 10.0.0.56\n2    21:12:08.436842 arp who-has 10.0.0.99 tell 10.0.0.56\n3    21:12:09.436836 arp who-has 10.0.0.99 tell 10.0.0.56\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;由于我们已知使用广播地址发送 ARP 请求，因此本次并没有指定 -e 选项。 ARP 请求的频率接近每秒一次，这是 [&lt;a href=\&#34;#RFC1122\&#34;&gt;RFC1122&lt;/a&gt;] 建议的最大值。 Windows 系统中（没有给出图示）的测试显示出不同的行为。不是 3 个请求之间各间隔 1 秒，而是根据使用的应用程序或其他协议改变间隔。对于 ICMP 和 UDP （分别见第 8 章和第 10 章），使用的间隔约为 5 秒，而 TCP 使用的间隔为 10 秒。对于 TCP，在 TCP 放弃尝试建立一条连接之前， 10 秒间隔足以发送 2 个无须应答的 ARP 请求。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;46-arp-缓存超时\&#34;&gt;4.6 ARP 缓存超时&lt;/h2&gt;\n&lt;p&gt;超时通常与 ARP 缓存中的每个条目相关（我们在后面将会看到， arp 命令允许管理员设置缓存条目永远不超时）。在大多数实现中，完整条目的超时为 20 分钟，而不完整条目的超时为 3 分钟（我们在前面的例子中看到一个不完整条目，它强迫执行一次到不存在主机的 ARP 请求）。这些实现通常在每次使用一个条目后为它重新启动 20 分钟的超时。 [&lt;a href=\&#34;#RFC1122\&#34;&gt;RFC1122&lt;/a&gt;] 是描述主机需求的 RFC，它规定每个条目即使在使用也应启动超时，但很多实现并不这样做，它们在每次使用条目后重新启动超时。&lt;/p&gt;\n&lt;p&gt;注意，这是关于&lt;strong&gt;软状态&lt;/strong&gt;的一个重要例子。软状态是指在超时到达前没有更新而被丢弃的信息。如果网络条件发生玫变，软状态有助于启动自动重新配置，因此很多 Internet 协议使用软状态。软状态的成本是协议必须刷新状态以避免过期。在一些协议设计中，经常包括“软状态刷新”，以保持软状态的活跃。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;47-代理-arp\&#34;&gt;4.7 代理 ARP&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;代理 ARP&lt;/strong&gt; [&lt;a href=\&#34;#RFC1027\&#34;&gt;RFC1027&lt;/a&gt;] 使一个系统（通常是一台专门配置的路由器）可回答不同主机的 ARP 请求。它使 ARP 请求的发送者认为做出响应的系统就是目的主机，但实际上目的主机可能在其他地方（或不存在）。ARP 代理并不场景，通常应尽量避免使用它。&lt;/p&gt;\n&lt;p&gt;代理 ARP 也被成为 &lt;strong&gt;混杂 ARP&lt;/strong&gt; 或 &lt;strong&gt;ARP 黑客&lt;/strong&gt;。这些名称来自 ARP 代理的历史用途：两个物理网络相互隐蔽自己。在这种情况下，两个物理网络可使用相同的 IP 前缀，只要将中间的路由器配置为一个代理 ARP，在一个网络中由代理响应对其他网络中主机的 ARP 请求。这种技术可用于向一组主机隐藏另一组主机。从前，这样做有两个常见原因：有些系统无法进行子网划分，有些系统使用比较旧的广播地址（全 0 的主机 ID，而不是当前全 1 的主机 ID）。&lt;/p&gt;\n&lt;p&gt;Linux 支持一种称为&lt;strong&gt;自动代理 ARP&lt;/strong&gt; 的功能。它可通过在文件 &lt;code&gt;/proc/sys/net/ipv4/confys/proxy_aap&lt;/code&gt; 中写入字符 1，或使用 sysctl 命令来启用。它支持使用代理 ARP 功能，而不必为被代理的每个可能的 IPv4 地址手工输入 ARP 条目。这样做允许自动代理一个地址范围，而不是单个地址。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;48-免费-arp-和地址冲突检测\&#34;&gt;4.8 免费 ARP 和地址冲突检测&lt;/h2&gt;\n&lt;p&gt;ARP 的另一个功能被称为&lt;strong&gt;免费 ARP&lt;/strong&gt;。它发生在一台主机发送 ARP 请求以寻找自己的地址时。它通常出现在启动时，当接口被配置为“上行”时常这样做。下面是一个例子，在一台 Linux 机器上跟踪显示 Windows 主机的启动：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;Linux# tcpdump -e -n arp\n1        0.0    0:0:c0:6f:2d:40    ff:ff:ff:ff:ff:ff    arp    60:\n        arp who-has 10.0.0.56    tell    10.0.0.56\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;（我们为 tcpdump 增加 -n 标志，以打印数字化的点分十进制地址而不是主机名。）就 ARP 请求字段而言，发送方协议地址和目的协议地址相同：&lt;code&gt;10.0.0.56&lt;/code&gt;。另外，以太网头部中的源地址字段被 tcpdump 显示为 &lt;code&gt;0:0:c0:6f:2d:40&lt;/code&gt;，它等于发送方硬件地址。免费 ARP 需要达到两个目标：&lt;/p&gt;\n&lt;ol&gt;\n&lt;li&gt;允许一台主机确定另一台主机是否配置相同的 IPv4 地址。发送免费 ARP 的主机并不期望它的请求获得应答。但是，如果它接收到一个应答，通常显示的是错误消息“从以太网地址......发送的重复 IP 地址”。这是对系统管理员和用户的警告，在同一广播域（例如局域网或 VLAN）中有一个系统配置出错。&lt;/li&gt;\n&lt;li&gt;如果发送免费 ARP 的主机已改变硬件地址（关闭主机或替换接口卡，然后重新启动主机），该帧导致任何接收广播并且其缓存中有该条目的其他主机，将该条目中的旧硬件地址更新为与该帧一致。如前面所述，如果一台主机接收到一个 ARP 请求，该请求来自一个已存在接收方缓存中的 IPv4 地址，则缓存条目更新为 ARP 请求中发送方的硬件地址。这由接收到 ARP 请求的主机完成，免费 ARP 正好利用这个特性。&lt;/li&gt;\n&lt;/ol&gt;\n&lt;p&gt;虽然免费 ARP 提供的一些迹象显示，多个站可尝试使用相同 IPv4 地址，但它实际上没有对这种情况提供解决机制（除了显示一个消息，实际由系统管理员完成）。为了解决这个问题， [&lt;a href=\&#34;#RFC5227\&#34;&gt;RFC5227&lt;/a&gt;] 描述了 &lt;strong&gt;IPv4 地址冲突检测（ACD）&lt;/strong&gt;。 ACD 定义了 &lt;strong&gt;ARP 探测&lt;/strong&gt;分组和 &lt;strong&gt;ARP 通告&lt;/strong&gt;分组。ARP 探测分组是一个 ARP 请求分组，其中&lt;strong&gt;发送方协议（IPv4）地址&lt;/strong&gt;字段被设置为 0。探测分组用于查看一个候选 IPv4 地址是否被广播域中的任何其他系统所使用。通过将&lt;strong&gt;发送方协议地址&lt;/strong&gt;字段设置为 0，避免候选 IPv4 地址被另一台主机使用时的缓存污染，这是它与免费 ARP 工作方式的一个差别。ARP 通告与 ARP 探测相同，除了其&lt;strong&gt;发送方协议地址&lt;/strong&gt;和&lt;strong&gt;目的协议地址&lt;/strong&gt;字段被填充为候选 IPv4 地址外。它用于通告发送方使用侯选 IPv4 地址的意图。&lt;/p&gt;\n&lt;p&gt;为了执行 ACD，当一个接口被启用或从睡眠中唤醒，或一个新链路建立（例如，当一个新的无线网络关联建立）时，这台主机发送一个 ARP 探测分组。在发送 3 个探测分组之前，首先需要等待一个随机时间（范围为 0 ~ 1 秒，均匀分布）。当多个系统同时启用时，通过延迟来避免启用带来的拥塞，否则都立即执行 ACD，这将导致网络流量激增。探测分组之间存在一个随机的时间间距，大约 1 ~ 2 秒的延迟（均匀分布）。&lt;/p&gt;\n&lt;p&gt;当请求站发送探测的探测时，它可能接收到 ARP 请求或应答。对其探测的应答表明其他站已使用候选 IP 地址。从不同系统发送的请求，其&lt;strong&gt;目的协议地址&lt;/strong&gt;字段中包含相同的候选 IPv4 地址，表明其他系统也在同时尝试获得候选 IPv4 地址。在这两种情况下，该系统将会显示一个地址冲突消息，并采用其他可选地址。例如，当使用 DHCP （见第 6 章）分配地址时，这是推荐的行为。 [&lt;a href=\&#34;#RFC5227\&#34;&gt;RFC5227&lt;/a&gt;] 对尝试获得地址设置了 10 次的冲突限制，在请求的主机进入限速阶段之前，它被允许每 60 秒执行一次 ACD，直至成功。&lt;/p&gt;\n&lt;p&gt;根据前面所描述的过程，如果发送请求的主机没有发现冲突，它会间隔 2 秒向广播域中发送 2 个 ARP 通告，以表明它现在使用这个 IPv4 地址。在这个通告中，&lt;strong&gt;发送方协议地址&lt;/strong&gt;和&lt;strong&gt;目的协议地址&lt;/strong&gt;字段被设置为其声称的地址。发送这些通告的目的是确保更新缓存地址映射，以正确反映发送方当前使用的地址。&lt;/p&gt;\n&lt;p&gt;ACD 被认为是一个持续的过程，这是它与免费 ARP 的区别。当一台主机通告它正使用的地址后，它会继续检查输入的 ARP 流量（请求和应答），查看自己的地址是否出现在&lt;strong&gt;发送方协议地址&lt;/strong&gt;字段中。如果是的话，说明其他系统与自己在使用相同的地址。在这种情况下，[&lt;a href=\&#34;#RFC5227\&#34;&gt;RFC5227&lt;/a&gt;] 提供了 3 种可能的解决方案：停止使用这个地址；保留这个地址，但发送一个“防御性” ARP 通告，如果冲突继续，则停止使用它；不理会冲突，仍继续使用。对于最后一个选择，仅建议那些真正需要一个固定、稳定地址的系统（例如打印机或路由器等嵌入式设备）使用。&lt;/p&gt;\n&lt;p&gt;[&lt;a href=\&#34;#RFC5227\&#34;&gt;RFC5227&lt;/a&gt;] 还说明了使用链路层广播发送 ARP 应答的潜在好处。虽然这不是传统的 ARP 工作方式，但同一网段中所有站需处理 ARP 流量时，这样做可带来一些好处。广播应答可以更快地执行 ACD，这是由于所有站都会注意到这个应答，并在发现冲突时使自己的缓存无效。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;49-arp-命令\&#34;&gt;4.9 arp 命令&lt;/h2&gt;\n&lt;p&gt;在 Windows 和 Linux 中，我们使用带有 -a 标志的 arp 命令显示 ARP 缓存中的所有条目（在 Linux 上，我们可不使用 -a 而获得类似信息）。超级用户或管理员可指定 -d 选项来删除 ARP 缓存中的条目（这在运行一些例子前用于强制执行一次 ARP 交换。）&lt;/p&gt;\n&lt;p&gt;我们也可以使用 -s 选项增加条目。它需要一个 IPv4 地址（或使用 DNS 从 IPv4 地址转换的主机名）和一个以太网地址。这个 IPv4 地址和以太网地址作为一个条目被添加在缓存中。这个条目是半永久性的（即它在缓存中不会超时，但在系统重启时消失）。&lt;/p&gt;\n&lt;p&gt;Linux 版本的 arp 比 Windows 版本提供更多功能。当在命令行结尾使用关键字 temp，并使用 -s 增加一个条目时，这个条目被认为是临时的，并与其他 ARP 条目一样会超时。当在命令行结尾使用关键字 pub 并使用 -s 时，系统对该条目做出 ARP 应答。系统对 ARP 请求的 IPv4 地址以相应的以太网地址来应答。如果通告地址是系统自己的地址之一，该系统可作为一个指定 IPv4 地址的代理 ARP （见 4.7 节）。如果 arp -s 用于启用代理 ARP， Linux 对指定地址做出应答，在 &lt;code&gt;/proc/sys/net/ipv4/conf/*/proxy_arp&lt;/code&gt; 文件中写人 0。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;410-使用-arp-设置一台嵌入式设备的-ipv4-地址\&#34;&gt;4.10 使用 ARP 设置一台嵌入式设备的 IPv4 地址&lt;/h2&gt;\n&lt;p&gt;随着越来越多的嵌入式设备与以太网、 TCP/IP 协议兼容，那些无法直接输入网络配置信息的联网设备越来越普遍（例如，它们没有键盘，难以输入自已使用的 IP 地址）。这些设备通常采用以下两种方式之一配置：一种是使用 DHCP 自动分配地址和其他信息（见第 6 章）；另一种是使用 ARP 设置 IPv4 地址，虽然这种方法并不常见。&lt;/p&gt;\n&lt;p&gt;通过 ARP 为嵌入式设备配置 IPv4 地址不是协议的初衷，这是由于它不是完全自动的。它的基本思路是为设备手动建立一个 ARP 映射（使用 arp -s 命令），然后向这个地址发送一个 IP 分组。由于相应 ARP 条目已存在，因此不会产生 ARP 请求/应答。相反，硬件地址可以立即使用。当然，设备的以太网（MAC）地址必须已知。它通常印在设备上，有时兼作制造商的设备序列号。当设备接收到一个目标为自身硬件地址的分组时，这个数据报包含的目的地址用于指定其初始 IPv4 地址。此后，这台设备可用其他方式（例如通过一个嵌入式 Web 服务器）完成配置。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;411-与-arp-相关的攻击\&#34;&gt;4.11 与 ARP 相关的攻击&lt;/h2&gt;\n&lt;p&gt;目前已有一系列涉及 ARP 的攻击。最直接的是使用代理 ARP 功能假扮主机，对 ARP 请求做出应答。如果受害主机不存在，这很直观，而且可能难以发现。如果该主机仍在运行，这被认为更困难，因为每个 ARP 请求可能有多个应答，这样比较容易发现。&lt;/p&gt;\n&lt;p&gt;一种更巧妙的攻击可被 ARP 触发，它涉及一台主机被连接到多个网络，并且一个接口的 ARP 条目被其他 ARP 表“遗漏”的情况，这是由 ARP 软件的一个错误造成的。利用这种漏洞可将流量引导到错误网段上。 Linux 提供了一个直接影响该行为的方式，可通过修改文件 &lt;code&gt;/proc/sys/net/ipv4/conf/*/arp_filter&lt;/code&gt; 实现。如果将数值 1 写入这个文件，当输入的 ARP 请求到达一个接口时，就进行一次 IP 转发检查。这时需要查找请求者的 IP 地址，以确定哪个接口将用于发送返回的 IP 数据报。如果到达的 ARP 请求与返回发送方的 IP 数据报使用不同的接口，这个 ARP 应答被抑制（触发它的 ARP 请求被丢弃）。&lt;/p&gt;\n&lt;p&gt;更具破坏性的 ARP 攻击涉及静态条目处理。如前所述，当查找对应一个特定 IP 地址的以太网（MAC）地址时，静态条目可用于避免 ARP 请求/应答。这种条目已被用于尝试增强安全性。它的思路是在 ARP 缓存中对重要主机使用静态条目，以快速检测任何针对该 IP 地址的主机欺骗。不幸的是，大多数 ARP 实现通常用 ARP 应答提供的条目代替静态缓存条目。这样的后果是，接收到 ARP 应答（即使它没发送 ARP 请求）的主机被欺骗，并使用攻击者提供的条目代替自己的静态条目。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;412-总结\&#34;&gt;4.12 总结&lt;/h2&gt;\n&lt;p&gt;ARP 是 TCP/IP 实现中的一个基本协议，但它通常在应用程序或用户没有察觉的情况下运行。 ARP 用于确定本地可达的 IPv4 子网使用的 IPv4 地址对应的硬件地址。它在数据报的目的地与发送方处于同一子网时使用，还用于数据报的目的地不在当前子网（在第 5 章详细说明）时将其转发到一台路由器。 ARP 缓存是其运行的基础，我们可使用 arp 命令查看和处理缓存。缓存中每个条目都有一个计时器，用于清除不完整的条目和完整的条目。 arp 命令可显示和修改 ARP 缓存中的条目。&lt;/p&gt;\n&lt;p&gt;我们深入了解特殊 ARP 的正常运行：代理 ARP （一台路由器回答主机通过另一台路由器接口访问的 ARP 请求）和免费 ARP （发送自己拥有的 IP 地址的 ARP 请求，通常用于引导）。我们还讨论了 IPv4 地址冲突检测，采用一种持续运行的类似免费 ARP 的交换，来避免在同一广播域中地址重复。最后，我们讨论了一系列涉及 ARP 的攻击。如果高层协议没有强大的安全措施，这可能会导致高层协议出现问题（见第 18 章）。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;413-参考文献\&#34;&gt;4.13 参考文献&lt;/h2&gt;\n&lt;p&gt;&lt;span id=\&#34;RFCO826\&#34;&gt;[RFCO826]&lt;/span&gt; D. Plummer, &amp;quot;Ethernet Address Resolution Protocol: Or Converting Network Protocol Addresses to 48.bit Ethernet Address for Transmission on Ethernet Hardware,&amp;quot; Internet RFC 0826/STD 0037, Nov.1982.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFCO903\&#34;&gt;[RFCO903]&lt;/span&gt;R. Finlayson, T. Mann,J. C. Mogul, and M. Theimer, &amp;quot;A Reverse Address Resolution Protocol,&amp;quot; Internet RFC 0903/STD 0038,June 1984.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC1027\&#34;&gt;[RFC1027]&lt;/span&gt; S. Carl-Mitchell and J. S. Quarterman, &amp;quot;Using ARP to Implement Transparent Subnet Gateways,&amp;quot; Internet RFC 1027,Oct. 1987.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC1122\&#34;&gt;[RFC1122]&lt;/span&gt;R. Braden, ed., &amp;quot;Requirements for Internet Hosts,&amp;quot; Internet RFC 1122/STD 0003,Oct. 1989.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC2332\&#34;&gt;[RFC2332]&lt;/span&gt; J. Luciani, D. Katz, D. Piscitello, B. Cole, and N. Doraswamy, &amp;quot;NBMA Next Hop Resolution Protocol (NHRP),&amp;quot; Internet RFC 2332,Apr. 1998.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC5227\&#34;&gt;[RFC5227]&lt;/span&gt; S. Cheshire, &amp;quot;IPv4 Address Conflict Detection,&amp;quot; Internet RFC 5227, July. 1998.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC5494\&#34;&gt;[RFC5494]&lt;/span&gt; J.Arkko and C. Pignataro, &amp;quot;IANA Allocation Guidelines for the Address Resolution Protocol(ARP)&amp;quot; Internet RFC 5494,Apr. 2009.&lt;/p&gt;\n&#34;,&#34;fileName&#34;:&#34;lesslesstcpip-xiang-jie-juan-yi-xie-yi-greatergreater-di-si-zhang-di-zhi-jie-xi-xie-yi&#34;,&#34;abstract&#34;:&#34;&lt;h2 id=\&#34;41-引言\&#34;&gt;4.1 引言&lt;/h2&gt;\n&lt;p&gt;IP 协议的设计目标是为跨越不同类型物理网络的分组交换提供互操作。这需要网络层软件使用的地址和底层网络硬件使用的地址之间进行转换。网络接口硬件通常有一个主要的硬件地址（例如以太网或 802.11 无线接口的 48 位地址）。由硬件交换的帧需要使用正确的硬件地址定位到正确的接口；否则，无法传输数据。但是，一个传统 IPv4 网络需要使用自己的地址：32 位的 IPv4 地址。如果一台主机要将一个帧发送到另一台主机，仅知道这台主机的 IP 地址是不够的，还需要知道主机在网络中的有效硬件地址。操作系统软件（即以太网驱动程序）必须知道目的主机的硬件地址，以便直接向它发送数据。对于 TCP/IP 网络，&lt;strong&gt;地址解析协议（ARP）&lt;/strong&gt; [&lt;a href=\&#34;#RFC0826\&#34;&gt;RFC0826&lt;/a&gt;] 提供了一种在 IPv4 地址和各种网络技术使用的硬件地址之间的映射。 ARP 仅用于 IPv4， IPv6 使用邻居发现协议，它被合并入 ICMPv6 （见第 8 章）。&lt;/p&gt;\n&#34;,&#34;title&#34;:&#34;《TCP/IP 详解 卷一：协议》第四章：地址解析协议&#34;,&#34;tags&#34;:[{&#34;index&#34;:-1,&#34;name&#34;:&#34;TCP/IP&#34;,&#34;slug&#34;:&#34;NhO-Hr8Eu&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://wenbozhangw.github.io/tag/NhO-Hr8Eu/&#34;}],&#34;date&#34;:&#34;2022-05-20 00:48:06&#34;,&#34;dateFormat&#34;:&#34;2022-05-20&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://wenbozhangw.github.io/post/lesslesstcpip-xiang-jie-juan-yi-xie-yi-greatergreater-di-si-zhang-di-zhi-jie-xi-xie-yi/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;36 min read&#34;,&#34;time&#34;:2143000,&#34;words&#34;:9511,&#34;minutes&#34;:36},&#34;description&#34;:&#34;4.1 引言\nIP 协议的设计目标是为跨越不同类型物理网络的分组交换提供互操作。这需要网络层软件使用的地址和底层网络硬件使用的地址之间进行转换。网络接口硬件通常有一个主要的硬件地址（例如以太网或 802.11 无线接口的 48 位地址）。由...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#41-%E5%BC%95%E8%A8%80\&#34;&gt;4.1 引言&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#42-%E4%B8%80%E4%B8%AA%E4%BE%8B%E5%AD%90\&#34;&gt;4.2 一个例子&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#421-%E7%9B%B4%E6%8E%A5%E4%BA%A4%E4%BB%98%E5%92%8C-arp\&#34;&gt;4.2.1 直接交付和 ARP&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#43-arp-%E7%BC%93%E5%AD%98\&#34;&gt;4.3 ARP 缓存&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#44-arp-%E5%B8%A7%E6%A0%BC%E5%BC%8F\&#34;&gt;4.4 ARP 帧格式&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#45-arp-%E4%BE%8B%E5%AD%90\&#34;&gt;4.5 ARP 例子&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#451-%E6%AD%A3%E5%B8%B8%E7%9A%84%E4%BE%8B%E5%AD%90\&#34;&gt;4.5.1 正常的例子&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#452-%E5%AF%B9%E4%B8%80%E4%B8%AA%E4%B8%8D%E5%AD%98%E5%9C%A8%E7%9A%84%E4%B8%BB%E6%9C%BA%E7%9A%84-arp-%E8%AF%B7%E6%B1%82\&#34;&gt;4.5.2 对一个不存在的主机的 ARP 请求&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#46-arp-%E7%BC%93%E5%AD%98%E8%B6%85%E6%97%B6\&#34;&gt;4.6 ARP 缓存超时&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#47-%E4%BB%A3%E7%90%86-arp\&#34;&gt;4.7 代理 ARP&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#48-%E5%85%8D%E8%B4%B9-arp-%E5%92%8C%E5%9C%B0%E5%9D%80%E5%86%B2%E7%AA%81%E6%A3%80%E6%B5%8B\&#34;&gt;4.8 免费 ARP 和地址冲突检测&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#49-arp-%E5%91%BD%E4%BB%A4\&#34;&gt;4.9 arp 命令&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#410-%E4%BD%BF%E7%94%A8-arp-%E8%AE%BE%E7%BD%AE%E4%B8%80%E5%8F%B0%E5%B5%8C%E5%85%A5%E5%BC%8F%E8%AE%BE%E5%A4%87%E7%9A%84-ipv4-%E5%9C%B0%E5%9D%80\&#34;&gt;4.10 使用 ARP 设置一台嵌入式设备的 IPv4 地址&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#411-%E4%B8%8E-arp-%E7%9B%B8%E5%85%B3%E7%9A%84%E6%94%BB%E5%87%BB\&#34;&gt;4.11 与 ARP 相关的攻击&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#412-%E6%80%BB%E7%BB%93\&#34;&gt;4.12 总结&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#413-%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE\&#34;&gt;4.13 参考文献&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;h2 id=\&#34;31-引言\&#34;&gt;3.1 引言&lt;/h2&gt;\n&lt;p&gt;在第 1 章中，我们知道 TCP/IP 协议族中设计链路层的目的是为 IP 模块发送和接收 IP 数据报。它可用于携带一些支持 IP 的辅助性协议，例如 ARP （见第 4 章）。 TCP/IP 支持多种不同的链路层，它依赖于使用的网络硬件类型：有线局域网，例如以太网；&lt;strong&gt;城域网（MAN）&lt;/strong&gt;，例如服务供应商提供的有线电视和 DSL 连接；有线语音网络，例如支持调制解调器的电话线；无线网络，例如Wi-Fi （无线局域网）；基于蜂窝技术的各种无线数据服务，例如 HSPA、EV-DO、LTE 和 WiMAX。在本章中，我们将详细讨论以下内容：在以太网和 Wi-Fi 的链路层中，如何使用&lt;strong&gt;点到点协议（PPP）&lt;/strong&gt;，如何在其他（链路或更高层）协议中携带链路层协议，以及一种称为隧道的技术等。详细描述当前使用的每种链路技术需要专门一本书才行，因此我们将注意力集中在一些常用的链路层协议，以及 TCP/IP 中如何使用它们。&lt;/p&gt;\n&lt;p&gt;大多数链路层技术都有一个相关的协议，描述由网络硬件传输的相应 PDU 格式。在描述链路层的 PDU 时，我们通常使用术语&lt;strong&gt;帧&lt;/strong&gt;，以区分那些更高层的 PDU 格式，例如描述网络层和传输层 PDU 的分组和段。帧格式通常支持可变的帧长度，范围从几字节到几千字节。这个范围的上限称为&lt;strong&gt;最大传输单元（MTU）&lt;/strong&gt;，我们将在后续章节中提到链路层的这一特点。有些网络技术（例如调制解调器和串行线路）不强制规定最大的帧，因此它们可以由用户来配置。&lt;/p&gt;\n&lt;h2 id=\&#34;32-以太网和-ieee-802-局域网城域网标准\&#34;&gt;3.2 以太网和 IEEE 802 局域网/城域网标准&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;以太网&lt;/strong&gt;这个术语通常指一套标准，由 DEC、 Intel 公司和 Xerox 公司在 1980 年首次发布，并在 1982 年加以修订。第一个常见格式的以太网，目前被称为“10Mb/s 以太网”或“共享以&lt;br&gt;\n太网”，它被 IEEE 采纳（轻微修改）为 802.3 标准。这种网络的结构通常如图 3-1 所示。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;1\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1651118328245.png\&#34; alt=\&#34;图 3-1\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 3-1   基本的共享以太网包含一个或多个站（例如工作站、超级计算机），它们都被连接到一个共享的电缆段上。当介质被确定为空闲状态时，链路层的 PDU（帧）可以从一个站发送到一个或更多其他站。如果多个站同时发送数据，可能因信号传播延迟而发生碰撞。碰撞可以被检测到，它会导致发送站等待一个随机事件，然后重新发送数据。这种常见的方法称为带冲突检测的载波侦听多路访问&lt;/p&gt;\n&lt;p&gt;由于多个站共享同一网络，该标准需要在每个以太网接口实现一种分布式算法，以控制一个站发送自己的数据。这种特定方法称为&lt;strong&gt;带冲突（或称碰撞）检测的载波侦听多路访问（CSMA/CD）&lt;/strong&gt;，它协调哪些计算机可访问共享的介质（电缆），同时不需要其他特殊协议或同步。这种相对简单的方法有助于降低成本和促进以太网投术普及。&lt;/p&gt;\n&lt;p&gt;采用 CSMA/CD，一个站（例如计算机）首先检测目前网络上正在发送的信号，并在网络空闲时发送自己的帧。这是协议中的“载波侦听”部分。如果其他站碰巧同时发送，发生重叠的电信号被检测为一次碰撞。在这种情况下，每个站等待一个随机时间，然后再次尝试发送。这个时间量的选择依据一个统一的概率分布，随后每个碰撞被检测到的时间长度加倍。最终，每个站会得到机会发送，或者在尝试一定次数（传统以太网为 16）后超时。采用 CSMA/CD，在任何给定的时间内，网络中只能有一个帧传输。如 CSMA/CD 这样的访问方法更正式的名称为&lt;strong&gt;介质访问控制(MAC)协议&lt;/strong&gt;。 MAC 协议有很多类型，有些基于每个站尝试独立使用网络（例如 CSMA/CD 的基于竞争的协议），有些基于预先安排的协调（例如依据为每个站分配的时段发送） 。&lt;/p&gt;\n&lt;p&gt;随着 10Mb/s 以太网的发展，更快的计算机和基础设施使得局域网速度不断提升。由于以太网的普及，已取得以下显著创新和成果：其速度从 10Mb/s 增加到 100Mb/s、 1000Mb/s、10Gb/s，现在甚至更高。 10Gb/s 技术在大型数据中心和大型企业中越来越普遍，并且已被证实可达到 100Gb/s 的速度。最早（研究）的以太网速度为 3Mb/s，但 DIX （Digital、 Intel、 Xerox）标准可达到 10Mb/s，它在一条共享的物理电缆或由电子中继器互联的一组电缆上运行。 20 世纪 90 年代初，共享的电缆已在很大程度上被双绞线（类似电话线，通常称为“10BASE-T”）代替。随着 100Mb/s （也称为“快速以太网”，最流行的版本是“100BASE-TX”）的发展，基于竞争的 MAC 协议已变得不流行。相反，局域网中每个站之间的线路通常不共享，而是提供了一个专用的星形拓扑结构。这可以通过以太网&lt;strong&gt;交换机&lt;/strong&gt;来实现，如图 3-2 所示&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;2\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1651120249525.png\&#34; alt=\&#34;图 3-2\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 3-2   一个交换式以太网包含一个或多个站，每个站使用一条专用的线路连接到一个交换机端口。在大多数情况下，交换式以太网以全双工方式运行，并且不需要使用 CSMA/CD 算法。交换机可以通过交换机端口级联形成更大的以太网，该端口有时也称为“上行”端口&lt;/p&gt;\n&lt;p&gt;目前，交换机为以太网中的每个站提供同时发送和接收数据的能力（称为“全双工以太网”）。虽然 1000Mb/s 以太网（1000BASE-T）仍支持半双工（一次一个方向）操作，但相对于全双工以太网来说，它很少使用。下面我们将详细讨论交换机如何处理 PDU。&lt;/p&gt;\n&lt;p&gt;当前连接 Internet 的最流行技术之一是无线网络，常见的无线局域网（WLAN） IEEE 标准称为无线保真或 Wi-Fi，有时也称为“无线以太网”或 802.11。虽然这个标准与 802 有线以太网标准不同，但帧格式和通用接口大部分来自 802.3，并且都是 IEEE 802 局域网标准的一部分。因此， TCP/IP 用于以太网的大部分功能，也可用于 Wi-Fi 网络。我们将详细探讨这些功能。首先，我们描绘一个建立家庭和企业网络的所有 IEEE 802 标准的蓝图。这里也包括那些涉及城域网的 IEEE 标准，例如 IEEE 802.16（WiMAX）和蜂窝网络中的异构网络无缝切换标准（IEEE 802.21）。&lt;/p&gt;\n&lt;h3 id=\&#34;321-ieee-802-局域网城域网标准\&#34;&gt;3.2.1 IEEE 802 局域网/城域网标准&lt;/h3&gt;\n&lt;p&gt;原始的以太网帧格式和工作过程由前面提到的行业协议所描述。这种格式被称为 DIX 格式或 Ethernet II 格式。对这种类型的以太网稍加修改后，由 IEEE 标准化为一种 CSMA/CD 网络，称为 802.3。在 IEEE 标准中，带 802 前缀的标准定义了局域网和城域网的工作过程。当前最流行的 802 标准包括 802.3 （以太网）和 802.11（WLAN/Wi-Fi）。这些标准随着时间推移而演变，经过独立修订后名称发生改变（例如 802.11g），并最终被纳入修订过的标准。表 3-1 显示了一个相当完整的列表，包括截至 2011 年年中支持 TCP/IP 的相关 IEEE 802 局域网和城域网标准。&lt;/p&gt;\n&lt;center&gt;表 3-1   有关 TCP/IP 协议的局域网和城域网 IEEE 802 标准（2011）&lt;/center&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;名称&lt;/th&gt;\n&lt;th&gt;描述&lt;/th&gt;\n&lt;th&gt;官方参考&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;802.1ak&lt;/td&gt;\n&lt;td&gt;多注册协议（MRP）&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.1AK-2007\&#34;&gt;802.1AK-2007&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.1AE&lt;/td&gt;\n&lt;td&gt;MAC 安全（MACSec）&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.AE-2006\&#34;&gt;802.AE-2006&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.1AX&lt;/td&gt;\n&lt;td&gt;链路聚合（以前的 802.3ad）&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.AX-2008\&#34;&gt;802.AX-2008&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.1d&lt;/td&gt;\n&lt;td&gt;MAC 网桥&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.1D-2004\&#34;&gt;802.1D-2004&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.1p&lt;/td&gt;\n&lt;td&gt;流量类/优先级/QoS&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.1D-2004\&#34;&gt;802.1D-2004&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.1q&lt;/td&gt;\n&lt;td&gt;虚拟往前的局域网/MRP的更正&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.1Q-2005/Corl-2008\&#34;&gt;802.1Q-2005/Corl-2008&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.1s&lt;/td&gt;\n&lt;td&gt;多生成树协议（MSTP）&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.1Q-2005\&#34;&gt;802.1Q-2005&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.1w&lt;/td&gt;\n&lt;td&gt;快速生成树协议（RSTP）&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.1D-2004\&#34;&gt;802.1D-2004&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.1X&lt;/td&gt;\n&lt;td&gt;基于端口的网络控制访问（PNAC）&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.1X-2010\&#34;&gt;802.1X-2010&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.2&lt;/td&gt;\n&lt;td&gt;逻辑链路控制（LLC）&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.2-1998\&#34;&gt;802.2-1998&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.3&lt;/td&gt;\n&lt;td&gt;基本以太网和 10 Mb/s 以太网&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.3-2008\&#34;&gt;802.3-2008&lt;/a&gt;] （第 1 节）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.3u&lt;/td&gt;\n&lt;td&gt;100 Mb/s 以太网（“快速以太网”）&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.3-2008\&#34;&gt;802.3-2008&lt;/a&gt;] （第 2 节）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.3x&lt;/td&gt;\n&lt;td&gt;全双工运行和流量控制&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.3-2008\&#34;&gt;802.3-2008&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.3z/802.3ab&lt;/td&gt;\n&lt;td&gt;1000 Mb/s 以太网（“千兆以太网”）&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.3-2008\&#34;&gt;802.3-2008&lt;/a&gt;] （第 3 节）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.3ae&lt;/td&gt;\n&lt;td&gt;10 Gb/s 以太网&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.3-2008\&#34;&gt;802.3-2008&lt;/a&gt;] （第 4 节）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.3ad&lt;/td&gt;\n&lt;td&gt;链路聚合&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.1AX-2008\&#34;&gt;802.1AX-2008&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.3af&lt;/td&gt;\n&lt;td&gt;以太网供电（PoE，15.4W）&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.3-2008\&#34;&gt;802.3-2008&lt;/a&gt;] （第2 节）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.3ah&lt;/td&gt;\n&lt;td&gt;以太网接入（第一公里以太网）&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.3-2008\&#34;&gt;802.3-2008&lt;/a&gt;] （第 5 节）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.3as&lt;/td&gt;\n&lt;td&gt;帧格式扩展（2000 字节）&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.3-2008\&#34;&gt;802.3-2008&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.3at&lt;/td&gt;\n&lt;td&gt;以太网供电增强（“PoE+”，30W）&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.3at-2009\&#34;&gt;802.3at-2009&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.3ba&lt;/td&gt;\n&lt;td&gt;40/100Gb/s 以太网&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.3ba-2010\&#34;&gt;802.3ba-2010&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.11a&lt;/td&gt;\n&lt;td&gt;运行在 5GHz 的 54Mb/s 的无线局域网&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.11-2007\&#34;&gt;802.11-2007&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.11b&lt;/td&gt;\n&lt;td&gt;运行在 2.4GHz 的 11Mb/s 的无线局域网&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.11-2007\&#34;&gt;802.11-2007&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.11e&lt;/td&gt;\n&lt;td&gt;针对 802.11 的 QoS 增强&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.11-2007\&#34;&gt;802.11-2007&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.11g&lt;/td&gt;\n&lt;td&gt;运行在 2.4GHz 的 54Mb/s 的无线局域网&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.11-2007\&#34;&gt;802.11-2007&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.11h&lt;/td&gt;\n&lt;td&gt;频谱/电源管理扩展&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.11-2007\&#34;&gt;802.11-2007&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.11i&lt;/td&gt;\n&lt;td&gt;安全增强/代替 WEP&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.11-2007\&#34;&gt;802.11-2007&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.11j&lt;/td&gt;\n&lt;td&gt;运行在 4.9 ~ 5.0GHz（日本）&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.11-2007\&#34;&gt;802.11-2007&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.11n&lt;/td&gt;\n&lt;td&gt;预先在 2.4GHz 和 5GHz 的 6.5 ~ 600Mb/s 的无线局域网，&lt;br/&gt;使用可选的 MIMO 和 40MHz 管道&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.11n-2009\&#34;&gt;802.11n-2009&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.11s（草案）&lt;/td&gt;\n&lt;td&gt;网状网，拥塞控制&lt;/td&gt;\n&lt;td&gt;开发中&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.11y&lt;/td&gt;\n&lt;td&gt;运行在 3.7GHz 的 54Mb/s 的无线局域网（许可的）&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.11y-2008\&#34;&gt;802.11y-2008&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.16&lt;/td&gt;\n&lt;td&gt;微波存取全球互通技术（WiMAX）&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.16-2009\&#34;&gt;802.16-2009&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.16d&lt;/td&gt;\n&lt;td&gt;固定的无线城域网标准（WiMAX）&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.16-2009\&#34;&gt;802.16-2009&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.16e&lt;/td&gt;\n&lt;td&gt;固定/移动的无限城域网标准（WiMAX）&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.16-2009\&#34;&gt;802.16-2009&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.16h&lt;/td&gt;\n&lt;td&gt;改进的共存机制&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.16h-2010\&#34;&gt;802.16h-2010&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.16j&lt;/td&gt;\n&lt;td&gt;802.16 中的多跳中继&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.16j-2009\&#34;&gt;802.16j-2009&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.16k&lt;/td&gt;\n&lt;td&gt;802.16 网桥&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.16k-2007\&#34;&gt;802.16k-2007&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.21&lt;/td&gt;\n&lt;td&gt;介质无关切换&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#802.21-2008\&#34;&gt;802.21-2008&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;p&gt;除了 802.3、 802.11、 802.16 标准定义的特定类型的局域网之外，还有一些相关标准适用于所有 IEEE 标准的局域网技术。最常见的是定义**逻辑链路控制（LLC）**的 802.2 标准，其帧头部在 802 网络的帧格式中常见。在 IEEE 的术语中， LLC 和 MAC 是链路层的“子层”，LLC （多数帧格式）对每种网络都是通用的，而 MAC 层可能有所不同。虽然最初的以太网使用 CSMA/CD，但无线局域网常使用  CSMA/CA （CA 是“冲突避免”）。&lt;/p&gt;\n&lt;p&gt;注意 不幸的是， 802.2 和 802.3 共同定义了与 Ethemet II 不同的帧格式，这个情况直到 802.3x 才最终纠正。它已经被纳入 [&lt;a href=\&#34;#802.3-2008\&#34;&gt;802.3-2008&lt;/a&gt;] 。在 TCP/IP 世界中，[&lt;a href=\&#34;#RFC0894\&#34;&gt;RFC0894&lt;/a&gt;] 和 [&lt;a href=\&#34;#RFC2464\&#34;&gt;RFC2464&lt;/a&gt;] 定义了针对以太网的 IP 数据报封装，但旧的 LLC/SNAP 封装仍发布在 [&lt;a href=\&#34;#RFC1042\&#34;&gt;RFC1042&lt;/a&gt;] 中。虽然这不再是一个大问题，但它曾经令人关注，并偶尔出现类似问题 [&lt;a href=\&#34;#RFC4840\&#34;&gt;RFC4840&lt;/a&gt;]。&lt;/p&gt;\n&lt;p&gt;直到最近，帧格式在本质上还一直相同。为了获得该格式的详细信息，并了解它是如何演变的，我们现在将焦点转向这些细节。&lt;/p&gt;\n&lt;h3 id=\&#34;322-以太网帧格式\&#34;&gt;3.2.2 以太网帧格式&lt;/h3&gt;\n&lt;p&gt;所有的以太网（802.3）帧都基于一个共同的格式。在原有规范的基础上，帧格式已被改进以支持额外功能。图 3-3 显示了当前的以太网帧格式，以及它与 IEEE 提出的一个相对新的术语 IEEE 分组（一个在其他标准中经常使用的术语）的关系。&lt;/p&gt;\n&lt;p&gt;以太网帧开始是一个&lt;strong&gt;前导&lt;/strong&gt;字段，接收器电路用它确定一个帧的到达时间，并确定编码位（称为&lt;strong&gt;时钟恢复&lt;/strong&gt;）之间的时间量。由于以太网是一个异步的局域网（即每个以太网接口卡中不保持精确的时钟同步），从一个接口到另一个接口的编码位之间的间隔可能不同。前导是一个公认的模式（典型值为 &lt;code&gt;0xAA&lt;/code&gt;），在发现**帧起始分隔符（SFD）**时，接收器使用它“恢复时钟”。 SFD 的固定值为 &lt;code&gt;0xAB&lt;/code&gt;。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;3\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1651207095547.png\&#34; alt=\&#34;图 3-3\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 3-3   以太网（IEEE802.3）帧格式包含一个源地址和目的地址、一个重载的&lt;strong&gt;长度/类型&lt;/strong&gt;字段、一个数据字段和一个帧校验序列（CRC32）。另外，基本帧格式提供了一个标签，其中包含一个 VLAN ID 和优先级信息（802.1p/q），以及一个最近出现的可扩展标签。前导和 SFD 被用于接收器同步。当以太网以半双工模式运行在 100Mb/s 或以上速率时，其他位可能被作为载体扩展添加到短帧中，以确保冲突检测电路的正常运行&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;注意  最初以太网的位编码使用两个电压等级的曼彻斯特相位编码（MPE）。通过 MPE，\n每位被编码为电压变化，而不是绝对值。例如， 0 位被编码为从 -0.85V 到 +0.85V 的变化，\n1 位被编码为从 +0.85V 到 -0.85V 的变化（0V 指共享线路处于空闲状态）。 10Mb/s \n以太网规范要求网络硬件使用 20MHz 振荡器，因为 MPE 的每位需要两个时钟周期。\n字节 0xAA （二进制为10101010）在以太网的前导中，表示为一个 +0.85 和 -0.85V 之间\n的 10MHz 频率的方波。在其他以太网标准中，曼彻斯特编码被替换为不同编码，以提高效率。\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;这个基本的帧格式包括 48 位（6 字节）的**目的地址（DST）&lt;strong&gt;和&lt;/strong&gt;源地址（SRC）**字段。这些地址有时也采用其他名称，例如“MAC地址”、“链路层地址”、“802 地址”、“硬件地址”或“物理地址”。以太网帧的目的地址也允许寻址到多个站点（称为“广播”或“组播”，见第 9 章）。广播功能用于 ARP 协议（见第 4 章），组播功能用于 ICMPv6 协议（见第 8 章），以实现网络层地址和链路层地址之间的转换。&lt;/p&gt;\n&lt;p&gt;源地址后面紧跟着一个&lt;strong&gt;类型&lt;/strong&gt;字段，或一个&lt;strong&gt;长度&lt;/strong&gt;字段。在多数情况下，它用于确定头部后面的数据类型。 TCP/IP 网络使用的常见值包括IPv4 （&lt;code&gt;0x0800&lt;/code&gt;）、 IPv6 （&lt;code&gt;0x86DD&lt;/code&gt;）和 ARP （&lt;code&gt;0x0806&lt;/code&gt;）。 &lt;code&gt;0x8100&lt;/code&gt; 表示一个 Q 标签帧（可携带一个“虚拟局域网”或 802.1q 标准的 VLAN ID）。一个以太网帧的基本大小是 1518 字节，但最近的标准将该值扩大到 2000 字节。&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;注意   最初的 IEEE （802.3）规范将长度/类型字段作为长度字段而不是类型字段使用。\n因此，这个字段被重载（可用于多个目的）。关键是看字段值。目前，如果字段值大于\n或等于 1536，则该字段表示类型，它是由标准分配的超过 1536 的值。如果字段值等于\n或小于 1500，则该字段表示长度。 [ETHERTYPES] 给出了类型的完整列表。\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;在上述字段之后， [&lt;a href=\&#34;#802.3-2008\&#34;&gt;802.3-2008&lt;/a&gt;] 提供了多种标签包含由其他 IEEE 标准定义的各种协议字段。其中，最常见的是那些由 802.1p 和 802.1q 使用的标签，它提供虚拟局域网和一些 **服务质量（Qos）**指示符。这些在 3.2.3 节讨论。&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;注意   当前的 [802.3-2008] 标准采用修改后的 802.3 帧格式，提供最大为 482 字节的\n“标签”，它携带在每个以太网帧中。这些较大的帧称为信封帧，长度最大可能达到\n2000 字节。包含 802.1p/q 标签的帧称为 Q 标签帧，也是信封帧。但是，并非所有\n信封帧必然是 Q 标签帧。\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;在这些讨论过的字段之后，是帧的数据区或&lt;strong&gt;有效载荷&lt;/strong&gt;部分。这里是放高层 PDU （例如IP数据报）的地方。传统上，以太网的有效载荷一直是 1500 字节，它代表以太网的 MTU。 目前，大多数系统为以太网使用 1500 字节的 MTU，虽然在必要时它也可设置为一个较小的值。有效载荷有时被&lt;strong&gt;填充&lt;/strong&gt;（添加）数个 0，以确保帧总体长度符合最小长度要求，这些我们将在 3.2.2.2 节讨论。&lt;/p&gt;\n&lt;h4 id=\&#34;3221-帧校验序列循环冗余校验\&#34;&gt;3.2.2.1 帧校验序列/循环冗余校验&lt;/h4&gt;\n&lt;p&gt;在以太网帧格式中，有效载荷区域之后的最后字段提供了对帧完整性的检查。&lt;strong&gt;循环冗余校验（CRC）&lt;strong&gt;字段位于尾部，有 32 位，有时称之为 IEEE/ANSI 标准的 CRC32 [&lt;a href=\&#34;#802.3-2008\&#34;&gt;802.3-2008&lt;/a&gt;]。要使用一个 n 位 CRC 检测数据传输错误，被检查的消息首先需要追加 n 位 0 形成一个&lt;/strong&gt;扩展消息&lt;/strong&gt;。然后，扩展消息（使用模 2 除法）除以一个（n + 1）位的值，这个作为除数的值称为&lt;strong&gt;生成多项式&lt;/strong&gt;。放置在消息的 CRC 字段中的值是这次除法计算中余数的二进制反码（商被丢弃）。生成多项式已被标准化为一系列不同的 n 值。以太网使用 &lt;code&gt;n=32&lt;/code&gt;， CRC32 的生成多项式是 33 位的二进制数&lt;code&gt;100000100110000010001110110110111&lt;/code&gt;。为了理解如何使用（mod 2）二进制除法计算&lt;br&gt;\n余数，我们看一个 CRC4 的简单例子。国际电信联盟（ITU）将 CRC4 的生成多项式值标准化为&lt;code&gt;10011&lt;/code&gt;，这是在 G.704 [&lt;a href=\&#34;#G704\&#34;&gt;G704&lt;/a&gt;] 标准中规定的。如果我们要发送 16 位的消息&lt;br&gt;\n&lt;code&gt;1001111000101111&lt;/code&gt;，首先开始进行图 3-4 所示的（mod2）二进制除法。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;4\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1652281247055.png\&#34; alt=\&#34;图 3-4\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 3-4   长（mod2）二进制除法延时了 CRC4 的计算过程&lt;/p&gt;\n&lt;p&gt;在该图中，我们看到这个除法的余数是 4 位的值 &lt;code&gt;1111&lt;/code&gt;。通常，该余数的反码（0000）将放置在帧的 CRC 或**帧校验序列（FCS）**字段中。在接收到数据之后，接收方执行相同的除法计算出余数，并判断该值与 FCS 字段的值是否匹配。如果两者不匹配，帧可能在传输过程中受损，通常被丢弃。 CRC 功能可用于提示信息受损，因为位模式的任何改变极可能导致余数的改变。&lt;/p&gt;\n&lt;h4 id=\&#34;3222-帧大小\&#34;&gt;3.2.2.2 帧大小&lt;/h4&gt;\n&lt;p&gt;以太网帧有最小和最大尺寸。最小的帧是 64 字节，要求数据区（有效载荷）长度（无标签）最小为 48 字节。当有效载荷较小时，填充字节（值为0）被添加到有效载荷尾部，以确保达到最小长度。&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;注意   最小长度对最初的 10Mb/s 以太网的 CSMA/CD 很重要。为了使传输数据的\n站能知道哪个帧发生了冲突，将一个以太网的最大长度限制为 2500m（通过4个\n中继器连接的 5 个 500m 的电缆段）。根据电子在铜缆中传播速度约为 0.77c （约\n2.31×108m/s），可得到 64 字节采用 10Mb/s 时的传输时间为 64×8/10000000=\n51.2 μs，最小尺寸的帧能在电缆中传输约 11000m。如果采用一条最长为 2500m \n的电缆，从一个站到另一个站之间的最大往返距离为 5000m。以太网设计者确定最\n小帧长度基于安全因素，在完全兼容（和很多不兼容）的情况下，一个输出帧的最\n后位在所需时间后仍处于传输过程中，这个时间是信号到达位于最大距离的接收器\n并返回的时间。如果这时检测到一个冲突，传输中的站能知道哪个帧发生冲突，即\n当前正在传输中的那个帧。在这种情况下，该站发送一个干扰信号（高电压）提醒\n其他站，然后启动一个随机的二进制指数退避过程。\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;传统以太网的最大帧长度是 1518 字节（包括 4 字节 CRC 和 14 字节头部）。选择这个值出于一种折中：如果一个帧中包括一个错误（接收到不正确的 CRC 校验），只需重发 1.5kB 以修复该问题。另一方面， MTU 大小限制为 1500 字节。为了发送一个更大的消息，则需要多个帧（例如，对于 TCP/IP 网络常用的较大尺寸 64KB，需要至少 44 个帧）。&lt;/p&gt;\n&lt;p&gt;由多个以太网帧构成一个更大的上层 PDU 的后果是，每个帧都贡献了一个固定开销（14 字节的头部和 4 字节的 CRC）。更糟的是，为了允许以太网硬件接收电路正确恢复来自网络的数据，并为其他站提供将自己的流量与已有流量区分开的机会，以太网帧在网络中不能无缝地压缩在一起。 Ethernet II 规范除了在帧开始处定义了 7 字节前导和 1 字节 SFD 之外，还指定了 12 字节的包间距（IPG）时间（10Mb/s 为9.6μs， 100Mb/s 为 960ns， 1000Mb/s 为 96ns， 10000Mb/s 为 9.6ns）。因此， Ethernet II 的每帧效率最多为 &lt;code&gt;1500/(12 + 8 + 14 + 1500 + 4)=0.975293&lt;/code&gt;，约 98%。一种提高效率的方式是，在以太网中传输大量数据时，尽量使帧尺寸更大一些。这可采用以太网&lt;strong&gt;巨型帧&lt;/strong&gt; [&lt;a href=\&#34;#JF\&#34;&gt;JF&lt;/a&gt;] 来实现，它是一种非标准的以太网扩展（主要在 1000Mb/s 以太网交换机中使用），通常允许帧尺寸高达 9000 字节。有些环境使用的帧称为&lt;strong&gt;超级巨型帧&lt;/strong&gt;，它们通常超过 9000 字节。在使用巨型帧时要谨慎，这些较大的帧无法与较小的 1518 字节的帧互操作，因为它们无法由大多数传统以太网设备处理。&lt;/p&gt;\n&lt;h3 id=\&#34;323-8021pq虚拟局域网和-qos-标签\&#34;&gt;3.2.3 802.1p/q：虚拟局域网和 QoS 标签&lt;/h3&gt;\n&lt;p&gt;随着交换式以太网的使用越来越多，位于同一以太网中的每台主机互连已成可能。这样做的好处是，任何主机都可直接与其他主机通信，它们使用 IP 和其他网络层协议，并很少或根本不需要管理员配置。另外，广播和组播流量（见第 9 章）被分发到所有希望接收的主机，而不必建立特殊的组播路由协议。虽然这是很多主机位于同一以太网的优势，但在很多主机使用广播时，广播到每台主机将带来大量网络流量，并出于某些安全因素可能要禁止任意站之间通信。&lt;/p&gt;\n&lt;p&gt;为了解决大型多用途交换网络运行中的问题， IEEE 采用一种称为**虚拟局域网（VLAN）**的功能扩展 802 LAN 标准，它被定义在 802.1q [&lt;a href=\&#34;#802.1Q-2005\&#34;&gt;802.1Q-2005&lt;/a&gt;]标准中。兼容的以太网交换机将主机之间的流量分隔为常见的 VLAN。注意，正是由于这种分隔，连在同一交换机但在不同 VLAN 中的两台主机，它们之间的流量需要一台路由器来传递。已研发出交换机/路由器组合设备来满足这种需求，路由器性能最终得到改进以匹配 VLAN 交换性能。因此， VLAN 的吸引力已有所减弱，现代高性能路由器逐渐取代它们。尽管如此，它们仍在使用，在某些环境中仍受欢迎，因此有必要了解它们。&lt;/p&gt;\n&lt;p&gt;工作站到 VLAN 的映射有几种方法。通过端口分配 VLAN 是一种简单而常见的方法，交换机端口所连接的站被分配在一个特定 VLAN 中，这样连接的任意站就都成为 VLAN 中的成员。其他选择包括基于 MAC 地址的 VLAN，以太网交换机使用表将一个站的 MAC 地址映射到一个 VLAN。如果有些站改变它们的 MAC 地址（由于某些用户行为，有时需要这样做），它们可能变得难以管理。 IP 地址也可用作分配 VLAN 的基础。&lt;/p&gt;\n&lt;p&gt;当不同 VLAN 中的站连接在同一交换机时，交换机确保流量不在两个 VLAN 之间泄漏，无论这些站使用哪种类型的以太网接口。当多个 VLAN 跨越多个交换机（&lt;strong&gt;中继&lt;/strong&gt;）时，在以太网帧发送到另一台交换机之前，需要使用 VLAN 来标记该帧的归属。本功能使用一个称为 &lt;strong&gt;VLAN标签&lt;/strong&gt;（或头部）的标记，其中包含 12 位 &lt;strong&gt;VLAN 标识符&lt;/strong&gt;（提供 4096 个 VLAN，但保留 VLAN 0 和 VLAN 4095）。它还包含支持 QoS 的 3 位优先级（定义在 802.1p 标准中），如图 3-3 所示。在很多情况下，管理员必须配置交换机端口，以便发送 802.1p/q 帧时能中继到适当的端口。为了使这项工作更加容易，有些交换机通过中继端口支持&lt;strong&gt;本地 VLAN&lt;/strong&gt; 选项，这意味着未标记的帧默认与本地 VLAN 相关。中继端口用于互连带 VLAN 功能的交换机，其他端口通常用于直接连接工作站。有些交换机还支持专用的 VLAN 中继方法，例如思科 &lt;strong&gt;内部交换链路（ISL）&lt;/strong&gt; 协议。&lt;/p&gt;\n&lt;p&gt;802.1p 规定了在帧中表示 QoS 标识符的机制。802.1p 头部包括一个 3 位优先级字段，它用于表明一个 QoS 级别。这个标准是 802.1q VLAN 标准的扩展。这两个标准可以一起工作，并在同一头部中共享某些位。它用 3 个有效位定义了 8 个服务级别。 0 级为最低优先级，用于传统的尽力而为的流量。 7 级为最高优先级，可用于关键路由或网管功能。这个标准规定了优先级如何被编码在分组中，但没指定如何控制哪些分组采用哪个级别，以及实现优先级服务的底层机制，这些可由具体的实现者来定义。因此，一个优先级流量相对于另一个的处理方式是由实现或供应商定义的。注意，如果 802.1p/q 头部中的 VLAN ID 字段被设置为 0， 802.1p 可以独立于 VLAN 使用。&lt;/p&gt;\n&lt;p&gt;控制 802.1p/q 信息的 Linux 命令是 &lt;code&gt;vconfig&lt;/code&gt;。它可用来添加和删除虚拟接口，即与物理接口相关联的 VLAN ID。它也可用来设置 802.1p 优先级，更改虚拟接口确定方式，改变由特定 VLAN ID 标记的分组之间的映射，以及协议在操作系统中处理时如何划分优先级。下面的命令为 VLAN ID 为 2 的接口 eth1 添加、删除虚拟接口，修改虚拟接口的命名方式并添加新接口：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;Linux# vconfig add eth1 2\nAdded VLAN with VID == 2 to IF -:eth1:-\nLinux# ifconfig eth1.2\nethl.2 Link encap:Ethernet HWaddr 00:04:5A:9F:9E:80\n            BROADCAST MULTICAST MTU:1500 Metric:1\n            RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n            TX packets:0 errors:0 dropped:0 overruns:0 carrier:O\n            collisions:0 txqueuelen:0\n            RX bytes:0 (0.0 b) TX bytes:0 (0.0 b)\nLinux# vconfig rem eth1.2\nRemoved VLAN -:eth1.2:-\nLinux# vconfig set_name_type VLAN_PLUS_VID\nSet name-type for VLAN subsystem. Should be visible in\n            /proc/net/vlan/config\nLinux# vconfig add eth1 2\nAdded VLAN with VID == 2 to IF -:eth1:-\nLinux# ifconfig vlan0002\nvlan0002 Link encap:Ethernet HWaddr 00:04:5A:9F:9E:80\n            BROADCAST MULTICAST MTU:1500 Metric:1\n            RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n            TX packets:0 errors:0 dropped:0 overruns:0 carrier:O\n            collisions:0 txqueuelen:0\n            RX bytes:0 (0.0 b) TX bytes:0 (0.0 b)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;这里，我们可以看到在 Linu x中，虚拟接口命名的默认方法是将相关物理接口与 VLAN ID 串联。例如， VLAN ID 2 与接口 eth1 关联为 eth1.2。这个例子还显示了另一种命名方法，VLAN 被枚举为名称  &lt;code&gt;vlan &amp;lt;n&amp;gt;&lt;/code&gt;，其中 &lt;code&gt;&amp;lt;n&amp;gt;&lt;/code&gt; 是 VLAN 的标识符。一旦这样设置， VLAN 设备发送帧会如期望的那样被标记为VLAN ID。我们可通过 Wireshark 看到，如图 3-5 所示。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;5\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1652326011999.png\&#34; alt=\&#34;图 3-5\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 3-5   VLAN ID 标记的帧显示在 Wireshark 中。默认的列和设置已被修改，以显示 VLAN ID 和原始以太网地址&lt;/p&gt;\n&lt;p&gt;本图显示了一个在 VLAN 2 中传输的 ARP 分组（见第 4 章）。我们可以看到，该帧大小为 60 字节（不包括 CRC）。该帧用 Ethemet II 封装（类型 0x8100），表示一个 VLAN。另外，VLAN 头部表明该帧属于 VLAN 2，优先级为 0，并且是普通帧。其他字段如我们预期的是一个普通 ARP 分组。&lt;/p&gt;\n&lt;h3 id=\&#34;324-8021ax链路聚合以前的-8023ad\&#34;&gt;3.2.4 802.1AX：链路聚合（以前的 802.3ad）&lt;/h3&gt;\n&lt;p&gt;有些系统配备多个网络接口，具有 &lt;strong&gt;绑定（bonding）&lt;/strong&gt; 或 &lt;strong&gt;链路聚合&lt;/strong&gt; 能力。通过链路聚合，两个或更多接口被视为一个，通过冗余或将数据分割（分拆）到多个接口，提高性能并获得更好的可靠性。 IEEE修订的 802.1AX [&lt;a href=\&#34;#802.1AX-2008\&#34;&gt;802.1AX-2008&lt;/a&gt;] 定义了最常用的链路聚合方法，以及可管理这些链路的&lt;strong&gt;链路聚合控制协议（LACP）&lt;/strong&gt;。 LACP 使用一种特定格式的 IEEE 802 帧（称为LACPDU）。&lt;/p&gt;\n&lt;p&gt;以太网交换机支持的链路聚合是一个替代方案，它比支持更高速网络接口的性价比高。如果多个端口聚合能提供足够的带宽，则可能并不需要高速接口。链路聚合不仅可被网络交换机支持，而且可在一台主机上跨越多个&lt;strong&gt;网络接口卡（NIC）&lt;/strong&gt;。在通常情况下，聚合的端口必须是同一类型，并工作在同一模式（半双工或全双工）下。&lt;/p&gt;\n&lt;p&gt;Linux 可实现跨越不同类型设备的链路聚合（绑定），使用以下命令：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;Linux# modporbe bonding\nLinux# ifconfig bond0 10.0.0.111 netmask 255.255.255.128\nLinux# ifenslave bond0 eth0 wlan0\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;这组命令中的第一个用于加载绑定驱动，它是一个支持链路聚合的特殊设备驱动程序。第二个命令使用 IPv4 地址来创建 bond0 接口。虽然 IP 相关信息对创建聚合接口不是必需的，但它是典型的。在 &lt;code&gt;ifenslave&lt;/code&gt; 命令执行后，绑定设备 bond0 用 MASTER 标志来标记，而设备 eth0 和 wlan0 用 SLAVE 标志来标记：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;bond0 Link encap:Ethernet HWaddr 00:11:A3:00:2C:2A\n            inet addr:10.0.0.111 Bcast:10.0.0.127 Mask:255.255.255.128\n            inet6 addr: fe80::211:a3ff:fe00:2c2a/64 Scope:Link\n            UP BROADCAST RUNNING MASTER MULTICAST MTU:1500 Metric:1\n            RX packets:2146 errors:0 dropped:0 overruns:0 frame:0\n            TX packets:985 errors:0 dropped:0 overruns:0 carrier:O\n            collisions:18 txqueuelen:0\n            RX bytes:281939 (275.3 Kib) TX bytes:141391 (138.0 Kib)\neth0 Link encap:Ethernet HWaddr 00:11:A3:00:2C:2A\n            UP BROADCAST RUNNING SLAVE MULTICAST MTU:1500 Metric:1\n            RX packets:1882 errors:0 dropped:0 overruns:0 frame:0\n            TX packets:961 errors:0 dropped:0 overruns:0 carrier:O\n            collisions:18 txqueuelen:1000\n            RX bytes:244231 (238.5 Kib) TX bytes:136561 (133.3 Kib)\n            Interrupt:20 Base address:0x6c00\nwlan0 Link encap:Ethernet HWaddr 00:11:A3:00:2C:2A\n            UP BROADCAST RUNNING SLAVE MULTICAST MTU:1500 Metric:1\n            RX packets:269 errors:0 dropped:0 overruns:0 frame:0\n            TX packets:24 errors:0 dropped:0 overruns:0 carrier:O\n            collisions:18 txqueuelen:1000\n            RX bytes:38579 (37.6 Kib) TX bytes:4830 (4.7 Kib)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;在这个例子中，我们将一个有线以太网接口和一个 Wi-Fi 接口绑定在一起。为主设备 bond0 分配了 IPv4 地址信息，通常分配给两个独立接口之一，它默认使用第一个从设备的 MAC 地址。当 IPv4 流量通过 bond0 虚拟接口发送时，很可能使用不同的从设备来发送。在 Linux 中，当绑定的驱动程序被加载时，可使用系统提供的参数选择选项。例如，模式选项决定了能否做以下工作：在接口之间使用循环交付，一个接口作为另一个接口的备份使用，基于对 MAC 源地址和目的地址执行的异或操作选择接口，将帧复制到所有接口，执行 802.3ad 标准的链路聚合，或采用更先进的负载平衡选项。第二种模式用于高可用性系统，当一个链路停止运行时（由 MII 监控来检测；更多细节见 [&lt;a href=\&#34;#BOND\&#34;&gt;BOND&lt;/a&gt;] ），这种系统将故障部分转移到冗余的网络基础设施上。第三种模式是基于流量的流向选择从接口。如果目的地完全不同，两个站之间的流量被固定到一个接口。在希望尽量少尝试重新排序，并保证多个接口负载平衡的情况下，这种模式可能是有效的。第四种模式针对容错。第五种模式用于支持 802.3ad 的交换机，在同类链路上实现动态聚合能力。&lt;/p&gt;\n&lt;p&gt;LACP 协议旨在通过避免手工配置，以简化链路聚合的建立工作。在 LACP “主角” （客户端）和“参与者” （服务器）启用后，它们通常每秒都会发送 LACPDU。 LACP 自动确定哪些成员链路可被聚合成一个&lt;strong&gt;链路聚合组（LAG）&lt;/strong&gt;，并将它们聚合起来。这个过程的实现需要通过链路发送一系列信息（MAC地址、端口优先级、端口号和密钥）。一个接收站可比较来自其他端口的值，如果匹配就执行聚合。 LACP 协议的细节见[&lt;a href=\&#34;#802.1AX-2008\&#34;&gt;802.1AX-2008&lt;/a&gt;]。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;33-全双工-省电-自动协商和-8021x-流量控制\&#34;&gt;3.3 全双工、省电、自动协商和 802.1X 流量控制&lt;/h2&gt;\n&lt;p&gt;当以太网最初被开发出来时，它仅工作在半双工模式，并使用一条共享的电缆。也就是说，同一时间内只能在一个方向发送数据，因此在任何时间点只有一个站可发送一个帧。随着交换式以太网的发展，网络不再是单一的共享线路，而代之以很多链路的组合。因此，多个站之间可以同时进行数据交换。另外，以太网被修改为全双工操作，这样可以有效禁用冲突检测电路。这样也可以增加以太网的物理长度，因为半双工操作和冲突检测的相关时间约束被取消。&lt;/p&gt;\n&lt;p&gt;在 Linux 中， &lt;code&gt;ethtool&lt;/code&gt; 程序可用于查询是否支持全双工，以及是否正在执行全双工操作。这个工具也可显示和设置以太网接口的很多属性：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;Linux# ethtool eth0\nSettings for eth0:\n            Supported ports: [ TP MII ]\n            supported link modes: 10baseT/Half 10baseT/Full\n                                100baseT/Half 100baseT/Full\n            Supports auto-negotiation: Yes\n            Advertised link modes: 10baseT/Half 10baseT/Full\n                                100baseT/Half 100baseT/Full\n            Advertised auto-negotiation: Yes\n            Speed: 10Mb/s\n            Duplex: Half\n            Port: MII\n            PHYAD: 24\n            Transceiver: internal\n            Auto-negotiation: on\n            Current message level: 0x00000001 (1)\n            Link detected: yes\nLinux# ethtool eth1\nSettings for eth1:\n            Supported ports: [ TP ]\n            supported link modes: 10baseT/Half 10baseT/Full\n                                100baseT/Half 100baseT/Full\n                                1000baseT/Full\n            Supports auto-negotiation: Yes\n            Advertised link modes: 10baseT/Half 10baseT/Full\n                                100baseT/Half 100baseT/Full\n                                1000baseT/Full\n            Advertised auto-negotiation: Yes\n            Speed: 100Mb/s\n            Duplex: Full\n            Port: Twisted Pair\n            PHYAD: 0\n            Transceiver: internal\n            Auto-negotiation: on\n            Supports Wake-on: umbg\n            Wake-on: g\n            Current message level: 0x00000007 (7)\n            Link detected: yes\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;在这个例子中，第一个以太网接口（eth0）连接到一个半双工的 10Mb/s 网络。我们看到它能够&lt;strong&gt;自动协商&lt;/strong&gt;，这是一种来源于 802.3u 的机制，使接口能交换信息（例如速度）和功能（例如半双工或全双工运行）。自动协商信息在物理层通过信号交换，它可在不发送或接收数据时发送。我们可以看到，第二个以太网接口（eth1）也支持自动协商，它的速率为 100Mb/s，工作模式为全双工。其他值（Port、PHYAD、 Transceiver）指出物理端口类型、地址，以及物理层电路在 NIC 内部还是外部。当前消息级别用于配置与接口操作模式相关的日志消息，它的行为由使用的驱动程序指定。我们在下面的例子讨论如何设置这些值。&lt;/p&gt;\n&lt;p&gt;在 Windows 中，我们可以看到以下细节，首先进入“控制面板”中的“网络连接”，然后在感兴趣的接口上单击鼠标右键并选择“属性”，然后单击“配置”框并选择“高级”选项卡。这时，将打开一个类似图 3-6 （这个例子来自 Windows 7 机器上的以太网接口）所示的对话框。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;6\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1652338313157.png\&#34; alt=\&#34;图 3-6\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 3-6   Windows (7) 的网络接口属性的“高级”选项卡。该控件允许用户提供网络设备驱动程序的运行参数&lt;/p&gt;\n&lt;p&gt;在图 3-6 中，我们可看到通过适配器的设备驱动程序来配置的特殊功能。对于这个特殊的适配器和驱动程序， 802.1p/q 标签可启用或禁用，也可提供流量控制和唤醒功能（见 3.3.2 节）。我们可以手工设置速率和双工模式，或使用更典型的自动协商选项。&lt;/p&gt;\n&lt;h3 id=\&#34;331-双工不匹配\&#34;&gt;3.3.1 双工不匹配&lt;/h3&gt;\n&lt;p&gt;自动协商曾经有一些互操作性问题，特别是一台计算机及其相关的交换机端口使用不同的双工配置时，或者当自动协商只在链路的一端被禁用时。在这些情况下，可能会发生双工不匹配。令人惊讶的是，当这种状况发生时，连接不会完全失败，但可能带来显著的性能下降。当网络中出现中等程度的双向流量繁忙时（例如，在大数据传输期间），一个半双工接口会将输入的流量检测为冲突，从而触发以太网 MAC 的 CSMA/CD 的指数退避功能。同时，导致这个冲突的数据被丢弃，这可能需要更高层协议（例如 TCP）重传。因此，性能下降可能只在半双工接口发送数据，同时又有大量流量需要接收时才是明显的，站处于轻负载时通常不会发生这种情况。一些研究者已试图开发分析工具来检测这种问题 [&lt;a href=\&#34;#SC05\&#34;&gt;SC05&lt;/a&gt;]。&lt;/p&gt;\n&lt;h3 id=\&#34;332-局域网唤醒wol-省电和魔术分组\&#34;&gt;3.3.2 局域网唤醒（WoL）、省电和魔术分组&lt;/h3&gt;\n&lt;p&gt;在 Linux 和 Windows 的例子中，我们看到一些电源管理方面的功能。** Windows 唤醒功能**和 &lt;strong&gt;Linux 唤醒&lt;/strong&gt; 选项用于使网络接口或主机脱离低功耗（睡眠）状态，这是基于某类分组的传输来实现的。这种分组用来触发可配置的功率状态改变。在 Linux 中，用于唤醒的值可以是零，或者是多个用于低功耗状态唤醒的位，它们可以被以下几种帧所触发：任何物理层（PHY）活动（p）、发往站的单播帧（u）、组播帧（m）、广播帧（b）、 ARP 帧（a）、魔术分组帧（g），以及包括密码的魔术分组帧。这些都可以使用 &lt;code&gt;ethtool&lt;/code&gt; 的选项来配置。例如，可以使用以下命令：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;Linux# ethtool -s eth0 wol umgb\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;当接收到任何 u、 m、 g 或 b 类型的帧时，这个命令将 eth0 设备配置为发送一个唤醒信号。Windows 提供了类似的功能，但标准的用户接口只支持魔术分组帧，以及一个预定义的 u、m、b和a类型帧的子集。魔术分组包含一个字节值 &lt;code&gt;0xFF&lt;/code&gt; 的特定重复模式。在通常情况下，这种帧采用 UDP 分组（见第 10 章）形式封装在以太网广播帧中发送。有几个工具可以生成它们，包括 wol [&lt;a href=\&#34;#WOL\&#34;&gt;WOL&lt;/a&gt;] ：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;Linux# wol 00:08:74:93:C8:3C\nWaking up 00:08:74:93:C8:3C...\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;这个命令的结果是构造一个魔术分组，我们可以使用 Wireshark 查看( 见图 3-7 )。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;7\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1652346183244.png\&#34; alt=\&#34;图 3-7\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 3-7   Wireshark 中的一个魔术分组帧，开始是 6 字节的 0xFF，然后重复 MAC 地址 16 次&lt;/p&gt;\n&lt;p&gt;图 3-7 中显示的分组多数是传统的 UDP 分组，但端口号（1126 和 40000）是任意的。分组中最特别的是数据区域。它以一个 6 字节的值 0xFF 开始，其余部分包含重复 16 次的目的 MAC 地址&lt;code&gt;00:08:74:93:C8:3C&lt;/code&gt;。该数据的有效载荷模式定义了魔术分组。&lt;/p&gt;\n&lt;h3 id=\&#34;333-链路层流量控制\&#34;&gt;3.3.3 链路层流量控制&lt;/h3&gt;\n&lt;p&gt;以全双工模式运行扩展的以太网和跨越不同速率的网段时，可能需要由交换机将帧缓存（保存）一段时间。例如，当多个站发送到同一目的地（称为输出端口争用），这种情况可能发生。如果一个站聚合的流量速率超过该站的链路速率，那么帧就开始存储在中间交换机中。如果这种情况持续一段时间，这些帧可能被丢弃。&lt;/p&gt;\n&lt;p&gt;缓解这种情况的一种方法是在发送方采取&lt;strong&gt;流量控制&lt;/strong&gt;（使它慢下来）。一些以太网交换机（和接口）通过在交换机和网卡之间发送特殊信号帧来实现流量控制。流量控制信号被发送到发送方，通知它必须放慢传输速率，但规范将这些细节留给具体实现来完成。以太网使用** PAUSE 消息（也称为PAUSE帧）**实现流量控制，它由 802.3x [&lt;a href=\&#34;#802.3-2008\&#34;&gt;802.3-2008&lt;/a&gt;] 来定义。&lt;/p&gt;\n&lt;p&gt;PAUSE 消息包含在 MAC 控制帧中，通过将以太网&lt;strong&gt;长度/类型&lt;/strong&gt;字段值设为 &lt;code&gt;0x8808&lt;/code&gt;，以及使用 MAC 控制操作码 &lt;code&gt;0x0001&lt;/code&gt; 来标识。如果一个站接收到这种帧，表示建议它减缓发送速度。 PAUSE 帧总是被发送到 MAC 地址 &lt;code&gt;01:80:C2:00:00:01&lt;/code&gt;，并且只能在全双工链路上使用。它包含一个保持关闭（hold-off）时间值（指定量为 512 比特的时间），表明发送方在继续发送之前需要暂停多长时间。&lt;/p&gt;\n&lt;p&gt;MAC 控制帧采用如图 3-3 所示的常规封装的帧格式，但紧跟在&lt;strong&gt;长度/类型&lt;/strong&gt;字段后的是一个 2 字节的操作码。 PAUSE 帧实际上是唯一一种使用 MAC 控制帧的帧类型。它包括一个 2 字节的保持关闭时间。 “整个” MAC 控制层（基本只是 802.3x 流量控制）的实现是可选的。&lt;/p&gt;\n&lt;p&gt;以太网层次的流量控制可能有重大负面影响，因此通常并不使用它。当多个站通过一台过载的交换机发送时（见下一节），该交换机通常向所有主机发送 PAUSE 帧。不幸的是，交换机的内存使用可能对发送主机不均衡，因此有些主机可能被惩罚（流量控制），即使它们对交换机流量过载没有多少责任。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;34-网桥和交换机\&#34;&gt;3.4 网桥和交换机&lt;/h2&gt;\n&lt;p&gt;IEEE 802.1d 标准规定了网桥的操作，交换机本质上是高性能的网桥。网桥或交换机用于连接多个物理的链路层网络（例如一对物理的以太网段）或成组的站。最基本的设置涉及连接两个交换机来形成一个扩展的局域网，如图 3-8 所示。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;8\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1652347179551.png\&#34; alt=\&#34;图 3-8\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 3-8   一个包括两台交换机的扩展以太网。每个交换机端口有一个编号，每个站（包括每个交换机）有自己的 MAC 地址&lt;/p&gt;\n&lt;p&gt;图中的交换机 A 和 B 互连形成一个扩展的局域网。在这个特定例子中，客户端系统都连接到 A，服务器都连接到 B，端口编号供参考。注意，每个网络单元（包括每个交换机）有自己的 MAC 地址。每个网桥经过一段时间对域外 MAC 地址的“学习”后，最终每个交换机会知道每个站可由哪个端口到达。每个交换机基于每个端口（也可能是每个 VLAN）的列表被存储在一张表（称为&lt;strong&gt;过滤数据库&lt;/strong&gt;）中。图 3-9 显示每个交换机了解每个站的位置后，形成的包含这些信息的数据库例子。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;9\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1652349458178.png\&#34; alt=\&#34;图 3-9\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;当第一次打开一个交换机（网桥）时，它的数据库是空的，因此它不知道除自己之外的任何站的位置。当它每次接收到一个目的地不是自己的帧时，它为除该帧到达的端口之外的所有端口做一个备份，并向所有端口发送这个帧的备份。如果交换机（网桥）未学习到站的位置，每个帧将会被交付到每个网段，这样会导致不必要的开销。学习能力可以显著降低开销，它是交换机和网桥的一个基本功能。&lt;/p&gt;\n&lt;p&gt;目前，多数操作系统支持网络接口之间的网桥功能，这意味着具有多个接口的计算机可用作网桥。例如，在 Windows 中，多个接口可被桥接，进入“控制面板”的“网络连接”菜单，选中（突出显示）需要桥接的接口，点击鼠标右键，并选择“网桥连接”。这时，出现一个表示网桥功能的新图标。许多接口相关的正常网络属性消失，取而代之的是网桥设备（见图 3-10）。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;10\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1652350474031.png\&#34; alt=\&#34;图 3-10\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 3-10   在 Windows 中，通过选中需要桥接的网络接口，鼠标右击并选择桥接网络接口，可创建网桥设备。在网桥建立之后，可进一步修改网桥设备&lt;/p&gt;\n&lt;p&gt;图 3-10 显示 Windows 7 中的虚拟网桥设备的属性面板。网桥设备的属性包括一个被桥接的相关设备列表，以及在网桥上运行的一组服务（例如， Microsoft网络客户端、文件和打印机共享等）。 Linux 以类似方式工作，它使用命令行参数。在这个例子中，我们使用图 3-11 所示的拓扑结构。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;11\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1652350584033.png\&#34; alt=\&#34;图 3-11\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 3-11   在这个简单的拓扑中，一台基于 Linux 的 PC 被配置为网桥，它在两个以太网之间实现互联。作为一个处于学习中的网桥，它不断积累并建立一些表，其中包含有关哪个端口可到达扩展局域网中的其他系统的信息&lt;/p&gt;\n&lt;p&gt;在图 3-11 中，这个简单的网络使用一台基于 Linux、带两个端口的 PC 作为网桥。只有一个站连接到端口 2，网络其他部分都连接到端口 1。以下命令可启用网桥：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;Linux# brctl addbr br0\nLinux# brctl addif br0 eth0\nLinux# brctl addif br0 eth1\nLinux# ifconfig eth0 up\nLinux# ifconfig eth1 up\nLinux# ifconfig br0 up\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;以下几个命令可创建一个网桥设备 br0，并为网桥增加接口 eth0 和 eth1。 &lt;code&gt;brctl delif&lt;/code&gt; 命令可用于删除接口。在建立接口之后， &lt;code&gt;brctl showmacs&lt;/code&gt; 命令可用于检查过滤数据库（称为&lt;strong&gt;转发数据库&lt;/strong&gt;，用 Linux 的术语称为 fdbs）：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;Linux# brctl show\nbridge name  bridge id           STP     enabled     interfaces\nbr0          8000.0007e914a9cl   no       eth0          eth1\nLinux# brctl showmacs br0\nport no mac addr is local? ageing timer\n1 00:04:5a:9f:9e:80 no 0.79\n2 00:07:e9:14:a9:cl yes 0.00\n1 00:08:74:93:c8:3c yes 0.00\n2 00:14:22:f4:19:5f no 0.81\n1 00:17:f2:e7:6d:91 no 2.53\n1 00:90:f8:00:90:b7 no 17.13\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;这个命令的输出显示关于网桥的其他细节。由于站可能出现移动、网卡更换、 MAC 地址改变或其他情况，所以就算网桥曾发现一个 MAC 地址可通过某个端口访问，这个信息也不能假设永远是正确的。为了解决这个问题，在每次学习一个地址后，网桥启动一个计时器（通常默认为5分钟）。在 Linux 中，每个学习条目使用一个与网桥相关的固定时间。如果在指定的“有效期”内，没有再次看到该条目中的地址，则将这个条目删除，如下所示：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;Linux# brctl setageing br0 1\nLinux# brctl showmacs br0\nport no mac addr is local? ageing timer\n1 00:04:5a:9f:9e:80 no 0.79\n2 00:07:e9:14:a9:cl yes 0.00\n1 00:08:74:93:c8:3c yes 0.00\n2 00:14:22:f4:19:5f no 0.78\n1 00:17:f2:e7:6d:91 no 0.00\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;为了方便演示，我们选择了一个比平时数值低的值作为&lt;strong&gt;有效期&lt;/strong&gt;。当一个条目因有效期满而被删除时，后续的帧将被发送到接收端口之外的所有端口（称为&lt;strong&gt;洪泛&lt;/strong&gt;），并更新过滤数据库中的这个条目。实际上，过滤数据库的使用和学习有利于优化性能，如果表是空的，网络将花费更多开销，但仍能履行职责。下一步，我们将注意力转移到两个以上的网桥通过冗余链路互联的情况。在这种情况下，帧的洪泛可能导致帧永远循环的洪泛灾难。显然，我们需要一种方法来解决这个问题。&lt;/p&gt;\n&lt;h3 id=\&#34;341-生成树协议\&#34;&gt;3.4.1 生成树协议&lt;/h3&gt;\n&lt;p&gt;网桥可能单独或与其他网桥共同运行。当两个以上的网桥使用（或交换机端口交叉连接）时，由于存在级联的可能性，因此可能形成很多组的循环帧。我们看如图 3-12 所示的网络。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;12\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1652351442343.png\&#34; alt=\&#34;图 3-12\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 3-12   一个扩展的以太网包括 4 台交换机和多条冗余链路。如果在这个网络中采用简单的洪泛转发帧，由于多余的倍增流量（所谓的广播风暴），将会导致一场大的灾难。这种情况需要使用 STP&lt;/p&gt;\n&lt;p&gt;假设图 3-12 中的多个交换机刚被打开，并且它们的过滤数据库为空。当站 S 发送一个帧时，交换机 B 在端口 7、 8 和 9 复制该帧。这时，最初的帧已被“放大” 3 倍。这些帧被交换机 A、 D 和 C 接收。交换机 A 在端口 2 和 3 生成该帧的副本。交换机 D 和 C 分别在端口 20、 22 和 13、 14 生成更多副本。当这些副本在交换机 A、 C 和 D 之间双向传输，这时放大倍数已增大为6。 当这些帧到达时，&lt;br&gt;\n转发数据库开始出现震荡，这是由于网桥反复尝试查找通过哪些端口可到达站 S。显然，这种情况是不能容忍的。如果允许这种情况发生，采用这种配置的网桥将无法使用。幸运的是，有一种协议可避免这种情况，这种协议称为&lt;strong&gt;生成树协议（STP）&lt;/strong&gt;。我们将介绍 STP 的一些细节，解释网桥和交换机采用哪些方法抑制放大。在当前的标准 [&lt;a href=\&#34;#802.1D-2004\&#34;&gt;802.1D-2004&lt;/a&gt;] 中，传统的 STP 被**快速生成树协议（RSTP）**代替，我们将在了解传统 STP 的基础上再介绍它。&lt;/p&gt;\n&lt;p&gt;STP 通过在每个网桥禁用某些端口来工作，这样可避免拓扑环路（即两个网桥之间不允许出现重复路径），但如果拓扑结构未分区，则仍可到达所有站。在数学上，一个生成树是一张图中所有节点和一些线的集合，从任何节点到其他节点（跨越图）有一条路径或路由，但是没有环路（这些线的集合构成一棵树）。一张图可能存在多个生成树。 STP 用于找出这张图的其中一个生成树，该图将网桥作为节点并将链路作为线（或称“边”）。图 3-13 说明了这个想法。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;13\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1652352139379.png\&#34; alt=\&#34;图 3-13\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 3-13   通过 STP，链路 B-A、 A-C 和 C-D 在生成树中是活跃的。端口 6、7、 1、2、 13、14 和 20 处于转发状态；所有其他端口被阻塞（即不转发）。这样可以防止帧循环，避免广播风暴。如果配置发生变化或某台交换机故障，则将阻塞端口改变为转发状态，并由网桥计算一个新生成树&lt;/p&gt;\n&lt;p&gt;在本图中，粗线表示网络中被 STP 选择用于转发帧的链路。其他链路没有被使用，端口 8、9、 12、21、22 和 3 被&lt;strong&gt;阻塞&lt;/strong&gt;。通过使用 STP，早期的各种问题并没有出现，这些帧只是作为另一个抵达帧的副本而被创建。这里没有出现放大的问题。由于任意两个站之间只有一条路径，因此可以避免循环。生成树的形成和维护由多个网桥完成，在每个网桥上运行一个分布式算法。&lt;/p&gt;\n&lt;p&gt;用于转发数据库时， STP 必须处理以下情况，例如网桥启用和关闭、接口卡更换或 MAC 地址改变。显然，这种变化可能影响生成树运行，因此 STP 必须适应这些变化。这种适应通过交换一种称为**网桥协议数据单元（BPDU）**的帧来实现。这些帧用来形成和维护生成树。这棵树“生长”自一个网桥——该网桥由其他网桥选举为“根网桥”。&lt;/p&gt;\n&lt;p&gt;如前所述，一个网络可能存在多个生成树。如何确定哪棵生成树最适于转发帧，这基于每条链路和根网桥位置的相关成本。这个成本是一个与链路速度成反比的整数（建议）。例如，一条 10Mb/s 链路的成本为 100， 100Mb/s 和 1000Mb/s 链路的成本分别为 19 和 4。 STP 计算到根网桥的成本最小的路径。如果必须遍历多条链路，相关成本是这些链路成本之和。&lt;/p&gt;\n&lt;h4 id=\&#34;3411-端口状态和角色\&#34;&gt;3.4.1.1 端口状态和角色&lt;/h4&gt;\n&lt;p&gt;为了理解 STP 的基本操作，我们需要了解网桥端口的状态机，以及 BPDU 内容。网桥端口可能有 5 个状态：阻塞、侦听、学习、转发和禁用。在图 3-14 所示的状态转换图中，我们可以看出它们之间的关系。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;14\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1652353538285.png\&#34; alt=\&#34;图 3-14\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 3-14   在正常的 STP 操作中，端口在 4 个主要状态之间转换。在阻塞状态下，帧不被转发，但一次拓扑变化或超时可能导致向侦听状态转换。转发状态是活跃的交换机端口承载数据流量的正常状态。括号中的状态名用于表示 RSTP 相关的端口状态&lt;/p&gt;\n&lt;p&gt;在图 3-14 显示的生成树中，实线箭头表示端口的正常转换，小的虚线箭头表示由管理配置引起的改变。在初始化后，一个端口进入阻塞状态。在这种状态下，它不进行地址学习、数据转发或 BPDU 发送，但它会监控接收的 BPDU，并在它需要被包含在将到达的根网桥的路径中的情况下，使端口转换到侦听状态。在侦听状态下，该端口允许发送和接收 BPDU，但不进行地址学习或数据转发。经过一个典型的 15 秒的转发延迟，端口进入学习状态。这时，它被允许执行数据转发之外的所有操作。在进入转发状态并开始转发数据之前，需要等待另一个转发延迟。&lt;/p&gt;\n&lt;p&gt;相对于端口状态机，每个端口都扮演一定的&lt;strong&gt;角色&lt;/strong&gt;。由于 RSTP （见 3.4.1.6 节）的出现，这个术语变得越来越重要。端口可能扮演&lt;strong&gt;根端口&lt;/strong&gt;、&lt;strong&gt;指定端口&lt;/strong&gt;、&lt;strong&gt;备用端口&lt;/strong&gt;或&lt;strong&gt;备份端口&lt;/strong&gt;等角色。根端口是生成树中位于指向根的线段终点的那些端口。指定端口是指处于转发状态，并与根相连线段中路径成本最小的端口。备用端口是与根相连线段中成本更高的端口。它们不处于转发状态。备份端口是指连接到同一线段中作为同一网桥指定端口使用的端口。因此，备份端口可轻易接管一个失效的指定端口，而不影响生成树拓扑的其余部分，但是它不能在全部网桥失效的情况下提供一条到根的备用路径。&lt;/p&gt;\n&lt;h4 id=\&#34;3412-bpdu-结构\&#34;&gt;3.4.1.2 BPDU 结构&lt;/h4&gt;\n&lt;p&gt;为了确定生成树中的链路， STP 使用图 3-15 所示的 BPDU。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;15\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1652354174126.png\&#34; alt=\&#34;图 3-15\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 3-15   BPDU 被放置在 802 帧的有效载荷区，并在网桥之间交换以建立生成树。重要的字段包括源、根节点、到根的成本和拓扑变化提示。在 802.1w 和 [&lt;a href=\&#34;#802.1D-2004\&#34;&gt;802.1D-2004&lt;/a&gt;] 中（包括快速 ST P或 RSTP），附加字段显示端口状态&lt;/p&gt;\n&lt;p&gt;图 3-15 所示的格式适用于最初的 STP，以及新的 RSTP （见 3.4.1.6 节）。 BPDU 总被发送到组地址 &lt;code&gt;01:80:C2:00:00:00&lt;/code&gt; （链路层组和因特网组播寻址的详细信息见第 9 章），并且不会通过一个未修改的网桥转发。在该图中， DST、 SRC 和 L/T （长度/类型）字段是携带 BPDU 的传统以太网（802.3）帧头部的一部分。 3 字节的 LLC/SNAP 头部由 802.1 定义，并针对 BPDU 被设置为常数 &lt;code&gt;0x424203&lt;/code&gt;。并非所有 BPDU 都使用 LLC/SNAP 封装，但这是一个常见的选项。&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;协议（Prot）&lt;/strong&gt; 字段给出协议 ID 号，它被设置为 0。&lt;strong&gt;版本（Vers）&lt;/strong&gt; 字段被设置为 0 或 2，取决于使用 STP 还是 RSTP。&lt;strong&gt;类型（rtype）&lt;/strong&gt; 字段的分配与版本类似。&lt;strong&gt;标志（Flags）&lt;/strong&gt; 字段包含&lt;strong&gt;拓扑变化（TC）&lt;/strong&gt; 和 &lt;strong&gt;拓扑变化确认（TCA）&lt;/strong&gt; 位，它们由最初的 802.1d 标准定义。附加位被定义为 &lt;strong&gt;建议（P）&lt;/strong&gt;、&lt;strong&gt;端口角色（00 为未知， 01 为备用， 10 为根， 11 为指定）&lt;/strong&gt;、&lt;strong&gt;学习（L）&lt;/strong&gt;、&lt;strong&gt;转发（F）&lt;strong&gt;和&lt;/strong&gt;协议（A）&lt;/strong&gt;。这些都作为 RSTP 内容在 3.4.1.6 节中讨论。根 ID 字段给出发送方使用的根网桥标识符，即从网桥 ID 字段中获得的 MAC 地址。这些 ID 字段都用一种特殊方式编码，包括 MAC 地址之前的一个 2 字节的优先级字段。优先级的值可通过管理软件来设置，以强制要求生成树采用某个特定网桥作为根（例如， Cisco 在自己的 Catalyst 交换机中使用默认值 &lt;code&gt;0x8000&lt;/code&gt;）。&lt;/p&gt;\n&lt;p&gt;根路径成本是在 &lt;strong&gt;根 ID&lt;/strong&gt; 字段中指定的计算出的到达某个网桥的成本。 PID 字段是端口标识符和由发送帧给出的端口号，它被附加在一个可配置的 1 字节的&lt;strong&gt;优先级&lt;/strong&gt;字段（默认为 &lt;code&gt;0x80&lt;/code&gt;）之后。&lt;strong&gt;消息有效期（MsgA）&lt;/strong&gt; 字段指出消息有效期。&lt;strong&gt;最大有效期（MaxA）&lt;/strong&gt; 字段指出超时（默认为 20 秒）的最大期限。&lt;strong&gt;欢迎时间（HelloTime）&lt;/strong&gt; 字段指出配置帧的传输周期。&lt;strong&gt;转发延迟&lt;/strong&gt;字段指出处于学习和侦听状态的时间。所有的有效期和时间字段可在 1/256 秒内获得。&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;消息有效期&lt;/strong&gt;字段不像其他的时间字段那样是固定值。当根网桥发送一个 BPDU 时，它将该字段设置为 0。 网桥转发接收到的不是根端口的帧，并将&lt;strong&gt;消息有效期&lt;/strong&gt;字段加1。从本质上来说，该字段是一个跳步计数器，用于记录 BPDU 经过的网桥数量。当一个 BPDU 被一个端口接收时，其包含的信息在内存和 STP 算法参与者中被保存至超时（超时发生在（MaxA-MsgA）时刻）。如果超过这个时间，根端口没有接收到另一个 BPDU，根网桥被宣布“死亡”，并重新开始根网桥选举过程。&lt;/p&gt;\n&lt;h4 id=\&#34;3413-建立生成树\&#34;&gt;3.4.1.3 建立生成树&lt;/h4&gt;\n&lt;p&gt;STP 的第一个工作是选举根网桥。根网桥是在网络（或 VLAN）中标识符最小（优先级与 MAC 地址结合）的网桥。当一个网桥初始化时，它假设自己是根网桥，并用自己的网桥 ID 作为根 ID 字段的值发送配置 BPDU 消息，如果它检测到一个 ID 更小的网桥，则停止发送自己的帧，并基于接收到的 ID 更小的帧构造下一步发送的 BPDU。发出根 ID 更小的 BPDU 的端口被标记为根端口（即端口在到根网桥的路径上）。剩余端口被设置为阻塞或转发状态。&lt;/p&gt;\n&lt;h4 id=\&#34;3414-拓扑变化\&#34;&gt;3.4.1.4 拓扑变化&lt;/h4&gt;\n&lt;p&gt;STP 的另一个重要工作是处理拓扑变化。虽然可用前面所述的数据库有效期机制适应拓扑变化，但这是一个比较差的方法，因为有效期计时器需要花费很长时间（5分钟）删除错误条目。相反， STP 采用一种方法检测拓扑变化，并快速通知它们所在的网络。在 STP 中，当一个端口进入阻塞或转发状态时，意味着发生拓扑变化。当网桥检测到一个连接变化（例如一条链路故障），它向根端口之外的端口发送&lt;strong&gt;拓扑变化通知（TCN）&lt;/strong&gt; BPDU，通知自己在树中的父网桥，直到根为止。树中通向根的下一个网桥向发送通知的网桥确认 TCN BPDU，并将它们转发到根。当接收到拓扑变化通知时，根网桥在后续的周期性配置消息中设置 TC 位。这种消息被网络中的每个网桥所转发，并被处于阻塞或转发状态的端口接收。设置这个位允许网桥减小转发延时计时器的有效期，将有效期以秒代替推荐的 5 分钟。这样，数据库中已有的错误条目可被快速清除和重新学习，同时允许访问那些被误删除的条目。&lt;/p&gt;\n&lt;h4 id=\&#34;3415-例子\&#34;&gt;3.4.1.5 例子&lt;/h4&gt;\n&lt;p&gt;在 Linux 中，网桥功能默认禁用 STP。假设在多数情况下拓扑相对简单，一台普通计算机可被用作网桥。可执行以下命令为当前使用的网桥启用 STP：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;Linux# brctl stp br0 on\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;执行该命令的结果如下：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;Linux# brctl stp br0 on\nbr0\nbridge id       8000.0007e914a9c1\ndesignated root     8000.0007e914a9c1\nroot port       0       path cost       0\nmax age     19.99       bridge max age      19.99\nhello time      1.99        bridge hello time       1.99\nforward delay       14.99       bridge forward delay        14.99\nageing time     0.99\nhello timer     1.26        tcn timer       0.00\ntopology change timer       3.37        gc timer        3.26\nflags       TOPOLOGY_CHANGE TOPOLOGY_CHANGE_DETECTED\n\neth0 (0)\nport id       0000      state       forwarding\ndesignated root     8000.0007e914a9c1       path cost       100\ndesignated bridge     8000.0007e914a9c1     message age timer       0.00\ndesignated port       8001       forward delay timer 0.00\n\ndesignated cost       0       hold timer 0.26\n\nflags\n\neth1 (0)\nport id       0000      state       forwarding\ndesignated root     8000.0007e914a9c1       path cost       19\ndesignated bridge     8000.0007e914a9c1     message age timer       0.00\ndesignated port       8002       forward delay timer 0.00\ndesignated cost       0       hold timer 0.26\n\nflags\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;我们看到一个简单的桥接网络的 STP 设置。网桥设备 br0 保存网桥的整体信息。这些信息包括网桥 ID （8000.0007e914a9cl），它由图 3-11 中基于 PC 的网桥（端口 1）的最小 MAC 地址生成。可在几秒钟内获得主要的配置参数（例如欢迎时间、拓扑变化计时器等）。标志值表示最近的拓扑变化，用于获得最近的网络连接变化的实际情况。输出的其余部分描述每个端口的信息，即 eth0（网桥端口 1）和 eth1（网桥端口 2）。注意， eth0 的路径成本大约是 eth1 成本的 10 倍。这个结果与 eth0 是一个 10Mb/s 以太网而 eth1 是一个100Mb/s 全双工网络是一致的。&lt;/p&gt;\n&lt;p&gt;我们可使用 Wireshark 查看一个BPDU。在图 3-16 中，我们看到一个 52 字节的消息内容。消息长度为 52 字节（由于 Linux 捕获功能会拆除填充，因此它小于以太网的 64 字节的最小限制），这个长度是由以太网头部中的&lt;strong&gt;长度/类型&lt;/strong&gt;字段加 14 得到的。目的地址是预期的组地址 &lt;code&gt;01:80:C2:00:00:00&lt;/code&gt;。有效载荷长度是 38 字节，这个值包含在&lt;strong&gt;长度&lt;/strong&gt;字段中。 SNAP/LLC字段包含常数 &lt;code&gt;0x424243&lt;/code&gt;，并且封装帧是一个生成树（版本 0）帧。其余协议字段表明站 &lt;code&gt;00:07:e9:14:a9:c1&lt;/code&gt; 认为自己是生成树的根，优先级为 32768 （低优先级），并且 BPDU 从端口 2 以优先级 &lt;code&gt;0x80&lt;/code&gt; 发送。另外，最大有效期是 20 秒，欢迎时间是 2 秒，转发延迟是 15 秒。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;16\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1652356336887.png\&#34; alt=\&#34;图 3-16\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 3-16   Wireshark 显示一个 BPDU。以太网帧的目的地址是一个通过网桥（&lt;code&gt;01:80:C2:00:00:00&lt;/code&gt;）的组地址&lt;/p&gt;\n&lt;h4 id=\&#34;3416-快速生成树协议以前的-8021w\&#34;&gt;3.4.1.6 快速生成树协议（以前的 802.1w）&lt;/h4&gt;\n&lt;p&gt;传统 STP 的问题之一是在拓扑变化之后，只能通过一定时间内未接收到 BPDU 来检测。如果这个超时很大，收敛时间（沿着生成树重新建立数据流的时间）可能比预期大。 IEEE 802.1w标准（[&lt;a href=\&#34;#802.1D-2004\&#34;&gt;802.1D-2004&lt;/a&gt;] 的一部分）改进了传统 STP，它定义了采用新名称的 &lt;strong&gt;快速生成树协议（Rapid Sparming Tree Protocol， RSTP）&lt;/strong&gt; 。在 RSTP 中，对 STP 的主要改进是监视每个端口的状态，并在故障时立即发送一个拓扑变化通知。另外， RSTP 使用 BPDU 的标志字段中的全部 6 位来支持网桥之间的协议，以避免由计时器来启动协议操作。它将正常的 STP 端口状态由 5 个减少到 3 个（丢弃、学习和转发，由图 3-14 的括号中的状态名表示）。 RSTP 的丢弃状态代替了传统 STP 的禁止、阻塞和侦听状态。 RSTP 创建了一个称为&lt;strong&gt;备用端口&lt;/strong&gt;的新角色，作用是在根端口停止运行时立即代替它。&lt;/p&gt;\n&lt;p&gt;由于 RSTP 只使用一种类型的 BPDU，因此这里没有专门的拓扑变化 BPDU。正如所说的那样， RSTP 的 BPDU 使用版本和类型号 2 而不是 0。在 RSTP 中，检测到一次拓扑变的交换机会发送一个表示拓扑变化的 BPDU，任何接收到它的交换机立即清除自己的过滤数据库。这个改变可显著影响协议的收敛时间。这时，无须等待拓扑变化传递到根网桥再经过转发延迟后返回，而是立即清除相关条目。总之，在大多数情况下，收敛时间可从几十秒减少到几分之一秒。&lt;/p&gt;\n&lt;p&gt;RSTP 使&lt;strong&gt;边缘端口&lt;/strong&gt;（只连接到端站的端口）和正常的生成树端口之间，以及点到点链路和共享链路之间都有区别。边缘端口和点到点链路上的端口通常不会形成循环，因此允许它们跳过侦听和学习状态，直接进入转发状态。当然，如果假设一个边缘端口可能被入侵，例如两个端口交叉连接，它们可携带任何形式的BPDU （简单的端站通常不处理 BPDU），这时它们将被重新分类为生成树端口。点到点链路可根据接口操作模式来识别。如果这个接口运行在全双工模式下，则这条链路是点到点链路。&lt;/p&gt;\n&lt;p&gt;在普通的 STP 中， BPDU 通常由一个通知网桥或根网桥来转发。在 RSTP 中， BPDU 为了“保持活跃”而由所有网桥来定期发送，以便确定相连的邻居是否正常运行。大多数高层路由协议也会这样做。注意，在 RSTP 中，拓扑变化没有像普通 STP 那样包括边缘端口连接或断开。当检测到一次拓扑变化时，通知网桥发送 TC 位被设置的 BPDU，不仅到根网桥而且到所有网桥。这样做允许将拓扑变化通知整个网络，并且比传统 STP 更快速。当一个网桥接收到这些消息时，它会更新除边缘端口之外的所有相关条目。&lt;/p&gt;\n&lt;p&gt;RSTP 的很多功能由 Cisco 和其他公司开发，他们有时需要在自己的产品中为普通 STP做专门的扩展。 IEEE 委员会将这些扩展纳入 802.1d 标准的更新中，该标准涵盖所有类型的 STP，因此扩展局域网可在某些网段中运行传统 STP，同时在其他部分中运行 RSTP （虽然 RSTP 的优势将丧失）。 RSTP 已被扩展到 VLAN [&lt;a href=\&#34;#802.1Q-2005\&#34;&gt;802.1Q-2005&lt;/a&gt;] 中，它采用一种称为多生成树协议（MSTP）的协议。这个协议保留了RSTP （和 STP）报文格式，因此它有可能做到向后兼容，也支持形成多个生成树（每个 VLAN 一个生成树）。&lt;/p&gt;\n&lt;h3 id=\&#34;342-8021ak多注册协议\&#34;&gt;3.4.2 802.1ak：多注册协议&lt;/h3&gt;\n&lt;p&gt;**多注册协议（Multiple Registration Protocol， MRP）**提供了在桥接局域网环境中的站之间注册属性的通用方法。 [&lt;a href=\&#34;#802.1ak-2007\&#34;&gt;802.1ak-2007&lt;/a&gt;]定义了两个特殊的 MRP “应用程序”，称为 MVRP（用于注册 VLAN）和 MMRP （用于注册组 MAC 地址）。 MRP 代替了早期的 GARP 框架;MVRP 和 MMRP 分别代替了旧的 GVRP 和 GMRP 协议。这些协议最初都由 802.1q 定义。&lt;/p&gt;\n&lt;p&gt;在使用 MVRP 时，当一个站被配置为一个 VLAN 成员时，该信息被传输到它所连接的交换机，并由该交换机将站加入 VLAN 通知其他交换机。这允许交换机根据站的 VLAN ID 添加自己的过滤表，也允许 VLAN 拓扑变化不必通过 STP 而重新计算现有生成树。避免重新计算 STP 是从 GVRP 向 MVRP 迁移的原因之一。&lt;/p&gt;\n&lt;p&gt;MMRP 是一个站注册其感兴趣的组 MAC 地址（组播地址）的方法。这个信息可能被用于交换机建立端口，组播流量必须通过该端口来交付。如果没有这样的功能，交换机将不得不广播所有的组播流量，这样可能导致不必要的开销。 MMRP 是一个第 2 层协议，它与第 3 层协议 IGMP 和 MLD 相似，并在很多交换机中支持“  IGMP/MLD 探听”能力。我们将在第 9 章讨论 IGMP、MLD 和探听。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;35-无线局域网ieee-80211wi-fi\&#34;&gt;3.5 无线局域网——IEEE 802.11（Wi-Fi）&lt;/h2&gt;\n&lt;p&gt;目前，&lt;strong&gt;无线保真（Wi-Fi）&lt;/strong&gt; 是访问 Intemet 的最流行技术之一，其众所周知的 IEEE 标准名称为 802.11，它是一种常用的无线以太网标准。 Wi-Fi 已发展成为一种廉价、高效、便捷的方式，为大多数应用提供可接受的连通性和性能。 Wi-Fi 网络很容易建立。当前多数的便携式电脑和智能手机包含接入 Wi-Fi 基础设施的必要硬件。很多咖啡馆、机场、宾馆和其他公共设施提供了 Wi-Fi “热点”， Wi-Fi 在那些可能难以提供其他基础设施的发展中国家发展甚至更快。图 3-17 显示了 IEEE 802.11 网络体系结构。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;17\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1652419793689.png\&#34; alt=\&#34;图 3-17\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 3-17   一个无线局域网的 802.11 术语。接入点可采用一种分布式服务（一个无线或有线的主干）来连接，以形成一个扩展的无线局域网（称为一个 ESS）。站（包括 AP 和移动设备）之间的通信构成一个基本服务集。在通常情况下，每个 ESS 有一个指定的 ESSID，它的功能是作为一个网络的名称&lt;/p&gt;\n&lt;p&gt;图 3-17 中的网络包括多个&lt;strong&gt;站（STA）&lt;/strong&gt;。在通常情况下，站和&lt;strong&gt;接入点（AP）&lt;strong&gt;组成一个操作子集。一个 AP 和相关的站被称为一个&lt;/strong&gt;基本服务集（BSS）&lt;/strong&gt;。 AP 之间通常使用一种有线的&lt;strong&gt;分布式服务&lt;/strong&gt;（称为 DS，基本是“主干”）连接，形成一个&lt;strong&gt;扩展服务集（ESS）&lt;/strong&gt;。这种方式通常被称为&lt;strong&gt;基础设施模式&lt;/strong&gt;。 802.11 标准也提供了一种 Ad hoc （自组织）模式。在这种配置中没有 AP 或 DS，而是直接采用站到站（对等）的通信。在 IEEE 的术语中，加入一个 Ad hoc 网络的 STA 形成一个&lt;strong&gt;独立基本服务集（IBSS）&lt;/strong&gt;。由 BSS 或 IBSS 的集合形成的无线局域网称为&lt;strong&gt;服务集&lt;/strong&gt;，它由一个**服务集标识符（SSID）**来标识。**扩展服务集标识符（ESSID）**是由 SSID 命名的一个 BSS 集合，它实际上是一个最长 32 个字符的局域网名称。在 WLAN 第一次建立时，该名称通常分配给 AP。&lt;/p&gt;\n&lt;h3 id=\&#34;351-80211-帧\&#34;&gt;3.5.1 802.11 帧&lt;/h3&gt;\n&lt;p&gt;802.11 网络有一个常见的总体框架，但包括多种类型的帧格式。每种类型的帧不一定包含所有字段。图 3-18 显示了常见帧格式和（最大尺寸的）数据帧。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;18\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1652420491239.png\&#34; alt=\&#34;图 3-18\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 3-18   802.11 基本数据帧格式（见 [&lt;a href=\&#34;#802.11n-2009\&#34;&gt;802.11n-2009&lt;/a&gt;]）。 MPDU 格式类似于以太网，但取决于接入点之间使用的 DS 类型：帧是发送到 DS 还是来自它，以及帧是否被聚合。 QoS 控制字段用于特殊功能， HT 控制字段用于控制 802.11n 的“高吞吐量”功能&lt;/p&gt;\n&lt;p&gt;图 3-18 所示的帧包括一个用于同步的前导码，它取决于正在使用的 802.11 协议类型。接下来，**物理层会聚程序（PLCP）**头部以独立于物理层的方式提供特定的物理层信息。帧的 PLCP 部分的传输速率通常比其余部分低。这样做有两个目的：提高正确交付的概率（较低速度通常具有更好的容错性能），提供对传统设备的兼容性和防止慢速操作的干扰。帧的 MAC PDU（MPDU）与以太网相似，但是有一些额外的字段。&lt;/p&gt;\n&lt;p&gt;MPDU 以帧控制字开始，其中包括 2 位的&lt;strong&gt;类型&lt;/strong&gt;字段，用于识别该帧的类型。这里有三种类型的帧：&lt;strong&gt;管理帧&lt;/strong&gt;、&lt;strong&gt;控制帧&lt;/strong&gt;和&lt;strong&gt;数据帧&lt;/strong&gt;。每种类型有不同的子类型。 [&lt;a href=\&#34;#802.11n-2009\&#34;&gt;802.11n-2009，表 7-1&lt;/a&gt;]给出了有关类型和子类型的完整列表。剩余字段由帧类型（如果有的话）来决定，后面将单独讨论。&lt;/p&gt;\n&lt;h4 id=\&#34;3511-管理帧\&#34;&gt;3.5.1.1 管理帧&lt;/h4&gt;\n&lt;p&gt;管理帧用于创建、维持、终止站和接入点之间的连接。它们也被用于确定是否采用加密，传输网络名称（SSID 或 ESSID），支持哪种传输速率，以及采用的时间数据库等。当一个 Wi-Fi 接口“扫描”临近的接入点时，这些帧被用于提供必要的信息。&lt;/p&gt;\n&lt;p&gt;扫描是一个站发现可用的网络及相关配置信息的过程。这涉及每个可用频率和流量的侦听过程，以确定可用的接入点。一个站可以主动探测网络，在扫描时传输一个特殊的管理帧（“探测请求”）。这些探测请求有一定的限制，以保证 802.11 流量不在非 802.11 （例如医疗服务）频率上传输。下面是在 Linux 系统中手工启动扫描的例子：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;Linux# iwlist wlan0 scan\nwlan0 Scan completed :\n                Cell 01 - Address: 00:02:6F:20:B5:84\n                        ESSID: &amp;quot;Grizzly-5354-Aries-802.11b/g&amp;quot;\n                        Mode:Master\n                        Channel:4\n                        Frequency:2.427 GHz (Channel 4)\n                        Quality=5/100 Signal level=47/100\n                        Encryption key:on\n                        IE : WPA Version 1\n                            Group Cipher : TKIP\n                            Pairwise Ciphers (2) : CCMP TKIP\n                            Authentication Suites (1) : PSK\n                        Bit Rates:1 Mb/s; 2 Mb/s; 5.5 Mb/s; 11 Mb/s;\n                                6 Mb/s; 12 Mb/s; 24 Mb/s; 36 Mb/s; 9 Mb/s;\n                                18 Mb/s; 48 Mb/s; 54 Mb/s\n                        Extra:tsf=0000009d832ff037\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;这里，我们看到在无线接口 wlan0 上手工启动扫描的结果。一个 MAC 地址为 &lt;code&gt;00:02:6F:20:B5:84&lt;/code&gt;的 AP 作为主角（即在基础设施模式中作为 AP）工作。它在信道 4 （2.427GHz）上广播 ESSID “Grizzly-5354-Aries-802.11b/g” （更多细节见 3.5.4 节讨论信道和频率时对信道选择的描述）。信号质量和强度决定执行扫描的站从 AP 接收信号的好坏，但相应值的含义可能因设备生产商而不同。 WPA 加密被用于这种链路（见3.5.5节），传输速率从 1Mb/s 到 54Mb/s 不等。 &lt;strong&gt;tsf（时间、同步、功能）&lt;/strong&gt; 的值表示 AP 的时间概念，它被用于需要同步的各种功能，例如省电模式（见3.5.2节）。&lt;/p&gt;\n&lt;p&gt;当一个 AP 广播它的 SSID 时，任何站可尝试与 AP 建立连接。当一个连接建立时，大多数 Wi-Fi 网络会提供必要的配置信息，以便为站提供 Internet 接入（见第 6 章）。但是， AP 的运营商可能希望控制使用网络的站。有些运营商故意使连接变得更困难， AP 不广播其 SSID 被作为一项安全措施。这种方法提供了有限的安全性，这是由于 SSID 可以被猜测。链路加密和密码可提供更可靠的安全性，我们将在 3.5.5 节讨论。&lt;/p&gt;\n&lt;h4 id=\&#34;3512-控制帧rtscts-和-ack\&#34;&gt;3.5.1.2 控制帧：RTS/CTS 和 ACK&lt;/h4&gt;\n&lt;p&gt;控制帧与帧确认被用于一种流量控制方式。流量控制有助于接收方使一个过快的发送方降低发送速度。帧确认有助于发送方知道哪些帧已正确接收。这些概念也适用于传输层的 TCP 协议（见第15章）。 802.11 网络支持可选的&lt;strong&gt;请求发送/明确发送（RTS/CTS）&lt;/strong&gt;，通过放缓传输来进行流量控制。当 RTS/CTS 启用时，一个站在发送数据帧之前发送一个 RTS 帧，当接收方愿意接收额外的流量时，它会响应一个 CTS 帧。在 RTS/CTS 交换之后，这个站开启一个时间窗口（在 CTS 帧中标识），用于向确认接收的站发送数据帧。这种协同传输方法在无线网络中是常见的，模拟流量控制信号多年前已被用于有线的串行线路（有时称为硬件流量控制）。&lt;/p&gt;\n&lt;p&gt;RTS/CTS 交换有助于避免隐藏终端问题，通过在允许发送时对每个站加以指导，以便发现对方站同时进行的传输。由于 RTS 和 CTS 帧比较短，因此它们不会长期使用信道。如果一个分组的大小足够大， AP 通常为每个分组启动一次 RTS/CTS 交换。在通常情况下， AP 提供一个称为&lt;strong&gt;分组大小阈值&lt;/strong&gt;（或类似）的配置选项。超过阈值的帧将会导致一个 RTS 帧优先于数据帧发送。如果需要执行 RTS/CTS 交换，大多数设备生产商设置的默认值为 500 字节。在 Linux 中， RTS/CTS 阈值可通过以下方式设置：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;Linux# iwconfig wlan0 rts 250\nwlan0 IEEE 802.11g ESSID:&amp;quot;Grizzly-5354-Aries-802.11b/g&amp;quot;\n        Mode : Managed\n        Frequency:2.427 GH\n        Access Point: 00:02:6F:20:B5:84\n        Bit Rate=24 Mb/s Tx-Power=0 dBm\n        Retry min limit:7 RTs   thr=250 B    Fragment thr=2346 B\n        Encryption key:xxxx- ... 一xxxx [3]\n        Link Quality=100/100    Signal level=46/100\n        Rx invalid nwid:0    Rx invalid crypt:0    Rx invalid frag:0\n        Tx excessive retries:0    Invalid misc:0    Missed beacon:0\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;&lt;code&gt;iwconfig&lt;/code&gt; 命令可用于设置多种变量，包括 RTS 和分片阈值（见 3.5.1.3 节）。它也可用于确定统计数据，例如错误的网络 ID （ESSID）或加密密钥而导致的帧出错数量。它也可用于给出过多的重试次数（即重传次数），这是一个用于衡量链路可靠性的粗略指标，在无线网络中常用于指导路由决策 [&lt;a href=\&#34;#ETX\&#34;&gt;ETX&lt;/a&gt;]。在覆盖范围有限的 WLAN 中，隐藏终端问题通常很少发生，可将站的 RTS 阈值设置为很大（1500 或更大）来禁用 RTS/CTS。这可避免每个分组执行 RTS/CTS 交换带来的开销。&lt;/p&gt;\n&lt;p&gt;在有线的以太网中，冲突较少意味着正确接收帧的概率较高。在无线网络中，更多的因素导致帧交付可能出错，例如信号不够强或受到干扰。为了帮助解决这些潜在问题， 802.11 采用一种重传/确认（ACK）方法来扩展 802.3 重传机制。确认是对预期在一定时间内接收的一个单播帧（802.11a/b/g）或一组帧（802.11n 或带“块确认”的 802.11e）的响应。组播或广播帧没有相关的确认，以避免出现“ACK爆炸”问题（见第 9 章）。在指定时间内没有接收到对应的 ACK 会导致帧的重传。&lt;/p&gt;\n&lt;p&gt;重传可能在网络中形成重复的帧。当任何帧是某个帧的一次重传时，&lt;strong&gt;帧控制字&lt;/strong&gt;中的 &lt;strong&gt;重试（Retry）&lt;/strong&gt; 位需要设置为相应的值。接收站可通过它删除重复的帧。每个站需要保持一个小的缓存条目，以说明最近查看的地址和序列号/分片号。当一个接收帧与一个条目匹配时，则丢弃该帧。&lt;/p&gt;\n&lt;p&gt;发送一个帧和接收一个 ACK 所需时间与链路距离和&lt;strong&gt;时隙&lt;/strong&gt;（802.11 MAC 协议的一个基本时间单位，见 3.5.3 节）相关。在大多数系统中，可配置等待的 ACK 时间（以及时隙），我们可采用不同方法完成配置。在大多数情况下，例如在家庭或办公室中使用，默认值是足够的。在长距离的 Wi-Fi 中，这些值可能需要调整（例如见 [&lt;a href=\&#34;#MWLD\&#34;&gt;MWLD&lt;/a&gt;] ）。&lt;/p&gt;\n&lt;h4 id=\&#34;3513-数据帧-分片和聚合\&#34;&gt;3.5.1.3 数据帧、分片和聚合&lt;/h4&gt;\n&lt;p&gt;在一个繁忙的网络中看到的帧大多数是数据帧，它们如大家所期望的那样携带数据。在通常情况下， 802.11 帧和链路层（LLC）帧之间存在一对一关系，它们保证更高层协议（例如 IP）是可用的。但是，802.11 支持帧&lt;strong&gt;分片&lt;/strong&gt;，可将一个帧分为多个分片。根据 802.11n 的规定，它也支持帧聚合，可将多个帧合并发送以减少开销。&lt;/p&gt;\n&lt;p&gt;当使用帧分片时，每个分片有自己的 MAC 头部和尾部的 CRC，并且它们独立于其他分片处理。例如，到不同目的地的分片可以交错。当信道有明显的干扰时，分片有助于提高性能。除非使用块确认功能，否则每个分片将被单独发送，并由接收方为每个分片产生一个 ACK。 由于分片小于全尺寸的帧，如果需要启动一次重传，则只需要重传少量数据。&lt;/p&gt;\n&lt;p&gt;分片仅用于目的地址为单播（非广播或组播）的帧。为了具备这种能力，顺序控制字段包含一个&lt;strong&gt;分片号&lt;/strong&gt;（4 位）和一个&lt;strong&gt;序列号&lt;/strong&gt;（12 位）。如果一个帧经过分片，所有分片包含相同的序列号值，而每个相邻的分片的分片号之差为 1。 由于分片号字段长度为 4 位，同一帧最多可能有 15 个分片。&lt;strong&gt;帧控制字&lt;/strong&gt;中的&lt;strong&gt;更多标志&lt;/strong&gt;字段表示更多分片还没有到达。最后一个分片将这个位设置为 0。接收方将接收到的同一序列号的分片根据分片号重组成原始帧。当所有包含同一序列号的分片被接收，并且最后一个分片将更多标志字段设为 0 时，这个帧被重组并交给更高层协议来处理。&lt;/p&gt;\n&lt;p&gt;分片并不常使用，因为它需要经过调整。如果不调整就使用，可能导致性能下降。当帧大小更小的情况下，出现位差错的概率（参见下一段）更小。分片大小通常可设为 256 字节至 2048 字节，并作为一个阈值（只有那些超过阈值的帧才被分片）。很多 AP 通常设置更高的阈值（例如 Linksys 品牌 AP 的 2437 字节），这样就会默认不使用分片。&lt;/p&gt;\n&lt;p&gt;分片有用的原因在于其出错的概率。如果 &lt;strong&gt;误码率（Bit Error Rate， BER）&lt;/strong&gt; 为 P， 1 位数据成功交付的概率为 &lt;code&gt;(1-P)&lt;/code&gt; ， N 位成功交付的概率为 (1-P)&lt;sup&gt;N&lt;/sup&gt; 。随着 N 的增长，这个值逐渐减小。因此，如果我们减小一个帧的大小，理论上可改善错误交付的概率。当然，如果我们将一个 N 位大小的帧分成 K 个分片，我们可发送至少 &lt;code&gt;N/K&lt;/code&gt; 个分片。我们给出一个具体的例子，假设要发送一个 1500 字节（12000 位）的帧。如果假设 P= 10&lt;sup&gt;-4&lt;/sup&gt; （一个相对较高的误码率），不分片时的成功交付概率为 (1-10&lt;sup&gt;-4&lt;/sup&gt;)&lt;sup&gt;12000&lt;/sup&gt;=0.301 ，那么只有约 30% 机会将这个帧成功交付，即平均发送三或四次可使它成功接收。&lt;/p&gt;\n&lt;p&gt;如果我们对同样的例子使用分片，并将分片阈值设置为 500，这时将产生 3 个 4000 位的分片。每个分片成功交付的概率为 (1-10&lt;sup&gt;-4&lt;/sup&gt;)&lt;sup&gt;4000&lt;/sup&gt; = 0.670。因此，每个分片约有 67% 的机会成功交付。当然，我们必须在交付成功后重组该帧。 3 个分片、 2 个分片、 1 个分片与 0 个分片成功交付的概率分别为 (0.67)&lt;sup&gt;3&lt;/sup&gt;= 0.30、 3(0.67)&lt;sup&gt;2&lt;/sup&gt;(0.33) = 0.44、 3(0.67)(0.33)&lt;sup&gt;2&lt;/sup&gt;= 0.22、 (0.33)&lt;sup&gt;3&lt;/sup&gt;=0.04。 因此，虽然所有分片未重传而被成功交付的概率与未分片被成功交付的概率相同，但两个或三个分片被成功交付的机会相对较大。如果发生这种情况，顶多是一个分片需要重传，这比发送 1500 字节的未分片帧显然节省时间（大约三分之一）。当然，每个分片需要花费一些开销，如果误码率实际为 0 ，分片只会因创建更多帧而降低性能。&lt;/p&gt;\n&lt;p&gt;802.11n 提供的增强功能之一是支持两种形式的帧聚合。一种形式称为&lt;strong&gt;聚合的 MAC 服务数据单元（A-MSDU）&lt;/strong&gt;，它可将多个完整的 802.3 （以太网）帧聚合在一个 802.11 帧中。另一种形式称为&lt;strong&gt;聚合的 MAC 协议数据单元（A-MPDU）&lt;/strong&gt;，它可将多个具有相同的源、目的和 QoS 的 MPDU 聚合为短帧。图 3-19 描述了两种类型的聚合。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;19\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1652429598770.png\&#34; alt=\&#34;图 3-19\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 3-19   802.11n 中的帧聚合包括 A-MSDU 和 A-MPDU。 A-MSDU 使用一个 FCS 聚合多个帧。A-MPDU 在聚合的每个 802.11 帧之间使用一个 4 字节的分隔符。每个 A-MPDU 子帧拥有自己的 FCS，并可以分别使用 ACK 确认，以及在必要时重传&lt;/p&gt;\n&lt;p&gt;对于一次单一的聚合， A-MSDU 方法在技术上更有效率。每个 802.3 头部通常为 14 字节，相对 36 字节的 802.11 MAC 头部更短。因此，仅一个 802.11 MAC 头部对应于多个 802.3 帧，每聚合一个帧最多可节约 22 字节。一个 A-MSDU 可能高达 7935 字节，可容纳 100 多个小（例如 50 字节）的分组，但只能容纳少数（5 个）较大（1500 字节）的数据分组。 A-MSDU 仅对应一个 FCS。更大的 A-MSDU 帧会增大交付出错的概率，由于整个聚合只是针对一个 FCS，因此在出错时将不得不重传整个帧。&lt;/p&gt;\n&lt;p&gt;A-MPDU 聚合是另一种形式的聚合，多个（最多 64 个） 802.11 帧可聚合起来，每个帧有自己的 802.11 MAC 头部和 FCS，每个帧最多 4095 字节。 A-MPDU 可携带最多 64KB 的数据，足够包含 1000 多个小的分组和大约 40 个较大（1.5KB）的分组。由于每个子帧都携带自己的 FCS，因此可有选择地重传那些出错的子帧。这使得 802.11n （最初在 802.11e）中的块确认功能成为可能，它是一种扩展的确认形式，为发送方提供哪个 A-MPDU 子帧交付成功的反馈信息。这种功能在目的上类似，但在细节上不同，我们将在 TCP （见第 14 章）中介绍选择确认。因此， A-MSDU 提供的聚合类型在无差错网络中传输大量小的分组时可能更有效率，但在实际运行中可能不如 A-MPDU 聚合好 [&lt;a href=\&#34;#S08\&#34;&gt;S08&lt;/a&gt;] 。&lt;/p&gt;\n&lt;h3 id=\&#34;352-省电模式和时间同步功能\&#34;&gt;3.5.2 省电模式和时间同步功能&lt;/h3&gt;\n&lt;p&gt;802.11 规范提供一种使站进入有限电源状态的方式，称为&lt;strong&gt;省电模式（PSM）&lt;/strong&gt;。 PSM 的设计目标是为了节省电源， STA 可在某个时间关闭无线电收发器电路。在不使用 PSM 时，收发器电路将始终运行，并消耗能量。在使用 PSM 时， STA 的输出帧在帧控制字中设置 1 位。当 AP 发现某些帧的该位被设置时，它会缓冲该帧直到该站需要时为止。 AP 发送信标帧（一种管理帧）提供不同信息，例如 SSID、信道和认证信息。当某个站使用 PSM 时， AP 可向该站提示存在缓冲的帧，只需在发送帧的&lt;strong&gt;帧控制字&lt;/strong&gt;中设置一个标识。在某个站执行 PSM 后，它会一直保持这样，直到接收到下一个 AP 信标帧，这时它将苏醒过来，并确定 AP 中是否有为它缓存的帧。&lt;/p&gt;\n&lt;p&gt;我们应了解和关注 PSM 的使用。虽然它可能延长电池寿命，但是在大多数无线设备中，NIC 不是唯一可节约电源的模块。系统其他部分（例如屏幕和硬盘驱动器）也是电源的主要消耗者，因此总的电池寿命可能不会延长太多。另外， PSM 可能显著影响在帧传输之间空闲期间的吞吐量，时间被过多花费在模式切换上 [&lt;a href=\&#34;#SHK07\&#34;&gt;SHK07&lt;/a&gt;] 。&lt;/p&gt;\n&lt;p&gt;在正确的时间（即一个 AP 打算发送一个信标帧时）唤醒 STA 检查等候帧的能力，取决于这个 AP 和它所服务的站对时间的感知。 Wi-Fi 采用&lt;strong&gt;时间同步功能（TSF）&lt;/strong&gt;。每个站保持一个 64 位计数器的参考时间（微秒），这个时间与网络中的其他站保持同步。同步保持在 4μs 加 PHY （速率为 1Mb/s 或以上）最大传播延迟之内。这是通过多个站接收一个 TSF 更新（另一个站发送的 64 位计数器副本），并检查其中的值是否比自己的值更大来实现。如果是，接收站将自己的时间更新为更大的值。这种方法可确保时钟总是向前走，但它也会带来一些问题，如果不同站的时钟速率稍有差异，较慢的站就会被最快的站的时钟所同步。&lt;/p&gt;\n&lt;p&gt;通过将 802.11e （QoS）功能纳入 802.11 中， 802.11 的 PSM 扩展为提供定期批处理缓冲帧功能。这个频率用信标帧的数量来表示。这个功能被称为&lt;strong&gt;自动省电交付模式（APSD）&lt;/strong&gt;，它使用 QoS 控制字中的一些子字段。 APSD 对电源有限的设备可能非常有用，因为它们不像传统 802.11 PSM 那样，并不需要在每个信标间隔都被唤醒。相反，它们可选择在自己所选的较长时间内关闭无线电收发器电路。 802.11n 也扩展了 PSM 基本功能，允许一个 STA 装备的多个射频电路（见 3.5.4.2 节 MIMO）共同工作，关闭所有而不是其中一个电路，直到准备好一个帧为止。这被称为&lt;strong&gt;空间复用&lt;/strong&gt;省电模式。这个规范还包括称为&lt;strong&gt;省电多重轮询&lt;/strong&gt;的增强型 APSD，它提供同时双向（例如，到达 AP 和来自 AP）传输帧的方法。&lt;/p&gt;\n&lt;h3 id=\&#34;353-80211-介质访问控制\&#34;&gt;3.5.3 802.11 介质访问控制&lt;/h3&gt;\n&lt;p&gt;与有线网络（例如 802.3 局域网）相比，在无线网络中检测“冲突”具有更大挑战性。实际上，介质是相对单一的，无论是集中方式还是分布方式，都需要协同传输，避免多个站同时发送。 802.11 标准采用三种方法控制共享的无线介质，它们分别称为&lt;strong&gt;点协调功能（PCF）&lt;/strong&gt;、&lt;strong&gt;分布式协调功能（DCF）&lt;strong&gt;和&lt;/strong&gt;混合协调功能（HCF）&lt;/strong&gt;。 HCF 被纳入 802.11 规范 [&lt;a href=\&#34;#802.11-2007\&#34;&gt;802.11-2007&lt;/a&gt;] ，在 802.11e 中增加支持 QoS，它也被用于 802.11n。某些类型的站或 AP 强制实现 DCF，也可选择实现 PCF，但 PCF 使用得并不广泛（因此我们不详细讨论）。相对较新的支持 QoS 的 Wi-Fi 设备通常会实现 HCF，例如 802.11n 的 AP 和更早的 802.11e 的 AP。现在，我们将注意力转移到 DCF 上，并在下面的 QoS 内容中描述 HCF。&lt;/p&gt;\n&lt;p&gt;DCF 是一种 CSMA/CA 类型，是基于竞争的介质访问方法。它可用于基础设施和 Ad hoc 网络。通过 CSMA/CA，一个站可查看介质是否空闲，如果空闲，它将有机会传输。如果不空闲，它在一段随机的时间内避免发送，直到它再次查看介质是否空闲为止。这个行为与有线局域网中使用的 CSMA/CD 检测方法相似。 802.11 信道仲裁是对 CSMA/CA 的改进，提供优先访问某些站或帧的功能。&lt;/p&gt;\n&lt;p&gt;802.11 载波侦听能以物理和虚拟方式实现。一个站在准备发送时，通常需要等待一段时间（称为&lt;strong&gt;分布式帧间间隔（DIFS）&lt;/strong&gt;），以允许更高优先级的站访问信道。如果信道在 DIFS 期间变得繁忙，该站再次开始一个等待时间。当介质出现空闲时，希望发送数据的站将启动 3.5.3.3 节所述的冲突避免/退避过程。这个过程在一次成功（失败）的传输后，通过一个 ACK 知道数据被接收（或没有接收）后启动。在传输不成功的情况下，经过不同时间（称为&lt;strong&gt;扩展帧间间隔（EIFS）&lt;/strong&gt;）启动退避过程。现在，我们将详细地讨论 DCF 实现，包括虚拟和物理载波侦听机制。&lt;/p&gt;\n&lt;h4 id=\&#34;3531-虚拟载波侦听-rtscts-和网络分配向量\&#34;&gt;3.5.3.1 虚拟载波侦听、RTS/CTS 和网络分配向量&lt;/h4&gt;\n&lt;p&gt;在 802.11 MAC 协议中，虚拟载波侦听机制会检查每个 MAC 帧中的&lt;strong&gt;持续时间&lt;/strong&gt;字段。这通过站的侦听而非引导流量来实现。 RTS 和 CTS 帧中都有一个&lt;strong&gt;持续时间&lt;/strong&gt;字段，它们像普通帧那样在传输之前可选择是否交换，并估计介质将处于繁忙状态的时间。&lt;/p&gt;\n&lt;p&gt;发送方基于帧长度、传输速率和 PHY 特性（例如速率等）设置&lt;strong&gt;持续时间&lt;/strong&gt;字段。每个站保持一个称为&lt;strong&gt;网络分配向量（NAV）&lt;strong&gt;的本地计数器，它被用于估计介质传输当前帧所需的时间，以及尝试下一次传输之前需等待的时间。当一个站侦听到一个&lt;/strong&gt;持续时间&lt;/strong&gt;大于自己的 NAV 时，它将自己的 NAV 更新为这个值。由于 RTS 和 CTS 帧中都有&lt;strong&gt;持续时间&lt;/strong&gt;字段，如果使用 NAV，在其范围内的任何站（无论是发送方还是接收方）都能看到&lt;strong&gt;持续时间&lt;/strong&gt;字段值。 NAV 采用单位时间来维护，并基于本地时钟递减。当本地 NAV 不为 0 时，介质被认为是繁忙的。在接收到一个 ACK 后，本地 NAV 将复位为 0。&lt;/p&gt;\n&lt;h4 id=\&#34;3532-物理载波侦听cca\&#34;&gt;3.5.3.2 物理载波侦听（CCA）&lt;/h4&gt;\n&lt;p&gt;每个 802.11 PHY 规范（例如，对于不同的频率和无线电技术）需提供一种评估信道是否空闲的功能，它基于能量和波形识别（通常是一个完好的 PLCP）。这个功能称为&lt;strong&gt;空闲信道评估（Clear Channel Assessment， CCA）&lt;/strong&gt;，它的实现依赖于 PHY。 CCA 功能是针对 802.11 MAC 的物理载波侦听功能，用于了解介质当前是否繁忙。它通常与 NAV 结合使用，以确定一个站在传输之前是否需要推迟（等待）。&lt;/p&gt;\n&lt;h4 id=\&#34;3533-dcf-冲突避免退避过程\&#34;&gt;3.5.3.3 DCF 冲突避免/退避过程&lt;/h4&gt;\n&lt;p&gt;在确定某个信道可能空闲时（已到达 NAV 持续时间，并且 CCA 没有提示信道繁忙），一个站在传输之前需推迟访问该信道。由于很多站可能在等待信道变空闲，每个站在发送之前需计算和等待一个&lt;strong&gt;退避时间&lt;/strong&gt;。退避时间等于一个随机数和&lt;strong&gt;时隙&lt;/strong&gt;的乘积（除非该站已有一个非零的退避时间尝试传输，在这种情况下无须重新计算）。时隙依赖于 PHY，通常是几十微秒。随机数是一个在区间 &lt;code&gt;[0，CW]&lt;/code&gt; 中均匀分布的数值，**竞争窗口（CW）**是一个整数，其中包含许多等待时隙，且 &lt;code&gt;aCWmin ≤ CW ≤ aCWmax&lt;/code&gt; （该限制由 PHY 定义）。 CW 值的集合从 PHY 指定的常数 aCWmin 开始，以 2 的幂（减 1）增加，直到每个连续传输尝试次数的常数 aCWmax 为止。这样做与以太网中由冲突检测事件引发的退避过程相似。&lt;/p&gt;\n&lt;p&gt;在无线环境中，冲突检测是不实际的。由于难以发现发送方和接收方同时发送，也难以监听自己之外的传输，因此采用&lt;strong&gt;冲突避免&lt;/strong&gt;来代替冲突检测。另外， ACK 是针对单播帧的响应，以确定一个帧是否成功传递。当一个站正确接收一个帧时，在等待一小段时间（称为&lt;strong&gt;短帧间间隔（SIFS）&lt;/strong&gt;）后开始传输 ACK，并且不考虑介质的忙碌/空闲状态。这样做不会导致问题，由于 SIFS 的值始终比 DIFS 小，因此该站产生的 ACK 可优先访问信道，以完成接收确认。源站在一定时间内没有接收到 ACK，则意味着一次传输失败。在失败后，源站启动前面讨论的退避过程，并重新尝试发送帧。如果在一定时间（CTStimeout 常数）内没有接收到对较早 RTS 响应的 CTS，则启动同样的过程。&lt;/p&gt;\n&lt;h4 id=\&#34;3534-hcf-和-80211en-的-qos\&#34;&gt;3.5.3.4 HCF 和 802.11e/n 的 QoS&lt;/h4&gt;\n&lt;p&gt;802.11标准 [&lt;a href=\&#34;#802.11-2007\&#34;&gt;802.11-2007&lt;/a&gt;] 中的条款 5、 6、 7 和 9 都基于 IEEE 802.11e 工作组的部分工作，常用的术语有 802.11e、Wi-Fi QoS和 WMM（基于Wi-Fi的多媒体）。它们涉及 QoS 功能：修改 802.11 MAC 层和系统接口以支持多媒体应用，例如 IP 语音（VoIP）和流媒体。 QoS 功能实际是否必要，取决于网络层拥塞和应用类型。如果网络利用率较低，可能不必要支持 QoS 的 MAC，虽然其他 802.11e 功能可能有用（例如块确认和 APSD）。在网络利用率和拥塞较高的情况下，需要为 VoIP 等服务提供低抖动交付能力，这时支持 QoS 可能是可取的。这些规范相对较新，支持 QoS 的 Wi-Fi 设备通常比不支持 QoS 的设备更昂贵和更复杂。&lt;/p&gt;\n&lt;p&gt;QoS 功能引入了新的术语，例如 QoS 站（QSTA）、 QoS 接入点（QAP）和 QoS BSS（QBSS，支持QoS 的 BSS）。在一般情况下，支持 QoS 功能的设备也支持传统的非 QoS 操作。 802.11n “高吞吐量”站（又称为 HTSTA）也是 QSTA。&lt;strong&gt;混合协调功能（HCF）&lt;strong&gt;是一种新的协调功能，支持基于竞争和可控制的信道访问，尽管可控制的信道访问技术很少使用。在 HCF 中，有两种专门的信道访问方法可协同工作：&lt;strong&gt;HFCA 控制信道访问（HCCA）&lt;strong&gt;和更流行的&lt;/strong&gt;增强型 DCF 信道访问（EDCA）&lt;/strong&gt;，它们分别对应于基于预约和基于竞争的访问。这里也有一些对&lt;/strong&gt;准入控制&lt;/strong&gt;的支持，它们可在高负载下完全拒绝访问。&lt;/p&gt;\n&lt;p&gt;EDCA 建立在基本的 DCF 访问之上。通过 EDCA， 8 个&lt;strong&gt;用户优先级（UP）&lt;strong&gt;被映射为 4 个&lt;/strong&gt;访问类别（AC）&lt;/strong&gt;。用户优先级使用与 802.1d 优先级标记相同的结构，并被编号为 1 至 7 （在 2 和 3 之间还有一个优先级 0），其中 7 为最高优先级。 4 个访问类别分别为背景、尽力而为、视频和音频流量。优先级 1 和 2 用于背景 AC，优先级 0 和 3 用于尽力而为 AC，优先级 4 和 5 用于视频 AC，优先级 6 和 7 用于音频 AC。对于每个 AC， DCF 的一个变种竞争信道访问许可，称为&lt;strong&gt;传输机会（TXOP）&lt;/strong&gt;，为较高优先级的流量使用可选的 MAC 参数。在 EDCA 中，很多来自 DCF 的 MAC 参数（例如， DIFS、 aCWmin、 aCWmax）作为配置参数是可调整的。这些值可通过管理帧传输给 QSTA。&lt;/p&gt;\n&lt;p&gt;HCCA 松散地建立在 PCF 之上，并使用轮询来控制信道访问。它属于同步方式的访问控制，并优先于基于竞争的 EDCA 访问。&lt;strong&gt;混合协调（HC）&lt;strong&gt;位于一个 AP 中，并优先于信道访问分配。在一次传输之前，一个站可为其流量发布一个&lt;/strong&gt;流量规范（TSPEC）&lt;/strong&gt;，并使用 8 和 15 之间的 UP 值。 HC 可为这种请求分配保留的 TXOP，它被用于基于 EDCA 的帧传输之前的短期控制访问阶段的帧交换。 HC 可拒绝 TXOP 的基于网络管理员设置的管理控制策略的 TSPEC。 HCF 利用前面讨论过的虚拟载波侦听机制和 DCF，以避免基于竞争的站被不基于竞争的访问所干扰。注意，在包括 QSTA 和常规站的网络中，可同时运行 HCF 和 DCF，并在两者之间切换，但 Ad hoc 网络不支持 HC，因此它不处理 TSPEC 和不执行管理控制。这种网络可能仍运行 HCF，但 TXOP 通过基于 EDCA 的竞争来获得。&lt;/p&gt;\n&lt;h3 id=\&#34;354-物理层的细节速率-信道和频率\&#34;&gt;3.5.4 物理层的细节：速率、信道和频率&lt;/h3&gt;\n&lt;p&gt;目前， [&lt;a href=\&#34;#802.11-2007\&#34;&gt;802.11-2007&lt;/a&gt;] 标准包括以下较早的修订版：802.11a、 802.11b、 802.11d、 802.11g、802.11h、 802.11i、 802.11j 和 802.11e。 802.11n 标准在 2009 年被采纳为 802.11 的修订版 [&lt;a href=\&#34;#802.11n-2009\&#34;&gt;802.11n-2009&lt;/a&gt;]。大多数的修订版为 802.11 网络提供额外的调制、编码和工作频率，但 802.11n 还增加了多种数据流和一种聚合多帧方法（见3.5.1.3节）。我们尽量避免详细讨论物理层，这里只是看一下可选的内容。表 3-2 包括 802.11 标准中特别描述的物理层部分。&lt;/p&gt;\n&lt;center&gt;表 3-2   802.11 标准中描述的物理层部分&lt;/center&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;标准（条款）&lt;/th&gt;\n&lt;th&gt;速率（Mb/s）&lt;/th&gt;\n&lt;th&gt;频率范围；调制&lt;/th&gt;\n&lt;th&gt;信道设置&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;802.11a（第 17 条）&lt;/td&gt;\n&lt;td&gt;6、9、12、18、24、36、48、54&lt;/td&gt;\n&lt;td&gt;5.16GHz ~ 5.35GHz 和 5.725 ~ 5.825GHz；OFDM&lt;/td&gt;\n&lt;td&gt;37 ~ 168（根据国家不同），20MHz/10MHz/5MHz 信道宽度选项&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.11b（第 18 条）&lt;/td&gt;\n&lt;td&gt;1、2 、5.5、11&lt;/td&gt;\n&lt;td&gt;2.401GHz ~ 2.495GHz；DSSS&lt;/td&gt;\n&lt;td&gt;1 ~ 14（根据国家不同）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.11g（第 19 条）&lt;/td&gt;\n&lt;td&gt;1、2 、5.5、6、9、11、12、18、24、36、48、54（加 22、23）&lt;/td&gt;\n&lt;td&gt;2.401GHz ~ 2.495GHz；OFDM&lt;/td&gt;\n&lt;td&gt;1 ~ 14（根据国家不同）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.11n&lt;/td&gt;\n&lt;td&gt;6.5 ~ 600，很多选项（最多 4 个 MIMO 流）&lt;/td&gt;\n&lt;td&gt;2.4GHz 和 5GHz 模式，信道宽度 20MHz 或 40MHz；OFDM&lt;/td&gt;\n&lt;td&gt;1 ~ 13（2.4GHz 频段）；36 ~ 196（5GHz 频段）（根据国家不同）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;802.11y&lt;/td&gt;\n&lt;td&gt;（与 802.11-2007 相同）&lt;/td&gt;\n&lt;td&gt;3.650GHz ~ 3.700GHz （需许可）；OFDM&lt;/td&gt;\n&lt;td&gt;1 ~ 25；36 ~ 64；100 ~ 161（根据国家不同）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;p&gt;第一列给出了标准的原有名称和在 [&lt;a href=\&#34;#802.11-2007\&#34;&gt;802.11-2007&lt;/a&gt;] 中的当前位置，并增 802.11n 和 802.11y 修订版的细节。在这个表中，需要注意的是， 802.11b/g 工作在 2.4GHz 的**工业、科学和医疗（ISM）&lt;strong&gt;频段， 802.11 仅工作在更高的 5GHz 的&lt;/strong&gt;无须许可的国家信息基础设施（U-NII）**频段，而 802.11n 可工作在这两个频段。 802.11y 修订版在美国工作在需要许可的 3.65 ~ 3.70GHz频段。我们应注意的一个重要的实践结论是：802.11b/g 设备与 802.11a 设备不会互操作或干扰，但是如果不认真进行部署， 802.11n 设备可能被任何设备干扰。&lt;/p&gt;\n&lt;h4 id=\&#34;3541-信道和频率\&#34;&gt;3.5.4.1 信道和频率&lt;/h4&gt;\n&lt;p&gt;监管机构（例如美国联邦通信委员会）将电磁波谱划分为不同频率范围，并分配给世界各地的不同应用。对于每个频率范围及其用途，根据本地政策可能需要或不需要申请许可证。在 802.11 中，多个信道可能以不同方式、不同功率水平工作，这取决于所在地区或国家的监管。 Wi-Fi 信道在某个基本中心频率的基础上以 5MHz 为单位进行编号。例如，信道 36 的基本中心频率为 5.00GHz，则信道 36 的中心频率为 &lt;code&gt;5000 + 36*5 = 5180MHz&lt;/code&gt;。虽然信道的中心频率之间以 5MHz 为间隔，但信道宽度可能超过 5MHz（802.11n 高达 40MHz）。因此，信道集中的某些频段内的信道经常重叠。实际上，这意味着一个信道上的传输可能干扰附近信道上的传输。&lt;/p&gt;\n&lt;p&gt;图 3-20 给出了 802.11b/g 信道在 2.4GHz 的 ISM 频段内的信道与频率映射。每个信道宽度为 22MHz。并非所有信道都可在每个国家合法使用。例如，信道 14 仅被授权在日本使用，信道 12 和 13 被授权在欧洲使用，而美国只能使用信道1 ~ 11。其他国家可能更严格（见 802.11 标准的 Annex J 和修订版）。注意，政策和许可要求可能随时间而改变。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;20\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1652883012661.png\&#34; alt=\&#34;图 3-20\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 3-20   802.11b 和 802.11g 标准使用 2.4GHz 和 2.5GHz 之间的频段。这个频段被划分为 14 个 22MHz 宽的重叠信道，其中一些子集是否可合法使用取决于所在国家。在同一地区运行多个基站，分配非重叠的信道是可取的做法，例如美国的 1、 6 和 11。只有一个 40MHz 的 802.11n 信道可用于此频段而不会发生重叠&lt;/p&gt;\n&lt;p&gt;如图 3-20 所示，重叠信道的影响是明显的。例如，一个传输方工作在信道 1 上，它与信道 2、 3、 4 和 5 重叠，但与更高的信道不重叠。在可使用多个接入点的环境中，选择使用哪条信道是很重要的，当同一区域中有多个接入点为多个网络提供服务时，如何选择信道至关重要。在美国，常用方法是同一区域中的 3 个 AP 使用不重叠的信道 1、 6 和 11，信道 11 在美国是无须许可即可使用的最高频率信道。在其他无线局域网也在同一频段运行的情况下，应该由所有受影响的 WLAN 管理员共同规划信道。&lt;/p&gt;\n&lt;p&gt;如图 3-21 所示， 802.11a/n/y 共享一个有些复杂的信道设置，但提供了更多的不重叠信道（即美国的 12 个无须许可的 20MHz 信道）。&lt;/p&gt;\n&lt;p&gt;在图 3-21 中，信道以 5MHz 为单位递增，但存在不同的信道宽度：5MHz、 10MHz、20MHz 和 40MHz。 40MHz 信道宽度是 802.11n 的一个选项（见 3.5.4.2 节），可将几个不同所有者的 Wi-Fi 系统聚合为 2 个 20MHz 信道（称为信道绑定）。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;21\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1652883308062.png\&#34; alt=\&#34;图 3-21\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 3-21   20MHz 信道中的一些可用的 802.11 信道号和中心频率。最常见的无须许可使用的频率范围包括 U-NII 频段，它们均在 5GHz 之上。较低频段被批准可用于大多数国家。 “欧洲”频段被批准用于大多数欧洲国家，高频段被批准用于美国和中国。 802.11a/y 信道的典型宽度为 20MHz，但 802.11n 的信道宽度可能为 40MHz。另外，在日本也可使用窄信道和某些信道（未显示）&lt;/p&gt;\n&lt;p&gt;对于典型的 Wi-Fi 网络，在 AP 安装过程中需要指定其运行信道，并由用户所在的站修改信道以便连接到 AP。当运行在 Ad hoc 模式时，没有起控制作用的 AP，因此一个站通常需要为 AP 手工配置信道。可用的信道和运行功率可能受限于监管环境、硬件功能，以及所支持的驱动程序软件。&lt;/p&gt;\n&lt;h4 id=\&#34;3542-更高吞吐量的-80211802211n\&#34;&gt;3.5.4.2 更高吞吐量的 802.11/8022.11n&lt;/h4&gt;\n&lt;p&gt;2009 年年底， IEEE 将 [&lt;a href=\&#34;#802.11-2007\&#34;&gt;802.11-2007&lt;/a&gt;] 修订为802.11n [&lt;a href=\&#34;#802.11n-2009\&#34;&gt;802.11n-2009&lt;/a&gt;]。它对 802.11 做了一些重要改变。为了支持更高吞吐量，它采用&lt;strong&gt;多输入多输出（MIMO）&lt;strong&gt;管理&lt;/strong&gt;空间流（Spatial Stream）&lt;/strong&gt;，即由多个天线同时传输的多个数据流。一个给定信道上最多支持 4 个这种空间流。802.11n 信道宽度可以是 40MHz （使用两个相邻的 20MHz 信道），这是传统 802.11a/b/g/y 信道宽度的两倍。因此，它可将 802.11a/g 的最大传输速率（54Mb/s）提高 8 倍，达到 432Mb/s。802.11n 也提高了单个流的性能，使用一种更高效的调制方案（802.11n采用 MIMO-正交频分复用（OFDM），每个 20MHz 信道最多承载 52 个数据载波，每个 40MHz 信道最多承载 108 个数据载波，代替 802.11a 和 802.11g 中的 48 个），以及一种更有效的转发纠错编码（以编码率 5/6 代替 3/4），将每个流性能提升到 65Mb/s （20MHz 信道）或 135Mb/s （40MHz信道）。通过将&lt;strong&gt;保护间隔&lt;/strong&gt;（GI，一个强制的符号之间的空闲时间）从传统的 800ns 减少到 400ns，每个流的最大性能可提高到 72.2Mb/s （20MHz信道）和 150Mb/s （40MHz信道）。通过 4 个空间流的完美协同操作，这样可提供最高 600Mb/s 的传输速率。&lt;/p&gt;\n&lt;p&gt;802.11n 标准支持大约 77 种调制和编码选项组合，其中包括 8 种对应单个流的选项， 24 种可在所有流中使用的**平等调制（EQM）&lt;strong&gt;选项，以及 43 种可在多个流上使用的&lt;/strong&gt;不平等调制（UEQM）&lt;strong&gt;选项。表 3-3 给出了调制和编码方案的一些组合，对应于&lt;/strong&gt;调制和编码方案（MCS）**的前 33 个值。更大的值（33 - 76）包括 2 个信道（值 33 - 38）、3 个信道（39 - 52）和 4 个信道（53 - 76）的组合。 MCS 值 32 是一个特殊组合，即 40MHz 信道的两路信号包含相同信息。每行给出了 2 个数据传输速率，一个使用早期的 800ns GI，一个使用较短的 400ns GI 以获得更大传输速率。两个带下划线的值 6Mb/s 和 600Mb/s，分别表示最小和最大吞吐率。&lt;/p&gt;\n&lt;center&gt;表 3-3   802.11n 的 MCS 值包括平等和不平等调制，不同的 FEC 编码率，使用 20MHz 或 40MHz 信道宽度的 4 个空间流，以及 800ns 或 400ns GI 的组合。77 种组合提供从 6Mb/s 到 600Mb/s 的数据传输速率&lt;/center&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;MCS 值&lt;/th&gt;\n&lt;th&gt;调制类型&lt;/th&gt;\n&lt;th&gt;FEC 编码率&lt;/th&gt;\n&lt;th&gt;空间流&lt;/th&gt;\n&lt;th&gt;速率（Mb/s）（20MHz）[800/400ns]&lt;/th&gt;\n&lt;th&gt;速率（Mb/s）（40MHz）[800/400ns]&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;0&lt;/td&gt;\n&lt;td&gt;BPSK&lt;/td&gt;\n&lt;td&gt;1/2&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;6.5/7.2&lt;/td&gt;\n&lt;td&gt;13.5/15&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;QPSK&lt;/td&gt;\n&lt;td&gt;1/2&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;13/14.4&lt;/td&gt;\n&lt;td&gt;27/30&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;td&gt;QPSK&lt;/td&gt;\n&lt;td&gt;3/4&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;19.4/21.7&lt;/td&gt;\n&lt;td&gt;40.5/45&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;3&lt;/td&gt;\n&lt;td&gt;16-QAM&lt;/td&gt;\n&lt;td&gt;1/2&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;26/28.9&lt;/td&gt;\n&lt;td&gt;54/60&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;4&lt;/td&gt;\n&lt;td&gt;16-QAM&lt;/td&gt;\n&lt;td&gt;3/4&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;39/43.3&lt;/td&gt;\n&lt;td&gt;81/90&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;5&lt;/td&gt;\n&lt;td&gt;16-QAM&lt;/td&gt;\n&lt;td&gt;2/3&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;52/57.8&lt;/td&gt;\n&lt;td&gt;108/120&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;6&lt;/td&gt;\n&lt;td&gt;16-QAM&lt;/td&gt;\n&lt;td&gt;3/4&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;58.5/65&lt;/td&gt;\n&lt;td&gt;121.5/135&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;7&lt;/td&gt;\n&lt;td&gt;16-QAM&lt;/td&gt;\n&lt;td&gt;5/6&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;65/72.2&lt;/td&gt;\n&lt;td&gt;135/150&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;8&lt;/td&gt;\n&lt;td&gt;BPSK&lt;/td&gt;\n&lt;td&gt;1/2&lt;/td&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;td&gt;13/14.4&lt;/td&gt;\n&lt;td&gt;27/30&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;...&lt;/td&gt;\n&lt;td&gt;....&lt;/td&gt;\n&lt;td&gt;...&lt;/td&gt;\n&lt;td&gt;...&lt;/td&gt;\n&lt;td&gt;...&lt;/td&gt;\n&lt;td&gt;...&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;15&lt;/td&gt;\n&lt;td&gt;64-QAM&lt;/td&gt;\n&lt;td&gt;5/6&lt;/td&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;td&gt;130/144.4&lt;/td&gt;\n&lt;td&gt;270/300&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;16&lt;/td&gt;\n&lt;td&gt;BPSK&lt;/td&gt;\n&lt;td&gt;1/2&lt;/td&gt;\n&lt;td&gt;3&lt;/td&gt;\n&lt;td&gt;19.5/21.7&lt;/td&gt;\n&lt;td&gt;40.5/45&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;...&lt;/td&gt;\n&lt;td&gt;...&lt;/td&gt;\n&lt;td&gt;...&lt;/td&gt;\n&lt;td&gt;...&lt;/td&gt;\n&lt;td&gt;...&lt;/td&gt;\n&lt;td&gt;...&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;31&lt;/td&gt;\n&lt;td&gt;64-QAM&lt;/td&gt;\n&lt;td&gt;5/6&lt;/td&gt;\n&lt;td&gt;4&lt;/td&gt;\n&lt;td&gt;260/288.9&lt;/td&gt;\n&lt;td&gt;540/600&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;32&lt;/td&gt;\n&lt;td&gt;BPSK&lt;/td&gt;\n&lt;td&gt;1/2&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;N/A&lt;/td&gt;\n&lt;td&gt;6/6.7&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;...&lt;/td&gt;\n&lt;td&gt;...&lt;/td&gt;\n&lt;td&gt;...&lt;/td&gt;\n&lt;td&gt;...&lt;/td&gt;\n&lt;td&gt;...&lt;/td&gt;\n&lt;td&gt;...&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;76&lt;/td&gt;\n&lt;td&gt;64x3/16x1-QAM&lt;/td&gt;\n&lt;td&gt;3/4&lt;/td&gt;\n&lt;td&gt;4&lt;/td&gt;\n&lt;td&gt;214.5/238.3&lt;/td&gt;\n&lt;td&gt;445.5/495&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;p&gt;表 3-3 显示了可用于 802.11n 的各种编码组合，包括&lt;strong&gt;二进制相移键控（BPSK）&lt;/strong&gt;、&lt;strong&gt;正交相移键控（QPSK）&lt;/strong&gt;，以及各种&lt;strong&gt;正交幅度调制（16-QAM和64-QAM）&lt;/strong&gt;。这些调制方案为给定的信道提供更大的传输速率。但是，性能更高和更复杂的调制方案，通常更容易受到噪声干扰。**转发纠错（FEC）**包括一套方法，在发送方引入一些冗余位，用于检测和修改传输过程中的错误。对于 FEC，编码率是可用传输速率与底层信道规定速率之比。例如， 1/2 编码率表示每发送 2 位数据，只有 1 位有效交付。&lt;/p&gt;\n&lt;p&gt;802.11n 可工作在 3 种模式下。在 802.11n 环境中，可选择所谓的&lt;strong&gt;绿地模式&lt;/strong&gt;， PLCP 包含特殊位序列（“训练序列”），它仅被 802.11n 设备获得，不与传统设备进行互操作。为了保持兼容性， 802.11n 提供了 2 种互操作模式。但是，这些模式对纯 802.11n 设备会带来性能损失。一种模式称为&lt;strong&gt;非 HT 模式&lt;/strong&gt;，禁止所有 802.11n 功能，但仍与原有设备兼容。这不是一种很有趣的模式，因此我们不再进一步讨论。另一种模式称为 &lt;strong&gt;HT 混合模式&lt;/strong&gt;，支持 802.11n 和传统操作，这取决于与哪个站进行通信。 PLCP 给出了向 HT STA 提供 AP 的802.11n 功能和保护传统 STA 所需的信息， PLCP 被修订为包含 HT 和传统信息，并以一个比绿地模式慢的速度传输，以便传统设备来得及处理。在一个传统站使用共享信道时， HT 保护还要求 HTAP 使用自定向 CTS 帧（或 RTS/CTS 帧交换）以传统速率通知传统站。尽管 RTS/CTS 帧是短的，但由于它们是以传统速率（6Mb/s）发送，所以这将显著降低 802.11n WLAN 性能。&lt;/p&gt;\n&lt;p&gt;在部署一个 802.11n AP 时，应考虑分配适当的信道。在使用 40MHz 信道时， 802.11n AP 应运行在 5GHz 以上的 U-NII 频段， 2.4GHz 的 ISM 频段中根本没有足够的可用频段提供这么宽的信道。一种可选的 BSS 功能称为&lt;strong&gt;分阶段共存操作（PCO）&lt;/strong&gt;，允许一个 AP 定期在 20MHz 和 40MHz 信道宽度之间切换，更好地提供 802.11n AP 之间的共存，以一些额外流量代价为附近的传统设备提供服务。最后值得一提的是， 802.11n AP 通常比传统 AP 消耗更多能量。这种比基本的 15W 更高的电源功率，可由 **802.3af 以太网供电（PoE）**系统提供，这意味着需要使用 PoE+ （802.3at 能提供 30W），除非有其他形式的电源（例如一个外接电源）。&lt;/p&gt;\n&lt;h3 id=\&#34;355-wi-fi-安全\&#34;&gt;3.5.5 Wi-Fi 安全&lt;/h3&gt;\n&lt;p&gt;802.11 网络的安全模型有很大变化。早期， 802.11 采用一种称为**有线等效保密（WEP）**的加密方法。 WEP 后来被证明安全性薄弱，并出现了替换它的需求。工业界通过 &lt;strong&gt;Wi-Fi 保护访问（WPA）&lt;strong&gt;来回应，它使用加密块（见第 18 章的密码学基础知识）代替密钥方式。在 WPA 中，采用一种称为&lt;/strong&gt;临时密钥完整性协议（TKIP）&lt;strong&gt;的方案，确保每个帧都用不同密钥加密。它还包括一种称为 Michael 的消息完整性检查，以弥补 WEP 中的主要弱点之一。 WPA 被创建为一个占位符，可通过硬件升级方式使设备支持 WEP 功能。 IEEE 802.11i 工作组制定了一个功能更强的标准，最终被吸收到 [&lt;a href=\&#34;#802.11-2007\&#34;&gt;802.11-2007&lt;/a&gt;] 的第 8 条，并被工业界称为“WPA2”。WEP 和 WPA 都使用 RC4 加密算法 [&lt;a href=\&#34;#S96\&#34;&gt;S96&lt;/a&gt;]。 WPA2 使用&lt;/strong&gt;高级加密标准&lt;/strong&gt;（AES）算法 [&lt;a href=\&#34;#AES01\&#34;&gt;AES01&lt;/a&gt;]。&lt;/p&gt;\n&lt;p&gt;我们刚才讨论的加密技术，用于在站和 AP 之间提供隐私保护（假设站拥有访问网络的合法授权）。在使用 WEP、 WPA 或 WPA2 的小规模环境中，授权通常通过预先设置一个共享密钥或密码来实现，它在每个站和 AP 的配置过程中生成。知道这个密钥的用户拥有访问网络的合法授权。这些密钥常用于保护隐私的加密密钥的初始化。这种&lt;strong&gt;预共享密钥（PSK）&lt;strong&gt;具有局限性。例如，管理员为授权用户提供密钥，这可能是相当麻烦的事。如果一个新的用户被授权，必须更换 PSK 并通知所有合法用户。这种方法难以用于有很多用户的环境。因此， WPA 和后期标准支持&lt;/strong&gt;基于端口的网络访问控制&lt;/strong&gt;标准，称为 802.1x [&lt;a href=\&#34;#802.1x-2010\&#34;&gt;802.1x-2010&lt;/a&gt;]。它提供了一种在 IEEE 802 局域网（称为 EAPOL，包括 802.3 和 802.11 [&lt;a href=\&#34;#RFC4017\&#34;&gt;RFC4017&lt;/a&gt;]）中使用&lt;strong&gt;扩展身份验证协议（EAP）&lt;/strong&gt;  [&lt;a href=\&#34;#RFC3748\&#34;&gt;RFC3748&lt;/a&gt;] 的方式。 EAP 可使用多种标准和非标准化的认证协议。它也可用于建立密钥，包括 WEP 密钥。第 18 章将详细讨论这些协议。我们在 3.6 节讨论 PPP 时也会看到 EAP 的使用。&lt;/p&gt;\n&lt;p&gt;随着 IEEE 802.11i 工作组的工作完成， WPA 和 RC4/TKIP 组合扩展为一个称为 CCMP 的新方案，它被作为 WPA2 的一部分。 CCMP 是基于&lt;strong&gt;计数器模式&lt;/strong&gt;（CCM [&lt;a href=\&#34;#RFC3610\&#34;&gt;RFC3610&lt;/a&gt;]）的 AES ，以确保用于认证和完整性的&lt;strong&gt;密码块链接消息认证码&lt;/strong&gt;（CBC-MAC；注意术语MAC在这里的“其他”用途）的安全。 AES 采用 128 位的块和 128 位的密钥。 CCMP 和 TKIP 形成了 Wi-Fi 安全体系结构的基础，称为&lt;strong&gt;强健安全网络（RSN）&lt;/strong&gt;，并支持&lt;strong&gt;强健安全网络访问（RSNA）&lt;/strong&gt;。早期的一些方法（如 WEP）称为预 RSNA 方法。 RSNA 要求支持 CCMP （TKIP 可选），而 802.11n 标准完全不使用 TKIP。表 3-4 总结了这种复杂情况。&lt;/p&gt;\n&lt;center&gt;表 3-4   Wi-Fi 安全已从不安全的 WEP 演变到 WPA，再到当前标准的 WPA2 方案&lt;/center&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;名称/标准&lt;/th&gt;\n&lt;th&gt;密码&lt;/th&gt;\n&lt;th&gt;密钥流管理&lt;/th&gt;\n&lt;th&gt;认证&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;WEP（预 RSNA）&lt;/td&gt;\n&lt;td&gt;RC4&lt;/td&gt;\n&lt;td&gt;（WEP）&lt;/td&gt;\n&lt;td&gt;PSK，（802.1X/EAP）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;WPA&lt;/td&gt;\n&lt;td&gt;RC4&lt;/td&gt;\n&lt;td&gt;TKIP&lt;/td&gt;\n&lt;td&gt;PSK，802.1X/EAP&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;WPA2/802.11(i)&lt;/td&gt;\n&lt;td&gt;CCMP&lt;/td&gt;\n&lt;td&gt;CCMP，（TKIP）&lt;/td&gt;\n&lt;td&gt;PSK，802.1X/EAP&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;p&gt;在所有情况下，预共享密钥和 802.1X 可用于认证和初始化密钥。 802.1X/EAP 的主要吸引力在于其可管理的认证服务器，它基于 AP 为每个用户提供访问控制决策。出于这个原因，使用 802.1X 的认证有时称为“企业” （例如 WPA 企业）。 EAP 本身可封装各种认证协议，我们将在第 18 章详细讨论这些协议。&lt;/p&gt;\n&lt;h3 id=\&#34;356-wi-fi-网状网80211s\&#34;&gt;3.5.6 Wi-Fi 网状网（802.11s）&lt;/h3&gt;\n&lt;p&gt;IEEE 正在制定 802.11s 标准，其中包括 Wi-Fi 的&lt;strong&gt;网状网（Mesh）&lt;strong&gt;操作。通过 Mesh 操作，无线站点可用作数据转发代理（像 AP 那样）。在作者编写本书期间（2011 年中期），这个标准仍未完成。 802.11s 草案定义了&lt;/strong&gt;混合无线路由协议（HWRP）&lt;/strong&gt;，它基于 &lt;strong&gt;Ad hoc 按需距离向量（AODV）&lt;strong&gt;路由 [&lt;a href=\&#34;#RFC3561\&#34;&gt;RFC3561&lt;/a&gt;] 和&lt;/strong&gt;优化链路状态路由（OLSR）&lt;strong&gt;协议 [&lt;a href=\&#34;#RFC3626\&#34;&gt;RFC3626&lt;/a&gt;] 等 IETF 标准。Mesh 站（Mesh STA）是一种 QoS 站，它可能参与 HWRP 或其他路由协议，但兼容节点必须包括 HWRP 实现和相关&lt;/strong&gt;通话时间链路度量&lt;/strong&gt;。 Mesh 节点使用 EDCA 来协同工作，或使用一种可选的称为 &lt;strong&gt;Mesh 确定性访问&lt;/strong&gt;的协同功能。 Mesh 点（MP）是与邻居形成 Mesh 连接的那些节点。那些包含 AP 功能的 Mesh 点称为 Mesh AP （MAP）。常规 802.11 站可使用 AP 或 MAP 访问无线局域网的其他部分。&lt;/p&gt;\n&lt;p&gt;802.11s 草案为 RSNA 制定了一种可选的新安全方案，称为基于对等同时认证（SAE）的认证 [&lt;a href=\&#34;#SAE\&#34;&gt;SAE&lt;/a&gt;]。这种安全协议与其他协议有些区别，它并不需要一个特定的发起者和响应者之间的操作同步。相反，所有站都被平等对待，先发现其他站的任何站可启动一次安全交换（这可能导致两个站同时启动一次交换）。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;36-点到点协议\&#34;&gt;3.6 点到点协议&lt;/h2&gt;\n&lt;p&gt;PPP 表示点到点协议 [&lt;a href=\&#34;#RFC1661\&#34;&gt;RFC1661&lt;/a&gt;] [&lt;a href=\&#34;#RFC1662\&#34;&gt;RFC1662&lt;/a&gt;] [&lt;a href=\&#34;#RFC2153\&#34;&gt;RFC2153&lt;/a&gt;] 。这是一种在串行链路上传输 IP 数据报的流行方法，从低速的拨号调制解调器到高速的光链路 [&lt;a href=\&#34;#RFC2615\&#34;&gt;RFC2615&lt;/a&gt;]。它被一些 DSL 服务供应商广泛部署，也可分配 Internet 系统的参数（例如，最初的 IP 地址和域名服务器；见第 6 章）。&lt;/p&gt;\n&lt;p&gt;PPP 实际上是一个协议集合，而不是一个单一的协议。它支持建立链接的基本方法——称为&lt;strong&gt;链路控制协议（Link Control Protocol， LCP）&lt;/strong&gt;，以及一系列 NCP 协议，在 LCP 建立了基本链路之后，用于为各种协议（包括 IPv4、 IPv6 和非 IP 协议）建立网络层链路。一些相关标准涉及对 PPP 的压缩和加密控制，以及在链接建立后的一些认证方法。&lt;/p&gt;\n&lt;h3 id=\&#34;361-链路控制协议\&#34;&gt;3.6.1 链路控制协议&lt;/h3&gt;\n&lt;p&gt;PPP 的 LCP 用于在点到点链路上建立和维护低层的双方通信路径。因此， PPP 操作只需关注一条链路的两端，它不需要像以太网和 Wi-Fi 的 MAC 层协议那样处理共享资源访问的问题。&lt;/p&gt;\n&lt;p&gt;PPP 通常对底层的点到点链路有最低要求，LCP 更是这样。链路必须支持双向操作（LCP 使用的确认），以及异步或同步操作。通常， LCP 使用简单的位级别帧格式，基于&lt;strong&gt;高级数据链路控制（HDLC）&lt;strong&gt;建立链路协议。在 PPP 设计时， HDLC 就已建立了一种良好的帧格式 [&lt;a href=\&#34;#ISO3309\&#34;&gt;ISO3309&lt;/a&gt;] [&lt;a href=\&#34;#ISO4335\&#34;&gt;ISO4335&lt;/a&gt;] 。 IBM 将它修改为&lt;/strong&gt;同步数据链路控制（SDLC）&lt;/strong&gt;，在其专用的**系统网络体系结构（SNA）**协议族中用作链路层协议。 HDLC 协议还用作 802.2 中 LLC 标准的基础，并最终被用于 PPP。 图 3-22 显示了这种格式。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;22\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1652887335410.png\&#34; alt=\&#34;图 3-22\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 3-22   PPP 基本帧格式借用了 HDLC 的格式。它包括一个协议标识符、有效载荷区域，以及 2 或 4 字节的 FCS。其他字段是否存在取决于压缩选项&lt;/p&gt;\n&lt;p&gt;在通常情况下， PPP 帧格式类似于图 3-22 所示的 HDLC 帧，由 2 个 1 字节的包含固定值 &lt;code&gt;0x7E&lt;/code&gt; 的&lt;strong&gt;标志&lt;/strong&gt;字段“包围” 。点到点链路的两个端点使用这些字段来发现一个帧的开始和结束。如果 &lt;code&gt;0x7E&lt;/code&gt; 值出现在帧内部，这时会带来一个小问题。它可通过两种方式来处理，这取决于 PPP 工作在异步还是同步链路上。对于异步链路， PPP 使用&lt;strong&gt;字符填充&lt;/strong&gt;（也称为字节填充）。如果标志字符出现在帧中其他地方，则用 2 字节序列 &lt;code&gt;0x7D5E&lt;/code&gt; （ &lt;code&gt;0x7D&lt;/code&gt; 称为“ppp转义字符”）替换。如果转义字符本身出现在帧中，则用 2 字节序列 &lt;code&gt;0x7D5D&lt;/code&gt;  替换。因此，接收方用 &lt;code&gt;0x7E&lt;/code&gt; 替换接收的 &lt;code&gt;0x7D5E&lt;/code&gt; ，并用 &lt;code&gt;0x7D&lt;/code&gt; 替换接收的 &lt;code&gt;0x7D5D&lt;/code&gt;。 在同步链路（例如 T1 线路、 T3 线路）上， PPP 使用&lt;strong&gt;位填充&lt;/strong&gt;。注意，标志字符的位模式为 &lt;code&gt;01111110&lt;/code&gt; （连续 6 个 1 的位序列），在除了标志字符之外的任何地方，位填充在 5 个连续 1 之后填充一个 0。这样做意味着，发送的字节可能超过 8 位，但这通常是正常的，因为低层串行处理硬件能去掉填充的比特流，并将它恢复成未填充时的样子。&lt;/p&gt;\n&lt;p&gt;在第一个标志字段之后， PPP 采用 HDLC 的&lt;strong&gt;地址&lt;/strong&gt;（Addr）和控制字段。在 HDLC 中，地址字段用于指定哪个站正在处理，但是由于 PPP 只关心一个目的地，这个字段总是被设置为 &lt;code&gt;0xFF&lt;/code&gt; （所有站）。 HDLC 控制字段用于指示帧序列和重传行为。由于这些链路层的可靠性功能通常不是由 PPP 实现，所以控制字段设置为固定值 &lt;code&gt;0x03&lt;/code&gt;。 由于地址和控制字段在 PPP 中都是固定的常数，所以在传输过程中经常通过一个称为**地址和控制字段压缩（ACFC）**的选项来省略它们，该选项实质上是消除了这两个字段。&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;注意   链路层网络应提供多少可靠性，多年来一直存在相当大的争议。在以太网\n中，在放弃之前可尝试重传多达 16 次。通常， PPP 被配置为不重传，尽管确实\n有增加重传的规范 [RFC1663]。折中方案是巧妙的，但它依赖于携带的流量类型。\n[RFC3366] 详细讨论了要考虑的有关因素。\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;PPP 帧的&lt;strong&gt;协议&lt;/strong&gt;字段表明携带的数据类型。在一个 PPP 帧中，可携带多种不同类型的协议。正式列表和用于&lt;strong&gt;协议&lt;/strong&gt;字段的分配号显示在“点到点协议字段分配”文档中 [&lt;a href=\&#34;#PPPn\&#34;&gt;PPPn&lt;/a&gt;] 。根据 HDLC 规范，协议号的分配方式为：高位字节的最低有效位为 0，低位字节的最低有效位为1。 &lt;code&gt;0x0000 ~ 0x3FFF&lt;/code&gt; （十六进制）范围内的值表示网络层协议， &lt;code&gt;0x8000 ~ 0xBFFF&lt;/code&gt; 范围内的值表示 NCP 的相关数据。 &lt;code&gt;0x4000 ~ 0x7FFF&lt;/code&gt; 范围内的值用于 NCP 不相关的“很少使用的”协议。 &lt;code&gt;0xC000 ~ 0xEFFF&lt;/code&gt; 范围内的值表示控制协议，例如 LCP。在某些情况下，如果**协议字段压缩（PFC）**选项在链路建立时协商成功，&lt;strong&gt;协议&lt;/strong&gt;字段可被压缩为 1 字节。 &lt;code&gt;0x0000 ~ 0x00FF&lt;/code&gt; 范围内的协议号适用于包括大多数流行的网络层协议在内的协议。注意， LCP 分组总是使用 2 字节的未压缩格式。&lt;/p&gt;\n&lt;p&gt;PPP 帧的最后部分包含一个 16 位的 FCS（一个 CRC16，生成多项式为 &lt;code&gt;10001000000100001&lt;/code&gt;），涵盖除 FCS 字段本身和标志字节之外的整个帧。注意， FCS 的值涵盖任何字节或位被填充之前的帧。 LCP 选项（见 3.6.1.2 节）可将 CRC 从 16 位扩展到 32 位。在这种情况下，可采用与前面提到的以太网相同的 CRC32 多项式。&lt;/p&gt;\n&lt;h4 id=\&#34;3611-lcp-操作\&#34;&gt;3.6.1.1 LCP 操作&lt;/h4&gt;\n&lt;p&gt;LCP 在基本 PPP 分组之上进行了简单的封装。如图 3-23 所示。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;23\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1652888191158.png\&#34; alt=\&#34;图 3-23\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 3-23   LCP 分组采用很普通的格式，能识别封装数据的类型和长度。 LCP 帧主要用于建立 PPP 链路，这种格式已成为很多网络控制协议的基础&lt;/p&gt;\n&lt;p&gt;LCP 的 PPP 协议字段值始终是 &lt;code&gt;0xC021&lt;/code&gt;，它不能用 PFC 删除，以免产生歧义。&lt;strong&gt;标识&lt;/strong&gt;字段是由 LCP 请求帧的发送方提供的序列号，并随着每个后续消息进行递增。在生成一个回复（ACK、 NACK 或 REJECT 响应）时，这个字段通过复制响应分组请求中包含的值来构造。采用这种方式，请求方可通过匹配标识符来识别相应请求的应答。&lt;strong&gt;代码&lt;/strong&gt;字段给出了请求或响应的操作类型：配置请求（&lt;code&gt;0x01&lt;/code&gt;）、配置 ACK （&lt;code&gt;0x02&lt;/code&gt;）、配置 NACK （&lt;code&gt;0x03&lt;/code&gt;）、配置 REJECT（&lt;code&gt;0x04&lt;/code&gt;）、终止请求（&lt;code&gt;0x05&lt;/code&gt;）、终止 ACK （&lt;code&gt;0x06&lt;/code&gt;）、代码 REJECT（&lt;code&gt;0x07&lt;/code&gt;）、协议REJECT（&lt;code&gt;0x08&lt;/code&gt;）、回送请求（&lt;code&gt;0x09&lt;/code&gt;）、回送应答 （&lt;code&gt;0x0A&lt;/code&gt;）、放弃请求 （&lt;code&gt;0x0B&lt;/code&gt;）、标识（&lt;code&gt;0x0C&lt;/code&gt;）和剩余时间（&lt;code&gt;0x0D&lt;/code&gt;）。 ACK 消息通常表明接受一组选项， NACK 消息用建议选项表明部分拒绝。 REJECT 消息完全拒绝一个或多个选项。拒绝代码表明前一个分组包含的某些字段值未知。长度字段给出了 LCP 分组的字节长度，它不能超过链路的&lt;strong&gt;最大接收单元（MRU）&lt;/strong&gt;，我们稍后讨论一种建议的最大帧限制。注意，长度字段是 LCP 协议的一部分；PPP 协议通常不提供这种字段。&lt;/p&gt;\n&lt;p&gt;LCP 的主要工作是使一条点到点链路达到最低要求。&lt;strong&gt;配置&lt;/strong&gt;消息使链路两端开始基本配置过程，并建立商定的选项。&lt;strong&gt;终止&lt;/strong&gt;消息用于在完成后清除一条链路。 LCP 也提供了前面提到的一些附加功能。&lt;strong&gt;回送请求/应答&lt;/strong&gt;消息可由 LCP 在一条活跃链路上随时交换，以验证对方的操作。&lt;strong&gt;放弃请求&lt;/strong&gt;消息可用于性能测试，指示对方丢弃没有响应的分组。&lt;strong&gt;标识&lt;/strong&gt;和&lt;strong&gt;剩余时间&lt;/strong&gt;消息用于管理目的：了解对方的系统类型，指出链路保持建立的时间（例如出于管理或安全原因）。&lt;/p&gt;\n&lt;p&gt;从历史上来看，如果一个远程工作站处于&lt;strong&gt;环回模式&lt;/strong&gt;（或者说“回路”），这时点到点链路会出现一个常见问题。电话公司的广域数据线路有时会为了测试而设置成环回模式，由一方发送的数据直接由另一方返回。虽然这可能对线路测试有用，但它对数据通信完全没有帮助，所以 LCP 包括一种发送&lt;strong&gt;魔术数字&lt;/strong&gt;（由发送方选择的任意数字）的方式，并查看是否立即返回相同类型的消息。如果是的话，该线路被检测为处于回路，并可能需要进行维护。&lt;/p&gt;\n&lt;p&gt;为了对 PPP 链路建立和选项协商有一个更好的认识，图 3-24 显示了一个简化的分组交换时间表和一个简化的状态机（在链路两端实现）。&lt;/p&gt;\n&lt;p&gt;一旦底层协议表明一个关联变为活跃（例如调制解调器检测到载波），则认为这个链路已被建立。链路质量测试包含链路质量报告和确认交换（见 3.6.1.2 节），它也可以在此期间完成。如果链接需要认证（这是常见的），例如当拨号到一个 ISP 时，可能需要一些额外的信息交换，以认证链路上的一方或双方的身份。当底层协议或硬件表明一个关联已停止（例如载波消失），或发送一个链路终止请求，并从对方接收到一个终止响应，则认为这个链路已被终止。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;24\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1652888802627.png\&#34; alt=\&#34;图 3-24\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 3-24   LCP 用于建立 PPP 链路和各方商定选项。典型的交换过程包括一对包含选项列表的配置请求和配置确认、一个认证交换、数据交换（未画出）和一个终止交换。因为 PPP 是一个包括很多部分的通用协议，所以在一条链路建立和终止之间可能发生很多其他类型的操作&lt;/p&gt;\n&lt;h4 id=\&#34;3612-lcp-选项\&#34;&gt;3.6.1.2 LCP 选项&lt;/h4&gt;\n&lt;p&gt;当 LCP 建立一条由一个或多个 NCP 使用的链路时，可以对一些选项进行协商。我们将讨论两种或更多的常见情况。**异步控制字符映射（ACCM）**或简称“ asyncmap”选项定义哪些控制字符（即 &lt;code&gt;0x00 ~ 0x1F&lt;/code&gt; 范围内的 ASCII 字符）需要被“转义”为 PPP 操作。转义一个字符表示不发送这个字符的真实值，而将 PPP 转义字符（&lt;code&gt;0x7D&lt;/code&gt;）放在控制字符原始值和 &lt;code&gt;0x2D&lt;/code&gt; 异或形成的值之前。例如， XOFF 字符（&lt;code&gt;0x13&lt;/code&gt;）将转换为（&lt;code&gt;0x7D33&lt;/code&gt;）发送。 ACCM 用于控制字符可能影响底层硬件操作的情况。例如，如果软件流控制能够使用 XON/XOFF 字符，而 XOFF 字符未经转义就通过链路传输，则硬件直到看到一个 XON 字符才停止数据传输。asyncmap 选项通常是一个 32 位的十六进制数，其中第 n 个最低有效位被设置为 1 ，表示值为 n 的控制字符应被转义。因此， asyncmap 为 &lt;code&gt;0xffffffff&lt;/code&gt; 表示转义所有控制字符，为 &lt;code&gt;0x00000000&lt;/code&gt;表示不转义任何控制字符，为 &lt;code&gt;0x000A0000&lt;/code&gt; 表示转义 XON （&lt;code&gt;0x11&lt;/code&gt;）和 XOFF （&lt;code&gt;0x13&lt;/code&gt;）。虽然 &lt;code&gt;0xffffffff&lt;/code&gt; 是默认值，但当前很多链路可在 asyncmap 被设置为 &lt;code&gt;0x00000000&lt;/code&gt; 时安全运行。&lt;/p&gt;\n&lt;p&gt;由于 PPP 缺少一个长度字段，并且串行线路通常不提供帧封装，所以在理论上对一个 PPP 帧的长度没有硬性限制。实际上，最大帧大小通常由 MRU 指定。当一台主机指定一个 MRU 选项（&lt;code&gt;0x01&lt;/code&gt;）时，它要求对方不发送比 MRU 选项提供的值更长的帧。 MRU 值是数据字段的字节长度，它不计算其他 PPP 开销字段（即协议、 FCS、标志字段）。它的典型值是 1500 或 1492，但也可能多达 65535。 1Pv6 操作需要的长度最小为 1280。 PPP 标准要求具体实现能接收最大 1500 字节的帧， MRU 更多的是建议对方选择帧大小，而不是硬性限制帧大小。当小分组和大分组在同一条 PPP 链路上交错传输时，较大分组可能占用一条低带宽链路的大部分带宽，并影响小分组的正常传输。这可能导致抖动（延迟变化），对交互式应用（例如远程登录和 VoIP）产生负面影响。配置较小的 MRU （或 MTU）有助于缓解这个问题，但会产生更大的开销。&lt;/p&gt;\n&lt;p&gt;PPP 支持一种交换链路质量报告信息的机制。在选项协商期间，可能包括一个包含所请求的特定质量协议的配置信息。选项中的第 16 位被保留给特定协议，但最常见的是一个包括**链路质量报告（LQR）**的 PPP 标准 [&lt;a href=\&#34;#RFC1989\&#34;&gt;RFC1989&lt;/a&gt;] ，它在 PPP 协议字段中使用值 &lt;code&gt;0xC025&lt;/code&gt;。如果启用该选项，则要求对方按某个周期间隔提供 LQR。 LQR 请求之间的最大周期间隔被编码为一个 32 位数字，它被保存在配置选项中，并以 1/100 秒为单位表示。对方可能比这个要求更频繁地生成 LQR。LQR 包括以下信息：一个魔术数字、发送和接收的分组数和字节数、出错的输入分组数和丢弃的分组数，以及交换的 LQR 总数。在一个典型的实现中，允许用户设置对方发送 LQR 的频繁程度。如果链路质量无法满足某些配置阈值，有些实现也提供了终止链路的方法。 LQR 可在 PPP 链路进入建立状态后请求。每个 LQR 被赋予一个序列号，因此它能确定一段时间内的趋势，甚至在 LQR 重新排序时也能确定。&lt;/p&gt;\n&lt;p&gt;很多 PPP 实现支持一种&lt;strong&gt;回叫&lt;/strong&gt;功能。在一次典型的回叫建立过程中， PPP 拨号回叫客户端呼叫 PPP 回叫服务器，并提供认证信息，而服务器断开连接并回叫客户端。在呼叫费用不对称或对于某些安全级别的情况下，这种做法可能是有用的。 LCP 选项针对用于协商回叫的协议，该选项值为 &lt;code&gt;0x0D&lt;/code&gt;  [&lt;a href=\&#34;#RFC1570\&#34;&gt;RFC1570&lt;/a&gt;]。如果许可，**回叫控制协议（CBCP）**完成协商。&lt;/p&gt;\n&lt;p&gt;PPP 使用的一些压缩和加密算法在处理时需要一定的最小字节数，称为&lt;strong&gt;块大小&lt;/strong&gt;。在数据不够长的情况下，通过填充增加数据长度，达到一个甚至多个块的大小。如果存在填充，它通常位于数据区后面，并位于 PPP FCS 字段之前。一种填充方法称为&lt;strong&gt;自描述填充&lt;/strong&gt; [&lt;a href=\&#34;#RFC1570\&#34;&gt;RFC1570&lt;/a&gt;]，它将填充值变为非零值。这时，每个字节获得填充区域的偏移量值。因此，填充的第一个字节值为 &lt;code&gt;0x01&lt;/code&gt;，最后一个字节包含填充字节数。最多支持 255 字节的填充。自描述填充选项（类型 10）用于让对方了解填充类型和&lt;strong&gt;最大填充值（MPV）&lt;/strong&gt;，它是这个关联允许的最大填充值。由于基本 PPP 帧缺少一个明确的长度字段，因此一个接收方可使用自描述填充，以确定应从接收的数据区删除多少填充字节。&lt;/p&gt;\n&lt;p&gt;为了减小每个帧包含一个头部的固定开销，提出了一种将多个不同协议的有效载荷聚合成 PPP 帧的方法，称为 PPPMux [&lt;a href=\&#34;#RFC3153\&#34;&gt;RFC3153&lt;/a&gt;] 方法。主要 PPP 头部的协议字段被设置为聚合帧（&lt;code&gt;0x0059&lt;/code&gt;），然后每个有效载荷块被插入帧中。通过在每个有效载荷块之前插入 1 ~ 4 字节的子帧头部来实现。在子帧头部中， 1 位（称为 PFF）说明子帧头部中是否包含协议字段，1 位（称为 LXT）说明后面的长度字段是 1 字节还是 2 字节。除此之外， 1 或 2 字节的协议 ID 使用与外部的 PPP 头部相同的值和压缩方法。在子帧与默认 PID （该 PID 在配置阶段通过 **PPPMux 控制协议（PPPMuxCP）**建立）匹配时， PFF 可以为 0 （意味着不存在 PID 字段）。&lt;/p&gt;\n&lt;p&gt;PPP 帧格式如图 3-19 所示，普通 PPP/HDLC 的 FCS 可以是 16 或 32 位。默认的 FCS 为 16 位，但 32 位的 FCS 值可通过 32 位的 FCS 选项来启用。其他的 LCP 选项包括使用 PFC 和 ACFC，以及认证算法的选择。&lt;/p&gt;\n&lt;p&gt;国际化 [&lt;a href=\&#34;#RFC2484\&#34;&gt;RFC2484&lt;/a&gt;] 提供了一种使用语言和字符集的表示方式。字符集是一个来自“字符集注册表” [&lt;a href=\&#34;#IANA-CHARSET\&#34;&gt;IANA-CHARSET&lt;/a&gt;] 的标准值，并从 [&lt;a href=\&#34;#RFC5646\&#34;&gt;RFC5646&lt;/a&gt;] [&lt;a href=\&#34;#RFC4647\&#34;&gt;RFC4647&lt;/a&gt;] 的列表中选择语言。&lt;/p&gt;\n&lt;h3 id=\&#34;362-多链路-ppp\&#34;&gt;3.6.2 多链路 PPP&lt;/h3&gt;\n&lt;p&gt;PPP 的一个特殊版本称为&lt;strong&gt;多链路PPP （MP）&lt;/strong&gt; [&lt;a href=\&#34;#RFC1990\&#34;&gt;RFC1990&lt;/a&gt;]，可用于将多条点到点链路聚合为一条链路。这种想法与前面讨论过的链路聚合相似，并被用于多个电路交换信道（例如 ISDNB 信道）的聚合。 MP 包含一个特殊的 LCP 选项，表示支持多链路，以及一个用于多链路上 PPP 帧分片与重组的协商协议。一条聚合链路（称为一个&lt;strong&gt;捆绑&lt;/strong&gt;）可作为一条完整的虚拟链路来操作，并包含自己的配置信息。链路捆绑由大量&lt;strong&gt;成员链路&lt;/strong&gt;组成。每个成员链路可能有自己的选项集。&lt;/p&gt;\n&lt;p&gt;实现 MP 的典型方法是使分组轮流经过各个成员链路传输。这种方法称为&lt;strong&gt;银行柜员算法&lt;/strong&gt;，它可能导致分组重新排序，可能为其他协议带来不良的性能影响。 （例如，虽然 TCP/IP 可以正确处理重新排序后的分组，但也可能不如没有重新排序处理得好。） MP 在每个分组中添加一个 2 ~ 4 字节的&lt;strong&gt;序列头部&lt;/strong&gt;，而远程 MP 接收方的任务是重建正确的顺序。图 3-25 显示了这种数据帧。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;25\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1652953897257.png\&#34; alt=\&#34;图 3-25\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 3-25   一个 MP 分片包含一个序列头部，允许在一个多链路捆绑的远端对分片重新排序。这个头部支持 2 种格式：短头部（2 字节）和长头部（4 字节）&lt;/p&gt;\n&lt;p&gt;在图 3-25 中，我们看到一个 MP 分片的开始分片（B）、结束分片（E）位字段和&lt;strong&gt;序列号&lt;/strong&gt;字段。这里，需要注意的是长格式（4 字节用于分片信息）和短格式（2 字节用于分片信息）。在选项协商阶段，  LCP 的&lt;strong&gt;短序列号&lt;/strong&gt;选项（类型 18）用于选择使用的格式。如果一个帧没有被分片，但使用这种格式传输，则 B 和 E 位都被置位，表明该分片是第一个和最后一个（即它是整个帧）。否则，第一个分片的 B、 E 位组合被设置为 &lt;code&gt;10&lt;/code&gt;，最后一个分片的 B、 E位 组合被设置为 &lt;code&gt;01&lt;/code&gt; ，它们之间的所有分片被设置为 &lt;code&gt;00&lt;/code&gt;。序列号给出相对第一个分片的分组号偏移量。&lt;/p&gt;\n&lt;p&gt;MP 使用一个称为多链路&lt;strong&gt;最大接收重构单元&lt;/strong&gt;（MRRU，类型 18）的 LCP 选项，它可将一系列更大的 MRU 应用于捆绑中。大于成员链路 MRU 的帧仍被允许通过这个 MP 链路，直到达到这个值的上限为止。&lt;/p&gt;\n&lt;p&gt;由于一个 MP 捆绑可能跨越多条成员链路，因此需要一种方法来确定成员链路属于同一捆绑。同一捆绑中的成员链路由 LCP &lt;strong&gt;端点鉴别&lt;/strong&gt;（类型 19）选项识别。端点鉴别可使用电话号码、从 IP 或 MAC 地址中提取的数字，以及其他可管理的字符串。除了每个成员链路的常见内容，对这个选项的格式没有多少限制。&lt;/p&gt;\n&lt;p&gt;建立 MP 的基本方法定义在 [&lt;a href=\&#34;#RFC1990\&#34;&gt;RFC1990&lt;/a&gt;] 中，希望各个成员链路可对称使用，相近数量的分片被分配到号码固定的每条链路上。为了实现更复杂的分配， [&lt;a href=\&#34;#RFC2125\&#34;&gt;RFC2125&lt;/a&gt;] 中规定了&lt;strong&gt;带宽分配协议（BAP）&lt;strong&gt;和&lt;/strong&gt;带宽分配控制协议（BACP）&lt;/strong&gt;。 BAP 用于为一个捆绑动态添加或删除链路，而 BACP 用于交换如何使用 BAP 添加或删除链路的信息。这种功能有助于实现&lt;strong&gt;按需带宽（BOD）&lt;/strong&gt;。在一些需要分配固定资源以满足应用（例如一定数量的电话连接）对带宽需求的网络中， BOD 通常需要监测流量，在应用需求高时创建新的连接，以及在应用需求低时删除连接。在某些开销和连接数量相关的情况下，这种功能是有用的。&lt;/p&gt;\n&lt;p&gt;BAP/BACP 使用一种新的&lt;strong&gt;链路鉴别&lt;/strong&gt; LCP 选项（LCP 选项类型为 23）。这个选项包含一个 16 位的数字值，一个捆绑中的每条成员链路有不同的值。它被 BAP 用于确定需要添加或删除哪些链路。在一条 PPP 链路的网络阶段，每个捆绑都需要使用 BACP 协商。它的主要目的是找出&lt;strong&gt;首选对端&lt;/strong&gt;。也就是说，如果在多个对端之间同时建立多个捆绑时，将会优先为首选对端分配成员链路。&lt;/p&gt;\n&lt;p&gt;BAP 包括 3 种分组类型：请求、响应和标识。请求用于向一个捆绑添加一条链路，或从一个捆绑中删除一条链路。标识用于为原始或被确认的请求返回结果。响应是对这些请求的 ACK 或 NACK。更多细节见 [&lt;a href=\&#34;#RFC2125\&#34;&gt;RFC2125&lt;/a&gt;] 。&lt;/p&gt;\n&lt;h3 id=\&#34;363-压缩控制协议\&#34;&gt;3.6.3 压缩控制协议&lt;/h3&gt;\n&lt;p&gt;从历史上来看， PPP 是相对较慢的拨号调制解调器使用的协议。因此，针对 PPP 链路上压缩后发送数据已提出一些方法。压缩类型是不同的，无论是调制解调器硬件支持的压缩类型（例如 V.42bis、 V.44），还是我们以后讨论的协议头部压缩。目前，有几个压缩选项可选。可在一条 PPP 链路的两个方向做出选择， LCP 可协商一个使&lt;strong&gt;压缩控制协议（CCP）&lt;/strong&gt; [&lt;a href=\&#34;#RFC1962\&#34;&gt;RFC1962&lt;/a&gt;] 生效的选项。 CCP 的作用就像 NCP （见 3.6.5 节），只不过在 LCP 链路建立交换阶段指明压缩选项时才开始处理配置压缩细节。&lt;/p&gt;\n&lt;p&gt;CCP 在行为上很像 NCP，仅在链路进入网络状态时协商。它使用与 LCP 相同的分组交换过程和格式（除协议字段被设置为 &lt;code&gt;0x80FD&lt;/code&gt; 之外），另外还有一些特殊选项，并对常见的&lt;strong&gt;代码&lt;/strong&gt;字段值（1 ~ 7）定义了 2个 新的操作：复位请求（&lt;code&gt;0x0e&lt;/code&gt;）和复位确认（&lt;code&gt;0x0f&lt;/code&gt;）。如果在一个压缩帧中检测到一个错误，复位请求可用于要求对方复位压缩状态（例如字典、状态变量、状态机等）。在复位后，对方响应一个复位确认。&lt;/p&gt;\n&lt;p&gt;一个或多个压缩帧可作为一个 PPP 帧的一部分（即包括 LCP 数据和可能的填充部分）。压缩帧携带的&lt;strong&gt;协议&lt;/strong&gt;字段值为 &lt;code&gt;0x00FD&lt;/code&gt;，但是如何指明存在多个压缩帧，这依赖于使用的特定压缩算法（见 3.6.6 节）。当 CCP 与 MP 结合使用时，既可用于一个捆绑，也可用于多条成员链路的某些组合。如果只用于成员链路，&lt;strong&gt;协议&lt;/strong&gt;字段设置为 &lt;code&gt;0x00FB&lt;/code&gt; （单个的链路压缩数据报）。&lt;/p&gt;\n&lt;p&gt;CCP 可使用十几个压缩算法之一 [&lt;a href=\&#34;#PPPn\&#34;&gt;PPPn&lt;/a&gt;] 。大多数算法是官方标准的 IETF 文档，虽然它们可能已在 RFC 中加以描述（例如， [&lt;a href=\&#34;#RFC1977\&#34;&gt;RFC1977&lt;/a&gt;] 描述了 BSD 压缩方案， [&lt;a href=\&#34;#RFC2118\&#34;&gt;RFC2118&lt;/a&gt;] 描述了 Microsoft &lt;strong&gt;点对点压缩协议&lt;/strong&gt;（MPPC））。如果使用压缩， PPP 帧在进一步处理之前需要重构，因此高层的 PPP 操作通常不关心压缩帧的细节。&lt;/p&gt;\n&lt;h3 id=\&#34;364-ppp-认证\&#34;&gt;3.6.4 PPP 认证&lt;/h3&gt;\n&lt;p&gt;在一条 PPP 链路处于网络状态之前，通常有必要使用某种&lt;strong&gt;认证&lt;/strong&gt;（身份验证）机制，以识别建立链路的对方身份。基本的 PPP 规范默认不提供认证，因此图 3-24 中的认证交换在这种情况下不会出现。但是，某种形式的认证在多数时候是需要的，一些经过多年演变的协议被用于应对这种情况。在本章中，我们仅从高层的角度展开讨论，并将细节留给关于安全的章节（第 18 章）。与不提供认证相比，最简单、安全性最低的认证方案是&lt;strong&gt;密码认证协议（PAP）&lt;/strong&gt;。这种协议非常简单，一方请求另一方发送一个密码。由于该密码在 PPP 链路上未加密传输，窃听者在线路上可轻易捕获密码并使用它。由于这个重大的漏洞，不建议使用 PAP 进行认证。 PAP 分组像 LCP 分组那样编码，协议字段值设置为 &lt;code&gt;0xC0230&lt;/code&gt;。&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;查询——握手认证协议（CHAP）&lt;/strong&gt; [&lt;a href=\&#34;#RFC1994\&#34;&gt;RFC1994&lt;/a&gt;] 提供了一种更安全的认证方法。在使用 CHAP 时，一个随机值从一方（称为认证方）发送到另一方。响应通过一种特殊的&lt;strong&gt;单向&lt;/strong&gt;（即不可逆）功能，将一个随机值和一个共享密钥（通常由密码生成）结合形成响应中的一个数字。在接收到这个响应之后，认证方能更可靠地验证对方密钥是否正确。这个协议在链路上不会以明文（未加密）形式发送密钥或密码，因此窃听者难以了解相关信息。由于每次使用不同的随机值，每个查询/响应的结果会改变，即使一个窃听者有可能捕捉到这个值，也无法通过重新使用（回放）来欺骗对方。&lt;/p&gt;\n&lt;p&gt;EAP [&lt;a href=\&#34;#RFC3748\&#34;&gt;RFC3748&lt;/a&gt;] 是一个可用于各种网络的认证框架。它支持很多（约 40 个）不同的认&lt;br&gt;\n证方法，从简单密码（例如 PAP 和 CHAP）到更可靠的认证类型（例如智能卡、生物识别）。EAP 定义了一种携带各种认证的消息格式，但需要额外的规范定义 EAP 消息如何在特定的链路上传输。&lt;/p&gt;\n&lt;p&gt;当 EAP 被用于 PPP 时，前面讨论过的基本认证方法不变。 EAP 不是在链路建立（LCP 建立）阶段协商一种认证方法，认证操作将被推迟到认证状态（网络状态的前一个状态）。这允许更多信息类型用于影响**远程访问服务器（RAS）**的访问控制决策。当某种标准的协议用于执行各种认证机制，网络访问服务器可能无须处理 EAP 消息内容，但可依靠其他基础设施的认证服务器（例如 RADIUS 服务器 [&lt;a href=\&#34;#RFC2865\&#34;&gt;RFC2865&lt;/a&gt;] ）确定访问控制决策。这是当前的企业网和 ISP 设计中的首选方案。&lt;/p&gt;\n&lt;h3 id=\&#34;365-网络控制协议\&#34;&gt;3.6.5 网络控制协议&lt;/h3&gt;\n&lt;p&gt;虽然多种 NCP 可用于一条 PPP 链路（甚至同时），但我们将关注支持 IPv4 和 IPv6 的 NCP。 对于 IPv4， NCP 被称为&lt;strong&gt;IP控制协议（IPCP）&lt;/strong&gt; [&lt;a href=\&#34;#RFC1332\&#34;&gt;RFC1332&lt;/a&gt;] 。对于 IPv6， NCP 被称为 IPV6CP [&lt;a href=\&#34;#RFC5072\&#34;&gt;RFC5072&lt;/a&gt;] 。在 LCP 完成链路建立和认证之后，该链路每端都进入网络状态，并使用一个或多个 NCP （例如典型的是一个 IPCP）进行网络层的相关协商。&lt;/p&gt;\n&lt;p&gt;IPCP （针对 IPv4 的标准 NCP）可用于在一条链路上建立 IPv4 连接，以及配置 &lt;strong&gt;Van Jacobson 头部压缩（VJ 压缩）&lt;/strong&gt; [&lt;a href=\&#34;#RFC1144\&#34;&gt;RFC1144&lt;/a&gt;] 。 IPCP 分组在 PPP 状态机进入网络状态之后交换。IPCP 分组使用与 LCP 相同的分组交换机制和分组格式，除非协议字段被设置为 &lt;code&gt;0x8021&lt;/code&gt;，并且代码字段被限制在范围 0 ~ 7。代码字段的值对应于消息类型：特定供应商（见 [&lt;a href=\&#34;#RFC2153\&#34;&gt;RFC2153&lt;/a&gt;] ）、配置请求、配置 ACK、配置 REJECT、终止请求、终止 ACK和代码 REJECT。 IPCP 可协商一系列选项，包括 IP 压缩协议（2）、 IPv4 地址（3）和移动 IPv4 （4） [&lt;a href=\&#34;#RFC2290\&#34;&gt;RFC2290&lt;/a&gt;]。其他选项可用于获得主要和次要的域名服务器（见第 11 章）。&lt;/p&gt;\n&lt;p&gt;IPV6CP 使用与 LCP 相同的分组交换机制和分组格式，但它有两种不同的选择：接口标识符和 IPv6 压缩协议。接口标识符选项用于传输一个 64 位的 IID 值（见第 2 章），它作为形成一个链路本地 IPv6 地址的基础。由于它仅在本地链路上使用，因此不需要具有全球唯一性。这通过在 IPv6 地址的高位使用标准链路本地前缀，在低位设置某种功能的接口标识符来实现。这里模拟了 IPv6 自动配置过程（见第 6 章）。&lt;/p&gt;\n&lt;h3 id=\&#34;366-头部压缩\&#34;&gt;3.6.6 头部压缩&lt;/h3&gt;\n&lt;p&gt;PPP 拨号线路的速率一直较慢（54000b/s 或更少），很多小的分组通常使用 TCP/IP （例如 TCP 确认，见第 15 章）。这些分组大部分包含 TCP 和 IP 头部，同一 TCP 连接上的分组之间变化不大。其他高层协议的行为相似。因此，压缩（或消除）高层协议头部是一种有用的方法，这样以来就可在相对较慢的点到点链路上传输更少字节。现代的压缩或消除头部方法一直在随着时间演变。我们将从前面提到的 VJ 压缩开始，按时间顺序讨论它们。&lt;/p&gt;\n&lt;p&gt;在 VJ 压缩中，部分高层（TCP 和 IP）头部被 1 字节的连接标识符代替。 [&lt;a href=\&#34;#RFC1144\&#34;&gt;RFC1144&lt;/a&gt;] 讨论了这种方法的起源，它最初来源于一种旧的、称为 CSLIP （压缩串行线路 IP）的点到点协议。一个典型 IPv4 头部的长度是 20 字节，一个没有选项的 TCP 头部的长度也是 20 字节。因此，一个常见的 TCP/IPv4 头部组合是 40 字节，并且很多字段在分组间没有变化。另外，很多字段在分组间只有很小或有限的变化。如果不变的值通过一条链路（或一段时间内）传输并被保存在一张表中，则在后续分组中可用一个小的索引代替该值。变化有限的值可以仅编码差异部分（即仅发送变化的部分）。因此，整个 40 字节头部通常可有效压缩到 3 或 4 字节。这样可显著提高在低速链路上的 TCP/IP 性能。&lt;/p&gt;\n&lt;p&gt;头部压缩的下一步演化简称为 IP 头部压缩 [&lt;a href=\&#34;#RFC2507\&#34;&gt;RFC2507&lt;/a&gt;] [&lt;a href=\&#34;#RFC3544\&#34;&gt;RFC3544&lt;/a&gt;] 。它提供了一种压缩多个分组头部的方式，使用 TCP 或 UDP 传输层协议，以及 IPv4 或 IPv6 网络层协议。这种技术是 VJ 压缩技术的一种逻辑上的扩展，可用于多种协议以及 PPP 链路之外的其他链路。 [&lt;a href=\&#34;#RFC2507\&#34;&gt;RFC2507&lt;/a&gt;] 指出了底层链路层的一些强大的差错检测机制的必要性，因为，如果压缩头部在运输过程中损坏，出错的分组可在离开链路层时被构造。我们需要认识到，当头部压缩用于链路上时，可能不会像 PPP 的 FCS 计算那样强大。&lt;/p&gt;\n&lt;p&gt;头部压缩的最新改进方案称为&lt;strong&gt;鲁棒性头部压缩（ROHC）&lt;/strong&gt; [&lt;a href=\&#34;#RFC5225\&#34;&gt;RFC5225&lt;/a&gt;]。它进一步改进了 IP 头部压缩以涵盖更多的传输协议，并允许同时处理多种头部压缩方式。前面提到的 IP 头部压缩可适用于不同类型的链路，包括 PPP。&lt;/p&gt;\n&lt;h3 id=\&#34;367-例子\&#34;&gt;3.6.7 例子&lt;/h3&gt;\n&lt;p&gt;我们查看一台 PPP 服务器的调试输出，它通过拨号的调制解调器与客户机交互。客户机是一台有 IPv6 功能的运行 Microsoft Windows Vista 的计算机，服务器是一台运行 Linux 的计算机。客户机配置为可在单一链路上协商多链路功能（属性|选项IPPP 设置），出于演示目的，服务器配置为使用 CCP 协商加密协议（见以下代码清单中的 MPPE）：&lt;/p&gt;\n&lt;p&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1652962371471.png\&#34; alt=\&#34;\&#34; loading=\&#34;lazy\&#34;&gt;&lt;br&gt;\n&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1652962559431.png\&#34; alt=\&#34;\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/p&gt;\n&lt;p&gt;这里，我们可看到一些涉及 PPP 的交换，它是从服务器的角度来看的。 PPP 服务器进程创建的（虚拟）网络接口为 ppp0，它在连接串行端口 ttyS0 的拨号调制解调器上等待连接请求（称为“输入连接”）。当有连接请求到达时，服务器依次发送 &lt;code&gt;0x0&lt;/code&gt; 的异步控制字符映射（asyncmap）、 EAP 认证、 PFC 和ACFC 请求。客户拒绝 EAP 认证，并建议使用 MS-CHAP-v2 （ConENak） [&lt;a href=\&#34;#RFC2759\&#34;&gt;RFC2759&lt;/a&gt;]。服务器再次尝试发送请求，并使用 MS-CHAP-v2，这请求被接受和确认（ConfAck）。接下来，“输入”请求包括 CBCP，一个与 MP 支持相关的 1614 字节的 MRRU，以及一个端点 ID。 服务器拒绝 CBCP 和多链路操作（ConfRej）请求。客户机发送不带 MRRU 的端点鉴别请求，并被接收和确认。下一步，服务器发送一个名为 dialer 的 CHAP 查询。在该查询的响应到达之前，两个标识消息到达，表明对方以字符串 MSRASV5.20 和 MSRAS-0-VISTA 来标识。最后， CHAP 响应到达并验证通过，表明许可访问。这时， PPP 转换为网络状态。&lt;/p&gt;\n&lt;p&gt;当进入网络状态时， CCP、 IPCP 和 IPV6CP NCP 被交换。 CCP 尝试协商&lt;strong&gt;微软点对点加密（MPPE）&lt;/strong&gt; [&lt;a href=\&#34;#RFC3078\&#34;&gt;RFC3078&lt;/a&gt;] 。MPPE 有些不同之处，因为它是一种加密协议，而不是一种压缩协议，它实际将分组扩大了 4 字节。但是，它提供了一个相对简单的方法，早在协商过程中就完成了加密。选项 &lt;code&gt;+H -M +S +L -D -C&lt;/code&gt; 表明 MPPE 是否采用无状态操作（H）、使用哪种加密密钥强度（安全， S；中等， M；低， L）、是否存在过时的 D 位，以及是否需要单独、专用的 MPPC 的压缩协议（C） [&lt;a href=\&#34;#RFC2118\&#34;&gt;RFC2118&lt;/a&gt;] 。最终，双方同意在有状态模式下使用强大的 128 位密钥（-H， +S）。注意，在这次协商过程中，客户机尝试发送一个 IPCP 请求，但服务器响应的是一个主动的 TermAck （一个 LCP 定义、 ICPC 采纳的消息）。它用于向对方指出服务器“需要重新谈判”         [&lt;a href=\&#34;#RFC1661\&#34;&gt;RFC1661&lt;/a&gt;]。&lt;/p&gt;\n&lt;p&gt;在 MPPE 协商成功之后，服务器请求使用 VJ 头部压缩，并提供它的 IPv4 地址和 IPv6 地址，分别为 &lt;code&gt;192.168.0.1&lt;/code&gt; 和 &lt;code&gt;fe80::0206:5bff:fedd:c5c3&lt;/code&gt;。这个 IPv6 地址是从服务器的以太网 MAC 地址 &lt;code&gt;00:06:5B:DD:C5:C3&lt;/code&gt; 而来。客户机最初使用 IPCP 建议的 IPv4 地址和域名服务器&lt;code&gt;0.0.0.0&lt;/code&gt;，但被拒绝。客户机请求使用 &lt;code&gt;fe80::0000:0000:dead:beef&lt;/code&gt; 作为 IPv6 地址，这个请求被接受和确认。最后，客户机确认服务器的 IPv4 和 IPv6 地址，并且表明自己已建立 IPv6 地址。接着，客户机再次请求 IPv4 和服务器地址 &lt;code&gt;0.0.0.0&lt;/code&gt; ，再次被拒绝。 &lt;code&gt;192.168.0.1&lt;/code&gt; 被接受和确认。&lt;/p&gt;\n&lt;p&gt;我们从这次交换中可看到， PPP 协商是既灵活又烦琐的。很多选项可以尝试、拒绝和重新协商。虽然在低延时链路上这可能不是一个大间题，但这种交换中的每个消息都需要花费几秒（或更长）到达目的地。如果在一条卫星链路上，则可能出现很大的超时。对用户来说，链路建立明显是一个太长的过程。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;37-环回\&#34;&gt;3.7 环回&lt;/h2&gt;\n&lt;p&gt;尽管可能看起来很奇怪，但在很多情况下，客户机可能希望使用 Internet 协议（例如 TCP/IP）与同一计算机上的服务器通信。为了实现这个目标，大多数实现支持一种工作在网络层的&lt;strong&gt;环回&lt;/strong&gt;（或称“回送”）能力——通常使用一个虚拟的环回网络接口来实现。它就像一个真正的网络接口，但实际上是一个由操作系统提供的专用软件，可通过 TCP/IP 与同一主机的其他部分通信。以 127 开始的 IPv4 地址就是为这个目的而保留， IPv6 地址 &lt;code&gt;::1&lt;/code&gt; （见第 2 章的 IPv4 和 IPv6 寻址约定）用于同样目的。传统上，类 UNIX 系统（包括 Linux）为环回接口分配的 IPv4 地址为 &lt;code&gt;127.0.0.1&lt;/code&gt; （IPv6 地址为 &lt;code&gt;::1&lt;/code&gt;），为它分配的名称为 &lt;code&gt;localhost&lt;/code&gt;。发送到环回接口的 IP 数据报不会出现在任何网络中。尽管我们可以想象传输层检测到另一端是一个环回地址，并跳过某些传输层逻辑和所有网络层逻辑，但大多数的实现在传输层和网络层对数据执行完整的处理流程，并仅在数据报离开网络层时将其回送给网络层协议栈。这种处理对于性能测试可能有用，例如在没有任何硬件开销的情况下，测量执行协议栈软件所需的时间。在 Linux 中，环回接口被称为 &lt;code&gt;Io&lt;/code&gt;。&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;lo Link encap:Local Loopback\n        inet  addr:127.0.0.1  Mask:255.0.0.0\n        inet6 addr:  ::1/128  Scope:Host\n        UP LOOPBACK RUNNING MTU:16436 Metric:1\n        RX packets:458511 errors:0 dropped:0 overruns:0 frame:0\n        TX packets:458511 errors:0 dropped:0 overruns:0 carrier:0\n        collisions:0  txqueuelen:0\n        RX bytes:266049199 (253.7 MiB)\n        TX bytes:266049199 (253.7 MiB)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;这里，我们看到本地环回接口的 IPv4 地址为 &lt;code&gt;127.0.0.1&lt;/code&gt;，子网掩码为 &lt;code&gt;255.0.0.0&lt;/code&gt;（对应于分级寻址中的 A 类网络号 127）。 IPv6 地址1有一个128位的前缀，它表示只有一个地址。这个接口支持 16KB 的 MTU （可配置为更大尺寸，最大可达 2GB）。从主机在两个月前初始化开始，巨大的流量（接近 50 万个分组）无差错地通过该接口。我们不希望在本地环回设备上看到错误，假设它实际上没有在任何网络上发送分组。&lt;/p&gt;\n&lt;p&gt;在 Windows 中，默认情况下没安装 Microsoft 环回适配器，尽管这样仍支持 IP 环回功能。这个适配器可用于测试各种网络配置，甚至在一个物理网络接口不可用的情况下。在 Windows XP 下安装该适配器，可选择“开始 | 控制面板 | 添加硬件 | 从列表中选择网络适配器 | 选择 Microsoft 作为制造商 | 选择 Microsoft 环回适配器” 。对于 Windows Vista 或 Windows 7，在命令提示符下运行程序 hdwwiz，并手动添加 Microsoft 环回适配器。在执行上述操作后， ipconfig 命令显示如下（这个例子来自 Windows Vista 环境）：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;C:\\&amp;gt; ipconfig /all\n...\nEthernet adapter Local Area Connection 2:\n   Connection-specific DNS Suffix  . . . . . . . :\n   Description . . . . . . . . . . . . . . . : Microsoft Loopback Adapter\n   Physical Address. . . . . . . . . . . . . : 02-00-4C-4F-4F-50\n   DHCP Enabled . . . . . . . . . . . : Yes\n   Autoconfiguration Enabled. . . . . . . . . . : Yes\n   Link-local IPv6 Address. . . . . . . . : fe80::9c0d:77a:52b8:39f0%18(Preferred)\n   Autoconfiguration IPv4 Address . . . . . . . . . . . . : 169.254.57.240(Preferred)\n   Subnet Mask  . . . . . . . . . . . . : 255.255.0.0\n   Default Gateway. . . . . . . . . . . . . : \n   DHCPv6 IAID . . . . . . . . . . . : 302121036\n   DNS Servers  . . . . . . . . . . . : fec0:0:0:ffff::1%1\n                                       fec0:0:0:ffff::2%1\n                                       fec0:0:0:ffff::3%1\n    NetBIOS over Tcpip  . . . . . . . : Enabled\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;这里，我们可看到该接口已被创建，分配了 IPv4 和 IPv6 地址，并显示为一系列的虚拟以太网设备。现在，这台计算机具有以下环回地址：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;C:\\&amp;gt; ping 127.1.2.3\nPinging 127.1.2.3 with 32 bytes of data:\nReply from 127.1.2.3: bytes=32 time&amp;lt;1ms TTL=128\nReply from 127.1.2.3: bytes=32 time&amp;lt;1ms TTL=128\nReply from 127.1.2.3: bytes=32 time&amp;lt;1ms TTL=128\nReply from 127.1.2.3: bytes=32 time&amp;lt;1ms TTL=128\n\nPing statistics for 127.1.2.3:\n    Packets: Sent = Received = Lost = 0 (0% loss)，\nApproximate round trip times in milli-seconds:\n    Mininum = 0ms，Maximum = 0ms，Average = 0ms\n\nC:\\&amp;gt; ping ::1\nPinging ::1 with 32 bytes of data:\nReply from ::1: bytes=32 time&amp;lt;1ms TTL=128\nReply from ::1: bytes=32 time&amp;lt;1ms TTL=128\nReply from ::1: bytes=32 time&amp;lt;1ms TTL=128\nReply from ::1: bytes=32 time&amp;lt;1ms TTL=128\n\nPing statistics for ::1:\n    Packets: Sent = Received = Lost = 0 (0% loss)，\nApproximate round trip times in milli-seconds:\n    Mininum = 0ms，Maximum = 0ms，Average = 0ms\n\nC:\\&amp;gt; ping 169.254.57.240\nPinging 169.254.57.240 with 32 bytes of data:\nReply from 169.254.57.240: bytes=32 time&amp;lt;1ms TTL=128\nReply from 169.254.57.240: bytes=32 time&amp;lt;1ms TTL=128\nReply from 169.254.57.240: bytes=32 time&amp;lt;1ms TTL=128\nReply from 169.254.57.240: bytes=32 time&amp;lt;1ms TTL=128\n\nPing statistics for 169.254.57.240:\n    Packets: Sent = Received = Lost = 0 (0% loss)，\nApproximate round trip times in milli-seconds:\n    Mininum = 0ms，Maximum = 0ms，Average = 0ms\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;我们可以看到， IPv4 中以 127 开始的目的地址被环回。但是，对于 IPv6，只有地址 &lt;code&gt;::1&lt;/code&gt; 被定义用于环回操作。我们还可以看到，地址为 &lt;code&gt;169.254.57.240&lt;/code&gt; 的环回适配器如何立即返回数据。我们将在第 9 章讨论组播或广播数据报是否被复制并返回给发送主机（通过环回接口）。每个应用程序都可做出这种选择。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;38-mtu-和路径-mtu\&#34;&gt;3.8 MTU 和路径 MTU&lt;/h2&gt;\n&lt;p&gt;我们可以从图 3-3 中看到，在很多链路层网络（例如以太网）中，携带高层协议 PDU 的帧大小是有限制的。以太网有效载荷的字节数通常被限制为 1500， PPP 通常采用相同大小以保持与以太网兼容。链路层的这种特征被称为&lt;strong&gt;最大传输单元（MTU）&lt;/strong&gt;。大多数的分组网络（例如以太网）都有固定的上限。大多数的流类型网络（串行链路）提供可设置的上限，它可被帧协议（例如 PPP）所使用。如果 IP 需要发送一个数据报，并且这个数据报比链路层 MTU大，则 IP 通过分片将数据报分解成较小的部分，使每个分片都小于 MTU。我们将在第 5 章和第 10 章讨论 IP 分片。&lt;/p&gt;\n&lt;p&gt;当同一网络中的两台主机之间通信时，本地链路的 MTU 在会话期间对数据报大小有直接影响。当两台主机之间跨越多个网络通信时，每条链路可能有不同大小的 MTU。在包含所有链路的整个网络路径上，最小的 MTU 称为&lt;strong&gt;路径 MTU&lt;/strong&gt;。&lt;/p&gt;\n&lt;p&gt;任何两台主机之间的路径 MTU 不会永远不变，这取决于当时使用的路径。如果网络中的路由器或链路故障， MTU 可能改变。另外，路径通常不对称（主机 A 到 B 路径可能不是 B 到 A 的反向路径），路径 MTU 不需要在两个方向上相同。&lt;/p&gt;\n&lt;p&gt;[&lt;a href=\&#34;#RFC1191\&#34;&gt;RFC1191&lt;/a&gt;] 规定了** IPv4 路径 MTU 发现（PMTUD）**机制， [&lt;a href=\&#34;#PMTUD\&#34;&gt;RFC1981&lt;/a&gt;] 描述了用于 IPv6 的相应机制。 [&lt;a href=\&#34;#RFC4821\&#34;&gt;RFC4821&lt;/a&gt;] 描述了一个补充方案，以解决这些机制中的一些问题。 PMTUD 用于确定某个时间的路径 MTU，它在 IPv6 实现中是需要的。在后面的章节中，针对前面描述的 ICMP 和 IP 分片，我们将观察这个机制如何运行。我们在讨论 TCP 和 UDP 时，也会讨论它对传输性能的影响。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;39-隧道基础\&#34;&gt;3.9 隧道基础&lt;/h2&gt;\n&lt;p&gt;在某些情况下，两台计算机通过 Internet 或其他网络建立一条虚拟链路是有用的。虚拟专用网络（VpN）提供这种服务。实现这类服务的最常用方法称为&lt;strong&gt;隧道&lt;/strong&gt;。一般来说，隧道是在高层（或同等层）分组中携带低层数据。例如，在一个 IPv4 或 IPv6 分组中携带 IPv4 数据，在一个 UDP、 IPv4 或 IPv6 分组中携带以太网数据。隧道转变了在头部中协议严格分层的思路，并允许形成&lt;strong&gt;覆盖网络&lt;/strong&gt;（即这些“链路”实际是其他协议实现的虚拟链路，而不是物理连接的网络）。这是一个非常强大和有用的技术。这里，我们讨论了一些隧道方案的基础。&lt;/p&gt;\n&lt;p&gt;为某个协议层的分组或另一层的分组建立隧道有多种方法。用于建立隧道的 3 个常见协议包括：&lt;strong&gt;通用路由封装（GRE）&lt;/strong&gt; [&lt;a href=\&#34;#RFC2784\&#34;&gt;RFC2784&lt;/a&gt;] 、&lt;strong&gt;Microsoft 专用的点对点隧道协议（PPTP）&lt;/strong&gt; [&lt;a href=\&#34;#RFC2637\&#34;&gt;RFC2637&lt;/a&gt;] 和 &lt;strong&gt;第 2 层隧道协议（L2TP）&lt;/strong&gt;  [&lt;a href=\&#34;#RFC3931\&#34;&gt;RFC3931&lt;/a&gt;] 。其他协议包括早期非标准的 IP-in-IP 隧道协议 [&lt;a href=\&#34;#RFC1853\&#34;&gt;RFC1853&lt;/a&gt;]。 GRE 和 IT2P 后来发展为标准，并分别代替了 IP-in-IP 和 PPTP （但这两种协议仍在使用）。我们将重点放在 GRE 和 PPTP，但更关注 PPTP，因为它是个人用户的常用协议，即使它并不是一个 IETF 标准。 L2TP 本身不提供安全保障，它常用于 IP 层安全（IPsec；见第 18 章）。由于 GRE 和 PPTP 有密切关系，我们现在看图 3-26 中的 GRE 头部，它们分别基于原来的标准和修订后的标准。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;26\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1652968099400.png\&#34; alt=\&#34;图 3-26\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 3-26   基本的 GRE 头部只有 4 字节，包括一个 16 位的校验和选项（很多 Internet 协议中的典型选项）。后来，这个头部被扩展为包括一个标识符（密钥字段），该标识符是同一流中的多个分组共有的，还包括一个序列号（用于顺序混乱的分组重新排序）&lt;/p&gt;\n&lt;p&gt;从图 3-26 中的头部可以看出，基本 GRE 规范 [&lt;a href=\&#34;#RFC2784\&#34;&gt;RFC2784&lt;/a&gt;] 是相当简单的，它只提供了对其他分组的最简化的封装。第一个位字段（C）指出是否存在&lt;strong&gt;校验和&lt;/strong&gt;。如果是，&lt;strong&gt;校验和&lt;/strong&gt;字段中包含相同类型的&lt;strong&gt;校验和&lt;/strong&gt;，它在很多 Internet 相关协议中可看到（见 5.2.2 节）。如果&lt;strong&gt;校验和&lt;/strong&gt;字段存在，&lt;strong&gt;保留 1 &lt;strong&gt;字段也存在，并被设置为 0。 [&lt;a href=\&#34;#RFC2890\&#34;&gt;RFC2890&lt;/a&gt;] 扩展了基本格式，包括可选的&lt;/strong&gt;密钥&lt;/strong&gt;和&lt;strong&gt;序列号&lt;/strong&gt;字段，如果有这两个字段的话，图 3-26 中的 K 和 S 位字段分别被设置为1。 密钥字段在多个分组中被分配了一个同样的值，表示它们是属于同一流中的分组。如果分组顺序被打乱（例如通过不同链路），可利用序列号字段对分组重新排序。&lt;/p&gt;\n&lt;p&gt;虽然 GRE 是 PPTP 的基础，并被 PPTP 使用，但这两个协议的目的不同。 GRE 隧道常用于网络基础设施内的流量传输，例如 ISP 之间或企业内部网与分支机构之间，虽然 GRE 隧道可与 IPsec 结合，但这个流量通常没必要加密。相反， PPTP 常用于用户和 ISP 或企业内部网之间，并需要加密（例如使用 MPPE）。 PPTP 本质上是 GRE 和 PPP 的结合，因此 GRE 可基于 PPP 提供虚拟的点到点链路。 GRE 使用 IPv4 或 IPv6 携带流量，因此它更像是一种第 3 层隧道技术。 PPTP 常用于携带第 2 层帧（例如以太网），因此需要模拟一条直接的局域网（链路层）连接。例如，它可用于对企业网络的远程访问。 PPTP 采用的是对标准 GRE 头部的改进方案（见图 3-27）。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;27\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1652968427453.png\&#34; alt=\&#34;图 3-27\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 3-27   PPTP 头部基于一个旧的、非标准的 GRE 头部。它包括一个序列号、一个累积的分组确认号和一些标识信息。多数字段在第一次使用时设置为 0&lt;/p&gt;\n&lt;p&gt;我们可看到图 3-27 与标准 GRE 头部的一些差异，包括额外的 R、 S 和 A 位字段，以及&lt;strong&gt;标志&lt;/strong&gt;字段和&lt;strong&gt;回溯（Recur）&lt;strong&gt;字段。它们中的多数设置为 0，并且没有使用（它们的分配是基于一个旧的、非标准的 GRE 版本）。 K、 S 和 A 位字段分别表示&lt;/strong&gt;密钥&lt;/strong&gt;、&lt;strong&gt;序列号&lt;/strong&gt;和&lt;strong&gt;确认号&lt;/strong&gt;字段是否存在。如果存在，&lt;strong&gt;序列号&lt;/strong&gt;字段保存对方可看到的最大分组数。&lt;/p&gt;\n&lt;p&gt;我们现在建立一个 PPTP 会话，稍后对 PPTP 的其他功能进行简单讨论。下面的例子类似于前面给出的 PPP 链路建立的例子，区别在于现在不常使用拨号连接， PPTP 为 PPP 提供了一条“原始”链路。第二个客户端使用 Windows Vista 系统，服务器使用 Linux 系统。当调试选项启用时，这个输出保存在/ &lt;code&gt;var/log/messages&lt;/code&gt; 文件中：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;pptpd: MGR: Manager process started\npptpd: MGR: Maximum of 100 connections available\npptpd: MGR: Launching /usr/sbin/pptpctrl to handle client\npptpd: CTRL: local address = 192.168.0.1\npptpd: CTRL: remote address = 192.168.1.1\npptpd: CTRL: pppd iptions file = /etc/ppp/options.pptpd\npptpd: CTRL: Client 71.141.227.30 control connection started\npptpd: CTRL: Received PPTP Control Message (type : 1)\npptpd: CTRL: Made a START CTRL CONN RPLY packet\npptpd: CTRL: I wrote 156 bytes to the client.\npptpd: CTRL: Sent packet to client\npptpd: CTRL: Received PPPTP Control Message (type : 7)\n\npptpd: CTRL: Set parameters to 100000000 maxbps， 64 window size\npptpd: CTRL: Made a OUT CALL RPLY packet\npptpd: CTRL: Starting call (launching ppd， opening GRE)\npptpd: CTRL: pty_fd = 6\npptpd: CTRL: tty_fd = 7\npptpd: CTRL (PPPD Launcher) : program binary = /usr/sbin/pppd \npptpd: CTRL (PPPD Launcher) : local address = 192.168.0.1\npptpd: CTRL (PPPD Launcher) : remote address = 192.168.1.1\npppd: pppd 2.4.4 started by root， uid 0\npppd: using channel 60\npptpd: CTRL: I wrote 32 but4es to the client.\npptpd: CTRL: Sent packet to client\npppd: Using interface ppp0\npppd: Connect: ppp0 &amp;lt;--&amp;gt; /dev/pts/1\npppd:sent [LCP ConfReq id=0x1 &amp;lt;asyncmap 0x0&amp;gt; &amp;lt;auth chap MS-v2&amp;gt;\n            &amp;lt;magic 0x4e2ca200&amp;gt; &amp;lt;pcomp&amp;gt; &amp;lt;accomp&amp;gt;]\npptpd: CTRL: Received PPTP Control Message (type : 15)\npptpd: CTRL: Got a SET LINK INFO packet with standard ACCMs\npptpd: GRE: accepting packet #0\npppd: rcvd [LCP ConfReq id=0x0 &amp;lt;mru 1400&amp;gt; &amp;lt;magic 0x5e565505&amp;gt;\n            &amp;lt;pcomp&amp;gt; &amp;lt;accomp&amp;gt;]]\npppd: sent [LCP ConfAck id=0x0 &amp;lt;mru 1400&amp;gt; &amp;lt;magic 0x5e565505&amp;gt;\n            &amp;lt;pcomp&amp;gt; &amp;lt;accomp&amp;gt;]]\npppd: sent [LCP ConfReq id=0x0 &amp;lt;asyncmap 0x0&amp;gt; &amp;lt;auth chap MS-v2&amp;gt; \n            &amp;lt;magic 0x4e2ca200&amp;gt; &amp;lt;pcomp&amp;gt; &amp;lt;accomp&amp;gt;]]\npptpd: GRE: accepting packet #1\npppd: rcvd [LCP ConfAck id=0x1 &amp;lt;asyncmap 0x0&amp;gt; &amp;lt;auth chap MS-v2&amp;gt;\n            &amp;lt;magic 0x4e2ca200&amp;gt; &amp;lt;pcomp&amp;gt; &amp;lt;accomp&amp;gt;]\npppd: sent [CHAP Challenge id=0x3 \n            &amp;lt;eb88bfff67dlc239ef73e98ca32646a5&amp;gt;， name = &amp;quot;dialer&amp;quot;]\npptpd: CTRL: Received PPTP Control Message (type = 15)\npptpd: CTRL: Ignored a SET LINK INFO packet with real ACCMs!\npptpd: GRE: accepting packet #2\npppd: rcvd [CHAP Response id=0x3 \n            &amp;lt;276f3678fofO3fa57f64b3c367529565000000\n            00000000000fa2b2aeoad8db9d986f8e222a0217a620638a24\n            3179160900&amp;gt;， name = &amp;quot;dialer&amp;quot;]\npppd: sent [CHAP Success id=0x3\n            &amp;quot;S=C551119E0E1AAB68E86DED09A32D0346D7002E05\n            M=Accessgranted&amp;quot;]\npppd: sent [CCP ConfReq id=0x1 &amp;lt;mppe +H -M +S +L -D -C&amp;gt;]\npptpd: GRE: accepting packet #3\npppd: rcvd [ IPV6CP ConfReq id=0x1 &amp;lt;addr fe80::1cfc:fddd:8e2c:e118&amp;gt;]\npppd: sent [ IPV6CP TermAck id=0x1 ]\npptpd:GRE: accepting packet #4\npppd: rcvd [CCP confReq id=0x2 &amp;lt;mppe +H -M -S -L -D -C&amp;gt;]\npppd: sent [CCP confNak id=0x2&amp;lt;mppe +H -M +S +L -D -C&amp;gt;]\npptpd: GRE: accepting packet #5\npptpd: GRE: accepting packet #6\npppd: rcvd [ IPCP ConfReq id=0x3 &amp;lt;addr 0.0.0.0&amp;gt;&amp;lt;ms-dns1 0.0.0.0&amp;gt;\n&amp;lt;ms-wins 0.0.0.0&amp;gt;&amp;lt;ms-dns3 0.0.0.0&amp;gt;&amp;lt;ms-wins 0.0.0.0&amp;gt;]\npptpd: GRE: accepting packet #7\npppd: sent [ IPCP TermAck id=0x3]\npppd: rcvd [CCP ConfNak id=0x1 &amp;lt;mppe +H -M+S -L -D -C&amp;gt;\npppd: sent [CCP ConfReq id=0x2 &amp;lt;mppe +H -M +S -L -D -C&amp;gt;\npppd: rcvd [CCP confReq id=0x4 &amp;lt;mppe +H -M +S -L -D -C&amp;gt;\npppd: sent [CCP ConfAck id=0x4 &amp;lt;mppe +H -M +S -L -D -C&amp;gt;\npptpd: GRE: accepting packet #8\npppd: rcvd [CCP ConfAck id=0x2 &amp;lt;mppe +H -M +S -L -D -C&amp;gt;\npppd: MPPE 128-bit stateless compression enabled\npppd: sent [ IPCP ConfReq id=0x1 &amp;lt;addr 192.168.0.1&amp;gt;]\npppd: sent [ IPV6CP ConfReq id=0x1 &amp;lt;addr fe80::0206:5bff:fedd:c5c3&amp;gt;]\npptpd: GRE: accepting packet #9\npppd: rcvd [ IPCP ConfAck id=0x1 &amp;lt;addr 192.168.0.1&amp;gt;]\npptpd: GRE: accepting packet #10\npppd: rcvd [ IPV6CP ConfAck id=0x1 &amp;lt;addr fe80::0206:5bff:fedd:c5c3&amp;gt;]\npptpd: GRE:accepting packet #11\npppd: rcvd [ IPCP ConfReq id=0x5 &amp;lt;addr 0.0.0.0&amp;gt;\n            &amp;lt;ms-dns1 0.0.0.0&amp;gt;&amp;lt;ms-wins 0.0.0.0&amp;gt;\n            &amp;lt;ms-dns3 0.0.0.0&amp;gt;&amp;lt;ms-wins 0.0.0.0&amp;gt;]\npppd: sent [ IPCP ConfRej id=0x5 &amp;lt;ms-wins 0.0.0.0&amp;gt;&amp;lt;ms-wins 0.0.0.0&amp;gt;]\npptpd: GRE: accepting packet #12\npppd: rcvd [ IPV6CP ConfReq id=0x6 &amp;lt;addr fe80::1cfc:fddd:8e2c:e118&amp;gt;]\npppd: sent [ IPV6CP ConfAck id=0x6 &amp;lt;addr fe80::1cfc:fddd:8e2c:e118&amp;gt;]\npppd: local LL address fe80::0206:5bff:fedd:c5c3\npppd: remote LL address fe80::1cfc:fddd:8e2c:e118\npptpd: GRE: accepting packet #13\npppd: rcvd [ IPCP ConfReq id=0x7 &amp;lt;addr 0.0.0.0&amp;gt;\n            &amp;lt;ms-dns1 0.0.0.0&amp;gt;&amp;lt;ms-dns3 0.0.0.0&amp;gt;]\npppd: sent [ IPCP ConfNak id=0x7 &amp;lt;addr 192.168.1.1&amp;gt;\n            &amp;lt;ms-dns1 192.168.0.1&amp;gt;&amp;lt;ms-dns3 192.168.0.1&amp;gt;]\npptpd: GRE: accepting packet #14\npppd: rcvd [ IPCP ConfReq id=0x8 &amp;lt;addr 192.168.1.1&amp;gt;\n            &amp;lt;ms-dns1 192.168.0.1&amp;gt;&amp;lt;ms-dns3 192.168.0.1&amp;gt;]\npppd: sent [ IPCP confAck id=0x8 &amp;lt;addr 192.168.1.1&amp;gt;\n            &amp;lt;ms-dns1 192.168.0.1&amp;gt;&amp;lt;ms-dns3 192.168.0.1&amp;gt;]\npppd: local IP address 192.168.0.1\npppd: remote IP address 192.168.1.1\npptpd: GRE:accepting packet #15\npptpd: CTRL: sending ECHO REQ id 1\npptpd: CTRL: Made a ECHO REQ packet\npptpd: CTRL: l wrote 16 bytes to the client.\npptpd: CTRL: sent packet to client\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;这个输出类似于前面看过的 PPP 的例子，区别在于一个 pppd 过程和一个 pptpd 过程。这些进程协同工作以建立到服务器的 PPTP 会话。整个建立过程开始于用 pptpd 接收 1 个类型为 1 的控制消息，表示客户机希望建立一个控制连接。 PPTP 使用分离的控制流和数据流，因此首先需要建立一个控制流。在响应这个请求之后，服务器接收到一个类型为 7 的控制消息（表示对方发送的呼叫请求）。最大速度（b/s）设置为一个很大的值 100000000，实际上意味着它是无限制的。&lt;strong&gt;窗口&lt;/strong&gt;设置为 64，这是在传输协议例如 TCP （见第 15 章）中经常看到的一个概念。这里，窗口用于流量控制。也就是说， PPTP 使用自己的序列号和确认号来确定多少帧成功到达目的地。如果成功交付的帧太少，发送者需要减小发送速率。为了确定帧确认的等待时间， PPTP 使用一种自适应的超时机制，根据链路的往返时间进行估算。当我们学习 TCP 时将看到这种计算过程。&lt;/p&gt;\n&lt;p&gt;在设置窗口后不久， pppd 应用开始运行和处理 PPP 数据，就像我们之前在拨号例子中看到的那样。两者之间唯一的区别在于： pptpd 在分组到达和离开时转发给 pppd 过程，以及 pptpd 处理的少量特殊 PPTP 消息（例如 set link info 和 echo request）。这个例子说明了 PPTP 协议如何实际运行，就像一个针对 PPP 分组的 GRE 隧道。由于现有 PPP 实现（这里是 pppd）可处理封装的 PPP 分组，因此它是很方便的。注意，虽然 GRE 本身通常封装在 IPv4 分组中，但类似功能也可使用 IPv6 隧道分组 [&lt;a href=\&#34;#RFC2473\&#34;&gt;RFC2473&lt;/a&gt;] 。&lt;/p&gt;\n&lt;h3 id=\&#34;391-单向链路\&#34;&gt;3.9.1 单向链路&lt;/h3&gt;\n&lt;p&gt;当链路仅在一个方向工作时出现一个有趣的问题。这种在一个方向工作的链路称为&lt;strong&gt;单向链路（UDL）&lt;/strong&gt;，由于它们需要交换信息（例如 PPP 配置消息），因此前面介绍的很多协议在这种情况下不能正常运行。为了解决这种问题提出了一种标准，可在辅助 Internet 接口上创建隧道，它可与 UDL 操作相结合 [&lt;a href=\&#34;#RFC3077\&#34;&gt;RFC3077&lt;/a&gt;] 。典型情况是由卫星提供下行流量（流向用户）而形成一条 Intenet 连接，或者是调制解调器提供上行流量而形成一条拨号链路。这在卫星连接的用户主要是下载而不是上传的情况下是有用的，并且通常用于早期的卫星 Internet 连接。它使用 GRE 将链路层的上行流量封装在 IP 分组中。&lt;/p&gt;\n&lt;p&gt;为了在接收方自动建立和维护隧道， [&lt;a href=\&#34;#RFC3077\&#34;&gt;RFC3077&lt;/a&gt;] 规定了一种&lt;strong&gt;动态隧道配置协议（DTCP）&lt;/strong&gt;。DTCP 涉及在下行链路中发送组播 &lt;strong&gt;Hello 消息&lt;/strong&gt;，因此任何有兴趣的接收方都可知道已有 UDL 及其 MAC 和 IP 地址。另外， Hello 消息表示网络中一个隧道端点的接口，它可通过用户端的辅助接口到达。在用户选择隧道端点之后， DTCP 在 GRE 隧道中将同一 MAC 作为 UDL 封装返回流量。服务提供商接收由 GRE 封装的这些第 2 层帧（通常是以太网），将它们从隧道中提取并适当转发。因此，上游（提供商） UDL 需要手工配置隧道，下游（很多用户）自动配置隧道。注意，这种 UDL 处理方法实际上是为上层协议不对称地“隐藏”链路。因此，这条链路“两个”方向上的性能（延迟、带宽）可能非常不对称，并可能对高层协议产生不利影响 [&lt;a href=\&#34;#RFC3449\&#34;&gt;RFC3449&lt;/a&gt;] 。&lt;/p&gt;\n&lt;p&gt;这个例子说明，隧道的一个重要问题是配置的工作量，这个工作从前一直由手工完成。在通常情况下，隧道配置涉及选择一个隧道端点，以及用对方的 IP 地址配置位于隧道端点的设备，也许还需要选择协议和提供认证信息。一些相关技术已经出现，以协助自动配置或使用隧道。一种从 IPv4 向 IPv6 的过渡方法称为6to4 [&lt;a href=\&#34;#RFC3056\&#34;&gt;RFC3056&lt;/a&gt;] 。在 6to4 中， IPv6 分组在一个 IPv4 网络中通过隧道传输， [&lt;a href=\&#34;#RFC3056\&#34;&gt;RFC3056&lt;/a&gt;] 中规定它采用的封装方式。当相应主机经过了网络地址转换（见第 7 章），采用这种方法就会出现一个问题。这在当前是常见的，特别是对于家庭用户。自动配置隧道的 IPv6 过渡处理方法规定在 Teredo 技术方案中 [&lt;a href=\&#34;#RFC4380\&#34;&gt;RFC4380&lt;/a&gt;] 。 Teredo 在 UDP/IPv4 分组上形成 IPv6 分组的隧道。理解这种方法需要一些 IPv4、 IPv6 和 UDP 的背景知识，我们将在第 10 章详细讨论这种隧道自动配置选项。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;310-与链路层相关的攻击\&#34;&gt;3.10 与链路层相关的攻击&lt;/h2&gt;\n&lt;p&gt;对 TCP/IP 以下的层进行攻击以影响 TCP/IP 网络运行一直是常见的做法，这是由于大部分链路层信息不被高层共享，因而难以检测。不过，现在大家已知道很多这种攻击，我们在这里提到其中一些，以更好地理解链路层问题如何影响高层运行。&lt;/p&gt;\n&lt;p&gt;在传统的有线以太网中，接口可被设置为&lt;strong&gt;混杂模式&lt;/strong&gt;，这允许它接收目的地不是自己的流量。在早期的以太网中，当介质是名副其实的共享电缆时，该功能允许任何一台连接以太网电缆的计算机“嗅探”别人的帧并检查其内容。当时很多高层协议包含密码等敏感信息，仅通过查看一个分组并解码就能轻易获得密码。两个因素对这种方法的影响很大：交换机部署和高层协议加密部署。在使用交换机后，只有连接到交换机端口的站提供流量，流量的目的地也是其他站（或其他桥接的站），以及广播/组播流量。这种流量很少包含敏感信息（例如密码），可在很大程度上阻止攻击。但是，在更高层使用加密更有效，这在当前是常见的。在这种情况下，嗅探分组难以获得多少好处，因为基本无法直接获取内容。&lt;/p&gt;\n&lt;p&gt;另一种攻击的目标是交换机。交换机中有一个基于每个端口的站列表。如果这种表能被快速填充（例如被大量伪装的站快速填充），交换机可能被迫放弃合法条目，从而导致中断对合法站的服务。一个相关但可能更严重的攻击是使用 STP。在这种情况下，一个站可伪装成一个到根网桥拥有低成本路径的站，从而吸引流量直接导向它。&lt;/p&gt;\n&lt;p&gt;随着 Wi-Fi 网络的使用，有线以太网中存在的一些窃听和伪装问题变得更严重，这是由于任何站都可进入监控模式并嗅探分组（802.11 接口置于监控模式通常比以太网接口置于混杂模式更有挑战性，这样做依赖于一个适当的设备）。一些早期“攻击” （可能不是真的被攻击，依据相关的法律框架）涉及扫描中的简单漫游，寻找提供 Internet 连接的接入点（即&lt;strong&gt;驾驶攻击&lt;/strong&gt;）。虽然很多接入点使用加密来限制授权用户的访问，但有些人却能打开或使用&lt;strong&gt;捕获门户&lt;/strong&gt;技术访问注册网页，然后进行基于 MAC 地址的过滤访问。通过观察站注册以及冒充合法注册用户来“劫持”连接，捕获门户系统已被破坏。&lt;/p&gt;\n&lt;p&gt;一种更先进的 Wi-Fi 攻击涉及对加密保护的攻击，尤其是很多早期接入点使用的 WEP 加密。针对 WEP [&lt;a href=\&#34;#BHL06\&#34;&gt;BHL06&lt;/a&gt;] 的攻击有显著的破坏性，它促使 IEEE 修订了自已的标准。新的WPA2 （和 WPA）加密体系明显更强，因此不再推荐使用 WEP。&lt;/p&gt;\n&lt;p&gt;如果攻击者可访问两个端点之间的信道，它可采用很多方式来攻击 PPP 链路。对于很简单的认证机制（例如 PAP），嗅探可用于捕获密码，以便后续的非法访问。通过 PPP 链路（例如路由流量）上的更高层流量，可导致系统的不可用。&lt;/p&gt;\n&lt;p&gt;从攻击的角度看，隧道经常是目标，有时也成为攻击工具。作为目标，隧道穿过一个网络（通常是 Internet），它是被截获和分析的目标。隧道端点配置也可被攻击，尝试由端点建立更多隧道（一个 DoS 攻击）或攻击配置自身。如果该配置被攻破，可能打开一个未授权的隧道端点。在这点上，隧道变成工具而不再是目标，有些协议（例如 L2TP）提供一种与协议无关的简便方法，以在链路层访问私有的内部网络。在一种 GRE 相关的攻击中，例如将流量简单地插入一个非加密隧道，它到达隧道端点并被注入“私有”网络，虽然它本来只应被送往端点本地。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;311-总结\&#34;&gt;3.11 总结&lt;/h2&gt;\n&lt;p&gt;在本章中，我们探讨 Internet 协议族的低层，也就是我们关注的链路层。我们首先介绍以太网的演变，速度从 10Mb/s 增加到 10Gb/s 及以上，功能上的变化包括 VLAN、优先级、链路聚合和帧格式等方面。我们介绍了交换机如何通过网桥改善性能，这主要通过在多个独立站的集合之间提供直连电路来实现，以及由全双工操作取代早期半双工操作。我们还介绍了 IEEE 802.11 无线局域网 Wi-Fi 标准的一些细节，并说明它与以太网的相似点和区别。它已成为最流行的 IEEE 标准之一，并通过两个主要频段 2.4GHz 和 5GHz 提供无须许可的网络访问。我们还介绍了 Wi-Fi 安全方法的演变，从较弱的 WEP 到更强的 WPA 和 WPA2 框架。在 IEEE 标准的基础上，我们讨论了点到点链路和 PPP 协议。 PPP 实际上可封装任何类型的分组，可用于 TCP/IP 和非 TCP/IP 网络，采用一种类似 HDLC 的帧格式，并且可用于从低速拨号调制解调器到高速光纤线路。它本身是一整套协议，涉及压缩、加密、认证和链路聚合。它只支持两个参与者之间通信，无法处理对共享介质的访问控制，例如以太网或 Wi-Fi 的 MAC 协议。&lt;/p&gt;\n&lt;p&gt;大多数实现提供了环回接口。通过特殊的环回地址，通常为 &lt;code&gt;127.0.0.1&lt;/code&gt; （IPv6 为 &lt;code&gt;::1&lt;/code&gt;），或将 IP 数据报发送到主机自己的 IP 地址，都可访问该接口。环回数据可被传输层处理，并在网络层被 IP 处理。我们描述了链路层的一个重要特点，即 MTU 和路径 MTU 的相关概念。&lt;/p&gt;\n&lt;p&gt;我们也讨论了隧道的使用，涉及在更高层（或同等层）分组中携带低层协议。这种技术可形成覆盖网络，在 Internet 中将隧道作为网络基础设施的其他层中的链路。这项技术已变得非常流行，包括新功能的实验（例如在一个 IPv4 网络上运行的一个 IPv6 覆盖网络）和实际使用（例如 VPN）。&lt;/p&gt;\n&lt;p&gt;最后简要讨论了链路层涉及的各种攻击类型，它们既是目标又是工具。很多攻击涉及流量截取与分析（例如查找密码），但很多复杂攻击涉及伪造端点和修改传输中的流量。其他攻击涉及修改控制信息，例如隧道端点或 STP 信息，以将流量导向其他意想不到的位置。链路层访问也提供了一种执行 DoS 攻击的通用方式。这方面最著名的攻击是干扰通信信号，这种攻击几乎从无线电问世以来就有了。&lt;/p&gt;\n&lt;p&gt;本章仅涵盖了当前 TCP/IP 使用的一些常见链路技术。 TCP/IP 成功的原因之一在于它能工作在几乎任何一种链路技术之上。从本质上来说， IP 只要求发送方和接收方之间存在某条路径，它们可能经过一些级联的中间链路。这是一个相对适中的要求，很多研究的目标甚至延伸得更远，发送方和接收方之间可能永远没有一条端到端路径 [&lt;a href=\&#34;#RFC4838\&#34;&gt;RFC4838&lt;/a&gt;]。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;312-参考文献\&#34;&gt;3.12 参考文献&lt;/h2&gt;\n&lt;p&gt;&lt;span id=\&#34;802.11-2007\&#34;&gt;[802.11-2007]&lt;/span&gt;&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks, Part 11: Wireless LAN Medium Access Control (MAC) and Physical Layer (PHY) Specifications,&amp;quot; June 2007.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;802.11n-2009\&#34;&gt;[802.11n-2009]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks, Part 11: Wireless LAN Medium Access Control (MAC) and Physical Layer (PHY) Specifications Amendment 5: Enhancements for Higher Throughput,&amp;quot; Oct. 2009.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;802.11y-2008\&#34;&gt;[802.11y-2008]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks, Part 11: Wireless LAN Medium Access Control (MAC) and Physical Layer (PHY) Specifications Amendment 3: 3650-3700 MHz Operation in USA,&amp;quot; Nov. 2009.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;802.16-2009\&#34;&gt;[802.16-2009]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks, Part 16: Air Interface for Fixed Broadband Wireless Access Systems,&amp;quot; May 2009.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;802.16h-2010\&#34;&gt;[802.16h-2010]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks, Part 16: Air Interface for Fixed Broadband Wireless Access Systems Amendment 2: Improved Coexistence Mechanisms for License-Exempt Operation,&amp;quot; July 2010.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;802.16j-2009\&#34;&gt;[802.16j-2009]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks, Part 16: Air Interface for Fixed Broadband Wireless Access Systems Amendment 1: Multihop Relay Specification,&amp;quot; June 2009.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;802.16k-2007\&#34;&gt;[802.16k-2007]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks, Part 16:Air Interface for Fixed Broadband Wireless Access Systems Amendment 5: Bridging of IEEE 802.16,&amp;quot;Aug. 2010.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;802.1AK-2007\&#34;&gt;[802.1AK-2007]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks, Virtual Bridged Local Area Networks Amendment 7: Multiple RegistrationProtocol,&amp;quot; June 2007.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;802.1AE-2006\&#34;&gt;[802.1AE-2006]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks Media Access Control (MAC) Security,&amp;quot; Aug. 2006.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;802.1ak-2007\&#34;&gt;[802.1ak-2007]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks--—Virtual Bridged Local Area Networks--Amendment 7: Multiple Registration Protocol,&amp;quot; June 2007.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;802.1AX-2008\&#34;&gt;[802.1AX-2008]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks—Link Aggregation,&amp;quot; Nov. 2008.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;802.1D-2004\&#34;&gt;[802.1D-2004]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks Media Access Control (MAC) Bridges,&amp;quot; June 2004.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;802.1Q-2005\&#34;&gt;[802.1Q-2005]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks Virtual Bridged Local Area Networks,&amp;quot; May 2006.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;802.1X-2010\&#34;&gt;[802.1X-2010]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks Port-Based Network Access Control,&amp;quot;Feb. 2010.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;802.2-1998\&#34;&gt;[802.2-1998]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks Logical Link Control&amp;quot;(also ISO/IEC 8802-2:1998), May 1998.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;802.21-2008\&#34;&gt;[802.21-2008]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks, Part 21: Media Independent Handover Services&amp;quot; Jan. 2009.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;802.3-2008\&#34;&gt;[802.3-2008]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks, Part 3:Carrier Sense Multiple Access with Collision Detection (CSMA/CD) Access Method and Physical Layer Specifications,&amp;quot;Dec. 2008.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;802.3at-2009\&#34;&gt;[802.3at-2009]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks—Specific Requirements, Part 3: Carrier Sense Multiple Access with Collision Detection (CSMA/CD) Access Method and Physical Layer Specifications Amendment 3: Date Terminal Equipment (DTE) Power via the Media Dependent Interface (MDI) Enhancements,&amp;quot; Oct. 2009.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;802.3ba-2010\&#34;&gt;[802.3ba-2010]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks, Part 3: Carrier Sense Multiple Access with Collision Detection (CSMA/CD) Access Method and Physical Layer Specifications, Amendment 4: Media Access Control Parameters, Physical Layers, and Management Parameters for 40Gb/s and 100Gb/s Operation,&amp;quot; June 2010.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;802.11n-2009\&#34;&gt;[802.11n-2009]&lt;/span&gt; &amp;quot;IEEE Standard for Local and Metropolitan Area Networks, Part 11: Wireless LAN Medium Access Control (MAC) and Physical Layer (PHY) Specifications,Amendment 5: Enhancements for Higher Throughput,&amp;quot; Oct. 2009.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;AESO1\&#34;&gt;[AESO1]&lt;/span&gt; U.S. National Institute of Standards and Technology, FIPS PUB 197, &amp;quot;Advanced Encryption Standard,&amp;quot; Nov.2001.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;BHLO6\&#34;&gt;[BHLO6]&lt;/span&gt; A.Bittau, M.Handley, and J.Lackey, &amp;quot;The Final Nail in WEP&#39;s Coffin, &amp;quot; Proc. IEEE Symposium on Security and Privacy, May 2006.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;BOND\&#34;&gt;[BOND]&lt;/span&gt; http://bonding.sourceforge.net&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;ETHERTYPES\&#34;&gt;[ETHERTYPES]&lt;/span&gt; http://www.iana.org/assignments/ethernet-numbers&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;ETX\&#34;&gt;[ETX]&lt;/span&gt; D. De Couto, D.Aguayo, J. Bicket, and R. Morris,&amp;quot;A High-Throughput Path Metric for Multi-Hop Wireless Routing,&amp;quot; Proc. Mobicom, Sep. 2003.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;G704\&#34;&gt;[G704]&lt;/span&gt; ITU, &amp;quot;General Aspects of Digital Transmission Systems: Synchronous Frame Structures Used at 1544, 6312, 2048k, 8488, and 44736 kbit/s Hierarchical Levels,&amp;quot; ITU-T Recommendation G.704, July 1995.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;IANA-CHARSET\&#34;&gt;[IANA-CHARSET]&lt;/span&gt; &amp;quot;Character Sets,&amp;quot; http://www.iana.org/assignments/character-sets&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;ISO3309\&#34;&gt;[ISO3309]&lt;/span&gt; International Organization for Standardization, &amp;quot;Information Processing Systems--Data Communication High-Level Data Link Control Procedure--Frame Structure,&amp;quot; IS 3309,1984.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;ISO4335\&#34;&gt;[ISO4335]&lt;/span&gt; International Organization for Standardization, &amp;quot;Information Processing Systems-Data Communication High-Level Data Link Control Procedure—Elements of Procedure,&amp;quot; IS 4335,1987.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;JF\&#34;&gt;[JF]&lt;/span&gt; M.Mathis,&amp;quot;Raising the Internet MTU,&amp;quot; http://www.psc.edu/~mathis/MTU&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;MWLD\&#34;&gt;[MWLD]&lt;/span&gt; &amp;quot;Long Distance Links with MadWiFi,&amp;quot; http://madwifi-project.org/wiki/UserDocs/LongDistance&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;PPPn\&#34;&gt;[PPPn]&lt;/span&gt; http://www.iana.org/assignments/ppp-numbers&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC0894\&#34;&gt;[RFC0894]&lt;/span&gt; C.Hornig, &amp;quot;A Standard for the Transmission of IP Datagrams over Ethernet Networks,&amp;quot; Internet RFC 0894/STD 0041, Apr. 1984.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC1042\&#34;&gt;[RFC1042]&lt;/span&gt; J. Postel and J. Reynolds,&amp;quot;Standard for the Transmission of IP Datagrams over IEEE 802 Networks,&amp;quot; Internet RFC 1042/STD 0043, Feb. 1988.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC1144\&#34;&gt;[RFC1144]&lt;/span&gt; V.Jacobson, &amp;quot;Compressing TCP/IP Headers for Low-Speed Serial Links&amp;quot; Internet RFC 1144, Feb. 1990.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC1191\&#34;&gt;[RFC1191]&lt;/span&gt; J. Mogul and S. Deering,&amp;quot;Path MTU Discovery,&amp;quot; Internet RFC 1191, Nov. 1990.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC1332\&#34;&gt;[RFC1332]&lt;/span&gt; G. McGregor, &amp;quot;The PPP Internet Protocol Control Protocol,&amp;quot; Internet RFC 1332, May 1992.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC1570\&#34;&gt;[RFC1570]&lt;/span&gt; W.Simpson, ed., &amp;quot;PPP LCP Extensions,&amp;quot; Internet RFC 1570, Jan. 1994.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC1661\&#34;&gt;[RFC1661]&lt;/span&gt; W. Simpson, &amp;quot;The Point-to-Point Protocol (PPP),&amp;quot; Internet RFC 1661/STD 0051, July 1994.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC1662\&#34;&gt;[RFC1662]&lt;/span&gt; W. Simpson, ed.,&amp;quot;PPP in HDLC-like Framing,&amp;quot; Internet RFC 1662/STD 0051, July 1994.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC1663\&#34;&gt;[RFC1663]&lt;/span&gt; D. Rand,&amp;quot;PPP Reliable Transmission,&amp;quot; Internet RFC 1663, July 1994.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC1853\&#34;&gt;[RFC1853]&lt;/span&gt; W. Simpson, &amp;quot;IP in IP Tunneling,&amp;quot; Internet RFC 1853 (informational), Oct. 1995.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC1962\&#34;&gt;[RFC1962]&lt;/span&gt; D. Rand, &amp;quot;The PPP Compression Protocol (CCP),&amp;quot; Internet RFC 1962, June 1996.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC1977\&#34;&gt;[RFC1977]&lt;/span&gt; V.Schryver, &amp;quot;PPP BSD Compression Protocol,&amp;quot; Internet RFC 1977 (informational), Aug. 1996.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC1981\&#34;&gt;[RFC1981]&lt;/span&gt; J. McCann and S. Deering ,&amp;quot;Path MTU Discovery for IP Version 6,&amp;quot; Internet RFC 1981,Aug. 1996.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC1989\&#34;&gt;[RFC1989]&lt;/span&gt; w. Simpson, &amp;quot;PPP Link Quality Monitoring,&amp;quot; Internet RFC 1989, Aug.1996.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC1990\&#34;&gt;[RFC1990]&lt;/span&gt; K. Sklower, B. Lloyd, G. McGregor, D. Carr, and T. Coradetti, &amp;quot;The PPP Multilink Protocol (MP)&amp;quot; Internet RFC 1990, Aug. 1996.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC1994\&#34;&gt;[RFC1994]&lt;/span&gt; W. Simpson, &amp;quot;PPP Challenge Handshake Authentication Protocol (CHAP),&amp;quot; Internet RFC 1994, Aug. 1996.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC2118\&#34;&gt;[RFC2118]&lt;/span&gt; G.Pall, &amp;quot;Microsoft Point-to-Point (MPPC) Protocol,&amp;quot; Internet RFC 2118 (informational), Mar. 1997.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC2125\&#34;&gt;[RFC2125]&lt;/span&gt; C.Richards and K. Smith, &amp;quot;The PPP Bandwidth Allocation Protocol (BAP)/The PPP Bandwidth Allocation Control Protocol (BACP),&amp;quot; Internet RFC 2125, Mar. 1997.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC2153\&#34;&gt;[RFC2153]&lt;/span&gt; W. Simpson,&amp;quot;PPP Vendor Extensions,&amp;quot; Internet RFC 2153(informational), May 1997.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC2290\&#34;&gt;[RFC2290]&lt;/span&gt; J. Solomon and S.Glass,&amp;quot;Mobile-IPv4 Configuration Option for PPP IPCP,&amp;quot; Internet RFC 2290, Feb. 1998.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC2464\&#34;&gt;[RFC2464]&lt;/span&gt; M.Crawford, &amp;quot;Transmission of IPv6 Packets over Ethernet Networks,&amp;quot; Internet RFC 2464, Dec. 1988.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC2473\&#34;&gt;[RFC2473]&lt;/span&gt; A.Conta and S. Deering ,&amp;quot;Generic Packet Tuneling in IPv6 Specification,&amp;quot; Internet RFC 2473, Dec. 1998.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC2484\&#34;&gt;[RFC2484]&lt;/span&gt; G.Zorn, &amp;quot;PPP LCP Internationalization Configuration Option,&amp;quot; Internet RFC 2484, Jan. 1999.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC2507\&#34;&gt;[RFC2507]&lt;/span&gt; M. Degermark, B. Nordgren, and S. Pink, &amp;quot;IP Header Compression,&amp;quot; Internet RFC 2507, Feb. 1999.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC2615\&#34;&gt;[RFC2615]&lt;/span&gt; A. Malis and W. Simpson, &amp;quot;PPP over SONET/SDH,&amp;quot; Internet RFC 2615, June 1999.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC2637\&#34;&gt;[RFC2637]&lt;/span&gt; K.Hamzeh, G. Pall, W. Verthein, J. Taarud, W. Little, and G.Zorn, &amp;quot;Point-to-Point Tunneling Protocol (PPTP),&amp;quot; Internet RFC 2637 (informational), July 1999.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC2759\&#34;&gt;[RFC2759]&lt;/span&gt; G.Zorn, &amp;quot;Microsoft PPP CHAP Extensions, Version 2,&amp;quot; Internet RFC 2759 (informational), Jan. 2000.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC2784\&#34;&gt;[RFC2784]&lt;/span&gt; D. Farinacci, T. Li, S. Hanks, D. Meyer, and P. Traina, &amp;quot;Generic Routing Encapsulation (GRE),&amp;quot;Internet RFC 2784, Mar. 2000.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC2865\&#34;&gt;[RFC2865]&lt;/span&gt; C.Rigney, S. Willens, A. Rubens, and W. Simpson, &amp;quot;Remote Authentication Dial In User Service (RADIUS),&amp;quot; Internet RFC 2865, June 2000.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC2890\&#34;&gt;[RFC2890]&lt;/span&gt; G. Dommety,&amp;quot;Key and Sequence Number Extensions to GRE,&amp;quot; Internet RFC 2890, Sept. 2000.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC3056\&#34;&gt;[RFC3056]&lt;/span&gt; B.Carpenter and K. Moore,&amp;quot;Connection of IPv6 Domains via IPv4 Clouds,&amp;quot; Internet RFC 3056, Feb. 2001.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC3077\&#34;&gt;[RFC3077]&lt;/span&gt; E. Duros, W. Dabbous, H.Izumiyama, N. Fujii, and Y.Zhang,&amp;quot;A Link-Layer Tunneling Mechanism for Unidirectional Links,&amp;quot; Internet RFC 3077, Mar. 2001.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC3078\&#34;&gt;[RFC3078]&lt;/span&gt; G.Pall and G.Zorn, &amp;quot;Microsoft Point-to-Point Encryption (MPPE) Protocol,&amp;quot; Internet RFC 3078 (informational), Mar. 2001.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC3153\&#34;&gt;[RFC3153]&lt;/span&gt; R.Pazhyannur, I. Ali, and C. Fox, &amp;quot;PPP Multiplexing,&amp;quot; Internet RFC 3153, Aug. 2001.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC3366\&#34;&gt;[RFC3366]&lt;/span&gt; G.Fairhurst and L. Wood,&amp;quot;Advice to Link Designers on Link Automatic Repeat reQuest (ARQ),&amp;quot;Internet RFC 3366/BCP 0062,Aug.2002.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC3449\&#34;&gt;[RFC3449]&lt;/span&gt; H. Balakrishnan, V.Padmanabhan, G. Fairhurst, and M. Sooriyabandara, &amp;quot;TCP Performance Implications of Network Path Asymmetry,&amp;quot; Internet RFC 3449/BCP 0069, Dec. 2002.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC3544\&#34;&gt;[RFC3544]&lt;/span&gt; T.Koren, S.Casner, and C. Bormann, &amp;quot;IP Header Compression over PPP&amp;quot; Internet RFC 3544, July 2003.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC3561\&#34;&gt;[RFC3561]&lt;/span&gt; C.Perkins,E. Belding-Royer, and S. Das,&amp;quot;Ad Hoc On-Demand Distance Vector (AODV) Routing,&amp;quot; Internet RFC 3561 (experimental), July 2003.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC3610\&#34;&gt;[RFC3610]&lt;/span&gt; D. Whiting,R.Housley, and N.Ferguson, &amp;quot;Counter with CBC-MAC (CCM),&amp;quot; Internet RFC 3610(informational), Sept. 2003.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC3626\&#34;&gt;[RFC3626]&lt;/span&gt; T. Clausen and P. Jacquet, eds.,&amp;quot;Optimized Link State Routing Protocol (OLSR),&amp;quot; Internet RFC 3626 (experimental), Oct. 2003.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC3748\&#34;&gt;[RFC3748]&lt;/span&gt; B. Aboba et al., &amp;quot;Extensible Authentication Protocol (EAP),&amp;quot; Internet RFC 3748, June 2004.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC3931\&#34;&gt;[RFC3931]&lt;/span&gt; J. Lau, M. Townsley, and L. Goyret, eds,&amp;quot;Layer Two Tunneling Protocol--Version 3 (L2TPv3),&amp;quot; Internet RFC 3931, Mar. 2005.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC4017\&#34;&gt;[RFC4017]&lt;/span&gt; D.Stanley, J. Walker, and B. Aboba,&amp;quot;Extensible Authentication Protocol (EAP) Method Requirements for Wireless LANs,&amp;quot; Internet RFC 4017 (informational), Mar. 2005.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC4380\&#34;&gt;[RFC4380]&lt;/span&gt;C. Huitema,&amp;quot;Teredo: Tunneling IPv6 over UDP through Network Address Translations (NATs),&amp;quot; Internet RFC 4380,Feb. 2006.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC4647\&#34;&gt;[RFC4647]&lt;/span&gt; A. Phillips and M. Davis, &amp;quot;Matching of Language Tags,&amp;quot; Internet RFC 4647/BCP 0047, Sept. 2006.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC4821\&#34;&gt;[RFC4821]&lt;/span&gt; M.Mathis and J. Heffner, &amp;quot;Packetization Layer Path MTU Discovery,&amp;quot; Internet RFC 4821, Mar. 2007.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC4838\&#34;&gt;[RFC4838]&lt;/span&gt; V.Cerf et al.,&amp;quot;Delay-Tolerant Networking Architecture,&amp;quot; Internet RFC 4838 (informational), Apr. 2007.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC4840\&#34;&gt;[RFC4840]&lt;/span&gt; B.Aboba, ed., E. Davies, and D. Thaler, &amp;quot;Multiple Encapsulation Methods Considered Harmful,&amp;quot; Internet RFC 4840 (informational), Apr. 2007.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC5072\&#34;&gt;[RFC5072]&lt;/span&gt; S. Varada, ed., D. Haskins, and E.Allen, &amp;quot;IP Version 6 over PPP,&amp;quot; Internet RFC 5072,Sept. 2007.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC5225\&#34;&gt;[RFC5225]&lt;/span&gt; G. Pelletier and K.Sandlund, &amp;quot;RObust Header Compression Version 2 (ROHCv2): Profiles for RTP, UDP,IP, ESP, and UDP-Lite,&amp;quot; Internet RFC 5225, Apr. 2008.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC5646\&#34;&gt;[RFC5646]&lt;/span&gt; A. Phillips and M. Davis, eds., &amp;quot;Tags for Identifying Languages,&amp;quot; Internet RFC 5646/BCP 0047,Sept. 2009.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;S08\&#34;&gt;[S08]&lt;/span&gt; D. Skordoulis et al., &amp;quot;IEEE 802.11n MAC Frame Aggregation Mechanisms for Next-Generation High-Throughput WLANs,” IEEE Wireless Communications, Feb. 2008.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;S96\&#34;&gt;[S96]&lt;/span&gt; B. Schneier,Applied Cryptography, Second Edition (John Wiley &amp;amp; Sons, 1996).&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;SAE\&#34;&gt;[SAE]&lt;/span&gt; D. Harkins, &amp;quot;Simultaneous Authentication of Equals: A Secure, Password-Based Key Exchange for Mesh Networks,&amp;quot; Proc. SENSORCOMM,Aug.2008.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;SC05\&#34;&gt;[SC05]&lt;/span&gt; S. Shalunov and R.Carlson, &amp;quot;Detecting Duplex Mismatch on Ethernet,&amp;quot; Proc. Passive and Active Measurement Workshop, Mar. 2005.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;SHKO7\&#34;&gt;[SHKO7]&lt;/span&gt; C.Sengul, A.Harris, and R. Kravets,&amp;quot;Reconsidering Power Management,&amp;quot; Invited Paper, Proc. IEEE Broadnets, 2007.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;WOL\&#34;&gt;[WOL]&lt;/span&gt; http://wake-on-lan.sourceforge.net&lt;/p&gt;\n&#34;,&#34;fileName&#34;:&#34;lesslesstcpip-xiang-jie-juan-yi-xie-yi-greatergreater-di-san-zhang-lian-lu-ceng&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;《TCP/IP 详解 卷一：协议》第三章：链路层&#34;,&#34;tags&#34;:[{&#34;index&#34;:-1,&#34;name&#34;:&#34;TCP/IP&#34;,&#34;slug&#34;:&#34;NhO-Hr8Eu&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://wenbozhangw.github.io/tag/NhO-Hr8Eu/&#34;}],&#34;date&#34;:&#34;2022-04-28 11:10:17&#34;,&#34;dateFormat&#34;:&#34;2022-04-28&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://wenbozhangw.github.io/post/lesslesstcpip-xiang-jie-juan-yi-xie-yi-greatergreater-di-san-zhang-lian-lu-ceng/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;189 min read&#34;,&#34;time&#34;:11301000,&#34;words&#34;:48811,&#34;minutes&#34;:189},&#34;description&#34;:&#34;3.1 引言\n在第 1 章中，我们知道 TCP/IP 协议族中设计链路层的目的是为 IP 模块发送和接收 IP 数据报。它可用于携带一些支持 IP 的辅助性协议，例如 ARP （见第 4 章）。 TCP/IP 支持多种不同的链路层，它依赖于...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#31-%E5%BC%95%E8%A8%80\&#34;&gt;3.1 引言&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#32-%E4%BB%A5%E5%A4%AA%E7%BD%91%E5%92%8C-ieee-802-%E5%B1%80%E5%9F%9F%E7%BD%91%E5%9F%8E%E5%9F%9F%E7%BD%91%E6%A0%87%E5%87%86\&#34;&gt;3.2 以太网和 IEEE 802 局域网/城域网标准&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#321-ieee-802-%E5%B1%80%E5%9F%9F%E7%BD%91%E5%9F%8E%E5%9F%9F%E7%BD%91%E6%A0%87%E5%87%86\&#34;&gt;3.2.1 IEEE 802 局域网/城域网标准&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#322-%E4%BB%A5%E5%A4%AA%E7%BD%91%E5%B8%A7%E6%A0%BC%E5%BC%8F\&#34;&gt;3.2.2 以太网帧格式&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#3221-%E5%B8%A7%E6%A0%A1%E9%AA%8C%E5%BA%8F%E5%88%97%E5%BE%AA%E7%8E%AF%E5%86%97%E4%BD%99%E6%A0%A1%E9%AA%8C\&#34;&gt;3.2.2.1 帧校验序列/循环冗余校验&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#3222-%E5%B8%A7%E5%A4%A7%E5%B0%8F\&#34;&gt;3.2.2.2 帧大小&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#323-8021pq%E8%99%9A%E6%8B%9F%E5%B1%80%E5%9F%9F%E7%BD%91%E5%92%8C-qos-%E6%A0%87%E7%AD%BE\&#34;&gt;3.2.3 802.1p/q：虚拟局域网和 QoS 标签&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#324-8021ax%E9%93%BE%E8%B7%AF%E8%81%9A%E5%90%88%E4%BB%A5%E5%89%8D%E7%9A%84-8023ad\&#34;&gt;3.2.4 802.1AX：链路聚合（以前的 802.3ad）&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#33-%E5%85%A8%E5%8F%8C%E5%B7%A5-%E7%9C%81%E7%94%B5-%E8%87%AA%E5%8A%A8%E5%8D%8F%E5%95%86%E5%92%8C-8021x-%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6\&#34;&gt;3.3 全双工、省电、自动协商和 802.1X 流量控制&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#331-%E5%8F%8C%E5%B7%A5%E4%B8%8D%E5%8C%B9%E9%85%8D\&#34;&gt;3.3.1 双工不匹配&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#332-%E5%B1%80%E5%9F%9F%E7%BD%91%E5%94%A4%E9%86%92wol-%E7%9C%81%E7%94%B5%E5%92%8C%E9%AD%94%E6%9C%AF%E5%88%86%E7%BB%84\&#34;&gt;3.3.2 局域网唤醒（WoL）、省电和魔术分组&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#333-%E9%93%BE%E8%B7%AF%E5%B1%82%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6\&#34;&gt;3.3.3 链路层流量控制&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#34-%E7%BD%91%E6%A1%A5%E5%92%8C%E4%BA%A4%E6%8D%A2%E6%9C%BA\&#34;&gt;3.4 网桥和交换机&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#341-%E7%94%9F%E6%88%90%E6%A0%91%E5%8D%8F%E8%AE%AE\&#34;&gt;3.4.1 生成树协议&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#3411-%E7%AB%AF%E5%8F%A3%E7%8A%B6%E6%80%81%E5%92%8C%E8%A7%92%E8%89%B2\&#34;&gt;3.4.1.1 端口状态和角色&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#3412-bpdu-%E7%BB%93%E6%9E%84\&#34;&gt;3.4.1.2 BPDU 结构&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#3413-%E5%BB%BA%E7%AB%8B%E7%94%9F%E6%88%90%E6%A0%91\&#34;&gt;3.4.1.3 建立生成树&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#3414-%E6%8B%93%E6%89%91%E5%8F%98%E5%8C%96\&#34;&gt;3.4.1.4 拓扑变化&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#3415-%E4%BE%8B%E5%AD%90\&#34;&gt;3.4.1.5 例子&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#3416-%E5%BF%AB%E9%80%9F%E7%94%9F%E6%88%90%E6%A0%91%E5%8D%8F%E8%AE%AE%E4%BB%A5%E5%89%8D%E7%9A%84-8021w\&#34;&gt;3.4.1.6 快速生成树协议（以前的 802.1w）&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#342-8021ak%E5%A4%9A%E6%B3%A8%E5%86%8C%E5%8D%8F%E8%AE%AE\&#34;&gt;3.4.2 802.1ak：多注册协议&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#35-%E6%97%A0%E7%BA%BF%E5%B1%80%E5%9F%9F%E7%BD%91ieee-80211wi-fi\&#34;&gt;3.5 无线局域网——IEEE 802.11（Wi-Fi）&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#351-80211-%E5%B8%A7\&#34;&gt;3.5.1 802.11 帧&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#3511-%E7%AE%A1%E7%90%86%E5%B8%A7\&#34;&gt;3.5.1.1 管理帧&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#3512-%E6%8E%A7%E5%88%B6%E5%B8%A7rtscts-%E5%92%8C-ack\&#34;&gt;3.5.1.2 控制帧：RTS/CTS 和 ACK&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#3513-%E6%95%B0%E6%8D%AE%E5%B8%A7-%E5%88%86%E7%89%87%E5%92%8C%E8%81%9A%E5%90%88\&#34;&gt;3.5.1.3 数据帧、分片和聚合&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#352-%E7%9C%81%E7%94%B5%E6%A8%A1%E5%BC%8F%E5%92%8C%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5%E5%8A%9F%E8%83%BD\&#34;&gt;3.5.2 省电模式和时间同步功能&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#353-80211-%E4%BB%8B%E8%B4%A8%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6\&#34;&gt;3.5.3 802.11 介质访问控制&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#3531-%E8%99%9A%E6%8B%9F%E8%BD%BD%E6%B3%A2%E4%BE%A6%E5%90%AC-rtscts-%E5%92%8C%E7%BD%91%E7%BB%9C%E5%88%86%E9%85%8D%E5%90%91%E9%87%8F\&#34;&gt;3.5.3.1 虚拟载波侦听、RTS/CTS 和网络分配向量&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#3532-%E7%89%A9%E7%90%86%E8%BD%BD%E6%B3%A2%E4%BE%A6%E5%90%ACcca\&#34;&gt;3.5.3.2 物理载波侦听（CCA）&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#3533-dcf-%E5%86%B2%E7%AA%81%E9%81%BF%E5%85%8D%E9%80%80%E9%81%BF%E8%BF%87%E7%A8%8B\&#34;&gt;3.5.3.3 DCF 冲突避免/退避过程&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#3534-hcf-%E5%92%8C-80211en-%E7%9A%84-qos\&#34;&gt;3.5.3.4 HCF 和 802.11e/n 的 QoS&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#354-%E7%89%A9%E7%90%86%E5%B1%82%E7%9A%84%E7%BB%86%E8%8A%82%E9%80%9F%E7%8E%87-%E4%BF%A1%E9%81%93%E5%92%8C%E9%A2%91%E7%8E%87\&#34;&gt;3.5.4 物理层的细节：速率、信道和频率&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#3541-%E4%BF%A1%E9%81%93%E5%92%8C%E9%A2%91%E7%8E%87\&#34;&gt;3.5.4.1 信道和频率&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#3542-%E6%9B%B4%E9%AB%98%E5%90%9E%E5%90%90%E9%87%8F%E7%9A%84-80211802211n\&#34;&gt;3.5.4.2 更高吞吐量的 802.11/8022.11n&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#355-wi-fi-%E5%AE%89%E5%85%A8\&#34;&gt;3.5.5 Wi-Fi 安全&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#356-wi-fi-%E7%BD%91%E7%8A%B6%E7%BD%9180211s\&#34;&gt;3.5.6 Wi-Fi 网状网（802.11s）&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#36-%E7%82%B9%E5%88%B0%E7%82%B9%E5%8D%8F%E8%AE%AE\&#34;&gt;3.6 点到点协议&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#361-%E9%93%BE%E8%B7%AF%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE\&#34;&gt;3.6.1 链路控制协议&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#3611-lcp-%E6%93%8D%E4%BD%9C\&#34;&gt;3.6.1.1 LCP 操作&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#3612-lcp-%E9%80%89%E9%A1%B9\&#34;&gt;3.6.1.2 LCP 选项&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#362-%E5%A4%9A%E9%93%BE%E8%B7%AF-ppp\&#34;&gt;3.6.2 多链路 PPP&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#363-%E5%8E%8B%E7%BC%A9%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE\&#34;&gt;3.6.3 压缩控制协议&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#364-ppp-%E8%AE%A4%E8%AF%81\&#34;&gt;3.6.4 PPP 认证&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#365-%E7%BD%91%E7%BB%9C%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE\&#34;&gt;3.6.5 网络控制协议&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#366-%E5%A4%B4%E9%83%A8%E5%8E%8B%E7%BC%A9\&#34;&gt;3.6.6 头部压缩&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#367-%E4%BE%8B%E5%AD%90\&#34;&gt;3.6.7 例子&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#37-%E7%8E%AF%E5%9B%9E\&#34;&gt;3.7 环回&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#38-mtu-%E5%92%8C%E8%B7%AF%E5%BE%84-mtu\&#34;&gt;3.8 MTU 和路径 MTU&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#39-%E9%9A%A7%E9%81%93%E5%9F%BA%E7%A1%80\&#34;&gt;3.9 隧道基础&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#391-%E5%8D%95%E5%90%91%E9%93%BE%E8%B7%AF\&#34;&gt;3.9.1 单向链路&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#310-%E4%B8%8E%E9%93%BE%E8%B7%AF%E5%B1%82%E7%9B%B8%E5%85%B3%E7%9A%84%E6%94%BB%E5%87%BB\&#34;&gt;3.10 与链路层相关的攻击&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#311-%E6%80%BB%E7%BB%93\&#34;&gt;3.11 总结&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#312-%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE\&#34;&gt;3.12 参考文献&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;p&gt;本规范定义了 IP 版本 6 （IPv6）协议的寻址体系结构。该文档包括 IPv6 地址模型、IPv6 地址的文本表示、IPv6 单播地址、任播地址和组播地址的定义，以及 IPv6 节点所需的地址。本文档废除了 RFC 3513，“IP 版本 6 寻址架构”。&lt;/p&gt;\n&lt;p&gt;本文档为 Internet 社区指定了一个 Internet 标准跟踪协议，并请求讨论和改进建议。请参阅最新版本的“互联网官方协议标准”（STD 1）以了解该协议的标准化状态和状态。本备忘录的分发不受限制。&lt;/p&gt;\n&lt;p&gt;Copyright （C） The Internet Society （2006）.&lt;/p&gt;\n&lt;!-- more --&gt;\n&lt;h1 id=\&#34;1-introduction\&#34;&gt;1. Introduction&lt;/h1&gt;\n&lt;p&gt;本规范定义了 IP 版本 6 协议的寻址体系结构。它包括各种类型 IPv6 地址（单播、任播和组播）的基本格式。&lt;/p&gt;\n&lt;h1 id=\&#34;2-ipv6-addressing\&#34;&gt;2. IPv6 Addressing&lt;/h1&gt;\n&lt;p&gt;IPv6 地址是接口和接口集的 128 位标识符（其中“接口”的定义见 [IPv6] 章节 2）。地址有三种类型：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;单播（Unicast）：单个接口的标识符。发送到单播地址的数据包会被发送到该地址标识的接口。&lt;/li&gt;\n&lt;li&gt;任播（Anycast）：一组接口的标识符（通常属于不同的节点）。发送到任播地址的数据包被发送到由该地址（根据路由协议的距离度量，是“最近的”）识别的接口之一。&lt;/li&gt;\n&lt;li&gt;多播（Multicast）：一组接口的标识符（通常属于不同节点）。发送到多播地址的数据包会被传送到该地址标识的所有接口。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;IPv6 中没有广播（broadcast）地址，其功能被多播（multicast）地址取代。&lt;/p&gt;\n&lt;p&gt;在本文档中，地址中的字段被赋予特定的名称，例如“子网（subnet）”。当此名称与名称后的标识符术语“ID”一起使用时（例如，“子网ID”），它指的是命名字段的内容。当它与术语“前缀”（例如，“子网前缀”）一起使用时，它指的是从左侧开始到包含此字段在内的所有地址。&lt;/p&gt;\n&lt;p&gt;在 IPv6 中，对于任何字段，全 0 和全 1 都是的合法值，除非明确排除。具体来说，前缀可能包含 0 值字段，或者以 0 值字段结尾。&lt;/p&gt;\n&lt;h2 id=\&#34;21-addressing-model\&#34;&gt;2.1 Addressing Model&lt;/h2&gt;\n&lt;p&gt;所有类型的 IPv6 地址都是分配给接口的，而不是分配给节点。IPv6 单播地址只的是单个接口。因为每个接口属于单个节点，所以该节点的任何接口的单播地址都可以用作该节点的标识符。&lt;/p&gt;\n&lt;p&gt;所有接口都要求至少有一个链路本地单播地址（有关其他要求的地址，请参见 2.8 节）。一个接口也可以有多个任意类型（单播、任播和组播）或任何范围的 IPv6 地址。如果接口不作为任何与非邻居的 IPv6 报文的源或目的地址，这不需要作用域大于 link-scope 的单播地址。这在某些情况对点对点接口很方便。这种寻址模型有一个例外：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;如果实现中向 internet 层呈现时，将多个物理接口视为一个接口，则一个单播地址或一组单播地址\n可以分配给多个物理接口。这样做有利于多个物理接口上的负载均衡。\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;目前，IPv6 延续了 IPv4 模型，子网前缀与一条链路相关联。多个子网前缀可以分配给同一个链路。&lt;/p&gt;\n&lt;h2 id=\&#34;22-text-representation-of-addresses\&#34;&gt;2.2 Text Representation of Addresses&lt;/h2&gt;\n&lt;p&gt;有三种将 IPv6 地址表示为文本串的约定格式：&lt;/p&gt;\n&lt;ol&gt;\n&lt;li&gt;首选形式为 &lt;code&gt;x:x:x:x:x:x:x:x&lt;/code&gt;，这里“&lt;code&gt;x&lt;/code&gt;”是地址的 8 个 16 位地址片段的 1到 4 个 16 进制数字。例如：&lt;code&gt;ABCD:EF01:2345:6789:ABCD:EF01:2345:6789&lt;/code&gt; 、 &lt;code&gt;2001:DB8:0:0:8:800:200C:417A&lt;/code&gt; 。请注意，没有必要在单个字段中写入前导零，但每个字段必须至少有一个数字（除了 2. 中描述的情况）。&lt;/li&gt;\n&lt;li&gt;由于需要分配一些特定类型的 IPv6 地址，地址通常包含很长的零位字符串。为了使写包含零位的地址更容易，可以使用一种特殊的语法来压缩零位。使用“&lt;code&gt;::&lt;/code&gt;”表示一组或多组 16 位的 0。“&lt;code&gt;::&lt;/code&gt;”在一个地址中只能出现一次。&amp;quot;&lt;code&gt;::&lt;/code&gt;&amp;quot;也可以用来压缩地址的前导或尾随零。例如下面的地址：&lt;pre&gt;&lt;code&gt;2001:DB8:0:0:8:800:200C:417A   a unicast address\nFF01:0:0:0:0:0:0:101            a multicast address\n0:0:0:0:0:0:0:1                 the loopback address\n0:0:0:0:0:0:0:0                 the loopback address\n&lt;/code&gt;&lt;/pre&gt;\n可以表示为：&lt;pre&gt;&lt;code&gt;2001:DB8::8:800:200C:417A   a unicast address\nFF01::101                    a multicast address\n::1                          the loopback address\n::                           the loopback address\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;li&gt;在混用 IPv4 和 IPv6 节点的环境，另一种有时更方便的形式是 &lt;code&gt;x:x:x:x:x:x:d.d.d.d&lt;/code&gt;。这里“&lt;code&gt;x&lt;/code&gt;”是地址的 6 个高阶 16 位地址片段的 16 进制值，“&lt;code&gt;d&lt;/code&gt;”是地址的 4 个低阶 8 位地址片段的 10 进制值（标准的 IPv4 地址表示）。例如：&lt;code&gt;0:0:0:0:0:0:13.1.68.3&lt;/code&gt; 、&lt;code&gt;0:0:0:0:0:FFFF:129.144.52.38&lt;/code&gt; 或者压缩格式：&lt;code&gt;::13.1.68.3&lt;/code&gt;、&lt;code&gt;::FFFF:129.144.52.38&lt;/code&gt; 。&lt;/li&gt;\n&lt;/ol&gt;\n&lt;h2 id=\&#34;23-text-representation-of-address-prefixes\&#34;&gt;2.3 Text Representation of Address Prefixes&lt;/h2&gt;\n&lt;p&gt;IPv6 地址前缀的文本表示类似于 IPv4 地址前缀在无类域间路由（Classless Inter-Domain Routing，CIDR）斜线表示法[CIDR]中的书写方式。IPv6地址前缀由以下符号表示：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;ipv6-address/prefix-length\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;其中，&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;ipv6-address    是用第 2.2 节列出的任何一种符号表示法表示的 IPv6 地址。\nprefix-length   是十进制值，规定地址中最左边多少个连续位构成前缀。\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;例如，以下是 60 位前缀 &lt;code&gt;20010DB80000CD3&lt;/code&gt; （十六进制）的合法表示形式：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;2001:0DB8:0000:CD30:0000:0000:0000:0000/60\n2001:0DB8::CD30:0:0:0:0/60\n2001:0DB8:0:CD30::/60\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;以下不是上述前缀的合法表示：&lt;br&gt;\n&lt;code&gt;2001:0DB8:0:CD3/60&lt;/code&gt;：在地址的任何16位块中，可以删除前导零，但不删除尾随零&lt;br&gt;\n&lt;code&gt;2001:0DB8::CD30/60&lt;/code&gt;：“/”左边的地址扩展为 &lt;code&gt;2001:0DB8:0000:0000:0000:0000:0000:CD30&lt;/code&gt;&lt;br&gt;\n&lt;code&gt;2001:0DB8::CD3/60&lt;/code&gt;：“/”左边的地址扩展为 &lt;code&gt;2001:0DB8:0000:0000:0000:0000:0000:0CD3&lt;/code&gt;&lt;/p&gt;\n&lt;p&gt;当书写节点地址和该节点地址的前缀（例如，节点的子网前缀）时，二者合并写法如下：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;节点地址          2001:0DB8:0:CD30:123:4567:89AB:CDEF\n和它的子网号      2001:0DB8:0:CD30::/60\n二者能够缩写为    2001:0DB8:0:CD30:123:4567:89AB:CDEF/60\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h2 id=\&#34;24-address-type-identification\&#34;&gt;2.4 Address Type Identification&lt;/h2&gt;\n&lt;p&gt;IPv6 地址的类型由地址的高阶位来标识，具体如下:&lt;/p&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;Address type&lt;/th&gt;\n&lt;th&gt;Binary prefix&lt;/th&gt;\n&lt;th&gt;IPv6 notation&lt;/th&gt;\n&lt;th&gt;Section&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;Unspecified&lt;/td&gt;\n&lt;td&gt;00...0（128位）&lt;/td&gt;\n&lt;td&gt;::/128&lt;/td&gt;\n&lt;td&gt;2.5.2&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;Loopback&lt;/td&gt;\n&lt;td&gt;00...1（128位）&lt;/td&gt;\n&lt;td&gt;::1/128&lt;/td&gt;\n&lt;td&gt;2.5.3&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;Multicast&lt;/td&gt;\n&lt;td&gt;11111111&lt;/td&gt;\n&lt;td&gt;FF00::/8&lt;/td&gt;\n&lt;td&gt;2.7&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;Link-Local unicast&lt;/td&gt;\n&lt;td&gt;1111111010&lt;/td&gt;\n&lt;td&gt;FE80::/10&lt;/td&gt;\n&lt;td&gt;2.5.6&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;Global Unicast&lt;/td&gt;\n&lt;td&gt;（everything else）&lt;/td&gt;\n&lt;td&gt;&lt;/td&gt;\n&lt;td&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;p&gt;任播（Anycast）地址取自（任何作用域的）单播地址空间，在语法上与单播地址不可区分。&lt;/p&gt;\n&lt;p&gt;全球单播（Global Unicast）地址的一般格式见 2.5.4 节。一些特殊用途的包含嵌入式 IPv4 地址的全球单播地址子类型（用于 IPv4-IPv6 互操作）将在章节 2.5.5 中描述。&lt;/p&gt;\n&lt;p&gt;将来的规范可能会为其他目的重新定义全局单播空间的一个或多个子范围，但除非发生这种情况，否则实现必须把没有以上述列出的任何一种前缀开始的所有地址，当作是全球单播地址。&lt;/p&gt;\n&lt;h2 id=\&#34;25-unicast-addresses\&#34;&gt;2.5 Unicast Addresses&lt;/h2&gt;\n&lt;p&gt;IPv6 单播地址可以与任意位长的前缀聚合，类似于无分类域间路由中的 IPv4 地址。&lt;/p&gt;\n&lt;p&gt;IPv6 中有几种类型的单播地址，特别是全局单播、站点-本地单播（已弃用，参见 2.5.7 节）和链路-本地单播。全球单播也有一些特殊用途的子类型，例如带有嵌入式 IPv4 地址的 IPv6 地址。将来可以定义更多的地址类型或子类型。&lt;/p&gt;\n&lt;p&gt;IPv6 节点可能非常了解，也可能很少了解 IPv6 地址内部结构，这取决于节点扮演的角色（例如，主机 vs 路由器）。至少，一个节点可以认为单播地址（包括它自己的）没有内部结构：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;   |                           128 bits                              |\n   +-----------------------------------------------------------------+\n   |                          node address                           |\n   +-----------------------------------------------------------------+\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;一个稍微复杂的主机（但仍然相当简单）可能还知道它所连接的链路的子网前缀，不同的地址可能有不同的 n 位值：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;   |          n bits               |           128-n bits            |\n   +-------------------------------+---------------------------------+\n   |       subnet prefix           |           interface ID          |\n   +-------------------------------+---------------------------------+\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;虽然一个非常简单的路由器可能不知道 IPv6 单播地址的内部结构，但路由器通常会知道一个或多个路由协议运行分层边界。已知的边界会因路由器而异，这取决于路由器在路由层次结构中的位置。&lt;/p&gt;\n&lt;p&gt;除了前面讨论的子网边界的知识，节点不应该对 IPv6 地址的结构做任何假设。&lt;/p&gt;\n&lt;h3 id=\&#34;251-interface-identifiers\&#34;&gt;2.5.1 Interface Identifiers&lt;/h3&gt;\n&lt;p&gt;IPv6 单播地址中的&lt;strong&gt;接口标识符&lt;/strong&gt;（Interface identifiers，IID）用于标识链路上的接口。它们在子网前缀中必须是唯一的。建议同一条链路上的不同节点不要使用相同的接口标识符。它们在更广泛的范围内也可能是唯一的。在某些情况下，接口的标识符将直接从该接口的链路层地址派生。同一个节点上的多个接口可以使用相同的接口标识符，只要这些接口属于不同的子网。&lt;/p&gt;\n&lt;p&gt;注意接口标识符的唯一性与 IPv6 地址的唯一性无关。例如，可以使用本地作用域接口标识（local  scope interface identifier）创建全局单播地址，也可以使用通用作用域接口标识（universal scope interface identifier）创建链路本地地址（Link-Local address）。&lt;/p&gt;\n&lt;p&gt;除了以二进制值 &lt;code&gt;000&lt;/code&gt; 开头的单播地址外，所有单播地址的“接口ID”长度都要求为 64 位，并按照修改的 EUI-64 格式构造。&lt;/p&gt;\n&lt;p&gt;修改的基于 EUI-64 格式的接口标识符在从通用令牌派生时可能具有通用作用域（例如，IEEE 802 48位MAC 或 IEEE EUI-64 标识符 [EUI64]），或者在通用全球令牌不可用时可能具有本地作用域（例如，串行链路、隧道端点）或不希望使用全球标记时（例如，隐私临时令牌 [PRIV]）。&lt;/p&gt;\n&lt;p&gt;修改的 EUI-64 格式的接口标识符由 IEEE EUI-64 标识符组成时，是通过将“u”位（IEEE EUI-64 术语中的通用/本地位）反转来形成的。在产生的修改 EUI-64 格式中，“u”位被设置为 （1） 表示通用范围，它被设置为 （0） 表示本地范围。IEEE EUI-64 二进制标识符的前三个字节如下:&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;          0       0 0       1 1       2\n         |0       7 8       5 6       3|\n         +----+----+----+----+----+----+\n         |cccc|ccug|cccc|cccc|cccc|cccc|\n         +----+----+----+----+----+----+\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;以互联网标准位顺序书写，其中“u”是 通用/本地（universal/local）位，“g”是个体/组（individual/group）位，“c”是公司 ID 的位。附录A“Creating Modified EUI-64 Format Interface Identifiers”提供了创建基于修改后的 EUI-64 格式的接口标识符的示例。&lt;/p&gt;\n&lt;p&gt;在形成接口标识符时，将“u”位反转的动机是，当硬件令牌不可用时，系统管理员可以方便地配置非全局标识符。例如，串行连接（serial link）和隧道端点（tunnel end-points）都可能出现这种情况。另一种形式是 &lt;code&gt;0200:0:0:1&lt;/code&gt;、&lt;code&gt;0200:0:0:2&lt;/code&gt;，等等，代替更简单的 &lt;code&gt;0:0:0:0:1&lt;/code&gt;、&lt;code&gt;0:0:2&lt;/code&gt;，等等。&lt;/p&gt;\n&lt;p&gt;IPv6 节点不需要验证使用修改过的 EUI-64 令牌（“u”位设置为universal）创建的接口标识符是否唯一。&lt;/p&gt;\n&lt;p&gt;在修改的EUI-64格式标识符中使用通用/本地位是为了允许未来技术的开发，从而利用具有通用作用域的接口标识符。&lt;/p&gt;\n&lt;p&gt;形成接口标识符的细节在适当的“&lt;code&gt;IPv6 over &amp;lt;link&amp;gt;&lt;/code&gt;”规范中定义，例如“IPv6 over Ethernet”[ETHER]和“IPv6 over FDDI”[FDDI]。&lt;/p&gt;\n&lt;h3 id=\&#34;252-the-unspecified-address\&#34;&gt;2.5.2 The Unspecified Address&lt;/h3&gt;\n&lt;p&gt;地址 &lt;code&gt;0:0:0:0:0:0&lt;/code&gt; 称为未指定地址（unspecified address）。它永远不能被分配给任何节点。它用来表示没有地址。使用它的一个例子是，正在初始化的主机还没有学习到它自己的地址之前，它发送的任何 IPv6 分组中 Source Address 字段的内容。&lt;/p&gt;\n&lt;p&gt;未指定的地址不能用作 IPv6 报文的目的地址或在 IPv6 路由报头中。源地址不指定的 IPv6 报文不能被 IPv6 路由器转发。&lt;/p&gt;\n&lt;h3 id=\&#34;253-the-loopback-address\&#34;&gt;2.5.3 The Loopback Address&lt;/h3&gt;\n&lt;p&gt;单播地址 &lt;code&gt;0:0:0:0:0:1&lt;/code&gt; 称为环回地址（Loopback Address）。节点可以使用它向自身发送 IPv6 数据包。它不能被分配给任何物理接口。它被视为具有 Link-Local 作用域，可以被认为是到一个不存在的虚拟链路的虚拟接口（通常称为“环回接口（loopback interface）”）的 Link-Local 单播地址。&lt;/p&gt;\n&lt;p&gt;环回地址不能作为发送到单个节点外的 IPv6 报文的源地址。以环回地址为目的地地址的 IPv6 分组决不能发送到单一节点以外，也不能被 IPv6 路由器转发。对于目的地址为 loopback 的接口，必须丢弃报文。&lt;/p&gt;\n&lt;h3 id=\&#34;254-global-unicast-addresses\&#34;&gt;2.5.4 Global Unicast Addresses&lt;/h3&gt;\n&lt;p&gt;IPv6 全球单播地址的一般格式如下：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;   |         n bits         |   m bits  |       128-n-m bits         |\n   +------------------------+-----------+----------------------------+\n   | global routing prefix  | subnet ID |       interface ID         |\n   +------------------------+-----------+----------------------------+\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;其中全局路由前缀（global routing prefix）是一个分配给站点（子网/链路集群）的值（通常是层次结构的），子网 ID （subnet ID）是站点内链路的标识符，接口 ID （interface ID）如章节 2.5.1 所定义。&lt;/p&gt;\n&lt;p&gt;除以二进制 &lt;code&gt;000&lt;/code&gt; 开头的地址外，所有的全球单播地址都有一个 64 位的接口 ID 字段（即n + m = 64），格式如章节 2.5.1 所述。以二进制 &lt;code&gt;000&lt;/code&gt; 开头的全球单播地址对接口 ID 字段的大小或结构没有这样的约束。&lt;/p&gt;\n&lt;p&gt;以二进制 &lt;code&gt;000&lt;/code&gt; 开头的全球单播地址的例子是在 2.5.5 节中描述的嵌入 IPv4 地址的 IPv6 地址。在[GLOBAL] 中可以找到一个以二进制值而不是 &lt;code&gt;000&lt;/code&gt; （因此有一个64位的接口ID字段）开头的全局地址示例。&lt;/p&gt;\n&lt;h3 id=\&#34;255-ipv6-addresses-with-embedded-ipv4-addresses\&#34;&gt;2.5.5 IPv6 Addresses with Embedded IPv4 Addresses&lt;/h3&gt;\n&lt;p&gt;定义了两种 IPv6 地址，它们携带 IPv4 地址的低阶 32 位。即“IPv4-Compatible IPv6 address”和“IPv4-mapped IPv6 address”。&lt;/p&gt;\n&lt;h4 id=\&#34;2551-ipv4-compatible-ipv6-address\&#34;&gt;2.5.5.1 IPv4-Compatible IPv6 Address&lt;/h4&gt;\n&lt;p&gt;定义“IPv4-Compatible IPv6 address”是为了帮助实现 IPv6 的过渡。“IPv4-Compatible IPv6 address”格式如下:&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;   |                80 bits               | 16 |      32 bits        |\n   +--------------------------------------+--------------------------+\n   |0000..............................0000|0000|    IPv4 address     |\n   +--------------------------------------+----+---------------------+\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;注:“IPv4-Compatible IPv6 address”中的 IPv4 地址必须为全球唯一的 IPv4 单播地址。&lt;/p&gt;\n&lt;p&gt;“IPv4-Compatible IPv6 address”现在已弃用，因为当前的 IPv6 转换机制不再使用这些地址。不需要新的或更新的实现来支持这种地址类型。&lt;/p&gt;\n&lt;h4 id=\&#34;2552-ipv4-mapped-ipv6-address\&#34;&gt;2.5.5.2 IPv4-mapped IPv6 Address&lt;/h4&gt;\n&lt;p&gt;定义了第二种类型的 IPv6 地址，它包含一个嵌入式 IPv4 地址。该地址类型用于将 IPv4 节点的地址表示为 IPv 6地址。“IPv4-mapped IPv6 address”格式如下:&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;   |                80 bits               | 16 |      32 bits        |\n   +--------------------------------------+--------------------------+\n   |0000..............................0000|FFFF|    IPv4 address     |\n   +--------------------------------------+----+---------------------+\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;关于“IPv4-mapped IPv6 address”的使用背景参见 [RFC4038]。&lt;/p&gt;\n&lt;h3 id=\&#34;256-link-local-ipv6-unicast-addresses\&#34;&gt;2.5.6 Link-Local IPv6 Unicast Addresses&lt;/h3&gt;\n&lt;p&gt;链路本地（Link-Local）地址用于单个链路。Link-Local 地址格式如下：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;   |   10     |\n   |  bits    |         54 bits         |          64 bits           |\n   +----------+-------------------------+----------------------------+\n   |1111111010|           0             |       interface ID         |\n   +----------+-------------------------+----------------------------+\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;Link-Local 地址被设计用于在单个链路上寻址，用于自动地址配置、邻居发现或没有路由器时。&lt;/p&gt;\n&lt;p&gt;路由器不能将源地址或目的地址为 Link-Local 的报文转发到其他链路。&lt;/p&gt;\n&lt;h3 id=\&#34;257-site-local-ipv6-unicast-addresses\&#34;&gt;2.5.7 Site-Local IPv6 Unicast Addresses&lt;/h3&gt;\n&lt;p&gt;站点-本地（Site-Local）地址最初设计用于在站点内部寻址，而不需要全局前缀。站点本地地址现在已如 [SLDEP] 中定义的那样被弃用。&lt;/p&gt;\n&lt;p&gt;Site-Local 地址有以下格式：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;   |   10     |\n   |  bits    |         54 bits         |         64 bits            |\n   +----------+-------------------------+----------------------------+\n   |1111111011|        subnet ID        |       interface ID         |\n   +----------+-------------------------+----------------------------+\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;这个前缀在 [RFC3513] 中定义的特殊行为在新的实现中必须不再被支持（即，新的实现必须将这个前缀视为全局单播）。&lt;/p&gt;\n&lt;p&gt;现有的实现和部署可能会继续使用这个前缀。&lt;/p&gt;\n&lt;h2 id=\&#34;26-anycast-addresses\&#34;&gt;2.6 Anycast Addresses&lt;/h2&gt;\n&lt;p&gt;IPv6 任播地址是一个被分配给多个接口（通常属于不同的节点）的地址，其属性是，发送到任播地址的数据包将被路由到具有该地址的“最近”接口，根据路由协议的距离度量。&lt;/p&gt;\n&lt;p&gt;任播地址从单播地址空间中分配，使用任何定义的单播地址格式。因此，任播地址和单播地址在语法上是不可区分的。当一个单播地址被分配给多个接口，从而将其转换为任播地址时，被分配该地址的节点必须显式配置，以知道它是任播地址。&lt;/p&gt;\n&lt;p&gt;对于任何被分配的任播地址，该地址有一个最长的前缀 P，它标识了属于该任播地址的所有接口所在的拓扑区域。在由 P 标识的区域内，任播地址必须在路由系统中作为一个单独的条目维护（通常称为“主机路由”）；在由 P 标识的区域之外，任播地址可以聚合到前缀 P 的路由表项中。&lt;/p&gt;\n&lt;p&gt;注意，在最坏的情况下，任播集合的前缀 P 可能是空前缀，也就是说，集合的成员可能没有拓扑局部性。在这种情况下，任播地址必须在整个 Internet 中作为一个单独的路由条目来维护，这对支持多少这样的“全局”任播集合提出了一个严重的扩展限制。因此，预计对全局任播集合的支持可能不可用或非常有限。&lt;/p&gt;\n&lt;p&gt;任播地址的一个预期用途是识别属于提供互联网服务的组织的一组路由器。这些地址可以用作 IPv6 路由报头中的中间地址，以使数据包通过特定的服务提供者或服务提供者序列被交付。&lt;/p&gt;\n&lt;p&gt;其他一些可能的用途是识别连接到特定子网的路由器集合，或提供进入特定路由域的入口的路由器集合。&lt;/p&gt;\n&lt;h3 id=\&#34;261-required-anycast-address\&#34;&gt;2.6.1 Required Anycast Address&lt;/h3&gt;\n&lt;p&gt;子网路由器任播（Subnet-Router anycast）地址是预定义的。其格式如下：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;   |                         n bits                 |   128-n bits   |\n   +------------------------------------------------+----------------+\n   |                   subnet prefix                | 00000000000000 |\n   +------------------------------------------------+----------------+\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;任播地址中的“subnet prefix”是标识特定链路的前缀。该任播地址在语法上与接口标识符为零的接口的单播地址相同。&lt;/p&gt;\n&lt;p&gt;发送到 Subnet-Router anycast 地址的数据包将被发送到子网中的一个路由器。所有的路由器都需要支持子网路由器的任播地址，因为它们有接口。&lt;/p&gt;\n&lt;p&gt;Subnet-Router anycast 地址用于节点需要与任意一组路由器进行通信的应用程序。&lt;/p&gt;\n&lt;h2 id=\&#34;27-multicast-addresses\&#34;&gt;2.7 Multicast Addresses&lt;/h2&gt;\n&lt;p&gt;IPv6 组播地址是一组接口（通常在不同的节点上）的标识符。一个接口可以属于任意数量的多播组。多播地址的格式如下：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;   |   8    |  4 |  4 |                  112 bits                   |\n   +------ -+----+----+---------------------------------------------+\n   |11111111|flgs|scop|                  group ID                   |\n   +--------+----+----+---------------------------------------------+\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;地址开头的二进制 &lt;code&gt;11111111&lt;/code&gt; 标识该地址为多播地址。&lt;br&gt;\nflags 是 4 个 flag 的集合：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;+-+-+-+-+\n|0|R|P|T|\n+-+-+-+-+\n&lt;/code&gt;&lt;/pre&gt;\n&lt;ul&gt;\n&lt;li&gt;高阶标志是保留的，必须初始化为0。&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;T = 0&lt;/code&gt; 表示一个永久分配的（众所周知的）组播地址，由IANA （Internet assigned Numbers Authority）分配。&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;T = 1&lt;/code&gt; 表示非永久分配（“瞬态”或“动态”分配）的多播地址。&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;P&lt;/code&gt; 标志的定义和用法可以在 [RFC3306] 中找到。&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;R&lt;/code&gt; 标志的定义和用法可以在 [RFC3956] 中找到。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;scop 是一个 4 位组播作用域值，用于限制组播组的作用域。取值如下：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;         0  reserved\n         1  Interface-Local scope\n         2  Link-Local scope\n         3  reserved\n         4  Admin-Local scope\n         5  Site-Local scope\n         6  （unassigned）\n         7  （unassigned）\n         8  Organization-Local scope\n         9  （unassigned）\n         A  （unassigned）\n         B  （unassigned）\n         C  （unassigned）\n         D  （unassigned）\n         E  Global scope\n         F  reserved\n&lt;/code&gt;&lt;/pre&gt;\n&lt;pre&gt;&lt;code&gt;Interface-Local 作用域只覆盖节点上的一个接口，只适用于组播的环回传输。从其他节点收到的 Interface-Local 作用域的报文必须被丢弃。\n\nLink-Local 组播作用域与对应的单播作用域跨越相同的拓扑区域。\n\nAdmin-Local 作用域是必须管理性配置的最小作用域，即不是从物理连接或其他非多播相关配置中自动获得的。\n\nSite-Local 作用域旨在跨越单个站点。\n\nOrganization-Local 作用域旨在跨越属于单个组织的多个站点。\n\n标有“（unassigned）”的作用域可供管理员定义其他多播区域。\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;group ID 标识给定范围内的多播组（永久或临时）。组播组 ID 字段结构的附加定义在 [RFC3306] 中提供。&lt;/p&gt;\n&lt;p&gt;永久分配的多播地址的“含义”与作用域值无关。例如，如果“NTP服务器组”被分配一个组 ID 为 &lt;code&gt;101&lt;/code&gt; （十六进制）的永久多播地址，那么&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;FF01:0:0:0:0:0:0:101 表示所有 NTP 服务器与发送者在同一个接口（即同一个节点）上。\nFF02:0:0:0:0:0:0:101 表示与发送方在同一条链路上的所有 NTP 服务器。\nFF05:0:0:0:0:0:0:101 表示与发送方在同一站点的所有 NTP 服务器。\nFF0E:0:0:0:0:0:0:101 表示互联网上的所有 NTP 服务器。\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;非永久分配的多播地址（Non-premanently-assigned multicast address）仅在给定范围内有意义。例如，一组确定的非永久性的，本地站点多播地址 &lt;code&gt;FF15:0:0:0:0:0:0:101&lt;/code&gt; 标识的组与在不同站点处使用相同地址的组、使用不同范围的相同组 ID 的非永久组、以及具有相同组 ID 的永久组都没有关系。&lt;/p&gt;\n&lt;p&gt;多播地址不能用作 IPv6 数据包中的源地址，也不能出现在任何路由头中。&lt;/p&gt;\n&lt;p&gt;路由器不得转发任何超出目的多播地址中 scop 字段所指示范围之外的多播数据包。&lt;/p&gt;\n&lt;p&gt;节点不得向其 scop 字段包含保留值 0 的多播地址发起分组；如果收到这样的数据包，它必须被无声地丢弃。节点不应该向其 scop 字段包含保留值 F 的多播地址发起分组；如果发送或接收到这样的数据包，它必须被视为与目的地为全局（scop E）多播地址的数据包相同。&lt;/p&gt;\n&lt;h3 id=\&#34;271-pre-defined-multicast-addresses\&#34;&gt;2.7.1 Pre-Defined Multicast Addresses&lt;/h3&gt;\n&lt;p&gt;下面是预定义的众所周知（well-known）的多播地址。本节中定义的组 ID 是为显式范围值定义的。&lt;/p&gt;\n&lt;p&gt;不允许将这些组 ID 用于任何其他范围值，T 标志等于0。&lt;/p&gt;\n&lt;p&gt;保留的多播地址：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;                                      FF00:0:0:0:0:0:0:0\n                                      FF01:0:0:0:0:0:0:0\n                                      FF02:0:0:0:0:0:0:0\n                                      FF03:0:0:0:0:0:0:0\n                                      FF04:0:0:0:0:0:0:0\n                                      FF05:0:0:0:0:0:0:0\n                                      FF06:0:0:0:0:0:0:0\n                                      FF07:0:0:0:0:0:0:0\n                                      FF08:0:0:0:0:0:0:0\n                                      FF09:0:0:0:0:0:0:0\n                                      FF0A:0:0:0:0:0:0:0\n                                      FF0B:0:0:0:0:0:0:0\n                                      FF0C:0:0:0:0:0:0:0\n                                      FF0D:0:0:0:0:0:0:0\n                                      FF0E:0:0:0:0:0:0:0\n                                      FF0F:0:0:0:0:0:0:0\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;上述多播地址被保留，不得分配给任何多播组。&lt;br&gt;\n所有节点地址:&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;                              FF01:0:0:0:0:0:0:1\n                              FF02:0:0:0:0:0:0:1\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;上述多播地址标识范围 1（接口本地，interface-local）或范围 2（链路本地，link-local）内的所有 IPv6 节点的组。&lt;/p&gt;\n&lt;p&gt;所有路由器地址:&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;                               FF01:0:0:0:0:0:0:2\n                               FF02:0:0:0:0:0:0:2\n                               FF05:0:0:0:0:0:0:2\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;上述多播地址标识范围 1（接口本地，interface-local）或范围 2（链路本地，link-local）或 5 （站点本地，site-local）内的所有 IPv6 路由器的组。&lt;/p&gt;\n&lt;p&gt;请求节点地址（Solicited-Node Address）：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;                               FF02:0:0:0:0:1:FFXX:XXXX\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;Solicited-Node 组播地址的计算是节点单播地址和任播地址的函数。Solicited-Node 多播地址是由一个地址的低阶的 24 位（单播或任播）和附加位前缀 &lt;code&gt;FF02:0:0:0:0:1:FF00::/104&lt;/code&gt; 来形成的。从而得到范围 &lt;code&gt;FF02:0:0:0:0:1:FF00:0000&lt;/code&gt; 到 &lt;code&gt;FF02:0:0:0:0:1:FFFF:FFFF&lt;/code&gt;  的多播地址。&lt;/p&gt;\n&lt;p&gt;例如，对应于 IPv6 地址 &lt;code&gt;4037::01:800:200E:8C6C&lt;/code&gt; 的请求节点多播地址是 &lt;code&gt;FF02::1:FF0E:8C6C&lt;/code&gt;。仅在高阶位不同的 IPv6 地址（例如，由于与不同聚合相关联的多个高阶前缀）将映射到相同的被请求节点地址，从而减少节点必须加入的多播地址的数量。&lt;/p&gt;\n&lt;p&gt;要求节点计算并加入（在适当的接口上）已经为该节点的接口（手动或自动）配置的所有单播和任播地址的相关 Solicited-Node 多播地址。&lt;/p&gt;\n&lt;h2 id=\&#34;28-a-nodes-required-addresses\&#34;&gt;2.8 A Node&#39;s Required Addresses&lt;/h2&gt;\n&lt;p&gt;主机需要识别以下地址作为其自身的标识：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;它需要每个接口的 Link-Local 地址。&lt;/li&gt;\n&lt;li&gt;（手动或自动）为节点接口配置的任何其他 Unicast 和 Anycast 地址。&lt;/li&gt;\n&lt;li&gt;环回地址。&lt;/li&gt;\n&lt;li&gt;在章节 2.7.1 中定义的所有节点组播地址。&lt;/li&gt;\n&lt;li&gt;Solicited-Node 的单播和任播地址的组播地址。&lt;/li&gt;\n&lt;li&gt;该节点所属的所有其他组的多播地址。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;路由器需要识别主机需要识别的所有地址，以及以下用于识别自身的地址：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;配置为充当路由器的所有接口的 Subnet-Router Anycast 地址。&lt;/li&gt;\n&lt;li&gt;路由器已配置的所有其他 Anycast 地址。&lt;/li&gt;\n&lt;li&gt;在章节 2.7.1 定义的 All-Routers 组播地址。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h1 id=\&#34;3-secutiry-considerations\&#34;&gt;3. Secutiry Considerations&lt;/h1&gt;\n&lt;p&gt;IPv6 寻址文档对 Internet 基础设施安全没有任何直接影响。在 [AUTH] 中定义了 IPv6 报文的认证。&lt;/p&gt;\n&lt;h1 id=\&#34;4-iana-considerations\&#34;&gt;4. IANA Considerations&lt;/h1&gt;\n&lt;p&gt;不建议使用“IPv4-Compatible IPv6 address”。IANA 应该继续将 &lt;a href=\&#34;#http://www.iana.org/assignments/ipv6-address-space\&#34;&gt;http://www.iana.org/assignments/ipv6-address-space&lt;/a&gt; 上包含这些地址的地址块列为“由 IETF 保留的”，而不为任何其他目的重新分配它。例如：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;      0000::/8        Reserved by IETF        [RFC3513]      [1]\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;IANA 已经添加了以下注释和到这个地址块的链接。&lt;br&gt;\n[5]  0000::/96 以前被定义为“IPv4-Compatible IPv6 address”前缀。该定义已被 RFC 4291弃用。&lt;br&gt;\nIANA 相应地更新了 IANA 注册表中关于 IPv6 地址体系结构的参考。&lt;/p&gt;\n&lt;h1 id=\&#34;5-acknowledgements\&#34;&gt;5. Acknowledgements&lt;/h1&gt;\n&lt;p&gt;The authors would like to acknowledge the contributions of Paul Francis, Scott Bradner, Jim Bound, Brian Carpenter, Matt Crawford, Deborah Estrin, Roger Fajman, Bob Fink, Peter Ford, Bob Gilligan, Dimitry Haskin, Tom Harsch, Christian Huitema, Tony Li, Greg Minshall, Thomas Narten, Erik Nordmark, Yakov Rekhter, Bill Simpson, Sue Thomson, Markku Savela, Larry Masinter, Jun-ichiro Itojun Hagino, Tatuya Jinmei, Suresh Krishnan, and Mahmood Ali.&lt;/p&gt;\n&lt;h1 id=\&#34;6-references\&#34;&gt;6. References&lt;/h1&gt;\n&lt;h2 id=\&#34;61-normative-references\&#34;&gt;6.1 Normative References&lt;/h2&gt;\n&lt;p&gt;[IPV6]  Deering, S. and R. Hinden, &amp;quot;Internet Protocol, Version 6 (IPv6) Specification&amp;quot;, RFC 2460, December 1998.&lt;/p&gt;\n&lt;h2 id=\&#34;62-informative-references\&#34;&gt;6.2 Informative References&lt;/h2&gt;\n&lt;p&gt;[AUTH]    Kent, S. and R. Atkinson, &amp;quot;IP Authentication Header&amp;quot;, RFC 2402, November 1998.&lt;/p&gt;\n&lt;p&gt;[CIDR]    Fuller, V., Li, T., Yu, J., and K. Varadhan, &amp;quot;Classless Inter-Domain Routing (CIDR): an Address Assignment and Aggregation Strategy&amp;quot;, RFC 1519, September 1993.&lt;/p&gt;\n&lt;p&gt;[ETHER]   Crawford, M., &amp;quot;Transmission of IPv6 Packets over Ethernet Networks&amp;quot;, RFC 2464, December 1998.&lt;/p&gt;\n&lt;p&gt;[EUI64]   IEEE, &amp;quot;Guidelines for 64-bit Global Identifier (EUI-64) Registration Authority&amp;quot;, http://standards.ieee.org/regauth/oui/tutorials/EUI64.html, March 1997.&lt;/p&gt;\n&lt;p&gt;[FDDI]    Crawford, M., &amp;quot;Transmission of IPv6 Packets over FDDI Networks&amp;quot;, RFC 2467, December 1998.&lt;/p&gt;\n&lt;p&gt;[GLOBAL]  Hinden, R., Deering, S., and E. Nordmark, &amp;quot;IPv6 Global Unicast Address Format&amp;quot;, RFC 3587, August 2003.&lt;/p&gt;\n&lt;p&gt;[PRIV]    Narten, T. and R. Draves, &amp;quot;Privacy Extensions for Stateless Address Autoconfiguration in IPv6&amp;quot;, RFC 3041, January 2001.&lt;/p&gt;\n&lt;p&gt;[RFC3513] Hinden, R. and S. Deering, &amp;quot;Internet Protocol Version 6 (IPv6) Addressing Architecture&amp;quot;, RFC 3513, April 2005.&lt;/p&gt;\n&lt;p&gt;[RFC3306] Haberman, B. and D. Thaler, &amp;quot;Unicast-Prefix-based IPv6&lt;br&gt;\nMulticast Addresses&amp;quot;, RFC 3306, August 2002.&lt;/p&gt;\n&lt;p&gt;[RFC3956] Savola, P. and B. Haberman, &amp;quot;Embedding the Rendezvous Point (RP) Address in an IPv6 Multicast Address&amp;quot;, RFC 3956, November 2004.&lt;/p&gt;\n&lt;p&gt;[RFC4038] Shin, M-K., Hong, Y-G., Hagino, J., Savola, P., and E. Castro, &amp;quot;Application Aspects of IPv6 Transition&amp;quot;, RFC 4038, March 2005.&lt;/p&gt;\n&lt;p&gt;[SLDEP]   Huitema, C. and B. Carpenter, &amp;quot;Deprecating Site Local Addresses&amp;quot;, RFC 3879, September 2004.&lt;/p&gt;\n&lt;h1 id=\&#34;appendix-a-creating-modified-eui-64-format-interface-identifiers\&#34;&gt;Appendix A: Creating Modified EUI-64 Format Interface Identifiers&lt;/h1&gt;\n&lt;p&gt;根据特定链接或节点的特征，有许多方法可以创建修改 EUI-64格式的接口标识符。本附录描述了其中的一些方法。&lt;/p&gt;\n&lt;h2 id=\&#34;links-or-nodes-with-ieee-eui-64-identifiers\&#34;&gt;Links or Nodes with IEEE EUI-64 Identifiers&lt;/h2&gt;\n&lt;p&gt;将 IEEE EUI-64 标识符转换为接口标识符所需的唯一更改是将“u”（通用/本地）位反转。一个例子是表单的全局唯一 IEEE EUI-64 标识符：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;   |0              1|1              3|3              4|4              6|\n   |0              5|6              1|2              7|8              3|\n   +----------------+----------------+----------------+----------------+\n   |cccccc0gcccccccc|ccccccccmmmmmmmm|mmmmmmmmmmmmmmmm|mmmmmmmmmmmmmmmm|\n   +----------------+----------------+----------------+----------------+\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;其中，“&lt;code&gt;c&lt;/code&gt;”是指定的 company_id 的位，“&lt;code&gt;0&lt;/code&gt;”是通用/本地位的值，表示通用范围，“&lt;code&gt;g&lt;/code&gt;”是单个/组位，“&lt;code&gt;m&lt;/code&gt;”是制造商选择的扩展标识符的位。IPv6 接口标识符的形式如下:&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;   |0              1|1              3|3              4|4              6|\n   |0              5|6              1|2              7|8              3|\n   +----------------+----------------+----------------+----------------+\n   |cccccc1gcccccccc|ccccccccmmmmmmmm|mmmmmmmmmmmmmmmm|mmmmmmmmmmmmmmmm|\n   +----------------+----------------+----------------+----------------+\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;唯一的变化是将通用/本地位的值颠倒。&lt;/p&gt;\n&lt;h2 id=\&#34;links-or-nodes-with-ieee-802-48-bit-macs\&#34;&gt;Links or Nodes with IEEE 802 48-bit MACs&lt;/h2&gt;\n&lt;p&gt;[EUI64]定义了一种从 IEEE 48 位 MAC 标识符创建 IEEE EUI-64 标识符的方法。这是在 48 位 MAC （在 company_id 和供应商提供的 id 之间）的中间插入两个 octet，其十六进制值为 &lt;code&gt;0xFF&lt;/code&gt; 和&lt;code&gt;0xFE&lt;/code&gt;（参见附录末尾的注释）。一个例子是具有全局作用域的 48 位 IEEE MAC：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;   |0              1|1              3|3              4|\n   |0              5|6              1|2              7|\n   +----------------+----------------+----------------+\n   |cccccc0gcccccccc|ccccccccmmmmmmmm|mmmmmmmmmmmmmmmm|\n   +----------------+----------------+----------------+\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;其中，“&lt;code&gt;c&lt;/code&gt;”是分配的 company_id 的位，“&lt;code&gt;0&lt;/code&gt;”是通用/本地位的值，用来表示 Global 作用域，“&lt;code&gt;g&lt;/code&gt;”是单个/组位，“&lt;code&gt;m&lt;/code&gt;”是制造商选择的扩展标识符的位。接口标识符的形式如下：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;   |0              1|1              3|3              4|4              6|\n   |0              5|6              1|2              7|8              3|\n   +----------------+----------------+----------------+----------------+\n   |cccccc1gcccccccc|cccccccc11111111|11111110mmmmmmmm|mmmmmmmmmmmmmmmm|\n   +----------------+----------------+----------------+----------------+\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;当 IEEE 802 48 位 MAC 地址可用时（在接口或节点上），由于其可用性和唯一性，实现可能使用它们来创建接口标识符。&lt;/p&gt;\n&lt;h2 id=\&#34;links-with-other-kinds-of-identifiers\&#34;&gt;Links with Other Kinds of Identifiers&lt;/h2&gt;\n&lt;p&gt;除了 IEEE EUI-64 或 IEEE 802 48 位 MAC 之外，还有许多类型的链路具有链路层接口标识符。例如 LocalTalk 和 Arcnet 。创建 Modified EUI-64 格式标识符的方法是采用链接标识符（例如，LocalTalk 8 位节点标识符），并将其填充到左侧。例如，LocalTalk 的 8 位节点标识符的十六进制值 &lt;code&gt;0x4F&lt;/code&gt; 会导致如下接口标识符：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;   |0              1|1              3|3              4|4              6|\n   |0              5|6              1|2              7|8              3|\n   +----------------+----------------+----------------+----------------+\n   |0000000000000000|0000000000000000|0000000000000000|0000000001001111|\n   +----------------+----------------+----------------+----------------+\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;注意，这将导致通用/本地位被设置为“0”，以表示本地作用域。&lt;/p&gt;\n&lt;h2 id=\&#34;links-without-identifiers\&#34;&gt;Links without Identifiers&lt;/h2&gt;\n&lt;p&gt;有许多链接没有任何类型的内置标识符。其中最常见的是串行连接和配置的隧道。必须选择在子网前缀内唯一的接口标识符。&lt;/p&gt;\n&lt;p&gt;当链路上没有内置标识符时，首选方法是使用另一个接口的通用接口标识符或分配给节点本身的标识符。当使用这种方法时，将同一节点连接到同一子网前缀的其它接口不能使用同一标识符。&lt;/p&gt;\n&lt;p&gt;如果链路上没有可用的通用接口标识符，则实现需要创建一个本地范围的接口标识符。唯一的要求是它在子网前缀中是唯一的。有许多可能的方法来选择子网前缀唯一接口标识符。其中包括以下内容：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Manual Configuration&lt;/li&gt;\n&lt;li&gt;Node Serial Number&lt;/li&gt;\n&lt;li&gt;Other Node-Specific Token&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;子网前缀唯一（subnet-prefix-unique）接口标识符应该以这样一种方式生成，使得它在节点重新启动后或者在节点中添加或删除接口时不会改变。&lt;/p&gt;\n&lt;p&gt;适当算法的选择取决于链路和实现。在适当的“&lt;code&gt;IPv6 over &amp;lt;link &amp;gt;&lt;/code&gt;”规范中定义了关于形成接口标识符的细节。强烈建议将冲突检测算法作为任何自动算法的一部分来实现。&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;注意：[EUI-64] 实际上将 0xFF 和 0xFE 定义为要插入的位，以从 IEEE MAC- 48 标识\n符创建 IEEE EUI-64 标识符。从 IEEE EUI-48 标识符开始时，使用 0xFF 和 0xFE \n值。由于对 IEEE MAC-48 和 EUI-48 标识符之间的差异存在误解，早期版本的规范中使用\n了不正确的值。\n\n本文档特意继续使用 0xFF 和 0xFE，因为它符合 IPv6 接口标识符的要求(即它们在链路上\n必须是唯一的)，IEEE EUI-48 和 MAC-48 标识符在语法上是等效的，并且在实践中不会引\n起任何问题。\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h2 id=\&#34;appendix-b-changes-from-rfc-3513\&#34;&gt;Appendix B: Changes from RFC 3513&lt;/h2&gt;\n&lt;p&gt;RFC 3513“IP Version 6 Addressing Architecture”有以下变化：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;取消了对使用 IPv6 任播地址的限制，因为现在已经有了足够的使用任播地址的经验，这些问题并不是 IPv6 所特有的，并且 GROW 工作组正在这一领域开展工作。&lt;/li&gt;\n&lt;li&gt;不赞成使用站点本地单播前缀。变化包括以下内容：\n&lt;ul&gt;\n&lt;li&gt;从2.4节的特殊前缀列表中删除了Site-Local。&lt;/li&gt;\n&lt;li&gt;将标题为“Local-use IPv6 Unicast Addresses”的部分分成两个部分，“Link-Local IPv6 Unicast Addresses”和“Site-   Local IPv6 Unicast Addresses”。&lt;/li&gt;\n&lt;li&gt;向新部分添加了描述 Site-Local 不推荐使用的文本。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;更改以解决 IAB 回应 Robert Elz 上诉时提出的问题。变化包括以下内容：\n&lt;ul&gt;\n&lt;li&gt;在第 2.5 节中添加了说明，即节点不应假设 IPv6 地址的结构。&lt;/li&gt;\n&lt;li&gt;更改了第 2.5.1 节和附录 A 中的文本，将“&lt;code&gt;u&lt;/code&gt;”位设置为一 (1) 的修改后的 EUI-64 格式接口标识符称为通用标识符。&lt;/li&gt;\n&lt;li&gt;在第 2.5.1 节中添加了说明，即 IPv6 节点不需要验证以修改后的 EUI-64 格式创建的接口标识符（其中“&lt;code&gt;u&lt;/code&gt;”位设置为 1 ）是否唯一。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;将第 2.5.4 节“Global Unicast  Addresses”中指示的参考更改为 RFC 3587。&lt;/li&gt;\n&lt;li&gt;删除了示例中提到的 NSAP 地址。&lt;/li&gt;\n&lt;li&gt;澄清了文本表示中的“&lt;code&gt;x&lt;/code&gt;”可以是一到四位数。&lt;/li&gt;\n&lt;li&gt;不推荐使用“IPv6 Compatible Address”，因为它没有在 IPv6 转换机制中使用。&lt;/li&gt;\n&lt;li&gt;在关于多播地址的第 2.7 节中添加了“&lt;code&gt;R&lt;/code&gt;”和“&lt;code&gt;P&lt;/code&gt;”标志，以及指向定义它们的文档的指针。&lt;/li&gt;\n&lt;li&gt;编辑上的改动。&lt;/li&gt;\n&lt;/ul&gt;\n&#34;,&#34;fileName&#34;:&#34;rfc4291-ip-version-6-addressing-architecture&#34;,&#34;abstract&#34;:&#34;&lt;p&gt;本规范定义了 IP 版本 6 （IPv6）协议的寻址体系结构。该文档包括 IPv6 地址模型、IPv6 地址的文本表示、IPv6 单播地址、任播地址和组播地址的定义，以及 IPv6 节点所需的地址。本文档废除了 RFC 3513，“IP 版本 6 寻址架构”。&lt;/p&gt;\n&lt;p&gt;本文档为 Internet 社区指定了一个 Internet 标准跟踪协议，并请求讨论和改进建议。请参阅最新版本的“互联网官方协议标准”（STD 1）以了解该协议的标准化状态和状态。本备忘录的分发不受限制。&lt;/p&gt;\n&lt;p&gt;Copyright （C） The Internet Society （2006）.&lt;/p&gt;\n&#34;,&#34;title&#34;:&#34;RFC4291: IP Version 6 Addressing Architecture&#34;,&#34;tags&#34;:[{&#34;index&#34;:-1,&#34;name&#34;:&#34;TCP/IP&#34;,&#34;slug&#34;:&#34;NhO-Hr8Eu&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://wenbozhangw.github.io/tag/NhO-Hr8Eu/&#34;}],&#34;date&#34;:&#34;2022-04-26 10:57:39&#34;,&#34;dateFormat&#34;:&#34;2022-04-26&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://wenbozhangw.github.io/post/rfc4291-ip-version-6-addressing-architecture/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;34 min read&#34;,&#34;time&#34;:2035000,&#34;words&#34;:8474,&#34;minutes&#34;:34},&#34;description&#34;:&#34;本规范定义了 IP 版本 6 （IPv6）协议的寻址体系结构。该文档包括 IPv6 地址模型、IPv6 地址的文本表示、IPv6 单播地址、任播地址和组播地址的定义，以及 IPv6 节点所需的地址。本文档废除了 RFC 3513，“IP 版...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;&lt;a href=\&#34;#1-introduction\&#34;&gt;1. Introduction&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#2-ipv6-addressing\&#34;&gt;2. IPv6 Addressing&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#21-addressing-model\&#34;&gt;2.1 Addressing Model&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#22-text-representation-of-addresses\&#34;&gt;2.2 Text Representation of Addresses&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#23-text-representation-of-address-prefixes\&#34;&gt;2.3 Text Representation of Address Prefixes&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#24-address-type-identification\&#34;&gt;2.4 Address Type Identification&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#25-unicast-addresses\&#34;&gt;2.5 Unicast Addresses&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#251-interface-identifiers\&#34;&gt;2.5.1 Interface Identifiers&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#252-the-unspecified-address\&#34;&gt;2.5.2 The Unspecified Address&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#253-the-loopback-address\&#34;&gt;2.5.3 The Loopback Address&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#254-global-unicast-addresses\&#34;&gt;2.5.4 Global Unicast Addresses&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#255-ipv6-addresses-with-embedded-ipv4-addresses\&#34;&gt;2.5.5 IPv6 Addresses with Embedded IPv4 Addresses&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#2551-ipv4-compatible-ipv6-address\&#34;&gt;2.5.5.1 IPv4-Compatible IPv6 Address&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#2552-ipv4-mapped-ipv6-address\&#34;&gt;2.5.5.2 IPv4-mapped IPv6 Address&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#256-link-local-ipv6-unicast-addresses\&#34;&gt;2.5.6 Link-Local IPv6 Unicast Addresses&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#257-site-local-ipv6-unicast-addresses\&#34;&gt;2.5.7 Site-Local IPv6 Unicast Addresses&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#26-anycast-addresses\&#34;&gt;2.6 Anycast Addresses&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#261-required-anycast-address\&#34;&gt;2.6.1 Required Anycast Address&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#27-multicast-addresses\&#34;&gt;2.7 Multicast Addresses&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#271-pre-defined-multicast-addresses\&#34;&gt;2.7.1 Pre-Defined Multicast Addresses&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#28-a-nodes-required-addresses\&#34;&gt;2.8 A Node&#39;s Required Addresses&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#3-secutiry-considerations\&#34;&gt;3. Secutiry Considerations&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#4-iana-considerations\&#34;&gt;4. IANA Considerations&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#5-acknowledgements\&#34;&gt;5. Acknowledgements&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#6-references\&#34;&gt;6. References&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#61-normative-references\&#34;&gt;6.1 Normative References&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#62-informative-references\&#34;&gt;6.2 Informative References&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#appendix-a-creating-modified-eui-64-format-interface-identifiers\&#34;&gt;Appendix A: Creating Modified EUI-64 Format Interface Identifiers&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#links-or-nodes-with-ieee-eui-64-identifiers\&#34;&gt;Links or Nodes with IEEE EUI-64 Identifiers&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#links-or-nodes-with-ieee-802-48-bit-macs\&#34;&gt;Links or Nodes with IEEE 802 48-bit MACs&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#links-with-other-kinds-of-identifiers\&#34;&gt;Links with Other Kinds of Identifiers&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#links-without-identifiers\&#34;&gt;Links without Identifiers&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#appendix-b-changes-from-rfc-3513\&#34;&gt;Appendix B: Changes from RFC 3513&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;h2 id=\&#34;abstract\&#34;&gt;Abstract&lt;/h2&gt;\n&lt;p&gt;本教程介绍由 IEEE 注册结构（IEEE RA, IEEE Registration Authority）分配的组织标识符（origanizational identifiers）以及基于它们的扩展标识符（extended identifiers）。它涵盖了与受让人以及标准开发人员相关的标识符格式（identifier formats）、assignment（分配）、指导方针（guidelines）和策略（policies）。本教程包括与组织标识符（如组织唯一标识符（Organizational Unique Identifier，OUI）和公司 ID（Company ID），以及扩展标识符（Extended Unique Identifier，EUI）和扩展本地标识符（Extended Local Identifier，ELI））相关的信息。&lt;/p&gt;\n&lt;!-- more --&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;status-and-history\&#34;&gt;Status and History&lt;/h2&gt;\n&lt;p&gt;本教程替代以下三个 IEEE RA 教程文档：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Guidelines for Use Organizationally Unique Identifier (OUI) and Company ID (CID)&lt;/li&gt;\n&lt;li&gt;Guidelines for 48-Bit Global Identifier (EUI-48)&lt;/li&gt;\n&lt;li&gt;Guidelines for 64-Bit Global Identifier (EUI-64)&lt;/li&gt;\n&lt;/ul&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;contents\&#34;&gt;Contents&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#abstract\&#34;&gt;Abstract&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#status-and-history\&#34;&gt;Status and History&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#contents\&#34;&gt;Contents&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#ieee-administered-organizational-identifiers-oui-and-cid\&#34;&gt;IEEE-Administered organizational identifiers: OUI and CID&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#oui\&#34;&gt;OUI&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#oui-36\&#34;&gt;OUI-36&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#cid\&#34;&gt;CID&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#extended-identifiers\&#34;&gt;Extended Identifiers&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#extended-unique-identifiers\&#34;&gt;Extended Unique Identifiers&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#extended-local-identifiereli\&#34;&gt;Extended Local Identifier&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#ieee-ra-assignment-of-identifiers\&#34;&gt;IEEE RA assignment of identifiers&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#eui-structure-and-representation\&#34;&gt;EUI Structure and Representation&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#eui-bit-ordering\&#34;&gt;EUI Bit Ordering&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#unassigned-and-null-eui-values\&#34;&gt;Unassigned and NULL EUI values&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#appropriate-eui-use\&#34;&gt;Appropriate EUI Use&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#maintaining-longevity-of-eui-48-and-eui-64\&#34;&gt;Maintaining Longevity of EUI-48 and EUI-64&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#non-overlapping-assignments\&#34;&gt;Non-Overlapping Assignments&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#ieee-ra-policies-to-reduce-the-volume-of-unused-eui-48s\&#34;&gt;IEEE RA Policies to Reduce the Volume of Unused EUI-48s&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#mapping-an-eui-48-to-an-eui-64\&#34;&gt;Mapping an EUI-48 to an EUI-64&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#other-worldwide-identifiers-based-on-eui\&#34;&gt;Other worldwide identifiers based on EUI&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#context-dependent-identifiers\&#34;&gt;Context dependent identifiers&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#restrictions-on-the-use-of-context-dependent-identifiers\&#34;&gt;Restrictions on the Use of Context Dependent Identifiers&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#deprecated-and-obsolete-identifiers\&#34;&gt;Deprecated and Obsolete Identifiers&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;ieee-administered-organizational-identifiers-oui-and-cid\&#34;&gt;IEEE-Administered organizational identifiers: OUI and CID&lt;/h2&gt;\n&lt;p&gt;IEEE 注册机构（IEEE Registration Authority，IEEE RA）向组织分配全局唯一标识符。两种类型的标识符：24 位组织唯一标识符（24-bit Organizationally Unique Identifier, OUI）和 24 位公司 ID （24-bit Company ID，CID）—— 是相互关联的，它们来自相同的 24 位空间，但落在不同的子空间，由成为 X 位的特定位来区分，如表 1 所示。X 位位置如图 1 所示。每个分配的 OUI 和 CID 相对于所有分配的 OUI 和 CID 是唯一的（IEEE 注册管理机构努力避免重复作业，全局唯一性还依赖于赋值的正确使用和没有可能导致重复的错误）。&lt;/p&gt;\n&lt;center&gt;表 1 ：24 位 CID/OUI 空间划分为两个子空间&lt;/center&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;X bit&lt;/th&gt;\n&lt;th&gt;identifier&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;0&lt;/td&gt;\n&lt;td&gt;OUI&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;CID&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;p&gt;OUI 或 CID 可用于识别公司、组织、实体、制造商、供应商等。&lt;/p&gt;\n&lt;p&gt;IEEE 注册管理局还识别并分配 36 位的 OUI-36 作为组织的全球唯一标识符。被分配的 OUI-36 的前 24 位不重复任何 OUI 或 CID 分配。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;oui\&#34;&gt;OUI&lt;/h2&gt;\n&lt;p&gt;OUI 是一个 24 位（3 个 octet）序列。OUI 的结构如图 1 所示。Octet 0 是起始（most significant，最高有效位）octet。Octet 0 的最低有效位（least significant）和第二最低有效位分别为 M 位和 X 位。在 OUI 中，M 和 X 位的值都是 0。&lt;/p&gt;\n&lt;p&gt;注意：大约有 18 个分配给早起以太网实施者的组织标识符（有些是在 IEEE std 802.3-1085 批准之前分配的 BlockID）的 X 位等于 1。BlockID，就像取代它的 OUI 一样，是一个 24 位的数字，作为 2&lt;sup&gt;24&lt;/sup&gt;  的 48 位 MAC 地址块的基数。BlockID 分配被记录在 MA-L（OUI）注册表中。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;1\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1650724485618.png\&#34; alt=\&#34;图 1：Structure of OUI\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;OUI 可以表示为 6 个十六进制数字。或者，它可以表示为由连字符分割的 octet；IEEE RA 将其称为十六进制（hex）表示。表 2 显示了 OUI 的一个例子，以 base-16 形式 &lt;code&gt;ACDE48&lt;/code&gt; 和 hex 形式 &lt;code&gt;AC-DE-48&lt;/code&gt;（这个例子中的八位字符串可以被使用，并且不是一个保留值）。表 2 的最后一行表示 24 位二进制 OUI 序列。&lt;/p&gt;\n&lt;center&gt; 表 2：Example OUI &lt;/center&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;octet identifier&lt;/th&gt;\n&lt;th&gt;0&lt;/th&gt;\n&lt;th&gt;1&lt;/th&gt;\n&lt;th&gt;2&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;example value (hex)&lt;/td&gt;\n&lt;td&gt;AC&lt;/td&gt;\n&lt;td&gt;DE&lt;/td&gt;\n&lt;td&gt;48&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;example value (binary)&lt;/td&gt;\n&lt;td&gt;1010(MSB) 1100&lt;/td&gt;\n&lt;td&gt;1101 1110&lt;/td&gt;\n&lt;td&gt;0100 1000(LSB)&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;oui-36\&#34;&gt;OUI-36&lt;/h2&gt;\n&lt;p&gt;OUI-36 是一个 36 位（four-and-one-half-octet）序列。Octet 0 是起始的（most significant，最高有效位）octet。Octet 0 的最低有效位（least significant）和第二最低有效位分别为 M 位和 X 位。在 OUI-36 中，M 和 X 位的值都是 0。&lt;/p&gt;\n&lt;p&gt;当需要 36 位组织标识符或 36 位协议标识符（protocol identifier）时，可以使用 OUI-36 分配。例如，一些协议指定 36 位标识符来标识一个组织或该组织指定的对象。OUI 的受让人可以在 OUI 的末尾加上 12 位来创建 OUI-36。如果 OUI-36 的受让人需要唯一的 24 位组织标识符，建议使用 CID 分配。&lt;/p&gt;\n&lt;p&gt;OUI-36 可以表示为 9 个十六进制数字。或者，也可以表示为由连字符分割的 octet，使用 IEEE RA 十六进制（hex）表示法。表 3 显示了一个 OUI-36 示例，它具有 base-16 形式 &lt;code&gt;ACDE48234&lt;/code&gt; 和 hex 形式 &lt;code&gt;AC-DE-48-23-4&lt;/code&gt;。表 3 的最后一行表示 36 位二进制 OUI-36 序列。&lt;/p&gt;\n&lt;center&gt; 表 3：Example OUI-36 &lt;/center&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;octet identifier&lt;/th&gt;\n&lt;th&gt;0&lt;/th&gt;\n&lt;th&gt;1&lt;/th&gt;\n&lt;th&gt;2&lt;/th&gt;\n&lt;th&gt;3&lt;/th&gt;\n&lt;th&gt;4&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;example value (hex)&lt;/td&gt;\n&lt;td&gt;AC&lt;/td&gt;\n&lt;td&gt;DE&lt;/td&gt;\n&lt;td&gt;48&lt;/td&gt;\n&lt;td&gt;23&lt;/td&gt;\n&lt;td&gt;4&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;example value (binary)&lt;/td&gt;\n&lt;td&gt;1010(MSB) 1100&lt;/td&gt;\n&lt;td&gt;1101 1110&lt;/td&gt;\n&lt;td&gt;0100 1000&lt;/td&gt;\n&lt;td&gt;0010 0011&lt;/td&gt;\n&lt;td&gt;0100（LSB）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;p&gt;一个 OUI-36 是由 IEEE RA 通过将 12 位连接到 24 位 IEEE 保留的基底 OUI 来创建的，并将这 12 位连接到 Octet 2 的最低有效位之后，如图 1 所示。基底 OUI 不会被分配给另一个组织，也不会被用作 OUI。OUI-36 的受让人不得将 OUI-36 截断用作 OUI，因为 IEEE RA 将使用基底 OUI 将 OUI-36 值分配给多个组织。&lt;/p&gt;\n&lt;p&gt;对于基底 OUI 不应做任何假设。例如，不应该假定对单个组织的多个 OUI-36 任务将共一个公共基底 OUI。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;cid\&#34;&gt;CID&lt;/h2&gt;\n&lt;p&gt;CID 是一个 24 位（three-octet）的序列。CID 的结构如下面的图 2 所示。Octet 0 是起始的（most significant，最高有效位）octet。Octet 0 的 4 个最低有效位分别为 M bit、X bit、Y bit、Z bit，从最低有效位开始。在 CID 中，M、X、Y 和 Z 位分别为 0、1、0 和 1。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;2\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1650727795660.png\&#34; alt=\&#34;图 2：Structure of CID\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;CID 可以表示为 6 个十六进制数字。或者，也可以表示为由连字符分割的 octet，使用 IEEE RA 十六进制（hex）表示法。表 4 显示了一个 base-16 表示的 &lt;code&gt;AADE48&lt;/code&gt; 和 hex 表示的 &lt;code&gt;AA-DE-48&lt;/code&gt; 的示例。表 4 的最后一行表示 24 位二进制 CID 序列。&lt;/p&gt;\n&lt;center&gt; 表 4：Example CID &lt;/center&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;octet identifier&lt;/th&gt;\n&lt;th&gt;0&lt;/th&gt;\n&lt;th&gt;1&lt;/th&gt;\n&lt;th&gt;2&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;example value (hex)&lt;/td&gt;\n&lt;td&gt;AA&lt;/td&gt;\n&lt;td&gt;DE&lt;/td&gt;\n&lt;td&gt;48&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;example value (binary)&lt;/td&gt;\n&lt;td&gt;1010(MSB) 1010&lt;/td&gt;\n&lt;td&gt;1101 1110&lt;/td&gt;\n&lt;td&gt;0100 1000(LSB)&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;extended-identifiers\&#34;&gt;Extended Identifiers&lt;/h2&gt;\n&lt;p&gt;除了最为全局唯一的组织标识符，OUI、OUI-36 或 CID 还可以通过连接额外的区分位（differentiating bits），作为扩展标识符（extended identifiers）的基础，包括协议标识符（protocol identifiers）和上下文相关的标识符（context dependent identifiers）。这些扩展标识符可能是全局唯一的（例如，EUI-48 和 EUI-64），或者仅在使用它们的上下文中唯一。详情见下文。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h3 id=\&#34;extended-unique-identifiers\&#34;&gt;Extended Unique Identifiers&lt;/h3&gt;\n&lt;p&gt;一个扩展唯一标识符（Extended Unique Identifier，EUI）是 48 位扩展唯一标识符（48-bit Extended Unique Identifier，EUI-48）或 64 位位扩展唯一标识符（64-bit Extended Unique Identifier，EUI-64）。除了一些例外情况，特别是在协议标识符方面，每个 EUI 都是全局唯一的，并绑定到需要唯一标识的硬件设备实例或其他对象。EUI-48 和 EUI-64 标识符最常用来作为全局唯一的网络地址（有时成为 MAC 地址），这在各种标准中都有规定。例如，根据 IEEE Std 802，EUI-48 通常被用作硬件接口的地址，历史上使用的名称是 &lt;code&gt;MAC-48&lt;/code&gt;。另一个例子是，根据 IEEE 标准 1588，EUI-64 可以作为时钟的标识符。IEEE Std 802 还指定 EUI-64 使用 64 位全球唯一的网络地址。关于 EUI-48 和 EUI-64 的进一步细节如下。&lt;/p&gt;\n&lt;p&gt;当 EUI 被用作 MAC 地址（例如，IEEE 802 网络地址），初始 octet（Octet 0）中最低有效的两位被用于特殊用途。Octet 0 的最低有效位（I/G 位，I/G 表示 Individual/Group）表示单个地址（I/G = 0，Individual address）或组地址（I/G = 1，Group address），Octet 0 的第二最低有效位（U/L 位，U/L 表示 Universal/Local）表示通用地址（U/L = 0，Universal address）或本地地址（U/L = 1，Local address）的管理。普遍管理地址（universally administered address）是全局唯一的地址（globally unique address）。&lt;/p&gt;\n&lt;p&gt;在扩展 OUI 创建的 EUI 中，OUI 是起始的（最高有效）三个字节。在扩展 OUI-36 创建的 EUI 中，OUI-36 是起始的（最高有效）四个半字节。&lt;/p&gt;\n&lt;p&gt;由于由 IEEE RA 分配的 OUI 和 OUI-36 的 X 位等于 0，因此从分配的 OUI 或 OUI-36 创建的扩展标识符 EUI 具有 &lt;code&gt;U/L = 0&lt;/code&gt;，当用作 MAC 地址时，因此是一个普遍管理地址。&lt;/p&gt;\n&lt;p&gt;由于所有由 IEEE RA 分配的 OUI 和 OUI-36 的 M 位 都等于 0，因此从被分配的 OUI 或 OUI-36 创建的扩展标识符 EUI 的 &lt;code&gt;I/G = 0&lt;/code&gt;，当用做 MAC 地址时，因此是一个单独的地址。&lt;/p&gt;\n&lt;p&gt;OUI 或 OUI-36 的受让人被授权分配组 MAC 地址，通过将 OUI 或 OUI-36 的修改版本扩展其 M 位为 1 ，使 &lt;code&gt;I/G = 1&lt;/code&gt;。这些地址不是 EUI，并且不能全局识别硬件实例，即使 &lt;code&gt;U/L = 0&lt;/code&gt;。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;extended-local-identifiereli\&#34;&gt;Extended Local Identifier（ELI）&lt;/h2&gt;\n&lt;p&gt;一个扩展本地标识符（ELI）是有一个 CID 拼接而成的，CID 由起始的三个（最低有效）字节组成。ELI-48 是 48 为 ELI，ELI-64 是 64 位 ELI。&lt;/p&gt;\n&lt;p&gt;由于由 IEEE RA 进行的 CID 分配的 X 位等于 1，因此从已分配的 CID 创建的 ELI 作为扩展标识符具有 &lt;code&gt;U/L = 1&lt;/code&gt;，因此当用作 MAC 地址时，它是一个本地地址。本地地址不是全局唯一的，网络管理员负责确保分配的任何本地地址在使用范围内是唯一的。（本地地址的唯一性通常不需要扩展到路由器之外。）IEEE Std 802（从修订 IEEE Std 802c-2017 开始）指定了结构化本地地址计划（Structured Local Address Plan，SLAP），它基于 CID 的 Y 位和 Z 位的指定值，描述了本地 MAC 地址空间的一个象限中 ELIs 的使用。在本地 MAC 地址空间的其他象限（quadrants），SLAP 用于描述不基于 CID 的标准分配标识符（Standard Assigned Identifiers，SAIs）和管理分配标识符（Administratively Assigned Identifiers, AAIs）的使用。&lt;/p&gt;\n&lt;p&gt;由于所有由 IEEE RA 进行的 CID 分配的 M 位都等于 0，因此从已分配的 CID 创建的 ELI 作为扩展标识符的 &lt;code&gt;I/G = 0&lt;/code&gt;，因此当用作 MAC 地址时，它是一个单独的地址。CID 的受让人可以通过将已分配 CID 的修改版本扩展为 M 为 1（使 &lt;code&gt;I/G = 1&lt;/code&gt;）来分配本地组 MAC 地址。得到的扩展标识符是  ELI。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h3 id=\&#34;ieee-ra-assignment-of-identifiers\&#34;&gt;IEEE RA assignment of identifiers&lt;/h3&gt;\n&lt;p&gt;一个被分配的 EUI 块可以被看做是通过扩展标识符连接从基数（例如，OUI）扩展而来的数组序列。它也可以被描述为 EUI-48 或 EUI-64 的连续范围。&lt;/p&gt;\n&lt;p&gt;EUI 块由 IEEE RA 分配为三种不同的大小。MA-L 分配块（assignment block）提供 2&lt;sup&gt;24&lt;/sup&gt; 的 EUI-48 标识符和 2&lt;sup&gt;40&lt;/sup&gt; 的 EUI-64 标识符。MA-M 分配块提供 2&lt;sup&gt;20&lt;/sup&gt; 的 EUI-48 标识符和 2&lt;sup&gt;36&lt;/sup&gt; 的 EUI-64 标识符。MA-S 分配块提供 2&lt;sup&gt;12&lt;/sup&gt; 的 EUI-48 标识符和 2&lt;sup&gt;28&lt;/sup&gt; 的 EUI-64 标识符。&lt;/p&gt;\n&lt;p&gt;MA-L 的分配包括 OUI 的分配，OUI 是已分配的 EUI-48 和 EUI-64 扩展标识符块的基础。MA-L 相当于 2014 年 1 月 1 日之前进行的 OUI 赋值，也包括 OUI 以及 EUI-48 和 EUI-64 标识符相关 块的分配。&lt;/p&gt;\n&lt;p&gt;MA-S 分配包括 OUI-36 的分配，OUI-36 是已分配的 EUI-48 和 EUI-64 扩展标识符块的基础。MA-S 不包括 24 位 OUI 的分配。分配的 MA-S 的 24 位初始位是一个分配给 IEEE RA 的 OUI。&lt;/p&gt;\n&lt;p&gt;说明 —— MA-S 分配于 2014 年 1 月 1日可用。MA-S 分配取代了 2014 年 1 月 1 日之前 IEEE RA 提供的个人地址块（Individual Address Block，IAB）和 OUI-36 分配。IAB 只提供了一个包含 4096 个 EUI-48 标识符的块，并没有提供任何其他标识符，例如 EUI-64 标识符；请参阅本教程后面的 &lt;a href=\&#34;#iab-based-identifiers\&#34;&gt;IAB Based Identifiers&lt;/a&gt; 小节。&lt;/p&gt;\n&lt;p&gt;MA-M 不包括 OUI 的分配。MA-M 的受让人可以在 MA-M 分配块中创建一个 OUI-36 作为地址的前 36 位。如果 MA-M 的受让人需要唯一的 24 位组织标识符，建议使用 CID 分配。被分配的 MA-M 块的前 24 位是一个分配给 IEEE 的 OUI，不会被重新分配。&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;注意&lt;/em&gt; —— MA-M 分配于 2014 年 1 月 1 日生效，以响应客户对中间标识块（intermediate block of identifiers）的请求。&lt;/p&gt;\n&lt;p&gt;CID 分配是一个唯一的 24 位标识符，可用于标识公司、组织等。CID 分配不包括任何 EUI-48 或 EUI-64 分配，且一个 CID 不得用于创建 EUI-48 或 EUI-64。对于寻找唯一 24 位标识符的实体，CID 可以作为 MA-M 或 MA-S 分配的补充，因为这些分配不包括 OUI。&lt;/p&gt;\n&lt;p&gt;表 5 总结了来自 IEEE RA 的 OUI、OUI-36、CID、EUI-48 和 EUI-64 分配。&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;IEEE RA 公开列表：\n&amp;lt;https://regauth.standards.ieee.org/standards-ra-web/pub/view.html#registries&amp;gt; \n为 MA-L、MA-M 和 MA-S 提供了单独的数据库。如果前 24 位匹配 IEEE RA 已分配的 OUI，那\n么搜索前 28 位或 36 位可能会发现分配了 MA-M 或 MA-S。如果在 MA-S 中没有找到 \nOUI-36，那么对前 24 或 28 位的搜索可能会发现一个 MA-L 或 MA-M 分配，该分配块中的一\n个成员可能已经创建了 OUI-36 。\n&lt;/code&gt;&lt;/pre&gt;\n&lt;center&gt;表 5：EUI, OUI, and CID assignment summary&lt;/center&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;IEEE RA Assignment&lt;/th&gt;\n&lt;th&gt;Number of IEEE assigned bits&lt;/th&gt;\n&lt;th&gt;Block size of globally unqiue EUI-48 identifiers&lt;/th&gt;\n&lt;th&gt;Block size of globally unqiue EUI-64 identifiers&lt;/th&gt;\n&lt;th&gt;company or organization identifier included&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;MA-L（MAC Adresses - Large）&lt;/td&gt;\n&lt;td&gt;24&lt;/td&gt;\n&lt;td&gt;2&lt;sup&gt;24&lt;/sup&gt; （16,777,216）&lt;/td&gt;\n&lt;td&gt;2&lt;sup&gt;40&lt;/sup&gt; （1,099,511,627,776）&lt;/td&gt;\n&lt;td&gt;OUI（24-bit）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;MA-M（MAC Adresses - Medium）&lt;/td&gt;\n&lt;td&gt;28&lt;/td&gt;\n&lt;td&gt;2&lt;sup&gt;20&lt;/sup&gt; （1,048,576）&lt;/td&gt;\n&lt;td&gt;2&lt;sup&gt;36&lt;/sup&gt; （68,719,476,736）&lt;/td&gt;\n&lt;td&gt;none&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;MA-S（MAC Adresses - Small）&lt;/td&gt;\n&lt;td&gt;36&lt;/td&gt;\n&lt;td&gt;2&lt;sup&gt;12&lt;/sup&gt; （4096）&lt;/td&gt;\n&lt;td&gt;2&lt;sup&gt;28&lt;/sup&gt; （268,435,456）&lt;/td&gt;\n&lt;td&gt;OUI-36（36-bit）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;CID（Company ID）&lt;/td&gt;\n&lt;td&gt;24&lt;/td&gt;\n&lt;td&gt;0 （zero）&lt;/td&gt;\n&lt;td&gt;0 （zero）&lt;/td&gt;\n&lt;td&gt;CID（24-bit）&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;p&gt;IEEE 标识符的受让人负责在其指定的块内管理扩展标识符。IEEE RA 不能控制扩展标识符的分配，并且对于使用 IEEE 分配的标识符（例如，重复的上下文相关标识符、EUI-48 或 EUI-64 值）的组织分配重复的扩展标识符不承担任何责任。&lt;/p&gt;\n&lt;p&gt;表 5 中 IEEE 管理的标识符的分配通常是公开的，可从 IEEE RA 获得，因此感兴趣的用户可以标识 EUI-48、EUI-64、OUI、OUI-36 或 CID 的注册所有者。然而，对于选择使用私有上市选项的受让人，IEEE 分配是公开的，但不公开受让人的身份。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;eui-structure-and-representation\&#34;&gt;EUI Structure and Representation&lt;/h2&gt;\n&lt;p&gt;表 6 说明了 EUI-48 的结构及其与 IEEE RA 的分配的关系。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;3\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1650783393894.png\&#34; alt=\&#34;表 6\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;一个 EUI-48 是一个由六个 octets 组成的字符串，在表 6 中从 Octet 0（起始的和最高有效的）标记到 Octet 5（最后的和最低有效的）。表 6 的最后两行包括一个 EUI-48 的例子，以 base-16 表示 &lt;code&gt;ACDE48234567&lt;/code&gt; 和 hex 表示 &lt;code&gt;AC-DE-48-23-45-67&lt;/code&gt;。注意：EUI-48 可以用 IEEE RA 十六进制（hex）表示（octet 用连字符隔开），也可以用纯 16 进制数字表示。&lt;/p&gt;\n&lt;p&gt;表 6 举例说明了 EUI-48 是如何产生的：OUI &lt;code&gt;AC-DE-48&lt;/code&gt; 的 MA-L 分配，扩展标识符为 &lt;code&gt;23-45-67&lt;/code&gt; 的实体分配；以 &lt;code&gt;AC-DE-48-2&lt;/code&gt; 为基址的 MA-M 分配，以及扩展标识符为 &lt;code&gt;3-45-67&lt;/code&gt; 的实体分配；以一个带有 OUI-36 &lt;code&gt;AC-DE-48-23-4&lt;/code&gt; 的 MA-S 分配，以及一个扩展标识符为 &lt;code&gt;5-67&lt;/code&gt; 的实体分配。&lt;/p&gt;\n&lt;p&gt;EUI-64 以类似的方式表示，它是一个由 8 个 octet 组成的字符串，从 Octet 0（起始位和最高有效位）到 Octet 7（最后位和最低有效位）。表 7 显示了这一点，使用 base-16 表示 &lt;code&gt;ACDE48234567019F&lt;/code&gt; 和 hex 表示 &lt;code&gt;AC-DE-48-23-45-67-01-9F&lt;/code&gt; 为例的 EUI-64。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;4\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1650787323392.png\&#34; alt=\&#34;表 7: Structure if EUI-64\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;eui-bit-ordering\&#34;&gt;EUI Bit Ordering&lt;/h2&gt;\n&lt;p&gt;虽然 EUI octet 的顺序和 octet 中的位是特定的和固定的，但是它们的传输顺序可以根据协议变化。通常，基于 octet 的传输以 octet 标识符升序的方式传输，从 Octet 0 开始。一些分组代码对多个 octet 进行编码。数据的位串行编码可能在 octet 内的位传输顺序上有所不同。同样，地址在内存中的存储顺序也会因协议的不同而不同。有关比特传输顺序的进一步信息可在相关标准中找到，如 IEEE Std 802。&lt;/p&gt;\n&lt;p&gt;考虑到位顺序和字节定位可能存在混淆，应用程序和协议必须明确地指定标识符值（表示为十六进制数字）到使用的寄存器或字节和位序列的映射。为了确保清晰，每个映射都应该是自包含的（self-contained）。如果认为有必要对其他文件进行交叉引用，则应将具体的文件和页码进行交叉引用，使不熟悉的读者能够容易地找到来源。&lt;/p&gt;\n&lt;p&gt;为了避免现有标准的变化，工作组可能会提供关于在其标准中使用标识符的教程，并将其发布在 IEEE RA 网站上。&lt;/p&gt;\n&lt;p&gt;如果某个标准，或其在其他标准中的交叉引用部分，不符合这些文档策略，IEEE 注册管理委员会（IEEE Registration Authority Committee，RAC）可以建议不批准该标准。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;unassigned-and-null-eui-values\&#34;&gt;Unassigned and NULL EUI values&lt;/h2&gt;\n&lt;p&gt;许多应用程序发现定义一个独特的空标识符（null identifier）很有用，通常表示没有有效的 EUI-48  或 EUI-64 值。例如，空值可能是集成电路寄存器的上电状态，直到硬件或固件用有效的 EUI 初始化寄存器。类似的，当另一个设备或对象的 EUI 被放置在一个协议字段时，可能会使用一个空值，直到学习将有效的 EUI 值放置在协议字段的中为止 。如果方便地使用空值，管理信息库参数也可能面临类似的初始值问题。&lt;/p&gt;\n&lt;p&gt;全零的 EUI-48 值（&lt;code&gt;00-00-00-00-00-00&lt;/code&gt;） 和 EUI-64 （&lt;code&gt;00-00-00-00-00-00-00-00&lt;/code&gt;），虽然被分配给一个组织，但尚未也不会被受让人用作 EUI。（它们可以被认为是分配给 IEEE 注册管理局的）全 1 的 48 位值（&lt;code&gt;FF-FF-FF-FF-FF-FF&lt;/code&gt;）和 64 位值（&lt;code&gt;FF-FF-FF-FF-FF-FF-FF-FF&lt;/code&gt;）是指示网络上所有站点的 IEEE 多播（group）MAC 地址。这些全 1 值不是有效的 EUI。&lt;/p&gt;\n&lt;p&gt;推荐的空值分别为 &lt;code&gt;FF-FF-FF-FF-FF-FF&lt;/code&gt; 和 &lt;code&gt;FF-FF-FF-FF-FF-FF-FF-FF&lt;/code&gt;，作为未知的 EUI-48 和 EUI-64 的默认值。基于零值的 OUI 的值，例如 &lt;code&gt;00-00-00-00-00-00&lt;/code&gt; 和 &lt;code&gt;00-00-00-00-00-00-00-00&lt;/code&gt;，不能用作标识符。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;appropriate-eui-use\&#34;&gt;Appropriate EUI Use&lt;/h2&gt;\n&lt;p&gt;EUI 用于需要固定大小的全局唯一标识符的应用程序。&lt;/p&gt;\n&lt;p&gt;除某些情况外，如协议标识符，受让人将 EUI-48 或 EUI-64 与单个可识别对象（如网络接口）相关联。根据设备支持的功能，它可以使用多个标识符。例如，智能手机可以使用 EUI-48 作为 802.11/ Wi-Fi ® MAC 地址和蓝牙®接口的第二标识符。以太网连接的设备可以有一个 EUI-48 MAC 地址和一个 EUI-64 唯一标识 802.1 AS clock（即，&amp;quot;clockIdentity&amp;quot;）。&lt;/p&gt;\n&lt;p&gt;使用 EUI-64 而不是 EUI-48，以避免在大容量（特别是非联网）应用程序中过度消耗 OUI 值。考虑到使用所有 EUI-64 标识符的可能性极小，IEEE RA 对它们在标准内的使用施加了最小的限制。除非有向后兼容的限制，否则使用 EUI-64 比使用 EUI-48 更可取。但是，为了向后兼容，这种转换对于一些与 IEEE 802 相关的应用程序（例如，需要桥接到 48 位 IEEE 802 网络的新网络）可能是困难的。因此，IEEE 注册委员会将考虑在 802 相关系统中选择性地使用 48 位标识符。详细见下文 &lt;a href=\&#34;#maintaining-longevity-of-eui-48-and-eui-64\&#34;&gt;Maintaining Longevity of EUI-48 and EUI-64&lt;/a&gt; 。&lt;/p&gt;\n&lt;p&gt;EUI-48 和 EUI-64 是由 IEEE 注册的。组织被允许为商业目的有限地使用这些术语。如果这种使用是在标准中指定的特性或功能的标识，或者是声称符合 IEEE 标准，那么没有 IEEE 明确批准的使用是可以接受的，但是术语的其他使用必须由 IEEE RAC 审查和批准。&lt;/p&gt;\n&lt;p&gt;当 EUI 在 IEEE 标准或标准草案中使用时，草案的正确性和清晰度应由 IEEE RAC 进行审查。当 EUI 在非 IEEE 标准中被引用时，标准开发人员应该联系 IEEE RAC 以检查正确的用法。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;maintaining-longevity-of-eui-48-and-eui-64\&#34;&gt;Maintaining Longevity of EUI-48 and EUI-64&lt;/h2&gt;\n&lt;p&gt;可用的 EUI-48 标识符的总数虽然很大，但并不是无穷无尽的。IEEE RAC 有责任与 IEEE 标准和非 IEEE 标准一起促进 EUI-48 能力的持续可用性，以使使用这些标准的全球社区受益。&lt;/p&gt;\n&lt;p&gt;最初，EUI-48 表示仅用于识别实际物理设备的项目（identify item of real physical equipment）、设备的部分（parts of such equipment）或适用于许多实例的物理设备的功能（functions that apply to many instance of physical equipment）。&lt;/p&gt;\n&lt;p&gt;48 位标识符的使用后来得到了扩展，以便它们可以用作协议标识符。通过这种使用，它们确定了物理设备实例之间操作的协议设计和设计修订。与物理设备的项目数量相比，这种协议所需的标识符要少得多。&lt;/p&gt;\n&lt;p&gt;除此类协议标识符外，EUI-48 标识符仍用于标识实际物理设备的项目或此类设备的部分，如可分离子系统或单独寻址的网络端口。每个硬件子系统的预期使用不应超过一个 EUI-48 标识符，或者此类设备的每个物理实例最多不超过非常低数量的 EUI-48 标识符（例如，用于链路聚合的 IEEE Std 802.1 AX 中的端口组）。分配单个 EUI-48 标识符，以识别或允许寻址与物理设备的真实项目相关联的固定和永久功能，这在该设备的整个寿命期间或无限期使用期间发生。&lt;/p&gt;\n&lt;p&gt;任何标准规范，或 EUI 区块的受让人实现或受让人管理，要求对可用的数字空间进行细分，将区块分配给产品类型，或将区块分配给物理设备，而每个 EUI-48 标识符没有可识别的物理实例，或对于编码功能中的重要位或位模式的标识符，有可能迅速耗尽地址空间。为了减耗尽的可能性，强烈鼓励新应用程序和对当前应用程序的延伸，以利用 EUI-64 而不是 EUI-48 来识别硬件实例。IEEE 将审查标准中规定的要求地址格式与现有 EUI-48 设备相匹配的新应用程序，此类例外情况将根据具体情况进行审批。不支持 EUI-48 的非标准使用。&lt;/p&gt;\n&lt;p&gt;IEEE RAC 征求任何关于威胁到唯一的 EUI-48/EUI-64 地址空间的信息，无论是 IEEE 提议的标准还是另一个标准或规范。信息应该发送到 IEEE RAC（ieee-registration-authority@ieee.org）。此外，为了履行保持这些标识符功能寿命的职责，IEEE RAC 将通过联络或直接协调采取行动，以防止潜在的误用 EUI-48。&lt;/p&gt;\n&lt;p&gt;当 IEEE 802 在 1980 年开始工作时，EUI-48 标识符的目标寿命是 100 年。在这个世纪中，超过三分之一的时间里，EUI-48 标识符的使用继续增长，没有迹象表明 EUI-48 地址将在 2080 年过时。因此，IEEE RAC 认为这些限制的一致实施是确保 EUI-48 标识符寿命和基本的现实基础。&lt;/p&gt;\n&lt;p&gt;如果一个实体（无论是否是 IEEE RA 客户），有意或无意地滥用了 IEEE RA 分配，使得 EUI-48/EUI-64 地址或该实体从其 RA 分配中创建的任何其他标识符被分配到其分配之外，则该实体违反了 IEEE RAC 政策。在这种情况下，IEEE RAC 可以建议 IEEE RA 向该实体收取额外费用，以弥补任何潜在的重复和/或组织未来的滥用。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;non-overlapping-assignments\&#34;&gt;Non-Overlapping Assignments&lt;/h2&gt;\n&lt;p&gt;无论应用程序如何，都鼓励受让人只分配一种形式的 EUI-48 或 EUI-64 标识符。换句话说，鼓励组织不要将相同的标识符分配给多个组织的不同最终应用使用。该建议的目的是减少由管理每个组织中多个与上下文相关地址空间的复杂性而可能引入的错误。&lt;/p&gt;\n&lt;p&gt;例如，指定 I/O 驱动程序软件接口、语言代码和硬件型号的 EUI-48 值不应该重叠。同样的，指定 I/O 驱动程序软件接口、语言代码、硬件型号和硬件实例的 EUI-64 值永远不会重叠。虽然可能消耗更多的标识符值，但是通过消除主观的应用程序类判断，这种不重叠策略有望减少标识符值的无意重复。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;ieee-ra-policies-to-reduce-the-volume-of-unused-eui-48s\&#34;&gt;IEEE RA Policies to Reduce the Volume of Unused EUI-48s&lt;/h2&gt;\n&lt;p&gt;MA-L 分配包括超过 1600 万个（2&lt;sup&gt;24&lt;/sup&gt;） EUI-48 值。为了减少未使用 EUI-48 的发生（例如，当受让人需要远远少于 1600 万 EUI-48 时），IEEE RAC 在第一次引入 CID 时制定了以下分配 MA-L、MA-M、MA-S 和 CID 标识符的策略：&lt;/p&gt;\n&lt;ol&gt;\n&lt;li&gt;首次客户（即受让人）不能购买 MA-L。第一次需要 24 位公司/组织标识符的客户可以购买 CID，而第一次需要 EUI-48  或 EUI-64（或废弃标识符）的客户可以购买 MA-M 或 MA-S，具体取决于客户需要多少特定标识符。这个策略的例外必须由 IEEE RAC 审查。&lt;/li&gt;\n&lt;li&gt;回头客（即以前购买过 MA-L、MA-M、MA-S 和/或 CID 的客户）可以购买任意标识符块大小，受以下限制：\n&lt;ol&gt;\n&lt;li&gt;如果当前 EUI-48 的 MA-L 或 MA-M 分配的 95% 被使用，IEEE 注册机构将接受额外的分配申请。这同样适用于 2014 年 1 月之前发布的 OUI 转让。当现有 EUI-48 大部分已用完时，可能会发出额外的转让。客户必须同意，在之前的 EUI-48 配额用完之前，不得使用新的配额生产产品。这适用于所有注册表分配。&lt;/li&gt;\n&lt;li&gt;一个客户有一个 MA-L （2014 年 1 月 1 日或之前，是的）或 CID 分配，不应该需要购买新的公司标识，但有资格购买新 CID 用作其他用途，例如，当电流 CID 作业提供了 ELI 地址空间不足。&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/li&gt;\n&lt;/ol&gt;\n&lt;p&gt;由 IEEE 管理的组织标识符标识管理级联的扩展标识符以创建例如 EUI 的组织。不应孤立地使用 IEEE 管理的标识符来表示公司或组织的一个部门或类似部分。当受让人认为有必要识别这样的内部组时，可以使用 EUI-48 或 EUI-64 标识符。（使用一些扩展位标识部门或产品的受让人，管理实践并不能免除受让人使用上述大多数 EUI-48 值的要求。）类似的，标准开发组织中的组也可以由其发起组织管理的不同 EUI-48 （或 EUI-64）标识符标识。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;mapping-an-eui-48-to-an-eui-64\&#34;&gt;Mapping an EUI-48 to an EUI-64&lt;/h2&gt;\n&lt;p&gt;不支持将 EUI-48 映射到 EUI-64。这里描述映射是出于历史原因。&lt;/p&gt;\n&lt;p&gt;将一个分配了 MA-S/OUI-36 或 MA-M 的 EUI-48 映射到一个 EUI-64 可能会创建一个分配了不同 MA-S/OUI-36 或 MA-M 的 EUI-64 的副本。IEEE RA 已经采取了适当的措施来减少基于此映射的副本创建，但是，为了保护 EUI-64 标识符的完整性，不建议使用此映射。&lt;/p&gt;\n&lt;p&gt;一些标准已经描述了如何将一个 EUI-48 的值映射到 EUI-64，具体如下：设 EUI-48 的六个 octet 被标记位 eui48[0] 到 eui48[5]。设映射的 EUI-64 的八个 octet 被标记为 eui64[0] 到 eui64[7]。对应关系描述如下：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;eui64[0] = eui48[0]&lt;/li&gt;\n&lt;li&gt;eui64[1] = eui48[1]&lt;/li&gt;\n&lt;li&gt;eui64[2] = eui48[2]&lt;/li&gt;\n&lt;li&gt;eui64[3] = FFhex&lt;/li&gt;\n&lt;li&gt;eui64[4] = FEhex or eui64[4] = FFhex&lt;/li&gt;\n&lt;li&gt;eui64[5] = eui48[3]&lt;/li&gt;\n&lt;li&gt;eui64[6] = eui48[4]&lt;/li&gt;\n&lt;li&gt;eui64[7] = eui48[5]&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;换句话说，eui48[2] 和 eui48[3] 之间插入 &lt;code&gt;FF-FE&lt;/code&gt;hex 值或 &lt;code&gt;FF-FF&lt;/code&gt;hex 值生成 EUI-64 值。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;other-worldwide-identifiers-based-on-eui\&#34;&gt;Other worldwide identifiers based on EUI&lt;/h2&gt;\n&lt;p&gt;WWN（World Wide Names）有部分格式来源于 EUI-48 或 EUI-64。WWN 在 SCSI 和相关协议中用作磁盘和端点地址。请参阅最新的 INCITS SATA 和 SAS 标准以了解更多细节。&lt;/p&gt;\n&lt;p&gt;来自 EUI-64 的 IPv6 地址定义在 IETF RFC 4291，附录a。请参见 IETF RFC 2460、5952 和 6052。&lt;/p&gt;\n&lt;p&gt;UUID 寻址由 EUI-64 地址和 OUI 派生，在 ITU-T X.667 的 IETF RFC 4122 中定义。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;context-dependent-identifiers\&#34;&gt;Context dependent identifiers&lt;/h2&gt;\n&lt;p&gt;就像 OUI 可以扩展为创建 EUI-48 和 EUI-64 标识符，或者 CID 可以扩展为创建本地管理的 MAC 地址一样，其他扩展标识符也可以从 OUI 或 CID 分配中创建。这样的扩展标识符，称为上下文依赖标识符（Context Dependent Identifier，CDI），不一定是全局唯一的，但只在指定上下文中是唯一的。&lt;/p&gt;\n&lt;p&gt;上下文依赖标识符（Context Dependent Identifier，CDI）是基于 OUI、CID 或 OUI-36 的扩展标识符，通常在带有附加规范的标准中指定，以允许对标识符的明确解释和对其他数据的解析。一些例子包括（但不限于）：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;在一个标准中定义上下文依赖标识符的所有字段。例如，使用 OUI 或 CID 来标识硬件制造商，以及表示硬件型号和版本的附加字段。（OUI 或 CID 所有者通常在标准指定的范围内为附加字段分配值。）如果正确定义，这样的标识符在标准上下文中是唯一的。&lt;/li&gt;\n&lt;li&gt;在标准中定义特定于供应商的管理信息扩展，但允许唯一标识符的受让人指定附加字段。这个扩展标识符在定义的管理信息库上下文中是唯一的。&lt;/li&gt;\n&lt;li&gt;特定于供应商的协议可以通过 OUI/CID 进行识别，标准定义的固定字段允许识别来自同一供应商的多个协议；或使用 OUI/CID 指示用来解析 OUI/CID 之后的数据的规则集。&lt;/li&gt;\n&lt;li&gt;CDI-32 和 CDI-40 的遗留定义（参见 &lt;a href=\&#34;#deprecated-and-obsolete-identifiers\&#34;&gt;Deprecated and Obsolete Identifiers&lt;/a&gt; ）。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;restrictions-on-the-use-of-context-dependent-identifiers\&#34;&gt;Restrictions on the Use of Context Dependent Identifiers&lt;/h2&gt;\n&lt;p&gt;除非与 22 位公司标识的遗留定义兼容，否则在创建上下文依赖标识符时，OUI 被用作 24 位字段。在这种情况下，CID 应作为 OUI 的有效替代品。上下文相关标识符的规范应该允许使用 OUI 或 CID 作为上下文相关标识符的基础。&lt;/p&gt;\n&lt;p&gt;对于那些指定上下文依赖标识符的人，需要注意以下事项：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;如果准确地定义要求扩展标识符的分配必须在上下文是唯一的，那么就存在处于不同目的无意中重新使用现有标识符分配的危险，导致分配值使用的模糊性；&lt;/li&gt;\n&lt;li&gt;如果选择的扩展标识符的大小相对于在单个 OUI/CID 下需要分配的标识符值的实际数量较小，那么结果可能是 OUI/CID 值的消耗率不可接受。并且 OUI 的所有者可能难以满足注册机构的要求，也就是说在使用进一步的分配之前，他们现有的 OUI 所代表的块分配的 95% 需要被消耗掉；&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;因此，上下文相关的标识符的使用是可以接受的，但必须满足以下所有要求：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;相关标准中明确定义了上下文相关标识符使用的上下文，以及要求标识符值在上下文中唯一。&lt;/li&gt;\n&lt;li&gt;所选扩展标识符的大小足以容纳在定义的上下文中单个 OUI 下分配不同值的所有可能的需求。&lt;/li&gt;\n&lt;li&gt;IEEE RAC 已经批准了标识符和将使用它的上下文的定义。&lt;/li&gt;\n&lt;li&gt;描述提议的上下文相关标识符机器提议应用的标准草案或工作组材料应提交给 IEEE RAC。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;deprecated-and-obsolete-identifiers\&#34;&gt;Deprecated and Obsolete Identifiers&lt;/h2&gt;\n&lt;p&gt;对于“已弃用（deprecated）”这个词，IEEE 并没有一个标准的定义。当被 IEEE RA 或 IEEE RAC 使用时，术语 &lt;code&gt;deprecated&lt;/code&gt; 意味着它所描述的项目（例如，标识符(identifier)、映射(mapping)、需求(requirement)、推荐(recommendation)、过程(process) 等）不应用与任何新的应用程序。如果合理，遗留使用可以保存在 revision 或 amendment 中（例如，修订不会将不一致性引入标准中。）当术语发生变化时，应该尽快更新使用当前术语并删除已弃用的术语。此外，除符合相关标准外，新设备和新设计不得使用废弃项目，除非符合相关标准。不需要修改现有设备和部署的设备来不使用不赞成使用的项目。&lt;/p&gt;\n&lt;p&gt;过去使用的一些标识符和术语，包括一些由 IEEE 管理的标识符创建的标识符(即，由分配了 IEEE 管理标识符的组织创建的标识符)，现在已被弃用或废弃。这些标识符和术语包括独立地址块（IAB）、基于 OUI 的 22 位标识符、MAC-48 标识符和 EUI-60。这些标识符将在下面的小节中进行简要描述。&lt;/p&gt;\n&lt;h3 id=\&#34;iab-based-identifiers\&#34;&gt;IAB Based Identifiers&lt;/h3&gt;\n&lt;p&gt;不再分配 36 位的 IAB 标识符。IAB 分配的是 4096 个 MAC-48 地址块（现在称为 EUI-48）。基本的 24 位 OUI 被分配给 IEEE RA，IEEE RA 分配的附加 12 位扩展产生地址块的前 36 位。然后，4096 个 EUI-48 标识符随后由受让人通过另外一个 12 位与 36 位 IAB 基数连接而创建。&lt;/p&gt;\n&lt;p&gt;IAB 只能用于指定 EUI-48 标识符；使用用于创建 IAB 的 24 位 OUI 值创建的任何其他标识符仍然是 IEEE RA 的财产。此外，IAB 不能用于使用分配给受让人的 36 位来创建任何其他标识符（例如，受让人不能通过将 28 位附加到它已被分配的 IAB 标识符来创建 EUI-64）。&lt;/p&gt;\n&lt;p&gt;虽然 IEEE RA 不保证 36 位 IAB 标识符总是从相同的 OUI 创建的，但所有 IAB 分配实际上都是从两个特定的 OUI 创建的：&lt;code&gt;00-50-C2&lt;/code&gt;hex 和 &lt;code&gt;40-D8-55&lt;/code&gt;hex。使用前者知道基于它的所有 IAB 都被分配，然后使用后者。&lt;/p&gt;\n&lt;p&gt;IAB 和 MA-S 的 EUI-48 用法是相同的，因此被分配了 IAB 的组织可以继续按照最初的意图使用它。向 IEEE RA 提出的任何新的 IAB 请求都将通过分配 MA-S 来完成。&lt;/p&gt;\n&lt;p&gt;展望未来，现有的 IAB 公开列表将作为历史注册表进行维护。因为没有新的 IAB 会被分配，因此 IAB 注册表不会增加。&lt;/p&gt;\n&lt;h3 id=\&#34;22-bit-oui-based-identifiers\&#34;&gt;22-Bit OUI-Based Identifiers&lt;/h3&gt;\n&lt;p&gt;虽然 OUI 始终被指定为 24 位值，但过去指定了各种可选的上下文相关的标识符。一些标准规定只能使用 OUI 的 22 位（去掉 M 和 X 位）。不赞成这种用途。所有使用 OUI 的新规范，除网络寻址外，应使用 IEEE RA 指定的所有 24 为 OUI。这允许使用 OUI 或 CID。&lt;/p&gt;\n&lt;h3 id=\&#34;mac-48\&#34;&gt;MAC-48&lt;/h3&gt;\n&lt;p&gt;MAC-48 这个术语现在已经过时了。MAC-48 类似于 EUI-48，也就是说，它是一个由 IEEE RA 分配的 24 位 OUI 和一个由组织分配的 24 位扩展标识符的串联。然而，它被用来处理现有的基于 802 的网络应用程序中寻址硬件接口。术语EUI-48在历史上用于标识设计实例，与硬件接口相对；示例包括软件接口标准（如 VGA）、产品型号以及供应商特定内容的形式/功能。MAC-48 和 EUI-48 之间的细微差别尚不清楚，因此 EUI-48 一词现在用于两种用途，MAC-48 标识符一词现在已经过时了。（IEEE RAC 不了解任何情况，但是如果 MAC-48 用作任何 48 位 MAC 地址的名称，那么 EUI-48 不是 MAC-48 的合适替代术语，因为 EUI-48 仅指单独的、全球唯一的网络地址。）&lt;/p&gt;\n&lt;h3 id=\&#34;eui-60\&#34;&gt;EUI-60&lt;/h3&gt;\n&lt;p&gt;EUI-60 不应用于未来的应用。在可预见的未来，没有计划取消这些 EUI-60 值的使用。EUI-64 （与 EUI-60 相反）标识符应该在未来的应用程序、未来的标准以及现有标准的 revisions 和 amendments 中使用，这些标准要求每个硬件使用唯一的实例标识符。&lt;/p&gt;\n&lt;h3 id=\&#34;cdi-32-and-cdi-40\&#34;&gt;CDI-32 and CDI-40&lt;/h3&gt;\n&lt;p&gt;CDI-32 和 CDI-40 历史上被推荐作为上下文依赖的标识符。&lt;/p&gt;\n&lt;p&gt;历史上，CDI-32 是由 IEEE RA 分配的 OUI 值和由该组织分配的 8 位扩展标识符的串联。&lt;/p&gt;\n&lt;p&gt;历史上，CDI-40 是由 IEEE RA 分配的 OUI 值和由该组织分配的 16 位扩展标识符的串联。&lt;/p&gt;\n&lt;hr&gt;\n&lt;p&gt;来源：https://standards.ieee.org/wp-content/uploads/import/documents/tutorials/eui.pdf&lt;/p&gt;\n&#34;,&#34;fileName&#34;:&#34;guidelines-for-use-of-extended-unique-identifiereui-organizationally-unique-identifieroui-and-company-idcid&#34;,&#34;abstract&#34;:&#34;&lt;h2 id=\&#34;abstract\&#34;&gt;Abstract&lt;/h2&gt;\n&lt;p&gt;本教程介绍由 IEEE 注册结构（IEEE RA, IEEE Registration Authority）分配的组织标识符（origanizational identifiers）以及基于它们的扩展标识符（extended identifiers）。它涵盖了与受让人以及标准开发人员相关的标识符格式（identifier formats）、assignment（分配）、指导方针（guidelines）和策略（policies）。本教程包括与组织标识符（如组织唯一标识符（Organizational Unique Identifier，OUI）和公司 ID（Company ID），以及扩展标识符（Extended Unique Identifier，EUI）和扩展本地标识符（Extended Local Identifier，ELI））相关的信息。&lt;/p&gt;\n&#34;,&#34;title&#34;:&#34;Guidelines for Use of Extended Unique Identifier(EUI), Organizationally Unique Identifier(OUI), and Company ID(CID)&#34;,&#34;tags&#34;:[{&#34;index&#34;:-1,&#34;name&#34;:&#34;TCP/IP&#34;,&#34;slug&#34;:&#34;NhO-Hr8Eu&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://wenbozhangw.github.io/tag/NhO-Hr8Eu/&#34;}],&#34;date&#34;:&#34;2022-04-23 21:38:23&#34;,&#34;dateFormat&#34;:&#34;2022-04-23&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://wenbozhangw.github.io/post/guidelines-for-use-of-extended-unique-identifiereui-organizationally-unique-identifieroui-and-company-idcid/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;38 min read&#34;,&#34;time&#34;:2224000,&#34;words&#34;:9396,&#34;minutes&#34;:38},&#34;description&#34;:&#34;Abstract\n本教程介绍由 IEEE 注册结构（IEEE RA, IEEE Registration Authority）分配的组织标识符（origanizational identifiers）以及基于它们的扩展标识符（extende...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#abstract\&#34;&gt;Abstract&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#status-and-history\&#34;&gt;Status and History&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#contents\&#34;&gt;Contents&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#ieee-administered-organizational-identifiers-oui-and-cid\&#34;&gt;IEEE-Administered organizational identifiers: OUI and CID&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#oui\&#34;&gt;OUI&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#oui-36\&#34;&gt;OUI-36&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#cid\&#34;&gt;CID&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#extended-identifiers\&#34;&gt;Extended Identifiers&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#extended-unique-identifiers\&#34;&gt;Extended Unique Identifiers&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#extended-local-identifiereli\&#34;&gt;Extended Local Identifier（ELI）&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#ieee-ra-assignment-of-identifiers\&#34;&gt;IEEE RA assignment of identifiers&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#eui-structure-and-representation\&#34;&gt;EUI Structure and Representation&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#eui-bit-ordering\&#34;&gt;EUI Bit Ordering&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#unassigned-and-null-eui-values\&#34;&gt;Unassigned and NULL EUI values&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#appropriate-eui-use\&#34;&gt;Appropriate EUI Use&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#maintaining-longevity-of-eui-48-and-eui-64\&#34;&gt;Maintaining Longevity of EUI-48 and EUI-64&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#non-overlapping-assignments\&#34;&gt;Non-Overlapping Assignments&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#ieee-ra-policies-to-reduce-the-volume-of-unused-eui-48s\&#34;&gt;IEEE RA Policies to Reduce the Volume of Unused EUI-48s&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#mapping-an-eui-48-to-an-eui-64\&#34;&gt;Mapping an EUI-48 to an EUI-64&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#other-worldwide-identifiers-based-on-eui\&#34;&gt;Other worldwide identifiers based on EUI&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#context-dependent-identifiers\&#34;&gt;Context dependent identifiers&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#restrictions-on-the-use-of-context-dependent-identifiers\&#34;&gt;Restrictions on the Use of Context Dependent Identifiers&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#deprecated-and-obsolete-identifiers\&#34;&gt;Deprecated and Obsolete Identifiers&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#iab-based-identifiers\&#34;&gt;IAB Based Identifiers&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#22-bit-oui-based-identifiers\&#34;&gt;22-Bit OUI-Based Identifiers&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#mac-48\&#34;&gt;MAC-48&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#eui-60\&#34;&gt;EUI-60&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#cdi-32-and-cdi-40\&#34;&gt;CDI-32 and CDI-40&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;h2 id=\&#34;21-引言\&#34;&gt;2.1 引言&lt;/h2&gt;\n&lt;p&gt;本章介绍了 Internet 中使用的网络层地址，又称为 IP 地址。我们讨论了如何为 Internet 中的设备分配地址，有助于路由可扩展性的地址层次结构分配方式，以及特殊用途的地址，包括广播、组播和任播地址。我们还讨论了 IPv4 和 IPv6 地址结构和用途的区别。&lt;/p&gt;\n&lt;!-- more --&gt;\n&lt;p&gt;连接到 Internet 的每个设备至少有一个 IP 地址。基于 TCP/IP 协议的专用网络中使用的设备也需要 IP 地址。在任何情况下， IP 路由器（见第 5 章）实现的转发程序使用 IP 地址来识别流量去向。 IP 地址也表示流量来源。 IP 地址在某些方面与电话号码相似，但最终用户通常知道并直接使用电话号码，而IP 地址通常被 Internet 中的 DNS （见第11章）屏蔽在用户视线之外， DNS 让大多数用户使用名字而不是数字地址。当用户需要自已建立网络或 DNS 由于某种原因失效时，用户需要直接处理 IP 地址。为了了解 Internet 如何识别主机和路由器，并在它们之间实现流量的交付，我们必须了解 IP 地址的作用。因此，我们对它们的管理、结构和用途感兴趣。&lt;/p&gt;\n&lt;p&gt;当一台设备连接到全球性的 Internet 时，为它们分配地址就必须经过协调，这样就不会重复使用网络中的其他地址。对于专用网络，使用的 IP 地址必须经过协调，以避免在专用网络中出现类似的重复。成组的 IP 地址被分配给用户和组织。这些地址的拥有者再将它们&lt;strong&gt;分配&lt;/strong&gt;给设备，这通常根据某些“编号方案”进行。对于全球性的 Internet 地址，一个分层结构管理实体帮助用户和服务提供商分配地址。个人用户通常由 **Internet服务提供商（ ISP ）**分配地址，通过支付费用来获得地址和执行路由。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;22-表示-ip-地址\&#34;&gt;2.2 表示 IP 地址&lt;/h2&gt;\n&lt;p&gt;大多数 Internet 用户熟悉IP地址，并且了解最流行的地址类型：IPv4 地址。这些地址通常采用所谓的点分四组或点分十进制表示法，例如 &lt;code&gt;165.195.130.107&lt;/code&gt;。点分四组表示法由四个用点分隔的十进制数组成。每个这样的数字是一个非负整数，范围为 &lt;code&gt;[0， 255]&lt;/code&gt;，代表整个 IP 地址的四分之一。点分四组表示法是编写完整的 IPv4 地址（一个用于 Internet 系统的 32 位非负整数）的简单方式，它使用便捷的十进制数。在很多情况下，我们将关注这种地址的二进制结构。很多 Internet 站点，例如 &lt;a href=\&#34;http://www.subnetmask.info\&#34;&gt;http://www.subnetmask.info&lt;/a&gt; 和 &lt;a href=\&#34;http://www.subnetcalculator.com\&#34;&gt;http://www.subnetcalculator.com&lt;/a&gt; ，包含用于 IP 地址和相关信息之间格式转换的计算器。表2-1给出了几个 IPv4 地址的例子，以及对应的二进制表示，供大家开始学习。&lt;/p&gt;\n&lt;center&gt; 表 2-1 用点分四组和二进制表示法写的 IPv4 地址 &lt;/center&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;点分四组表示&lt;/th&gt;\n&lt;th&gt;二进制表示&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;0.0.0.0&lt;/td&gt;\n&lt;td&gt;00000000 00000000 00000000 00000000&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;1.2.3.4&lt;/td&gt;\n&lt;td&gt;00000001 00000010 00000011 00000100&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;10.0.0.255&lt;/td&gt;\n&lt;td&gt;00001010 00000000 00000000 11111111&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;255.255.255.255&lt;/td&gt;\n&lt;td&gt;11111111 11111111 11111111 11111111&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;p&gt;在 IPv6 中，地址的长度是 128 位，是 IPv4 地址长度的 4 倍。一般来说，大多数用户对它不太熟悉。 IPv6 地址的传统表示方法是采用称为&lt;strong&gt;块&lt;/strong&gt;或&lt;strong&gt;字段&lt;/strong&gt;的四个十六进制数，这些被称为块或字段的数由冒号分隔。例如，一个包含 8 个块的 IPv6 地址可写为&lt;code&gt;5f05:2000:80ad:5800:0058:0800:2023:1d71&lt;/code&gt; 。虽然不像用户熟悉的十进制数，但将十六进制数转换为二进制更容易。另外，一些已取得共识的 IPv6 地址简化表示法已被标准化 [&lt;a href=\&#34;#RFC4291\&#34;&gt;RFC4291&lt;/a&gt;] ：&lt;/p&gt;\n&lt;ol&gt;\n&lt;li&gt;一个块中前导的零不必书写。在前面的例子中，地址可写为 &lt;code&gt;5f05:2000:80ad:5800:58:800:2023:1d71&lt;/code&gt; 。&lt;/li&gt;\n&lt;li&gt;全零的块可以省略，并用符号 &lt;code&gt;::&lt;/code&gt; 代替。例如，地址 &lt;code&gt;0:0:0:0:0:0:0:1&lt;/code&gt; 可简写为 &lt;code&gt;::1&lt;/code&gt;。同样，地址 &lt;code&gt;2001:0db8:0:0:0:0:0:2&lt;/code&gt; 可简写为 &lt;code&gt;2001:0db8::2&lt;/code&gt; 。为了避免出现歧义，一个 IPv6 地址中符号 &lt;code&gt;::&lt;/code&gt; 只能使用一次。&lt;/li&gt;\n&lt;li&gt;在 IPv6 格式中嵌入 IPv4 地址可使用混合符号形式，紧接着 IPv4 部分的地址块的值为 &lt;code&gt;ffff&lt;/code&gt;，地址的其余部分使用点分四组格式。例如，IPv6 地址 &lt;code&gt;::ffff:10.0.0.1&lt;/code&gt; 可表示 IPv4 地址 &lt;code&gt;10.0.0.1&lt;/code&gt;。它被称为 &lt;strong&gt;IPv4 映射的 IPv6 地址&lt;/strong&gt;。&lt;/li&gt;\n&lt;li&gt;IPv6 地址的低 32 位通常采用点分四组表示法。因此，IPv6 地址 &lt;code&gt;::0102:f001&lt;/code&gt; 相当于地址 &lt;code&gt;::1.2.240.1&lt;/code&gt;。它被称为 &lt;code&gt;IPv4 兼容的 IPv6 地址&lt;/code&gt;。需要注意，IPv4 兼容地址与 IPv4 映射地址不同；它们只是在能用类似 IPv4 地址的方式书写或由软件处理方面给人以兼容的感觉。这种地址最初用于 IPv4 和 IPv6 之间的过渡计划，但现在不再需要 [&lt;a href=\&#34;#RFC4291\&#34;&gt;RFC4291&lt;/a&gt;] 。&lt;/li&gt;\n&lt;/ol&gt;\n&lt;p&gt;表 2-2 介绍了一些 IPv6 地址的例子以及它们的二进制表示。&lt;/p&gt;\n&lt;center&gt; 表 2-2  IPv6 地址和它的二进制表示的几个例子 &lt;/center&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;十六进制表示&lt;/th&gt;\n&lt;th&gt;二进制表示&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;5f05:2000:80ad:5800:0058:0800:2023:1d71&lt;/td&gt;\n&lt;td&gt;0101111100000101 0010000000000000 1000000010101101 0101100000000000 0000000001011000 0000100000000000 0010000000100011 0001110101110001&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;::1&lt;/td&gt;\n&lt;td&gt;0000000000000000 0000000000000000 0000000000000000 0000000000000000 0000000000000000 0000000000000000 0000000000000000 0000000000000001&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;::1.2.240.1 或 ::102:f001&lt;/td&gt;\n&lt;td&gt;0000000000000000 0000000000000000 0000000000000000 0000000000000000 0000000000000000 0000000000000000 0000000100000010 1111000000000001&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;p&gt;在某些情况下（例如表示一个包含地址的 URL 时），IPv6 地址中的冒号分隔符可能与其他分隔符混淆，例如 IP 地址和端口号之间使用的冒号。在这种情况下，用括号字符 &lt;code&gt;[&lt;/code&gt; 和 &lt;code&gt;]&lt;/code&gt; 包围 IPv6 地址。例如， URL&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;http://[2001:0db8:85a3:08d3:1319:8a2e:0370:7344]:443/\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;是指IPv6主机 &lt;code&gt;2001:0db8:85a3:08d3:1319:8a2e:0370:7344&lt;/code&gt; 中的端口号 443 使用 HTTP、 TCP 和 IPv6 协议。&lt;/p&gt;\n&lt;p&gt;[&lt;a href=\&#34;#RFC4291\&#34;&gt;RFC4291&lt;/a&gt;] 提供的灵活性造成了不必要的混淆，这是因为能用多种方式表示相同的 IPv6 地址。为了弥补这种情况，[&lt;a href=\&#34;#RFC5952\&#34;&gt;RFC5952&lt;/a&gt;] 制定了一些规则，以缩小选择范围，同时与 [&lt;a href=\&#34;#RFC4291\&#34;&gt;RFC4291&lt;/a&gt;] 保持兼容。这些规则如下：&lt;/p&gt;\n&lt;ol&gt;\n&lt;li&gt;前导的零必须压缩（例如，&lt;code&gt;2001:0db8::0022&lt;/code&gt; 编程 &lt;code&gt;2001:db8::22&lt;/code&gt;）。&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;::&lt;/code&gt;  只能用于影响最大的地方（压缩最多的零），但并不只是针对 16 位的块。如果多个块中包含等长度的零，顺序靠前的块将被替换为 &lt;code&gt;::&lt;/code&gt; 。&lt;/li&gt;\n&lt;li&gt;a 到 f 的十六进制数字应该用小写表示。&lt;/li&gt;\n&lt;/ol&gt;\n&lt;p&gt;在大多数情况下，我们会遵守这些规则。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;23-基本的-ip-地址结构\&#34;&gt;2.3 基本的 IP 地址结构&lt;/h2&gt;\n&lt;p&gt;IPv4 地址空间中有 &lt;code&gt;4 294 967 296&lt;/code&gt; 个可能的地址，而 IPv6 的地址个数为&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;340 282 366 920 938 463 463 374 607 431 768 211 456\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;由于拥有大量地址（特别是 IPv6），可以方便地将地址空间划分成块。IP 地址可根据类型和大小分组。大多数 IPv4 地址块最终被细分为一个地址，用于识别连接 Internet 或某些专用的内联网的计算机网络接口。这些地址称为&lt;strong&gt;单播&lt;/strong&gt;地址。 IPv4 地址空间中大部分是单播地址空间。 IPv6 地址空间中大部分目前未使用。除了单播地址，其他类型的地址包括广播、组播和任播地址，它们可能涉及多个接口，还有一些特殊用途的地址，我们将在后面讨论它们。在开始介绍当前地址结构的细节之前，理解 IP 地址的历史演变是有用的。&lt;/p&gt;\n&lt;h3 id=\&#34;231-分类寻址\&#34;&gt;2.3.1 分类寻址&lt;/h3&gt;\n&lt;p&gt;当最初定义 Internet 地址结构时，每个单播 IP 地址都有一个网络部分，用于识别接口使用的 IP 地址在哪个网络中可被发现；以及一个主机地址，用于识别由网络部分给出的网络中的特定主机。因此，地址中的一些连续位称为&lt;strong&gt;网络号&lt;/strong&gt;，其余位称为&lt;strong&gt;主机号&lt;/strong&gt;。当时，大多数主机只有一个网络接口，因此术语&lt;strong&gt;接口地址&lt;/strong&gt;和&lt;strong&gt;主机地址&lt;/strong&gt;有时交替使用。&lt;/p&gt;\n&lt;p&gt;现实中的不同网络可能有不同数量的主机，每台主机都需要一个唯一的 IP 地址。一种划分方法是基于当前或预计的主机数量，将不同大小的 IP 地址空间分配给不同的站点。地址空间的划分涉及五大&lt;strong&gt;类&lt;/strong&gt;。每类都基于网络中可容纳的主机数量，确定在一个 32 位的 IPv4 地址中分配给网络号和主机号的位数。图 2-1 显示了这个基本思路。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;1\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1650619000045.png\&#34; alt=\&#34;图 2-1\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 2-1 IPv4 地址空间最初分为五大类。A、B、C 类用于为 Internet （单播地址）中的接口分配地址，以及其他一些特殊情况下使用。类由地址中的头几位来定义：&lt;code&gt;0&lt;/code&gt; 为 A 类，&lt;code&gt;10&lt;/code&gt; 为 B 类，&lt;code&gt;110&lt;/code&gt; 为 C 类等。D 类地址供组广播使用（见第 9 章），E 类地址保留&lt;/p&gt;\n&lt;p&gt;这里，我们看到5个类被命名为 A、 B、 C、 D 和 E。 A、 B、 C 类空间用于单播地址。如果我们仔细看这些地址结构，可看到不同类的相对大小，以及在实际使用中的地址范围。表 2-3 给出了这种类结构（有时被称为&lt;strong&gt;分类地址&lt;/strong&gt;结构）。&lt;/p&gt;\n&lt;center&gt; 表 2-3 最初（“分类”）的 IPv4 地址空间划分&lt;/center&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;类&lt;/th&gt;\n&lt;th&gt;地址范围&lt;/th&gt;\n&lt;th&gt;高序位&lt;/th&gt;\n&lt;th&gt;用途&lt;/th&gt;\n&lt;th&gt;百分比&lt;/th&gt;\n&lt;th&gt;网络数&lt;/th&gt;\n&lt;th&gt;主机数&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;A&lt;/td&gt;\n&lt;td&gt;0.0.0.0 ~ 127.255.255.255&lt;/td&gt;\n&lt;td&gt;0&lt;/td&gt;\n&lt;td&gt;单播/特殊&lt;/td&gt;\n&lt;td&gt;1/2&lt;/td&gt;\n&lt;td&gt;128&lt;/td&gt;\n&lt;td&gt;16777216&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;B&lt;/td&gt;\n&lt;td&gt;128.0.0.0 ~ 191.255.255.255&lt;/td&gt;\n&lt;td&gt;10&lt;/td&gt;\n&lt;td&gt;单播/特殊&lt;/td&gt;\n&lt;td&gt;1/4&lt;/td&gt;\n&lt;td&gt;16384&lt;/td&gt;\n&lt;td&gt;65536&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;C&lt;/td&gt;\n&lt;td&gt;192.0.0.0 ~ 223.255.255.255&lt;/td&gt;\n&lt;td&gt;110&lt;/td&gt;\n&lt;td&gt;单播/特殊&lt;/td&gt;\n&lt;td&gt;1/8&lt;/td&gt;\n&lt;td&gt;2097152&lt;/td&gt;\n&lt;td&gt;256&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;D&lt;/td&gt;\n&lt;td&gt;224.0.0.0 ~ 239.255.255.255&lt;/td&gt;\n&lt;td&gt;1110&lt;/td&gt;\n&lt;td&gt;组播&lt;/td&gt;\n&lt;td&gt;1/16&lt;/td&gt;\n&lt;td&gt;N/A&lt;/td&gt;\n&lt;td&gt;N/A&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;E&lt;/td&gt;\n&lt;td&gt;240.0.0.0 ~ 255.255.255.255&lt;/td&gt;\n&lt;td&gt;1111&lt;/td&gt;\n&lt;td&gt;保留&lt;/td&gt;\n&lt;td&gt;1/16&lt;/td&gt;\n&lt;td&gt;N/A&lt;/td&gt;\n&lt;td&gt;N/A&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;p&gt;该表显示了分类地址结构的主要使用方式，如何将不同大小的单播地址块分配给用户。类划分基于给定大小的可用网络数和给定网络中的可分配主机数之间的折中。例如，某个站点分配了一个A类网络号 &lt;code&gt;18.0.0.0 &lt;/code&gt;(MIT)，其中有 2&lt;sup&gt;24&lt;/sup&gt; 个地址分配给主机（即 IPv4 地址使用范围 &lt;code&gt;18.0.0.0 ~ 18.255.255.255&lt;/code&gt;），但在整个 Internet 中只有 127 个A类网络。某个站点分配了一个 C 类网络号，例如 &lt;code&gt;192.125.3.0&lt;/code&gt;，只能容纳 256 台主机（也就是说在范围 &lt;code&gt;192.125.3.0 ~ 192.125.3.255&lt;/code&gt; 内），但有超过 200 万的 C 类网络号是可用的。&lt;/p&gt;\n&lt;p&gt;注意  这些数字是不准确的。有几个地址通常不作为单播地址使用。特别是，地址块中的第一个和最后一个地址通常不使用。在我们的例子中，站点分配的地址块为 &lt;code&gt;18.0.0.0&lt;/code&gt;，实际能分配多达 2&lt;sup&gt;24&lt;/sup&gt; - 2 = 16777214 个单播IP地址。&lt;/p&gt;\n&lt;p&gt;Internet 地址分类方法在经历 Internet 增长（20 世纪 80年代）的第一个十年中没有变化。此后，它开始出现规模问题，当每个新的网段被添加到 Internet 中，集中协调为其分配一个新的 A 类、B 类或 C 类网络号变得很不方便。另外， A 类和 B 类网络号通常浪费太多主机号，而 C 类网络号不能为很多站点提供足够的主机号。&lt;/p&gt;\n&lt;h3 id=\&#34;232-子网寻址\&#34;&gt;2.3.2 子网寻址&lt;/h3&gt;\n&lt;p&gt;Internet 发展初期首先遇到一个困难，那就是很难为接入 Internet 的新网段分配一个新的网络号。在 20 世纪 80 年代初，随着局域网（LAN）的发展和增加，这个问题变得更棘手。为了解决这个问题，人们很自然想到一种方式，在一个站点接入 Internet 后为其分配一个网络号，然后由站点管理员进一步划分本地的子网数。在不改变 Internet 核心路由基础设施的情况下解决这个问题将会更好。&lt;/p&gt;\n&lt;p&gt;实现这个想法需要改变一个 IP 地址的网络部分和主机部分的限制，但这样做只是针对一个站点自身而言； Internet 其余部分将只能“看到”传统的 A 类、 B 类和 C 类部分。支持此功能的方法称为 &lt;strong&gt;子网寻址&lt;/strong&gt; [&lt;a href=\&#34;#RFCO950\&#34;&gt;RFCO950&lt;/a&gt;] 。通过子网寻址，一个站点被分配一个 A 类、 B 类或 C 类的网络号，保留一些剩余主机号进一步用于站点内分配。该站点可能将基础地址中的主机部分进一步划分为一个子网号和一个主机号。从本质上来说，子网寻址为 IP 地址结构增加了一个额外部分，但它没有为地址增加长度。因此，一个站点管理员能在子网数和每个子网中预期的主机数之间折中，同时不需要与其他站点协调。&lt;/p&gt;\n&lt;p&gt;子网寻址提供额外灵活性的代价是增加成本。由于当前的&lt;strong&gt;子网&lt;/strong&gt;字段和&lt;strong&gt;主机&lt;/strong&gt;字段的定义由站点指定的（不是由网络号分类决定），一个站点中所有路由器和主机需要一种新的方式，以确定地址中的子网部分和其中的主机部分。在出现子网之前，这个信息可直接从一个网络号中获得，只需知道是 A 类、 B 类或 C 类地址（由地址的前几位表示）。图 2-2 给出了使用子网寻址的例子，显示了一个 IPv4 地址可能的格式。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;2\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1650625617558.png\&#34; alt=\&#34;图 2-2\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 2-2  一个 B 类地址被划分子网的例子。它使用 8 位作为子网 ID，提供 256 个子网和每个子网中 254 台主机。这种划分可由网络管理员改变&lt;/p&gt;\n&lt;p&gt;图 2-2 是一个 B 类地址被“划分子网”的例子。假设 Internet 中的一个站点已被分配一个 B 类网络号。该站点将每个地址的前 16 位固定为某些特定号码，这是由于这些位已被分配给核心机构。后 16 位（仅用于在无子网的 B 类网络中创建主机号）现在可以由站点的网络管理员接需分配。在这个例子中， 8 位被选定为子网号，剩下 8 位为主机号。这个特殊配置允许站点支持 256 个子网，每个子网最多可包含 254 台主机（当前每个子网的第一个和最后一个地址无效，即从整个分配范围中除去第一个和最后一个地址)。注意，只有划分子网的网络中的主机和路由器知道子网结构。在需要进行子网寻址之前， Internet 其他部分仍将它作为站点相关的地址来看待。图 2-3 显示了如何工作。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;3\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1650628367587.png\&#34; alt=\&#34;图 2-3\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 2-3  某个站点被分配一个典型的 B 类网络号 &lt;code&gt;128.320&lt;/code&gt;。网络管理员决定用于站点范围内的子网掩码为 &lt;code&gt;255.255.255.0&lt;/code&gt;，提供 256 个子网，每个子网可容纳 &lt;code&gt;256 - 2 = 254&lt;/code&gt; 台主机。同一子网中每台主机的 IPv4 地址拥有相同子网号。左侧的局域网段中主机的 IPv4 地址开始于 &lt;code&gt;128.32.1&lt;/code&gt;，右侧的所有主机开始于 &lt;code&gt;128.32.2&lt;/code&gt;&lt;/p&gt;\n&lt;p&gt;本图显示了一个虚拟的站点，使用一个边界路由器（即 Internet 的一个连接点）连接 Internet 和两个内部局域网。&lt;code&gt;x&lt;/code&gt; 的值可以是 &lt;code&gt;[0，255]&lt;/code&gt; 范围内的任意值。每个以太网是一个 IPv4 子网，整体分配为 B 类地址的网络号 &lt;code&gt;128.32&lt;/code&gt;。 Internet 中的其他站点要访问这个站点，目的地址以   &lt;code&gt;128.32&lt;/code&gt; 开始的所有流量直接由 Internet 路由系统交给边界路由器（特别是其接口的 IPv4 地址&lt;code&gt;137.164.23.30&lt;/code&gt;)。在这点上，边界路由器必须区分 &lt;code&gt;128.32&lt;/code&gt; 网络中的不同子网。特别是，它必须能区分和分离目的地址为 &lt;code&gt;128.32.1.x&lt;/code&gt; 和目的地址为 &lt;code&gt;128.32.2.x&lt;/code&gt; 的流量。这些地址分别表示子网号 &lt;code&gt;1&lt;/code&gt; 和 &lt;code&gt;2&lt;/code&gt;，它们都采用 &lt;code&gt;128.32&lt;/code&gt; 的 B 类网络号。为了做到这点，路由器必须知道在地址中如何找到子网ID。这可通过一个配置参数实现，我们将在后面加以讨论。&lt;/p&gt;\n&lt;h3 id=\&#34;233-子网掩码\&#34;&gt;2.3.3 子网掩码&lt;/h3&gt;\n&lt;p&gt;&lt;strong&gt;子网掩码&lt;/strong&gt;是由一台主机或路由器使用的分配位，以确定如何从一台主机对应 IP 地址中获得网络和子网信息。 IP 子网掩码与对应的 IP 地址长度相同（IPv4为 32 位， IPv6为 128 位）。它们通常在一台主机或路由器中以 IP 地址相同的方式配置，既可以是静态的（通常是路由器），也可以使用一些动态方式，例如&lt;strong&gt;动态主机配置协议&lt;/strong&gt;(DHCP ；见第 6 章)。对于 IPv4，子网掩码以 IPv4 地址相同的方式（即点分十进制）编写。虽然最初不需要以这种方式分配，当前子网掩码由一些 1 后跟一些 0 构成。这样安排，就可以用容易记的格式表示掩码，只需给出一些连续位的 1 （左起）的掩码。这种格式是当前最常见的格式，有时也被称为&lt;strong&gt;前缀长度&lt;/strong&gt;。表 2-4 列出了 IPv4 的一些例子。&lt;/p&gt;\n&lt;center&gt;表 2-4 各种格式的 IPv4 子网掩码的例子&lt;/center&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;点分十进制表示&lt;/th&gt;\n&lt;th&gt;容易记的格式（前缀长度）&lt;/th&gt;\n&lt;th&gt;二进制表示&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;128.0.0.0&lt;/td&gt;\n&lt;td&gt;/1&lt;/td&gt;\n&lt;td&gt;10000000 00000000 00000000 00000000&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;255.0.0.0&lt;/td&gt;\n&lt;td&gt;/8&lt;/td&gt;\n&lt;td&gt;11111111 00000000 00000000 00000000&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;255.192.0.0&lt;/td&gt;\n&lt;td&gt;/10&lt;/td&gt;\n&lt;td&gt;11111111 11000000 00000000 00000000&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;255.255.0.0&lt;/td&gt;\n&lt;td&gt;/16&lt;/td&gt;\n&lt;td&gt;11111111 11111111 00000000 00000000&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;255.255.254.0&lt;/td&gt;\n&lt;td&gt;/23&lt;/td&gt;\n&lt;td&gt;11111111 11111111 11111110 00000000&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;255.255.255.192&lt;/td&gt;\n&lt;td&gt;/27&lt;/td&gt;\n&lt;td&gt;11111111 11111111 11111111 11100000&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;255.255.255.255&lt;/td&gt;\n&lt;td&gt;/32&lt;/td&gt;\n&lt;td&gt;11111111 11111111 11111111 11111111&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;p&gt;表 2-5 列出了 IPv6 的一些例子。&lt;/p&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;十六进制表示&lt;/th&gt;\n&lt;th&gt;容易记的格式（前缀长度）&lt;/th&gt;\n&lt;th&gt;二进制表示&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;ffff:ffff:ffff:ffff::&lt;/td&gt;\n&lt;td&gt;/64&lt;/td&gt;\n&lt;td&gt;1111111111111111 1111111111111111 &lt;br/&gt; 1111111111111111 1111111111111111 &lt;br/&gt; 0000000000000000 0000000000000000 &lt;br/&gt; 0000000000000000 0000000000000000&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ff00::&lt;/td&gt;\n&lt;td&gt;/8&lt;/td&gt;\n&lt;td&gt;1111111100000000 0000000000000000 &lt;br/&gt; 0000000000000000 0000000000000000 &lt;br/&gt; 0000000000000000 0000000000000000 &lt;br/&gt; 0000000000000000 0000000000000000&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;p&gt;掩码由路由器和主机使用，以确定一个 IP 地址的网络 / 子网部分的结束和主机部分的开始。子网掩码中的一位设为 1 表示一个 IP 地址的对应位与一个地址的网络 / 子网部分的对应位相结合，并将结果作为转发数据报的基础（见第5章）。相反，子网掩码中的一位设为 0，表示一个 IP 地址的对应位作为主机 ID 的一部分。例如，我们在图 2-4 中可以看到，当子网掩码为 &lt;code&gt;255.255.255.0&lt;/code&gt; 时，如何处理 IPv4 地址 &lt;code&gt;128.32.1.14&lt;/code&gt;。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;4\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1650631778417.png\&#34; alt=\&#34;图 2-4\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 2-4  一个 IP 地址可以与一个子网掩码使用按位与操作，以形成用于路由的地址的网络 / 子网标识符（前缀）。在这个例子中， IPv4 地址 &lt;code&gt;128.32.1.14&lt;/code&gt; 使用长度为 24 的掩码得到前缀&lt;code&gt;128.32.1.0/24&lt;/code&gt;&lt;/p&gt;\n&lt;p&gt;这里，我们看如何将地址中的每位与子网掩码中的对应位进行与运算。回顾按位与运算，如果掩码和地址中的对应位都是 1，则结果位都只能是 1。在这个例子中，我们看到地址 &lt;code&gt;128.32.1.14&lt;/code&gt; 属于子网 &lt;code&gt;128.32.1.0/24&lt;/code&gt; 。图 2-3 中是边界路由器需要的信息，以确定一个目的地址为 &lt;code&gt;128.32.1.14&lt;/code&gt; 的数据报需要转发到的系统所在的子网。注意， Internet 路由系统其余部分不需要子网掩码的知识，因为站点之外的路由器做出路由决策只基于地址的网络号部分，并不需要网络 / 子网或主机部分。因此，子网掩码纯粹是站点内部的局部问题。&lt;/p&gt;\n&lt;h3 id=\&#34;234-可变长度子网掩码\&#34;&gt;2.3.4 可变长度子网掩码&lt;/h3&gt;\n&lt;p&gt;目前为止，我们已讨论如何将一个分配给站点的网络号进一步细分为多个可分配的大小相同的子网，并根据网络管理员的合理要求使每个子网能支持相同数量的主机。我们发现在同一站点的不同部分，可将不同长度的子网掩码应用于相同网络号。虽然这样增加了地址配置管理的复杂性，但也提高了子网结构的灵活性，这是由于不同子网可容纳不同数量的主机。目前，大多数主机、路由器和路由协议支持&lt;strong&gt;可变长度子网掩码（VLSM）&lt;/strong&gt;。要了解 VLSM 如何工作，可以看图 2-5 所示的网络拓扑，它使用 VLSM 为图 2-3 扩展了两个额外的子网。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;5\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1650635390775.png\&#34; alt=\&#34;图 2-5\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 2-5 VLSM 可用于分割一个网络号，使每个子网支持不同数量的主机。每个路由器和主机除了 IP 地址，还需要配置一个子网掩码。大多数软件支持 VLSM，除了一些旧的路由协议（例如 RIP 版本 1）&lt;/p&gt;\n&lt;p&gt;在图 2-5 显示的更复杂的例子中，三个不同的子网掩码被用于站点中的子网 &lt;code&gt;128.32.0.0/16&lt;/code&gt; : &lt;code&gt;/24&lt;/code&gt;、 &lt;code&gt;/25&lt;/code&gt; 和 &lt;code&gt;/26&lt;/code&gt;。这样，每个子网可提供不同数量的主机。主机数受 IP 地址中没有被网络 / 子网号使用的剩余位限制。对于 IPv4 和 &lt;code&gt;/24&lt;/code&gt; 前缀，允许有 &lt;code&gt;32-24=8&lt;/code&gt; 位 （ 256 台主机）；对于 &lt;code&gt;/25&lt;/code&gt;，有 &lt;code&gt;1/2&lt;/code&gt; 数量（ 128 台主机）；对于 &lt;code&gt;/26&lt;/code&gt; ，有 1/4 数量（ 64 台主机）。注意，主机和路由器的每个接口都需要用 IP 地址和子网掩码来描述，但掩码决定了网络拓扑的不同。基于路由器中运行的动态路由协议(例如 OSPF、 IS-IS、 RIPv2)，流量能正确地在同一站点中的主机之间流动，以及通过 Internet 前往或来自外部站点。&lt;/p&gt;\n&lt;p&gt;尽管这可能并不显而易见，但有一个常见情况，即一个子网中只包含两台主机。当路由器之间被一条点到点链路连接，则每个端点都需要分配一个 IP 地址，常见做法是 IPv4 使用 &lt;code&gt;/31&lt;/code&gt; 为前缀，目前也有建议 IPv6 使用 &lt;code&gt;/127&lt;/code&gt; 为前缀 [&lt;a href=\&#34;#RFC6164\&#34;&gt;RFC6164&lt;/a&gt;] 。&lt;/p&gt;\n&lt;h3 id=\&#34;235-广播地址\&#34;&gt;2.3.5 广播地址&lt;/h3&gt;\n&lt;p&gt;在每个 IPv4 子网中，一个特殊地址被保留作为子网广播地址。子网广播地址通过将 IPv4 地址的网络 / 子网部分设置为适当值，以及主机部分的所有位设置为 1 而形成。我们看图 2-5 中最左边的子网，它的前缀是 &lt;code&gt;128.32.1.0/24&lt;/code&gt;。子网广播地址的构建方式为：对子网掩码取反（即将所有的0位改变为1，反之亦然），并与子网中任意计算机的地址(或等值的网络 / 子网前缀)进行按位或运算。注意，如果两个输入位之一为 1，按位或运算的结果为1。图 2-6 显示了这个计算过程，其中使用 IPv4 地址&lt;code&gt;128.32.1.14&lt;/code&gt;。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;6\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1650636499514.png\&#34; alt=\&#34;图 2-6\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 2-6  子网广播地址由子网掩码首先取反，然后与 IPv4 地址进行或运算构成。在这种情况下，一个 &lt;code&gt;/24&lt;/code&gt; 的子网掩码，剩余的 &lt;code&gt;32-24 = 8&lt;/code&gt; 位设置为 1，得到一个十进制 255 和子网广播地址 &lt;code&gt;128.32.1.255&lt;/code&gt;&lt;/p&gt;\n&lt;p&gt;如图2-6所示，子网 &lt;code&gt;128.32.1.0/24&lt;/code&gt; 的子网广播地址是 &lt;code&gt;128.32.1.255&lt;/code&gt;。从历史上看，使用这种地址作为目的地的数据报，也被称为&lt;strong&gt;定向广播&lt;/strong&gt;。至少在理论上，这种广播可作为一个单独的数据报通过 Internet 路由直至到达目标子网，再作为一组广播数据报发送给子网中所有主机。对这个想法做进一步概括，我们可形成一个目的 IPv4 地址为 &lt;code&gt;128.32.255.255&lt;/code&gt; 的数据报，并且通过图 2-3 或图 2-5 所示的连接网络将它发送到 Internet 。这时，该数据报将发送给目标站点中的所有主机。&lt;/p&gt;\n&lt;p&gt;注意   定向广播是一个大问题，从安全的角度来看，它们至今在 Internet 中仍被禁用。 [&lt;a href=\&#34;#RFCO919\&#34;&gt;RFCO919&lt;/a&gt;] 描述了针对 IPv4 的各类广播， [&lt;a href=\&#34;#RFC1812\&#34;&gt;RFC1812&lt;/a&gt;] 建议支持由路由器转发定向广播，它不仅可用，而且默认启用。 [&lt;a href=\&#34;#RFC2644\&#34;&gt;RFC2644&lt;/a&gt;] 使这个策略发生逆转，路由器现在默认禁止转发定向广播，甚至完全省略支持能力。&lt;/p&gt;\n&lt;p&gt;除了子网广播地址，特殊用途地址 &lt;code&gt;255.255.255.255&lt;/code&gt; 被保留为&lt;strong&gt;本地网络广播&lt;/strong&gt;（也称为&lt;strong&gt;有限广播&lt;/strong&gt;），它根本不会被路由器转发（详见 2.5 节中的特殊用途地址）。注意，虽然路由器可能不转发广播，但子网广播和连接在同一网络中的计算机的本地网络广播将工作，除非被终端主机明确禁用。这种广播不需要路由器；如果有的话，链路层的广播机制用于支持它们（见第3章）。广播地址通常与某些协议一起使用，例如 UDP/IP （第 10 章）或 ICMP （第 8 章），因为这些协议不涉及 TCP/IP 那样的双方会话。 IPv6 没有任何广播地址；广播地址可用于 IPv4 中，而 IPv6 仅使用组播地址（见第 9 章）。&lt;/p&gt;\n&lt;h3 id=\&#34;236-ipv6-地址和接口标识符\&#34;&gt;2.3.6 IPv6 地址和接口标识符&lt;/h3&gt;\n&lt;p&gt;除了比 IPv4 地址长 4 倍这个因素， IPv6 地址还有一些额外的特点。 IPv6 地址使用特殊前缀表示一个地址范围。一个 IPv6 地址范围是指它可用的网络规模。有关范围的重要例子包括&lt;strong&gt;节点本地&lt;/strong&gt;（只用于同一计算机中通信）、&lt;strong&gt;链路本地&lt;/strong&gt;（只用于同一网络链路或 IPv6 前缀中的节点）或&lt;strong&gt;全球性&lt;/strong&gt;（ Internet 范围）。在 IPv6 中，大部分节点通常在同一网络接口上使用多个地址。虽然 IPv4 中也支持这样做，但是并不常见。一个 IPv6 节点中需要一组地址，包括组播地址(见 2.5.2 节)，它来源于 [&lt;a href=\&#34;#RFC4291\&#34;&gt;RFC4291&lt;/a&gt;] 。&lt;/p&gt;\n&lt;p&gt;注意   另一个范围层次称为站点本地，使用的前缀为 &lt;code&gt;fec0::/10&lt;/code&gt;，最初是由 IPv6 支持的，后来被 [&lt;a href=\&#34;#RFC3879\&#34;&gt;RFC3879&lt;/a&gt;] 放弃并用于单播地址。主要问题包括如何处理这种地址，这是由于它可能被重用于多个站点，以及如何准确定义一个“站点”。&lt;/p&gt;\n&lt;p&gt;链路本地 IPv6 地址（和一些全球性 IPv6 地址）使用**接口标识符（ IID ）**作为一个单播 IPv6 地址的分配基础。除了地址是以二进制值 000 开始之外， IID 在所有情况下都作为一个 IPv6 地址的低序位，这样它们必须在同一网络中有唯一前缀。 IID 的长度通常是 64 位，并直接由一个网络接口相关的链路层 MAC 地址形成，该地址使用 &lt;strong&gt;修改的 EUI-64 格式&lt;/strong&gt; [&lt;a href=\&#34;#EUI64\&#34;&gt;EUI64&lt;/a&gt;]，或者由其他进程随机提供的值形成，以提供可防范地址跟踪的某种程度的隐私保护（见第 6 章）。&lt;/p&gt;\n&lt;p&gt;在 IEEE 标准中， EUI 表示&lt;strong&gt;扩展唯一标识符&lt;/strong&gt;。 EUI-64 标识符开始于一个 24 位的&lt;strong&gt;组织唯一标识符（ OUI ）&lt;/strong&gt;，接着是一个由组织分配的 40 位&lt;strong&gt;扩展标识符&lt;/strong&gt;，它由前面 24 位识别。 OUI 由 IEEE 注册权威机构 [&lt;a href=\&#34;#IEEERA\&#34;&gt;IEEERA&lt;/a&gt;] 来维护和分配。 EUI 可能是“统一管理”或“本地管理”的。在 Internet 环境下，这种地址通常是统一管理的。&lt;/p&gt;\n&lt;p&gt;多年来，很多 IEEE 标准兼容的网络接口（例如以太网）在使用短格式的地址（48位的&lt;br&gt;\nEUI）。 EUI-48 和 EUI-64 格式之间的显著区别是它们的长度（见图 2-7）。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;7\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1650724664618.png\&#34; alt=\&#34;图 2-7\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 2-7   EUI-48 和 EUI-64 格式由 IEEE 定义。这些都是用于 IPv6 的地址，它们是通过将接口标识符反 u 位来形成的&lt;/p&gt;\n&lt;p&gt;OUI 的长度是 24 位，并占据 EU1-48 和 EU1-64 地址的前 3 个字节。这些地址的第一个字节的低两位分别是 u 位和 g 位。当 u 位被设置时，表示该地址是本地管理。当 g 位被设置时， 表示该地址是一组或组播类型的地址。目前，我们只关心 g 位未被设置的情况。&lt;/p&gt;\n&lt;p&gt;一个 EUI-64 地址可以由 EUI-48 地址形成，将 EU1-48 地址的24位 OUI 值复制到 EU1-64 地址，并将 EUI-64 地址的第 4 和第 5 个字节的 16 位替换为 &lt;code&gt;1111111111111110&lt;/code&gt; （十六进制 &lt;code&gt;FFFE&lt;/code&gt;），然后复制由组织分配的剩余位。例如， EUI-48 地址 &lt;code&gt;00-11-22-33-44-55&lt;/code&gt; 在 EUI-64地址中将会变成 &lt;code&gt;00-11-22-FF-FE-33-44-55&lt;/code&gt;。 这个映射的第一步是当可以用基本 EUI-48 地址时由 IPv6 构造接口标识符。修改的 EUI-64 用于形成 IPv6 地址的 IID，但是需要对 u 位取反。&lt;/p&gt;\n&lt;p&gt;当一个 IPv6 接口标识符需要一种接口，并且该接口没有由制造商提供 EUI-48 地址，但是有其他类型的基本地址时（例如 AppleTalk ），基本地址可用 0 从左侧填充形成接口标识符。当接口标识符是为缺乏任意形式标识符的接口（例如隧道、串行链路）创建时，它可由相同节点上（不在同一子网中）的其他接口，或者与节点有关联的某些标识符派生。在缺乏其他选择的情况下，手动分配是最后的方案。&lt;/p&gt;\n&lt;h4 id=\&#34;2361-例子\&#34;&gt;2.3.6.1 例子&lt;/h4&gt;\n&lt;p&gt;我们探讨使用 Linux 的 ifconfig 命令形成一个链路本地 IPv6 地址的方式:&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;Linux% ifconfig eth1\neth1     Link encap:Ethernet    HWaddr 00:30:48:2A:19:89\n            inet addr:12.46.129.28  Bcast:12.46.129.127\n            Mask:255.255.255.128\n            inet6 addr: fe80::230:48ff:fe2a:1989/64 Scope:Link\n            UP BROADCAST RUNNING MULTICAST  MTU:1500    Metric:1\n            RX packets:1359970341 errors:0 dropped:0 overruns:0 frame:0\n            TX packets:1472870787 errors:0 dropped:0 overruns:0 carrier:0\n            collisions:0    txqueuelen:1000\n            RX bytes:4021555658 (3.7 GiB)   TX bytes:3258456176 (3.0 GiB)\n            Base address:0x3040 Memory:f8220000-f8240000\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;这里，我们可看到以太网硬件地址 &lt;code&gt;00:30:48:2A:19:89&lt;/code&gt; 如何被映射为一个IPv6地址。首先，它被转换为 EUI-64 形成地址 &lt;code&gt;00:30:48:ff:fe:2a:19:89&lt;/code&gt;。 接着， u 位被取反，形成 IID 值&lt;code&gt;02:30:48:ff:fe:2a:19:89&lt;/code&gt;。 为了完成链路本地 IPv6 地址，我们使用保留的链路本地前缀 &lt;code&gt;fe80::/10&lt;/code&gt; （见 2.5 节）。总之，这样形成完整地址 &lt;code&gt;fe80::230:48ff:fe2a:1989&lt;/code&gt;。      &lt;code&gt; /64&lt;/code&gt; 是标准长度，用于从一个 IPv6 地址中识别子网/主机部分，它由 [&lt;a href=\&#34;#RFC4291\&#34;&gt;RFC4291&lt;/a&gt;] 要求的一个 IID 派生。&lt;/p&gt;\n&lt;p&gt;另一个有趣的例子来自支持 IPv6 的 Windows 系统。在这个例子中，我们将看到一个特殊的隧道端点，它被用于使 IPv6 流量通过仅支持 IPv4 的网络:&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;c:\\&amp;gt; ipconfig /all\n...\nTunnel adapter Automatic Tunneling pseud Interface:\n\nConnection-specific DNS Suffix .  : foo\nDescription . . . . . . . . . . . : Automatic Tunneling\n                                      Pseudo一Interface\nPhysical Address . . . . . . . . . : 0A-99-BD-87\ndhcp Enabled . . . . . . . . . . . : No\nIP Address . . . . . . . . . . . . : fe80::5efe:10.153.141.135%2\nDefault Gateway  . . . . . . . . . : \nDNS Servers  . . . . . . . . . . . : fec0:0:0:ffff::1%2\n                                     fec0:0:0:ffff::2%2\n                                     fec0:0:0:ffff::3%2\nNetBIOS over Tcpip . . . . . . . . : Disabled\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;在这个例子中，我们可以看到一个特殊的隧道接口为 ISATAP[&lt;a href=\&#34;#RFC5214\&#34;&gt;RFC5214&lt;/a&gt;]。实际上，所谓的物理地址是 IPv4 地址的十六进制编码：&lt;code&gt;0A-99-8D-87&lt;/code&gt; 与 &lt;code&gt;10.153.141.135&lt;/code&gt; 相同。这里，使用的 OUI （&lt;code&gt;00-00-5E&lt;/code&gt;）是由 IANA 分配的 [&lt;a href=\&#34;#IANA\&#34;&gt;IANA&lt;/a&gt;]。它被用于与十六进制值 &lt;code&gt;fe&lt;/code&gt; 组合，表示一个嵌入的 IPv4 地址。然后，这个组合与标准的链路本地前缀 &lt;code&gt;fe80::/10&lt;/code&gt; 组合，最终形成地址 &lt;code&gt;fe80::5efe:10.153.141.135&lt;/code&gt;。 附加在地址结尾的 &lt;code&gt;%2&lt;/code&gt; 在 Windows 中称为** 区域ID**，表示主机中对应于 IPv6 地址的接口索引号。 IPv6 地址通常由一个自动配置过程创建，我们在第6章详细讨论这个过程。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;24-cidr-和聚合\&#34;&gt;2.4 CIDR 和聚合&lt;/h2&gt;\n&lt;p&gt;20 世纪 90 年代初，在采用子网寻址缓解增长带来的痛苦后， Internet 开始面临更严重的规模问题。有三个问题很重要，需要立即引起注意：&lt;/p&gt;\n&lt;ol&gt;\n&lt;li&gt;到1994年，一半以上的 B 类地址已被分配。预计， B 类地址空间大约在 1995 年将被用尽。&lt;/li&gt;\n&lt;li&gt;32 位的 IPv4 地址被认为不足以应付 Internet 在 21 世纪初的预期规模。&lt;/li&gt;\n&lt;li&gt;全球性路由表的条目数（每个网络号对应一条）， 1995 年大约为 65000 个条目，目前仍在增长中。随着越来越多 A 类、 B 类和 C 类路由条目的出现，路由性能将受到影响。&lt;/li&gt;\n&lt;/ol&gt;\n&lt;p&gt;从 1992 年开始，这些问题受到 IETF 中的 ROAD （路由和寻址）小组的关注。他们认为问题 1 和 3 将很快来临，问题 2 需要一个长期的解决方案。他们提出的短期解决方案是有效清除 IP 地址的分类缺陷，并提高层次化分配的 IP 地址的聚合能力。这些措施将有助于解决问题 1 和 3 。 IPv6 被设想用于解决问题 2。&lt;/p&gt;\n&lt;h3 id=\&#34;241-前缀\&#34;&gt;2.4.1 前缀&lt;/h3&gt;\n&lt;p&gt;为了帮助缓解 IPv4 地址（特别是B类地址）的压力，分类寻址方案通常使用一个类似 VLSM 的方案，扩展 Internet 路由系统以支持&lt;strong&gt;无类别域间路由（Classless Inter-Domain Routing，CIDR）&lt;/strong&gt; [&lt;a href=\&#34;#RFC4632\&#34;&gt;RFC4632&lt;/a&gt;]。这提供了一种方便的分配连续地址范围的方式，包含多于 255 台但少于 65536 台主机。也就是说，不只是单个 B 类或多个 C 类网络号可分配给站点。使用 CIDR，未经过预定义的任何地址范围可作为一个类的一部分：但需要一个类似于子网掩码的掩码，有时也称为 CIDR 掩码。CIDR 掩码不再局限于一个站点，而对全球性路由系统都是可见的。因此，除了网络号之外，核心 Internet 路由器必须能解释和处理掩码。这个数字组合称为网络前缀，它用于 IPv4 和 IPv6 地址管理。&lt;/p&gt;\n&lt;p&gt;消除一个 IP 地址中网络和主机号的预定义分隔，将使更细粒度的 IP 地址分配范围成为可能。与分类寻址类似，地址空间分割成块最容易通过数值连续的地址来实现，以便用于某种类型或某些特殊用途。目前，这些分组普遍使用地址空间的前缀表示。一个 n 位的前缀是一个地址的前 n 个位的预定义值。对于IPv4， n （前缀长度）的值通常在范围 0 ~ 32 ；对于 IPv6，通常在范围 0 ~ 128。它通常被追加到基本 IP 地址，并且后面跟着一个 &lt;code&gt;/&lt;/code&gt; 字符。表 2-6 给出了一些前缀的例子，以及相应的 IPv4 或 IPv6 地址范围。&lt;/p&gt;\n&lt;center&gt;表 2-6 前缀的例子及其相应的 IPv4 或 IPv6 地址范围&lt;/center&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;前缀&lt;/th&gt;\n&lt;th&gt;前缀（二进制）&lt;/th&gt;\n&lt;th&gt;地址范围&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;0.0.0.0/0&lt;/td&gt;\n&lt;td&gt;00000000 00000000 00000000 00000000&lt;/td&gt;\n&lt;td&gt;0.0.0.0 ~ 255.255.255.255&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;128.0.0.0/1&lt;/td&gt;\n&lt;td&gt;&lt;b&gt;1&lt;/b&gt;0000000 00000000 00000000 00000000&lt;/td&gt;\n&lt;td&gt;128.0.0.0 ~ 255.255.255.255&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;128.0.0.0/24&lt;/td&gt;\n&lt;td&gt;&lt;b&gt;10000000 00000000 00000000&lt;/b&gt; 00000000&lt;/td&gt;\n&lt;td&gt;128.0.0.0 ~ 128.0.0.255&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;198.128.128.192/27&lt;/td&gt;\n&lt;td&gt;&lt;b&gt;11000110 10000000 10000000 1100&lt;/b&gt;0000&lt;/td&gt;\n&lt;td&gt;198.128.128.192 ~ 198.128.128.223&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;165.195.130.107/32&lt;/td&gt;\n&lt;td&gt;&lt;b&gt;10100101 11000011 100000010 01101011&lt;/b&gt;&lt;/td&gt;\n&lt;td&gt;165.195.130.107&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;2001:db8::/32&lt;/td&gt;\n&lt;td&gt;&lt;b&gt;0010000000000001 0000110110111000&lt;/b&gt; 0000000000000000 0000000000000000 0000000000000000 0000000000000000 0000000000000000 0000000000000000&lt;/td&gt;\n&lt;td&gt;2001:db8:: ~ 2001:db8:ffff:ffff&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;p&gt;在这个表中，由前缀来定义并固定的位被加粗表示。剩余位可设置为 0 和 1 的任意组合，从而涵盖可能的地址范围。显然，一个较小的前缀长度可对应于一个更大的地址范围。另外，早期的分类寻址方案易于被这个方案覆盖。例如， C 类网络号 &lt;code&gt;192.125.3.0&lt;/code&gt; 可以写成前缀 &lt;code&gt;192.125.3.0/24&lt;/code&gt; 或 &lt;code&gt;192.125.3/24&lt;/code&gt;。 分类的 A 类和 B 类网络号可分别用前缀长度 &lt;code&gt;/8&lt;/code&gt; 和 &lt;code&gt;/16&lt;/code&gt; 表示。&lt;/p&gt;\n&lt;h3 id=\&#34;242-聚合\&#34;&gt;2.4.2 聚合&lt;/h3&gt;\n&lt;p&gt;通过取消分类结构的 IP 地址，能分配各种尺寸的 IP 地址块。但是，这样做没有解决问题列表中的第三个问题，它并没有帮助减少路由表条目数。一条路由表条目告诉一个路由器向哪里发送流量。从本质上来说，路由器检查每个到达的数据报中的目的 IP 地址，找到一条匹配的路由表条目，并从该条目中提取数据报的“下一跳”。这有点像驾驶汽车去一个特定地址，并在沿路每个路口找到一个标志，指示沿着哪个方向去目的地路线的下一个路口。如果你能理解在每个路口设置很多标志，以指向每个可能的目的地的情形，就能认识到20 世纪 90 年代初 Internet 面临的一些问题。&lt;/p&gt;\n&lt;p&gt;当时，没什么技术可以解决以下问题：在维护 Internet中 到所有目的地的最短路径的同时，又能够显著减少路由表条目数。最有名的方法是 20 世纪 70 年代末由 Kleiurock 和 Kamoun 发表的&lt;strong&gt;分层路由研究&lt;/strong&gt; [&lt;a href=\&#34;#KK77\&#34;&gt;KK77&lt;/a&gt;]。他们发现，如果将网络拓扑排列为一棵树，并且以对这个网络拓扑“敏感的”方式来分配地址，这样可获得一个非常小的路由表，同时保持到所有目的地的最短路径。大家可以看图 2-8 。&lt;/p&gt;\n&lt;p&gt;图 2-8 中左侧树的根（顶级）是标记为 &lt;code&gt;19.12.4.8&lt;/code&gt; 的路由器。为了知道每个可能的目的地的下一跳，它需要一个树中在其“下面的”所有路由器的条目：&lt;code&gt;190.16.11.2&lt;/code&gt;、 &lt;code&gt;86.12.0.112&lt;/code&gt;、&lt;code&gt;159.66.2.231&lt;/code&gt;、 &lt;code&gt;133.17.97.12&lt;/code&gt;、 &lt;code&gt;66.103.2.19&lt;/code&gt;、 &lt;code&gt;18.1.1.1&lt;/code&gt;、 &lt;code&gt;19.12.4.9&lt;/code&gt;  &lt;code&gt;203.44.23.198&lt;/code&gt;。 对于任何其他目的地，它只需简单地路由到标有“网络其他部分”的云中。结果共有 9 个条目。相比之下，右侧树的根被标记为 &lt;code&gt;19.0.0.1&lt;/code&gt;，并要求其路由表中只有 3 个条目。注意，右树中左侧的所有路由器以前缀 &lt;code&gt;19.1&lt;/code&gt; 开始，右侧的所有路由器以前缀 &lt;code&gt;19.2&lt;/code&gt; 开始。因此，路由器 &lt;code&gt;19.0.0.1&lt;/code&gt; 的表中只需将以 &lt;code&gt;19.1&lt;/code&gt; 开始的目的地显示下一跳为 &lt;code&gt;19.1.0.1&lt;/code&gt;，而将以 &lt;code&gt;19.2&lt;/code&gt; 开始的目的地显示下一跳为 &lt;code&gt;19.2.0.1&lt;/code&gt;。任何其他目的地都被路由到标有“网络其他部分”的云中。结果共有 3 个条目。注意，这种行为是递归的，图 2-8b 所示树中的任意路由器，需要的条目数都不会超过它拥有的链路数。这是这种特殊的地址分配方法所带来的直接结果。即使越来越多的路由器加人图 2-8b 所示的树，这个良好的属性也保持不变。这是[&lt;a href=\&#34;#KK77\&#34;&gt;KK77&lt;/a&gt;]的分层路由思想的精髓。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;8\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1650894706114.png\&#34; alt=\&#34;图 2-8\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 2-8   在树状拓扑网络中，网络地址可采用特殊方式分配，以限制需保存在路由器中的路由信息（“状态”）数量。如果不以这种（左侧的）方式分配地址，没有存储与需到达的节点数量成正比的状态，则最短路径无法得到保证。当以保存状态的树状拓扑敏感的方式分配地址时，如果网络拓扑发生变化，通常需要重新分配地址&lt;/p&gt;\n&lt;p&gt;在 Internet 环境中，可采用分层路由思想以一种特定方式减少 Internet 路由条目数。这通过一个称为&lt;strong&gt;路由聚合&lt;/strong&gt;的过程来实现。通过将相邻的多个 IP 前缀合并成一个短前缀（称为一个&lt;strong&gt;聚合&lt;/strong&gt;或&lt;strong&gt;汇聚&lt;/strong&gt;），可以覆盖更多地址空间。我们可以看图 2-9。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;9\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1650897953256.png\&#34; alt=\&#34;图 2-9\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 2-9   在这个例子中，箭头表示将两个地址前缀聚合为一个，带下划线的前缀是每一步的结果。第一步，&lt;code&gt;190.154.27.0/26&lt;/code&gt; 和 &lt;code&gt;190.154.27.64.0/26&lt;/code&gt; 可以聚合，这是由于它们数值相邻，但是&lt;code&gt;190.154.27.192/26&lt;/code&gt; 不能聚合。通过与 &lt;code&gt;190.154.27.128/26&lt;/code&gt; 相加，它们可经过两步聚合形成&lt;code&gt;190.154.27.0/24&lt;/code&gt;。最后，通过与相邻的 &lt;code&gt;190.154.26.0/24&lt;/code&gt; 相加，生成聚合结果 &lt;code&gt;190.154.26.0/23&lt;/code&gt;&lt;/p&gt;\n&lt;p&gt;首先看图 2-9 中左侧的三个地址前缀。前两个（ &lt;code&gt;190.154.27.0/26&lt;/code&gt; 和&lt;code&gt;190.154.27.64/26&lt;/code&gt;）数值相邻，因此可被组合（聚合）。箭头表示聚合发生的地方。前缀 &lt;code&gt;190.154.27.192/26&lt;/code&gt; 不能在第一步被聚合，由于它们并非数值相邻。当增加一个新前缀 &lt;code&gt;190.154.27.128/26&lt;/code&gt; （下划线），前缀 &lt;code&gt;190.154.27.192/26&lt;/code&gt; 和 &lt;code&gt;190.154.27.128/26&lt;/code&gt; 可能被聚合，并形成 &lt;code&gt;190.154.27.128/25&lt;/code&gt; 前缀。这个聚合现在与聚合 &lt;code&gt;190.154.27.0/25&lt;/code&gt; 相邻，因此它们可进一步聚合成 &lt;code&gt;190.154.27.0/24&lt;/code&gt;。当增加前缀 &lt;code&gt;190.154.26.0/24&lt;/code&gt; （下划线），两个 C 类的前缀可以聚合成 &lt;code&gt;190.154.26.0/23&lt;/code&gt;。这样，原来的三个前缀和两个增加的前缀可聚合成一个前缀。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;25-特殊用途地址\&#34;&gt;2.5 特殊用途地址&lt;/h2&gt;\n&lt;p&gt;IPv4 和 IPv6 地址空间中都包括几个地址范围，它们被用于特殊用途（因此不能用于单播地址分配）。对于 IPv4 ，这些地址显示在表 2-7 中 [&lt;a href=\&#34;#RFC5735\&#34;&gt;RFC5735&lt;/a&gt;]。&lt;/p&gt;\n&lt;center&gt;表 2-7 IPv4 特殊用途地址（定义于 2010 年 1 月）&lt;/center&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;前缀&lt;/th&gt;\n&lt;th&gt;特殊用途&lt;/th&gt;\n&lt;th&gt;参考文献&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;0.0.0.0/8&lt;/td&gt;\n&lt;td&gt;本地网络中的主机。仅作为源 IP 地址使用&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC1122\&#34;&gt;RFC1122&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;10.0.0.0/8&lt;/td&gt;\n&lt;td&gt;专用网络（内联网）的地址。这种地址不会出现在公共 Internet 中&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC1918\&#34;&gt;RFC1918&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;127.0.0.0/8&lt;/td&gt;\n&lt;td&gt;Internet 主机回送地址（同一计算机）。通常只用 127.0.0.1&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC1122\&#34;&gt;RFC1122&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;169.254.0.0/16&lt;/td&gt;\n&lt;td&gt;“链路本地”地址，只用于一条链路，通常自动分配。见第 6 章&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC3927\&#34;&gt;RFC3927&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;172.16.0.0/12&lt;/td&gt;\n&lt;td&gt;专用网络（内联网）的地址。这种地址不会出现在公共 Internet 中&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC1918\&#34;&gt;RFC1918&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;192.0.0.0/24&lt;/td&gt;\n&lt;td&gt;IETF 协议分配（IANA 保留）&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC5736\&#34;&gt;RFC5736&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;192.0.2.0/24&lt;/td&gt;\n&lt;td&gt;批准用于文档中的 TEST-NET-1 地址。这种地址不会出现在公共 Internet 中&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC5737\&#34;&gt;RFC5737&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;192.88.99.0/24&lt;/td&gt;\n&lt;td&gt;用于 6to4 中继（任播地址）&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC3068\&#34;&gt;RFC3068&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;192.168.0.0/16&lt;/td&gt;\n&lt;td&gt;专用网络（内联网）的地址。这种地址不会出现在公共 Internet 中&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC1918\&#34;&gt;RFC1918&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;192.18.0.0/15&lt;/td&gt;\n&lt;td&gt;用于基准和性能测试&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2544\&#34;&gt;RFC2544&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;198.51.100.0/24&lt;/td&gt;\n&lt;td&gt;TEST-NET-2 地址。被批准用于文档中&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC5737\&#34;&gt;RFC5737&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;203.0.113.0/24&lt;/td&gt;\n&lt;td&gt;TEST-NET-3 地址。被批准用于文档中&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC5737\&#34;&gt;RFC5737&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;224.0.0.0/4&lt;/td&gt;\n&lt;td&gt;IPv4 组播地址（以前的 D 类），仅作为目的 IP 地址使用&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC5771\&#34;&gt;RFC5771&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;240.0.0.0/4&lt;/td&gt;\n&lt;td&gt;保留空间（以前的 E 类），除了 255.255.255.255&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC1112\&#34;&gt;RFC1112&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;255.255.255.255/32&lt;/td&gt;\n&lt;td&gt;本地网络（受限的）广播地址&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC0919\&#34;&gt;RFC0919&lt;/a&gt;] [&lt;a href=\&#34;#RFC9022\&#34;&gt;RFC9022&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;p&gt;在 IPv6 中，许多地址范围和个别地址用于特定用途，它们都列在表 2-8 中 [&lt;a href=\&#34;#RFC5156\&#34;&gt;RFC5156&lt;/a&gt;]。&lt;/p&gt;\n&lt;center&gt;表 2-8 IPv6 特殊用途地址（定义于 2008 年 4 月）&lt;/center&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;前缀&lt;/th&gt;\n&lt;th&gt;特殊用途&lt;/th&gt;\n&lt;th&gt;参考文献&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;::/0&lt;/td&gt;\n&lt;td&gt;默认路由条目。不用于寻址&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC5156\&#34;&gt;RFC5156&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;::/128&lt;/td&gt;\n&lt;td&gt;未指定地址，可作为源 IP 地址使用&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;RFC4291\&#34;&gt;RFC4291&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;::1/128&lt;/td&gt;\n&lt;td&gt;IPv6 主机回送地址，不用于发送出本地主机的数据报中&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;RFC4291\&#34;&gt;RFC4291&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;::ffff:0:0/96&lt;/td&gt;\n&lt;td&gt;IPv4 映射地址。这种地址不会出现在分组头部，只用于内部主机&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;RFC4291\&#34;&gt;RFC4291&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;::{ipv4-address}/96&lt;/td&gt;\n&lt;td&gt;IPv4 兼容地址。已过时，未使用&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;RFC4291\&#34;&gt;RFC4291&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;2001::/32&lt;/td&gt;\n&lt;td&gt;Teredo 地址&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC4380\&#34;&gt;RFC4380&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;2001:10::/28&lt;/td&gt;\n&lt;td&gt;ORCHI（覆盖可路由加密散列标识符）。这种地址不会出现在公共 Internet 中&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC4843\&#34;&gt;RFC4843&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;2001:db8::/32&lt;/td&gt;\n&lt;td&gt;用于文档和实例的地址范围。这种地址不会出现在公共 Internet 中&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC3849\&#34;&gt;RFC3849&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;2002::/16&lt;/td&gt;\n&lt;td&gt;6to4 隧道中继的 6to4 地址&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC3056\&#34;&gt;RFC3056&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;3ffe::/16&lt;/td&gt;\n&lt;td&gt;用于 6bone 实验。已过时，未使用&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC3701\&#34;&gt;RFC3701&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;5f00::/16&lt;/td&gt;\n&lt;td&gt;用于 6bone 实验。已过时，未使用&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC3701\&#34;&gt;RFC3701&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;fc00::7&lt;/td&gt;\n&lt;td&gt;唯一的本地单播地址，不用于全球性 Internet&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC4193\&#34;&gt;RFC4193&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;fe80::/10&lt;/td&gt;\n&lt;td&gt;链路本地单播地址&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;RFC4291\&#34;&gt;RFC4291&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ff00::/8&lt;/td&gt;\n&lt;td&gt;IPv6 组播地址，仅作为目的 IP 地址使用&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;RFC4291\&#34;&gt;RFC4291&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;p&gt;对于 IPv4 和 IPv6，没有指定作为特殊、组播或保留地址的地址范围可供单播使用。一些单播地址空间（IPv4 的前缀 &lt;code&gt;10/8&lt;/code&gt;、 &lt;code&gt;172.16/12&lt;/code&gt; 和 &lt;code&gt;192.168/16&lt;/code&gt;，以及 IPv6 的前缀 &lt;code&gt;fc00::/7&lt;/code&gt;） 被保留用于构建专用网络。来自这些范围的地址可用于一个站点或组织内部的主机和路由器之间的通信，但不能跨越全球性的 Internet。因此，这些地址有时也被称为不可路由的地址。也就是说，它们不能在公共 Internet 中路由。&lt;/p&gt;\n&lt;p&gt;专用、不可路由的地址空间管理完全由本地决定。IPv4 专用地址在家庭网络、中等规模和大型企业内部网络中很常见。它们经常与网络地址转换（NAT）结合使用，在 IP 数据报进入 Internet 时修改其中的 IP 地址。我们在第 7 章详细讨论 NAT。&lt;/p&gt;\n&lt;h3 id=\&#34;251-ipv4ipv6-地址转换\&#34;&gt;2.5.1 IPv4/IPv6 地址转换&lt;/h3&gt;\n&lt;p&gt;在有些网络中，可能需要在 IPv4 和 IPv6 之间转换 [&lt;a href=\&#34;#RFC6127\&#34;&gt;RFC6127&lt;/a&gt;]。目前，已制定了一个用于单播转换的框架 [&lt;a href=\&#34;#RFC6144\&#34;&gt;RFC6144&lt;/a&gt;]，以及一个正在开发的用于组播转换的方案 [&lt;a href=\&#34;#IDv-4v6mc\&#34;&gt;IDv 4v6mc&lt;/a&gt;]。一个基本功能是提供自动、基于算法的地址转换。例如，使用“知名的” IPv6 前缀 &lt;code&gt;64:ff9b::/96&lt;/code&gt;或其他指定前缀， [&lt;a href=\&#34;#RFC6052\&#34;&gt;RFC6052&lt;/a&gt;] 定义了如何在单播地址中实现它。&lt;/p&gt;\n&lt;p&gt;该方案使用一种特殊地址格式，称为&lt;strong&gt;嵌入 IPv4 的 IPv6 地址&lt;/strong&gt;。这种地址在 IPv6 地址内部包含 IPv4 地址。它可采用 6 种格式之一来编码， IPv6 前缀长度必须是下列数值之一：32、&lt;br&gt;\n40、 48、 56、 64 或 96。图 2-10 显示了可用的格式。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;10\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1650940609621.png\&#34; alt=\&#34;图 2-10\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 2-10   IPv4 地址可以嵌人 IPv6 地址中，形成一个嵌入 IPv4 的 IPv6 地址。有 6 种不同的格式可用，这取决于使用的 IPv6 前缀长度。众所周知的前缀（Well-Known Prefix） &lt;code&gt;64:ff9b::/96&lt;/code&gt; 可用于 IPv4 和 IPv6 单播地址之间的自动转换&lt;/p&gt;\n&lt;p&gt;在该图中，前缀既可以是一个众所周知的前缀，也可以是组织为转换器分配的唯一前缀。第 64 至 71 位必须设置为 0，以保持与 [&lt;a href=\&#34;#RFC4291\&#34;&gt;RFC4291&lt;/a&gt;] 指定标识符的兼容性。后缀的位被保留，并且应设置为 00 然后，采用简单方法来生成嵌入 IPv4 的 IPv6 地址：将 IPv6 前缀与 32 位的 IPv4 地址相串联，并确保第 64 至 71 位被设置为 0 （如果有必要，插入）。在后缀的后面增加 0，直到生成一个 128 位地址。嵌入 IPv4 的 IPv6 地址使用 96 位前缀选项，该选项通常用前面提到的 IPv6 映射地址来表示（ [&lt;a href=\&#34;#RFC4291\&#34;&gt;RFC4291&lt;/a&gt;]中的 2.2(3) 节）。例如，嵌入 IPv4 地址 &lt;code&gt;198.51.100.16&lt;/code&gt; 和众所周知的前缀，生成地址 &lt;code&gt;64:ff9b::198.51.100.16&lt;/code&gt;。&lt;/p&gt;\n&lt;h3 id=\&#34;252-组播地址\&#34;&gt;2.5.2 组播地址&lt;/h3&gt;\n&lt;p&gt;IPv4 和 IPv6 支持组播寻址。一个 IP 组播地址（也称为&lt;strong&gt;组&lt;/strong&gt;或&lt;strong&gt;组地址&lt;/strong&gt;）标识一组主机接口，而不是单个接口。一般来说，一个组可以跨越整个 Internet。一个组所覆盖的网络部分称为组的&lt;strong&gt;范围&lt;/strong&gt; [&lt;a href=\&#34;#RFC2365\&#34;&gt;RFC2365&lt;/a&gt;]。常见的范围包括&lt;strong&gt;节点本地&lt;/strong&gt;（同一计算机）、&lt;strong&gt;链路本地&lt;/strong&gt;（同一子网）、&lt;strong&gt;站点本地&lt;/strong&gt;（适用于一些站点）、&lt;strong&gt;全球&lt;/strong&gt;（整个Internet）和&lt;strong&gt;管理&lt;/strong&gt;。管理范围的地址可用于一个网络区域内已手动配置到路由器的地址。站点管理员可将路由器配置为&lt;strong&gt;管理范围边界&lt;/strong&gt;，这意味着相关组的组播流量不会被路由器转发。注意，站点本地和管理范围只在使用组播寻址时有效。&lt;/p&gt;\n&lt;p&gt;在软件的控制下，每个 Internet 主机中的协议栈能加入或离开一个组播组。当一台主机向一个组发送数据时，它会创建一个数据报，使用（单播） IP 地址作为源地址，使用组播 IP 地址作为目的地址。已加入组的所有主机将接收发送到该组的任何数据报。发送方通常不知道主机是否接收到数据报，除非它们明确做出应答。事实上，发送方甚至不知道通常有多少台主机接收它的数据报。&lt;/p&gt;\n&lt;p&gt;至此，原有的组播服务模型已成为大家所知的&lt;strong&gt;任意源组播（ASM）&lt;/strong&gt;。在这种模型下，任何发送方可以发送给任何组；一个加入组的接收方被指定唯一的组地址。一种新方案称为&lt;strong&gt;源特定组播（SSM）&lt;/strong&gt; [&lt;a href=\&#34;#RFC3569\&#34;&gt;RFC3569&lt;/a&gt;][&lt;a href=\&#34;#RFC4607\&#34;&gt;RFC4607&lt;/a&gt;]，在每个组中只使用一个发送方（见 [&lt;a href=\&#34;#RFC4607\&#34;&gt;RFC4607&lt;/a&gt;] 的勘误表）。在这种情况下，当一台主机加入一个组后，它会被指定一个信道地址，其中包括一个组地址和一个源 IP 地址。 SSM 避免了 ASM 模型部署时的复杂性。尽管有多种组播形式在整个 Internet 中广泛使用，但 SSM 是当前更受欢迎的候选者。&lt;/p&gt;\n&lt;p&gt;在 Internet 社区中，对广域组播的理解和实现已经过十年以上的不懈努力，并且已经开发出大量的广域组播协议。全球性 Internet 组播如何工作的细节超出本文的范围，有兴趣的读者可以查看 [&lt;a href=\&#34;#IMRO2\&#34;&gt;IMRO2&lt;/a&gt;]。第 9 章详细介绍本地 IP 组播如何工作。现在，我们要讨论 IPv4 和 IPv6 组播地址的格式和意义。&lt;/p&gt;\n&lt;h3 id=\&#34;253-ipv4-组播地址\&#34;&gt;2.5.3 IPv4 组播地址&lt;/h3&gt;\n&lt;p&gt;对于 IPv4， D 类空间（&lt;code&gt;224.0.0.0 ~ 239.255.255.255&lt;/code&gt;）已被保留支持组播。 28 位空闲意味着可提供 2&lt;sup&gt;28&lt;/sup&gt;= 268 435 456 个主机组（每个组是一个 IP 地址）。这个地址空间被分为几个主要部分，它建立在对路由分配和处理的基础上 [&lt;a href=\&#34;#IP4MA\&#34;&gt;IP4MA&lt;/a&gt;]。表 2-9 列出了这些主要部分。&lt;/p&gt;\n&lt;center&gt;表 2-9  用于支持组播的 IPv4 的 D 类地址空间的主要部分&lt;/center&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;范围（包含）&lt;/th&gt;\n&lt;th&gt;特殊用途&lt;/th&gt;\n&lt;th&gt;参考文献&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;224.0.0.0 ~ 224.0.0.255&lt;/td&gt;\n&lt;td&gt;本地网络控制；不转发&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC5771\&#34;&gt;RFC5771&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;224.0.1.0 ~ 224.0.1.255&lt;/td&gt;\n&lt;td&gt;互联网络控制；正常转发&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC5771\&#34;&gt;RFC5771&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;224.0.2.0 ~ 224.0.255.255&lt;/td&gt;\n&lt;td&gt;Ad hoc 块 1&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC5771\&#34;&gt;RFC5771&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;224.1.0.0 ~ 224.1.255.255&lt;/td&gt;\n&lt;td&gt;保留&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC5771\&#34;&gt;RFC5771&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;224.2.0.0 ~ 224.2.255.255&lt;/td&gt;\n&lt;td&gt;SDP/SAP&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC4566\&#34;&gt;RFC4566&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;224.3.0.0 ~ 224.3.255.255&lt;/td&gt;\n&lt;td&gt;Ad hoc 块 2&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC5771\&#34;&gt;RFC5771&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;224.5.0.0 ~ 224.255.255.255&lt;/td&gt;\n&lt;td&gt;保留&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#IP4MA\&#34;&gt;IP4MA&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;225.0.0.0 ~ 231.255.255.255&lt;/td&gt;\n&lt;td&gt;保留&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#IP4MA\&#34;&gt;IP4MA&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;232.0.0.0 ~ 232.255.255.255&lt;/td&gt;\n&lt;td&gt;源特定组播（SSM）&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC4607\&#34;&gt;RFC4607&lt;/a&gt;] [&lt;a href=\&#34;#RFC4608\&#34;&gt;RFC4608&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;233.0.0.0 ~ 233.251.255.255&lt;/td&gt;\n&lt;td&gt;GLOP&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC3180\&#34;&gt;RFC3180&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;233.252.0.0 ~ 233.255.255.255&lt;/td&gt;\n&lt;td&gt;Ad hoc 块 3（233.252.0.0/24 为文档保留）&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC5771\&#34;&gt;RFC5771&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;234.0.0.0 ~ 234.255.255.255 &lt;br/&gt;235.0.0.0 ~ 238.255.255.255&lt;/td&gt;\n&lt;td&gt;基于单播前缀的 IPv4 组播地址保留&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC6034\&#34;&gt;RFC6034&lt;/a&gt;] [&lt;a href=\&#34;#IP4MA\&#34;&gt;IP4MA&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;239.0.0.0 ~ 239.255.255.255&lt;/td&gt;\n&lt;td&gt;管理范围&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2365\&#34;&gt;RFC2365&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;p&gt;到 &lt;code&gt;224.255.255.255&lt;/code&gt; 的地址块被分配给某些应用协议或组织使用。这些分配工作由 IANA 或 IETF 完成。本地网络控制块限制为发送方的本地网络；发送到这些地址的数据报不会被组播路由器转发。 “所有主机”组（&lt;code&gt;224.0.0.1&lt;/code&gt;）是这个块中的一个组。互联网络控制块类似于本地网络控制范围，其目的是控制需要被路由到本地链路的流量。该地址块的一个例子是网络时间协议（NTP）组播组（&lt;code&gt;224.0.1.1&lt;/code&gt;） [&lt;a href=\&#34;#RFC5905\&#34;&gt;RFC5905&lt;/a&gt;]。&lt;/p&gt;\n&lt;p&gt;第一个 Ad hoc（特定）块用于保留一些地址，避免它们落人本地或互联网络控制块。在此范围内的大多数分配是用于商业服务，其中一些不（或永远不）需要全球地址分配；它们可能最终被返还以支持 GLOP 寻址（见下一段落）。在 SDP/ SAP 块中包含某些应用所使用的地址，例如会话目录工具（SDR） [&lt;a href=\&#34;#H96\&#34;&gt;H96&lt;/a&gt;]，它使用&lt;strong&gt;会话通告协议（SAP）&lt;strong&gt;发送组播会议通告 [&lt;a href=\&#34;#RFC2974\&#34;&gt;RFC2974&lt;/a&gt;]。新的&lt;/strong&gt;会话描述协议（SDP）&lt;/strong&gt; [&lt;a href=\&#34;#RFC4566\&#34;&gt;RFC4566&lt;/a&gt;]最初只是 SAP 的一个组成部分，当前它不仅用于 IP 组播，而且与其他机制一起描述多媒体会话。&lt;/p&gt;\n&lt;p&gt;其他主要地址块的出现稍晚于 IP 组播的演变。如前面所述，某些应用使用 SSM 块实现 SSM，结合自已的单播源地址形成一个 SSM 信道。在 GLOP 块中，组播地址基于主机的**自治系统（AS）**号，该主机处于应用分配地址的一端。 AS 号用于 ISP 之间的 Internet 范围的路由协议，以聚合路由器和实现路由策略。 AS 号最初是 16 位，但现在已扩展到 32 位 [&lt;a href=\&#34;#RFC4893\&#34;&gt;RFC4893&lt;/a&gt;]。GLOP 地址的生成是将一个 16 位 AS 号放在 IPv4 组播地址的第 2 和第 3 字节，并且保留 1 字节的空间表示可能的组播地址（即多达 256 个地址）。因此，它可在一个 16 位 AS 号和与这个 AS 号相关联的 GLOP 组播地址之间来回映射。这个计算过程很简单，目前已开发出几个在线计算器。&lt;/p&gt;\n&lt;p&gt;最近， IPv4 组播地址分配机制将多个组播地址与一个 IPv4 单播地址前缀关联。这被称为基于&lt;strong&gt;单播前缀的组播&lt;/strong&gt;寻址（UBM），它在 [&lt;a href=\&#34;#RFC6034\&#34;&gt;RFC6034&lt;/a&gt;] 中描述。它基于 IPv6 发展早期的一个类似结构，我们在前面 2.5.4 节讨论过。 UBM 的 IPv4 地址范围是 &lt;code&gt;234.0.0.0&lt;/code&gt; 至  &lt;code&gt;234.255.255.255&lt;/code&gt;。单播地址需分配一个 &lt;code&gt;/24&lt;/code&gt; 或更短的前缀以使用 UBM 地址。分配更短的地&lt;br&gt;\n址（即 &lt;code&gt;/25&lt;/code&gt; 或更长的前缀）必须使用一些其他机制。 UBM 地址被构造成前缀 &lt;code&gt;234/8&lt;/code&gt;、分配的&lt;br&gt;\n单播前缀和组播组 ID 的串联。图 2-11 显示了这个格式。&lt;/p&gt;\n&lt;p&gt;为了确定与一个单播分配相关的 UBM 地址，分配前缀只是简单地在前面添加前缀 &lt;code&gt;234/8&lt;/code&gt;。例如，单播 IPv4 地址前缀 &lt;code&gt;192.0.2.0/24&lt;/code&gt; 有一个关联的 UBM 地址 &lt;code&gt;234.192.0.2&lt;/code&gt;。 通过对组播地址简单地“左平移” 8 位，有可能确定一个组播地址的所有者。例如，我们知道组播地址范围 &lt;code&gt;234.128.32.0/24&lt;/code&gt; 被分配给加州大学伯克利分校，这是由于相应的单播 IPv4 地址空间 &lt;code&gt;128.32.0.0/16&lt;/code&gt; （&lt;code&gt;234.128.32.0&lt;/code&gt; 的“左移”版本）是由加州大学伯克利分校所拥有(可以使用 WHOIS 查询来确定，见 2.6.1.1 节)。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;11\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1651033894464.png\&#34; alt=\&#34;图 2-11\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 2-11   IPv4 的 UBM 地址格式。为单播地址分配 &lt;code&gt;/24&lt;/code&gt; 或更短的前缀，关联的组播地址分配基于前缀 &lt;code&gt;234/8&lt;/code&gt;、分配的单播前缀和组播组 ID 的串联。因此，较短的单播前缀分配包含更多单播和组&lt;br&gt;\n播地址&lt;/p&gt;\n&lt;p&gt;UBM 地址比其他类型的组播地址分配有更多优点。例如，用于 GLOP 寻址时，它们可以不受 16 位 AS 号限制。另外，它们可作为已存在的单播地址空间的分配结果。因此，使用组播地址的站点知道哪些地址可用，并且不需要进一步协调。最后， UBM 地址可以比 GLOP 地址更好地分配，对应的 AS 号可分配到更细粒度。在今天的 Internet 中，一个 AS 号可以与多个站点关联，但令人沮丧的是 UBM 支持在地址和所有者之间的简单映射。&lt;/p&gt;\n&lt;p&gt;管理范围的地址块可用于限制分布在路由器和主机的特定集合中的组播流量。它可以看作组播对专用单播 IP 地址的模拟。这种地址不能用于将组播分发到 Internet，这是因为其中大多数流量被阻塞在企业边界。大型站点有时会划分管理范围的组播地址，以用于某些特定范围（例如，工作组、部门和地理区域）。&lt;/p&gt;\n&lt;h3 id=\&#34;254-ipv6-组播地址\&#34;&gt;2.5.4 IPv6 组播地址&lt;/h3&gt;\n&lt;p&gt;对于 IPv6，对组播的使用相当积极，前缀 &lt;code&gt;ff00::/8&lt;/code&gt; 已被预留给组播地址，并且 112 位可用于保存组号，可提供的组数为 2&lt;sup&gt;112&lt;/sup&gt;= 5 192 296 858 534 827 628 530 496 329 220 096。其一般格式如图 2-12 所示。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;12\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1651035439616.png\&#34; alt=\&#34;图 2-12\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 2-12   基本的 IPv6 组播地址格式包括 4 个标志位（0，保留； R，包含会合点； P，使用单播前缀； T，是临时的）。 4 位范围值表示组播的范围（全球、本地等）。组 ID 编码在低序的 112 位中。如果 P 或 R 位被设置，则使用一种代替格式&lt;/p&gt;\n&lt;p&gt;IPv6 组播地址的第 2 字节包含一个 4 位标志字段和一个 4 位&lt;strong&gt;范围&lt;/strong&gt; ID 字段。范围字段表示到某些组播地址的数据报的分配限制。十六进制值 0、3 和 f 保留。十六进制值 6、 7 和 9 ~ d未分配。表 2-10 给出了这些值（根据 [&lt;a href=\&#34;#RFC4291\&#34;&gt;RFC4291&lt;/a&gt;] 中的2.7节）。&lt;/p&gt;\n&lt;center&gt;表 2-10  IPv6 范围字段的值 &lt;/center&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;值&lt;/th&gt;\n&lt;th&gt;范围&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;0&lt;/td&gt;\n&lt;td&gt;保留&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;接口/机器本地&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;td&gt;链路/子网本地&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;3&lt;/td&gt;\n&lt;td&gt;保留&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;4&lt;/td&gt;\n&lt;td&gt;管理&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;5&lt;/td&gt;\n&lt;td&gt;站点本地&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;6 ~ 7&lt;/td&gt;\n&lt;td&gt;未分配&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;8&lt;/td&gt;\n&lt;td&gt;组织本地&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;9 ~ d&lt;/td&gt;\n&lt;td&gt;未分配&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;e&lt;/td&gt;\n&lt;td&gt;全球&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;f&lt;/td&gt;\n&lt;td&gt;保留&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;p&gt;很多 IPv6 组播地址由 IANA 分配为永久使用，并且故意跨越多个地址范围。这些组播地址对每个范围都有一定偏移量（由于这个原因，这些地址被称为&lt;strong&gt;相对范围&lt;/strong&gt;或&lt;strong&gt;可变范围&lt;/strong&gt;）。例如，可变范围的组播地址：&lt;code&gt;ff0x::101&lt;/code&gt; 是由 [&lt;a href=\&#34;#IP6MA\&#34;&gt;IP6MA&lt;/a&gt;] 为 NTP 服务器预留。 &lt;code&gt;x&lt;/code&gt; 表示可变范围，表 2-11 显示了一些预留定义的地址。&lt;/p&gt;\n&lt;center&gt;表 2-11  针对 NTP （101）的永久可变范围的 IPv6 组播地址保留的例子 &lt;/center&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;地址&lt;/th&gt;\n&lt;th&gt;含义&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;ff01::101&lt;/td&gt;\n&lt;td&gt;同一机器中的所有 NTP 服务器&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ff02::101&lt;/td&gt;\n&lt;td&gt;同一链路/子网中的所有 NTP 服务器&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ff04::101&lt;/td&gt;\n&lt;td&gt;某些管理定义范围内的所有 NTP 服务器&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ff05:101&lt;/td&gt;\n&lt;td&gt;同一站点中的所有 NTP 服务器&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ff08::101&lt;/td&gt;\n&lt;td&gt;同一组织中的所有 NTP 服务器&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ff0e::101&lt;/td&gt;\n&lt;td&gt;Internet 中的所有 NTP 服务器&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;p&gt;在 IPv6 中，当 P 和 R 位字段设置为 0 时，使用图 2-12 中给出的组播地址格式。当 P 设置为 1，无须基于每个组的全球性许可，对组播地址有两个可选方法。它们被描述在 [&lt;a href=\&#34;#RFC3306\&#34;&gt;RFC3306&lt;/a&gt;] 和 [&lt;a href=\&#34;#RFC4489\&#34;&gt;RFC4489&lt;/a&gt;] 中。第一种方法称为&lt;strong&gt;基于单播前缀&lt;/strong&gt;的 IPv6 组播地址分配，由 ISP 或地址分配机构提供单播前缀分配，并且有效分配一个组播地址集合，从而限制了因避免重复而需全球协调的数量。第二种方法称为&lt;strong&gt;链路范围&lt;/strong&gt;的 IPv6 组播，使用接口标识符，并且组播地址是基于主机的 IID。为了了解这些不同格式如何工作，首先要了解 IPv6 组播地址中位字段的使用细节。它们被定义在表 2-12 中。&lt;/p&gt;\n&lt;center&gt;表 2-12  IPv6 组播地址标志 &lt;/center&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;位字段（标志）&lt;/th&gt;\n&lt;th&gt;含义&lt;/th&gt;\n&lt;th&gt;参考文献&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;R&lt;/td&gt;\n&lt;td&gt;会合点标志（0，常规的；1，包括 RP 地址）&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC3956\&#34;&gt;RFC3956&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;P&lt;/td&gt;\n&lt;td&gt;前缀标志（0，常规的；1，基于单播前缀的地址）&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC3306\&#34;&gt;RFC3306&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;T&lt;/td&gt;\n&lt;td&gt;临时标志（0，永久分配的；1，临时的）&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC4291\&#34;&gt;RFC4291&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;p&gt;当 T 位字段被设置时，表示组地址是临时或动态分配的；它不是 [&lt;a href=\&#34;#IP6MA\&#34;&gt;IP6MA&lt;/a&gt;] 中定义的标准地址。当 P 位字段被设置为 1， T 位也必须被设置为 1 。 当这种情况发生时，使用基于单播地址前缀的特殊格式的 IPv6 组播地址，如图 2-13 所示。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;13\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1651040916674.png\&#34; alt=\&#34;图 2-13\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 2-13  IPv6 组 播地址可以基于单播 IPv6 地址来创建 [&lt;a href=\&#34;#RFC3306\&#34;&gt;RFC3306&lt;/a&gt;]。在这样做时， P 位字段设置为 1，单播前缀和 32 位的组 ID 被加入地址。这种形式的组播地址分配简少了全球地址分配协议的需求&lt;/p&gt;\n&lt;p&gt;这里，我们可以看到如何使用基于单播前缀的地址改变组播地址格式，包括一个单播前缀及其长度，以及一个更小的（32 位）组 ID。该方案的目的是提供全球唯一的 IPv6 组播地址分配方式，同时不需要提出新的全球性机制。由于 IPv6 单播地址已分配全球性的前缀单元（见 2.6 节），所以在组播地址中可以使用这个前缀中的位，从而在组播应用中利用现有的单播地址分配方法。例如，一个组织分配了一个单播前缀 &lt;code&gt;3ffe:ffff:1::/48&lt;/code&gt;，那么它随之分配了一个基于单播的组播前缀 &lt;code&gt;ff3x:30:3ffe:ffff:1::/96&lt;/code&gt;，其中 &lt;code&gt;x&lt;/code&gt; 是任何有效范围。 SSM 通过设置前缀长度和将前缀字段设置为 0 来支持这种格式，以便有效地将前缀 &lt;code&gt;ffx::/32&lt;/code&gt; （其中 &lt;code&gt;x&lt;/code&gt; 是任何有效的范围值）用于所有这类 IPv6 SSM 组播地址。&lt;/p&gt;\n&lt;p&gt;为了创建唯一的链路本地范围的组播地址，可使用一种基于 IID 的方法 [&lt;a href=\&#34;#RFC4489\&#34;&gt;RFC4489&lt;/a&gt;]，当只需要链路本地范围时，这种方法是基于单播前缀分配的首选。在这种情况下，可使用另一种形式的 IPv6 组播地址结构（见图 2-14 ）。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;14\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1651042022256.png\&#34; alt=\&#34;图 2-14\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 2-14   IPv6 链路范围的组播地址格式。只适用于链路（或更小）范围内的地址，组播地址可以结合 IPv6 接口 ID 和组 ID 来形成。这种映射是直接的，所有地址使用前缀形式 &lt;code&gt;ff3:0011/32&lt;/code&gt;，其中 &lt;code&gt;x&lt;/code&gt; 是范围 ID 并且小于 3&lt;/p&gt;\n&lt;p&gt;图 2-14 所示的地址格式与图 2-13 的格式相似，除了&lt;strong&gt;前缀长度&lt;/strong&gt;字段被设置为 255，并将随后字段中的前缀替换为 IPv6 的 IID。这个结构的优点是不需要提供前缀以形成组播地址。在不需要路由器的 Ad hoc（无线自组织）网络中，一台单独的计算机可基于自已的 IID 形成唯一的组播地址，而无须运行一个复杂的许可协议。如前所述，这种格式只适用于本地链路或节点组播范围。但是，当需要更大的范围时，无论是基于单播前缀的地址还是永久组播地址都可使用。作为这种格式的一个例子，一个 IID &lt;code&gt;02-11-22-33-44-55-66-77&lt;/code&gt; 的主机将使用 组播地址  &lt;code&gt;ff3x:0011:0211:2233:4455:6677:gggg:gggg&lt;/code&gt;，其中 &lt;code&gt;x&lt;/code&gt; 是一个等于或小于 2 的范围值， &lt;code&gt;gggg:gggg&lt;/code&gt; 是一个 32 位组播组 ID 的十六进制表示。&lt;/p&gt;\n&lt;p&gt;我们还要讨论的位字段是 R 位字段。当使用基于单播前缀的地址（P 位被设置）时，它表示组播路由协议需要知道一个会合点。&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;注意   会合点（RP）是一个路由器中用于处理一个或多个组播组的组播路由的 IP 地址。 RP 用于\nPIM-SM协议 [RFC4601]，以帮助参加同一组播组中的发送方和接收方找到对方。 Internet 范围\n的组播部署遇到的问题之一是会合点定位。这种方法重载 IPv6 组播地址以包含一个 RP 地址。因\n此，从一个组地址找到一个 RP 是简单的，只需从中选择合适的位的子集。\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;当标志 P 被设置时，图 2-15 显示了组播地址修改后的格式。&lt;/p&gt;\n&lt;p&gt;图 2-15 所示的格式与图 2-13 类似，但不使用 SSM （这样前缀长度不能为零）。另外，新引入了一个称为 RIID 的 4 位字段。为了形成图 2-15 所示格式的基于 RP 地址的 IPv6 地址，前缀长度字段表示的位数从前缀字段提取，并放置在一个新的 IPv6 地址的高位。然后，RIID 字段值被用作 RP 地址的低 4 位。剩余的部分用零填充。作为一个例子，我们看一个组播地址&lt;code&gt;ff75:940:2001:db8:dead:beef:f00d:face&lt;/code&gt;。在这个例子中，范围为 5 （站点本地）， RIID 字段值为 9，前缀长度为 &lt;code&gt;0x40 = 64&lt;/code&gt; 位。因此，前缀本身为 &lt;code&gt;2001:db8‥dead:beef&lt;/code&gt;， RP 地址为 &lt;code&gt;2001‥db8:dead:beef::9&lt;/code&gt;。更多的例子见 [&lt;a href=\&#34;#RFC3956\&#34;&gt;RFC3956&lt;/a&gt;]。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;15\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1651043845441.png\&#34; alt=\&#34;图 2-15\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 2-15   RP 的单播 IPv6 地址可以嵌入 IPv6 组播地址 [&lt;a href=\&#34;#RFC3956\&#34;&gt;RFC3956&lt;/a&gt;]。56]。这样，它可以直接找到用于路由的 RP 关联的地址。RP 被用于组播路由系统，以协调不在同一子网中的组播发送方和接收方&lt;/p&gt;\n&lt;p&gt;与 IPv4 相似， IPv6 也有一些保留的组播地址。除了前面提到的可变范围地址，这些地址还根据范围划分成组。表 2-13 给出了一个 IPv6 组播空间中的保留列表。 [&lt;a href=\&#34;#IP6MA\&#34;&gt;IP6MA&lt;/a&gt;] 提供了更多的信息。&lt;/p&gt;\n&lt;center&gt;表 2-13   IPv6 组播地址空间中的保留地址&lt;/center&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;地址&lt;/th&gt;\n&lt;th&gt;范围&lt;/th&gt;\n&lt;th&gt;特殊用途&lt;/th&gt;\n&lt;th&gt;参考文献&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;ff01::1&lt;/td&gt;\n&lt;td&gt;节点&lt;/td&gt;\n&lt;td&gt;所有节点&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC4291\&#34;&gt;RFC4291&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ff01::2&lt;/td&gt;\n&lt;td&gt;节点&lt;/td&gt;\n&lt;td&gt;所有路由器&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC4291\&#34;&gt;RFC4291&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ff01::fb&lt;/td&gt;\n&lt;td&gt;节点&lt;/td&gt;\n&lt;td&gt;mDNSv6&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#IDChes\&#34;&gt;IDChes&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ff02::1&lt;/td&gt;\n&lt;td&gt;链路&lt;/td&gt;\n&lt;td&gt;所有节点&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC4291\&#34;&gt;RFC4291&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ff02::2&lt;/td&gt;\n&lt;td&gt;链路&lt;/td&gt;\n&lt;td&gt;所有路由器&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC4291\&#34;&gt;RFC4291&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ff02::4&lt;/td&gt;\n&lt;td&gt;链路&lt;/td&gt;\n&lt;td&gt;DVMRP 路由器&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC1075\&#34;&gt;RFC1075&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ff02::5&lt;/td&gt;\n&lt;td&gt;链路&lt;/td&gt;\n&lt;td&gt;OSPFIGP&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2328\&#34;&gt;RFC2328&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ff02::6&lt;/td&gt;\n&lt;td&gt;链路&lt;/td&gt;\n&lt;td&gt;基于 OSPFIGP 设计的路由器&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2328\&#34;&gt;RFC2328&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ff02::9&lt;/td&gt;\n&lt;td&gt;链路&lt;/td&gt;\n&lt;td&gt;RIPng 路由器&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC2080\&#34;&gt;RFC2080&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ff02::a&lt;/td&gt;\n&lt;td&gt;链路&lt;/td&gt;\n&lt;td&gt;EIGRP 路由器&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#EIGRP\&#34;&gt;EIGRP&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ff02::d&lt;/td&gt;\n&lt;td&gt;链路&lt;/td&gt;\n&lt;td&gt;PIM 路由器&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC5059\&#34;&gt;RFC5059&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ff02::16&lt;/td&gt;\n&lt;td&gt;链路&lt;/td&gt;\n&lt;td&gt;支持 MLDv2 的路由器&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC3810\&#34;&gt;RFC3810&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ff02::6a&lt;/td&gt;\n&lt;td&gt;链路&lt;/td&gt;\n&lt;td&gt;所有探测器&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC4286\&#34;&gt;RFC4286&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ff02::6d&lt;/td&gt;\n&lt;td&gt;链路&lt;/td&gt;\n&lt;td&gt;LL-MANET 路由器&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC5498\&#34;&gt;RFC5498&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ff02::fb&lt;/td&gt;\n&lt;td&gt;链路&lt;/td&gt;\n&lt;td&gt;mDNSv6&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#IDChes\&#34;&gt;IDChes&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ff02::1:2&lt;/td&gt;\n&lt;td&gt;链路&lt;/td&gt;\n&lt;td&gt;所有 DHCP 代理&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC3315\&#34;&gt;RFC3315&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ff02::1:3&lt;/td&gt;\n&lt;td&gt;链路&lt;/td&gt;\n&lt;td&gt;LLMNR&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC4795\&#34;&gt;RFC4795&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ff02::1:ffxx:xxxx&lt;/td&gt;\n&lt;td&gt;链路&lt;/td&gt;\n&lt;td&gt;请求节点地址范围&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC4291\&#34;&gt;RFC4291&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ff05::2&lt;/td&gt;\n&lt;td&gt;站点&lt;/td&gt;\n&lt;td&gt;所有路由器&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC4291\&#34;&gt;RFC4291&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ff05::fb&lt;/td&gt;\n&lt;td&gt;站点&lt;/td&gt;\n&lt;td&gt;mDNSv6&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#IDChes\&#34;&gt;IDChes&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ff05::1:3&lt;/td&gt;\n&lt;td&gt;站点&lt;/td&gt;\n&lt;td&gt;所有 DHCP 服务器&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC3315\&#34;&gt;RFC3315&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ff0x::&lt;/td&gt;\n&lt;td&gt;可变的&lt;/td&gt;\n&lt;td&gt;保留&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC4291\&#34;&gt;RFC4291&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ff0x::fb&lt;/td&gt;\n&lt;td&gt;可变的&lt;/td&gt;\n&lt;td&gt;mDNSv6&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#IDChes\&#34;&gt;IDChes&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ff0x::101&lt;/td&gt;\n&lt;td&gt;可变的&lt;/td&gt;\n&lt;td&gt;NTP&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC5905\&#34;&gt;RFC5905&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ff0x::133&lt;/td&gt;\n&lt;td&gt;可变的&lt;/td&gt;\n&lt;td&gt;聚合服务器访问协议&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC5352\&#34;&gt;RFC5352&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ff0x::18c&lt;/td&gt;\n&lt;td&gt;可变的&lt;/td&gt;\n&lt;td&gt;所有 AC 的地址（CAPWAP）&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC5415\&#34;&gt;RFC5415&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ff3x::/32&lt;/td&gt;\n&lt;td&gt;（特殊的）&lt;/td&gt;\n&lt;td&gt;SSM 块&lt;/td&gt;\n&lt;td&gt;[&lt;a href=\&#34;#RFC4607\&#34;&gt;RFC4607&lt;/a&gt;]&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;h3 id=\&#34;255-任播地址\&#34;&gt;2.5.5 任播地址&lt;/h3&gt;\n&lt;p&gt;任播地址是一个单播 IPv4 或 IPv6 地址，这些地址根据它所在的网络确定不同的主机。这是通过配置路由器通知 Internet 中多个站点有相同单播路由来实现。因此，一个任播地址不是指 Internet 中的一台主机，而是对于任播地址“最合适”或“最接近”的一台主机。任播地址最常用于发现一台提供了常用服务的计算机 [&lt;a href=\&#34;#RFC4786\&#34;&gt;RFC4786&lt;/a&gt;]。例如，某个数据报发送到一个任播地址，可用于找到 DNS 服务器（见第 11 章）， 6to4 网关将 IPv6 流量封装在 IPv4 隧道中 [&lt;a href=\&#34;#RFC3068\&#34;&gt;RFC3068&lt;/a&gt;]，或用于组播路由的 RP 中 [&lt;a href=\&#34;#RFC4610\&#34;&gt;RFC4610&lt;/a&gt;]。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;26-分配\&#34;&gt;2.6 分配&lt;/h2&gt;\n&lt;p&gt;IP 地址空间通常被分配为大的块，这由一些分层次组织的权威机构完成。权威机构是为各种“所有者”分配地址空间的组织， “所有者”通常是 ISP 或其他较小的权威机构。权威机构经常参与全球单播地址空间分配，但有时也分配其他类型的地址（组播和特殊用途）。权威机构为用户分配一个不限时的地址块，或是一个限时（例如实验）的地址块。这个层次结构的顶部是 IANA [&lt;a href=\&#34;#IANA\&#34;&gt;IANA&lt;/a&gt;] ，它负责分配 IP 地址和 Internet 协议使用的其他号码。&lt;/p&gt;\n&lt;h3 id=\&#34;261-单播\&#34;&gt;2.6.1 单播&lt;/h3&gt;\n&lt;p&gt;对于单播 IPv4 和 IPv6 的地址空间， IANA 将分配权限主要委托给几个&lt;strong&gt;地区性 Internet 注册机构（RIR）&lt;/strong&gt;。 RIR 之间通过一个组织互相协作，即 2003 年创建的号码资源组织（NRO）[&lt;a href=\&#34;#NRO\&#34;&gt;NRO&lt;/a&gt;]。表 2-14 给出了本书写作时（2011 年中期）的一组 RIR，它们都加人了 NRO。截至 2011 年初， IANA 拥有的剩余的 IPv4 单播地址空间将移交给这些 RIR 分配。&lt;/p&gt;\n&lt;center&gt; 表 2-14  加入 NRO 的地区性 Internet 注册机构 &lt;/center&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;RIR 名称&lt;/th&gt;\n&lt;th&gt;负责的地区&lt;/th&gt;\n&lt;th&gt;参考文献&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;AfriNIC——非洲网络信息中心&lt;/td&gt;\n&lt;td&gt;非洲&lt;/td&gt;\n&lt;td&gt;http://www.afrinic.net&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;APNIC——亚洲太平洋地区网络信息中心&lt;/td&gt;\n&lt;td&gt;亚洲/太平洋地区&lt;/td&gt;\n&lt;td&gt;http://www.apnic.net&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ARIN——美洲 Internet 号码注册机构&lt;/td&gt;\n&lt;td&gt;北美洲&lt;/td&gt;\n&lt;td&gt;http://www.arin.net&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;LACNIC——拉丁美洲和加勒比地区的 IP 地址注册&lt;/td&gt;\n&lt;td&gt;拉丁美洲和一些加勒比岛屿&lt;/td&gt;\n&lt;td&gt;http://lacnic.net/en/index.html&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;RIPE NCC——欧洲网络协调中心&lt;/td&gt;\n&lt;td&gt;欧洲、中东、中亚&lt;/td&gt;\n&lt;td&gt;http://www.ripe.net&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;p&gt;这些实体通常处理较大的地址块 [&lt;a href=\&#34;#IP4AS\&#34;&gt;IP4AS&lt;/a&gt;] [&lt;a href=\&#34;#IP6AS\&#34;&gt;IP6AS&lt;/a&gt;]。他们为一些国家（例如澳大利亚和新加坡）运营的小型注册机构和大型 ISP 分配地址空间。接下来， ISP 为自已和自已的客户提供地址空间。当用户登记 Internet 服务时，他们通常以地址前缀形式使用 ISP 地址空间的一部分（通常很小）。这些地址范围由客户的 ISP 拥有和管理，并被称为&lt;strong&gt;供应商聚合（PA）&lt;strong&gt;的地址，这是由于它们包含一个或多个前缀，并可与 ISP 的其他前缀实现聚合。这种地址有时也称为&lt;/strong&gt;不可移植&lt;/strong&gt;的地址。交换供应商通常需要客户自已修改连接到 Internet 的所有主机和路由器的IP前缀（这种不愉快的操作通常称为&lt;strong&gt;重新编号&lt;/strong&gt;）。&lt;/p&gt;\n&lt;p&gt;一种可选的地址空间类型称为&lt;strong&gt;供应商独立（PI）&lt;strong&gt;的地址空间。从 PI 空间分配的地址可以直接分配给用户，并且可以由任何 ISP 来使用。但是，由于这些地址是客户拥有的，它们没有与 ISP 的地址在数字上相邻，因此它们不能聚合。一个 ISP 需要为客户的 PL 地址提供路由，客户可能需要为路由服务支付额外费用，或根本不支持这种服务。在某种意义上，一个 ISP 同意为客户的 PI 地址提供路由，相对于其他客户有一个额外成本，它会增加自已的路由表大小。另一方面，很多站点喜欢使用 PI 地址，他们可能愿意支付额外费用，因为有助于转换 ISP 时避免重新编号（这被称为&lt;/strong&gt;供应商锁&lt;/strong&gt;）。&lt;/p&gt;\n&lt;h4 id=\&#34;2611-例子\&#34;&gt;2.6.1.1 例子&lt;/h4&gt;\n&lt;p&gt;这时，可能需要使用 Internet 中的WHOIS服务，以确定如何分配地址空间。例如，我们可通过访问相应的URL http://whois.arin.net/rest/ip/72.1.140.203.txt ，形成一个对 IPv4 地址  &lt;code&gt;72.1.140.203&lt;/code&gt; 的信息查询：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;Net Range:    72.1.140.192 - 72.1.140.223\nCIDR:         72.1.140.192/27\nOriginAS:\nNetName:      SPEK-SEA5-PART-1\nNetHandle:    NET-71-1-140-192-1\nParent:       NET-72-1-128-0-1\nNetType:      Reassigned\nRegDate:      2005-06-29\nUpdated:      2005-06-29\nRef:          http://whois.arin.net/rest/net/NET-71-1-140-192-1\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;这里，我们看到地址 &lt;code&gt;72.140.203&lt;/code&gt; 实际上是网络 SPEK-SEA5-PART-1 的一部分，并且已分配地址范围 &lt;code&gt;72.1.140.192/27&lt;/code&gt;。另外，我们可以看到， SPEK-SEA5-PART-1 的地址范围是 NET-72-1-128-0-1 的 PA 地址空间的一部分。我们可生成一个关于该网络的信息查询，需要访问 URL  http://whois.arin.net/rest/net/NET-71-1-128-0-1.txt 。&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;Net Range:    72.1.128.0 - 72.1.191.255\nCIDR:         72.1.128.0/18\nOriginAS:\nNetName:      SPEAKEASY-6\nNetHandle:    NET-71-1-128-0-1\nParent:       NET-72-0-0-0-0\nNetType:      Direct Allocation\nRegDate:      2004-09-09\nUpdated:      2009-05-19\nRef:          http://whois.arin.net/rest/net/NET-71-1-128-0-1\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;这个记录指出地址范围 &lt;code&gt;72.1.128.0/18&lt;/code&gt;（称为“句柄”或名称 NET-72-1-128-0-1）已被直接分配，它在 ARIN 管理的地址范围 &lt;code&gt;72.0.0.0/8&lt;/code&gt; 之外。有关 ARIN 支持的数据格式和多种方法的更多细节，可以通过 WHOIS 查询在 &lt;a href=\&#34;#WRWS\&#34;&gt;[WRWS]&lt;/a&gt; 中看到。&lt;/p&gt;\n&lt;p&gt;通过其他 Internet 注册机构，我们可以看到不同的结果。例如，如果使用 Web 查询接口 http://www.ripe.net/whois 搜索有关 IPv4 地址 &lt;code&gt;193.5.93.80&lt;/code&gt; 的信息，我们将获得下面的结果：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;% This is the RIPE Database query service.\n% The objects are in RPSL format.\n%\n% The RIPE Database is subject to Terms and Conditions.\n% See http://www.ripe.net/db/support/db-terms-conditions.pdf\n% \n% Note: This output has been filtered.\n%       To receive output for a database update， use the &amp;quot;-B&amp;quot; flag.\n% Information related to &#39;193.5.88.0 - 193.5.95.255&#39;\ninetnum:         193.5.88.0 - 193.5.95.255\nnetname:         WIPONET\ndescr:           World Intellectual Property Organization\ndescr:           UN Specialized Agency\ndescr:           Geneva\ncountry:         CH\norg:             ORG-WWIP1-RIPE\nadmin-c:         AM4504-RIPE\ntech-c:          AM4504-RIPE\nmnt-by:          RIPE-NCC-END-MNT\nstatus:          ASSIGNED PI\nmnt-by:          ICC-NETMGR-MNT\nmnt-by:          CH-UNISOURCE-MNT\nmnt-by:          DE-COLT-MNT\ncreated:         2002-08-16T08:00:36Z\nlast-modified:   2018-06-22T08:40:13Z\nsource:          RIPE\nsponsoring-org:  ORG-UNIC3-RIPE\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;我们可以看到，地址 &lt;code&gt;193.5.93.80&lt;/code&gt; 是分配给 WIPO 的地址块 &lt;code&gt;193.5.88.0/21&lt;/code&gt; 的一部分。注意，这个块的状态为 &lt;code&gt;ASSIGNED PI&lt;/code&gt;，意味着该地址块是供应商独立类型。 RPSL 的参考文献表示数据库记录使用路由策略规范语言 [&lt;a href=\&#34;#RFC2622\&#34;&gt;RFC2622&lt;/a&gt;] [&lt;a href=\&#34;#RFC4012\&#34;&gt;RFC4012&lt;/a&gt;]， ISP 用它来表示自已的路由策略。这些信息允许网络运营商配置路由器，以帮助缓解 Internet 中的路由不稳定。&lt;/p&gt;\n&lt;h3 id=\&#34;262-组播\&#34;&gt;2.6.2 组播&lt;/h3&gt;\n&lt;p&gt;在 IPv4 和 IPv6 中，组播地址（即组地址）可根据其范围来描述，它们需要确定组播方式（静态、动态的协议或算法），以及是否使用 ASM 或 SSM。这些组的分配策略已被制定（ [&lt;a href=\&#34;#RFC5771\&#34;&gt;RFC5771&lt;/a&gt;] 针对 IPv4 ； [&lt;a href=\&#34;#RFC3307\&#34;&gt;RFC3307&lt;/a&gt;] 针对 IPv6 ），整体架构在 [&lt;a href=\&#34;#RFC6308\&#34;&gt;RFC6308&lt;/a&gt;] 中详细描述。全球范围之外的组（例如管理范围的地址和 IPv6 链路范围的组播地址）可在 Internet 的各个部分重复使用，并由网络管理员配置管理范围之外的地址块或由端主机自动选择。静态分配的全球范围地址通常是固定的，并且可能被硬件编码到应用中。这种地址空间是有限的，特别是在 IPv4 中，这种地址实际上计划被用于任何其他 Internet 站点。通过算法确定的全球范围地址可以像 GLOP 基于 AS 号创建，或是根据相关的单播前缀分配。注意， SSM 可使用全球范围的地址（即来自SSM块）、管理范围的地址，或前缀实际为 0 的基于单播前缀的 IPv6 地址。&lt;/p&gt;\n&lt;p&gt;我们可以看到，大量的协议和复杂的组播地址格式，导致组播地址管理成为一个难题（更不用说全球组播路由 [&lt;a href=\&#34;#RFC5110\&#34;&gt;RFC5110&lt;/a&gt;]）。从用户的角度来看，组播很少使用，可能受到的关注有限。从程序员的角度来看，在应用设计中支持组播可能是有价值的， [&lt;a href=\&#34;#RFC3170\&#34;&gt;RFC3170&lt;/a&gt;]提供了一些这方面的设想。当网络管理员需要实现组播时，与服务提供商的交流可能是必要的。另外，一些组播地址分配方案已由厂商开发 [&lt;a href=\&#34;#CGEMA\&#34;&gt;CGEMA&lt;/a&gt;] 。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;27-单播地址分配\&#34;&gt;2.7 单播地址分配&lt;/h2&gt;\n&lt;p&gt;一个站点分配了单播 IP 地址范围后 —— 通常是从自己的 ISP 处获得，站点或网络管理员需要决定如何为每个网络接口指定地址，以及如何建立子网结构。如果这个站点只有一个物理网段（例如大多数家庭），这个过程相对简单。对于规模较大的企业，尤其是那些由多个 ISP 提供服务，并且多个物理网段分布在很大地理区域的企业，这个过程可能非常复杂。我们来看在以下情况下如何工作，家庭用户使用一个专用地址和一个 ISP 提供的 IPv4 地址。这是目前常见的场景。接着，我们继续介绍一些更复杂的情况。&lt;/p&gt;\n&lt;h3 id=\&#34;271-单个供应商无网络单个地址\&#34;&gt;2.7.1 单个供应商/无网络/单个地址&lt;/h3&gt;\n&lt;p&gt;目前，我们可获得的最简单的 Internet 服务是由 ISP 提供一个在一台计算机上使用的 IP 地址（在美国通常只是IPv4）。例如，对于 DSL 服务，单个地址可被分配到一个点到点链路的一端，并可能只是暂时的。例如，如果用户的计算机通过 DSL 连接 Internet，它可能在某天被分配了一个地址&lt;code&gt;63.204.134.177&lt;/code&gt;。在计算机上运行的任何程序可以发送和接收 Internet流量，这些流量将采用 &lt;code&gt;63.204.134.177&lt;/code&gt; 作为 IPv4 源地址。一台主机同样也有其他活动的 IP 地址。这些地址包括本地的“回送”地址（&lt;code&gt;127.0.0.1&lt;/code&gt;）和一些组播地址，至少包括所有主机的组播地址（&lt;code&gt;224.0.0.1&lt;/code&gt;）。如果主机正在运行 IPv6，它至少使用所有节点的 IPv6 组播地址（&lt;code&gt;ff02::!&lt;/code&gt;）、 ISP 分配的任何 IPv6 地址、 IPv6 回送地址( &lt;code&gt;::1&lt;/code&gt; )和为每个网络接口配置的一个用于 IPv6 的链接本地地址。&lt;/p&gt;\n&lt;p&gt;为了在 Linux 上查看一台主机使用的组播地址（组），我们可使用 ifconfig 和 netstat 命令查看正在使用的 IP 地址和组：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;Linux% ifconfig ppp0\nppp0  Link encap: Point-to-Point Protocol\n      inet addr:71.141.244.213\n      P-t-P:71.141.255.254   Mask:255.255.255.255\n      UP POINTOPOINT RUNNING NOARP MULTICAST   MTU:1492   Metric:1\n      RX packets:33134  errors:0  dropped:0  overruns:0  frame:0\n      TX packets:41031  errors:0  dropped:0  overruns:0  carrier:0\n      collisions:0  txqueuelen:3\n      RX bytes:17748984 (16.9 MiB)   TX bytes:9272209 (8.8 MiB)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;pre&gt;&lt;code&gt;Linux% netstat -gn\nIPv6/IPv4 Group Memberships\nInterface   RefCnt   Group\n---------   ------   ----------------\nlo          1        224.0.0.1\nppp0        1        224.0.0.251\nppp0        1        224.0.0.1\nlo          1        ff02::1\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;这里，我们看到设备 ppp0 关联的一条点到点链路，它已分配 IPv4 地址 &lt;code&gt;71.141.244.213&lt;/code&gt; ;但没有分配 IPv6 地址。这台主机系统已启用 IPv6，但当检查它的组成员时，我们看到其本地回送（lo）接口出现在“所有 IPv6 节点”组播组中。我们也可以看到， IPv4 所有节点组正在使用，以及 mDNS （组播DNS）服务 [&lt;a href=\&#34;#IDChes\&#34;&gt;IDChes&lt;/a&gt;] 。 mDNS 协议使用静态 IPv4 组播地址 &lt;code&gt;224.0.0.251&lt;/code&gt;。&lt;/p&gt;\n&lt;h3 id=\&#34;272-单个供应商单个网络单个地址\&#34;&gt;2.7.2 单个供应商/单个网络/单个地址&lt;/h3&gt;\n&lt;p&gt;很多拥有多台计算机的 Internet 用户发现，只有一台计算机连接到 Internet 并不是理想情况。因此，他们通常拥有家庭局域网（LAN）或无线局域网（WLAN），并使用一台路由器或主机作为路由器连接 Internet。这种配置与单个计算机的情况相似，除了路由器将分组从家庭网络转发到 ISP，它们也执行 NAT （见第 7 章；在 Windows 中称为 Internet 连接共享（ICS）），在与 ISP 通信时重写分组中的 IP 地址。从 ISP 的角度来看，只有一个 IP 地址被使用。目前，这些操作大部分是自动的，因此需要手动配置的地址很少。路由器使用 DHCP 为家庭用户提供自动地址分配。如果有必要，它们也为与 ISP 建立链路提供地址分配。第 6 章详细介绍 DHCP 操作和主机配置。&lt;/p&gt;\n&lt;h3 id=\&#34;273-单个供应商多个网络多个地址\&#34;&gt;2.7.3 单个供应商/多个网络/多个地址&lt;/h3&gt;\n&lt;p&gt;很多组织发现仅分配一个单播地址，特别是当它只是暂时分配时，通常无法满足自己的上网需求。对于运行 Internet服务器（例如 Web 站点）的组织，通常希望拥有一个固定的 IP 地址。这些站点经常有多个局域网，其中有些是内部的（通过防火墙和 NAT 设备与 Internet 分离），有些可能是外部网（为 Internet 提供服务）。对于这样的网络，通常需要有一个站点或网络管理员，以确定站点需要多少个 IP 地址，如何构建网站的子网，以及哪些子网是内部或外部网。图 2-16 显示了典型的中小规模企业方案。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;16\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1651066473523.png\&#34; alt=\&#34;图 2-16\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 2-16   一个典型的小型到中型规模的企业网络。该网站已被分配 &lt;code&gt;128.32.2.64/26&lt;/code&gt; 范围内的 64 个公开（可路由）的 IPv4 地址。 “DMZ”网络包含 Internet 中可见的服务器。内部路由器使用 NAT 为企业内部的计算机提供 Internet 访问&lt;/p&gt;\n&lt;p&gt;在该图中，一个站点已分配前缀 &lt;code&gt;128.32.2.64/26&lt;/code&gt;，提供最多 64 （减 2）个可路由的 IPv4 地址。 “DMZ”网络（“非军事区”网络，在主防火墙之外，见第 7 章）用来连接服务器，以便 Internet 中的用户可以访问它们。这种计算机通常提供 Web 访问、登录服务器和其他服务。这些服务器的 IP 地址来自前缀范围的一小部分；很多站点只拥有少数的公共服务器。站点前缀中的保留地址交给 NAT 路由器，将它们作为一个“NAT 池”（见第 7 章）的基础。 NAT 路由器可以使用池中的任何地址重写进入或离开内部网络的数据报。图 2-16 显示的网络设置很方便，这里主要有两个原因。&lt;/p&gt;\n&lt;p&gt;首先，将内部网络与 DMZ 分隔开，有助于保护内部的计算机免受破坏，并由 DMZ 服务器来面对攻击。另外，它会设置区域内的 IP 地址。在边界路由器、 DMZ 和内部 NAT 路由器建立后，可在内部使用任何地址结构，其中可以使用很多（专用的） IP 地址。当然，这个例子只是建立小型的企业网络的一种方式，其他因素（例如成本）可能最终决定路由器、网络和 IP 地址在小型或中型规模的企业中的部署方式。&lt;/p&gt;\n&lt;h3 id=\&#34;274-多个供应商多个网络多个地址多宿主\&#34;&gt;2.7.4 多个供应商/多个网络/多个地址（多宿主）&lt;/h3&gt;\n&lt;p&gt;对于一些依赖 Internet 接人来保证持续运营的组织，他们通常使用一个以上的供应商（称为&lt;strong&gt;多宿主&lt;/strong&gt;），以便在失效时或其他情况下提供冗余连接。由于 CIDR，只有一个 ISP 的组织通常拥有与该 ISP 相关联的 PA 地址。如果他们又使用一个 ISP，这样会出现每个主机使用哪个 IP 地址的问题。目前，已有针对多个 ISP 同时运行的方法，以及在 ISP 之间转换的指导原则（其中提出了一些类似问题）。对于 IPv4， [&lt;a href=\&#34;#RFC4116\&#34;&gt;RFC4116&lt;/a&gt;]讨论了 PI 或 PA 地址如何用于多宿主。我们看图 2-17 所示的情况。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;17\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1651067041956.png\&#34; alt=\&#34;图 2-17\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 2-17   供应商聚合和供应商独立的 IPv4 地址用于一个假设的多宿主企业。如果 PI 地址是可用的，站点运营者倾向于选择使用 PI 空间。 ISP更喜欢 PA 空间，因为它可促进前缀聚合，减少路&lt;br&gt;\n由表的大小&lt;/p&gt;\n&lt;p&gt;这里，一个虚拟的站点 S 有两个 ISP，即 P1 和 P2。如果它使用来自 P1 块（&lt;code&gt;12.46.129.0/25&lt;/code&gt;）的 PA 地址空间，将在 C 和 D 点把该前缀分别通知 P1 和 P2。 这个前缀可被 P1 聚合到自已的 &lt;code&gt;12/8&lt;/code&gt; 块，并在 A 点将它通知 Internet 其他部分，但 P2 不能在 B 点聚合该前缀，因为它与自已的前缀（&lt;code&gt;137.164/16&lt;/code&gt;）在数值上不相邻。另外，从Internet 其他部分的一些主机的角度来看， &lt;code&gt;12.46.129.0/25&lt;/code&gt; 的流量趋向于 ISP P2 而不是 ISP P1，因为站点 S 的前缀比它通过 P1 时更长（“更具体”）。这是 Internet 路由（详情见第 5 章）采用最长匹配前缀算法工作方式的结果。本质上，一台 Internet 其他部分的主机经过 A 点匹配的前缀 &lt;code&gt;12.0.0.0/8&lt;/code&gt; 或 B 点匹配的前缀 &lt;code&gt;12.46.129.0/25&lt;/code&gt; 都可到达 &lt;code&gt;12.46.129.1&lt;/code&gt;。 由于每个前缀都匹配（即目的地址 &lt;code&gt;12.46.129.1&lt;/code&gt; 中包含一组共同的前缀位），则具有更大或更长的那个前缀是首选，在这种情况下是 P2。因此， P2 位于无法聚合来自 S 的前缀的位置，并需要携带更多站点 S 的流量。&lt;/p&gt;\n&lt;p&gt;如果站点 S 决定使用 PI 空间而不是 PA 空间，这个情况更对称。但是，不聚合是可能的。在这种情况下，它在 C 和 D 点将 PI 前缀 &lt;code&gt;198.134.135.0/24&lt;/code&gt; 分别通知 PI 和 P2，但任何 ISP 都不能聚合它，因为它与 ISP 地址块中任何一个数值都不相邻。因此，每个 ISP 在 A 点和 B 点通知可识别的前缀 &lt;code&gt;198.134.135.0/24&lt;/code&gt;。在这种方式下，在 Internet 路由中执行“自然的”最短路径计算，站点 S 可通过更靠近发送主机的 ISP 到达。另外，如果站点 S 决定切换另一个 ISP，它不需要改变其分配的地址。不幸的是，无法聚合这种地址可能关系到 Internet 未来的扩展性，因此 PI 空间相对供不应求。&lt;/p&gt;\n&lt;p&gt;IPv6 多宿主已成为 IETF 近年来的研究课题，并出现了 Multi6 体系结构 [&lt;a href=\&#34;#RFC4177\&#34;&gt;RFC4177&lt;/a&gt;] 和 Shim6 协议 [&lt;a href=\&#34;#RFC5533\&#34;&gt;RFC5533&lt;/a&gt;] 。 Multi6 概括了一些已提出处理意见的方法。从广义上来说，上述选择包括使用一种相当于前面提到的 IPv4 多宿主的路由方式、使用&lt;strong&gt;移动 IPv6&lt;/strong&gt; 的能力&lt;br&gt;\n[&lt;a href=\&#34;#RFC6275\&#34;&gt;RFC6275&lt;/a&gt;]，以及采用一种将节点标识符与定位符分离的新方法。当前， IP 地址作为连接 Internet 的一个网络接口标识符（本质上是一种名称）和定位符（一种路由系统理解的地址）。&lt;br&gt;\n这种分离使得将来即使在底层 IP 地址改变的情况下网络协议也能够实现。提供这种分离的协议有时称为&lt;strong&gt;标识符/定位符分&lt;/strong&gt;离或 &lt;strong&gt;id/loc 分离&lt;/strong&gt;协议。&lt;/p&gt;\n&lt;p&gt;Shim6 介绍了一个网络层协议“隔离层”（shim），传输层协议使用它分离来自 IP 地址的“上层协议标识符” 。多宿主通过选择使用的 IP 地址（定位符）来实现，基于动态网络环境且不需要 PI 地址分配。通信主机（端点）之间对使用的定位符及交换的时机进行协商。标识符与定位符分离是其他几项工作的主题，包括实验性的&lt;strong&gt;主机标识协议（HIP）&lt;/strong&gt; [&lt;a href=\&#34;#RFC4423\&#34;&gt;RFC4423&lt;/a&gt;]，它使用加密的主机标识符来标识主机。这种标识符实际上是与主机相关的公共/私人密钥对中的公钥，因此来源于一个特定主机的 HIP 流量可被认证。第 18 章将详细讨论安全问题。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;28-与-ip-地址相关的攻击\&#34;&gt;2.8 与 IP 地址相关的攻击&lt;/h2&gt;\n&lt;p&gt;IP 地址基本上都是数字，只有少数网络攻击涉及它们。一般情况下，执行攻击可发送“欺骗”数据包（见第 5 章）或其他相关活动。也就是说， IP 地址现在有助于查明涉嫌不良活动的个体（例如，对等网络中的版权侵权或非法材料分发）。这样做可能被以下几个原因所误导。例如，在很多情况下，IP 地址只是暂时的，并在不同时间重新分配给不同用户。因此，在精确计时中出现任何错误，容易造成数据库中的 IP 地址到用户的映射出错。另外，访问控制没有被广泛和安全地部署；用户可能通过一些公共的接入点，或一些无意中开放的家庭或办公室的无线路由器连接 Internet。在这种情况下，不知情的家庭或企业所有者可能因 IP 地址而成为嫌疑人，即使这个人并不是网络流量的发送者。这种情况也可能因受攻击的主机被用于组成僵尸网络而发生。目前，这类计算机（和路由器）可通过基于 Internet 的黑市来租赁，并被用于执行攻击、非法内容服务和其他违法活动 [&lt;a href=\&#34;#RFC4948\&#34;&gt;RFC4948&lt;/a&gt;] 。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;29-总结\&#34;&gt;2.9 总结&lt;/h2&gt;\n&lt;p&gt;IP 地址用于识别和定位整个 Internet 系统（单播地址）中设备的网络接口。它也用于识别多个接口（组播、广播或任播地址）。每个接口有一个最少 32 位的 IPv4 地址，并且通常有几个 128 位的 IPv6 地址。单播地址由一些分层次组织的管理机构分配成块。由这些机构分配的前缀表示一个单播 IP 地址空间块，这些块通常分配给 ISP，并由它们为自已的用户分配地址。这种前缀通常是 ISP 地址块的子区间（称为供应商聚合的地址或 PA 地址），但也可能代之为用户拥有的地址（称为供应商独立的地址或 PI 地址）。数值相邻的地址前缀（PA 地址）可被聚合，以节省路由表空间和提高 Internet 扩展性。这种方法出现于由 A、 B、 C 类网络号组成的“有类别” Internet 网络结构被无类别域间路由（CIDR）所取代时。  CIDR 允许根据对地址空间的不同需求，将不同大小的地址块分配给某个组织， CIDR 实际上可以更有效地分配地址空间。任播地址是根据发送者位置指向不同主机的单播地址；这种地址常用于发现可能出现在不同位置的网络服务。&lt;/p&gt;\n&lt;p&gt;IPv6 单播地址与 IPv4 地址有所不同。最重要的是， IPv6 地址有一个范围的概念，无论是单播地址还是组播地址，都需要明确指出地址的有效范围。典型的范围包括节点本地、链路本地和全球范围。链路本地地址通常基于一个标准前缀和一个 IID 创建，这个 IID 可由低层协议（例如硬件 / MAC 地址）基于地址提供或取随机值。这种方法有助于自动配置 IPv6 地址。&lt;/p&gt;\n&lt;p&gt;IPv4 和 IPv6 都支持同时指向多个网络接口的地址格式。 IPv4 支持广播地址和组播地址，但 IPv6 只支持组播地址。广播允许一人对所有人通信，而组播允许一人对多人通信。发送方向组播组（IP 地址）的发送，其行为有点像电视频道；发送方并不知道接收方信息或一个信道中有多少个接收方。 Internet 中的全球性组播已发展了十多年，并且涉及很多协议，有些是针对路由，有些是针对地址分配和协调，有些是针对主机希望加入或离开一个组的信息。无论是 IPv4 还是 IPv6，特别是 IPv6，都有很多类型和用途的组播地址。 IPv6 组播地址格式变化提供了基于单播前缀分配组的方法，在组中嵌入路由信息（RP地址），并且能基于 IID 创建组播地址。&lt;/p&gt;\n&lt;p&gt;可以说 CIDR 的开发和部署是 Internet 核心路由系统的一个根本性变化。 CIDR 成功地为分配地址空间提供更多灵活性，并通过聚合提升路由的可扩展性。另外， IPv6 在 20 世纪 90 年代初开始受到更多重视，这是出于很快将会需要更多地址的想法。当时没有预见的是，NAT （见第7章）的广泛使用显著推迟了 IPv6 的使用，这是因为连接 Internet 的每台主机不再需要唯一的地址。相反，大型网络使用专用地址空间已司空见惯。但是，可用于路由的 IP 地址数量最终将减少到零，因此未来将会出现一些变化。 2011 年 2 月， IANA 分配了最后 5 个 &lt;code&gt;/8&lt;/code&gt; 的 IPv4 地址前缀， 5 个 RIR 备分配 1 个前缀。2011 年 04 月 15 日， APNIC 用尽了其所有可分配的前缀。剩余前缀由不同 RIR 持有，预计最多只能几年保持未分配状态。 [&lt;a href=\&#34;#IP4R\&#34;&gt;IP4R&lt;/a&gt;] 是一个关于当前 IPv4 地址利用率的统计。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;210-参考文献\&#34;&gt;2.10 参考文献&lt;/h2&gt;\n&lt;p&gt;&lt;span id=\&#34;CGEMA\&#34;&gt; [CGEMA] &lt;/span&gt; Cisco Systems, &amp;quot;Guidelines for Enterprise IP Multicast Address Allocation,&amp;quot; 2004, http://www.cisco.com/warp/public/cc/techno/tity/prodlit/ipmlt_wp.pdf&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;EIGRP\&#34;&gt; [EIGRP] &lt;/span&gt; B.Albrightson, J.J.Garcia-Luna-Aceves, and J.Boyle, &amp;quot;EIGRP -- A Fast Routing Protocol Based on Distance Vectors,&amp;quot; Proc. Infocom, 2004.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;EUI64\&#34;&gt; [EUI64] &lt;/span&gt; Institute for Electrical and Electronics Engineers, &amp;quot;Guidelines for 64-Bit Global Identifier (EU1-64) Registration Authority&amp;quot; Mar. 1997 http://standards.ieee.org/regauth/oui/tutorials/EUI64.html&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;H96\&#34;&gt; [H96] &lt;/span&gt; M.Handley &amp;quot;The SDR Session Directory: An Mbone Conference Scheduling and Booking System,&amp;quot; Department of Computer Science, University College London, Apr. 1996, http://cobweb.ecn.purdue.edu/~ace/mbone/mbone/sdr/intro.html&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;IANA\&#34;&gt; [IANA] &lt;/span&gt; Internet Assigned Numbers Authority, http://www.iana.org&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;IDChes\&#34;&gt; [IDChes] &lt;/span&gt; S.Cheshire and M.Krochmal, &amp;quot;Multicast DNS,&amp;quot; Internet draft-cheshire-dnsext-multicastdns, Work in progress, Oct. 2010&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;IDv4v6mc\&#34;&gt; [IDv4v6mc] &lt;/span&gt; S.Venaas, X.Li, and C.Bao, &amp;quot;Framework for IPv4/IPv6 Multicast Translation,&amp;quot; Internet draft-venaas-behave-v4v6mc-framework, Work in progress, Dec. 2010.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;IEEERA\&#34;&gt; [IEEERA] &lt;/span&gt; IEEE Registration Authority, http://standards.ieee.org/regauth&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;IMR02\&#34;&gt; [IMR02] &lt;/span&gt; B.Edwards, L.Giuliano, and B.Wright, Interdomain Multicast Routing: Practical Juniper Networks and Cisco Systems Solutions (Addison-Wesley, 2002).&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;IP4AS\&#34;&gt; [IP4AS] &lt;/span&gt; http://www.iana.org/assignments/ipv4-address-space&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;IP4MA\&#34;&gt; [IP4MA] &lt;/span&gt; http://www.iana.org/assignments/multicast-addresses&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;IP4R\&#34;&gt; [IP4R] &lt;/span&gt;  IPv4 Address Report, http://www.potaroo.net/tools/ipv4&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;IP6AS\&#34;&gt; [IP6AS] &lt;/span&gt; http://www.iana.org/assignments/ipv6-address-space&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;IP6MA\&#34;&gt; [IP6MA] &lt;/span&gt; http://www.iana.org/assignments/ipv6-multicast-addresses&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;KK77\&#34;&gt; [KK77] &lt;/span&gt; L.Kleinrock and F.Kamoun, &amp;quot;Hierarchical Routing for Large Networks, Performance Evaluation and optimization,&amp;quot; Computer Networks, 1(3), 1977.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;NRO\&#34;&gt; [NRO] &lt;/span&gt; Number Resource organization, http://www.uro.net&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFCO919\&#34;&gt; [RFCO919] &lt;/span&gt; J.C.Mogul, &amp;quot;Broadcasting Internet Datagrams,&amp;quot; Internet RFC O919/BCP OOO5, Oct. 1984.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFCO922\&#34;&gt; [RFCO922] &lt;/span&gt; J.C.Mogul, &amp;quot;Broadcasting Internet Datagrams in the Presence of Subnets,&amp;quot; Internet RFC O922/STD OOO5, Oct. 1984.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFCO950\&#34;&gt; [RFCO950] &lt;/span&gt; J.C.Mogul and T.Postel, &amp;quot;Internet Standard Subnetting Procedure,&amp;quot; Internet RFC O950/STD OOO5, Aug. 1985.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC1O75\&#34;&gt; [RFC1O75] &lt;/span&gt; D.Waitzman, C.Partridge, and S.E.Deering, &amp;quot;Distance Vector Multicast Routing Protocol,&amp;quot; Internet RFC lO75 (experimental), Nov. 1988.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC1112\&#34;&gt; [RFC1112] &lt;/span&gt; S.E.Deering, &amp;quot;Host Extensions for IP Multicasting,&amp;quot; Internet RFC 1112/STD OOO5, Aug. 1989.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC1122\&#34;&gt; [RFC1122] &lt;/span&gt; R.Braden, ed., &amp;quot;Requirements for Internet Hosts-Communication Layers,&amp;quot; Internet RFC l122/STD OOO3, Oct. 1989.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC1812\&#34;&gt; [RFC1812] &lt;/span&gt; F.Baker, ed., &amp;quot;Requirements for IP Version 4 Routers,&amp;quot; Internet RFC 1812/STD OOO4, June 1995.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC1918\&#34;&gt; [RFC1918] &lt;/span&gt; Y.Rekhter, B.Moskowitz, D.Karrenberg, G.J.deGroot, and E.Lear, &amp;quot;Address Allocation for Private Internets,&amp;quot; Internet RFC 1918/BCP OOO5, Feb. 1996.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC2080\&#34;&gt; [RFC2080] &lt;/span&gt; G.Malkin and R.Minnear, &amp;quot;RIPng for IPv6,&amp;quot; Internet RFC 2080, Jan. 1997&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC2328\&#34;&gt; [RFC2328] &lt;/span&gt; J.Moy &amp;quot;OSPF Version 2,&amp;quot; Internet RFC 2328/STD OO54, Apr. 1988.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC2365\&#34;&gt; [RFC2365] &lt;/span&gt; D. Meyer, &amp;quot;Administratively Scoped IP Multicast,&amp;quot; Internet RFC 2365/ BCP OO23, July 1998.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC2544\&#34;&gt; [RFC2544] &lt;/span&gt; S.Bradner and J.McQuaid, &amp;quot;Benchmarking Methodology for Network Interconnect Devices,&amp;quot; Internet RFC 2544 (informational), Mar. 1999.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC2622\&#34;&gt; [RFC2622] &lt;/span&gt; C.Alaettinoglu, C.Villamizar, E.Gerich, D.Kessens, D.Meyer, T.Bates, D.Karrenberg, and M.Terpstra, &amp;quot;Routing Policy Specification Language(RPSL),&amp;quot; Internet RFC 2622, June 1999.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC2644\&#34;&gt; [RFC2644] &lt;/span&gt; D.Senie, &amp;quot;Changing the Default for Directed Broadcasts in Routers,&amp;quot; Internet RFC 2644/BCP OO34, Aug. 1999.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC2974\&#34;&gt; [RFC2974] &lt;/span&gt; M.Handley C.Perkins, and E.Whelan, &amp;quot;Session Announcement Protocol,″ Internet RFC 2974 (experimental), Oct. 2000.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC3056\&#34;&gt; [RFC3056] &lt;/span&gt; B.Carpenter and K. Moore, &amp;quot;Connection of IPv6 Domains via IPv4 Clouds,&amp;quot; Internet RFC 3056, Feb. 2001.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC3068\&#34;&gt; [RFC3068] &lt;/span&gt; C.Huitema, &amp;quot;An Anycast Prefix for 6to4 Relay Routers,&amp;quot; Internet RFC 3068, June 2001.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC3170\&#34;&gt; [RFC3170] &lt;/span&gt; B.Quinn and K.Almeroth, &amp;quot;IP Multicast Applications: Challenges and Solutions,&amp;quot; Internet RFC 3170 (informational), Sept. 2001.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC3180\&#34;&gt; [RFC3180] &lt;/span&gt; D.Meyer and P.Lothberg, &amp;quot;GLOP Addressing in 233/8,&amp;quot; Internet RFC 3180/BCP OO53, Sept. 2001.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC3306\&#34;&gt; [RFC3306] &lt;/span&gt; B.Haberman and D.Thaler, &amp;quot;Unicast-Prefix-Based IPv6 MulticastAddresses,&amp;quot; Internet RFC 3306, Aug. 2002.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC3307\&#34;&gt; [RFC3307] &lt;/span&gt; B.Haberman, &amp;quot;Allocation Guidelines for IPv6 Multicast Addresses,″ Internet RFC 3307 Aug. 2002.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC3315\&#34;&gt; [RFC3315] &lt;/span&gt; R.Droms, ed., J.Bound, B.Volz, T.Lemon, C.Perkins, and M.Camey &amp;quot;Dynamic Host Configuration Protocol for IPv6 (DHCPv6),″ Internet RFC 3315, Aug. 2002.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC3569\&#34;&gt; [RFC3569] &lt;/span&gt; S. Bhattacharyya, ed., &amp;quot;An overview of Source-Specific Multicast (SSM),&amp;quot; Internet RFC 3569 (informational), July 2003.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC3701\&#34;&gt; [RFC3701] &lt;/span&gt; R.Fink and R.Hinden, &amp;quot;6bone (IPv6 Testing Address Allocation) Phaseout,&amp;quot; Internet RFC 3701 (informational), Mar. 2004.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC3810\&#34;&gt; [RFC3810] &lt;/span&gt; R.Vida and L.Costa, eds., &amp;quot;Multicast Listener Discovery Version 2 (MLDv2) for IPv6,″ Internet RFC 3810, June 2004.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC3849\&#34;&gt; [RFC3849] &lt;/span&gt; G.Huston, A.Lord, and P.Smith, &amp;quot;IPv6 Address Prefix Reserved for Documentation,&amp;quot; Internet RFC 3849 (informational), July 2004.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC3879\&#34;&gt; [RFC3879] &lt;/span&gt; C.Huitema and B.Carpenter, &amp;quot;Deprecating Site Local Addresses,″ Internet RFC 3879 Sept. 2004.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC3927\&#34;&gt; [RFC3927] &lt;/span&gt; S.Cheshire, B.Aboba, and E.Guttman, &amp;quot;Dynamic Configuration of IPv4 LinkLocal Addresses,&amp;quot; Internet RFC 3927, May 2005.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC3956\&#34;&gt; [RFC3956] &lt;/span&gt; P.Savola and B.Haberman, &amp;quot;Embedding the Rendezvous Point (RP) Address in an IPv6 Multicast Address,&amp;quot; Internet RFC 3956, Nov 2004.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC4012\&#34;&gt; [RFC4012] &lt;/span&gt; L.Blunk, J.Damas, F.Parent, and A.Robachevsky, &amp;quot;Routing Policy Specification Language Next Generation (RPSLng),&amp;quot; Internet RFC 4012, Mar. 2005.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC4116\&#34;&gt; [RFC4116] &lt;/span&gt; J.Abley K.Lindqvist, E.Davies, B.Black, and V.Gill, &amp;quot;IPv4 Multi-homing Practices and Limitations,″ Internet RFC 4116 (informational), July 2005.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC4177\&#34;&gt; [RFC4177] &lt;/span&gt; G.Huston, &amp;quot;Architectural Approaches to Multi-homing for IPv6,&amp;quot; Internet RFC 4177 (informational), Sept. 2005.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC4193\&#34;&gt; [RFC4193] &lt;/span&gt; R.Hinden and B.Haberman, &amp;quot;Unique Local IPv6 Unicast Addresses,″ Oct.2005.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC4286\&#34;&gt; [RFC4286] &lt;/span&gt; B.Haberman and J.Martin, &amp;quot;Multicast Router Discovery&amp;quot; Internet RFC 4286, Dec. 2005.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC4291\&#34;&gt; [RFC4291] &lt;/span&gt; R.Hinden and S.Deering, &amp;quot;IP Version 6 Addressing Architecture,″ Internet RFC 4291, Feb. 2006.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC4380\&#34;&gt; [RFC4380] &lt;/span&gt; C.Huitema, &amp;quot;Teredo: Tunneling IPv6 over UDP through Network Address Translations (NATs),″ Internet RFC 4380, Feb. 2006.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC4423\&#34;&gt; [RFC4423] &lt;/span&gt; R.Moskowitz and P.Nikander, &amp;quot;Host Identity Protocol (HIP) Architecture,&amp;quot; Internet RFC 4423 (informational), May 2006.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC4489\&#34;&gt; [RFC4489] &lt;/span&gt; J.-S.Park, M.-K.Shin, and H.-J.Kim, &amp;quot;A Method for Generating Link-Scoped IPv6 Multicast Addresses,&amp;quot; Internet RFC 4489 Apr. 2006.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC4566\&#34;&gt; [RFC4566] &lt;/span&gt; M.Handley, V.Jacobson, and C.Perkins, &amp;quot;SDP: Session Description Protocol,&amp;quot; Internet RFC 4566, July 2006.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC4601\&#34;&gt; [RFC4601] &lt;/span&gt; B.Fenner, M.Handley H.Holbrook, and I.Kouvelas, &amp;quot;Protocol Independent Multicast-Sparse Mode (PIM-SM) : Protocol Specification (Revised),″ Internet RFC 4601, Aug. 2006.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC4607\&#34;&gt; [RFC4607] &lt;/span&gt; H.Holbrook and B.Cain, &amp;quot;Source-Specific Multicast for IP″ Internet RFC 4607, Aug. 2006.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC4608\&#34;&gt; [RFC4608] &lt;/span&gt; D.Meyer, R.Rockell, and G.Shepherd, &amp;quot;Source-Specific Protocol Independent Multicast in 232/8,&amp;quot; Internet RFC 4608/BCP 0120, Aug. 2006.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC4610\&#34;&gt; [RFC4610] &lt;/span&gt; D.Farinacci and Y.Cai, &amp;quot;Anycast-RP Using Protocol Independent Multicast (PIM),″ Internet RFC 4610, Aug. 2006.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC4632\&#34;&gt; [RFC4632] &lt;/span&gt; V.Fuller and T.Li, &amp;quot;Classless Inter-domain Routing (CIDR): The Internet Address Assignment and Aggregation Plan,&amp;quot; Internet RFC 4632/BCP 0122, Aug. 2006.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC4786\&#34;&gt; [RFC4786] &lt;/span&gt; J.Abley and K.Lindqvist, &amp;quot;Operation of Anycast Services,″ Internet RFC 4786/BCP O126, Dec. 2006.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC4795\&#34;&gt; [RFC4795] &lt;/span&gt; B.Aboba, D.Thaler, and L.Esibov, &amp;quot;LinkLocal Multicast Name Resolution (LLMNR),&amp;quot; Internet RFC 4795 (informational), Jan. 2007.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC4843\&#34;&gt; [RFC4843] &lt;/span&gt; P.Nikander, J.Laganier, and F.Dupont, &amp;quot;An IPv6 Prefix for overlay Routable Cryptographic Hash Identifiers (ORCHID),″ Internet RFC 4843 (experimental), Apr. 2007.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC4893\&#34;&gt; [RFC4893] &lt;/span&gt; Q.Vbhra and E.Chen, &amp;quot;BGP Support for Four-Octet AS Number Space,″ Internet RFC 4893, May 2007.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC4948\&#34;&gt; [RFC4948] &lt;/span&gt; L.Andersson, E.Davies, and L.Zhang, eds., &amp;quot;Report from the IAB Workshop on Unwanted Traffic March 9-10, 2006,&amp;quot; Internet RFC 4948 (informational), Aug. 2007.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC5059\&#34;&gt; [RFC5059] &lt;/span&gt; N.Bhaskar, A.Ga11, J.Lingard, and S.Venaas, &amp;quot;Bootstrap Router (BSR) Mechanism for Protocol Independent Multicast (PIM),″ Internet RFC 5059 Jan. 2008.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC5110\&#34;&gt; [RFC5110] &lt;/span&gt; P.Savola, &amp;quot;Overview of the Internet Multicast Routing Architecture,&amp;quot; Internet RFC 5110 (informational), Jan. 2008.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC5156\&#34;&gt; [RFC5156] &lt;/span&gt; M.Blanchet, &amp;quot;Special-Use IPv6 Addresses,&amp;quot; Internet RFC 5156 (informational), Apr. 2008.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC5214\&#34;&gt; [RFC5214] &lt;/span&gt; F.Templin, T.Gleeson, and D.Thaler, &amp;quot;Intra-Site Automatic Turnnel Addressing Protocol (ISATAP),″ Internet RFC 5214 (informational), Mar. 2008.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC5352\&#34;&gt; [RFC5352] &lt;/span&gt; R.Stewart, Q.Xie, M.Stillman, and M.Tuexen, &amp;quot;Aggregate Server Access Protocol (ASAP),&amp;quot; Internet RFC 5352 (experimental), Sept. 2008.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC5415\&#34;&gt; [RFC5415] &lt;/span&gt; P.Calhoun, M.Montemurro, and D.Stanley, eds., &amp;quot;Control and Provisioning of Wireless Access Points (CAPWAP) Protocol Specification,″ Internet RFC 5415, Mar. 2009.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC5498\&#34;&gt; [RFC5498] &lt;/span&gt; I.Chakeres, &amp;quot;IANA Allocations for Mobile Ad Hoc Network (MANET) Protocols,″ Internet RFC 5498, Mar. 2009.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC5533\&#34;&gt; [RFC5533] &lt;/span&gt; E.Nordmark and M.Bagnulo, &amp;quot;Shim6: Level 3 Multihoming Shim Protocol for IPv6,&amp;quot; Internet RFC 5533, June 2009.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC5735\&#34;&gt; [RFC5735] &lt;/span&gt; M.Cotton and L.Vegoda, &amp;quot;Special Use IPv4 Addresses,″ Internet RFC 5735/BCP O153, Jan. 2010.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC5736\&#34;&gt; [RFC5736] &lt;/span&gt; G.Huston, M.Cotton, and L.Vegoda, &amp;quot;IANA IPv4 Special Purpose Address Registry&amp;quot; Internet RFC 5736 (informational), Jan. 2010.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC5737\&#34;&gt; [RFC5737] &lt;/span&gt; J.Arkko, M.Cotton, and L.Vegoda, &amp;quot;IPv4 Address Blocks Reserved for Documentation,&amp;quot; Internet RFC 5737 (informational), Jan. 2010.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC5771\&#34;&gt; [RFC5771] &lt;/span&gt; M.Cotton, L.Vegoda, and D.Meyer, &amp;quot;IANA Guidelines for IPv4 Multicast Address Assignments,&amp;quot; Internet RFC 5771/BCP 0051, Mar. 2010.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC5952\&#34;&gt; [RFC5952] &lt;/span&gt; S.Kawamura and M.Kawashima, &amp;quot;A Recommendation for IPv6 Address Text Representation,&amp;quot; Internet RFC 5952, Aug, 2010.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC5905\&#34;&gt; [RFC5905] &lt;/span&gt; D.Mills, J.Martin, ed., J.Burbank, and W.Kasch, &amp;quot;Network Time Protocol Version 4: Protocol and Algorithms Specification,&amp;quot; Internet RFC 5905, June 2010.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC6034\&#34;&gt; [RFC6034] &lt;/span&gt; D.Thaler, &amp;quot;Unicast-Prefix-Based IPv4 Multicast Addresses,″ Internet RFC 6034, Oct. 2010&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC6052\&#34;&gt; [RFC6052] &lt;/span&gt; C.Bao, C.Huitema, M.Bagnulo, M.Boucadair, and X.Li, &amp;quot;IPv6 Addressing of IPv4/IPv6 Translators,″ Internet RFC 6052, Oct. 2010.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC6217\&#34;&gt; [RFC6217] &lt;/span&gt; J.Arkko and M.Townsley &amp;quot;IPv4 Run-Out and IPv4-1Pv6 Co-Existence Scenarios,&amp;quot; Internet RFC 6127 (experimental), May 2011.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC6144\&#34;&gt; [RFC6144] &lt;/span&gt; F.Baker, X.Li, C.Bao, and K.Yin, &amp;quot;Framework for IPv4/IPv6 Translation,″ Internet RFC 6144 (informational), Apr. 2011.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC6164\&#34;&gt; [RFC6164] &lt;/span&gt; M.Kohno, B.Nitzan, R.Bush, Y.Matsuzaki, L.Colitti, and T.Narten, &amp;quot;Using 127-Bit IPv6 Prefixes on Inter-Router Links,&amp;quot; Internet RFC 6164, Apr. 2011.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC6275\&#34;&gt; [RFC6275] &lt;/span&gt; C.Perkins, ed., D.Johnson, and J.Arkko, &amp;quot;Mobility Support in IPv6,&amp;quot; Internet RFC 3775, July 2011.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC6308\&#34;&gt; [RFC6308] &lt;/span&gt; P.Savola, &amp;quot;Overview of the Internet Multicast Addressing Architecture,&amp;quot; Internet RFC 6308 (informational), June 2011.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;WRWS\&#34;&gt; [WRWS] &lt;/span&gt; http://www.arin.net/resources/whoisrws&lt;/p&gt;\n&#34;,&#34;fileName&#34;:&#34;lesslesstcpip-xiang-jie-juan-yi-xie-yi-greatergreater-di-er-zhang-internet-di-zhi-jie-gou&#34;,&#34;abstract&#34;:&#34;&lt;h2 id=\&#34;21-引言\&#34;&gt;2.1 引言&lt;/h2&gt;\n&lt;p&gt;本章介绍了 Internet 中使用的网络层地址，又称为 IP 地址。我们讨论了如何为 Internet 中的设备分配地址，有助于路由可扩展性的地址层次结构分配方式，以及特殊用途的地址，包括广播、组播和任播地址。我们还讨论了 IPv4 和 IPv6 地址结构和用途的区别。&lt;/p&gt;\n&#34;,&#34;title&#34;:&#34;《TCP/IP 详解 卷一：协议》第二章：Internet 地址结构&#34;,&#34;tags&#34;:[{&#34;index&#34;:-1,&#34;name&#34;:&#34;TCP/IP&#34;,&#34;slug&#34;:&#34;NhO-Hr8Eu&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://wenbozhangw.github.io/tag/NhO-Hr8Eu/&#34;}],&#34;date&#34;:&#34;2022-04-22 10:30:33&#34;,&#34;dateFormat&#34;:&#34;2022-04-22&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://wenbozhangw.github.io/post/lesslesstcpip-xiang-jie-juan-yi-xie-yi-greatergreater-di-er-zhang-internet-di-zhi-jie-gou/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;100 min read&#34;,&#34;time&#34;:5950000,&#34;words&#34;:25058,&#34;minutes&#34;:100},&#34;description&#34;:&#34;2.1 引言\n本章介绍了 Internet 中使用的网络层地址，又称为 IP 地址。我们讨论了如何为 Internet 中的设备分配地址，有助于路由可扩展性的地址层次结构分配方式，以及特殊用途的地址，包括广播、组播和任播地址。我们还讨论了 ...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#21-%E5%BC%95%E8%A8%80\&#34;&gt;2.1 引言&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#22-%E8%A1%A8%E7%A4%BA-ip-%E5%9C%B0%E5%9D%80\&#34;&gt;2.2 表示 IP 地址&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#23-%E5%9F%BA%E6%9C%AC%E7%9A%84-ip-%E5%9C%B0%E5%9D%80%E7%BB%93%E6%9E%84\&#34;&gt;2.3 基本的 IP 地址结构&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#231-%E5%88%86%E7%B1%BB%E5%AF%BB%E5%9D%80\&#34;&gt;2.3.1 分类寻址&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#232-%E5%AD%90%E7%BD%91%E5%AF%BB%E5%9D%80\&#34;&gt;2.3.2 子网寻址&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#233-%E5%AD%90%E7%BD%91%E6%8E%A9%E7%A0%81\&#34;&gt;2.3.3 子网掩码&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#234-%E5%8F%AF%E5%8F%98%E9%95%BF%E5%BA%A6%E5%AD%90%E7%BD%91%E6%8E%A9%E7%A0%81\&#34;&gt;2.3.4 可变长度子网掩码&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#235-%E5%B9%BF%E6%92%AD%E5%9C%B0%E5%9D%80\&#34;&gt;2.3.5 广播地址&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#236-ipv6-%E5%9C%B0%E5%9D%80%E5%92%8C%E6%8E%A5%E5%8F%A3%E6%A0%87%E8%AF%86%E7%AC%A6\&#34;&gt;2.3.6 IPv6 地址和接口标识符&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#2361-%E4%BE%8B%E5%AD%90\&#34;&gt;2.3.6.1 例子&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#24-cidr-%E5%92%8C%E8%81%9A%E5%90%88\&#34;&gt;2.4 CIDR 和聚合&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#241-%E5%89%8D%E7%BC%80\&#34;&gt;2.4.1 前缀&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#242-%E8%81%9A%E5%90%88\&#34;&gt;2.4.2 聚合&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#25-%E7%89%B9%E6%AE%8A%E7%94%A8%E9%80%94%E5%9C%B0%E5%9D%80\&#34;&gt;2.5 特殊用途地址&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#251-ipv4ipv6-%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2\&#34;&gt;2.5.1 IPv4/IPv6 地址转换&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#252-%E7%BB%84%E6%92%AD%E5%9C%B0%E5%9D%80\&#34;&gt;2.5.2 组播地址&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#253-ipv4-%E7%BB%84%E6%92%AD%E5%9C%B0%E5%9D%80\&#34;&gt;2.5.3 IPv4 组播地址&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#254-ipv6-%E7%BB%84%E6%92%AD%E5%9C%B0%E5%9D%80\&#34;&gt;2.5.4 IPv6 组播地址&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#255-%E4%BB%BB%E6%92%AD%E5%9C%B0%E5%9D%80\&#34;&gt;2.5.5 任播地址&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#26-%E5%88%86%E9%85%8D\&#34;&gt;2.6 分配&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#261-%E5%8D%95%E6%92%AD\&#34;&gt;2.6.1 单播&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#2611-%E4%BE%8B%E5%AD%90\&#34;&gt;2.6.1.1 例子&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#262-%E7%BB%84%E6%92%AD\&#34;&gt;2.6.2 组播&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#27-%E5%8D%95%E6%92%AD%E5%9C%B0%E5%9D%80%E5%88%86%E9%85%8D\&#34;&gt;2.7 单播地址分配&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#271-%E5%8D%95%E4%B8%AA%E4%BE%9B%E5%BA%94%E5%95%86%E6%97%A0%E7%BD%91%E7%BB%9C%E5%8D%95%E4%B8%AA%E5%9C%B0%E5%9D%80\&#34;&gt;2.7.1 单个供应商/无网络/单个地址&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#272-%E5%8D%95%E4%B8%AA%E4%BE%9B%E5%BA%94%E5%95%86%E5%8D%95%E4%B8%AA%E7%BD%91%E7%BB%9C%E5%8D%95%E4%B8%AA%E5%9C%B0%E5%9D%80\&#34;&gt;2.7.2 单个供应商/单个网络/单个地址&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#273-%E5%8D%95%E4%B8%AA%E4%BE%9B%E5%BA%94%E5%95%86%E5%A4%9A%E4%B8%AA%E7%BD%91%E7%BB%9C%E5%A4%9A%E4%B8%AA%E5%9C%B0%E5%9D%80\&#34;&gt;2.7.3 单个供应商/多个网络/多个地址&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#274-%E5%A4%9A%E4%B8%AA%E4%BE%9B%E5%BA%94%E5%95%86%E5%A4%9A%E4%B8%AA%E7%BD%91%E7%BB%9C%E5%A4%9A%E4%B8%AA%E5%9C%B0%E5%9D%80%E5%A4%9A%E5%AE%BF%E4%B8%BB\&#34;&gt;2.7.4 多个供应商/多个网络/多个地址（多宿主）&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#28-%E4%B8%8E-ip-%E5%9C%B0%E5%9D%80%E7%9B%B8%E5%85%B3%E7%9A%84%E6%94%BB%E5%87%BB\&#34;&gt;2.8 与 IP 地址相关的攻击&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#29-%E6%80%BB%E7%BB%93\&#34;&gt;2.9 总结&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#210-%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE\&#34;&gt;2.10 参考文献&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;p&gt;有效沟通取决于使用共同的语言。这一观点对于人类、动物以及计算机而言都是适用的。当一种语言用于一组行为时，需要使用一种协议。根据《新牛津美国辞典》，对协议的第一定义是:&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;国家事务或外交场合的正式程序或规则系统。&lt;/strong&gt;&lt;/p&gt;\n&lt;!-- more --&gt;\n&lt;p&gt;我们每天执行很多协议:询问和回答问题、谈判商业交易、协同工作等。计算机也会执行备种协议。一系列相关协议的集合称为一个协议族。指定一个协议族中的备种协议之间的相互关系并划分需要完成的任务的设计，称为协议族的体系结构或参考模型。 TCP/IP是一个实现Internet体系结构的协议族，它来源于 ARPANET 参考模型（ARM） [&lt;a href=\&#34;#RFCO871\&#34;&gt;RFCO871&lt;/a&gt;]。 ARM 受到了早期分组交换工作的影响，这些工作包括美国的 Paul  Baran [&lt;a href=\&#34;#B64\&#34;&gt;B64&lt;/a&gt;] 和 Leonard Kleiurock [&lt;a href=\&#34;#K64%5D\&#34;&gt;K64&lt;/a&gt;、英国的Donald Davies [&lt;a href=\&#34;#DBSW66\&#34;&gt;DBSW66&lt;/a&gt;] 、法国的Louis Pouzin [&lt;a href=\&#34;#P73\&#34;&gt;P73&lt;/a&gt;] 。虽然数年之后制定了其他协议体系结构（例如， ISO协议体系结构[&lt;a href=\&#34;#Z80\&#34;&gt;Z80&lt;/a&gt;]、 Xerox的XNS [&lt;a href=\&#34;#X85\&#34;&gt;X85&lt;/a&gt;] 和 IBM 的 SNA [&lt;a href=\&#34;#I96\&#34;&gt;I96&lt;/a&gt;] ），但TCP/IP已成为最流行的协议族。这里有几本有趣的书籍，它们关注计算机通信的历史和Internet的发展，例如 [&lt;a href=\&#34;#PO7\&#34;&gt;PO7&lt;/a&gt;] 和 [&lt;a href=\&#34;#WO2\&#34;&gt;WO2&lt;/a&gt; ]。&lt;/p&gt;\n&lt;p&gt;值得一提的是，TCP/IP体系结构来源于实际工作，用于满足多种不同的分组交换计算机网络的互联需求 [&lt;a href=\&#34;#CK74\&#34;&gt;CK74&lt;/a&gt;]。这由一组网关（后来称为路由器）来实现，网关可以在互不兼容的网络之间提供翻译功能。随着越来越多的提供备种服务的节点投人使用，由此产生的“串联”网络或多类型网络（catenet）——后来称为互联网络（internetwork）将更加有用。在协议体系结构全面发展之前的几年，有人已经设想了全球性网络可能提供的服务类型。例如，在 1968 年， J. C. R. Licklider和Bob Taylor已预见到支持“超级通信”的全球性互联通信网络的潜在用途 [&lt;a href=\&#34;#LT68\&#34;&gt;LT68&lt;/a&gt;] ：&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;今天的在线社区彼此在功能和地理位置上是分离的。每个成员只能看到以自己社区为中心的设施的处理、存储和软件能力等功能。但是，现在的变化趋势是分离的社区之间的互联，从而将它们变成我们所说的超级社区。互联使所有社区中的所有成员能访问整个超级社区中的程序和数据资源……这个变化将形成一个由很多网络组成的不稳定网络，该网络无论在内容还是配置上都在变化。&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;因此，支撑 ARPANET 和后来的 Internet 的全球网络概念，很明显是针对我们今天使用的很多服务类型而设计的。但是，要做到这点是不容易的。其成功来源于对设计和实现的重视，创新型用户和开发人员，以及提供足够多的资源，促使概念转化为原型系统，并最终转化为商业化的网络产品。&lt;/p&gt;\n&lt;p&gt;本章是对 Internet 体系结构和 TCP/IP 协议族的概述，提供了一些历史知识，并为后续章节建立足够的背景支撑。体系结构(协议和物理)实际上是一组设计决策，涉及支持哪些特点和在哪里实现这些特点。设计一个体系结构更多的是艺术而不是科学，但我们将讨论体系结构中随着时间推移被认为可行的那些特点，网络体系结构的主题已在Day [&lt;a href=\&#34;#D08\&#34;&gt;D08&lt;/a&gt;] 中被广泛讨论，它是这方面的几种方案之一。&lt;/p&gt;\n&lt;h2 id=\&#34;11-体系结构原则\&#34;&gt;1.1 体系结构原则&lt;/h2&gt;\n&lt;p&gt;TCP/IP 协议族允许计算机、智能手机和嵌入式设备之间通信，它们可以采用备种尺寸、来自不同计算机生产商和运行备种软件。在 21 世纪到来之际，这已成为现代通信、娱乐和商务活动的必要需求。 TCP/IP 确实是一个 &lt;strong&gt;开放的系统&lt;/strong&gt;，协议族定义和很多实现是公开的，收费很少或根本不收费。它构成全球因特网（Internet）的基础（因特网是一个拥有遍布全球的大约 20 亿用户（2010 年，占全球人口的 30%）的广域网）。尽管很多人认为因特网和&lt;strong&gt;万维网&lt;/strong&gt;是可互换的术语，但我们通常认为因特网在计算机之间提供了消息通信能力，而万维网是一种使用因特网来通信的具体应用。在 20 世纪 90 年代早期，万维网恐怕是最重要的因特网应用，并使因特网技术得到全世界的重视。&lt;/p&gt;\n&lt;p&gt;Internet 体系结构在几个目标的指导下建立。在 [&lt;a href=\&#34;#C88\&#34;&gt;C88&lt;/a&gt;] 中， Clark 描述首要目标是“发展一种重复利用已有的互联网络的技术” 。这句话的本质是 Internet 体系结构应将多种网络互联起来，并在互联的网络上同时运行多个应用。基于这个首要目标， Clark 提供了以下的二级目标列表：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Internet 通信在网络或网关失效时必须能持续。&lt;/li&gt;\n&lt;li&gt;Internet 必须支持多种类型的通信服务。&lt;/li&gt;\n&lt;li&gt;Internet 体系结构必须兼容多种网络。&lt;/li&gt;\n&lt;li&gt;Internet 体系结构必须允许对其资源的分布式管理。&lt;/li&gt;\n&lt;li&gt;Internet 体系结构必须是经济有效的。&lt;/li&gt;\n&lt;li&gt;Internet 体系结构必须允许低能力主机的连接。&lt;/li&gt;\n&lt;li&gt;Internet 中使用的资源必须是可统计的。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;上面列出的很多目标将被最终的设计决策所采纳。但是，在制定这些体系结构原则时，这些原则影响到设计者所做的选择，最后少数几种设计方案脱颖而出。我们将提到其中几种重要方案及其结果。&lt;/p&gt;\n&lt;h3 id=\&#34;111-分组-连接和数据报\&#34;&gt;1.1.1 分组、连接和数据报&lt;/h3&gt;\n&lt;p&gt;直到 20 世纪 60 年代，网络的概念主要是基于电话网络。它是针对在一次通话中连接双方通话而设计的。一次通话通常要在通话双方之间建立一条&lt;strong&gt;连接&lt;/strong&gt;。建立一个连接意味着，在一次通话过程中，通话双方之间需要建立一条线路（最初是一条物理电路）。当一次通话结束时，这条连接被释放，允许这条线路用于其他用户通话。通话时间和连接端身份用于用户计费。当一次连接建立后，它为用户提供一定数量的&lt;strong&gt;带宽&lt;/strong&gt;或&lt;strong&gt;容量&lt;/strong&gt;，以便传输信息（通常是语音）。电话网从最初的模拟网络演变到数字网络，这样极大地提高了自身的可靠性和性能。在线路一端输入的数据，沿着某些预先建立的经过网络交换机的路径，通常具有某个时&lt;br&gt;\n间（&lt;strong&gt;延迟&lt;/strong&gt;）上限，在线路另一端以一种可预测方式出现。这样，在用户需要且线路可用的情况下，可以提供可预测的服务。线路是一条通过网络的路径，它为一次通话过程而保留，即使在并不繁忙的情况下。关于电话网络的常识是：在一次通话期间，即使我们没有说任何话，也要为这段时间而付费。&lt;/p&gt;\n&lt;p&gt;20世纪60年代出现的一个重要概念（如 [&lt;a href=\&#34;#B64\&#34;&gt;B64&lt;/a&gt;] 中）是&lt;strong&gt;分组交换&lt;/strong&gt;思想。在分组交换中，包含一定字节数的数字信息“块” （分组）独立通过网络。来自不同来源或发送方的块可以组合，而且以后可以分解，这称为“（多路）&lt;strong&gt;复用&lt;/strong&gt;”。这些块在到达目的地的过程中，需要在交换设备之间传输，并且路径可以改变。这样做有两个潜在的优点： 网络更有弹性（设计者不用担心网络受到物理攻击），基于&lt;strong&gt;统计复用&lt;/strong&gt;可更好地利用网络链路和交换设备。&lt;/p&gt;\n&lt;p&gt;当一台分组交换机接收到分组时，它们通常存储在&lt;strong&gt;缓存&lt;/strong&gt;或&lt;strong&gt;队列&lt;/strong&gt;中，并通过&lt;strong&gt;先到达先服务&lt;/strong&gt;（FCFS）的方式处理。这是最简单的分组处理调度方式，又称为&lt;strong&gt;先进先出&lt;/strong&gt;（FIFO）。 FIFO 缓冲区管理和按需调度很容易结合起来实现统计复用，它是 Internet 中用来处理不同来源的混合流量的主要方法。在统计复用中，流量基于到达的统计或时间模式而混合在一起。这种多路复用是简单而有效的，因为如果网络带宽被使用和有流量通过，那么网络中的每个瓶颈或阻塞点将会繁忙（高利用率）。这种方法的缺点是可预测性有限，通过某些特定应用的性能可看出，它依赖于对共享网络的其他应用的统计。统计复用就像是一条高速公路，车辆可以变换车道，但是最终会分散在备处，任何点的收缩都可能造成道路繁忙。&lt;/p&gt;\n&lt;p&gt;某些替代性的技术，例如&lt;strong&gt;时分复用&lt;/strong&gt;（TDM）和&lt;strong&gt;静态复用&lt;/strong&gt;，通常在每个连接上为数据保留一定量的时间或其他资源。虽然这种技术可能具有更好的可预测性，可用于支持恒定比特率的电话通话功能，但它可能无法充分利用网络带宽，这是由于保留的带宽可能未使用。注意，当电路是通过 TDM 技术来实现时，&lt;strong&gt;虚电路&lt;/strong&gt;（VC）会表现出很多电路行为，但是不依赖于物理的电路交换机，而通过顶层的面向连接的分组来实现。这是流行的 x.25 协议的基础，该技术直到 20 世纪 90 年代初才开始被帧中继大规模取代，并最终被&lt;strong&gt;数字用户线&lt;/strong&gt;（DSL）技术和支持Internet连接的电缆调制解调器所取代（见第 3 章）。&lt;/p&gt;\n&lt;p&gt;对于虚电路抽象和面向连接的分组网络（例如 x.25 ），需要在每个交换机中为每个连接存储一些信息或&lt;strong&gt;状态&lt;/strong&gt;。原因是每个分组只携带少量的额外信息，以提供到某个状态表的索引。例如，在 x.25 中， 12 位的&lt;strong&gt;逻辑信道标识符&lt;/strong&gt;（LCI）或&lt;strong&gt;逻辑信道号&lt;/strong&gt;（LCN）被用于这个目的。在每台交换机中， LCI 或 LCN 和交换机中的&lt;strong&gt;每个流状态&lt;/strong&gt;相结合，以决定分组交换路径中的下一台交换机。在使用信令协议在一条虚电路上交换数据之前，每个流状态已经建立，该协议支持连接建立、清除和状态信息。因此，这种网络称为&lt;strong&gt;面向连接的&lt;/strong&gt;。&lt;/p&gt;\n&lt;p&gt;无论是建立在线路还是交换的基础上，面向连接的网络是多年来最流行的联网方式。在 20 世纪 60 年代后期，&lt;strong&gt;数据报&lt;/strong&gt;作为另一种可选方案而得到发展。数据报起源于 CYCLADES [&lt;a href=\&#34;#P73\&#34;&gt;P73&lt;/a&gt;] 系统，它是一个特定类型的分组，有关来源和最终目的地的所有识别信息都位于分组中（而不是分组交换机中）。虽然这通常需要较大的数据包，但不需要在交换机中维护连接状态，它可用于建立一个&lt;strong&gt;无连接的&lt;/strong&gt;网络，并且没必要使用复杂的信令协议。数据报很快被早期的 Internet 设计者所接受，这个决定对协议族其他部分有深远影响。&lt;/p&gt;\n&lt;p&gt;另一个相关的概念是&lt;strong&gt;消息边界&lt;/strong&gt;或&lt;strong&gt;记录标记&lt;/strong&gt;。如图 1-1 所示，当一个应用将多个信息块发送到网络中，这些信息块可能被通信协议保留，也可能不被通信协议保留。大多数数据报协议保存消息边界。这样设计是很自然的，因为数据报本身有一个开始和结束。但是，在电路交换或虚电路网络中，一个应用程序可能需要发送几块数据，接收程序将所有数据作为一个块或多个块来读取。这些类型的协议不保留消息边界。在底层协议不保留消息边界，而应用程序需要它的情况下，应用程序必须自已来提供这个功能。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;1\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1650284886786.png\&#34; alt=\&#34;图 1-1 \&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 1-1 应用程序将协议携带的数据写人消息。消息边界是两次写入之间的位置或字节偏移量。保留消息边界的协议由接收方给出发送方的消息边界。不保留消息边界的协议（例如，像 TCP 这样的流协议）忽略这类信息，并使它在接收方无效。这样做的结果是，如果这个功能是必需的，应用程序需要自已实现发送方的消息边界&lt;/p&gt;\n&lt;h3 id=\&#34;112-端到端论点和命运共享\&#34;&gt;1.1.2 端到端论点和命运共享&lt;/h3&gt;\n&lt;p&gt;当我们设计一个大的系统（例如操作系统或协议族）时，随之而来的问题通常是在什么位置实现某个功能。影响 TCP/IP 协议族设计的一个重要原则称为&lt;strong&gt;端到端论点&lt;/strong&gt; [&lt;a href=\&#34;#SRC84\&#34;&gt;SRC84&lt;/a&gt;] ：&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;只有在通信系统端角度的应用知识的帮助下，才能完全和正确地实现问题中提到的功能。因此，作为通信自身的一个特点，不可能提供有疑问的功能。 （有时，通信系统提供的一个功能不完整的版本可能用于提高性能。）&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;在第一次阅读时，这种观点看起来似乎相当直观，它可能对通信系统设计产生深远影响。它认为只有涉及通信系统的应用程序或最终用户，其正确性和完整性才可能得到实现。即使为正确实现应用程序做了努力，其功能可能注定不会很完善。总之，这个原则认为重要功能（例如差错控制、加密、交付确认）通常不会在大型系统的低层（见 1.2.1 节）实现。但是，低层可以提供方便端系统工作的功能，并最终可能改善性能。这种观点表明低层功能不应以完美为目标，这是因为对应用程序需求做出完美推测是不可能的。&lt;/p&gt;\n&lt;p&gt;端到端论点倾向于支持一种使用“哑”网络和连接到网络的“智能”系统的设计方案。这是我们在 TCP/IP 设计中所看到的，很多功能（例如，保证数据不丢失、发送方控制发送速率）在端主机的应用程序中实现。选择哪些功能在同一计算机、网络或软件栈中实现，这是另一个称为命运共享的相关原则 [&lt;a href=\&#34;#C88\&#34;&gt;C88&lt;/a&gt;] 。&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;命运共享&lt;/strong&gt;建议将所有必要的状态放在通信端点，这些状态用于维护一个活动的通信关联（例如虚拟连接）。由于这个原因，导致通信失效的情况也会导致一个或更多端点失效，这样显然会导致整个通信的失败。命运共享是一种通过虚拟连接（例如，由 TCP 实现）维持活动的设计理念，即便网络连接在一段时间内失效。命运共享也支持一种“带智能终端主机的哑网络”模型，当前 Internet 中的矛盾是：哪些功能在网络中实现，哪些功能不在网络中实现。&lt;/p&gt;\n&lt;h3 id=\&#34;113-差错控制和流量控制\&#34;&gt;1.1.3 差错控制和流量控制&lt;/h3&gt;\n&lt;p&gt;在网络中存在数据损坏或丢失的情况。这可能出于各种原因，例如硬件间题、数据传输中被修改、在无线网络中超出范围，以及其他因素。对这种错误的处理称为&lt;strong&gt;差错控制&lt;/strong&gt;，它可以在构成网络基础设施的系统、连接到网络的系统或其他组合中实现。显然，端到端论点和命运共享建议在应用程序附近或内部实现差错控制。&lt;/p&gt;\n&lt;p&gt;通常，在只有少数位出错的情况下，我们关注的是，当数据已被接收或正在传输过程中，有些数学代码可用于检测和修复这种位差错 [&lt;a href=\&#34;#LC04\&#34;&gt;LC04&lt;/a&gt;] 。这个任务通常在网络中执行。当更多严重损坏发生在分组网络时，整个分组通常被重新发送或&lt;strong&gt;重新传输&lt;/strong&gt;。在线路交换或虚电路交换网络（例如 X.25 ）中，重新传输通常在网络内部进行。这对那些顺序要求严格和无差错交付的应用是有用的，但有些应用不需要这种功能或不希望为数据可靠交付而付出代价（例如连接建立和重新传输延迟）。一个可靠的文件传输应用并不关心交付的文件数据块的顺序，最终将所有块无差错地交付并接原来顺序重新组合即可。&lt;/p&gt;\n&lt;p&gt;针对网络中可靠、按顺序交付的实现开销，帧中继和 Internet 协议采用一种称为&lt;strong&gt;尽力而为交付&lt;/strong&gt;的服务。在尽力而为的交付中，网络不会花费很大努力来确保数据在没有差错或缺陷的情况下交付。某些差错通常用差错检测码或&lt;strong&gt;校验和&lt;/strong&gt;来检测，例如那些可能影响一个数据报定向的差错，当检测到这种差错时，出错的数据报仅被丢弃而没有进一步行动。&lt;/p&gt;\n&lt;p&gt;如果尽力而为的交付成功，发送方能以超过接收方处理能力的速度生成信息。在尽力而为的 IP 网络中，降低发送方的发送速度可通过&lt;strong&gt;流量控制&lt;/strong&gt;机制实现，它在网络外部或通信系统高层中运行。注意， TCP 会处理这种问题，我们将在第 15 章和第 16 章中详细讨论。这与端到端论点一致：TCP 在端主机中实现速率控制。它也与命运共享一致：这种方案在网络基础设施中有些单元失效的情况下，不会影响网络设备的通信能力（只要有些通信路径仍然可用）。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;12-设计和实现\&#34;&gt;1.2 设计和实现&lt;/h2&gt;\n&lt;p&gt;虽然建议用一个特定方法实现一个协议体系结构，但是这通常不是强制的。因此，我们对协议体系结构和&lt;strong&gt;实现体系结构&lt;/strong&gt;加以区分，实现体系结构定义了协议体系结构中的概念如何用于软件形式的实现中。&lt;/p&gt;\n&lt;p&gt;很多负责实现 ARPANET 协议的人员都熟悉操作系统的软件结构，一篇有影响力的论文描述的“ THE”多编程系统 [&lt;a href=\&#34;#D68\&#34;&gt;D68&lt;/a&gt;] ，主张使用一种层次结构的处理方式，以检查一个大型软件实现逻辑的稳健性和正确性。最终，这有助于形成一种网络协议的设计理念，它涉及实现（和设计）的多个层次。这种方案现在称为&lt;strong&gt;分层&lt;/strong&gt;，它是实现协议族的常用方案。&lt;/p&gt;\n&lt;h3 id=\&#34;121-分层\&#34;&gt;1.2.1 分层&lt;/h3&gt;\n&lt;p&gt;通过分层，每层只负责通信的一个方面。采用多层是有益的，这是因为分层设计允许开发人员分别实现系统的不同部分，它们通常由在不同领域的专业人员完成。最常提到的协议分层概念基于一个称为&lt;strong&gt;开放系统互连标准&lt;/strong&gt;（OSI）的模型 [&lt;a href=\&#34;#Z80\&#34;&gt;Z80&lt;/a&gt;]，该模型是由国际标准化组织（ISO）定义的。图 1-2 显示了标准的 OSI 层次，包括它们的名称、编号和若干例子。Internet 的分层模型比较简单，我们将在 1.3 节中介绍。&lt;/p&gt;\n&lt;p&gt;尽管 OSI 模型建议的 7 个逻辑层在协议体系结构的模块化实现中是可取的，但是通常认为 TCP/IP 体系结构包含 5 层。在 20 世纪 70 年代初，已有很多关于 OSI 模型的相对优势和不足，以及 ARPANET 模型优于它的争论。公平地说，尽管 TCP/IP 最终取得“胜利”，但来自 ISO 协议族（由 ISO 遵循 OSI 模型进行标准化）的一些思想，甚至整个协议已被用于 TCP/IP 中（例如 IS-IS [&lt;a href=\&#34;#RFC3787\&#34;&gt;RFC3787&lt;/a&gt;] ）。&lt;/p&gt;\n&lt;p&gt;如图1-2的简要介绍，每层都有不同任务。自下而上，&lt;strong&gt;物理层&lt;/strong&gt;定义了一种通过某种通信介质（例如一条电话线或光纤电缆）传输数字信息的方法。以太网和无线局域网（Wi-Fi）标准的一部分也在这层，但我们不打算在本书中深人介绍。&lt;strong&gt;链路层&lt;/strong&gt;或&lt;strong&gt;数据链路层&lt;/strong&gt;包含为共享相同介质的邻居建立连接的协议或方法。有些链路层网络（例如 DSL ）只连接两个邻居。当超过一个邻居可以访问共享网络时，这个网络称为&lt;strong&gt;多接入网络&lt;/strong&gt;。Wi-Fi 和以太网是这种多接入链路层网络的例子，特定协议用于协调多个站在任何时间访问共享介质。我们将在第3章中讨论。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;2\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1650351221367.png\&#34; alt=\&#34;图 1-2\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 1-2 ISO 定义的标准 7 层 OSI 模型。每个网络设备（至少从理论上）并不需要实现所有协议。OSI 的术语和层数被广泛使用&lt;/p&gt;\n&lt;p&gt;在层次结构中，我们对&lt;strong&gt;网络层&lt;/strong&gt;或&lt;strong&gt;互联网络层&lt;/strong&gt;最有兴趣。对于分组网络（例如 TCP/IP ），它提供了一种可互操作的分组格式，可通过不同类型的链路层网络来连接。本层也包括针对主机的地址方案和用于决定将分组从一台主机发送到另一台主机的路由算法。对于上述 3 层，我们发现协议（至少在理论上）仅实现在端主机中，这也包括&lt;strong&gt;传输层&lt;/strong&gt;。我们对传输层也有很大兴趣，它提供了一个会话之间的数据流，而且可能相当复杂，这取决于它提供的服务类型（例如，分组网络的可靠交付可能会丢弃数据）。&lt;strong&gt;会话&lt;/strong&gt;表示运行中的应用（例如， cookies 用于 Web 浏览器的 Web 登录会话过程中）之间的交互，会话层协议可提供例如连接初始化和重新启动、增加&lt;strong&gt;检查点&lt;/strong&gt;（保存到目前为止已完成的工作）等功能。在会话层之上是&lt;strong&gt;表示层&lt;/strong&gt;，它负责信息的格式转换和标准化编码。正如我们所看到的， Internet 协议不包括正式的会话层或表示层，如果需要的话，这些功能由应用程序来实现。&lt;/p&gt;\n&lt;p&gt;最高层是&lt;strong&gt;应用层&lt;/strong&gt;。各种应用通常会实现自已的应用层协议，它们对用户来说是最容易看到的。目前已存在大量的应用层协议，并且程序员仍在不断开发新协议。因此，应用层是创新最多，以及新功能开发和部署的地方。&lt;/p&gt;\n&lt;h3 id=\&#34;122-分层实现中的复用-分解和封装\&#34;&gt;1.2.2 分层实现中的复用、分解和封装&lt;/h3&gt;\n&lt;p&gt;分层体系结构的一个主要优点是具有&lt;strong&gt;协议复用&lt;/strong&gt;的能力。这种复用形式允许多种协议共存于同一基础设施中。它也允许相同协议对象（例如连接）的多个实例同时存在，并且不会被混淆。&lt;/p&gt;\n&lt;p&gt;复用可以发生在不同层，并在每层都有不同类型的&lt;strong&gt;标识符&lt;/strong&gt;，用于确定信息属于哪个协议或信息流。例如，在链路层，大多数的链路技术（例如以太网和 Wi-Fi ）在每个分组中包含一个&lt;strong&gt;协议标识符&lt;/strong&gt;字段，用于指出链路层帧携带的协议（IP 是这种协议）。当某层的一个称为&lt;strong&gt;协议数据单元&lt;/strong&gt;（PDU）的对象（分组、消息等）被低层携带时，这个过程称为在相邻低层的&lt;strong&gt;封装&lt;/strong&gt;（作为不透明数据）。因此，第 N 层的多个对象可以通过第 N-1 层的封装而复用。图 1-3 显示了封装的工作过程。第 N-1 层的标识符在第 N 层的分解过程中用于决定正确的接收协议或程序。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;3\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1650355972137.png\&#34; alt=\&#34;图 1-3\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 1-3 封装通常与分层一起使用。单纯的封装涉及获得某层的 PDU，并在低层将它作为不透明（无须解释）的数据来处理。封装发生在发送方，拆封（还原操作）发生在接收方。多数协议在封装过程中使用头部，少数协议也使用尾部&lt;/p&gt;\n&lt;p&gt;在图1-3中，每层都有自已的消息对象（PDU）的概念，对应于负责创建它的那个特定层。例如，如果第4层（传输层）协议生成一个分组，将它称为第4层 PDU 或&lt;strong&gt;传输层&lt;/strong&gt; PDU（TPDU）更准确。如果某层获得由它的上层提供的 PDU，它通常“承诺”不查看 PDU 中的具体内容。这是封装的本质，每层都将来自上层的数据看成不透明、无须解释的信息。最常见的处理是某层在获得的 PDU 前面增加自已的头部，有些协议是增加尾部（不是 TCP/IP）。头部用于在发送时复用数据，接收方基于一个分解（拆分）标识符执行分解。在 TCP/IP 网络中，这类标识符通常是硬件地址、 IP 地址和端口号。头部中也包含一些重要的状态信息，例如一条虚电路是正在建立还是已经建立。由此产生的对象是另一个 PDU。&lt;/p&gt;\n&lt;p&gt;图1-2 建议的分层的另一个重要特点是：在单纯的分层中，并不是所有网络设备都需要实现所有层。图 1-4 显示在某些情况下，如果设备只希望执行特定操作，那么它只需要实现少数几层。&lt;/p&gt;\n&lt;p&gt;在图 1-4 中，有些理想化的小型互联网络包括两种端系统，即交换机和路由器。在本图中，每个编号对应于在特定层中的一种协议。正如我们所见，每个设备实现协议栈的一个子集。左侧的主机对应的物理层实现了 3 种链路层协议（D、 E 和 F），以及运行在同一网络层协议上的3种传输层协议（A、 B 和 C）。端主机实现了所有层，交换机实现到第 2 层（这台交换机实现了 D 和 G），路由器实现到第 3 层。由于路由器具有互联不同类型的链路层网络的能力，因此它必须为互联的每种网络实现链路层协议。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;4\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1650358451406.png\&#34; alt=\&#34;图 1-4\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 1-4 不同的网络设备实现协议栈的不同子集。端主机通常实现所有层。路由器实现传输层之下的各层。这种理想化的结构经常被破坏，这是由于路由器和交换机通常包括类似于主机的功能（例如管理和建立），因此它们需要实现所有层，即使有些层很少使用&lt;/p&gt;\n&lt;p&gt;尽管我们只显示两台主机之间的通信，但是链路层和物理层网络（标记为 D 和 G）可能连接多台主机。如果这样，可以在任意两台实现相应的高层协议的系统之间通信。在图 1-4 中，针对一个特定的协议族，可以区分为&lt;strong&gt;端系统&lt;/strong&gt;（两边的两台主机）和&lt;strong&gt;中间系统&lt;/strong&gt;（中间的路由器）。网络层之上的各层使用&lt;strong&gt;端到端&lt;/strong&gt;协议。在我们的描述中，只有端系统需要这些层次。但是，网络层提供了一种&lt;strong&gt;逐跳&lt;/strong&gt;协议，它用于两个端系统和每个中间系统。通常不认为交换机或桥接是一个中间系统，这是由于它们没有使用互联网络协议的地址格式来编址，并在很大程度上以透明于网络层协议的方式运行。从路由器和端系统的角度来看，交换机或网桥实际是不可见的。&lt;/p&gt;\n&lt;p&gt;顾名思义，路由器有两个或更多的网络接口（由于它连接两个或多个网络）。有多个接口的系统称为&lt;strong&gt;多宿主&lt;/strong&gt;。一台主机也可以是多宿主的，但除非它专门将分组从一个接口转发到另一个接口，否则不能把它称为路由器。另外，路由器不一定只是在网络中转发分组的特殊硬件设备。在多数的 TCP/IP 实现中，如果正确配置的话，允许多宿主主机作为路由器使用。在这种情况下，我们可以把该系统称为主机（当它运行&lt;strong&gt;文件传输协议&lt;/strong&gt;（FTP） [&lt;a href=\&#34;#RFCO959\&#34;&gt;RFCO959&lt;/a&gt;] 或 Web 应用时）或路由器（当它将分组从一个网络转发到另一个网络时）。我们将结合上下文使用相关的术语。&lt;/p&gt;\n&lt;p&gt;互联网络的目标之一是对应用隐藏所有关于物理布局（拓扑）和低层协议的异构性的细节。虽然在图 1-4 所示的由两个网络组成的互联网络中并不明显，但应用层不关心（不在乎）以下事实：尽管连接在网络中的主机都采用链路层协议 D （例如以太网），但主机之间由采用链路层协议 G 的路由器和交换机隔开。主机之间可能有 20 个路由器，它们可采用其他类型的物理连接，应用程序无须修改即可运行（虽然性能可能有所不同）。以这种方式对细节加以抽象是促使互联网络概念变得强大和有用的原因。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;13-tcpip-协议族结构\&#34;&gt;1.3 TCP/IP 协议族结构&lt;/h2&gt;\n&lt;p&gt;到目前为止，我们已讨论了体系结构、协议、协议族和抽象的实现技术。在本节中，我们将讨论构成 TCP/IP &lt;strong&gt;协议族&lt;/strong&gt;的体系结构和特定协议。虽然这已成为 Internet 使用的协议的既定术语，但是也有很多 TCP 和 IP 之外的协议被包含在 Internet 使用的协议集或协议族中。我们将从最终形成 Internet 协议分层基础的ARPANET参考模型开始，研究它与前面讨论的 OSI 参考模型的区别。&lt;/p&gt;\n&lt;h3 id=\&#34;131-arpanet-参考模型\&#34;&gt;1.3.1 ARPANET 参考模型&lt;/h3&gt;\n&lt;p&gt;图 1-5 描述了源于 ARPANET 参考模型的分层，它最终被 TCP/IP 协议族采纳。它的结构比 OSI 模型更简单，但在实现中包括一些特定协议，并且不适合于常规层次的简化。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;5\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1650512857626.png\&#34; alt=\&#34;图 1-5\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 1-5 基于 ARM 或 TCP/IP 的协议分层被用于 Internet。这里没有正式的会话或表示层。另外，这里有几个不适合归入标准层的“附属”或辅助协议，它们为其他协议的运行提供重要功能。其中有些协议没有被 IPv6 使用（例如 IGMP 和 ARP）。&lt;/p&gt;\n&lt;p&gt;从图 1-5 底部沿着协议栈上移，我们首先看到的层次是 2.5，这是一个“非正式”的层。有几个协议工作在这层，一个最古老和最重要的协议是地址解析协议（ARP）。它是 IPv4 的专用协议，只用于多接入链路层协议（例如以太网和 Wi-Fi），完成IP层使用的地址和链路层使用的地址之间的转换。我们将在第4章讨论这个协议。IPv6的地址映射功能作为 ICMPv6 的一部分，我们将在第 8 章讨论。&lt;/p&gt;\n&lt;p&gt;我们在图 1-5 中编号为 3 的层中看到 IP，它是 TCP/IP 中最重要的网络层协议。我们将在第 5 章讨论它的细节。 IP 发送给链路层协议的 PDU 称为 &lt;strong&gt;IP 数据报&lt;/strong&gt;，它的大小是 64KB（IPv6 将它扩大为 4GB）。在很多情况下，当使用的上下文是清晰的，我们将会使用简化的术语“&lt;strong&gt;分组&lt;/strong&gt;”来表示 IP 数据报。大的分组放入链路层 PDU （称为&lt;strong&gt;帧&lt;/strong&gt;）时需要进行缩小处理，这个过程称为&lt;strong&gt;分片&lt;/strong&gt;，它通常由 IP 主机和某些路由器在必要时执行。在分片的过程中，大数据报的一部分被放入多个称为&lt;strong&gt;分片&lt;/strong&gt;的小数据报中，并在到达目的地后组合（称为&lt;strong&gt;重组&lt;/strong&gt;）。我们将在第 10 章中讨论分片。&lt;/p&gt;\n&lt;p&gt;在本书中，我们使用术语 IP 表示 IP 版本 4 和 6 ，使用 IPv6 表示 IP 版本 6，并使用 IPv4 表示 IP 版本 4，它是当前最流行的版本。在讨论体系结构时，我们很少关注 IPv4 和 IPv6 的细节。当我们讨论寻址和配置的工作原理（第 2 章和第 6 章）时，这些细节将变得更重要。&lt;/p&gt;\n&lt;p&gt;由于每个 IP 分组都是一个数据报，所以都包含发送方和接收方的第 3 层地址。这些地址称为 IP 地址，即 32 位的 IPv4 地址或 128 位的 IPv6 地址；我们将在第 2 章详细讨论它们。IP 地址长度不同是 IPv4 和 IPv6 之间的最大差别。每个数据报的目的地址用于决定将该数据报发送到哪里，而做出此决定和发送数据报到下一跳的过程称为&lt;strong&gt;转发&lt;/strong&gt;。路由器和主机都能进行转发，但更多的是由路由器实现转发。这里有 3 种类型的IP地址，地址类型决定如何进行转发：&lt;strong&gt;单播&lt;/strong&gt;（目的地是一台主机）、&lt;strong&gt;广播&lt;/strong&gt;（目的地是一个指定网络中的所有主机）和&lt;strong&gt;组播&lt;/strong&gt;（目的地是属于一个组播组中的一组主机）。第 2 章将详细介绍与 IP 一起使用的地址类型。&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Internet控制消息协议&lt;/strong&gt;（ICMP）是IP的一个辅助协议，我们将它标注为 3.5 层协议。 IP 层使用它与其他主机或路由器的IP层之间交换差错消息和其他重要信息。 ICMP有两个版本：IPv4 使用的ICMPv4， IPv6使用的 ICMPv6。 ICMPv6 是相当复杂的，包括地址自动配置和邻居发现等功能，它们在IPv4网络中由其他协议（例如ARP）处理。虽然 ICMP 主要由 IP 使用，但它也能被其他应用使用。事实上，两个流行的诊断工具（ ping 和 traceroute ）都使用 ICMP。 ICMP 消息被封装在 IP 数据报中，采用与传输层 PDU 相同的封装方式。&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Internet组管理协议&lt;/strong&gt;（ IGMP）是 IPv4 的另一个辅助协议。它采用组播寻址和交付来管理作为&lt;strong&gt;组播组&lt;/strong&gt;成员的主机（一组接收方接收一个特定目的地址的组播流量）。我们在这里只描述广播和组播的一般特点，在第 9 章介绍 IGMP 和&lt;strong&gt;组播监听&lt;/strong&gt;发现（MLD，用于IPv6）协议。&lt;/p&gt;\n&lt;p&gt;在第 4 层中，常见的两种 Internet 传输协议有很大区别。广泛使用的&lt;strong&gt;传输控制协议&lt;/strong&gt;（TCP）会处理数据包丢失、重复和重新排序等 IP 层不处理的问题。它采用面向连接（VC）的方式，并且不保留消息边界。相反，&lt;strong&gt;用户数据报协议&lt;/strong&gt;（UDP）仅提供比 IP 协议稍多的功能。 UDP允许应用发送数据报并保留消息边界，但不强制实现速率控制或差错控制。&lt;/p&gt;\n&lt;p&gt;TCP 在两台主机之间提供可靠的数据流传输。 TCP 涉及很多工作，例如将来自应用的数据分解成在网络层中传输的适当尺寸的块，确认接收到的分组和设置超时，以便对方能够确认自已发送的分组。由于传输层提供这种可靠的数据流，所以应用层可以忽略这些细节。TCP 发送到 IP 的 PDU 称为** TCP 段**。&lt;/p&gt;\n&lt;p&gt;另一方面， UDP 为应用层提供一种更简单的服务。它允许将数据报从一台主机发送到另一台主机，但不保证数据报能到达另一端。任何可靠性都需要由应用层提供。事实上， UDP 所做的是提供一套端口号，用于复用、分解数据和校验数据的完整性。正如我们所看到的，即使 UDP 和 TCP 在同一层次，它们也是完全不同的。这里给出每种传输层协议的用途，我们可看到使用 TCP 和 UDP 的不同应用。&lt;/p&gt;\n&lt;p&gt;这里还有两个传输层协议，它们相对比较新，并被用于某些系统中。由于它们的使用还不是很广泛，所以我们没对它们进行太多讨论，但它们是值得注意的。首先是&lt;strong&gt;数据报拥塞控制协议&lt;/strong&gt;（DCCP），它在 [&lt;a href=\&#34;#RFC4340\&#34;&gt;RFC4340&lt;/a&gt;] 中定义。它提供了一种介于 TCP 和 UDP 之间的服务类型：面向连接、不可靠的数据报交换，但具有拥塞控制功能。拥塞控制包括发送方控制发送速率的多种技术，以避免流量堵塞整个网络。我们将在第 16 章中结合 TCP 详细介绍拥塞控制。&lt;/p&gt;\n&lt;p&gt;另一个是&lt;strong&gt;流控制传输协议&lt;/strong&gt;（SCTP），它在 [&lt;a href=\&#34;#RFC4960\&#34;&gt;RFC4960&lt;/a&gt;] 中定义，是用于某些特定系统的传输协议。 SCTP 提供类似于 TCP 的可靠交付，但不要求严格保持数据的顺序。它还允许多个数据流逻辑上在同一连接上传输，并提供了一个消息抽象，这是它与 TCP 的主要区别。SCTP 用于在 IP 网络上携带信令消息，这类似于某些电话网络中的用途。&lt;/p&gt;\n&lt;p&gt;在传输层之上，应用层负责处理特定应用的细节。有很多常见的应用，几乎每个应用的实现都是基于 TCP/IP 的。应用层与应用的细节有关，但与网络中的数据传输无关。较低的三层则相反：它们对具体应用一无所知，但需要处理所有的通信细节。&lt;/p&gt;\n&lt;h3 id=\&#34;132-tcpip-中的复用-分解和封装\&#34;&gt;1.3.2 TCP/IP 中的复用、分解和封装&lt;/h3&gt;\n&lt;p&gt;我们已讨论了协议复用、分解和封装的基础内容。每层都会有一个标识符，允许接收方决定哪些协议或数据流可复用在一起。每层通常也有地址信息，它用于保证一个 PDU 被交付到正确的地方。图 1-6 模拟了如何在一台 Internet 主机上进行分解。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;6\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1650548793721.png\&#34; alt=\&#34;图 1-6\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 1-6 TCP/IP 协议栈将地址信息和协议分解标识符相结合，以决定一个数据报是否被正确接收，以及哪个实体将会处理该数据报。有几层还会检测数值（例如校验和），以保证内容在传输中没有损坏&lt;/p&gt;\n&lt;p&gt;虽然它不是 TCP/IP 协议族的真实部分，但我们也能自底向上地说明从链路层开始如何进行分解，这里使用以太网作为例子。我们在第 3 章讨论几种链路层协议。以太网帧包含一个 48 位的目的地址（又称为链路层或介质访问控制（MAC）地址）和一个16位的&lt;strong&gt;以太网类型&lt;/strong&gt;字段。 &lt;code&gt;0x0800&lt;/code&gt; （十六进制）表示这个帧包含 IPv4 数据报。 &lt;code&gt;0x0806&lt;/code&gt; 和 &lt;code&gt;0x86DD&lt;/code&gt; 分别表示 ARP 和 IPv6。 假设目的地址与接收方的一个地址匹配，这个帧将被接收并校验差错，&lt;strong&gt;以太网类型&lt;/strong&gt;字段用于选择处理它的网络层协议。&lt;/p&gt;\n&lt;p&gt;如果接收到的帧包含一个IP数据报，以太网头部和尾部信息将被清除，并将剩余字节（包含帧的&lt;strong&gt;有效载荷&lt;/strong&gt;）交给 IP 来处理。 IP检测一系列的字段，包括数据报中的目的 IP 地址。如果目的地址与自已的一个IP地址匹配，并且数据报头部（IP不检测有效载荷）没有错误，则检测 8 位的 IPv4 协议字段（在 IPv6 中称为下一个头部字段），以决定接下来调用哪个协议来处理。常见的值包括1 （ICMP）、 2 （IGMP）、 4 （IPv4）、 6 （TCP） 和 17 （UDP）。数值4 （和41，表示 IPv6 ）的含义是有趣的，因为它表示一个 IP 数据报可能出现在另一个 IP 数据报的有效载荷中。它违反了分层和封装的原有概念，但是作为&lt;strong&gt;隧道技术&lt;/strong&gt;的基础，我们在第3章进行更多讨论。&lt;/p&gt;\n&lt;p&gt;如果网络层（ IPv4 或 IPv6 ）认为传入的数据报有效，并且已确定正确的传输层协议，则将数据报（必要时由分片重组而成）交给传输层处理。在传输层中，大部分协议（包括 TCP 和 UDP ）通过端口号将复用分解到适当的应用。&lt;/p&gt;\n&lt;h3 id=\&#34;133-端口号\&#34;&gt;1.3.3 端口号&lt;/h3&gt;\n&lt;p&gt;&lt;strong&gt;端口号&lt;/strong&gt;是 16 位的非负整数（范围是0 - 65535）。这些数字是抽象的，在物理上没有指任何东西。相反，每个IP地址有 65536 个可用的端口号，每个传输协议可使用这些端口号（在大多数情况下），它们被用于确定正确的接收数据的具体服务。对于客户机/服务器应用（见 1.5.1 节），一台服务器首先“绑定”到一个端口号，然后一个或多个客户机可使用某种特定的传输协议与一台服务器上的端口号建立连接。从这个意义上来说，端口号的功能更像电话号码的扩展，差别是它们通常是由某个标准来分配。&lt;/p&gt;\n&lt;p&gt;标准的端口号由 Internet 号码分配机构（IANA）分配。这组数字被划分为特定范围，包括&lt;strong&gt;熟知&lt;/strong&gt;端口号（0 ~ 1023）、&lt;strong&gt;注册&lt;/strong&gt;端口号（ 1024 ~ 49151 ）和&lt;strong&gt;动态/私有&lt;/strong&gt;端口号（49152 ~ 65535）。在传统上，服务器需要绑定到（即在上面提供服务）一个熟知端口，它需要管理员或“根”访问这样的特殊权限。&lt;/p&gt;\n&lt;p&gt;熟知端口用于识别很多众所周知的服务，例如安全外壳协议（SSH，端口22）、 FTP （端口 20 和 21）、 Telnet远程终端协议（端口 23）、电子邮件/简单邮件传输协议（SMTP，端口 25）、域名系统（DNS，端口 53）、超文本传输协议或Web（HTTP和HTTPS，端口 80 和 443）、交互式邮件访问协议（ IMAP 和IMAPS，端口 143 和 993 ）、简单网络管理协议（SNMP，端口 161 和 162 ）、轻量级目录访问协议（LDAP，端口 389 ），以及其他几种服务。拥有多个端口的协议（例如 HTTP 和 HTTPS ）通常使用不同端口号，这取决于是否将&lt;strong&gt;传输层安全&lt;/strong&gt;（TLS）与基础的应用层协议共同使用（见第 18 章）。&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;注意  如果我们测试这些标准服务和其他 TCP/IP 服务（Telnet、 FTP、 SMTP等）使用的端口\n号，会发现它们大多数是奇数。这是有历史原因的，这些端口号从NCP端口号派生而来（ NCP是网络控\n制协议，在 TCP 之前作为 ARPANET 的传输层协议）。NCP 虽然简单，但不是全双工的，因此每个\n应用需要两个连接，并为每个应用保留奇偶成对的端口号。当 TCP 和 UDP 成为标准的传输层协议\n时，每个应用只需要一个端口号，因此来自 NCP 的奇数端口号被使用。\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;注册端口号提供给有特殊权限的客户机或服务器，但 IANA 会维护一个为特定用途而保留的注册表，开发新应用时通常应避免使用这些端口号，除非你已购买某些 IANA 分配的端口号。动态/私有端口号基本不受监管。正如我们所看到的，在某些情况下（例如在客户端），端口号的值无关紧要，这是因为它们只是短期被使用。这些端口号又称为&lt;strong&gt;临时&lt;/strong&gt;端口号。它们被认为是临时的，因为客户机只需支持一个应用的客户程序，并不需要被服务器发现以建立一个连接。相反，服务器通常需要不变的名称和端口号，以便被客户机所发现。&lt;/p&gt;\n&lt;h3 id=\&#34;134-名称-地址和-dns\&#34;&gt;1.3.4 名称、地址和 DNS&lt;/h3&gt;\n&lt;p&gt;在 TCP/IP 中，每台计算机（包括路由器）的每个链路层接口至少有一个IP地址。 IP 地址足以识别主机，但它们不方便被人们记忆或操作（尤其是更长的 IPv6 地址）。在 TCP/IP 环境中， DNS 是一个分布式数据库，提供主机名和 IP 地址之间的映射（反之亦然）。域名建立是有层次的，以 .com、.org、.gov、.in、.uk 和 .edu 等&lt;strong&gt;域&lt;/strong&gt;结尾。 DNS 是一个应用层协议，因此它的运行依赖于其他协议。虽然大多数 TCP/IP 协议不必关心域名，但用户（例如使用 Web 浏览器）通常会频繁使用域名，因此如果 DNS 不能正常工作，正常的 Internet 访问也难以使用。第 11 章将详细介绍 DNS。&lt;/p&gt;\n&lt;p&gt;执行域名操作的应用可以调用一个标准的 API 函数（见 1.5.3 节），将需要查找的 IP 地址（或地址）对应到一个主机名。同样，另一个函数提供反向查找功能，为一个给定的 IP 地址查找对应的主机名。大多数应用程序将主机名作为输人，但是经常也需要一个IP地址。 Web 浏览器支持这种功能。例如，在浏览器中输人&lt;strong&gt;统一资源定位符&lt;/strong&gt;（URL）， &lt;code&gt;http://131.243.2.201/index.html&lt;/code&gt;  和 &lt;code&gt;http://[2001:400:610:102::C9]/index.html&lt;/code&gt;，它们等效于 &lt;code&gt;http://ee.lbl.gov/index.html&lt;/code&gt; （在写作时，第二个例子需要成功建立 IPv6 连接）。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;14-internet-内联网和外联网\&#34;&gt;1.4 Internet、内联网和外联网&lt;/h2&gt;\n&lt;p&gt;如前所述， Internet （因特网）已发展成为由很多网络互联起来的网络集合。小写字母开头的 internet 表示使用常见协议族互联的多个网络。大写字母开头的 Internet 表示可使用 TCP/IP 通信的世界范围的主机集合。 Internet 是一个 internet，但反过来说是错误的。&lt;/p&gt;\n&lt;p&gt;组网在 20 世纪 80 年代得到快速发展的原因之一，那就是很多相互隔离的单机系统组合起来后作用并不明显。几个独立的系统连接起来组成一个&lt;strong&gt;网络&lt;/strong&gt;。虽然已向前迈进了一步，但我们在 20 世纪 90 年代意识到，不能互操作的独立网络不如一个更大的网络有价值。这个概念是 Metcalfe 定律的基础，计算机网络价值大致与连接的端系统（例如用户或设备）数量的平方成正比。 Internet 构想和它支持的协议使不同网络互联成为可能。实际上，这个看似简单的概念非常有用。&lt;/p&gt;\n&lt;p&gt;最容易的方式是构造一个由路由器连接两个或多个网络的互联网络。路由器通常是连接网络的一台专用设备，其优点是提供很多不同物理网络的连接，例如以太网、 Wi-Fi、点到点链路、 DSL、电缆 Internet 服务等。&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;注意   这些设备又被称为 IP 路由器，但我们将使用路由器这个术语。这些设备在历史上曾被称为网\n关，这个术语用于很多比较旧的 TCP/IP 文献中。当前的网关术语用于表示应用层网关 （ALG），它\n为一个特定应用（通常是电子邮件或文件传输）连接两个不同协议族（ TCP/IP 和 IBM 的 SNA）。\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;近年来，一些其他术语已被采用 TCP/IP 协议的各种互联网络所采纳。&lt;strong&gt;内联网&lt;/strong&gt;是一个用于描述专用互联网络的术语，它通常由一个商业机构或其他企业来运行。大多数情况下，内联网提供的访问资源只供特定企业的成员使用。用户可使用&lt;strong&gt;虚拟专用网&lt;/strong&gt;（VPN）连接到（例如企业）内联网。 VPN 有助于保证内联网中潜在的敏感资源只供授权用户访问，它通常使用前面提到的隧道概念。我们将在第7章详细讨论 VPN。&lt;/p&gt;\n&lt;p&gt;在很多情况下，一个企业或商业机构可能希望建立一个网络，其中包含可供合作伙伴或其他相关公司通过 Internet 访问的服务器。这种涉及 VPN 的网络通常被称为&lt;strong&gt;外联网&lt;/strong&gt;，由连接在提供服务的企业防火墙之外的计算机组成（见第 7 章）。从技术上来说，内联网、外联网和 Internet 之间的差别不大，但使用方式和管理策略通常不同，并由此出现更多的专业术语。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;15-设计应用\&#34;&gt;1.5 设计应用&lt;/h2&gt;\n&lt;p&gt;到目前为止，我们已接触的网络概念提供了一个简单的服务模型 [&lt;a href=\&#34;#RFC6250\&#34;&gt;RFC6250&lt;/a&gt;] ：在运行于不同（或相同）计算机上的程序之间传输数据。通过这种能力可完成任何有用的事。我们需要使用网络应用来提供服务或执行计算。网络应用的典型结构基于少数几种模式。最常见的模式是&lt;strong&gt;客户机/服务器&lt;/strong&gt;模式和&lt;strong&gt;对等&lt;/strong&gt;模式。&lt;/p&gt;\n&lt;h3 id=\&#34;151-客户机-服务器\&#34;&gt;1.5.1 客户机 / 服务器&lt;/h3&gt;\n&lt;p&gt;大多数网络应用被设计为一端是客户机，而另一端是服务器。服务器为客户机提供某类服务，例如访问服务器主机中的文件。我们可以将服务器分为两类：&lt;strong&gt;迭代&lt;/strong&gt;和&lt;strong&gt;并发&lt;/strong&gt;。迭代服务器经过以下步骤:&lt;/p&gt;\n&lt;ol&gt;\n&lt;li&gt;等待客户机请求到达。&lt;/li&gt;\n&lt;li&gt;处理客户机请求。&lt;/li&gt;\n&lt;li&gt;将响应发送给请求的客户机。&lt;/li&gt;\n&lt;li&gt;回到步骤 1。&lt;/li&gt;\n&lt;/ol&gt;\n&lt;p&gt;迭代服务器的问题是步骤 2 需要经过较长时间。在此期间，无法为其他客户机服务。并发服务器经过以下步骤:&lt;/p&gt;\n&lt;ol&gt;\n&lt;li&gt;等待客户机请求到达。&lt;/li&gt;\n&lt;li&gt;启用一个新服务器实例来处理客户机请求。这可能实际创建一个新的进程、任务或线程，它依赖于底层操作系统的支持。这个新的服务器处理一个客户机的全部请求。当请求的任务完成后，这个新的服务器终止。同时，原有服务器实例继续执行 3。&lt;/li&gt;\n&lt;li&gt;回到步骤 1。&lt;/li&gt;\n&lt;/ol&gt;\n&lt;p&gt;并发服务器的优点是服务器只产生其他服务器实例，并由它们来处理客户机请求。本质上，每个客户都有自已的服务器。假设操作系统支持多个程序（目前所有操作系统基本都支持），则多个客户机可以同时得到服务。我们将原因归于服务器而不是客户机，这是由于客户机通常无法判断与它通信的是迭代或并发服务器。大多数服务器通常是并发的。&lt;/p&gt;\n&lt;p&gt;注意，我们使用术语&lt;strong&gt;客户机&lt;/strong&gt;和&lt;strong&gt;服务器&lt;/strong&gt;表示应用，而不是应用所运行的特定计算机系统。相似的术语有时用于表示执行客户机或服务器应用的硬件。虽然这些术语有时并不准确，但它们在实际应用中表现良好。因此，我们通常发现一个服务器（硬件）上运行着多个服务器（应用）。&lt;/p&gt;\n&lt;h3 id=\&#34;152-对等\&#34;&gt;1.5.2 对等&lt;/h3&gt;\n&lt;p&gt;有些应用以更分布式的形式设计，其中没有专门的服务器。相反，每个应用既是客户机，又是服务器，有时同时是两者，并能转发请求。有些很流行的应用（例如 Skype [&lt;a href=\&#34;#SKYPE\&#34;&gt;SKYPE&lt;/a&gt;] 、 BitTorrent[&lt;a href=\&#34;#BT\&#34;&gt;BT&lt;/a&gt;] ）采用这种式。这种应用称为对等或 P2P 应用。并发的 P2P 应用接收到传入的请求，确定它是否能响应这个请求，如果不能，将这个请求转发给其他对等方。因此，一组 P2P 应用共同形成一个应用网络，也称为&lt;strong&gt;覆盖网络&lt;/strong&gt;。目前，这种覆盖网络是常见的，并且功能强大。例如， Skype 已发展成国际电话呼叫的最大运营商。根据某些估计，在 2009 年， BitTorrent 已占所有 Internet 流量的一半以上 [&lt;a href=\&#34;#IPIS\&#34;&gt;IPIS&lt;/a&gt; ]。&lt;/p&gt;\n&lt;p&gt;P2P网络的一个主要问题是&lt;strong&gt;发现服务&lt;/strong&gt;。也就是说，一个对等方如何在一个网络中发现提供它所需的数据或服务的其他对等方，以及可能进行交互的那些对等方的位置？这通常由一个引导程序来处理，以便每个客户机在最初配置中使用它所需的对等方的地址和端口号。一旦连接成功，新的参与者向其他活跃的对等方发出请求，并根据协议获得对等方提供的服务或文件。&lt;/p&gt;\n&lt;h3 id=\&#34;153-应用程序编程接口\&#34;&gt;1.5.3 应用程序编程接口&lt;/h3&gt;\n&lt;p&gt;无论是 P2P 或客户机/服务器，都需要表述其所需的网络操作（例如建立一个连接、写入或读取数据）。这通常由主机操作系统使用一个网络&lt;strong&gt;应用程序编程接口&lt;/strong&gt;（API）来实现。最流行的 API 被称为套接字 Berkeley 套接字，它最初由 [&lt;a href=\&#34;#LJFK93\&#34;&gt;LJFK93&lt;/a&gt;] 开发。&lt;/p&gt;\n&lt;p&gt;本书不是讲述网络编程的，我们只是通过介绍它说明 TCP/IP 的特点，以及哪个特点是由套接字 API 提供的。针对套接字的编程例子细节见 [&lt;a href=\&#34;#SFR04\&#34;&gt;SFR04&lt;/a&gt;] 。对于IPv6的套接字修改的描述，大量在线文档 [&lt;a href=\&#34;#RFC3493\&#34;&gt;RFC3493&lt;/a&gt;] 、 [&lt;a href=\&#34;#RFC3542\&#34;&gt;RFC3542&lt;/a&gt;] 、 [&lt;a href=\&#34;#RFC3678\&#34;&gt;RFC3678&lt;/a&gt;] 、  [&lt;a href=\&#34;#RFC4584\&#34;&gt;RFC4584&lt;/a&gt;] 、 [&lt;a href=\&#34;#RFC5014\&#34;&gt;RFC5014&lt;/a&gt;] 免费提供。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;16-标准化进程\&#34;&gt;1.6 标准化进程&lt;/h2&gt;\n&lt;p&gt;刚接触TCP/IP协议族的新手通常不了解谁负责各种协议的制定和标准化，以及它们如何运作。有些组织负责解决这个问题。我们最常关注的组织是 Internet 工程任务组（IETF）[&lt;a href=\&#34;#RFC4677\&#34;&gt;RFC4677&lt;/a&gt;] 。这个组织每年在世界不同地点举行3次会议，以便开发、讨论和通过 Internet 的“核心”协议标准。究竟什么构成“核心”是有争论的，但常见协议（例如IPv4、 IPv6、TCP、 UDP 和 DNS）显然属于此列。 IETF 会议对所有人开放，但它不是免费的。&lt;/p&gt;\n&lt;p&gt;IETF是一个论坛，它选举出称为 Internet 架构委员会（IAB）和 Internet 工程指导组（IESG）的领导组织。 IAB 负责提供 IETF 活动指导和执行其他任务，例如任命其他&lt;strong&gt;标准制定组织&lt;/strong&gt;（SDO）的联络员。IESG 具有决策权力，可以修改现有标准，以及建立和审批新的标准。”繁重“或细致的工作通常由 IETF 工作组执行，工作组主席负责协调执行此任务的志愿者。&lt;/p&gt;\n&lt;p&gt;除了 IETF，还有另外两个重要组织与 IETF 密切合作。 Internet 研究任务组（IRTF）讨论那些没有成熟到足以形成标准的协议、体系结构和程序。 IRTF 主席是 IAB 的列席成员。 IAB 和 Internet 协会（ISOC）共同影响和促进世界范围的有关 Internet 投术和使用的政策和培训。&lt;/p&gt;\n&lt;h3 id=\&#34;161-rfc\&#34;&gt;1.6.1 RFC&lt;/h3&gt;\n&lt;p&gt;Internet 社会中的每个官方标准都以一个 RFC （征求意见）的形式发布。 RFC可以通过多种方式创建， RFC 发布者（RFC编者）对一个已发布的 RFC 创建多个文件。当前文件（在 2010 年）包括 IETF、IAB、IRTF 和独立提交的文件。在被接受并作为 RFC 发布之前，文件将作为临时的 Internet 草案存在，在编辑和审查过程中将接收意见和公布进展。&lt;/p&gt;\n&lt;p&gt;不是所有 RFC 都是标准。只有标准跟踪类别的 RFC 被认为是官方标准。其他类别包括当前最佳实践（BCP）、信息、实验和历史。重要的是，一个文件成为一个 RFC，并不意味着 IETF 已采纳它作为标准。事实上，针对现有 RFC 有明显分歧。&lt;/p&gt;\n&lt;p&gt;RFC 的大小不等，从几页到几百页。每个 RFC 由一个数字来标识，例如 RFC 1122，新 RFC 被赋予更大的数字。它们可以从一些站点免费获得，包括 &lt;a href=\&#34;http://www.rfceditor.org\&#34;&gt;http://www.rfceditor.org&lt;/a&gt; 。由于历史原因，下载的 RFC 通常是基本的文本文件，虽然有些 RFC 已使用更先进的文件格式来格式化或撰写。&lt;/p&gt;\n&lt;p&gt;许多 RFC 具有特殊意义，它们总结、澄清或解释其他一些特殊标准。例如， [&lt;a href=\&#34;#RFC5000\&#34;&gt;RFC5000&lt;/a&gt;] 定义了一组其他 RFC （这个 RFC 最近正在撰写中），它们在 2008 年中期被视为官方标准。一个更新列表见当前标准站点 &lt;a href=\&#34;#OIPSW\&#34;&gt;[OIPSW]&lt;/a&gt; 。&lt;strong&gt;主机需求&lt;/strong&gt; RFC （[&lt;a href=\&#34;#RFC1122\&#34;&gt;RFC1122&lt;/a&gt;] 和 [&lt;a href=\&#34;#RFC1123\&#34;&gt;RFC1123&lt;/a&gt;] ）定义 Internet 中 IPv4 主机的协议实现，&lt;strong&gt;路由器需求&lt;/strong&gt; RFC [&lt;a href=\&#34;#RFC1812\&#34;&gt;RFC1812&lt;/a&gt;] 对路由器进行相同定义。&lt;strong&gt;节点需求&lt;/strong&gt; RFC [&lt;a href=\&#34;#RFC4294\&#34;&gt;RFC4294&lt;/a&gt;] 对 IPv6 系统进行上述定义。&lt;/p&gt;\n&lt;h3 id=\&#34;162-其他标准\&#34;&gt;1.6.2 其他标准&lt;/h3&gt;\n&lt;p&gt;虽然 IETF 负责我们在书中讨论的大部分协议的标准化，但是其他SDO负责定义的协议同样值得我们注意。这些重要组织包括电气和电子工程师学会（IEEE）、万维网联盟（W3C）以及国际电信联盟（ITU）。在本书描述的相关活动中， IEEE 关注第 3 层以下标准（例如 Wi-Fi 和以太网）， W3C关注应用层协议，特别是那些涉及 Web 的技术（例如基于 HTML 的语法）。 ITU特别是 ITU-T （原来的 CCITT）标准化的协议用于电话和蜂窝网络，它正成为 Internet 中一个越来越重要的组成部分。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;17-实现和软件分发\&#34;&gt;1.7 实现和软件分发&lt;/h2&gt;\n&lt;p&gt;实际上，标准的 TCP/IP 实现来自加州大学伯克利分校计算机系统研究组（CSRG）。它们通过 4.x BSD 系统发布，直到 20 世纪 90 年代中期才出现 BSD 网络发布版。这个源代码已成为许多其他实现的基础。今天，每个流行的操作系统都有自已的实现。在本书中，我们倾向于以 Linux、 Windows 的 TCP/IP 实现为例，有时也采用 FreeBSD 和 Mac OS （两者都由 BSD 版本派生而来）。在大多数情况下，某些特定实现通常无关紧要。&lt;/p&gt;\n&lt;p&gt;图 1-7 显示了各种 BSD 版本的年代列表，给出了我们在后面章节中涉及 TCP/IP 的重要特点。它也显示了 Linux 和 Windows 开始支持 TCP/IP 的时间。 BSD 网络发布版显示在第二列，它是免费提供的公共源代码发布版，其中包括所有网络代码，既包括协议本身，又包括很多应用程序和实用工具（例如 Telnet 远程终端程序和 FTP 文件传输程序）。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;7\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1650554902565.png\&#34; alt=\&#34;图 1-7\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;图 1-7 软件版本支持 TCP/IP 的历史可追溯到 1995 年。各种 BSD 版本率先支持 TCP/IP。 在 20 世纪 90 年代早期，由于 BSD 版本的合法性不确定， Linux 最初是为 PC 用户量身定制的代替品。几年后，微软开始在 Windows 中支持 TCP/IP&lt;/p&gt;\n&lt;p&gt;20 世纪 90 年代中期， Internet 和 TCP/IP 已很好地被实现。随后，所有流行的操作系统都开始支持 TCP/IP 协议。通过研究 TCP/IP 的新特点发现，之前首先出现在 BSD 版本中的功能，现在通常首先出现在 Linux 版本中。最近， Windows 已实现了一个新的 TCP/IP 协议栈（从 Windows Vista 开始），它具备很多新特点和本地 IPv6 功能。Linux、FreeBSD、MacOS X也支持 IPv6，并且不需要设置任何特殊配置选项。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;18-与-internet-体系结构相关的攻击\&#34;&gt;1.8 与 Internet 体系结构相关的攻击&lt;/h2&gt;\n&lt;p&gt;在整本书中，我们将简要描述攻击和漏洞，这些内容在讨论设计或实现主题时已谈到。很少有攻击将 Internet 体系结构整体作为目标。但是，值得注意的是， Internet 体系结构交付 IP 数据报是基于目的 IP 地址。因此，恶意用户能在自已发送的每个 IP 数据报的源地址字段中插人任何 IP 地址，这种行为称为&lt;strong&gt;欺骗&lt;/strong&gt;。生成的数据报被交付到目的地，但难以确定它的真实来源。也就是说，很难或不能确定从 Internet 中接收的数据报来源。&lt;/p&gt;\n&lt;p&gt;欺骗可以与 Internet 中出现的各种攻击相结合。&lt;strong&gt;拒绝服务&lt;/strong&gt;（DoS）攻击通常涉及消耗大量的重要资源，以导致合法用户被拒绝服务。例如，向一台服务器发送大量 IP 数据报，使它花费所有时间处理接收的分组和执行其他无用的工作，这是一种类型的 DoS 攻击。有些 DoS 攻击可能涉及以很多流量堵塞网络，导致其无法发送其他分组。这通常需要使用很多计算机来发送，并形成一个**分布式DoS （DDoS）**攻击。&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;未授权访问&lt;/strong&gt;攻击涉及以未授权方式访问信息或资源。它可以采用多种技术来实现，例如利用协议实现上的错误来控制一个系统（称为占有这个系统，并将它变成一个&lt;strong&gt;僵尸&lt;/strong&gt;）。它也可以涉及各种形式的伪装，例如攻击者的代理冒充一个合法用户（例如运行用户证书）。有些更恶毒的攻击涉及使用恶意软件（malware）控制很多远程系统，并以一种协同、分布式的方式（称为&lt;strong&gt;僵尸网络&lt;/strong&gt;（botnets））使用它们。那些出于（非法）获利或其他恶意目的而有意开发恶意软件和利用系统的程序员通常称为&lt;strong&gt;黑帽&lt;/strong&gt;。所谓的&lt;strong&gt;白帽&lt;/strong&gt;也在利用同样的技术做这方面的事情，但他们只是通知系统存在漏洞而不是利用它们。&lt;/p&gt;\n&lt;p&gt;关于 Internet 体系结构，值得注意的是，最初的 Internet 协议没有进行任何加密，加密可用于支持认证、完整性或保密。因此，恶意用户仅通过分析网络中的分组，通常就可以获得私人信息。如果具有修改传输中的分组的能力，他就可以冒充用户或更改消息内容。虽然这些问题由于加密协议（见第 18 章）而显著减少，但旧的或设计不当的协议有时在简单的窃听攻击面前仍很脆弱。由于无线网络的流行，“嗅探”其他人发送的分组比较容易，因此应避免使用旧的或不安全的协议。注意，虽然可在某层（例如 Wi-Fi 网络的链路层）启用加密，但只有主机到主机的加密（IP 层或以上）能保护穿过多个网段，以及可能采用遍历方式到达最终目的地的 IP 数据报。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;19-总结\&#34;&gt;1.9 总结&lt;/h2&gt;\n&lt;p&gt;本章快速浏览了网络体系结构和设计，特别是 TCP/IP 协议族的概念，后面章节将详细讨论它们。 Internet 体系结构被设计成支持现有不同网络互联，同时提供了广泛的服务和协议操作。选择使用数据报的分组交换是看中它的鲁棒性和效率。数据安全性和交付可预测性（例如有限的延迟）是次要原因。&lt;/p&gt;\n&lt;p&gt;基于对操作系统分层和模块化软件设计的理解，早期的 Internet 协议实现者采纳了经过封装的分层设计。 TCP/IP 协议族的 3 个主要层次是网络层、传输层和应用层，我们前面提到过每层具有不同功能。我们还提到了链路层，它与 TCP/IP 协议关系密切。我们将在以后的章节中详细讨论。&lt;/p&gt;\n&lt;p&gt;在 TCP/IP 中，网络层和传输层之间的区别至关重要：网络层（ IP ）提供了一个不可靠的数据报服务，必须由 Internet 中所有可寻址的系统来实现，而传输层（ TCP 和 UDP ）为端主机上运行的应用程序提供了端到端服务。主要的传输层协议有根本性的差异。 TCP提供了带流量控制和拥塞控制的有序、可靠的流交付。除了用于多路分解的端口号和错误检测机制之外， UDP提供的功能基本没有超越IP。但是，与 TCP 不同， UDP支持组播交付。&lt;/p&gt;\n&lt;p&gt;每层都使用地址和分解标识符，用以避免混淆不同协议或相同协议的不同关联/连接。链路层多接入网络通常使用 48 位地址；IPv4 使用 32 位地址， IPv6使用 128 位地址。TCP 和 UDP 传输协议使用一系列不同的端口号。有些端口号由标准来分配，有些端口号是临时使用的，通常由客户端与服务器通信时使用。端口号并不代表任何实际内容，它们只是作为应用程序与对方通信的一种方式。&lt;/p&gt;\n&lt;p&gt;虽然端口号和 IP 地址通常足以识别 Internet 中的一个服务，但它们不方便人们记忆或使用（特别是 IPv6 地址）。因此， Internet 使用了一种层次结构的主机名，可以通过 DNS 将主机名转换为 IP 地址（或者反过来），而DNS是一个运行在 Internet 上的分布式数据库应用程序。 DNS 已成为 Internet 基础设施中的重要组成部分，我们应尽力使它以更安全的方式运行（见第18章）。&lt;/p&gt;\n&lt;p&gt;互联网络（ internet）是一个网络集合，其中最常见的基本设备是路由器，它被用于在 IP 层连接多个网络。 Internet 是一个遍布全球和互联近两亿用户的互联网络（在 2010 年）。专用的互联网络称为内联网，通常使用特殊设备（防火墙，在第 10 章讨论）连接 Internet，它可以防止未授权的访问企图。外联网通常由一个机构的多个内联网组成，它能以有限的方式被合作伙伴或分支机构所访问。&lt;/p&gt;\n&lt;p&gt;网络应用通常采用客户机/服务器或对等模式设计。客户机/服务器是更流行、更传统的模式，但对等模式也获得了巨大成功。无论哪种设计模式，应用程序都要调用 API 执行网络任务。最常见的 TCP/IP 网络 API 称为套接字。它由 BSD UNIX 发布版提供，其软件版本率先使用 TCP/IP。 20 世纪 90年代末， TCP/IP 协议族和套接字 API 被用于所有流行的操作系统。&lt;/p&gt;\n&lt;p&gt;安全性不是 Internet 体系结构的主要设计目标。由于端主机易于篡改不安全的 IP 数据报的源 IP 地址，接收方难以确定分组的来源。分布式 DoS 攻击仍是一个挑战，作为受害者的端主机形成僵尸网络进行 DDoS 和其他攻击，而主机所有者通常对这些并不知情。最后，早期的 Internet 协议难以保护敏感信息的隐私，但这些协议中的大多数当前已过时，其现代版本通常采用加密方式为主机之间通信提供保密和认证。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;110-参考文献\&#34;&gt;1.10 参考文献&lt;/h2&gt;\n&lt;p&gt;&lt;span id=\&#34;B64\&#34;&gt;[B64]&lt;/span&gt; P.Baran, &amp;quot;On Distributed Communications: 1. Introduction to Distributed Communications Networks,&amp;quot;  RAND Memorandum RM-3420-PR, Aug. 1964.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;BT\&#34;&gt; [BT] &lt;/span&gt; http://www.bittorrent.com&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;C88\&#34;&gt; [C88] &lt;/span&gt; D.Clark, &amp;quot;The Design Philosophy of the DARPA Internet Protocols,&amp;quot; Proc. ACM SIGCOMM, Aug. 1988.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;CK74\&#34;&gt;[CK74] &lt;/span&gt; V Cerf and R.Kahn, &amp;quot;A Protocol for Packet Network Intercommunication,&amp;quot; IEEE Transactions on Communications, COM-22（5）, May 1974.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;D08\&#34;&gt; [D08] &lt;/span&gt; J.Day Patterns in Network Architecture: A Return to Fundamentals（Prentice Hall, 2008）.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;D68\&#34;&gt; [D68] &lt;/span&gt; E.Dijkstra,  &amp;quot;The Structure of the &#39;THE&#39;-Multiprogramming system,” Communications of the ACM, 11（5）, May 1968.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;DBSW66\&#34;&gt; [DBSW66] &lt;/span&gt; D.Davies, K.Bartlett, R.Scantlebury and P Wilkinson, ‘A Digital Communications Network for Computers Giving Rapid Response at Remote Terminals,” Proc. ACM Symposium on Operating System Principles, Oct. 1967.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;I96\&#34;&gt; [I96] &lt;/span&gt; IBM Corporation, Systems Network Architecture--APPN Architecture Reference, Document SC30-3422-04, 1996.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;IPIS\&#34;&gt; [IPIS] &lt;/span&gt; Ipoque, Internet Study 2008/2009,  http://www.ipoque.com/resources/internet-studies/internet-study-2008_2009&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;K64\&#34;&gt;[K64]&lt;/span&gt; L.Kleiurock, Communication Nets: Stochastic Message Flow and Delay  （McGraw-Hill, 1964）.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;LC04\&#34;&gt; [LC04] &lt;/span&gt; S.Lin and D. Costello Jr., Error Control Coding, Second Edition  （Prentice Hall, 2004）.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;LJFK93\&#34;&gt; [LJFK93] &lt;/span&gt; S.Leffler, W.Joy, R.Fabry, and M.Karels,  &amp;quot;Networking Implementation Notes-4.4BSD Edition,&amp;quot; June 1993.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;LT68\&#34;&gt; [LT68] &lt;/span&gt; J.C.R.Licklider and R.Taylor, “The Computer as a Communication Device,&amp;quot; Science and Technology, Apr. 1968.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;OIPSW\&#34;&gt; [OIPSW] &lt;/span&gt; http://www.rfc-editor.org/rfcxx00.htm&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;PO7\&#34;&gt; [PO7] &lt;/span&gt; J.Pelkey, Entrepreneurial Capitalism and Innovation: A History of Computer Communications 1968-1988, available at http://historyofcomputercommunications.info&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;P73\&#34;&gt; [P73] &lt;/span&gt; L.Pouzin, &amp;quot;Presentation and Major Design Aspects of the CYCLADES Computer Network,&amp;quot; NATO Advanced Study Institute on Computer Communication Networks, 1973.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFCO871\&#34;&gt;[RFCO871]&lt;/span&gt; M.Padlipsky &amp;quot;A Perspective on the ARPANET Reference Model,&amp;quot; Internet RFC O871, Sept. 1982.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFCO959\&#34;&gt; [RFCO959] &lt;/span&gt; J.Postel and J.Reynolds, “File Transfer Protocol,” Internet RFC O959/STD OOO9 0ct. 1985.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC1122\&#34;&gt; [RFC1122] &lt;/span&gt; R.Braden, ed., &amp;quot;Requirements for Internet Hosts-Communication Layers,″ Internet RFC 1122/STD OOO3, Oct. 1989.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC1123\&#34;&gt; [RFC1123] &lt;/span&gt; R.Braden, ed., &amp;quot;Requirements for Internet Hosts-Application and Support,″ Internet RFC l123/STD OOO3, Oct. 1989.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC1812\&#34;&gt; [RFC1812] &lt;/span&gt; F.Baker, ed., &amp;quot;Requirements for IP Version 4 Routers,″ Internet RFC 1812, June 1995.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC3493\&#34;&gt; [RFC3493] &lt;/span&gt; R.Gilligan, S.Thomson, J.Bound, J.McCann, and W.Stevens, &amp;quot;Basic Socket Interface Extensions for IPv6,&amp;quot; Internet RFC 3493 （informational）, Feb. 2003.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC3542\&#34;&gt; [RFC3542] &lt;/span&gt; W.Stevens, M.Thomas, E.Nordmark, and T.Jinmei, &amp;quot;Advanced Sockets Application Program Interface （API） for IPv6,″ Internet RFC 3542 （informational）, May 2003.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC3678\&#34;&gt; [RFC3678] &lt;/span&gt; D.Thaler, B.Fenner, and B.Quinn, &amp;quot;Socket Interface Extensions for Multicast Source Filters,&amp;quot; Internet RFC 3678 （informational）, Jan. 2004.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC3787\&#34;&gt; [RFC3787] &lt;/span&gt; J.Parker, ed., &amp;quot;Recommendations for Interoperable IP Networks Using Intermediate System to Intermediate System （IS-1S）,&amp;quot; Internet RFC 3787 （informational）, May 2004.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC4294\&#34;&gt; [RFC4294] &lt;/span&gt; J.Loughney ed., &amp;quot;IPv6 Node Requirements,&amp;quot; Internet RFC 4294 （informational）, Apr. 2006.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC4340\&#34;&gt; [RFC4340] &lt;/span&gt; E.Kohler, M.Handley and S.Floyd, &amp;quot;Datagram Congestion Control Protocol （DCCP）,&amp;quot; Internet RFC 4340, Mar. 2006.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC4584\&#34;&gt; [RFC4584] &lt;/span&gt; S.Chakrabarti and E.Nordmark, &amp;quot;Extension to Sockets API for Mobile IPv6,″ Internet RFC 4584 （informational）,JuIy 2006.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC4677\&#34;&gt; [RFC4677] &lt;/span&gt; P.Hoffman and S.Harris, &amp;quot;The Tao of IETF-A Novice&#39;s Guide to the Internet Engineering Task Force,” Internet RFC 4677 （informational）, Sept. 2006.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC4960\&#34;&gt; [RFC4960] &lt;/span&gt; R.Stewart, ed., &amp;quot;Stream Control Transmission Protocol,&amp;quot; Internet RFC 4960, Sept. 2007.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC5000\&#34;&gt; [RFC5000] &lt;/span&gt; RFC Editor, &amp;quot;Internet official Protocol Standards,&amp;quot; Internet RFC 5000/STD OOO1 （informational）, May 2008.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC5014\&#34;&gt; [RFC5014] &lt;/span&gt; E.Nordmark, S.Chakrabarti, and J.Laganier, &amp;quot;IPv6 Socket API for Source Address Selection,&amp;quot; Internet RFC 5014 （informational）, Sept. 2007.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;RFC6250\&#34;&gt; [RFC6250] &lt;/span&gt; D.Thaler, “Evolution of the IP Model,″ Internet RFC 6250 （informational）, May 2011.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;SFR04\&#34;&gt; [SFR04] &lt;/span&gt; W.R.Stevens, B.Fenner, and A.Rudoff, UNIX Network Programming, Volume 1, Third Edition（Prentice Hall, 2004）.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;SKYPE\&#34;&gt; [SKYPE] &lt;/span&gt; http://www.skype.com&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;SRC84\&#34;&gt; [SRC84] &lt;/span&gt; J.Saltzer, D.Reed, and D.Clark, &amp;quot;End-to-End Arguments in System Design,” ACM Transactions on Computer System, 2（4）, Nov. 1984.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;WO2\&#34;&gt; [WO2] &lt;/span&gt; M.Waldrop, The Dream Machine: J.C.R.Licklider and the Revolution That Made Computing Personal（Penguin Books, 1992）.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;X85\&#34;&gt; [X85] &lt;/span&gt; Xerox Corporation, XeroX Network Systems Architecture--General Information Manual, XNSG O68504, 1985.&lt;/p&gt;\n&lt;p&gt;&lt;span id=\&#34;Z80\&#34;&gt; [Z80] &lt;/span&gt; H.Zimmermann, &amp;quot;OSI Reference Model-The ISO Model of Architecture for open systems Interconnection,&amp;quot; IEEE Transactions on Communications, COM28（4）, Apr. 1980.&lt;/p&gt;\n&#34;,&#34;fileName&#34;:&#34;gai-shu&#34;,&#34;abstract&#34;:&#34;&lt;p&gt;有效沟通取决于使用共同的语言。这一观点对于人类、动物以及计算机而言都是适用的。当一种语言用于一组行为时，需要使用一种协议。根据《新牛津美国辞典》，对协议的第一定义是:&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;国家事务或外交场合的正式程序或规则系统。&lt;/strong&gt;&lt;/p&gt;\n&#34;,&#34;title&#34;:&#34;《TCP/IP 详解 卷一：协议》第一章：概述&#34;,&#34;tags&#34;:[{&#34;index&#34;:-1,&#34;name&#34;:&#34;TCP/IP&#34;,&#34;slug&#34;:&#34;NhO-Hr8Eu&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://wenbozhangw.github.io/tag/NhO-Hr8Eu/&#34;}],&#34;date&#34;:&#34;2022-04-15 13:51:57&#34;,&#34;dateFormat&#34;:&#34;2022-04-15&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://wenbozhangw.github.io/post/gai-shu/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;65 min read&#34;,&#34;time&#34;:3880000,&#34;words&#34;:17944,&#34;minutes&#34;:65},&#34;description&#34;:&#34;有效沟通取决于使用共同的语言。这一观点对于人类、动物以及计算机而言都是适用的。当一种语言用于一组行为时，需要使用一种协议。根据《新牛津美国辞典》，对协议的第一定义是:\n国家事务或外交场合的正式程序或规则系统。\n\n我们每天执行很多协议:询问和...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#11-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E5%8E%9F%E5%88%99\&#34;&gt;1.1 体系结构原则&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#111-%E5%88%86%E7%BB%84-%E8%BF%9E%E6%8E%A5%E5%92%8C%E6%95%B0%E6%8D%AE%E6%8A%A5\&#34;&gt;1.1.1 分组、连接和数据报&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#112-%E7%AB%AF%E5%88%B0%E7%AB%AF%E8%AE%BA%E7%82%B9%E5%92%8C%E5%91%BD%E8%BF%90%E5%85%B1%E4%BA%AB\&#34;&gt;1.1.2 端到端论点和命运共享&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#113-%E5%B7%AE%E9%94%99%E6%8E%A7%E5%88%B6%E5%92%8C%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6\&#34;&gt;1.1.3 差错控制和流量控制&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#12-%E8%AE%BE%E8%AE%A1%E5%92%8C%E5%AE%9E%E7%8E%B0\&#34;&gt;1.2 设计和实现&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#121-%E5%88%86%E5%B1%82\&#34;&gt;1.2.1 分层&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#122-%E5%88%86%E5%B1%82%E5%AE%9E%E7%8E%B0%E4%B8%AD%E7%9A%84%E5%A4%8D%E7%94%A8-%E5%88%86%E8%A7%A3%E5%92%8C%E5%B0%81%E8%A3%85\&#34;&gt;1.2.2 分层实现中的复用、分解和封装&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#13-tcpip-%E5%8D%8F%E8%AE%AE%E6%97%8F%E7%BB%93%E6%9E%84\&#34;&gt;1.3 TCP/IP 协议族结构&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#131-arpanet-%E5%8F%82%E8%80%83%E6%A8%A1%E5%9E%8B\&#34;&gt;1.3.1 ARPANET 参考模型&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#132-tcpip-%E4%B8%AD%E7%9A%84%E5%A4%8D%E7%94%A8-%E5%88%86%E8%A7%A3%E5%92%8C%E5%B0%81%E8%A3%85\&#34;&gt;1.3.2 TCP/IP 中的复用、分解和封装&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#133-%E7%AB%AF%E5%8F%A3%E5%8F%B7\&#34;&gt;1.3.3 端口号&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#134-%E5%90%8D%E7%A7%B0-%E5%9C%B0%E5%9D%80%E5%92%8C-dns\&#34;&gt;1.3.4 名称、地址和 DNS&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#14-internet-%E5%86%85%E8%81%94%E7%BD%91%E5%92%8C%E5%A4%96%E8%81%94%E7%BD%91\&#34;&gt;1.4 Internet、内联网和外联网&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#15-%E8%AE%BE%E8%AE%A1%E5%BA%94%E7%94%A8\&#34;&gt;1.5 设计应用&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#151-%E5%AE%A2%E6%88%B7%E6%9C%BA-%E6%9C%8D%E5%8A%A1%E5%99%A8\&#34;&gt;1.5.1 客户机 / 服务器&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#152-%E5%AF%B9%E7%AD%89\&#34;&gt;1.5.2 对等&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#153-%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E7%BC%96%E7%A8%8B%E6%8E%A5%E5%8F%A3\&#34;&gt;1.5.3 应用程序编程接口&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#16-%E6%A0%87%E5%87%86%E5%8C%96%E8%BF%9B%E7%A8%8B\&#34;&gt;1.6 标准化进程&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#161-rfc\&#34;&gt;1.6.1 RFC&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#162-%E5%85%B6%E4%BB%96%E6%A0%87%E5%87%86\&#34;&gt;1.6.2 其他标准&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#17-%E5%AE%9E%E7%8E%B0%E5%92%8C%E8%BD%AF%E4%BB%B6%E5%88%86%E5%8F%91\&#34;&gt;1.7 实现和软件分发&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#18-%E4%B8%8E-internet-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E7%9B%B8%E5%85%B3%E7%9A%84%E6%94%BB%E5%87%BB\&#34;&gt;1.8 与 Internet 体系结构相关的攻击&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#19-%E6%80%BB%E7%BB%93\&#34;&gt;1.9 总结&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#110-%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE\&#34;&gt;1.10 参考文献&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;p&gt;JEP 是 JDK改进提案(JDK Enhancement Proposal) 的缩写，简单来说，这是一个关于增强 JDK 的建议。&lt;br&gt;\nJEP 可以是关于语言功能的，也可以是关于 API 的，例如 &lt;a href=\&#34;https://openjdk.java.net/jeps/395\&#34;&gt;JEP 395&lt;/a&gt; 中关于 Record 的提案。Records 是一种语言特征，在反射 API 中进行了一些更改；或者关于 switch 表达式的新 switch 语法的 &lt;a href=\&#34;https://openjdk.java.net/jeps/361\&#34;&gt;JEP 361&lt;/a&gt; ，这是语言特性；它也可以是关于 JVM 是如何工作的，例如 &lt;a href=\&#34;https://openjdk.java.net/jeps/333\&#34;&gt;JEP 333&lt;/a&gt; 是关于 ZGC 的；它可能是和安全更新相关的，和工具相关的，任何有关 Java 的东西。&lt;/p&gt;\n&lt;!-- more --&gt;\n&lt;p&gt;JEP 是十年前创建的，它们有编号，第一个 JEP 是 &lt;a href=\&#34;https://openjdk.java.net/jeps/1\&#34;&gt;JEP 1: JDK Enhancement-Proposal &amp;amp; Roadmap Process&lt;/a&gt;，创建于 2011 年 6 月 23 日，它给出了详细的 JEP 定义，JEP 的第一个目标是描述一个新事物，Java可能需要从社区获得评论和反馈，这个新元素在将来仍然会很遥远，JEP 可能需要大约三年来实现。JEP 1 的第二个目标是定义一个统一的格式来描述这些新事物，以及你可以找到这些 JEP 的地方。JEP 只适用于重大修改，小错误修复不会通过 JEP 发布。JEP 告诉我们几件事，一个 JEP 应该代表至少两周的开发，JEP 应该讨论一些需要广泛了解的东西，可以创建 JEP 来讨论远远没有准备好但值得研究的事情，这个目标就是：得到一些评论，一些反馈，一些关于这些的想法。因此，如果你想这么做，只需要使用 JEP，JEP 也可以撤回。&lt;/p&gt;\n&lt;p&gt;&lt;a href=\&#34;https://openjdk.java.net/jeps/2\&#34;&gt;JEP 2: JEP Template&lt;/a&gt;，创建于 2011 年 6 月 23 日，该 JEP 提供了关于应该如何编写 JEP 的细节，最后一个是 2011 年 8 月 14 日发布的第三个 JEP，编号为 0，即&lt;a href=\&#34;https://openjdk.java.net/jeps/0\&#34;&gt;JEP 0: JEP Index&lt;/a&gt;，JEP 0 实际上是所有 JEP 的目录，如果你在寻找一个特定的 JEP，看这个是最好的。&lt;/p&gt;\n&lt;p&gt;一个新的语言特征可以分散多个 JEP 之间，例如对于 Record 功能，分别有 JDK 14 的 &lt;a href=\&#34;https://openjdk.java.net/jeps/359\&#34;&gt;JEP 359&lt;/a&gt; 第一次预览；还有 JDK 15 中的 &lt;a href=\&#34;https://openjdk.java.net/jeps/384\&#34;&gt;JEP 384&lt;/a&gt; 的 Record 第二次预览；JDK 17 的 &lt;a href=\&#34;https://openjdk.java.net/jeps/395\&#34;&gt;JEP 395&lt;/a&gt; 最终 Record 特性。最终，我们就有了 Record 的功能。&lt;/p&gt;\n&lt;p&gt;JEP 可以给你带来这几样东西，它的目标，它的非目标，它的动机，为什么有这个 JEP 以及它将带来的 JDK 的改进，最后一点，它应该描述这个 JEP 是关于什么的，以及它将对JDK中的其他地方产生什么影响。&lt;/p&gt;\n&lt;p&gt;所以，对于 Record 的 JEP，目标是设计一个面向对象的结构，表达一个简单的值聚合类型；第二，是帮助开发人员关注模块化的不可变数据，而不是可扩展行为；第三，自动实现数据驱动方法，如 &lt;code&gt;equals()&lt;/code&gt; 和 accessors；第四，保持长久 Java 原则，例如名义类型(nominal typing) 和 迁移兼容性(migration compatibility)。我把这些方法称为样本代码(boilerplate)，因为这就是你想要的，简单地说，Record 是值的集合(aggregation of values)，保存不可变数据(hold immutable data)，自动实现(automatically implement)。保持 Java 主体，每一种类型作为名字，所以简单地说，Record 只是一个命名的元组。&lt;/p&gt;\n&lt;p&gt;这里有三个非目标，第一个非目标是向样板代码(boilerplate)宣战；第二个非目标，解决使用 Java bean 命名约定的可变类问题；第三个非目标，添加注释驱动的代码生成。&lt;/p&gt;\n&lt;p&gt;Records 的动机在这里是为了更容易地创建仅仅作为数据载体的类。接下来是描述，在 &lt;a href=\&#34;https://openjdk.java.net/jeps/395\&#34;&gt;JEP 395&lt;/a&gt; 中的 Title 下，你可以看到几页非常清晰的代码示例和模式解释，这是一个非常容易阅读和教育的文本。JEP 不是作为规范文档编写的，在规范文档中你可可能会想添加只对实现者有用的不易于阅读的规范文档，不适合需要 Record 作为日常工作工具的开发人员。最后，依赖部分，这里是对反射 API 的影响，在 Java 反射 API 的几个类中有更多的方法，以及 Record 如何与封闭类(sealed class)一起工作，因为 Record 是用 final class 建模的。&lt;/p&gt;\n&lt;p&gt;简单地说，JEP 是为了易于阅读，易于访问和学习教育而编写的文档，所以你可以阅读它们，这对你的 Java 有好处。&lt;/p&gt;\n&#34;,&#34;fileName&#34;:&#34;what-is-jep&#34;,&#34;abstract&#34;:&#34;&lt;p&gt;JEP 是 JDK改进提案(JDK Enhancement Proposal) 的缩写，简单来说，这是一个关于增强 JDK 的建议。&lt;br&gt;\nJEP 可以是关于语言功能的，也可以是关于 API 的，例如 &lt;a href=\&#34;https://openjdk.java.net/jeps/395\&#34;&gt;JEP 395&lt;/a&gt; 中关于 Record 的提案。Records 是一种语言特征，在反射 API 中进行了一些更改；或者关于 switch 表达式的新 switch 语法的 &lt;a href=\&#34;https://openjdk.java.net/jeps/361\&#34;&gt;JEP 361&lt;/a&gt; ，这是语言特性；它也可以是关于 JVM 是如何工作的，例如 &lt;a href=\&#34;https://openjdk.java.net/jeps/333\&#34;&gt;JEP 333&lt;/a&gt; 是关于 ZGC 的；它可能是和安全更新相关的，和工具相关的，任何有关 Java 的东西。&lt;/p&gt;\n&#34;,&#34;title&#34;:&#34;What is JEP ?&#34;,&#34;tags&#34;:[],&#34;date&#34;:&#34;2022-03-26 10:00:17&#34;,&#34;dateFormat&#34;:&#34;2022-03-26&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://wenbozhangw.github.io/post/what-is-jep/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;5 min read&#34;,&#34;time&#34;:252000,&#34;words&#34;:1143,&#34;minutes&#34;:5},&#34;description&#34;:&#34;JEP 是 JDK改进提案(JDK Enhancement Proposal) 的缩写，简单来说，这是一个关于增强 JDK 的建议。\nJEP 可以是关于语言功能的，也可以是关于 API 的，例如 JEP 395 中关于 Record 的提案...&#34;,&#34;toc&#34;:&#34;&#34;},{&#34;content&#34;:&#34;&lt;h2 id=\&#34;acknowledgements\&#34;&gt;Acknowledgements&lt;/h2&gt;\n&lt;p&gt;四年多来，我一直在写这本书，以这样或那样的形式，一路上有很多人帮助和支持我。&lt;/p&gt;\n&lt;p&gt;我感谢许多阅读手稿和评论的人。如果没有这些反馈，这本书是不可能完成的。有几家对他们的评论给予了特别慷慨的关注。由Russ Rufer和Tracy Bialek领导的硅谷模式小组(Silicon Valley Patterns Group)花了七周时间仔细审阅这本书的第一份完整草稿。由拉尔夫·约翰逊(Ralph Johnson)领导的伊利诺伊大学读书小组也花了几周时间仔细审查后来的草稿。听这些小组长时间、生动的讨论，产生了深远的影响。Kyle Brown和Martin Fowler提供了详细的反馈，有价值的见解和无价的道德支持(坐在一条鱼上)。沃德·坎宁安的反馈很重要。Alistair Cockburn鼓励我，帮助我在出版过程中找到自己的方向。大卫·西格尔(David Siegel)和尤金·沃林福德(Eugene Wallingford)帮我避免了在技术层面上的尴尬。Vibhu Mohindra和Vladimir Gitlevitch煞费苦心地检查了所有的代码示例。&lt;/p&gt;\n&lt;p&gt;Rob Mee阅读了我最早的一些探索材料，并与我一起进行头脑风暴，当我在探索某种方式来传达这种设计风格时。然后他给我灌了一份很久以后的草稿。&lt;/p&gt;\n&lt;p&gt;Josh Kerievsky负责了这本书发展的一个主要转折点:他说服我尝试“亚历山大”模式格式，这成为了这本书的组织支柱。在1999年的PLoP会议之前的密集“指导”过程中，他还帮助我将第二部分中的一些材料第一次整合成一个连贯的形式。这成了本书其余大部分内容的基础。&lt;/p&gt;\n&lt;p&gt;在构思这本书之前，我必须先形成自己对软件开发的看法和理解。这一发展在很大程度上要归功于一些才华横溢的人的慷慨，他们是我的非正式导师，也是我的朋友。David Siegel, Eric Gold和Iseult White，以不同的方式帮助我形成了软件设计的思维方式。几乎同时，Bruce Gordon, Richard Freyberg和Judith Segal也以不同的方式帮助我在成功的项目工作中找到自己的道路。&lt;/p&gt;\n&lt;p&gt;在这个关键时期，我也有很多想法，这些想法形成了我自己技术观点的基础。其中一些贡献将在主要文本中清楚说明，并在可能时加以引用。其他的是如此的基本，我甚至没有意识到他们对我的影响。&lt;/p&gt;\n&lt;p&gt;我的硕士论文导师，Bala Subramanium博士，让我对数学建模产生了兴趣，我们把它应用到化学反应动力学中，但建模就是建模，而这项工作正是我写这本书的原因之一。&lt;/p&gt;\n&lt;p&gt;甚至在此之前，我的思维方式的形成多亏了我的父母，Carol 和 Gary Evans，以及一些特殊的老师，特别是 Dale Courier（一所高中的数学老师），Mary Brown（高中英语作文老师），和一个六年级的科学课老师的名字，我很抱歉已经遗忘了。&lt;/p&gt;\n&lt;p&gt;最后，我要感谢我的朋友和家人，还有 Fernando De Leon，感谢他们在这漫长的过程中给予我的鼓励。&lt;/p&gt;\n&lt;h2 id=\&#34;preface\&#34;&gt;Preface&lt;/h2&gt;\n&lt;p&gt;领先的软件设计师已经认识到领域建模和设计(domain modeling and design)作为关键的主题至少已经有 20 年了，但是令人惊讶的是，几乎没有人写过需要做什么或者如何做。虽然它从来没有被清晰的表述出来，但一种哲学已经发展成为对象社区中的一股暗流，我称之为“领域驱动设计(domain-driven design)”。&lt;/p&gt;\n&lt;p&gt;在过去的十年里，我专注于在几个业务和技术领域开发复杂的系统。我尝试过设计和开发过程中的最佳实践，因为它们已经从面向对象开发社区的领导者那里出现了。我的一些项目非常成功；一些失败了。成功案例的共同特征是丰富的领域模型，它通过设计的迭代不断发展，并成为项目结构的一部分。&lt;/p&gt;\n&lt;p&gt;本书提供了一个设计决策的框架和一个讨论领域设计的技术词汇表。它综合了广泛接受的最佳实践，以及我自己的见解和经验。面对复杂领域的项目可以使用这个框架，系统地实现领域驱动设计。&lt;/p&gt;\n&lt;h3 id=\&#34;contrasting-tree-projects\&#34;&gt;Contrasting Tree Projects&lt;/h3&gt;\n&lt;p&gt;我看到一个项目用一个有用的、简单的基于网络的交易系统很快就完成了。开发人员凭自己的感觉，但简单的软件也可以在不太关注设计的情况下编写出来。由于这一初步成功，人们对未来发展的期望很高。就在这个时候，有人找我做第二个版本的工作。当我仔细观察的时候，我发现他们缺少一个领域模型，甚至在项目上没有通用的语言，并且被强加于非结构化的设计。所以当项目领导不同意我的评估时，我拒绝了这份工作。一年后，他们发现自己陷入了困境，无法发布第二个版本。尽管他们对技术的使用不是典范，但业务逻辑战胜了他们。他们的第一个版本过早地僵化为一个高维护的遗产。&lt;/p&gt;\n&lt;p&gt;要想提高复杂性的上限，需要一种更严肃的领域逻辑设计方法。在我职业生涯的早期，我很幸运地完成了一个强调领域设计的项目。这个项目，在一个至少和上面一样复杂的领域，也开始了一个适度的初步成功，为机构交易者交付一个简单的应用程序。但这一交付之后，开发的速度连续加快。每次后续的迭代都为集成和细化功能打开了令人兴奋的新选项。团队的方式能够灵活地响应交易员的需求和扩展能力。这种向上的轨迹直接归因于一个尖锐的领域模型，它在代码中反复的细化和表达。随着团队对该领域有了新的认识，模型也加深了。开发人员之间以及开发人员与领域专家之间的交流质量得到了提高，而且设计非但没有增加越来越重的维护负担，反而变得更容易修改和扩展。&lt;/p&gt;\n&lt;p&gt;不幸的是，并非所有以这种意图开始的项目都能达到这种良性循环。我参加的一个项目一开始有一个远大的志向，那就是建立一个基于领域模型的全球企业系统，但最后却有一个失望的结果。这个团队有很好的工具，对业务有很好的理解，并且非常重视建模。但是开发人员角色的分离导致了模型和实现之间的脱节，因此设计没有反映正在进行的深入分析。在任何情况下，详细业务对象的设计都不够严格，无法支持在详细的应用程序中组合它们。由于开发人员的技能水平参差不齐，且对所需的特定类型的严格性没有清晰的理解，重复的迭代并没有产生代码的改进。几个月过去了，开发工作陷入了复杂性的泥潭，团队是去了系统的凝聚力。经过多年的努力，该项目确实生产处了规模不大、有用的软件，但已经放弃了早期的雄心壮志和模型重点。&lt;/p&gt;\n&lt;p&gt;当然，很多事情会让项目偏离轨道，比如官僚主义、目标不明确、资源缺乏等，但是设计方法在很大程度上决定了软件的复杂程度。当复杂性失去控制时，软件就不能再被很好地理解以方便地更改或扩展。相比之下，一个好的设计可以从这些复杂的功能中创造机会。&lt;/p&gt;\n&lt;p&gt;其中一些设计因素是技术性的，大量的工作已经投入到网络、数据库和软件的其他技术层面的设计中。关于如何解决这些问题的书已经出版了。开发人员已经培养了他们的技能。&lt;/p&gt;\n&lt;p&gt;然而，许多应用程序最显著的复杂性并不是技术上的。它属于领域本身，用户的活动或业务。如果在设计中没有处理这个领域的复杂性，那么基础设施技术是否经过了良好的考虑就无关紧要了。一个成功的设计必须系统地处理软件的这个核心方面。&lt;/p&gt;\n&lt;p&gt;这本书的前提是：&lt;/p&gt;\n&lt;ol&gt;\n&lt;li&gt;对大多数软件项目，主要关注点应该放在域和域逻辑(domain and domain logic)上。&lt;/li&gt;\n&lt;li&gt;复杂的领域涉及应该基于模型。&lt;/li&gt;\n&lt;/ol&gt;\n&lt;p&gt;领域驱动设计是一种思维方式和一组优先级，旨在加速必须处理复杂领域的软件项目。为了实现这个目标，这本书提出了一套管饭的设计实践，技术和原则。&lt;/p&gt;\n&lt;h3 id=\&#34;design-vs-development-process\&#34;&gt;Design vs. Development Process&lt;/h3&gt;\n&lt;p&gt;设计的书。过程的书。它们甚至很少相互引用。每一个都是一个复杂的主题。这是一本设计的书籍。但我认为，要想将设计理念成功地付诸实践，而不是在学术讨论中枯竭，这两个问题是不可分割的。当人们学习设计技术时，他们会面对真正项目的混乱现实。他们不知道什么时候该考虑某个特定的设计方面，什么时候该放弃以节省时间。虽然我们可以与其他团队成员讨论抽象设计原则的应用，但更自然的做法是讨论我们一起做的事情。所以，虽然这是一本书，但我要在需要的时候，打破这个人为的界限。这将把设计至于开发过程的上下文中。&lt;/p&gt;\n&lt;p&gt;这本书并不是针对特定的方法论，而是面向“敏捷开发过程”的新系列。具体的说，它假定在项目中有一些过程实践。这两个实践是应用本书中的方法的先决条件。&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;迭代开发。迭代开发的实践已经被提倡和实践了几十年，并且是敏捷开发方法的基石。关于敏捷开发和极限编程的文献中有很多很好的讨论，其中有 [Cockburn1998] 和 [Beck 1999]。&lt;/li&gt;\n&lt;li&gt;开发人员和领域专家之间的密切关系。领域驱动的设计将大量的知识转化为一个模型，该模型反映了对领域的深刻理解和对关键概念的关注。这是一个了解领域的人和知道如何构建软件的人之间的协作。因为它是迭代的，所以这种协作必须在项目的整个生命周期中继续进行。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;极限编程（Extreme Programming, XP）是由 Kent Beck，Ward Cunningham 和其他人 [Beck 2000] 构想的，它是敏捷过程中最杰出的，也是我接触最多的。为了使讨论更加具体，我将在整本书中使用 XP 作为讨论设计和过程交互的基础。说明的原则很容易适用于其他敏捷过程。&lt;/p&gt;\n&lt;p&gt;近年来，人们开始反对复杂的开发方法，这种方法是无用的、静态的文档、强迫性的前期计划和设计来给项目增加负担。相反，敏捷过程（如 XP）强调的是应对变化和不确定性的能力。&lt;/p&gt;\n&lt;p&gt;XP 认识到设计决策的重要性，但强烈反对预先设计。相反，它投入了令人钦佩的努力来增加沟通，并增加项目快速改变方向的能力。有了这种反应能力，开发人员可以在项目的任何阶段使用“最简单的可以工作的东西”，然后不断地重构，进行许多小的设计改进，最终达到符合客户真正需求的设计。&lt;/p&gt;\n&lt;p&gt;对于一些设计狂热者来说，这是一剂继续的解毒剂。项目陷入了没有价值的繁琐文档中。他们遭受了“分析麻痹”，如此害怕一个不完美的设计，以至于他们没有取得任何进展。必须有所改变。&lt;/p&gt;\n&lt;p&gt;不幸的是，其中一些新的过程思想很容易被误解。每个人对“最简单”都有不同的定义。没有设计原则来指导这些小的重新设计的持续重构，会产生难以理解或更改的代码库——这与敏捷性背道而驰。而且，尽管对未来预料到的需求的恐惧尝尝导致过度工程化，但试图避免过度工程化可能会发展成另一种恐惧：对任何深度设计思考的恐惧。&lt;/p&gt;\n&lt;p&gt;事实上，XP 最适合具有敏锐设计意识的开发人员。XP 过程假设您可以通过重构来改进设计，并且您经常和迅速地这样做。但是设计选择使重构本身变得更容易或更困难。XP 过程试图增加团队交流。但是模型和设计的选择会澄清或混淆沟通。我们需要的是一种能够发挥作用的领域建模和设计方法。&lt;/p&gt;\n&lt;p&gt;这本书交织了设计和开发实践，并说明了领域驱动的设计和敏捷开发是如何相互加强的。在敏捷开发过程的上下文中，一种复杂的领域建模方法将加速开发。过程与领域开发的相互关系使这种方法比任何真空中的“纯”设计处理更实用。&lt;/p&gt;\n&lt;h3 id=\&#34;the-structure-of-this-book\&#34;&gt;The Structure of This Book&lt;/h3&gt;\n&lt;p&gt;本书分为四个主要部分:&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;第一部分：Putting the Domain Model to Work&lt;/em&gt; 中提出了领域驱动开发的基本目标，这些开发将在后面的部分中激励实践。由于软件开发有很多方法，第一部分定义了术语，并概述了领域模型置于驱动通信和设计的角色中的含义。&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;第二部分：The Building Blocks of Model-driven Design&lt;/em&gt; 将面向对象领域建模的最佳时间核心浓缩为一组基本模块。本节的重点是弥合模型和实际运行的软件之间的差距。共享这些标准模式为设计带来的秩序，并使团队成员很容易理解彼此的工作。使用标准模式还可以建立一种公共语言，所有团队成员都可以使用它来讨论模型和设计决策。&lt;/p&gt;\n&lt;p&gt;但是，本节的主要观点是关于保持模型和实现相互对齐的那种决策、增强彼此的有效性。这种对齐需要注意单个元素的细节。在这种小范围内的精心制作为开发人员提供了一个稳定的平台来应用第三部分和第四部分中的建模方法。&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;第三部分：Refactoring Toward Deeper Insight&lt;/em&gt; 超越了构建模块的挑战，将它们组装成提供回报的实际模型。本节强调的是发现过程，而不是直接跳到深奥的设计原则。有价值的模型不会马上出现。它们要求对该领域有深刻的理解。这种理解来自于深入，实现一个基于 天真的(naïve) 模型的初始设计，然后一次又一次地转换它。每次团队获得洞察力时，模型都会被转换为揭示更丰富的知识，代码也会被重构，以反映更深层的模型，并使其潜能可用于应用程序。然后，有时，这种洋葱式的剥离会带来一个突破更深层模型的机会，伴随着一系列深刻的设计变化。&lt;/p&gt;\n&lt;p&gt;探索本质上是开放式的，但并不一定是随机的。&lt;em&gt;第三部分&lt;/em&gt;深入研究了可以指导选择的建模原则，以及帮助知道搜索的技术。&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;第四部分：Strategic Design&lt;/em&gt; 处理出现在复杂系统、大型组织、与外部系统和遗留系统的交互中的情况。本节讨论了适用于系统作为一个整体的三个原则：有界上下文(Bounded Context)、蒸馏(Distillation)、大规模结构(Large-Scale Structure)。战略设计决策有团队，甚至在团队之间制作。战略设计使我能够以更大的规模实现&lt;em&gt;第一部分&lt;/em&gt;的目标，适用于大型系统或适合企业范围内的应用程序。&lt;/p&gt;\n&lt;p&gt;整本书的讨论都是用显示的例子来说明的，这些例子来自实际的项目，而不是过于简化的“玩具”问题。&lt;/p&gt;\n&lt;p&gt;这本书的大部分内容都是作为一套“模式”而写的。读者应该能够完全理解材料而不关心这个设备，但是那些对模式的样式和格式感兴趣的人可以阅读附录1。&lt;/p&gt;\n&lt;h3 id=\&#34;who-this-book-is-written-for\&#34;&gt;Who This Book is Written For&lt;/h3&gt;\n&lt;p&gt;这本书主要是为面向对软件的开发人员编写的。软件项目团队的大多数成员都可以从它的某些部分中受益。这对于哪些正在进行项目的人来说是最有意义的，他们尝试着去做这些事情，或者那些已经有了与之相关的深刻经验的人。&lt;/p&gt;\n&lt;p&gt;本书需要一些面向对象建模的只是。这些例子包括 UML 图和 Java 代码，因此在基本层面上阅读这些语言的能力很重要，但是没有必要掌握 UML 或 Java 的细节。极限编程的知识将为开发过程的讨论增加视角，但是没有背景知识的讨论应该是可以理解的。&lt;/p&gt;\n&lt;p&gt;对于一个中级软件开发人员，一个已经知道一些面向对象设计的读者，可能已经读过一到两本软件设计书籍，这本书将填补空白，并提供了如何在软件项目的现实生活中使用对象建模的观点。它将帮助中级开发人员将复杂的建模和设计技能应用到实际问题。&lt;/p&gt;\n&lt;p&gt;高级或专业的软件开发人员应该对处理该领域的综合框架感兴趣。系统的设计方法将帮助他们带领团队走这条路。连贯的属于将有助于他们与同行交流。&lt;/p&gt;\n&lt;p&gt;不同背景的读者可能希望通过本书采取不同的路径，将重点转移到不同的点上。我建议所有读者从第一部分和第一章的介绍开始。这本书是一本叙事性的书，可以从头读到尾，也可以从任何一章的开头读。一个已经对某个主题有所了解的浏览者应该能够通过阅读标题和粗体文本来抓住要点。一个非常高级的读者可能想要浏览第一部分和第二部分，并且可能对第三部分和第四部分最感兴趣。&lt;/p&gt;\n&lt;p&gt;除了这些核心读者外，这本书还会引起分析人员和相对技术性的项目经理的兴趣。分析人员可以利用模型和设计之间的练习，在“敏捷”项目的上下文中做出更有效的贡献。分析师也可以使用一些战略设计原来来更好地集中和组织他们的工作。&lt;/p&gt;\n&lt;p&gt;项目经理应该关注如何使团队更有效，以及如何设计对业务专家和用户有意义的软件。而且，由于战略设计决策与团队组织和工作风格有关，这些设计决策必然涉及到项目的领导，并对项目的发展轨迹产生重大影响。&lt;/p&gt;\n&lt;p&gt;虽然理解领域驱动设计的开发人员将获得有价值的设计技术和观点，但当团队应用领域驱动的设计方法并将领域模型移到项目讨论的中心时，将获得最大的收益。团队成员将共享一种语言，这种语言丰富了他们的交流，并使其与软件保持联系。它们将生成与模型同步的实现，从而为应用程序开发提供优势。他们将分享不同团队的设计工作如何关联的映射，并将系统地关注对组织最有特色和最有价值的功能。&lt;/p&gt;\n&lt;p&gt;领域驱动的设计是一个困难的技术挑战，它可以带来巨大的回报，在大多数软件项目开始僵化为遗留项目的阶段，它打开了机会。&lt;/p&gt;\n&lt;p&gt;Eric Evans, San Francisco, California, March 2003&lt;br&gt;\nhttp://domainlanguage.com&lt;/p&gt;\n&lt;hr&gt;\n&lt;h1 id=\&#34;part-i-putting-the-domain-model-to-work\&#34;&gt;Part I. Putting the Domain Model to Work&lt;/h1&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;1\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1644831969455.png\&#34; alt=\&#34;The 18th century Chinese map\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;上面的 18 世纪中国地图代表了整个世界。在中心占据了大部分空间的是中国，周围是敷衍了事的其他国家的代表。这是一个适合那个故意向内转的社会的世界模式。这幅地图所代表的的世界观在与外国人打交道时一定没有帮助。当然，它根本不会为现代中国服务。地图是模型，每一个模型都代表了现实的某些方面或一个有趣的想法。这是一种简化。这是一种对现实的解释，它抽象了与解决手头问题有关的方面，而忽略了无关的细节。&lt;/p&gt;\n&lt;p&gt;每个软件程序都与用户的某些活动或兴趣有关。用户应用程序的主题区域就是软件的“领域(domain)”。有些领域涉及物理世界。航空公司预定程序的领域涉及到真实的人称作真实的飞机。有些领域是无形的。会计程序的领域是货币和金融。软件领域通常与计算机没有什么关系，尽管也有例外。源代码控制系统的领域是软件开发本身。&lt;/p&gt;\n&lt;p&gt;要创建有价值的软件，我们必须提供与软件将涉及的活动相关的知识体系。所需的知识量可能令人生畏。信息的数量和复杂性可能是压倒性的。这时，开发团队可以使用建模来处理过载问题。模型是一种有选择地简化和有意识地结构化的知识形式。一个合适的模型可以使信息有意义，并使其与问题相关。&lt;/p&gt;\n&lt;p&gt;领域模型不是一个特定的图：这就是图所要传达的思想。它不仅仅是领域专家头脑中的知识；&lt;em&gt;它是对知识的严格阻止和选择性的抽象&lt;/em&gt;。图可以表示和交流模型，也可以是精心编写的代码，也可以是英语句子。&lt;/p&gt;\n&lt;p&gt;领域建模不是使模型尽可能“真实”的问题。即使在有形的现实世界中，我们的模型也是人为创造的。也不只是构建一个软件机制来提供必要的结果。它更像电影制作，松散地代表现实以达到特定的目的。即使是异步纪录片也不会展现未经编辑的真实生活。正如电影制作人员选择体验的各个方面，并以一种特殊的方式来讲述一个故事或表达一个观点一样，选择领域模型是为了它的实用性。&lt;/p&gt;\n&lt;h3 id=\&#34;the-utility-of-a-model-in-domain-driven-design\&#34;&gt;The Utility of a Model in Domain-Driven Design&lt;/h3&gt;\n&lt;p&gt;在领域驱动的设计中，有三个基本的用途决定模型的选择。&lt;/p&gt;\n&lt;ol&gt;\n&lt;li&gt;该模型规定了软件核心的设计形式。正是模型和实现之间的密切关系，使模型具有相关性，并确保进入模型的分析适用于最终产品，即运行的程序。这种模型和实现的绑定还有助于维护和继续开发，因为可以根据对模型的理解来解释代码。（第三章）&lt;/li&gt;\n&lt;li&gt;模型是所有团队成员使用的语言的主干。由于模型和实现的绑定，开发人员可以用这种语言来讨论程序。他们无需翻译就可以与领域专家交流。因为语言是基于模型的，我们的自然语言能力可以被用来完善模型本身。（第二章）&lt;/li&gt;\n&lt;li&gt;模型是对知识的提炼。模型是团队一致同意的构建领域知识和区分最感兴趣的元素的方法。当我们选择术语、分解概念并将它们联系起来时，模型捕获了我们如何选择考虑这个领域。共享语言允许开发人员和领域专家有效地协作，将信息转换成这种形式。模型和实现的绑定意味着使用软件早期版本的经验也是对模型过程的有效反馈。（第一章）&lt;/li&gt;\n&lt;/ol&gt;\n&lt;p&gt;接下来的三章依次探讨这些贡献的意义和价值，以及它们互相交织的方式。以这些方式使用模型可以支持具有丰富功能的软件开发，否则将需要大量的临时开发投资。&lt;/p&gt;\n&lt;p&gt;然而，大多数项目从他们的领域模型中得到的很少。这本书将研究有效领域开发的一系列潜在障碍，以及通过设计原则（从高级概念到具体技术）客服这些障碍的方法。&lt;/p&gt;\n&lt;h3 id=\&#34;the-centrality-of-ddomain-functionality\&#34;&gt;The Centrality of Ddomain Functionality&lt;/h3&gt;\n&lt;p&gt;软件的核心是为用户解决领域相关问题的能力。所有其他功能，尽管可能很重要，都支持这一基本目的。当领域复杂时，这是一项艰巨的任务，需要有才能和技能的人集中努力。开发人员必须深入该领域以积累业务知识。他们必须磨炼自己的建模技能并掌握领域设计。&lt;/p&gt;\n&lt;p&gt;然而，这并不是大多数软件项目的优先级。大多数有才华的开发人员对他们工作的特定领域并没有太多的兴趣，更不用说对扩展他们的领域建模技能做出重大承诺了。技术人员喜欢可量化的技术问题，以锻炼他们的技术能力。这个领域很混乱，需要大量复杂的新知识，而这些知识似乎并不能发展一个计算机科学家的能力。&lt;/p&gt;\n&lt;p&gt;取而代之的是，技术人才致力于复杂的框架，试图用技术解决领域问题。软件核心的复杂性必须迎面解决。没有这个重点是一个项目风险。&lt;/p&gt;\n&lt;p&gt;在一次电视访谈节目中，喜剧演员 John Cleese 讲述了《Monty Python and the Holy Grail》拍摄期间的一个故事。他们一遍又一遍地拍摄一个特定的场景，但不知怎么的，这并不有趣。最后，他休息了一下，和他的喜剧伙伴 Michael Palin （现场的另一个演员）商量了一下，他们想出了一个轻微的变化。他们又拍了一集，所结果很有趣，所以就收工了。&lt;/p&gt;\n&lt;p&gt;第二天早上，Mr. Cleese 正在看电影剪辑师从前一天的工作中整理出来的粗剪。回到他们苦苦挣扎过的场面，他发现这一点也不好玩。一个早期的镜头被使用过。&lt;/p&gt;\n&lt;p&gt;他问电影编辑，为什么他没有按照导演的指示使用最后的镜头。“用不上。有人走了进来。”编辑回答。Mr. Cleese 看了一遍又一遍。他仍然看不出有什么不对。最后，剪辑员停下胶卷，指着照片边缘的一个外套袖子，在图片的边缘可以看到一会儿。&lt;/p&gt;\n&lt;p&gt;电影编辑担心其他看过这部电影的电影编辑会根据他作品的技术完美程度来评判他的作品。他专注于自己专业的精确执行，在这个过程中，场景的核心已经丢失。[“The Late Late Show with Craig Kilborn”, CBS, September, 2001]&lt;/p&gt;\n&lt;p&gt;幸运的是，一个懂喜剧的导演恢复了滑稽的场景。同样地，当热情的开发人员忙于开发复杂的技术框架，而这些技术框架并不服务于领域开发，或者实际上阻碍了领域开发，而反应了对领域深刻理解的模型的开发却在混乱中丢失时，理解领域中心的团队领导可以让他们的软件项目回到正规。&lt;/p&gt;\n&lt;p&gt;这本书将说明领域开发提供了培养非常复杂的设计技能的机会。大多数业务领域的混乱是一个有趣的技术挑战。事实上，在许多科学学科中，当研究人员试图解决现实世界的混乱时，“复杂性”是当前最令人兴奋的话题之一。当软件开发人员面对一个从未形式化的复杂领域时，也会有同样的前景。创建一个清晰的模型，并通过复杂的过程来解决问题是令人兴奋的。&lt;/p&gt;\n&lt;p&gt;开发者可以使用系统的思维方式来寻找洞察力并生成有效的模型。有一些设计技术可以为庞大的软件应用程序带来秩序。这些技能的培养使开发人员更有价值，即使是在最初不熟悉的领域。&lt;/p&gt;\n&lt;h2 id=\&#34;1-crunching-knowledge\&#34;&gt;1. Crunching Knowledge&lt;/h2&gt;\n&lt;p&gt;几年前，我开始为印刷电路板（Printed Circuit Board, PCB）设计一个专门的软件工具。有一个问题：我对电子硬件一无所知。当然，我接触到了一些 PCB 设计师，但他们通常在三分钟内就让我晕头转向。我怎样才能充分理解编写这个软件呢？我当然不会在截止日期之前成为一名电气工程师！&lt;/p&gt;\n&lt;p&gt;我们尝试让他们确切地告诉我软件该做什么。坏主意。他们是伟大的电路设计师，但他们的软件理念通常涉及阅读 ASCII 文件，对其进行分类，用一些注释将其写出来，然后生成一份报告。这显然不会带来他们所期望的生产力的飞跃。&lt;/p&gt;\n&lt;p&gt;最初的几次会议令人沮丧，但在他们要求的报告中有一丝希望。他们总是设计“网(nets)”和各种各样的是细节。在这个领域，网络本质上是一种导线，它可以连接 PCB 上任意数量的组件，并将电子信号传输到与之相连的任何东西上。我们有了领域模型的第一个元素。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;2\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1644908366466.png\&#34; alt=\&#34;Figure 1.1\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;当我们讨论他们希望软件做的事情时，我开始为他们绘制图表。我使用了对象交互图的非正式变体来演示场景。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;3\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1644908930476.png\&#34; alt=\&#34;Figure 1.2\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;pre&gt;&lt;code&gt;PCB 专家 1：组件(components)不必是芯片。\n开发人员（我）：所以我应该称它们为组件(components)?\n专家 1：我们称它们为“组件实例(component instances)”。可能有许多相同的组件。\n专家 2：“网络(net)” box 看起来就像一个组件实例。\n专家 1：他没有用我们的符号。我想，对他们来说，一切都是一个 box。\n开发人员：很抱歉，是的。我想我最好再多解释一下这个符号。\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;他们不断地纠正我，这样我才开始学习。我们消除了他们术语中的冲突和歧义，以及他们技术观点的差异，他们从中学习。他们开始更精确和一致地解释事物，我们开始一起开发一个模型。&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;专家 1：仅仅说一个信号到达一个 ref-des 是不够的，我们必须知道引脚(pin)。\n开发人员：Ref-des ?\n专家 2：和组件实例一样。Ref-des 是我们使用的一种特殊工具。\n专家 1：无论如何，一个 net 将一个实例的特定引脚连接到另一个实例的特定引脚。\n开发人员：你是说一个引脚只属于一个组件实例并连接到只有一个网络(net)？\n专家 1：是的，没错。\n专家 2：而且，每个网络(net)都有一个拓扑结构，一种决定网络(net)元素连接方式的排列。\n开发人员：好的，这个怎么样？\n&lt;/code&gt;&lt;/pre&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;4\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1644910473897.png\&#34; alt=\&#34;Figure 1.3\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;为了专注于我们的探索，我们暂时把自己限制在研究一个特定的功能上。“探测模拟(probe simulation)”将跟踪信号的转播，以检测设计中可能存在的某些类型的问题。&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;开发人员：我明白信号是如何通过网络(Net)传输到所有连接的引脚上(Pins)的，但它是如何进一步传播的呢？拓扑(Topology)和它有关系吗？\n专家 2：没有。组件推动信号通过。\n开发人员：我们当然不能模拟芯片内部的行为。这太复杂了。\n专家 2：我们不需要。我们可以简化一下。只是将组件从某些引脚(Pins)推到某些其他引脚的列表。\n开发人员：像这样？\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;[经过大量的反复试验，我们一起勾勒出了一个场景]&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;5\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1644911795739.png\&#34; alt=\&#34;Figure 1.4\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;pre&gt;&lt;code&gt;开发人员：但是您需要从这次计算中了解什么呢？\n专家 2：我们要找的是长时间的信号延迟——比如说，任何超过两到三跳(hops)的信号路径。这是经验法则。如果路径太长，信号可能在时钟周期内无法到达。\n开发人员：超过三跳(hops)......我们需要计算路径长度。什么算跳(hop)呢？\n专家 2：每次信号通过网络(Net)，就是一次跳跃(hop)。\n开发人员：所以我们可以传递跳(hops)数，没经过一个网络(Net)可以增加它，就像这样。\n&lt;/code&gt;&lt;/pre&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;6\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1644912129042.png\&#34; alt=\&#34;Figure 1.5\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;pre&gt;&lt;code&gt;开发人员：我唯一不清楚的部分是“推送(pushes)”从何而来。我们是否为每个组件实例存储这些数据？\n专家 2：推送(pushes)对于组件的所有实例来说都是一样的。\n开发人员：所以组件的类型决定推送(pushes)。它们对每一个都是实例都是一样的？\n&lt;/code&gt;&lt;/pre&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;7\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1644912318182.png\&#34; alt=\&#34;Figure 1.6\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;pre&gt;&lt;code&gt;专家 2：我不确定这到底意味着什么，但我想每个组件的推送存储(push-throughs)应该是这样的。\n开发人员：对不起，我说得有点太详细了。我只是在思考它。\n开发人员：所以，现在，拓扑(Topology)在哪里发挥作用呢？\n专家 1：这不是用来模拟探针的。\n开发人员：那我现在就退出，好吗？我们可以在讲到这些功能的时候再讲。\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;事情就这样发生了（比这里显示的更加磕磕绊绊）。头脑风暴和精炼；质疑和解释。随着我对领域的理解，以及他们对模型将如何在解决方案中发挥作用的理解，模型得到了开发。表示早期模型的类图如下所示。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;8\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1644912664180.png\&#34; alt=\&#34;Figure 1.7\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;在做了几天的业余工作后，我觉得自己已经能够理解一些代码了。我写了一个非常简单的原型，有一个自动化测试框架驱动。我避开了所有的基础设施。没有持久性，也没有 UI，这让我能够专注于行为。我能够在短短几天内演示一个简单的探测模拟。尽管他使用虚拟数据并将原始文本写入控制台，但它仍然适用 Java 对象进行路径长度的实际计算。这些 Java 对象反应了领域专家和我共享的模型。&lt;/p&gt;\n&lt;p&gt;这个原型的具体性使他们更清楚模型的含义，以及它如何与功能软件相关。从那时起，我们的模型讨论变得更有互动性，因为他们可以看到我如何将我新获得的知识整合到模型中，然后再到软件中。他们从原型中得到具体的反馈来评估自己的想法。&lt;/p&gt;\n&lt;p&gt;在这个模型中嵌入的是与我们正在解决的问题相关的 PCB 领域的知识，这个模型自然变得比这里展示的要复杂得多。它巩固了许多同义词和描述上的细微变化。它排除了数百个工程师理解但不直接相关的事实，比如组件的实际数字特征。像我这样的软件专家可以通过查看图表，在几分钟内就开始了解软件是关于什么的。他或她将有一个框架来组织新信息，并更快速地学习，更好地猜测什么是重要的，什么不是，并更好地与 PCB 工程师沟通。&lt;/p&gt;\n&lt;p&gt;当工程师们描述他们需要的新功能时，我让他们向我介绍这些物体相互作用的场景。当模型对象不能带我们通过一个重要的场景时，我们将新的内容或旧的更改进行了头脑风暴或改变。我们完善了模型：协同进化的代码。几个月后，他们有了超出预期的丰富工具。&lt;/p&gt;\n&lt;h3 id=\&#34;why-it-worked\&#34;&gt;Why It Worked&lt;/h3&gt;\n&lt;p&gt;我们做的一些事情导致了这次成功。&lt;/p&gt;\n&lt;ol&gt;\n&lt;li&gt;尽快绑定模型和实现。这个粗糙的原型铸就了关键的环节。&lt;/li&gt;\n&lt;li&gt;培养一种基于模型的语言。一开始，他们必须像我解释基本的 PCB 问题，而我必须解释类图的含义。但随着研究的进行，从模型中直接取出的术语，组织成与模型结构一致的句子，在他们或我听到后，立即测试了模型的可行性。&lt;/li&gt;\n&lt;li&gt;知识丰富的模型。对象有行为和强制的规则。这个模型不仅仅是一个数据模式，它对于解决一个复杂的问题是不可或缺的。它捕捉了各种各样的知识。&lt;/li&gt;\n&lt;li&gt;知识经过提炼。随着模型变得更完整，重要的概念被添加到模型中，但同样重要的是，当概念被证明没有用处或中心时，它们就会被丢弃。当一个不需要的概念被绑定到一个需要的概念上时，一个新的模型将本质概念区分开来，从而另一个概念可以被抛弃。&lt;/li&gt;\n&lt;li&gt;知识处理(Knowledge crunching)。这种语言结合了草图和头脑风暴的态度，把我们的讨论变成了模型的实验室，在那里可以练习、尝试和判断数百种实验变化。&lt;/li&gt;\n&lt;/ol&gt;\n&lt;p&gt;正式这最后一点，知识处理，使我们有可能找到一个知识丰富的模型和方法来提炼它。它需要头脑风暴和大量实验的创造力。&lt;/p&gt;\n&lt;p&gt;金融分析师分析数字。他们筛选大量的详细数据，将它们组合再组合，寻找潜在的含义，寻找一种能揭示真正重要的东西的简单表述——一种可以成为财务决策基础的理解。&lt;/p&gt;\n&lt;p&gt;有效的领域建模人员是知识处理者。他们获取大量的信息，并寻找相关的细流。他们尝试一个又一个有组织的想法，寻找对大众有意义的简单观点。许多模型都经过了尝试、拒绝或改造。成功来自于一系列新兴的抽象概念，这些概念能够理解所有的细节。这种蒸馏(distillation)是对已发现的最相关的特定知识的严格表达。&lt;/p&gt;\n&lt;p&gt;知识处理不是一项单独的活动。由开发人员和领域专家组成的团队协作，通常由开发人员领导。他们一起吸收信息并将其转化为有用的形式。这些原始资料来自领域专家的头脑，来自现有系统的用户，来自技术团队使用相关遗留系统或同一领域的另一个项目的先前经验。它根据为项目编写的文档或在业务中使用的文档形式出现，以及大量的讨论。早期的版本或原型将经验反馈给团队，并改变早期的解释。&lt;/p&gt;\n&lt;p&gt;在旧的瀑布方法(waterfall method)中，业务专家与分析人员交谈，分析人员对结果进行消化和抽象，并将结果传递给编写软件的程序员。这种方法之所以失败是因为它完全缺乏反馈。分析师完全有责任仅基于业务专家的输入来创建模型。他们没有机会从程序员那里学习或获得早期版本的经验。知识只向一个方向流淌，而不会累积。&lt;/p&gt;\n&lt;p&gt;其他项目有迭代，但没有积累知识，因为它们没有抽象。他们让专家来描述他们想要的功能，然后他们去构建它。他们将结果展示给专家，并询问他们下一步要做什么。如果程序员实践了重构，他们可以保持软件足够干净，以便继续扩展它，但如果程序员对领域不感兴趣，他们只了解应用程序应该做什么，而不是它背后的原则。有用的软件可以通过这种方式构建，但项目永远不会获得那种强大的新特性作为旧特性的必然结果展现出来的那种影响力。&lt;/p&gt;\n&lt;p&gt;优秀的程序员自然会开始抽象和开发可以做更多工作的模型。但是，如果这种情况只发生在技术环境中，而不与领域专家合作，概念都是天真的(naïve)。这种浅薄的知识使得软件只能完成基本的工作，但却与领域专家的思维方式缺乏深层次的联系。&lt;/p&gt;\n&lt;p&gt;团队成员之间的交互随着所有成员一起处理模型而改变。领域模型的不断细化破势开发人员学习他们所协助的业务的重要原则，而不是机械地生成功能。领域专家经常通过被迫将他们知道的提炼为要点来精炼他们自己的理解，并且他们开始了解概念严格的软件项目所需的要求。&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;所有这些都使团队成为更有能力的知识处理者(knowledge crunchers)。他们剔除无关的东西。他们将模型重新塑造成一种更加有用的形式。因为分析人员和程序员对它进行了输入，所以它被清晰地组织和抽象，并且可以为实现提供杠杆作用。因为领域专家正在向它提供信息，所以它反应了对业务的深刻认识，而那些抽象是真正的业务原则。&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;随着模型的改进，它将成为组织信息的工具，这些信息将继续在项目中流动。它侧重于需求分析。他与编程和设计密切相关。并且，有一个良性循环中，它加深了团队成员对领域的洞察，让他们更清楚地看到，并导致模型的进一步细化。这些模型从来都不是完美的。他们在不断发展。它们在理解领域时必须是实用的且有用的。它们必须足够严格，以使应用程序易于实现和理解。&lt;/p&gt;\n&lt;h3 id=\&#34;continuous-learning\&#34;&gt;Continuous Learning&lt;/h3&gt;\n&lt;p&gt;*当我们开始编写软件时，我们知道的永远不够。*关于项目的知识是支离破碎的，分散在许多人和文档中，并与其他信息混合在一起，所以我们甚至不知道哪些知识是我们真正需要的。看起来技术上不那么令人生畏的领域可能是具有欺骗性的——我们没有意识到有多少我们不知道。这导致我们做出错误的假设。&lt;/p&gt;\n&lt;p&gt;与此同时，所有的项目都会泄露知识。学会了一些东西的人会继续前进。重组又使团队分散，知识分散。关键的子系统是以这样一种方式外包的：交付的是代码而不是知识。在典型的设计方法中，代码和文档不能表达辛辛苦苦获得的知识，因此当口头传统因任何原因被打断时，这些知识就会丢失。&lt;/p&gt;\n&lt;p&gt;高效的团队有意识地增长他们的知识，实践“持续学习(continuous learning)”[Kerievsky 2001]。对于开发人员来说，这意味着提高技术知识，以及通用的领域建模技能（如本书中的技能）。但这样包括认真学习他们所从事的特定领域。这些自学成才的团队成员组成了一个稳定的核心团队，专注于涉及最关键领域的开发任务（参见第 15 章，“Distillation”）。&lt;/p&gt;\n&lt;p&gt;知识在核心团队的头脑中积累。&lt;/p&gt;\n&lt;p&gt;此时，停下来问自己一个问题。你学过 PCB 设计流程吗？尽管这只是对该主题的一个肤浅处理，但是在讨论领域模型时应该有一些学习。我学到了很多。我们学习如何成为一名 PCB 工程师。这不是我们的目标。我学会了与 PCB 专家交谈，理解与应用程序相关的主要该你那，并检查我们正在构建的内容。&lt;/p&gt;\n&lt;p&gt;事实上，我们发现探测模拟在开发中处于低优先级，最终被放弃了。与此同时，该模型的部分内容也随之小时，这些内容包括通过组件传递信号和计算跳数(counting hops)。应用程序的核心在别处，而模型的改变将这些方面置于中心位置。领域专家了解了更多信息，并明确了应用程序的目标。（第 15 章，“Distillation” 将深入讨论这些问题。）&lt;/p&gt;\n&lt;p&gt;尽管如此，早起的工作还是必不可少的。重要的模型元素被保留，但更重要的是，它启动了使所有后续工作有效的过程：由团队成员、开发成员和领域专家获得的知识，共享语言的开始，以及通过实现结束反馈循环。探索之旅总要从某个地方开始。&lt;/p&gt;\n&lt;h3 id=\&#34;knowledge-rich-design\&#34;&gt;Knowledge Rich Design&lt;/h3&gt;\n&lt;p&gt;在这样的模型中所不找到的知识超越了“找到名词(find the nouns)”。业务活动和规则与涉及的实体一样，都是领域的中心，任何领域都有各种类别的概念。知识处理产生了反应这种洞察力的模型。在模型更改的同时，开发人员重构实现以表达模型，并向应用程序提供该知识的使用。&lt;/p&gt;\n&lt;p&gt;随着这种超越实体和价值的移动，知识处理会变得更加激烈，因为业务规则之间可能存在实际的不一致。领域专家通常没有意识到他们的心理过程有多复杂，因为在他们工作的过程中，他们浏览所有这些规则，调和矛盾，用常识填补空白。软件做不到这一点。正式通过与软件专家密切合作的知识计算，规则才得以澄清、充实、协调或置于范围之外。&lt;/p&gt;\n&lt;h3 id=\&#34;example-extracting-a-hidden-concept\&#34;&gt;Example : Extracting a Hidden Concept&lt;/h3&gt;\n&lt;p&gt;让我们从一个非常简单的领域模型开始，该模型将用作预定货物到船舶航行的应用程序的基础。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;9\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1645087839643.jpg\&#34; alt=\&#34;Figure 1.8\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;我们可以指出，预定应用程序的职责是将每一个 &lt;strong&gt;Cargo&lt;/strong&gt; 与一个 &lt;strong&gt;Voyage&lt;/strong&gt; 关联起来，并记录和跟踪这种关系。到目前为止一切都好。在应用程序代码的某个地方可能有这样一个方法：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;public int makeBooking(Cargo cargo, Voyage voyage) { int confirmation = orderConfirmationSequence.next(); voyage.addCargo(cargo, confirmation);\nreturn confirmation;\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;航运业的标准做饭是接受比一艘船在一次航程中所能装载的更多的货物。这就是所谓的“超额预定(over-booking)”。有时使用一个简单的容量百分比，例如预定容量的 110%。在其他情况下，则适用复杂的规则，有利于主要客户或某些种类的货物。&lt;/p&gt;\n&lt;p&gt;这是航运领域的一个基本规则，航运业的任何业务人员都知道它，但可能不是软件团队中的所有技术人员都能理解它。&lt;/p&gt;\n&lt;p&gt;需求文档包含这一行: &lt;code&gt;Allow 10% overbooking.&lt;/code&gt;&lt;/p&gt;\n&lt;p&gt;类图和代码现在看起来像这样:&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;10\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1645088352838.png\&#34; alt=\&#34;Figure 1.9\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;public int makeBooking(Cargo cargo, Voyage voyage) {\n    double maxBooking = voyage.capacity() * 1.1;\n    if ((voyage.bookedCargoSize() + cargo.size()) &amp;gt; maxBooking) return –1; \n    int confirmation = orderConfirmationSequence.next(); voyage.addCargo(cargo, confirmation);\n    return confirmation;\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;现在，一个重要的业务规则作为一个保护子句隐藏在应用程序的方法中。稍后我们将看分层架构原则(LAYERED ARCHITECTURE)(第四章)，它将指导我们将朝顶规则重构为领域对象，但现在让我们集中于如何使这些知识更明确，并且对项目中的每个人都更容易访问。&lt;/p&gt;\n&#34;,&#34;fileName&#34;:&#34;domain-driven-design-tackling-complexity-in-the-heart-of-software&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;Domain-Driven Design Tackling Complexity in the Heart of Software&#34;,&#34;tags&#34;:[{&#34;index&#34;:-1,&#34;name&#34;:&#34;DDD&#34;,&#34;slug&#34;:&#34;nrVWFj23m&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://wenbozhangw.github.io/tag/nrVWFj23m/&#34;}],&#34;date&#34;:&#34;2022-01-27 09:36:57&#34;,&#34;dateFormat&#34;:&#34;2022-01-27&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://wenbozhangw.github.io/post/domain-driven-design-tackling-complexity-in-the-heart-of-software/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;43 min read&#34;,&#34;time&#34;:2569000,&#34;words&#34;:12534,&#34;minutes&#34;:43},&#34;description&#34;:&#34;Acknowledgements\n四年多来，我一直在写这本书，以这样或那样的形式，一路上有很多人帮助和支持我。\n我感谢许多阅读手稿和评论的人。如果没有这些反馈，这本书是不可能完成的。有几家对他们的评论给予了特别慷慨的关注。由Russ Ruf...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#acknowledgements\&#34;&gt;Acknowledgements&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#preface\&#34;&gt;Preface&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#contrasting-tree-projects\&#34;&gt;Contrasting Tree Projects&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#design-vs-development-process\&#34;&gt;Design vs. Development Process&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#the-structure-of-this-book\&#34;&gt;The Structure of This Book&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#who-this-book-is-written-for\&#34;&gt;Who This Book is Written For&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#part-i-putting-the-domain-model-to-work\&#34;&gt;Part I. Putting the Domain Model to Work&lt;/a&gt;&lt;br&gt;\n*\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#the-utility-of-a-model-in-domain-driven-design\&#34;&gt;The Utility of a Model in Domain-Driven Design&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#the-centrality-of-ddomain-functionality\&#34;&gt;The Centrality of Ddomain Functionality&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#1-crunching-knowledge\&#34;&gt;1. Crunching Knowledge&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#why-it-worked\&#34;&gt;Why It Worked&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#continuous-learning\&#34;&gt;Continuous Learning&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#knowledge-rich-design\&#34;&gt;Knowledge Rich Design&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#example-extracting-a-hidden-concept\&#34;&gt;Example : Extracting a Hidden Concept&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;p&gt;本文讨论了将模块化作为一种机制来提高系统的灵活性和可理解性，同时允许缩短系统的开发时间。&amp;quot;模块化(modularization)&amp;quot;的有效性取决于将系统划分为模块时使用的标准(criteria)。本文提出了系统设计问题，描述了常规分解和非常规分解(conventional and unconventional decomposition)。结果表明，非常规分解方法具有明显的优势。讨论了用于得到分解的标准。如果采用传统的假设，即一个模块由一个或多个子程序(subroutines)构成，那么在大多数情况下，非常规分解的效率会比较低。本文还简述了一种不具有这种效果的替代实现方法。&lt;/p&gt;\n&lt;p&gt;关键词：软件，模块，模块化，软件工程，KWIC指标，软件设计&lt;/p&gt;\n&lt;p&gt;CR类别:4.0&lt;/p&gt;\n&lt;!-- more --&gt;\n&lt;h2 id=\&#34;introduction\&#34;&gt;Introduction&lt;/h2&gt;\n&lt;p&gt;模块化编程哲学的清晰陈述可以在 1970 年 Gouthier 和 Pont 关于系统程序设计的教科书中找到，我们引用如下：&lt;sup&gt;[&lt;a href=\&#34;#reference-1\&#34;&gt;1&lt;/a&gt;]&lt;/sup&gt;&lt;/p&gt;\n&lt;p&gt;定义良好的项目工作分割可以确保系统模块化。每个任务构成一个独立的、不同的程序模块。在实现时，每个模块及其输入和输出都定义良好，在与其的接口中不会与其他系统模块混淆。在检验时，独立测试模块的完整性；在签出(checkout)开始之前，在同步几个任务的完成方面存在一些调度问题。最后，系统以模块化的方式进行维护；系统错误和缺陷可以追踪到特定的系统模块，从而限制了详细错误搜索的范围。&lt;/p&gt;\n&lt;p&gt;通常没有提到用户将系统划分为模块的标准。本文将讨论这个问题，并通过实例，提出一些可以用于将系统分解为模块的标准。&lt;/p&gt;\n&lt;h2 id=\&#34;a-brief-status-report\&#34;&gt;A Brief Status Report&lt;/h2&gt;\n&lt;p&gt;模块化编程领域的主要进步是编码技术和汇编程序的发展，它们 (1) 允许在不了解另一个模块代码的情况下编写一个模块，(2) 允许在不重新组装整个系统的情况下重新组装和替换模块。这个工具对于生成大块的代码非常有价值，但是最常被用作问题系统示例的系统是高度模块化的程序，并且利用了上面提到的技术。&lt;/p&gt;\n&lt;h2 id=\&#34;expected-benefits-of-modular-programming\&#34;&gt;Expected Benefits of Modular Programming&lt;/h2&gt;\n&lt;p&gt;模块化编程的预期好处是：(1) 管理——开发实践应该缩短，因为单独的小组将在每个模块上工作，几乎不需要交流；(2) 产品灵活性——应该有可能对一个模块进行重大更改，而不需要更改其他模块；(3) 可理解性——应该有可能一次只研究一个模块。因此，整个系统可以更好地设计，因为它可以更好地理解。&lt;/p&gt;\n&lt;h2 id=\&#34;what-is-modularization\&#34;&gt;What Is Modularization&lt;/h2&gt;\n&lt;p&gt;下面是几个称为 &lt;em&gt;模块化(modularizations)&lt;/em&gt; 的部分系统描述。在这种情况下，“模块(module)” 被认为是职责分配，而不是子程序。模块化包括在独立模块的工作开始之前必须做出的设计决策。每个备选方案都包含了不同的决策，但在所有情况下，目的都是描述所有“系统级(system level)”决策（即影响多个模块的决策）。&lt;/p&gt;\n&lt;h2 id=\&#34;example-system-1-a-kwic-index-production-system\&#34;&gt;Example System 1 : A KWIC Index Production System&lt;/h2&gt;\n&lt;p&gt;以下对 KWIC 索引的描述将满足本文的要求。KWIC 索引系统接收一个有序的行集合(set of lines)，每一行是一个有序的单词集合，而每个词是一个有序的字符集。任何行都可以通过重复删除第一个单词并将其附加到行尾来进行 &amp;quot;循环移位（circularly shifted）&amp;quot;。KWIC 索引系统按字母顺序输出所有行的所有循环移位列表。&lt;/p&gt;\n&lt;p&gt;这是一个小系统。除了在极端情况下（庞大的数据库，没有配套软件），这样一个系统可以由一个好的程序员在一两周内制作出来。因此，激发模块化编程的困难对于这个系统来说都不重要。因为彻底地对待一个大系统是不切实际的，所以我们必须把这个问题当做一个大项目来处理。我们给出了一种典型的模块化方法，以及另一种已成功应用于本科课程项目的模块化方法。&lt;/p&gt;\n&lt;h3 id=\&#34;modularization-i\&#34;&gt;Modularization I&lt;/h3&gt;\n&lt;p&gt;我们看到以下模块：&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Module 1: Input&lt;/strong&gt;。该模块从输入介质中读取数据行，并将其存储在内核中，以供其他模块处理。字符被打包成一个单词，使用一个其他未使用的字符来表示单词的结尾。保留索引以显示每行的起始地址。&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Module 2: Cricular Shift&lt;/strong&gt;。这个模块在输入模块完成它的工作后被调用。它准备了一个索引，该索引给出了每个循环移位的第一个字符的地址，以及模块 1 组成的数组中该行的原始索引。它将输出保留在内核中，并使用成对的单词（原始行号、起始地址）。&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Module 3: Alphabetizing&lt;/strong&gt;。该模块将模块 1 和模块 2 产生的数组作为输入。它生成的数组格式与模块 2 生成的数组格式相同。然而，在本例中，循环移位是按另一个顺序（字母顺序）列出的。&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Module 4: Output&lt;/strong&gt;。使用模块 3 和模块 1 生成的数组，该模块生成了一个格式良好的输出，列出了所有的循环移位。在一个复杂系统中，每一行的实际开始将被标记，指向进一步信息的指针可能被插入，循环移位的开始实际上可能不是行中的第一个单词，等等。&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Module 5: Master Control&lt;/strong&gt;。这个模块除了控制其他四个模块之间的顺序外，没有什么别的功能。它还可以处理错误信息、空间分配等。&lt;/p&gt;\n&lt;p&gt;应该清楚的是，上述内容并不构成一份确定的文档。在工作开始之前，还需要提供更多的信息。定义文档将包含许多显示核心格式、指针约定、调用约定等的图片。在工作开始之前，必须指定四个模块之间的所有接口。&lt;/p&gt;\n&lt;p&gt;从模块化编程的支持者的意义上来说，这是一种模块化。该系统被划分为若干具有定义良好接口的模块；每一个都足够小，足够简单，足以被彻底理解和良好的编程。小规模的实现证明，这大约是大多数程序员为指定的任务提出的分解。&lt;/p&gt;\n&lt;h3 id=\&#34;modularization-ii\&#34;&gt;Modularization II&lt;/h3&gt;\n&lt;p&gt;我们看到以下模块：&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Module 1: Line Storage&lt;/strong&gt;。这个模块由许多函数或子程序(subroutines)组成，这些函数或子程序提供了模块化用户可以调用它的方法。函数调用 &lt;code&gt;CHAR(r, w, c)&lt;/code&gt; 的值将是一个整数，表示第 r 行中的第 c 个字符，第 w 个单词。一个调用例如 &lt;code&gt;SETCHAR(r, w, c, d)&lt;/code&gt; 将返回第 r 行 的第 w 个单词的第 c 个字符是由字符 d 表示（即&lt;code&gt;CHAR(r, w, c) = d&lt;/code&gt;）。&lt;code&gt;WORDS(r)&lt;/code&gt; 返回第 r 行单词的个数。调用这些例程(routines)的方式有一定的限制；如果违反了这些限制，例程就&amp;quot;陷入&amp;quot;由例程用户提供的错误处理子例程。附加的例程可以向调用者显示任何一行中的单词数、当前存储的行数以及任何一个单词中的字符数。提供函数 &lt;code&gt;DELINE&lt;/code&gt; 和 &lt;code&gt;DELWRD&lt;/code&gt; 来删除已经存储的部分行。类似的模块的精确说明已经在 [&lt;a href=\&#34;#reference-3\&#34;&gt;3&lt;/a&gt;] 和 [&lt;a href=\&#34;#reference-8\&#34;&gt;8&lt;/a&gt;] 中给出，我们在此不再重复。&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Module 2: INPUT&lt;/strong&gt;。该模块从输入媒体中读取原始行，并调用行存储模块将它们存储在内部。&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Module 3: Cricular Shifter&lt;/strong&gt;。该模块提供的主要函数与模块 I 通的函数类似。该模块给人的印象是，我们创建了一个 line holder，该 holder 包含的不是所有的 line，而是所有 line 的循环移位。因此，函数调用 &lt;code&gt;CSCHAR(l, w, c)&lt;/code&gt; 提供了表示第 l 个循环移位的 w 个单词的第 c 个字符的值。(1) 如果 &lt;code&gt;i &amp;lt; j&lt;/code&gt;，则第 i 行移位在第 j 行移位之前；(2) 对于每一行，第一次移位的是原行(original line)，第二次移位通过一个单词旋转到第一次移位得到，以此类推。提供了一个函数 &lt;code&gt;CSSETUP&lt;/code&gt;，必须在其他函数有指定值之前调用它。有关此类模块的更精确规范，请参见 [&lt;a href=\&#34;#reference-8\&#34;&gt;8&lt;/a&gt;]。&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Module 4: Alphabetizer&lt;/strong&gt;。该模块主要由两个功能组成。其中一个，&lt;code&gt;ALPH&lt;/code&gt;，必须在另一个具有定义值之前被调用。第二个，&lt;code&gt;ITH&lt;/code&gt;，将作为一个索引。&lt;code&gt;ITH(i)&lt;/code&gt; 将给出以字符顺序排列的循环移位的索引。[&lt;a href=\&#34;#reference-8\&#34;&gt;8&lt;/a&gt;] 给出了这些函数的正式定义。&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Module 5: Ouput&lt;/strong&gt;。这个模块将打印所需的行的集合或循环移位。&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Module 6: Master Control&lt;/strong&gt;。功能类似于上面的模块化。&lt;/p&gt;\n&lt;h2 id=\&#34;comparison-of-the-two-modularizations\&#34;&gt;Comparison of the Two Modularizations&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;General&lt;/strong&gt;。这两种方案都将奏效。前者相当传统；第二个已经成功地在一个 class project [&lt;a href=\&#34;#reference-7\&#34;&gt;7&lt;/a&gt;] 中使用。两者都将编程减少到相对独立的一些小的、可管理的程序的编程。&lt;/p&gt;\n&lt;p&gt;首先请注意，这两个分解可能共享所有的数据表示和访问方法。我们的讨论是关于两种不同的方法来分割可能是同一个对象。根据分解 1 构建的系统在组装后可以与根据分解 2 构建的系统完全相同。这两种选择的区别在于它们划分工作任务的方式和模块之间的接口。两种情况下使用的算法可能是相同的。即使在可运行表示中(runnable representation)相同，这些系统也有本质上的不同。这是可能的，因为可运行表示只需要用于运行；其他表示用于更改、记录、理解等。这两种系统在其他表现形式中并不相同。&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Changeability&lt;/strong&gt;。有许多设计决策是有问题的，并且可能在许多情况下发生改变。这是一个不完整的列表。&lt;/p&gt;\n&lt;ol&gt;\n&lt;li&gt;输入格式。&lt;/li&gt;\n&lt;li&gt;决策将所有行存储在核心中。对于大型工作，在任何时候将所有的行都放在核心上可能是不方便或不切实际的。&lt;/li&gt;\n&lt;li&gt;决策将四个字符压缩成一个单词。在我们处理少量数据的情况下，打包字符可能是不可取的；单词的每个字符的布局都可以节省时间。在其他情况下，我们可以打包，但格式会不同。&lt;/li&gt;\n&lt;li&gt;决策为循环移位创建索引，而不是实际存储它们。同样，对于小型索引或大型核心，将它们写出来可能是更可取的方法。或者，我们可以选择在 CSSETUP 期间不准备任何东西。所有计算都可以在调用其他函数（如 CSCHAR）期间完成。&lt;/li&gt;\n&lt;li&gt;决策按名字福顺序排列列表一次，而不是(a)在需要的时候搜索每个项目，或(b)部分按字母顺序排列，就像在 Hoare 的 FIND [&lt;a href=\&#34;#reference-2\&#34;&gt;2&lt;/a&gt;] 中做的那样。在许多情况下，将字母排序所涉及的计算分配到生成索引所需的时间是有利的。&lt;/li&gt;\n&lt;/ol&gt;\n&lt;p&gt;通过观察这些变化，我们可以看到这两种模块之间的差异。第一个变化局限于两个分解中的一个模块。对于第一次分解，第二次更改将导致每个模块的更改！第三个变化也是如此。在第一次分解中，所有程序都必须使用核心中的行存储格式。在第二种分解中，情况完全不同。除了模块 1 之外，所有人都不知道这些行存储的确切方式。任何存储方式的改变都只能局限于该模块！&lt;/p&gt;\n&lt;p&gt;在这个系统的某些版本中，分解中有一个额外的模块。在杭存储模块中使用了符号表(symbol table)模块（如 [&lt;a href=\&#34;#reference-3\&#34;&gt;3&lt;/a&gt;] 中指定的）。这个事实对系统的其他部分是完全看不见的。&lt;/p&gt;\n&lt;p&gt;第四个变化局限于第二个分解中的循环移位模块，但是在第一个分解中，字母排序器和输出例程也知道这个变化。&lt;/p&gt;\n&lt;p&gt;在第一次分解中，第五次变化也将被证明是最困难的。输出模块期望索引在开始之前已经完成。第二次分解中的字母排序模块被设计成这样，用户无法检测到何时实际完成了字母排序。不需要更改其他模块。&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Independent development&lt;/strong&gt;。在第一个模块化中，模块之间的接口是上面描述的相当复杂的格式和表组织(table organizations)。这些代表了不能掉以轻心的设计决策。表的结构和组织对各个模块的效率至关重要，必须仔细设计。这些格式的开发将是模块化开发的主要部分，这一部分必须由几个开发小组共同努力。在第二种模块化中，接口更加抽象；它们主要由函数名、形参的数量和类型组成。这些都是相对简单的决策，模块的独立开发应该更早开始。&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Comprehensibility&lt;/strong&gt;。为了理解第一个模块化中的输出模块，需要理解字符排序器(alphabetizer)、循环移位器(circular shifter)和输入模块(input module)的一些内容。输出所使用的表的某些方面只会因为其他模块的工作方式而更有意义。由于其他模块中使用的算法，表的结构将受到限制。这个系统只有在整体上才能被理解。我的主观判断是，在第二次模块化中不是这样的。&lt;/p&gt;\n&lt;h2 id=\&#34;the-criteria\&#34;&gt;The Criteria&lt;/h2&gt;\n&lt;p&gt;许多读者现在将看到在每个分解中使用了哪些标准。在第一个分解中，使用的准则是使处理中的每个主要步骤成为一个模块。有人可能会说，为了得到第一个分解，我们需要做一个流程图。这是分解或模块化最常见的方法。它是所有程序员培训的结果，它告诉我们，我们应该从一个粗略的流程开始，然后从那里走向一个详细的实现。流程图对于有 5000 - 10000 条指令的系统来说是一种有用的抽象，但当我们超越它时，它似乎是不够的需要一些额外的东西。&lt;/p&gt;\n&lt;p&gt;使用 &amp;quot;信息隐藏(information hiding)&amp;quot;[&lt;a href=\&#34;#reference-4\&#34;&gt;4&lt;/a&gt;] 作为标准进行第二次分解。模块不再对应于处理中的步骤。例如，行存储模块在系统的几乎所有操作都使用。根据所使用的方法，字母排列可以，也可以不对应于处理中的一个节点。类似的，在某些情况下，循环移位可能根本不生成任何表，而是根据要求计算每个字符。第二次分解中的每个模块都具有其设计决策知识的特征，这些知识对所有其他模块都是隐藏的。他的接口或定义被选择来尽可能少地揭示它内部工作。&lt;/p&gt;\n&lt;h2 id=\&#34;improvement-in-circular-shift-module\&#34;&gt;Improvement in Circular Shift Module&lt;/h2&gt;\n&lt;p&gt;为了说明这样一个准则的影响，让我们从第二次分解来仔细看看循环移位模块的设计。现在，事后看来，这个定义揭示了的信息比必要的还要多久。虽然，我们小心地隐藏了存储或计算循环移位列表的方法，但我们指定了该列表的顺序。程序可以有效地编写，如果我们只指定(1) 行表示(lines indicated)在循环移位的当前定义将全部在表中存在，(2) 其中一个将包括两次，和(3) 一个额外的功能存在这将使我们能够确定原始的行的改变。通过规定转换的顺序，我们提供了比必要的更多的信息，因此不必要地限制了我们可以在不改变定义的情况下构建系统类别。例如，我们不允许在这一的系统中按字母顺序产生循环移位，ALPH 为空，而 ITH 只是将其参数作为值返回。我们在第二次分解构造系统时未能做到这点，必须清楚地将其归类为设计错误。&lt;/p&gt;\n&lt;p&gt;除了每个模块对系统的其他部分隐藏一些设计决策的一般标准之外，我们还可以提到一些具体的分解示例，它们似乎是明智的。&lt;/p&gt;\n&lt;ol&gt;\n&lt;li&gt;一个&lt;em&gt;数据结构(data structure)&lt;/em&gt;，它的内部链接，&lt;em&gt;访问过程(accessing procedures)&lt;/em&gt; 和 &lt;em&gt;修改过程(modifying procedures)&lt;/em&gt; 都是单个模块的一部分。它们不像传统的那样被许多模块共享。这个概念可能只是 Balzer [&lt;a href=\&#34;#reference-9\&#34;&gt;9&lt;/a&gt;] 和 Mealy [&lt;a href=\&#34;#reference-10\&#34;&gt;10&lt;/a&gt;] 论文背后假设的详细阐述、考虑到这一点的设计显然是 BLISS [&lt;a href=\&#34;#reference-11\&#34;&gt;11&lt;/a&gt;] 的设计背后。&lt;/li&gt;\n&lt;li&gt;&lt;em&gt;调用给定例程所需的指令序列和例程本身是同一个模块的一部分(The sequence of instructions necessary to call a given routine and the routine itself are part of the same module)&lt;/em&gt;。这条规则在用于实验的 Fortran 系统中是不相关的，但是对于用汇编语言构建的系统来说确实必不可少的。真正的机器不存在完美的通用调用序列(general calling sequences)，因此，随着我们继续寻找理想序列，它们往往会发生变化。通过将生成调用的责任分配给负责例程的人，我们是这种改进变得容易，也使在相同的软件结构中有几个不同的序列更加可行。&lt;/li&gt;\n&lt;li&gt;&lt;em&gt;操作系统和类似程序中队列中使用的控制快的格式必须隐藏在&amp;quot;控制模块&amp;quot;中(The formats of control blocks used in queues in operating systems and similar programs must be hidden within a &amp;quot;control block module&amp;quot;)&lt;/em&gt;。 传统的做法是对各个模块之间的接口进行格式化。因为设计的发展迫使控制模块格式频繁的改变，这样的决定通常被证明是非常昂贵的。&lt;/li&gt;\n&lt;li&gt;&lt;em&gt;字符代码、字母顺序和类似的数据应该隐藏在一个模块中，以获得最大的灵活性(Character codes, alphabetic orderings, and similar data should be hidden in a module for greatest flexibility)&lt;/em&gt;。&lt;/li&gt;\n&lt;li&gt;处理某些项的顺序应该（尽可能）隐藏在单个模块中。从设备的添加到操作系统中某些资源的不可用等各种变化是的排序非常不稳定。&lt;/li&gt;\n&lt;/ol&gt;\n&lt;h2 id=\&#34;efficiency-and-implementation\&#34;&gt;Efficiency and Implementation&lt;/h2&gt;\n&lt;p&gt;如果我们不小心的话，第二种分解会比第一种分解效率低得多。如果每个函数实际上是作为一个具有复杂调用序列的过程来实现的，那么由于模块之间的重复切换，将会有大量这样的调用。第一个分解不会遇到这个问题，因为模块之间的控制转移相较少。&lt;/p&gt;\n&lt;p&gt;为了节省过程调用开销，同时获得我们在上面看到的优势，我们必须以一种不同寻常的方式实现这些模块。在许多情况下，程序最好由汇编程序(assembler)插入到代码中；在其他情况下，将插入高度专业化和高效的转移。为了成功和有效地利用第二种类型的分解，需要一种工具，这种工具可以将程序编写为子例程，但是通过任何合适的任何适当的实现来组装。如果使用这种技术，模块之间的分离在最终代码中可能不清楚。因此，额外的程序修改功能也是有用的。换句话说，程序的几种表示（前面提到过）必须在机器中与执行它们之间映射的程序一起维护。&lt;/p&gt;\n&lt;h2 id=\&#34;a-decomposition-common-to-a-compiler-and-interpretor-for-the-same-language\&#34;&gt;A Decomposition Common to a Compiler and Interpretor for the Same Language&lt;/h2&gt;\n&lt;p&gt;在早期尝试将这些分解规则应用于设计项目时，我们为用 [&lt;a href=\&#34;#reference-6\&#34;&gt;6&lt;/a&gt;] 中扫描的符号表示的 Markov 算法构建了一个转换器。尽管我们无意研究一种语言的编译和解释性翻译程序之间的关系，但我们发现，我们的分解对于这种语言的纯编译器和多种解释器都是有效的。尽管在每种编译器类型的最终运行表示中存在深刻和实质性的差异，但我们发现，早起分解中隐含的决定适用于所有类型。&lt;/p&gt;\n&lt;p&gt;如果我们按照编译器(compiler)或解释器(interpretor)的经典路线划分职责（例如，语法识别器(syntax recognizer)、代码生成器(code generator)、编译器的运行时例程(run time routines for a compiler)），这就不会是真的。相反，分解是基于各种决策的隐藏，如上面的示例所示。因此，寄存器表示(register representation)、搜索算法(search algorithm)、规则解释(rule interpretation)等都是模块，这些问题都存在于编译和解释转换器(compiling and interpretive translators)中。不仅分解在所有情况下都是有效的，而且许多例程只需要在任何类型的翻译器进行微小的更改就可以使用。&lt;/p&gt;\n&lt;p&gt;此示例为该语言提供了额外的支持，即在进行模块分解时，不应该使用预期发生处理的时间顺序。他进一步证明了，仔细的分解工作可以导致大量的工作从一个项目转移到另一个项目。&lt;/p&gt;\n&lt;p&gt;对这个示例的更详细的讨论包含在 [&lt;a href=\&#34;#reference-8\&#34;&gt;8&lt;/a&gt;] 中。&lt;/p&gt;\n&lt;h2 id=\&#34;hierarchical-structure\&#34;&gt;Hierarchical Structure&lt;/h2&gt;\n&lt;p&gt;我们可以在根据分解 2 定义的系统中找到 Dijkstra [&lt;a href=\&#34;#reference-5\&#34;&gt;5&lt;/a&gt;] 所示的意义上的程序层次结构。如果一个符号表存在，他在没有任何其他模块的情况下运行，因此它是在 1 级。如果没有使用符号表，则行存储是在第 1 级，否则行存储在第二层。输入和循环移位器的功能需要行存储。输出和字母排序器将需要循环移位器，但是由于循环移位器和行持有器(line holder)在某种意义上是兼容的，所以很容易构建这些例程的参数化版本，这些例程可以用于按字母顺序排列或打印出原始行或循环移位。在第一次使用中，他们不需要循环移位器；第二次他们会使用。换句话说，我们的设计允许我们有一个单一的程序表示，它可以在两个层次中的任何一个层次上运行。&lt;/p&gt;\n&lt;p&gt;在讨论系统结构时，很容易混淆良好的分解和层次结构的好处。如果模块或程序之间可以定义某种关系，并且这种关系是部分排序的，那我们就有了层次结构。我们关心的关系是 &amp;quot;使用&amp;quot; 或 &amp;quot;依赖&amp;quot;。最好使用程序直接的关系，因为在很多情况下，一个模块只依赖于另一个模块的一部分（例如，虚幻移位器只依赖于 line holder 的输出部分，而不依赖与 SETWORD 的正确工作）。可以想象，如果没有这种部分排序，我们可以获得我们已经讨论过的好处，例如，如果所有模块都在同一水平上。部分排序给我们带来了两个额外的好处。首先，系统的某些部分受益（简化），因为它们使用 lower level 服务。其次，我们能够切断上层，仍然有一个可用的和有用的产品。例如，符号表可用于其他应用程序；line holder 可以作为问答系统的基础。层次结构的存在保证了我们可以 “修剪(prune)” 树的上层，并在旧的树干上开始一颗新树。如果我们设计的系统中 &amp;quot;low level&amp;quot; 模块使用了 &amp;quot;high level&amp;quot; 模块，我们就不会有层次结构，我们会发现很难删除系统的某些部分，&amp;quot;level&amp;quot; 在系统中也没有多少意义。（这里的 &amp;quot;lower&amp;quot; 以为 &amp;quot;lower numbered&amp;quot;）。&lt;/p&gt;\n&lt;p&gt;我们可以想象拥有一个版本 1 中所显示的分解类型的系统（接口中的重要设计决策），但是保留层次结构，因此我们必须得出这样的结论：层次结构和 &amp;quot;干净的&amp;quot; 分解是系统结构的两个可取但独立的属性。&lt;/p&gt;\n&lt;h2 id=\&#34;conclusion\&#34;&gt;Conclusion&lt;/h2&gt;\n&lt;p&gt;我们已经试图通过这些示例说明，在流程图的基础上开始将系统分解为模块几乎总是不正确的。我们建议从一组困难的设计决策或可能发生变化的决策开始。然后，每个模块都被设计为对其他模块隐藏这样的决定。因为，在大多数情况下，设计决策超越了执行时间，模块将不对应与处理中的步骤。为了更加高效的实现，我们必须放弃模块是一个或多个子例程的假设，而是允许子例程和程序被来自不同模块的代码集合组装起来。&lt;/p&gt;\n&lt;h2 id=\&#34;references\&#34;&gt;References&lt;/h2&gt;\n&lt;ol&gt;\n&lt;li&gt;&lt;span id=\&#34;reference-1\&#34;&gt;&lt;/span&gt; Gauthier, Richard, and Pont, Stephen. &lt;em&gt;Designing Systems Programs&lt;/em&gt;, (C), Prentice-Hall, Englewood Cliffs, N.J., 1970.&lt;/li&gt;\n&lt;li&gt;&lt;span id=\&#34;reference-2\&#34;&gt;&lt;/span&gt; Hoare, C. A. R. Proof of a program, FIND. Comm. ACM 14, 1 (Jan. 1971), 39-45.&lt;/li&gt;\n&lt;li&gt;&lt;span id=\&#34;reference-3\&#34;&gt;&lt;/span&gt; Parnas, D. L. A technique for software module specification with examples. Comm. ACM 15, 5 (May, 1972), 330-336.&lt;/li&gt;\n&lt;li&gt;&lt;span id=\&#34;reference-4\&#34;&gt;Parnas, D. L. Information distribution aspects of design methodology. Tech. Rept., Depart. Computer Science, CarnegieMellon U., Pittsburgh, Pa., 1971. Also presented at the IFIP Congress 1971, Ljubljana, Yugoslavia.&lt;/li&gt;\n&lt;li&gt;&lt;span id=\&#34;reference-5\&#34;&gt;Dijkstra, E. W. The structure of &amp;quot;THE&amp;quot;-multiprogramming system. Comm. ACM 11, 5 (May 1968), 341-346.&lt;/li&gt;\n&lt;li&gt;&lt;span id=\&#34;reference-6\&#34;&gt;Galler, B., and Perlis, A. J. &lt;em&gt;A View of Programming Languages&lt;/em&gt;, Addison-Wesley, Reading, Mass., 1970.&lt;/li&gt;\n&lt;li&gt;&lt;span id=\&#34;reference-7\&#34;&gt;Parnas, D. L. A course on software engineering. Proc. SIGCSE Technical Symposium, Mar. 1972.&lt;/li&gt;\n&lt;li&gt;&lt;span id=\&#34;reference-8\&#34;&gt;Parnas, D. L. On the criteria to be used in decomposing systems into modules. Tech. Rept., Depart. Computer Science, Carnegie-Mellon U., Pittsburgh, Pa., 1971.&lt;/li&gt;\n&lt;li&gt;&lt;span id=\&#34;reference-9\&#34;&gt;Balzer, R. M. Dataless programming. Proc. AFIPS 1967 FJCC, Vol. 31, AFIPS Press, Montvale, N.J., pp. 535-544.&lt;/li&gt;\n&lt;li&gt;&lt;span id=\&#34;reference-10\&#34;&gt;Mealy, G. H. Another look at data. Proc. AFIPS 1967 FJCC, Vol. 31, AFIPS Press, Montvale, N.J., pp. 525-534.&lt;/li&gt;\n&lt;li&gt;&lt;span id=\&#34;reference-11\&#34;&gt;Wulf, W. A., Russell, D. B., and Habermann, A. N. BLISS, A language for systems programming. Comm. ACM 14, 12 (Dec. 1971), 780-790.&lt;/li&gt;\n&lt;/ol&gt;\n&lt;h2 id=\&#34;source\&#34;&gt;Source&lt;/h2&gt;\n&lt;p&gt;&lt;a href=\&#34;https://dl.acm.org/doi/10.1145/361598.361623\&#34;&gt;https://dl.acm.org/doi/10.1145/361598.361623&lt;/a&gt;&lt;/p&gt;\n&#34;,&#34;fileName&#34;:&#34;on-the-criteria-to-be-used-in-decomposing-systems-into-modules&#34;,&#34;abstract&#34;:&#34;&lt;p&gt;本文讨论了将模块化作为一种机制来提高系统的灵活性和可理解性，同时允许缩短系统的开发时间。&amp;quot;模块化(modularization)&amp;quot;的有效性取决于将系统划分为模块时使用的标准(criteria)。本文提出了系统设计问题，描述了常规分解和非常规分解(conventional and unconventional decomposition)。结果表明，非常规分解方法具有明显的优势。讨论了用于得到分解的标准。如果采用传统的假设，即一个模块由一个或多个子程序(subroutines)构成，那么在大多数情况下，非常规分解的效率会比较低。本文还简述了一种不具有这种效果的替代实现方法。&lt;/p&gt;\n&lt;p&gt;关键词：软件，模块，模块化，软件工程，KWIC指标，软件设计&lt;/p&gt;\n&lt;p&gt;CR类别:4.0&lt;/p&gt;\n&#34;,&#34;title&#34;:&#34;On the Criteria To Be Used in Decomposing Systems into Modules&#34;,&#34;tags&#34;:[{&#34;index&#34;:-1,&#34;name&#34;:&#34;programming concept&#34;,&#34;slug&#34;:&#34;60uU_0nib&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://wenbozhangw.github.io/tag/60uU_0nib/&#34;}],&#34;date&#34;:&#34;2022-01-25 14:51:03&#34;,&#34;dateFormat&#34;:&#34;2022-01-25&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://wenbozhangw.github.io/post/on-the-criteria-to-be-used-in-decomposing-systems-into-modules/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;25 min read&#34;,&#34;time&#34;:1456000,&#34;words&#34;:6744,&#34;minutes&#34;:25},&#34;description&#34;:&#34;本文讨论了将模块化作为一种机制来提高系统的灵活性和可理解性，同时允许缩短系统的开发时间。&amp;quot;模块化(modularization)&amp;quot;的有效性取决于将系统划分为模块时使用的标准(criteria)。本文提出了系统设计问题，描...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#introduction\&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#a-brief-status-report\&#34;&gt;A Brief Status Report&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#expected-benefits-of-modular-programming\&#34;&gt;Expected Benefits of Modular Programming&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#what-is-modularization\&#34;&gt;What Is Modularization&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#example-system-1-a-kwic-index-production-system\&#34;&gt;Example System 1 : A KWIC Index Production System&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#modularization-i\&#34;&gt;Modularization I&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#modularization-ii\&#34;&gt;Modularization II&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#comparison-of-the-two-modularizations\&#34;&gt;Comparison of the Two Modularizations&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#the-criteria\&#34;&gt;The Criteria&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#improvement-in-circular-shift-module\&#34;&gt;Improvement in Circular Shift Module&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#efficiency-and-implementation\&#34;&gt;Efficiency and Implementation&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#a-decomposition-common-to-a-compiler-and-interpretor-for-the-same-language\&#34;&gt;A Decomposition Common to a Compiler and Interpretor for the Same Language&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#hierarchical-structure\&#34;&gt;Hierarchical Structure&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#conclusion\&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#references\&#34;&gt;References&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#source\&#34;&gt;Source&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;p&gt;&lt;strong&gt;抽象数据类型&lt;/strong&gt;(&lt;strong&gt;A&lt;/strong&gt;bstract &lt;strong&gt;D&lt;/strong&gt;ata &lt;strong&gt;T&lt;/strong&gt;ype, &lt;strong&gt;ADT&lt;/strong&gt;) 是计算机科学中具有类似行为的特定类别的数据结构和数学模型；或者具有类似语义的一种或多种程序设计语言的数据类型。抽象数据类型是间接定义的，通过其上的可执行的操作以及这些操作的效果的数学约束（与可能的代价）。&lt;/p&gt;\n&lt;p&gt;例如，抽象的堆栈(stack)由 3 个操作定义：推入 push，弹出 pop（接受约束：每次弹出返回的最新被推入且没有被弹出的数据，也就是后进先出），查看堆栈顶端数据 peek。当分析使用堆栈算法的效率，所有这 3 个操作用时相同，无论堆栈中包含多少项数据；并且堆每项数据栈使用了常量大小的存储。&lt;/p&gt;\n&lt;p&gt;抽象数据类型（ADT）是纯粹理论实体，用于简化描述抽象算法，分类与评价数据结构，形式描述程序设计语言的类似系统。一个 ADT 可以用特定数据类型或数据结构实现，在许多程序设计语言中有许多种实现方式；或者用形式规范语言描述。ADT 常实现为模块(module)：模块的接口声明了对应于 ADT 操作的例程(procedure)，有时用注释描述了约束。&lt;/p&gt;\n&lt;!-- more --&gt;\n&lt;h2 id=\&#34;示例\&#34;&gt;示例&lt;/h2&gt;\n&lt;p&gt;在编程语言（或库）和教科书中，常见的几个抽象数据类型如下：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;\&#34;&gt;关联数组&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;复数&lt;/li&gt;\n&lt;li&gt;容器&lt;/li&gt;\n&lt;li&gt;双端队列&lt;/li&gt;\n&lt;li&gt;列表&lt;/li&gt;\n&lt;li&gt;Multimap&lt;/li&gt;\n&lt;li&gt;优先队列&lt;/li&gt;\n&lt;li&gt;队列&lt;/li&gt;\n&lt;li&gt;集合&lt;/li&gt;\n&lt;li&gt;堆栈&lt;/li&gt;\n&lt;li&gt;字符串&lt;/li&gt;\n&lt;li&gt;树&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 id=\&#34;接口和实现的分离\&#34;&gt;接口和实现的分离&lt;/h2&gt;\n&lt;p&gt;实现于程序时，抽象数据类型只显现出其接口，并将实现加以隐藏。用户只需关心它的接口，而不是如何实现。未来更可以改变实现的方式。（其支持信息隐藏原理，或保护程序免受变化的冲击。）&lt;/p&gt;\n&lt;p&gt;抽象数据类型的强处在于对用户隐藏了实现细节，仅公开其接口。这表示抽象数据类型可以用各种方法来实现，只要遵循其接口，就不会影响到用户。&lt;/p&gt;\n&lt;p&gt;在抽象数据类型和数据结构之间，有一个实现上的微妙差别。例如，列表的抽象数据类型可以数组为基础、或者使用链表来实现。列表即是一种具良好运算（加入元素、移除元素等等）定义的抽象数据类型。链表是以指针为基础的数据结构，且可用来创建一个列表。链表常用于列表的抽象数据类型。&lt;/p&gt;\n&lt;p&gt;同样地，二叉树搜索法的抽象数据结构可以几个方式实现：二叉树、AVL树、红黑树、数组等等。且无须关心其实现，二叉树搜索法总是有相同的运算（插入、移除、查找等等）。&lt;/p&gt;\n&lt;p&gt;从实现中分离出接口，并不表示用户不该知道实现的方法，而是用户不能依赖于实现细节。例如，一个抽象数据类型可以用脚本语言创建，或其它可以被反编译的语言（如 C语言）。即使用户可发现实现的方法，只要所有客户端程序遵循该接口，且改变实现方式时不会产生影响，那就仍是抽象数据类型。&lt;/p&gt;\n&lt;p&gt;在面向对象的用语中，抽象数据类型相当于类别；抽象数据类型的实体就相当于对象。某些语言包含了用于宣告抽象数据类型的构造函数。例如，C++ 和 Java 为此提供了类的构造函数。&lt;/p&gt;\n&lt;h2 id=\&#34;抽象数据结构\&#34;&gt;抽象数据结构&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;抽象数据结构&lt;/strong&gt;即根据所要运算的数据以及其计算复杂性所定义的抽象存储区，而不关心具体的数据结构的实现。&lt;/p&gt;\n&lt;p&gt;就实现高效率的算法而言，对数据结构的选择相当重要。抽象数据结构的选择，决定了高效率的算法的设计，和估计其计算复杂性。&lt;/p&gt;\n&lt;p&gt;这个概念与编程语言理论中所使用的抽象数据类型非常接近，大致上抽象数据结构和抽象数据类型的名称，和具体的数据结构的名称一致。&lt;/p&gt;\n&lt;h2 id=\&#34;内置抽象数据类型\&#34;&gt;内置抽象数据类型&lt;/h2&gt;\n&lt;p&gt;一部分抽象数据类型在程序设计中相当普遍且实用，所以在某些编程语言中，成为原生类型、或加进标准库中。例如，Perl 的数组可以用列表或双端队列之类的抽象数据类型来实现，散列表也可以用 Map 或 Table 来做。C++ 标准库和 Java 库也提供了列表、堆栈、队列、Map、优先权队列和字符串。&lt;/p&gt;\n&lt;h2 id=\&#34;实际示例\&#34;&gt;实际示例&lt;/h2&gt;\n&lt;h3 id=\&#34;作为抽象数据类型的有理数\&#34;&gt;作为抽象数据类型的有理数&lt;/h3&gt;\n&lt;p&gt;有理数（可以 a/b 格式表示的数，且 a 和 b 都是整数）本来是不能在电脑中表示出来。不过可以合理的抽象数据类型来定义，如下。&lt;/p&gt;\n&lt;p&gt;构造：使用两个整数 a 与 b 创建实体，其中 a 为分子，b 为分母。&lt;/p&gt;\n&lt;p&gt;运算：加法、减法、乘法、除法、乘幕、比较、约分，转成实数（浮点数）。&lt;/p&gt;\n&lt;p&gt;要完成整个规格，就要根据数据来定义所有的运算。例如，当两个有理数 a/b 和 c/d 相乘时，相乘的结果就要定义为 ( a c ) / ( b d )。还有输入、输出、先决条件、后置条件，以及对抽象数据类型的各种假定。&lt;/p&gt;\n&lt;h3 id=\&#34;堆栈\&#34;&gt;堆栈&lt;/h3&gt;\n&lt;h4 id=\&#34;接口\&#34;&gt;接口&lt;/h4&gt;\n&lt;p&gt;堆栈的抽象数据类型接口，以 C 语法编写：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-c\&#34;&gt;long stack_create(); /* 建立新的堆栈实体 */\nvoid stack_push(long stack, void *item); /* 将一个项目推入堆栈 */\nvoid *stack_pop(long stack); /* 从堆栈顶部取得项目 */\nvoid stack_delete(long stack); /* 刪除堆栈 */\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h4 id=\&#34;用法\&#34;&gt;用法&lt;/h4&gt;\n&lt;p&gt;抽象数据类型可以如下方式使用：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-c\&#34;&gt;long stack;\nstruct foo *f;\n\nstack = stack_create(); /* 建立堆栈 */\n\nstack_push(stack, f); /* 将 foo 结构推入堆栈 */\n\nf = stack_pop(stack); /* 从堆栈取得顶部的结构 */\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h4 id=\&#34;各种实现\&#34;&gt;各种实现&lt;/h4&gt;\n&lt;p&gt;上述堆栈的抽象数据类型，一开始可以使用数组来实现，然后改用链表，而不会伤到任何用户的代码。有多少方法可以实现抽象数据类型，取决于编程语言。例如，上述示例可使用 C 编写一个结构，以及随同的一组数据结构，可使用数组或链表来存放记录；当构造函数函数返回一个抽象句柄时，就对用户隐藏了真实的实现过程。&lt;/p&gt;\n&#34;,&#34;fileName&#34;:&#34;abstract-data-type-wikipedia&#34;,&#34;abstract&#34;:&#34;&lt;p&gt;&lt;strong&gt;抽象数据类型&lt;/strong&gt;(&lt;strong&gt;A&lt;/strong&gt;bstract &lt;strong&gt;D&lt;/strong&gt;ata &lt;strong&gt;T&lt;/strong&gt;ype, &lt;strong&gt;ADT&lt;/strong&gt;) 是计算机科学中具有类似行为的特定类别的数据结构和数学模型；或者具有类似语义的一种或多种程序设计语言的数据类型。抽象数据类型是间接定义的，通过其上的可执行的操作以及这些操作的效果的数学约束（与可能的代价）。&lt;/p&gt;\n&lt;p&gt;例如，抽象的堆栈(stack)由 3 个操作定义：推入 push，弹出 pop（接受约束：每次弹出返回的最新被推入且没有被弹出的数据，也就是后进先出），查看堆栈顶端数据 peek。当分析使用堆栈算法的效率，所有这 3 个操作用时相同，无论堆栈中包含多少项数据；并且堆每项数据栈使用了常量大小的存储。&lt;/p&gt;\n&lt;p&gt;抽象数据类型（ADT）是纯粹理论实体，用于简化描述抽象算法，分类与评价数据结构，形式描述程序设计语言的类似系统。一个 ADT 可以用特定数据类型或数据结构实现，在许多程序设计语言中有许多种实现方式；或者用形式规范语言描述。ADT 常实现为模块(module)：模块的接口声明了对应于 ADT 操作的例程(procedure)，有时用注释描述了约束。&lt;/p&gt;\n&#34;,&#34;title&#34;:&#34;Abstract data type - wikipedia&#34;,&#34;tags&#34;:[{&#34;index&#34;:-1,&#34;name&#34;:&#34;programming concept&#34;,&#34;slug&#34;:&#34;60uU_0nib&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://wenbozhangw.github.io/tag/60uU_0nib/&#34;}],&#34;date&#34;:&#34;2022-01-25 14:19:13&#34;,&#34;dateFormat&#34;:&#34;2022-01-25&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://wenbozhangw.github.io/post/abstract-data-type-wikipedia/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;6 min read&#34;,&#34;time&#34;:347000,&#34;words&#34;:1670,&#34;minutes&#34;:6},&#34;description&#34;:&#34;抽象数据类型(Abstract Data Type, ADT) 是计算机科学中具有类似行为的特定类别的数据结构和数学模型；或者具有类似语义的一种或多种程序设计语言的数据类型。抽象数据类型是间接定义的，通过其上的可执行的操作以及这些操作的效果...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E7%A4%BA%E4%BE%8B\&#34;&gt;示例&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%8E%A5%E5%8F%A3%E5%92%8C%E5%AE%9E%E7%8E%B0%E7%9A%84%E5%88%86%E7%A6%BB\&#34;&gt;接口和实现的分离&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%8A%BD%E8%B1%A1%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84\&#34;&gt;抽象数据结构&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%86%85%E7%BD%AE%E6%8A%BD%E8%B1%A1%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B\&#34;&gt;内置抽象数据类型&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%AE%9E%E9%99%85%E7%A4%BA%E4%BE%8B\&#34;&gt;实际示例&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%BD%9C%E4%B8%BA%E6%8A%BD%E8%B1%A1%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E7%9A%84%E6%9C%89%E7%90%86%E6%95%B0\&#34;&gt;作为抽象数据类型的有理数&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%A0%86%E6%A0%88\&#34;&gt;堆栈&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%8E%A5%E5%8F%A3\&#34;&gt;接口&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E7%94%A8%E6%B3%95\&#34;&gt;用法&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%90%84%E7%A7%8D%E5%AE%9E%E7%8E%B0\&#34;&gt;各种实现&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;p&gt;本文提出了一种用于屋顶光伏发电潜力评估的快速扫描产量预测方法。该方法有三个主要部分。对于每个屋顶，首先利用航拍图像重建虚拟三维屋顶段，然后利用拟合算法将光伏组件自动贴合到屋顶段上，最后计算出预期的年产量。对每个屋面采用三种不同的快速产量计算方法计算年产量。两种方法是太阳猴(SM)和光伏地理信息系统(PVGIS)的商业软件包，而另一种是代尔夫特理工大学光伏材料和器件(PVMD)小组开发的基于天线的简化方法。为了验证快速扫描方法，在荷兰的城市地区选择了一组145个屋顶和215个屋顶段。对于所选择的屋顶，将安装模块的数量和计算的产量与实际的模块布局和现有光伏系统的实测产量进行比较。结果表明，快速扫描预测方法与实测结果吻合较好，相对标准偏差分别为7.2%、9.1%和7.5%。结果表明，包含障碍物的方法(如SM和PVMD)优于忽略周围障碍物遮挡的方法(如PVGIS)。结果还表明，3D屋顶段作为快速扫描PV产量预测方法的输入值具有附加价值，因为仅使用建筑的2D土地登记数据预测产量的精度明显较低。&lt;/p&gt;\n&lt;!-- more --&gt;\n&lt;p&gt;以更可持续和更无化石的方式满足人类能源需求的挑战让人类感到气馁，向风能和太阳能等可再生能源的过渡已经开始。2018年，全球光伏年装机容量超过100 GW，累计运行总容量超过0.5 TW (SolarPower Europe, 2019;光伏发电系统规划，2018)。尽管光伏系统的价格在过去几十年里大幅下降，但光伏的采用并没有迅速增长(Karakaya和Sriwannawit, 2015)。社会的心态必须转向光伏和光伏革命(Smets, 2017)。因此，需要更多的社会推动来帮助太阳能光伏产业的发展。&lt;/p&gt;\n&lt;p&gt;这种社会推动可以通过各种方式支持自动光伏系统设计。首先，设计光伏系统所需的时间可以大大减少。从软件辅助设计到视觉现场检查(例如，计算屋顶瓦的数量，粗略估计屋顶光伏潜力)，屋顶光伏系统的实际设计可能需要10分钟到几个小时(尼泊尔普拉莫德，2019年;de Proost, 2019)。由于国内光伏发电系统市场竞争激烈，目前国内光伏发电系统的设计成品率较低。如果系统设计的报价是自动生成的，那么PV安装公司可以节省大量的时间。一个自动化的光伏系统设计也可以使光伏销售过程更加高效。这样可以减少给潜在客户打电话的时间和精力。整个太阳能市场的活动可以增加作为一个更有效的销售过程的结果，因为它将提高生产力。此外，一个先进的设计算法可以设计出更精确的能量产出，更好的美学或更好的成本效益的系统，比人类可以在同样的时间内完成。可以计算出模块的最佳位置，使全年的阴影最小化。此外，算法可以找到其他模块配置，使更多模块适合同一屋顶。例如，它可以根据客户的要求，通过比较东西或南向的设置，在每平方米产量和总产量之间找到平衡。从另一个角度来看，通过以一种快速和用户友好的方式促进产量预测和系统设计，消费者将较少关注他们的屋顶是否适合光伏系统。&lt;/p&gt;\n&lt;p&gt;为了实现这一目标，开发了一种所谓的快速扫描产量预测方法。该方法实现了屋顶光伏系统设计和产量预测的自动化。它还通过尽可能减少运行时间，实现了大规模的屋顶光伏潜力评估(如一个城市或一个地区)。本文旨在介绍快速扫描方法，并讨论以下研究问题的结果:(1)自动模块安装在住宅屋顶上的现实程度如何?(2)不同快速产量计算方法的产量预测精度如何?(3)快速扫描方法的不同部分有多快，如何对其进行优化?&lt;/p&gt;\n&lt;p&gt;第二节概述了城市屋顶太阳能潜力估算的相关文献，并简要说明了研究提纲。在第3节中，描述了快速扫描方法的不同部分。第4节给出了模块拟合算法的结果和产量计算方法，并讨论了仿真时间。最后，将在第5节中得出结论，并就今后的工作提出建议。&lt;/p&gt;\n&lt;h2 id=\&#34;2-文献综述与研究概要\&#34;&gt;2. 文献综述与研究概要&lt;/h2&gt;\n&lt;p&gt;建筑屋顶光伏发电的潜力通常由以下几个方面决定:(i)寻找可用的屋顶面积光伏组件，(ii)模拟阵列平面(POA)太阳辐照度，(iii)计算这种系统的年交流发电量。&lt;/p&gt;\n&lt;p&gt;利用平均条件，可以利用土地利用、建筑密度和人口密度来计算屋顶总面积，假设利用系数固定，可以得到PV的可用屋顶面积(Izquierdo et al.， 2008)。2010年，Winginton et al.利用屋顶表面积和人口之间的关系来估计美国安大略省东南部的屋顶光伏发电潜力(Wiginton et al.， 2010)。同样，我们分析了西班牙安达卢西亚不同类型的住宅屋顶的太阳能容量(Ordóñez et al.， 2010)。2012年，Defaix等人发布了27个欧洲成员国的建筑集成光伏(BIPV)潜力，从人均平均建筑面积开始，寻找每个国家可用的屋顶表面(Defaix等人，2012)。对于印度城市孟买，我们使用航拍图像来计算建筑足迹面积(BFA)比率和光伏可用屋顶面积(PVA)的值，以估计这座城市的光伏潜力(Singh和Banerjee, 2015)。印度早前对德里光伏潜力的调查是基于拇指规则、标准假设和专家的意见，因为数据无法获得(革命，2013年)。2014年，Mainzer等人分析了德国各个城市的技术光伏潜力，通过统计数据估计了每座建筑的可用面积和能源需求(Mainzer等人，2014)。2015年，Byrne等人计算了首尔(韩国)每一种建筑类型的净可用屋顶面积，包括模块倾斜及其对地面覆盖比(GCR)和城市预期光伏潜力的影响的参数研究(Byrne等人，2015)。2017年，Khan等人对沙特阿拉伯王国的13个城市进行了类似的研究，并估计了潜在发电量(Khan等人，2017)。&lt;/p&gt;\n&lt;p&gt;基于地理信息系统(GIS)的其他方法最近也得到了越来越多的使用，特别是自从GIS成为一种常用的工具以来(Schallenberg-Rodríguez, 2013)。如果有的话，可以使用建筑物外部形状的GIS数据来估计可用屋顶面积。2011年，利用建筑外部形状的GIS数据，并对利用系数进行假设，评估了以色列屋顶光伏的潜在发电量(Vardimon, 2011)。Martín-Chivelet提出了GCR的解析表达式和PV潜力的逐步评估方法(MartínChivelet, 2016)。2015年，Freitas等人对城市地区太阳势计算方法进行了综述，认为计算方法需要在精度和计算时间之间进行折衷(Freitas等人，2015)。&lt;/p&gt;\n&lt;p&gt;如果3D信息和/或高度数据是可用的，如激光雷达测量，俯仰角和方位角的屋顶段可以用来确定POA辐照度。2012年，Brito等人利用LiDAR数据评估了里斯本郊区的光伏潜力(Brito等人，2012)。得出结论,为光伏穿透屋顶总面积的10%以下,PV潜力可以估计忽略了阴影和考虑PV的最佳倾角和取向,然而,高渗透,潜在的可以被考虑水平估计地表建筑物内占用面积。2011年，Bergamasco等人利用MATLAB评估了屋顶集成光伏系统的光伏潜力，首先是在皮埃蒙特地区进行的一项研究(Bergamasco和Asinari, 2011年)。随后，将MATLAB算法进行了阴影和屋顶内障碍物检测的增强，并应用于都灵市，处理了6万多栋建筑(Bergamasco和Asinari, 2011)。2013年，Kodysh等人将激光雷达数据和GIS方法结合起来，估算了美国田纳西州诺克斯县不同屋顶表面的辐照度(Kodysh等人，2013年)。然而，研究的输出是每个屋顶表面积的太阳辐照度，因为PV和电力输出的可用面积不在研究范围内。2014年，利用可用屋顶面积的GIS数据，并考虑到其他建筑造成的遮阳，评估了台湾的屋顶光伏潜力(Ko et al.， 2015)。有一些使用3D城市模型来计算总屋顶面积和预期发电量的例子，如Rodriguez等人在德国路德维希堡的工作(Rodríguez et al.， 2017)。然而，3D城市模型的创建或获取成本很高，目前世界上大多数地区都无法获得3D城市模型。此外，使用3D模型和光线投射进行遮阳计算是非常需要计算的，因此，限制了PV势可确定的规模。&lt;/p&gt;\n&lt;p&gt;上面描述的一些研究通过GCR因子计算了将放置在可用屋顶面积上的光伏组件的离散数量，然而，它们都没有计算出适合每个屋顶段的实际模块布局。唯一的例外是Mainzer等人在2017年进行的一项研究，该研究利用地理建筑数据和航空图像结合图像识别技术，将模块虚拟地放置在屋顶上(Mainzer等人，2017)。他们的模块拟合算法在可用面积上递增迭代，并在每个屋顶分段内尽可能多地安装光伏模块。然而，它忽略了从屋顶边缘取下的距离，以及模块与平屋顶边缘的对齐。&lt;/p&gt;\n&lt;p&gt;为了模拟POA辐照度和计算年度交流能源产量，可以在产量计算模型中应用各种细节。例如，天际线轮廓（抵御天空中定义的光伏系统周围的土地和建筑物的轮廓）会影响到达PV模块的太阳辐照度（Calcabrini等，2019）。虽然阴影降低了PV模块性能（Ziar等，2017），但在产量预测方法中，通常不会针对每个屋顶确定天际线轮廓，忽略由其引起的阴影。更先进的收益率计算模型，包括温度，模块技术和逆变器利用的非线性效果显着增加了运行时，并相当提高了准确性（Mainzer等，2017）。但是，在处理大批次的屋顶时，两种精度（数据集的近距离，在这种情况下，建模的PV产量，到所建模和测量的KWH / KWP值的完美预测线和精度（接近在数据集中，在这种情况下，模拟的光伏产量，他们自己的平均KWH / KWP线路很重要。&lt;/p&gt;\n&lt;p&gt;现实生活中可能导致光伏造型中的系统和随机误差。系统错误从完美的预测（参考）转移建模数据点，而随机错误导致建模数据点分散。系统和随机误差分别涉及准确性和精度。对于大型研究或初始调查（Quick-Scan）的批次，精度与准确性一样重要。原因是，获得精度比准确性快，并且需要更少的输入和/或详细建模，并且当找到用于屋顶的PV电位的精确批次输出数据时，所有结果都可以通过简单转移（调谐）。 （和快速）校正因子具有精确和准确的批量输出数据。因此，该研究的目的是开发一种方法，可以快速扫描许多屋顶的光伏电位，高精度，然后，通过校正因子进一步修改它，也可以进行准确的结果数据集。值得注意的是，将一个校正因子应用于所有产量预测将改善几个单独的PV系统产量预测，同时它可能使少数几个产生的产量预测。但是，所有PV系统的总体预测将改善。&lt;/p&gt;\n&lt;p&gt;本研究中开发的方法使用从航空图像和GIS数据产生的3D屋顶段数据，以评估要安装在每个屋顶上的离散数量的光伏模块。 通过选择在其屋顶上具有PV系统的建筑物并将结果与实际放置的模块数量进行比较来测试模块拟合。 此外，LIDAR高度数据用于通过周围障碍物来解释阴影的影响。 使用Real PV系统的AC产量测量获得三种不同产量计算方法的精度。 开发方法试图保持计算时间尽可能低，以使算法可用于区域或国家规模的屋顶PV。&lt;/p&gt;\n&lt;h2 id=\&#34;3-方法\&#34;&gt;3. 方法&lt;/h2&gt;\n&lt;p&gt;在图1中，示出了快速扫描算法的一般结构。为了初始化，将一组分成三维屋顶段的屋顶输入到算法中。对于每个线段，使用两种独立的方法计算线段方向。然后进行模块装配，以找到可以放置在其上的模块的最大数量。对于容纳大多数模块的解决方案，产量计算是按屋顶部分进行的。最后，快速扫描算法的输出将是已安装模块的数量、以千瓦时为单位的预期年交流发电量和特定年发电量 KWH / KWP，每个模块按屋顶或物理地址汇总。在安装光伏系统之前，行业和研究团体广泛使用的优点是kWh或kWh / kWp，这给出了光伏系统将产生多少的指示。但是，在安装后，监视预期和真实光伏产量之间的差异，使用了优异性能比（PR）。由于该研究的目标是屋顶的产生评估，因此使用KWH和KWH / KWP作为优点。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;1\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1642922901318.png\&#34; alt=\&#34;\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;为了开发适用于任何地址的快速扫描，有必要了解屋顶的信息:屋顶面积(用于光伏组件安装)、坡度和方向(用于产量预测)。一种方法是使用在几个国家都可以获得的建筑物轮廓的土地登记数据。然而，大多数屋顶不是由一个平面组成的，并且具有在建筑物轮廓中无法检测到的障碍物。在本研究中，使用立体航空图像将屋顶分成具有不同斜度和方向的段。该算法显示在图1的下部。通过使用目标建筑的土地登记数据中的建筑轮廓来选择屋顶。通过匹配从不同角度拍摄的一对航空图像的屋顶像素来制作视差图(地理信息系统中的立体匹配(莱门斯，1988年；维米尔，2018年))。然后，通过比较屋顶上的许多点来获得3D点云，如图2中的视差图所示。&lt;/p&gt;\n&#34;,&#34;fileName&#34;:&#34;ji-yu-hang-pai-ying-xiang-he-lida-de-guang-fu-wu-ding-qian-li-kuai-su-sao-miao-ping-gu-fang-fa&#34;,&#34;abstract&#34;:&#34;&lt;p&gt;本文提出了一种用于屋顶光伏发电潜力评估的快速扫描产量预测方法。该方法有三个主要部分。对于每个屋顶，首先利用航拍图像重建虚拟三维屋顶段，然后利用拟合算法将光伏组件自动贴合到屋顶段上，最后计算出预期的年产量。对每个屋面采用三种不同的快速产量计算方法计算年产量。两种方法是太阳猴(SM)和光伏地理信息系统(PVGIS)的商业软件包，而另一种是代尔夫特理工大学光伏材料和器件(PVMD)小组开发的基于天线的简化方法。为了验证快速扫描方法，在荷兰的城市地区选择了一组145个屋顶和215个屋顶段。对于所选择的屋顶，将安装模块的数量和计算的产量与实际的模块布局和现有光伏系统的实测产量进行比较。结果表明，快速扫描预测方法与实测结果吻合较好，相对标准偏差分别为7.2%、9.1%和7.5%。结果表明，包含障碍物的方法(如SM和PVMD)优于忽略周围障碍物遮挡的方法(如PVGIS)。结果还表明，3D屋顶段作为快速扫描PV产量预测方法的输入值具有附加价值，因为仅使用建筑的2D土地登记数据预测产量的精度明显较低。&lt;/p&gt;\n&#34;,&#34;title&#34;:&#34;基于航拍影像和LiDA的光伏屋顶潜力快速扫描评估方法&#34;,&#34;tags&#34;:[],&#34;date&#34;:&#34;2022-01-23 13:51:21&#34;,&#34;dateFormat&#34;:&#34;2022-01-23&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://wenbozhangw.github.io/post/ji-yu-hang-pai-ying-xiang-he-lida-de-guang-fu-wu-ding-qian-li-kuai-su-sao-miao-ping-gu-fang-fa/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;14 min read&#34;,&#34;time&#34;:824000,&#34;words&#34;:3956,&#34;minutes&#34;:14},&#34;description&#34;:&#34;本文提出了一种用于屋顶光伏发电潜力评估的快速扫描产量预测方法。该方法有三个主要部分。对于每个屋顶，首先利用航拍图像重建虚拟三维屋顶段，然后利用拟合算法将光伏组件自动贴合到屋顶段上，最后计算出预期的年产量。对每个屋面采用三种不同的快速产量计算...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#2-%E6%96%87%E7%8C%AE%E7%BB%BC%E8%BF%B0%E4%B8%8E%E7%A0%94%E7%A9%B6%E6%A6%82%E8%A6%81\&#34;&gt;2. 文献综述与研究概要&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#3-%E6%96%B9%E6%B3%95\&#34;&gt;3. 方法&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;p&gt;1、公式里有区分平面屋和斜坡屋，这个数据图里没有对应提现&lt;br&gt;\n2、图中没有提现建筑类型&lt;br&gt;\n3、是否能够周长和面积算出容积率（墙面计算需要）&lt;br&gt;\n4、是否考虑墙面安装、墙面安装可能需要考虑建筑高度&lt;/p&gt;\n&#34;,&#34;fileName&#34;:&#34;guang-fu-mian-ji-ji-suan&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;光伏面积计算&#34;,&#34;tags&#34;:[],&#34;date&#34;:&#34;2022-01-20 23:02:21&#34;,&#34;dateFormat&#34;:&#34;2022-01-20&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://wenbozhangw.github.io/post/guang-fu-mian-ji-ji-suan/&#34;,&#34;hideInList&#34;:true,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;1 min read&#34;,&#34;time&#34;:16000,&#34;words&#34;:81,&#34;minutes&#34;:1},&#34;description&#34;:&#34;1、公式里有区分平面屋和斜坡屋，这个数据图里没有对应提现\n2、图中没有提现建筑类型\n3、是否能够周长和面积算出容积率（墙面计算需要）\n4、是否考虑墙面安装、墙面安装可能需要考虑建筑高度\n&#34;,&#34;toc&#34;:&#34;&#34;},{&#34;content&#34;:&#34;&lt;p&gt;使用高级语言进行工作的动机是通过为程序员提供一种包含适合其问题领域的原语(primitives)或抽象(abstractions)的语言来简化编程任务。这样程序员就可以把精力花费在正确的地方；程序员可以专注于解决他的问题，结果程序将更加可靠。显然，这是一个值得实现的目标。&lt;/p&gt;\n&lt;p&gt;不幸的是，设计师很难提前选择使用该语言的用户可能需要的所有抽象(abstractions)。如果要使用一种语言，它很可能会被用来解决设计者没有预见到的问题，而且这种语言中嵌入的抽象可能并不足以解决这些问题。&lt;/p&gt;\n&lt;p&gt;本文提出了一种方法，当发现需要新的数据抽象时，可以扩展内置的抽象集。这种处理抽象的方法是为结构化编程设计语言的产物。本文描述了这种语言的相关方面，并给出了抽象的用法和定义的实例。&lt;/p&gt;\n&lt;!-- more --&gt;\n&lt;h2 id=\&#34;introduction\&#34;&gt;Introduction&lt;/h2&gt;\n&lt;p&gt;本文介绍了一种计算机抽象表示的方法。这种方法是在设计一种支持结构化编程的语言时开发的，他也适用于使用高级语言工作。我们首先解释它的相关性(relevance)，并比较结构化编程和高级语言的工作。&lt;/p&gt;\n&lt;p&gt;结构化编程的目的是增强程序的可靠性(reliability)和可理解性(understandability)。高级编程语言，虽然主要目的是为了通过减轻程序员的任务来提高程序员的工作效率，但同时也期望可以提高代码的可靠性和可理解性。因此，可以期望从这两个领域的工作中获得类似的好处。&lt;/p&gt;\n&lt;p&gt;然而，这两个领域的工作沿着不同的方向进行。高级编程语言试图向用户呈现抽象（操作、数据结构和控制结构）对他的应用领域很有用。用户可以使用这些抽象，而不用关心它们是如何实现的——他只关心它们做什么。因此，他能够忽略与其应用领域无关的细节，专注于解决自己的问题。&lt;/p&gt;\n&lt;p&gt;结构化编程试图对编程任务加一种约束，以便重新适应的程序具有良好的结构。在这种约束下，问题是通过一个连续分解(successive decomposition)的过程来解决的。第一步是编写一个程序来解决这个问题，但是这个程序运行在一个抽象的机器上，这个抽象的机器仅提供那些最合适解决这个问题的数据对象和操作。这些数据对象和操作中的部分或全部是真正抽象的，即，在所使用的编程语言中不作为原语呈现。目前，我们将把它们简单的归为 &amp;quot;abstraction&amp;quot; 一词。&lt;/p&gt;\n&lt;p&gt;程序员最初关心的是（或证明）他的程序是否令人满意地正确的解决了问题。在本文的分析中，他关注的是他的程序使用抽象的方式，而不是哪些抽象如何实现的细节。当他对程序的正确性感到满意时，他就把注意力转向程序使用的抽象。每个抽象都代表一个新问题，需要额外的程序来解决它。新的程序也可以编写为在抽象机器上运行，从而引入更多的抽象。当在构造程序过程中产生的所有抽象都被进一步的程序实现时，原来的问题就完全解决了。&lt;/p&gt;\n&lt;p&gt;现在很明显，高级语言和结构化编程的方法是相互关联的：每种方法都是基于利用那些对解决问题正确的抽象想法。此外，在这两种方法中使用抽象的基本原理是相同的：让程序员不用担心与他正在解决的问题无关的细节。&lt;/p&gt;\n&lt;p&gt;在高级语言中，设计者视图提前确定有用的抽象集。另一方面，结构化编程语言不包含关于特定的有用抽象集的先入为主的观念，而是必须提供一种机制，通过这种机制，语言可以扩展到包含用户需要的抽象。包含这种机制的语言可以被视为通用的、无限高级的语言(indefinitely-high-level language)。&lt;/p&gt;\n&lt;p&gt;在本文中，我们描述了一种抽象方法，当发现需要新的抽象时，允许对内置的抽象集进行扩充。我们从分析编写程序中使用的抽象开始，并确定对数据抽象的需求。非正式的描述了一种支持数据抽象的使用和定义的语言，并给出了一些示例程序。文中的其余部分讨论了该方法与之前的工作的关系，以及该语言实现的一些方面。&lt;/p&gt;\n&lt;h2 id=\&#34;the-meaning-of-abstraction\&#34;&gt;The Meaning of Abstraction&lt;/h2&gt;\n&lt;p&gt;上一节中对结构化编程的描述是模糊的，因为它是用&amp;quot;抽象(abstraction)&amp;quot;和&amp;quot;抽象机器(abstract mechine)&amp;quot;这样没有定义的术语来描述的。在本节中，我们将分析&amp;quot;抽象(abstraction)&amp;quot;的含义，以确定程序员需要什么样的抽象，以及结构化编程语言如何支持这些需求。&lt;/p&gt;\n&lt;p&gt;我们希望从抽象中得到一种机制，它允许表达相关的细节，一直不相关的细节。在编程的情况下，抽象的使用是相关的；抽象实现的方式无关紧要。如果我们考虑传统的编程语言，我们会发现它们为抽象提供了强大的帮助：函数(function)或过程(procedure)。当一个程序员使用一个过程时，他只关心（或者应该关心）它做什么——它为他提供了什么函数。他不关心由程序执行的算法。另外，过程提供了一种分解问题的方法——在过程中执行部分编码任务，在程序中执行调用过程的另一部分。因此，过程的存在对捕捉抽象的意义有很大的帮助。&lt;/p&gt;\n&lt;p&gt;不幸的是，过程本身并不能提供足够丰富的抽象词汇表(vocabulary of abstractions)。上文提及的抽象机器的抽象数据对象(abstract data object)和控制结构(control structures)不能用独立的过程准确地表示。因为我们在结构化编程的上下文中考虑抽象，所以我们将忽略控件抽象(control abstractions)的讨论。&lt;/p&gt;\n&lt;p&gt;这就引出了抽象数据类型的概念，这是语言设计的核心。抽象数据类型定义了一个抽象对象的类，该类完全由这些对象上可用的操作来描述。这意味着抽象数据类型可以通过定义该类型的特征化操作(characterizing operations)来定义。&lt;/p&gt;\n&lt;p&gt;我们认为，上述概念抓住了抽象对象的基本属性。当程序员使用一个抽象数据对象时，他只关心该对象表现出的行为，而不关心如何通过实现(implementation)来实现该行为的任何细节。对象的行为由一组特征和操作捕获。只有在定义如何实现特征化操作时，才需要实现信息，例如对象在存储中是如何表示的。对象的用户不需要知道或提供这些信息。&lt;/p&gt;\n&lt;p&gt;抽象类型与编程语言提供的内置类型非常相似。内置类型（如整数或整数数组）的用户只关心创建该类型的对象，然后对它们执行操作。他（通常）不关心数据对象是如何表示的，他认为对象上的操作是不可分割的(indivisible)和原子的(atomic)，而实际上可能需要几个机器指令来执行它们。此外，（通常）不允许他拆分对象。例如，考虑内置类型整数。&lt;/p&gt;\n&lt;p&gt;程序员想要声明数组类型的对象，并对它们执行通常的算术运算。他通常对整数对象作为位串(bit string)不感兴趣，并且不能使用计算机内的使用的位格式。此外，他希望这种语言能够保护他不犯一些愚蠢地误用类型错误（例如，将一个整数加到一个字符上），要么将这种事情视为错误（强类型），要么通过某种类型的自动转换。&lt;/p&gt;\n&lt;p&gt;在内置数据类型的情况下，程序员正在使用以较低的细节级别实现的概念或抽象——编程语言本身以及编译器。同样，抽象数据类型在一个级别使用，并在较低的级别实现，但是较低级别不会因为是语言的一部分自动出现，相反，抽象数据类型是通过编写一种特殊的程序来实现的，称为操作cluster(operation cluster)，简称cluster，它根据可以对其执行的操作来定义类型。该语言通过允许使用抽象数据类型来促进此活动，而无需其现场(on-the-spot)定义。语言处理程序支持抽象数据类型的方法是：在类型的使用和它的定义之间建立链接（可以提前或推迟提供），并且通过一种非常强大的数据类型形式将数据类型的视图强制为一组操作。&lt;/p&gt;\n&lt;p&gt;我们注意到，抽象数据类型概念的一个结果是，程序中的大多数抽象操作(abstract operations)将属于特征抽象类型(characterizing abstract types)的操作集。我们将使用属于函数抽象(functional abstraction)来表示哪些不属于任何特征集的抽象操作。函数抽象(functional abstraction)将被时限为一个或多个数据类型的特征操作的组合，并且将以通常的方式通过过程(producer)支持。正弦波轨迹(sine routine)的实现可以是一个泰勒级数(Taylor expansion)展开，用实际类型的特征操作而表现。&lt;/p&gt;\n&lt;h2 id=\&#34;the-programming-language\&#34;&gt;The Programming Language&lt;/h2&gt;\n&lt;p&gt;我们现在给出了一种编程语言的非正式描述，允许抽象数据类型的使用和定义。这种语言是在 M.I.T 下正在开发的结构化编程语言的简化版本。它主要来自 PASCALI ，并且在许多方面的是传统的编程语言一样，但它在几个重要的方面与传统语言不同。&lt;/p&gt;\n&lt;p&gt;该语言提供了两种形式的模块相对应于两种形式的抽象：过程（支持函数抽象）和操作cluster（支持抽象数据类型）。每个模块都是自己翻译（编译）的。&lt;/p&gt;\n&lt;p&gt;语言在传统意义上没有空闲变量(free variables)。在一个模块中，只有其他模块的名称是空闲的，因此需要在外部定义；也就是说，cluster名称和过程名称。这些名称借助编程器以绑定为目的创建的模块名称目录相绑定。翻译后的模块中没有任何名称需要绑定。&lt;/p&gt;\n&lt;p&gt;该语言只有结构化控制。没有 &lt;code&gt;goto&#39;s&lt;/code&gt;或&lt;code&gt;labels&lt;/code&gt;，而只有拼接(concatenation)、选择(selection)(&lt;code&gt;if&lt;/code&gt;， &lt;code&gt;case&lt;/code&gt;)和迭代(iteration)(&lt;code&gt;while&lt;/code&gt;)结构的变体。一些结构化的错误处理机制正在开发中。在本文中，他仅用保留字的存在&lt;code&gt;error&lt;/code&gt;来表示。&lt;/p&gt;\n&lt;p&gt;语言允许使用和定义抽象数据类型的方式可以通过一个例子来最好地说明。我们选择了以下问题：编写一个程序 &lt;code&gt;Polish_gen&lt;/code&gt;，它将从中 INFIX 语言转换为 POLISH 修复后的语言。&lt;code&gt;Polish_Gen&lt;/code&gt; 是一个通用程序，没有关于输入或输出设备（或文件）的假设(assumptions)。他只有一下堆输入语言的假设(assumptions)：&lt;/p&gt;\n&lt;ol&gt;\n&lt;li&gt;输入语言具有运算符优先语法。&lt;/li&gt;\n&lt;li&gt;输入语言的符号要没事字母和数字的任意字符串，要么是单个的非字母数字字符；空格用于终止符号，但其他部分将被忽略。&lt;/li&gt;\n&lt;/ol&gt;\n&lt;p&gt;例如，如果Polish_gen接收到字符串：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;a + b * (c + d)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;作为输入，它将生成字符串&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;a b c d + * +\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;作为输出。我们选择这个问题作为示例，是因为对编程语言感兴趣的人对这个问题及其解决方案很熟悉，而且这个问题足够复杂，可以说明许多抽象的使用。&lt;/p&gt;\n&lt;h2 id=\&#34;using-abstract-data-types\&#34;&gt;Using Abstract Data Types&lt;/h2&gt;\n&lt;p&gt;如图 1 所示，过程 &lt;code&gt;Polish_gen&lt;/code&gt; 执行上述转换。它需要三个参数：输入，一个抽象类型的对象，包含输入语言的句子(input， an object of abstract type infile which holds the sentence of the input language)；输出，抽象类型的输出对象，它将接受输出语言的句子(output， an object of abstract type outfile which will accept a sentence of the output language)；和 g，抽象类型语法的对象可用于识别输入语言的符号并确定其优先关系(and g， an object of abstract type grammar which can be used to recognize symbols of the input language and determine their precedence relations)。此外，&lt;code&gt;Polish_gen&lt;/code&gt;还利用了局部变量的抽象类型堆栈和令牌(stack and token)。请注意，所有的数据类型名称(data-type-names)在 &lt;code&gt;Polish_gen&lt;/code&gt; 中都是可用的(free)，&amp;quot;scan&amp;quot;也是如此，它为 &lt;code&gt;Polish_gen&lt;/code&gt; 使用的单个功能抽象(single functional abstraction)命名。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;1\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1642761202797.png\&#34; alt=\&#34;图1\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;该语言使用相同的语法来声明抽象数据类型的变量，以声明原始类型(primitive type)的的变量。语法区分了涉及创建对象的声明和不涉及对象创建的声明。例如&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;t: token\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;声明 t 是保存抽象类型 token 对象的变量的名称，但是不创建任何 token 对象，因此 t 的值最初是未定义的。因此变量 t 的声明方式与 mustscan 相同&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;mustscan: boolean\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;类型名称后出现括号表示创建了一个对象。例如&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;s: stack(token)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;表示 s 是保存抽象类型堆栈对象的变量的名称，堆栈对象将在 s 中创建和存储。创建对象所需的信息在参数列表中传递；在该示例中，唯一的参数 token 定义了可以放在堆栈上的元素类型。堆栈的声母类似于数组声明，例如 &lt;code&gt;array[1..10]的字符&lt;/code&gt;，因为它们都要求指定元素的类型。&lt;/p&gt;\n&lt;p&gt;语言是强类型的;因此，抽象对象只有三种使用方式:&lt;/p&gt;\n&lt;ol&gt;\n&lt;li&gt;抽象对象可以由定义其抽象类型的操作来操作。&lt;/li&gt;\n&lt;li&gt;抽象对象可以作为参数传递给过程。在这种情况下，调用过程传递的实际实参的类型必须与被调用过程中相应形参的类型相同。&lt;/li&gt;\n&lt;li&gt;抽象对象可以复制给变量，但前提是该变量声明保存该类型的对象。&lt;/li&gt;\n&lt;/ol&gt;\n&lt;p&gt;对抽象对象的定义操作的应用是通过使用复合名称(compound name)的操作调用来表示的，例如：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;grammar$eof(g)\nstack$push(s， t)\ntoken$is_op(t)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;复合名称的第一部分表示操作所属的抽象类型，而第二个组件标识操作。操作调用总是至少有一个参数——操作所属的抽象类型的对象。&lt;/p&gt;\n&lt;p&gt;操作调用(operation call)中包含 type-name 有几个原因。第一，由于操作调用可能有几个不同抽象类型的参数，缺少 type-name 可能会导致对实际操作的对象产生歧义。其次，复合名称的使用允许不同数据类型对操作使用相同的名称，而不会产生标识符冲突。第三，我们认为一旦读者习惯了这种表示方法，type-name 前缀将增强程序的可理解性。不仅操作的类型很明显，而且操作调用与过程调用也有明显的区别。&lt;/p&gt;\n&lt;p&gt;语句 &lt;code&gt;t:= scan(input， g)&lt;/code&gt; 演示了将抽象对象作为参数传递，以及将抽象对象赋值给变量。过程扫描，如图2所示，期望类型为 &lt;code&gt;infile&lt;/code&gt; 和 &lt;code&gt;grammar&lt;/code&gt; 的对象作为其参数，并返回类型为token的对象，&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;2\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1643007130633.png\&#34; alt=\&#34;图2\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;我们已经解释了对象可以与变量声明一起创建。也可以独立于变量声明创建对象。对象创建是通过 type-name 的出现加上括号来指定的(无论是否在声明中)。例如，在 &lt;code&gt;scan&lt;/code&gt; 的最后一行 &lt;code&gt;token(g， newsymb)&lt;/code&gt;  声明一个token对象，表示刚刚扫描的符号，将被创建; 创建对象所需的信息(刚扫描的语法和符号)在参数列表中传递。&lt;/p&gt;\n&lt;p&gt;现在可以给出 &lt;code&gt;Polish_gen&lt;/code&gt; 逻辑的简要描述。&lt;code&gt;Pollsh__gen&lt;/code&gt; 使用函数抽象扫描从输入字符串中获取语法符号。&lt;code&gt;Scan&lt;/code&gt; 以 token 的形式返回符号——引入 token 的目的是提供高效执行，而不会透露语法如何表示符号的信息。&lt;code&gt;Polish_gen&lt;/code&gt; 将包含新扫描符号的 token 存储在变量t中。如果t持有一个表示标识符(如&amp;quot;a&amp;quot;)而不是操作符(如&amp;quot;+&amp;quot;)的 token ，该标识符将立即被放入输出文件。否则，将栈顶部的 token 与t进行比较，以确定它们之间的优先关系。如果关系是 &amp;quot;~&amp;quot;，t被推到栈上(例如，&amp;quot;+&amp;quot; &amp;lt; &amp;quot;*&amp;quot;)。如果关系是&amp;quot;=&amp;quot;，t和栈顶 token 都被丢弃(例如，&amp;quot;(&amp;quot;=&amp;quot;)&amp;quot;)，如果关系是 &amp;quot;~&amp;quot;，栈顶 token 中的操作符被追加到输出文件中，暴露一个新的栈顶 token。由于运算符 token 的优先级比 t 更高，因此布尔变量 mustscan 用于放置扫描新符号并确保下一个比较是具有 t 的当前值。由于文件符号末尾的语法依赖表示(&lt;code&gt;grammar$eof(g)&lt;/code&gt;)最初被推到堆栈上，因此堆栈将变为空，导致 &lt;code&gt;Polish__gen&lt;/code&gt; 只有在耗尽输入生成匹配的eof token时才会完成。(我们已经做了一个简化的假设，即输入是中缀语言的合法句子。)&lt;/p&gt;\n&lt;p&gt;scan 过程通过定义抽象类型 infile 的操作输入问题中获取字符。它使用数据类型 char 和 string，以及对这些类型的对象的操作。虽然这些类型如内置所示，但它们很容易地变成抽象类型。在这种情况下，内置的谓词字母数字(predicate alphanumeric)将被表示为 &lt;code&gt;char$alphanumeric&lt;/code&gt;。只有语法会被改变；在任何一种情况下，类型的含义和使用都是相同的。&lt;/p&gt;\n&lt;p&gt;综上所述，&lt;code&gt;Polish_gen&lt;/code&gt;使用了 5 个数据抽象，infile， outfile， grammar， token 和 stack，外加一个函数抽象(functional abstraction)， scan。数据抽象的强大功能可以通过类型 infile 和 outfile 来说明，它们分别用来屏蔽与 &lt;code&gt;Polish_gen&lt;/code&gt; 的输入和输出相关的任何物理事实。当 I/O 实际发生时，&lt;code&gt;Polish_gen&lt;/code&gt; 不知道正在使用什么输入和输出设备，也不知道字符串是如何在设备上表示的。对于参数 output，它知道如何添加一个字符串字符(&lt;code&gt;outfile$out_str&lt;/code&gt;)，以及如何表示输出已经完成(&lt;code&gt;outfile$close&lt;/code&gt;)。对于参数 input，他知道如何获取下一个字符(&lt;code&gt;infile$get&lt;/code&gt;)，如何查看下一个字符而不将其从输入中删除(&lt;code&gt;infile$peek&lt;/code&gt;)，以及如何识别输入的结尾(&lt;code&gt;infile$eof&lt;/code&gt;)。（注意，为了正确的 scan 操作，infile 必须在到达文件结束后的 &lt;code&gt;infile$get&lt;/code&gt; 或 &lt;code&gt;infile$peek&lt;/code&gt; 上的任何调用中提供非空白的非字母数字字符串）在每种情况下，它的知识(knowledge)都由提供这些服务的操作的名称组成。&lt;/p&gt;\n&lt;h2 id=\&#34;defining-abstract-data-types\&#34;&gt;Defining Abstract Data Types&lt;/h2&gt;\n&lt;p&gt;在本节中，我们描述了编程对象 —— 操作cluster(operation cluster) —— 其翻译(编译)提供了类型的实现。该cluster包含实现每个特征操作的代码，从而体现了数据类型由一组操作定义的想法。&lt;/p&gt;\n&lt;p&gt;例如，考虑 &lt;code&gt;Polish_gen&lt;/code&gt; 使用的抽象类型 stack。cluster支持 stack 如图 3 所示。该cluster实现了一种非常常用的 stack 对象，其中 stack 元素的类型是预先知道的。cluster 参数 element_type 表示特定 stack 对象要包含的元素类型。&lt;/p&gt;\n&lt;p&gt;cluster定义的第一部分非常简短地描述了cluster呈现给用户的接口。cluster接口定义了cluster的名称，创建cluster实例(cluster 实现的抽象类型对象)所需的参数，以及定义 cluster 实现的类型的操作列表，例如：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;stack: cluster(element-type: type)\n    is push, pop, top, erasetop, empty\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;保留字 &lt;code&gt;is&lt;/code&gt; 是值数据类型的特征是一组操作。&lt;/p&gt;\n&lt;p&gt;cluster 定义的其余部分描述了如何实际支持抽象类型，包含三个部分：对象表示、创建对象的代码和操作定义。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;3\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1643018152626.png\&#34; alt=\&#34;图3\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;对象表示(Object Representation)。抽象数据类型的用户将该类型的对象视为不可分割的实体。然而，在 cluster 内部，对象被视为可分解为更基本类型的元素。 rep(Representation) 描述为：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;rep{(&amp;lt;rep-parameters&amp;gt;)} = &amp;lt;type-definition&amp;gt;\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;定义了一个新类型，用保留字 rep 表示，该类型只能在 cluster 中访问，并描述了在 cluster 中如何查看对象。&lt;code&gt;&amp;lt;type-definition&amp;gt;&lt;/code&gt;定义了一个模版，该末班允许构建和分解该类型的对象。通常，它会利用语言提供的数据结构方法：数组（可能是无界的）或 PASCAL 记录。可选的 &lt;code&gt;(&amp;quot;{}&amp;quot;) &amp;lt;rep-parameters&amp;gt;&lt;/code&gt; 使得可以延迟指定 &lt;code&gt;&amp;lt;type-definition&amp;gt;&lt;/code&gt; 的某些方面，知道创建了 rep 的实例。考虑 stack cluster 的 rep 描述：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;rep(type_param: type) = (tp: integer; e_type: type; stk: array[1..] of type_param)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;&lt;code&gt;&amp;lt;type-definition&amp;gt;&lt;/code&gt;指定 stack 对象由包含名为 tp, stk 和 e 类型的三个组件的记录表示。参数 type_param，它可以存储在名为 stk 的无界数组中，该数组将保存推入 task 对象的元素。同样的类型也将存储在 e_type 组件中，并用于类型检查，如下所述。tp 组件保存 stack 最顶层元素的索引。&lt;/p&gt;\n&lt;p&gt;对象创建(Object Creation)。保留字 create 标记为 create_code，这是创建抽象类型对象时要执行的代码。cluster 可以被视为一个过程，其过程主体是创建代码。当用户指示要创建抽象类型的对象时，例如，&lt;code&gt;s: stack(token)&lt;/code&gt; ，发生的一件事（在执行时）是对 create_code 的调用，导致该过程体被执行。cluster 的参数实际上是 create_code 的参数。由于除了对外部定义模块的引用之外，没有提供自由变量，因此这些参数对 rep 中的操作或 &lt;code&gt;&amp;lt;type definition&amp;gt;&lt;/code&gt; 都是不可访问的。因此，关于要保存的参数的任何信息都必须显式插入到 rep 的每个实例中。&lt;/p&gt;\n&lt;p&gt;stack cluster 中显示的代码是典型的 create_code。首先，创建 rep 的对象；也就是说，分配空间以将对象保存由 rep 定义。然后，一些初始值存储在对象中。最后，对象将返回给调用者。返回对象后，其类型从 rep 类型更改为 cluster 定义的抽象类型。&lt;/p&gt;\n&lt;p&gt;操作(Operations)。cluster 的其余部分由一组操作定义组成，这些定义提供了对数据类型允许的操作的实现。操作定义与普通的过程定义类似，除了它们可以访问 cluster 的 rep 之外，这允许它们分解 cluster 类型的对象。操作本身不是模块；它们将被编译器接受，仅作为 cluster 的一部分。&lt;/p&gt;\n&lt;p&gt;操作总是至少有一个参数 —— 类型为 rep。因为 cluster 可以同时支持多个其定义类型的对象，所以这个参数告诉操作要操作的特定对象。请注意，在调用者和操作之间传递时，该参数的类型将从抽象类型更改为 rep 类型。&lt;/p&gt;\n&lt;p&gt;因为该语言是强类型的，所以必须检查推送到给定 stack 上的对象类型是否与 stack 可容纳的元素类型一致。这个一致性要求在语法上是通过声明 push 的第二个参数的类型与 stack 对象的 rep 的 e_type 组件（即 push 的第一个参数）相同来指定的。翻译（编译）程序可以生成代码来验证类型在运行时是否匹配，如果不匹配则引发错误。&lt;/p&gt;\n&lt;h2 id=\&#34;controlling-the-use-of-information\&#34;&gt;Controlling the Use of Information&lt;/h2&gt;\n&lt;p&gt;引入抽象数据类型是为了让程序员在使用数据抽象时不必担心无关的细节。但事实上，我们已经走得更远了。因为语言是强类型的，用户无法使用任何实现细节。在本节中，我们将讨论这种限制所带来的好处：结果是程序更模块化，更容易理解、修改、维护和证明其正确性。&lt;/p&gt;\n&lt;p&gt;token 是个很好的类型示例，创建它是为了控制对实现细节的访问。与其引入一个新的类型，&lt;code&gt;Polish_gen&lt;/code&gt; 可以被写为接受来自 scan 的字符串，将字符串存储在 stack 上，并比较字符串以确定优先关系（通过一个适当的操作 &lt;code&gt;grammar$prec_rel&lt;/code&gt;）。这样的解决方案是低效的。因为优先级矩阵可以由 grammar 的保留字表中运算符的位置索引，因此有效的实现将仅查找一次字符串，一旦发现如果是操作者符号，则使用在 &lt;code&gt;Polish_gen&lt;/code&gt; 中的操作符的索引。&lt;/p&gt;\n&lt;p&gt;然而，这会暴露有关 grammar 表示的信息。如果 &lt;code&gt;Polish_gen&lt;/code&gt; 或使用 grammar 的一些其他模块利用此信息，则 grammar cluster 的正常维护和修改可以引入难以追踪的错误。因此，引入了新类型，token，以限制关于 grammar 是如何表示的信息的分布。限制，grammar cluster 的重新定义只能影响 token  cluster —— token cluster 对从 grammar 接收到的索引没有任何假设。如果在查找优先关系（如索引越界）时发生错误，则该错误只能是由 token 或 grammar cluster 中的某些内容引起的。&lt;/p&gt;\n&lt;p&gt;事实上，选择 token 的实现——例如，token 是用整数还是字符串表示——涉及到设计决策。这个决策可以延迟到 token 的 cluster 被定义时，而不必在 &lt;code&gt;Polish_gen&lt;/code&gt; 编码期间做出来。因此，&lt;code&gt;Polish_gen&lt;/code&gt; 的编程可以根据 Dijkstra 的编程原则之一来完成：每次只构建一个决策。遵循这一原则，可以简化 &lt;code&gt;Polish_gen&lt;/code&gt; 的逻辑，使其更容易理解和维护。&lt;/p&gt;\n&lt;p&gt;使 representation 无法访问也导致一个更容易证明正确的程序。程序的证明分为两部分：证明 cluster 正确实现该类型，以及使用类型的程序是正确的。只有在前一种证明中才需要考虑类型对象的实现细节；后一个证明仅仅基于类型的抽象属性，这些抽象属性可以用每种类型的特征操作之间的关系来表示。&lt;/p&gt;\n&lt;h2 id=\&#34;relationship-to-previous-work\&#34;&gt;Relationship to Previous Work&lt;/h2&gt;\n&lt;p&gt;在为定义数据类型创建合适的机制方面已经做了很多工作。这里不可能调研所有的工作，也不是说所有的工作都与本文相关。在本节中，我们将概述与 cluster 最密切相关的工作领域，因为它们提供了一些用于定义抽象数据类型的工具，并讨论 cluster 方法与这些工作的区别。相关工作可以大致分为三类：可扩展语言(extensible languages)、一组标准抽象操作符的实现规范(implementation specifications for a set of standard abstract operators)和 SIMULA 67 类定义(SIMULA 67 class definitions)。&lt;/p&gt;\n&lt;h3 id=\&#34;extensible-languages\&#34;&gt;Extensible Languages&lt;/h3&gt;\n&lt;p&gt;可扩展语言的大部分工作和成功都是在数据类型定义领域。然而，这项工作主要面向定义表示(defining representations)，而不是抽象类型。通过使用语言的基本模式构造工具(primitive mode construction facilities of the language)，根据现有模式构造表示()，可以创建新的数据表示(new data representations)，或者通常称为模式(mode)。可扩展语言提供的模式构建工具通常包括定义对象指针、定义不同模式类的联合以及构造对象聚合（数组和记录）的机制。这些与本文中用来定义 rep 的方法密切对应。这些模式定义机制的使用意味着定义了一组构造函数(constructors)、选择器(selectors)和谓词(predicates)，它们可以应用于所定义模式的对象。在某些语言中，模式定义可以允许这组操作被特定的操作扩充，比如在语言中明确规定的赋值操作。&lt;/p&gt;\n&lt;p&gt;可扩展语言的主要问题是它们不鼓励使用数据抽象。一般来说，在模式定义中定义描述抽象数据类型的所有操作是不可能的。正如我们注意到的，只有数据类型的 representation 是使用模式扩展机制定义的。任何不等同于 representation 的构造函数、选择器或谓词的抽象操作都必须由过程或宏在模式定义之外定义，可以使用语法扩展功能使其看起来像操作符。因此，用户必须学习两种不同的机制；定义不是像在操作 cluster 中那样收集在一个地方，而是被分割成不同的部分。此外，很难限制对抽象数据类型的特征操作的对 representation 的访问。&lt;/p&gt;\n&lt;h3 id=\&#34;standard-abstract-operations\&#34;&gt;Standard Abstract Operations&lt;/h3&gt;\n&lt;p&gt;源自 Mealy 和 Balzer 早期工作的作品在精神上更接近于这里采取的方法。Mealy 建立这样一个观点，即数据集合是从一组选择器到一组值的 map ，对数据集合的操作要么是 map 上的转换，要么是使用 map 来访问元素。这种观点导致了标准化一组用于数据集合的抽象操作符的尝试。例如，Balzer 为这样的集合提出了一个特定的抽象，它定义了一组四个抽象操作符，用于创建、访问、修改和销毁抽象数据集合。用户将通过指定如何实现每个抽象操作来定义一个特定的集合。这项工作已经被扩展（例如，Earley），但是它的主要重点仍然是定义一个标准的抽象操作集。更复杂的操作被定义为根据这些操作编写的过程。&lt;/p&gt;\n&lt;p&gt;尽管区分一些抽象操作（如&amp;quot;create&amp;quot;）很有用，因为他们很可能适用于所有抽象数据类型，但期望一组预先确定的操作足以操作所有抽象数据对象似乎是不合理的。因此，将操作的选择留给类型的创建者，就像操作 cluster 一样，提供了一个更紧密定制的抽象。&lt;/p&gt;\n&lt;h3 id=\&#34;simula-classes\&#34;&gt;SIMULA Classes&lt;/h3&gt;\n&lt;p&gt;在行驶时，最接近的语言是 SIMULA 67。SIMULA 类定义与 cluster 定义有很多相似之处。然而，这两种语言有一个非常重要的哲学差异，这导致了几个重要的语言差异。SIMULA 的类被设计用来表示和提供对数据对象的完全访问。类中的每个属性和函数都可以在嵌入类定义的块中访问。因此，用户总是知道 representation 的实际形式。&lt;/p&gt;\n&lt;p&gt;与此相反，cluster 的 representation 在 cluster 之外是不可访问的。cluster 中的操作提供了访问 representation 内容的唯一访问，即使这样，也只有 cluster 的定义的操作的一个子集可以从外部访问。由于这种哲学上的差异，两种语言中引用数据的机制、非局部变量引用的使用以及块和块结构的使用都有很大的不同。&lt;/p&gt;\n&lt;h2 id=\&#34;implementation-considerations\&#34;&gt;Implementation Considerations&lt;/h2&gt;\n&lt;p&gt;cluster 实现的大部分方面都和常规处理方式一样。然而，该实现有几个方面值得特别提及，因为它们是和常规实现不同的，或者对使用 cluster 来表示抽象数据的实用性有重大影响。&lt;/p&gt;\n&lt;h3 id=\&#34;modules-and-module-names\&#34;&gt;Modules and Module-Names&lt;/h3&gt;\n&lt;p&gt;编译器接收一个模块作为输入。模块通常是一个 cluster，但有时也会是一个过程，如 &lt;code&gt;Polish_gen&lt;/code&gt; 或 &lt;code&gt;scan&lt;/code&gt;。在模块转换的过程中，会遇到外部定义的模块名，用来指代过程和数据类型。（请注意，对抽象数据类型上操作的引用不会引入任何额外的外部引用，因为它们是相对于操作名前缀的抽象类型。）&lt;/p&gt;\n&lt;p&gt;当编译器处理一个模块时，它会构建或添加一个描述单元(description-unit)，该描述单元包含关于该模块的信息。描述单元中包含的信息包括：&lt;/p&gt;\n&lt;ol&gt;\n&lt;li&gt;由编译器生成的目标代码的位置。&lt;/li&gt;\n&lt;li&gt;模块对其用户可用的接口的描述。特别是，维护关于模块期望的所有参数和值类型的完整信息。如果该模块是一个 cluster，则将保留 cluster 中每个操作的信息。&lt;/li&gt;\n&lt;li&gt;使用该模块的所有模块的列表。&lt;br&gt;\n显然更多信息可以存储在描述单元：以符号表等形式调试信息，文档信息，以输入/输出关系的谓词演算描述的形式，甚至是基本原理的分析对于设计模块的决定。&lt;/li&gt;\n&lt;/ol&gt;\n&lt;p&gt;描述单元(description unit)是关于模块的所有信息的焦点。它可以在处理模块时创建，也可以创建为其他模块引用的目标。在处理描述单元所代表的的模块之前创建描述单元支持自顶向下设计，并提供了一种定义递归的简单方法。由于描述单元保存了所有使用模块的列表，所以当模块实际定义时，可以检查使用和定义的一致性，并在那时生成适当的错误消息。实际的定义可能会延迟一段时间，因为描述单元可以用来定位代码，以模拟模块的行为，已达到调试的目的。&lt;/p&gt;\n&lt;p&gt;在翻译（编译）模块的过程中，翻译器必须将每个模块名绑定到对应模块的代码，从而为每个模块名赋予含义。这是通过描述单元完成的。翻译程序通过一个目录获得对描述单元的访问，该目录包含一组 module-name/description unit pair，它将其作为参数接收。所有外部引用都必须通过此目录解析；如果无法解析它们，则生成适当的错误消息。&lt;/p&gt;\n&lt;p&gt;该目录是一个用户构造的对象，一般来说，构建该对象是为了控制一组特定相关模块的翻译。实际的描述单元存储在一个类似于 MULTICS 文件系统的多级树形文件系统中，对于目录中描述单元的引用实际上是对这个文件系统的引用。用于构造目录和操作文件的原语独立于语言，形成了 &amp;quot;file system cluster&amp;quot; 和 &amp;quot;directory cluster&amp;quot;。&lt;/p&gt;\n&lt;h3 id=\&#34;type-checking\&#34;&gt;Type Checking&lt;/h3&gt;\n&lt;p&gt;本文中描述的语言是基于强类型检查的思想，语言翻译器应该在两个独立编程过程之间的接口上执行强类型检查。在本节中，我们将讨论由强类型检查引起的一些问题。&lt;/p&gt;\n&lt;p&gt;强类型检查意味着，每当一个对象从调用函数传递到被调用函数时，它的类型必须与被调用函数中声明的类型兼容。如果被调用的函数是一个过程，则类型必须完全匹配。如果被调用的函数是一个操作，那么类型必须完全匹配，除非对象是由该操作所属的 cluster 定义的抽象类型。在本例中，对象的类型更改为该 cluster 的 rep 类型。因此，类型检查机制控制对象的 representation 是否对给定的操作可见。在这种情况下，如果类型错误未被检测到，则应该在 cluster 之外不可访问的信息将变为可访问的，程序模块化将被破坏。&lt;/p&gt;\n&lt;p&gt;这种语言中的类型检查比大多数传统语言中的要复杂。这是因为用户定义的抽象，包括数据类型和过程，都可以使用类型作为参数。考虑上面定义的数据类型 stack 。我们已经注意到 stack 和数组之间的相似性：在每种情况下，都必须在创建实例之前提供结果组件的类型规范。构造器(constructs)，如 stack 和 array，被称为类型生成器(tyoe generators)，因为它们定义了一个 class 类型(type of class)，而不是单个类型。类中的每个单独类型都是通过为类型生成器的每个类型参数提供类型定义来生成的。类型生成器（如 stack）是为了满足未来用户的需要而创建的，它定义一个开放的类型类，并且在编译 stack cluster 时不知道其他 class 类型的成员。&lt;/p&gt;\n&lt;p&gt;允许用户定义类型生成器的影响之一是，cluster 中针对该 “类型” 的一些操作是多态的(polymorphic)；也就是说，操作可以在许多不同的类型域(type domains)上定义，这会受到任何给定的参数集的类型是类型一致的(type-consistent)约束。这种操作的一个例子是 stack cluster 中的 push 操作。push 的操作数是一个 stack 和一个值。push 的类型一致性要求是，如果 stack 的类型是 &amp;quot;stack of T&amp;quot;，那么 push 的值必须是 T 类型；因此，操作 push 的强类型检查包括确定其 stack 参数是否真的是一个 stack、确定 stack 参数的类型、确定被 push 值的类型以及确定它们是否满足一致性要求。&lt;/p&gt;\n&lt;p&gt;最好进行编译时类型检查，因为类型错误可以尽早检测到。然而，由于在语言中可以自由地使用类型，编译时类型检查可以有多完整还不清楚。因此，该语言的设计是基于运行时类型检查机制的，该机制通过尽可能多的编译时检查进行扩充。&lt;/p&gt;\n&lt;p&gt;很明显，给定合适的 representation 类型表示形式，就可以编写运行时检查是否具有相同匹配的类型。导致对象的 representation 暴露给操作的那种类型检查可以在运行时通过 Morris I0 描述的技术来处理，该技术是操作系统汇总保护工作的产物。（cluster 和受保护的子系统之间有很强的相关性；cluster提供了封装私有信息的自然机制。）&lt;/p&gt;\n&lt;p&gt;在未来，我们也许可以不用运行时机制，因为 John Reynolds 最近的工作表明，完整的编译时类型检查是可能的。我们期待 Reynolds 的工作的完成，并打算在不久的将来设计一个基于编译时类型检查的语言版本。&lt;/p&gt;\n&lt;h3 id=\&#34;retention\&#34;&gt;Retention&lt;/h3&gt;\n&lt;p&gt;该语言被设计成允许使用 stack 规则(discipline)实现 cluster、procedure 和 operation 的激活。cluster、procedure 和 operation 在执行时没有自由变量，其中定义的所有变量都是纯本地的。要保留或共享的所有信息都必须存储在对象的 representation 中。在使用保留策略的堆中分配对象。在实践中，有许多容易识别的情况， 对象不需要放在堆中，而是可以在 stack 上分配，要么是因为对象不共享，要么是因为一旦分配了对象，其内容就永远不会更改。这些情况可以由语言翻译（编译）人员进行优化。&lt;/p&gt;\n&lt;h3 id=\&#34;efficiency\&#34;&gt;Efficiency&lt;/h3&gt;\n&lt;p&gt;我们认为将两个结构与一个程序相联系是有帮助的：它的逻辑结构(logical structure)和物理结构(physical structure)。程序员的主要任务是构建一个具有良好逻辑结构的程序——一个易于理解、易于修改和维护的程序。然而，一个好的逻辑结构并不一定意味着一个好的物理结构——一个有效执行的物理结构。事实上，用于实现良好逻辑结构（层次结构，仅通过函数访问数据等）的技术在许多情况下似乎意味着糟糕的物理结构。&lt;/p&gt;\n&lt;p&gt;我们相信编译器的任务是把好的逻辑结构映射成好的物理结构。这两个结构可能有差异的事实是可以接受的，前提是编译器被验证了，并且所有编程工具（例如，调试工具）都被定义为隐藏差异。&lt;/p&gt;\n&lt;p&gt;该语言旨在优化编译器进行编译，从而在输出代码中实现良好的物理结构。语言对于操作调用的一样具有灵活性，这一事实可以获得一个重要的效率。每个操作调用可以被对应操作的实际调用或操作的内联代码替换。语言设计的两个方面使得这种灵活性成为可能：&lt;/p&gt;\n&lt;ol&gt;\n&lt;li&gt;因为操作调用的语法在两种情况下都是相同的，所以可以更改所使用的编译技术，而无需重写使用操作符的过程。&lt;/li&gt;\n&lt;li&gt;cluster 的不变部分——操作代码——已经被小心地与 rep 分开，rep 保存着依赖于对象的信息；因此，代码的内联嵌入(inline insertion)是可能的。&lt;/li&gt;\n&lt;/ol&gt;\n&lt;p&gt;操作代码的内联插入允许该代码受编译器中可用的优化转换(optimization transformations)。优化转换，例如编译时间评估和常见的子表达式消除，删除冗余计算，从而降低执行操作所需的时间。例如，如果在 &lt;code&gt;Polish_gen&lt;/code&gt; 中插入哪些操作，则可以消除 stack cluster 操作中的所有错误检查。这些标准优化技术应该非常有效，因为编译器正在处理结构化程序；缺乏自由变量，以及 goto 和其他混乱的控制结构意味着可以执行彻底的数据和控制流程分析。换句话说，编译器可以从程序的良好逻辑结构中受益，以获得对它的彻底了解，就像一个人一样。&lt;/p&gt;\n&lt;p&gt;获得这种执行时间优化的代价是增加了重新定义或修改模块的成本。每次这样的修改都可能需要重新编译使用内联修改函数的模块。由于使用内联代码的决定可能会延迟，直到性能测量表明系统的哪些部分是关机的，因此只有当内联代码会带来积极的性能好处时，才需要放弃简单的程序修改的灵活性。请注意，保存在描述单元中的模块的使用列表可能用于在进行更改时自动重新编译。&lt;/p&gt;\n&lt;h2 id=\&#34;conclusions\&#34;&gt;Conclusions&lt;/h2&gt;\n&lt;p&gt;本文描述了一种新的抽象——抽象数据类型，它增强类我们利用抽象构建程序的能力。这种方法作为一个概念和编程语言的一部分进行了讨论。给出了几个应用实例。抽象数据类型被定义为一类对象，其特征完全是对这些对象执行的操作。为了提供对抽象数据类型的编程语言支持，引入了一种新的语言结构—— operation cluster。&lt;/p&gt;\n&lt;p&gt;开发该语言背后的根本原因是，通过提供一种语言来表达程序设计过程中暴露的抽象，从而使结构化编程的时间更容易理解。我们认为抽象数据类型的概念以一种对程序员最有用的形式提供了数据抽象：他只需要知道抽象对象的行为，这正是他编写程序所需要的信息，而有关对象在存储中如何表示以及操作如何实现的无关细节对他来说是隐藏的。事实上，他无法利用实现细节，从而导致了程序质量的改进：程序将更加模块化，更容易理解、修改、维护和证明其正确性。&lt;/p&gt;\n&lt;p&gt;当然，程序的质量在很大程度上决定于好的程序设计。尽管一门语言永远不能教会程序员什么构成了一个良好的程序，但它可以引导他思考正确的事情。我们相信抽象是优秀设计的关键，并且我们在使用该语言的实验中发现，它鼓励程序员有意识的寻找抽象，特别是数据抽象，并认真思考它们的使用和定义。&lt;/p&gt;\n&lt;p&gt;我们相信，本文中讨论的抽象方法可以有效地整合到许多不同类型的语言中。任何一种语言，无论多高级，都不可能包含任何使用它的人所需要的所有抽象。因此，本文中描述的抽象构建机制(abstraction-building-mechanism)将是一种非常高级的语言的有用特性。&lt;/p&gt;\n&lt;h2 id=\&#34;acknowledgements\&#34;&gt;Acknowledgements&lt;/h2&gt;\n&lt;p&gt;作者非常感谢Jack Dennis、Austin Henderson、Greg Pflster和其他推荐人对论文的内容和结构所作的有益的评论。&lt;/p&gt;\n&lt;h2 id=\&#34;references\&#34;&gt;References&lt;/h2&gt;\n&lt;ol&gt;\n&lt;li&gt;Wirth, N. The progranmting language PASCAL. Acta Informatica, Vol. I (1971), pp 35-63.&lt;/li&gt;\n&lt;li&gt;Parnas, D.L. Information distribution aspects of design methodology, Proceedings of the IFIP Congress, August 1971.&lt;/li&gt;\n&lt;li&gt;DiJkstra, E. W. Notes on structured programming. Structured Programming, A.P.I.C. Studies in Data Processing, No. 8, Academic Press, New York, 1972, pp 1-81.&lt;/li&gt;\n&lt;li&gt;Schuman, S. A. and P. Jorrand. Definition mechanisms in extensible programming languages. Proceedings of the AFIPS, Vol. 37, 1970, pp 9-19.&lt;/li&gt;\n&lt;li&gt;Mealy, G. Another look at data. Proceedings of the AFIPS, Vol. 31, 1967, pp 525-534.&lt;/li&gt;\n&lt;li&gt;Balzer, R. M. Dataless programming. Proceedings of the AFIPS, Vol. 31, 1967, pp 557-566.&lt;/li&gt;\n&lt;li&gt;Earley, J. Toward an understanding of data structures. Comm. of the ACM, Vol. 14, No. I0 (October 1971), pp 617-627.&lt;/li&gt;\n&lt;li&gt;Dahl, O.-J., B. Myhrhaug, and K. Nygaard. The SIMULA 67 Common Base Language. Norwegian Computing Center, Oslo, Publication S-22, 1970.&lt;/li&gt;\n&lt;li&gt;Daley, R. C., and P. G. Neumann. A general purpose file system for secondary storage. Proceedings of the AFIPS, Vol. 27, 1965, pp 213-229.&lt;/li&gt;\n&lt;li&gt;Morris, J. H., Jr. Protection in programming languages. Comm. of the ACM, Vol. 16, No. i (January 1973), pp 15-21.&lt;/li&gt;\n&lt;li&gt;Zilles, S. N. Procedural encapsulation: a linguistic protection technique. SIGPLAN Notices, Vol. 8, No. 9 (September 1973), pp 140-146.&lt;/li&gt;\n&lt;li&gt;Reynolds, J. Personal communication.&lt;/li&gt;\n&lt;li&gt;Liskov, B. H. A design methodology for reliable software systems. Proceedings of the AFIPS, Vol. 41, 1972, pp 191-199.&lt;/li&gt;\n&lt;/ol&gt;\n&lt;h2 id=\&#34;本文来源\&#34;&gt;本文来源&lt;/h2&gt;\n&lt;p&gt;PROGRAMMING WITH ABSTRACT DATA TYPES&lt;br&gt;\nBarbara Liskov Massachusetts Institute of Technology Project MAC&lt;br&gt;\nCambridge， Massachusetts&lt;br&gt;\nStephen Zilles Cambridge Systems Group&lt;br&gt;\nIBM Systems Development Division Cambridge， Massachusetts&lt;/p&gt;\n&lt;p&gt;原文：&lt;a href=\&#34;/Users/wenbo.zhang/Library/CloudStorage/OneDrive-%E4%B8%AA%E4%BA%BA/Gridea/post-file/liskov1974.pdf\&#34;&gt;Programming with abstract data types&lt;/a&gt;&lt;/p&gt;\n&#34;,&#34;fileName&#34;:&#34;programming-with-abstract-data-types&#34;,&#34;abstract&#34;:&#34;&lt;p&gt;使用高级语言进行工作的动机是通过为程序员提供一种包含适合其问题领域的原语(primitives)或抽象(abstractions)的语言来简化编程任务。这样程序员就可以把精力花费在正确的地方；程序员可以专注于解决他的问题，结果程序将更加可靠。显然，这是一个值得实现的目标。&lt;/p&gt;\n&lt;p&gt;不幸的是，设计师很难提前选择使用该语言的用户可能需要的所有抽象(abstractions)。如果要使用一种语言，它很可能会被用来解决设计者没有预见到的问题，而且这种语言中嵌入的抽象可能并不足以解决这些问题。&lt;/p&gt;\n&lt;p&gt;本文提出了一种方法，当发现需要新的数据抽象时，可以扩展内置的抽象集。这种处理抽象的方法是为结构化编程设计语言的产物。本文描述了这种语言的相关方面，并给出了抽象的用法和定义的实例。&lt;/p&gt;\n&#34;,&#34;title&#34;:&#34;Programming with abstract data types&#34;,&#34;tags&#34;:[{&#34;index&#34;:-1,&#34;name&#34;:&#34;programming concept&#34;,&#34;slug&#34;:&#34;60uU_0nib&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://wenbozhangw.github.io/tag/60uU_0nib/&#34;}],&#34;date&#34;:&#34;2022-01-20 10:29:13&#34;,&#34;dateFormat&#34;:&#34;2022-01-20&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://wenbozhangw.github.io/post/programming-with-abstract-data-types/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;43 min read&#34;,&#34;time&#34;:2523000,&#34;words&#34;:11756,&#34;minutes&#34;:43},&#34;description&#34;:&#34;使用高级语言进行工作的动机是通过为程序员提供一种包含适合其问题领域的原语(primitives)或抽象(abstractions)的语言来简化编程任务。这样程序员就可以把精力花费在正确的地方；程序员可以专注于解决他的问题，结果程序将更加可靠...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#introduction\&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#the-meaning-of-abstraction\&#34;&gt;The Meaning of Abstraction&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#the-programming-language\&#34;&gt;The Programming Language&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#using-abstract-data-types\&#34;&gt;Using Abstract Data Types&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#defining-abstract-data-types\&#34;&gt;Defining Abstract Data Types&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#controlling-the-use-of-information\&#34;&gt;Controlling the Use of Information&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#relationship-to-previous-work\&#34;&gt;Relationship to Previous Work&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#extensible-languages\&#34;&gt;Extensible Languages&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#standard-abstract-operations\&#34;&gt;Standard Abstract Operations&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#simula-classes\&#34;&gt;SIMULA Classes&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#implementation-considerations\&#34;&gt;Implementation Considerations&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#modules-and-module-names\&#34;&gt;Modules and Module-Names&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#type-checking\&#34;&gt;Type Checking&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#retention\&#34;&gt;Retention&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#efficiency\&#34;&gt;Efficiency&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#conclusions\&#34;&gt;Conclusions&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#acknowledgements\&#34;&gt;Acknowledgements&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#references\&#34;&gt;References&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%9C%AC%E6%96%87%E6%9D%A5%E6%BA%90\&#34;&gt;本文来源&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;p&gt;Aerospike 建议您监控此处列出的指标。 有关指标的完整列表，请参阅 &lt;a href=\&#34;https://docs.aerospike.com/reference/metrics\&#34;&gt;Metric Reference&lt;/a&gt; 。&lt;/p&gt;\n&lt;!-- more --&gt;\n&lt;p&gt;除了监控 Aerospike 服务器的运行状况，您还应该监控集群服务器的硬件资源，例如可用磁盘空间、可用 RAM、交换和 CPU 使用率。&lt;/p&gt;\n&lt;h2 id=\&#34;推荐的警报指标\&#34;&gt;推荐的警报指标&lt;/h2&gt;\n&lt;h3 id=\&#34;clock_skew_stop_writes\&#34;&gt;clock_skew_stop_writes&lt;/h3&gt;\n&lt;p&gt;位置：Namespace&lt;br&gt;\n版本：4.0&lt;br&gt;\n说明：如果 &lt;a href=\&#34;https://docs.aerospike.com/reference/metrics#clock_skew_stop_writes\&#34;&gt;clock_skew_stop_writes&lt;/a&gt; 为 &lt;code&gt;true&lt;/code&gt;，发出严重报警。&lt;br&gt;\n确保时钟在集群中同步。&lt;/p&gt;\n&lt;h3 id=\&#34;dead_partitions\&#34;&gt;dead_partitions&lt;/h3&gt;\n&lt;p&gt;位置：Namespace&lt;br&gt;\n版本：4.0&lt;br&gt;\n说明：如果 &lt;a href=\&#34;https://docs.aerospike.com/reference/metrics#dead_partitions\&#34;&gt;dead_partitions&lt;/a&gt; 不为零，发出严重报警。&lt;br&gt;\n如果您确定不存在潜在的数据不一致，或者数据不一致是可以接受的，请考虑发出 &lt;a href=\&#34;https://docs.aerospike.com/reference/info#revive\&#34;&gt;revive&lt;/a&gt; 和 &lt;a href=\&#34;https://docs.aerospike.com/reference/info#recluster\&#34;&gt;recluster&lt;/a&gt; 命令。&lt;/p&gt;\n&lt;h3 id=\&#34;device_available_pct\&#34;&gt;device_available_pct&lt;/h3&gt;\n&lt;p&gt;位置：Namespace&lt;br&gt;\n版本：3.9&lt;br&gt;\n说明：如果 &lt;a href=\&#34;https://docs.aerospike.com/reference/metrics#device_available_pct\&#34;&gt;device_available_pct&lt;/a&gt; 低于 20%，则应该对操作组员告警。这种情况可能表明碎片整理无法跟上当前负载。&lt;br&gt;\n如果  &lt;a href=\&#34;https://docs.aerospike.com/reference/metrics#device_available_pct\&#34;&gt;device_available_pct&lt;/a&gt; 低于 15%，应该发出严重报警。&lt;br&gt;\n如果  &lt;a href=\&#34;https://docs.aerospike.com/reference/metrics#device_available_pct\&#34;&gt;device_available_pct&lt;/a&gt; 低于 5%，则可用磁盘资源非常低。这种情况可能会导致 &lt;a href=\&#34;https://docs.aerospike.com/reference/metrics#stop_writes\&#34;&gt;stop_writes&lt;/a&gt; 。&lt;/p&gt;\n&lt;h3 id=\&#34;hwm_breached\&#34;&gt;hwm_breached&lt;/h3&gt;\n&lt;p&gt;位置：Namespace&lt;br&gt;\n版本：3.9&lt;br&gt;\n说明：如果 &lt;a href=\&#34;https://docs.aerospike.com/reference/metrics#hwm_breached\&#34;&gt;hwm_breached&lt;/a&gt; 为 &lt;code&gt;true&lt;/code&gt;，应该提醒您的操作组员内存或磁盘资源紧张。这种情况可能表明需要增加集群容量。&lt;/p&gt;\n&lt;h3 id=\&#34;memory_free_pct\&#34;&gt;memory_free_pct&lt;/h3&gt;\n&lt;p&gt;位置：Namespace&lt;br&gt;\n版本：3.9&lt;br&gt;\n说明：如果 &lt;code&gt;memory_free_pct&lt;/code&gt; 接近 &lt;code&gt;high-water-memory-pct&lt;/code&gt; 或 &lt;code&gt;stop-writes-pct&lt;/code&gt; 的配置值，应该发出报警调查问题原因。出现这个问题可能表明需要减少对象数量或增加容量，如果使用二级索引，则可能需要进一步调查 &lt;code&gt;memory_used_sindex_bytes&lt;/code&gt;，如果使用 Set 索引，则需要进一步调查 &lt;code&gt;memory_used_set_index_bytes&lt;/code&gt;，如果数据存储在内存中，则需要调查 &lt;code&gt;heap_efficiency_pct&lt;/code&gt;。&lt;/p&gt;\n&lt;h3 id=\&#34;pmem_available_pct\&#34;&gt;pmem_available_pct&lt;/h3&gt;\n&lt;p&gt;位置：Namespace&lt;br&gt;\n版本：4.8&lt;br&gt;\n说明：如果 &lt;a href=\&#34;https://docs.aerospike.com/reference/metrics#pmem_available_pct\&#34;&gt;pmem_available_pct&lt;/a&gt; 低于 20%，应该警告您的操作组员。这种情况可能表明碎片整理无法跟上当前负载。&lt;br&gt;\n如果  &lt;a href=\&#34;https://docs.aerospike.com/reference/metrics#pmem_available_pct\&#34;&gt;pmem_available_pct&lt;/a&gt; 低于 15%，应该发出严重报警。&lt;br&gt;\n如果  &lt;a href=\&#34;https://docs.aerospike.com/reference/metrics#pmem_available_pct\&#34;&gt;pmem_available_pct&lt;/a&gt;  低于 5%，则可用 PMEM 资源非常低。这种情况可能会导致 &lt;a href=\&#34;https://docs.aerospike.com/reference/metrics#stop_writes\&#34;&gt;stop_writes&lt;/a&gt; 。&lt;/p&gt;\n&lt;h3 id=\&#34;unavailable_partitions\&#34;&gt;unavailable_partitions&lt;/h3&gt;\n&lt;p&gt;位置：Namespace&lt;br&gt;\n版本：4.0&lt;br&gt;\n说明：如果 &lt;a href=\&#34;https://docs.aerospike.com/reference/metrics#unavailable_partitions\&#34;&gt;unavailable_partitions&lt;/a&gt; 不为零，应该严重报警。&lt;br&gt;\n检查网络问题并确保集群正确形成。&lt;/p&gt;\n&lt;h3 id=\&#34;client_connections\&#34;&gt;client_connections&lt;/h3&gt;\n&lt;p&gt;位置：Statistics&lt;br&gt;\n说明：如果 &lt;code&gt;client_connections&lt;/code&gt; 低于预期的低值， 那么这种情况可能表明客户端和服务器之间的网络存在问题。&lt;br&gt;\n如果 &lt;code&gt;client_connections&lt;/code&gt; 高于预期的高值， 那么这种情况可能表明客户端快速打开和关闭套接字存在问题。&lt;br&gt;\n如果 &lt;code&gt;client_connections&lt;/code&gt; 处于或接近 &lt;a href=\&#34;https://docs.aerospike.com/reference/metrics#proto_fd_max\&#34;&gt;proto_fd_max&lt;/a&gt; ， 那么 Aerospike 服务器要么当前无法接受新连接，要么很快就无法接受。&lt;/p&gt;\n&lt;h3 id=\&#34;client_connections_opened\&#34;&gt;client_connections_opened&lt;/h3&gt;\n&lt;p&gt;位置：Statistics&lt;br&gt;\n版本：5.6&lt;br&gt;\n说明：如果 &lt;code&gt;client_connections_opened&lt;/code&gt; 在没有添加或删除客户端的情况下发生意外更改，或者工作负载发生了重大变化， 那么这种情况可能表明节点速度变慢或节点出现连接问题。&lt;/p&gt;\n&lt;h3 id=\&#34;cluster_size\&#34;&gt;cluster_size&lt;/h3&gt;\n&lt;p&gt;位置：Statistics&lt;br&gt;\n说明：如果 &lt;a href=\&#34;https://docs.aerospike.com/reference/metrics#cluster_size\&#34;&gt;cluster_size&lt;/a&gt; 不等于预期的集群大小并且集群没有进行维护， 那么您的运营团队需要进行调查。&lt;/p&gt;\n&lt;h3 id=\&#34;fabric_connections_opened\&#34;&gt;fabric_connections_opened&lt;/h3&gt;\n&lt;p&gt;位置：Statistics&lt;br&gt;\n版本：5.6&lt;br&gt;\n说明：如果 &lt;code&gt;fabric_connections_opened&lt;/code&gt; 发生意外变化，应该发出警报，因为这种情况表明节点或集群更改存在连接问题。&lt;/p&gt;\n&lt;h3 id=\&#34;heartbeat_connections_opened\&#34;&gt;heartbeat_connections_opened&lt;/h3&gt;\n&lt;p&gt;位置：Statistics&lt;br&gt;\n版本：5.6&lt;br&gt;\n说明：如果 &lt;code&gt;heartbeat_connections_opened&lt;/code&gt; 发生意外变化，应该发出警报，因为这种情况表明节点或集群更改存在连接问题。&lt;/p&gt;\n&lt;h3 id=\&#34;system_free_mem_kbytes\&#34;&gt;system_free_mem_kbytes&lt;/h3&gt;\n&lt;p&gt;位置：Statistics&lt;br&gt;\n说明：如果 &lt;code&gt;system_free_mem_kbytes&lt;/code&gt; 异常低， 那么这种情况表明服务器达​​到了可用 RAM 的限制。操作员应调查并可能需要添加节点或增加每个节点的 RAM。&lt;/p&gt;\n&lt;h3 id=\&#34;system_free_mem_pct\&#34;&gt;system_free_mem_pct&lt;/h3&gt;\n&lt;p&gt;位置：Statistics&lt;br&gt;\n说明：如果 &lt;code&gt;system_free_mem_pct&lt;/code&gt; 异常低， 那么这种情况表明服务器达​​到了可用 RAM 的限制。操作员应调查并可能需要添加节点或增加每个节点的 RAM。&lt;/p&gt;\n&lt;h3 id=\&#34;lag\&#34;&gt;lag&lt;/h3&gt;\n&lt;p&gt;位置：XDR - DC&lt;br&gt;\n版本：5.0.0&lt;br&gt;\n说明：如果 &lt;a href=\&#34;https://docs.aerospike.com/reference/metrics#lag\&#34;&gt;lag&lt;/a&gt; 始终大于几秒， 那么这种情况可能表明网络连接问题或目标集群写入错误。&lt;/p&gt;\n&lt;hr&gt;\n&lt;h2 id=\&#34;其他监控指标\&#34;&gt;其他监控指标&lt;/h2&gt;\n&lt;h3 id=\&#34;client_delete_error\&#34;&gt;client_delete_error&lt;/h3&gt;\n&lt;p&gt;位置：Namespace&lt;br&gt;\n版本：3.9&lt;br&gt;\n说明：&lt;code&gt;client_delete_error&lt;/code&gt; 与 &lt;code&gt;client_delete_success&lt;/code&gt; 比例。 如果比率高于可接受的， 然后警报操作员进行调查。&lt;/p&gt;\n&lt;h3 id=\&#34;client_read_error\&#34;&gt;client_read_error&lt;/h3&gt;\n&lt;p&gt;位置：Namespace&lt;br&gt;\n版本：3.9&lt;br&gt;\n说明：&lt;code&gt;client_read_error&lt;/code&gt; 与 &lt;code&gt;client_read_success&lt;/code&gt;  比例。 如果比率高于可接受的， 然后警报操作员进行调查。&lt;/p&gt;\n&lt;h3 id=\&#34;client_udf_error\&#34;&gt;client_udf_error&lt;/h3&gt;\n&lt;p&gt;位置：Namespace&lt;br&gt;\n版本：3.9&lt;br&gt;\n说明：&lt;code&gt;client_udf_error&lt;/code&gt; 与 &lt;code&gt;client_udf_complete&lt;/code&gt; 比例。 如果比率高于可接受的， 然后警报操作员进行调查。&lt;/p&gt;\n&lt;h3 id=\&#34;client_write_error\&#34;&gt;client_write_error&lt;/h3&gt;\n&lt;p&gt;位置：Namespace&lt;br&gt;\n版本：3.9&lt;br&gt;\n说明：&lt;code&gt;client_write_error&lt;/code&gt; 与 &lt;code&gt;client_write_success&lt;/code&gt; 比例。 如果比率高于可接受的， 然后警报操作员进行调查。有关更多详细信息，请参阅 &lt;a href=\&#34;https://discuss.aerospike.com/t/understanding-client-write-errors/4442\&#34;&gt;Understanding Client Write Errors&lt;/a&gt;。&lt;/p&gt;\n&lt;h3 id=\&#34;index_flash_alloc_pct\&#34;&gt;index_flash_alloc_pct&lt;/h3&gt;\n&lt;p&gt;位置：Namespace&lt;br&gt;\n版本：5.6&lt;br&gt;\n说明：如果 &lt;code&gt;index_flash_alloc_pct&lt;/code&gt; 接近或高于 100%，应该提醒操作员检查命名空间的大小。&lt;/p&gt;\n&lt;h3 id=\&#34;memory_used_bytes\&#34;&gt;memory_used_bytes&lt;/h3&gt;\n&lt;p&gt;位置：Namespace&lt;br&gt;\n版本：3.9&lt;br&gt;\n说明：&lt;a href=\&#34;https://docs.aerospike.com/reference/metrics#used-bytes-memory\&#34;&gt;used-bytes-memory&lt;/a&gt; 的趋势提现，可让操作员深入了解此命名空间的内存使用情况如何随时间变化。&lt;/p&gt;\n&lt;h3 id=\&#34;scan-aggr-error\&#34;&gt;scan-aggr-error&lt;/h3&gt;\n&lt;p&gt;位置：Namespace&lt;br&gt;\n版本：3.9&lt;br&gt;\n说明：&lt;code&gt;scan_aggr_error&lt;/code&gt; 和 &lt;code&gt;scan_aggr_complete&lt;/code&gt; 比例。如果比率高于可接受的， 然后警报操作员进行调查。&lt;/p&gt;\n&lt;h3 id=\&#34;scan_basic_error\&#34;&gt;scan_basic_error&lt;/h3&gt;\n&lt;p&gt;位置：Namespace&lt;br&gt;\n版本：3.9&lt;br&gt;\n说明：&lt;code&gt;scan_basic_error&lt;/code&gt; 和 &lt;code&gt;scan_basic_complete&lt;/code&gt; 比例。如果比率高于可接受的， 然后警报操作员进行调查。&lt;/p&gt;\n&lt;h3 id=\&#34;scan_ops_bg_error\&#34;&gt;scan_ops_bg_error&lt;/h3&gt;\n&lt;p&gt;位置：Namespace&lt;br&gt;\n版本：4.7&lt;br&gt;\n说明：&lt;code&gt;scan_udf_bg_error&lt;/code&gt; 和 &lt;code&gt;scan_udf_bg_complete&lt;/code&gt; 比例。如果比率高于可接受的， 然后警报操作员进行调查。&lt;/p&gt;\n&lt;h3 id=\&#34;storage-enginedeviceixdefrag_q\&#34;&gt;storage-engine.device[ix].defrag_q&lt;/h3&gt;\n&lt;p&gt;位置：Namespace&lt;br&gt;\n版本：4.3&lt;br&gt;\n说明：根据存储配置，按照设备或按文件测算。如果 &lt;code&gt;storage-engine.device[ix].defrag_q&lt;/code&gt; 或 &lt;code&gt;storage-engine.file[ix].defrag_q&lt;/code&gt; 随着时间的推移继续增加， 然后提醒操作人员调查原因。&lt;/p&gt;\n&lt;h3 id=\&#34;storage-enginefileixwrite_q\&#34;&gt;storage-engine.file[ix].write_q&lt;/h3&gt;\n&lt;p&gt;位置：Namespace&lt;br&gt;\n版本：4.3&lt;br&gt;\n说明：根据存储配置，按照设备或按文件测算。如果 &lt;code&gt;storage-engine.device[ix].write_q&lt;/code&gt; 或 &lt;code&gt;storage-engine.file[ix].write_q&lt;/code&gt; 大于 1， 然后提醒操作人员调查原因。&lt;/p&gt;\n&lt;h3 id=\&#34;batch_index_error\&#34;&gt;batch_index_error&lt;/h3&gt;\n&lt;p&gt;位置：Statistics&lt;br&gt;\n版本：3.9&lt;br&gt;\n说明：将 &lt;code&gt;batch_index_error&lt;/code&gt; 与 &lt;code&gt;batch_index_complete&lt;/code&gt; 进行比较，如果比率高于可接受的，应该警报操作员以进行调查。&lt;/p&gt;\n&lt;h3 id=\&#34;heap_efficiency_pct\&#34;&gt;heap_efficiency_pct&lt;/h3&gt;\n&lt;p&gt;位置：Statistics&lt;br&gt;\n版本：3.10.1&lt;br&gt;\n说明：如果 &lt;code&gt;heap_efficiency_pct&lt;/code&gt; 低于 60% 或 50%（取决于配置，然后建议您的运营小组进行调查。）&lt;/p&gt;\n&lt;h3 id=\&#34;rw_in_progress\&#34;&gt;rw_in_progress&lt;/h3&gt;\n&lt;p&gt;位置：Statistics&lt;br&gt;\n版本：3.9&lt;br&gt;\n说明：取决于预期的工作量。&lt;br&gt;\n如果 &lt;code&gt;rw_in_progress&lt;/code&gt; 高于预期，或者如果随着时间的推移偏离预期值，超出可接受范围， 应该提醒操作人员调查原因。可能表示特定节点速度变慢或 fabric 过载。&lt;/p&gt;\n&lt;h3 id=\&#34;abandoned\&#34;&gt;abandoned&lt;/h3&gt;\n&lt;p&gt;位置：XDR - DC&lt;br&gt;\n版本：5.0&lt;br&gt;\n说明：如果 &lt;a href=\&#34;https://docs.aerospike.com/reference/metrics#abandoned\&#34;&gt;abandoned&lt;/a&gt; 一直高于预期，应该提醒操作人员进行调查。&lt;/p&gt;\n&lt;h3 id=\&#34;lap_us\&#34;&gt;lap_us&lt;/h3&gt;\n&lt;p&gt;位置：XDR - DC&lt;br&gt;\n版本：5.0&lt;br&gt;\n说明：如果 &lt;a href=\&#34;https://docs.aerospike.com/reference/metrics#lap_us\&#34;&gt;lap_us&lt;/a&gt; 一直高于预期，应该提醒操作人员进行调查。&lt;/p&gt;\n&lt;h3 id=\&#34;latency_ms\&#34;&gt;latency_ms&lt;/h3&gt;\n&lt;p&gt;位置：XDR - DC&lt;br&gt;\n版本：5.0&lt;br&gt;\n说明：根据配置，&lt;code&gt;latency_ms&lt;/code&gt; 应该在 DC 之间链路的延迟范围内。如果 &lt;code&gt;delay_ms&lt;/code&gt; 在集群之间的延迟（或已知的链路延迟）增加超过预期， 应该警报操作员进行调查。&lt;/p&gt;\n&lt;h3 id=\&#34;recoveries\&#34;&gt;recoveries&lt;/h3&gt;\n&lt;p&gt;位置：XDR - DC&lt;br&gt;\n版本：5.0&lt;br&gt;\n说明：如果 &lt;a href=\&#34;https://docs.aerospike.com/reference/metrics#recoveries\&#34;&gt;recoveries&lt;/a&gt; 持续增加 ，应该警报操作人员进行调查。&lt;/p&gt;\n&lt;h3 id=\&#34;recoveries_pending\&#34;&gt;recoveries_pending&lt;/h3&gt;\n&lt;p&gt;位置：XDR - DC&lt;br&gt;\n版本：5.0&lt;br&gt;\n说明：如果 &lt;a href=\&#34;https://docs.aerospike.com/reference/metrics#recoveries_pending\&#34;&gt;recovery_pending&lt;/a&gt; 增加超出预期 ，应该警报操作人员进行调查。&lt;/p&gt;\n&lt;h3 id=\&#34;retry_conn_reset\&#34;&gt;retry_conn_reset&lt;/h3&gt;\n&lt;p&gt;位置：XDR - DC&lt;br&gt;\n版本：5.0&lt;br&gt;\n说明：如果 &lt;a href=\&#34;https://docs.aerospike.com/reference/metrics#retry_conn_reset\&#34;&gt;retry_conn_reset&lt;/a&gt; 增加超出预期 ，应该警报操作人员进行调查。&lt;/p&gt;\n&lt;h3 id=\&#34;retry_dest\&#34;&gt;retry_dest&lt;/h3&gt;\n&lt;p&gt;位置：XDR - DC&lt;br&gt;\n版本：5.0&lt;br&gt;\n说明：如果 &lt;a href=\&#34;https://docs.aerospike.com/reference/metrics#retry_dest\&#34;&gt;retry_dest&lt;/a&gt; 增加超出预期 ，应该警报操作人员进行调查。&lt;/p&gt;\n&lt;h3 id=\&#34;retry_no_node\&#34;&gt;retry_no_node&lt;/h3&gt;\n&lt;p&gt;位置：XDR - DC&lt;br&gt;\n版本：5.1&lt;br&gt;\n说明：如果 &lt;a href=\&#34;https://docs.aerospike.com/reference/metrics#retry_no_node\&#34;&gt;retry_no_node&lt;/a&gt; 增加超出预期 ，应该警报操作人员进行调查。&lt;/p&gt;\n&lt;h3 id=\&#34;success\&#34;&gt;success&lt;/h3&gt;\n&lt;p&gt;位置：XDR - DC&lt;br&gt;\n版本：5.0&lt;br&gt;\n说明：如果 &lt;a href=\&#34;https://docs.aerospike.com/reference/metrics#retry_no_node\&#34;&gt;success&lt;/a&gt; 低于预期 ，应该警报操作人员进行调查。&lt;/p&gt;\n&#34;,&#34;fileName&#34;:&#34;aerospike-guan-fang-jian-yi-jian-kong-zhi-biao&#34;,&#34;abstract&#34;:&#34;&lt;p&gt;Aerospike 建议您监控此处列出的指标。 有关指标的完整列表，请参阅 &lt;a href=\&#34;https://docs.aerospike.com/reference/metrics\&#34;&gt;Metric Reference&lt;/a&gt; 。&lt;/p&gt;\n&#34;,&#34;title&#34;:&#34;Aerospike 官方建议监控指标&#34;,&#34;tags&#34;:[{&#34;index&#34;:-1,&#34;name&#34;:&#34;Aerospike&#34;,&#34;slug&#34;:&#34;VSeqxthmr&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://wenbozhangw.github.io/tag/VSeqxthmr/&#34;}],&#34;date&#34;:&#34;2022-01-19 13:54:53&#34;,&#34;dateFormat&#34;:&#34;2022-01-19&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://wenbozhangw.github.io/post/aerospike-guan-fang-jian-yi-jian-kong-zhi-biao/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;8 min read&#34;,&#34;time&#34;:445000,&#34;words&#34;:1976,&#34;minutes&#34;:8},&#34;description&#34;:&#34;Aerospike 建议您监控此处列出的指标。 有关指标的完整列表，请参阅 Metric Reference 。\n\n除了监控 Aerospike 服务器的运行状况，您还应该监控集群服务器的硬件资源，例如可用磁盘空间、可用 RAM、交换和 C...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%8E%A8%E8%8D%90%E7%9A%84%E8%AD%A6%E6%8A%A5%E6%8C%87%E6%A0%87\&#34;&gt;推荐的警报指标&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#clock_skew_stop_writes\&#34;&gt;clock_skew_stop_writes&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#dead_partitions\&#34;&gt;dead_partitions&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#device_available_pct\&#34;&gt;device_available_pct&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#hwm_breached\&#34;&gt;hwm_breached&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#memory_free_pct\&#34;&gt;memory_free_pct&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#pmem_available_pct\&#34;&gt;pmem_available_pct&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#unavailable_partitions\&#34;&gt;unavailable_partitions&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#client_connections\&#34;&gt;client_connections&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#client_connections_opened\&#34;&gt;client_connections_opened&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#cluster_size\&#34;&gt;cluster_size&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#fabric_connections_opened\&#34;&gt;fabric_connections_opened&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#heartbeat_connections_opened\&#34;&gt;heartbeat_connections_opened&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#system_free_mem_kbytes\&#34;&gt;system_free_mem_kbytes&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#system_free_mem_pct\&#34;&gt;system_free_mem_pct&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#lag\&#34;&gt;lag&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%85%B6%E4%BB%96%E7%9B%91%E6%8E%A7%E6%8C%87%E6%A0%87\&#34;&gt;其他监控指标&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#client_delete_error\&#34;&gt;client_delete_error&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#client_read_error\&#34;&gt;client_read_error&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#client_udf_error\&#34;&gt;client_udf_error&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#client_write_error\&#34;&gt;client_write_error&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#index_flash_alloc_pct\&#34;&gt;index_flash_alloc_pct&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#memory_used_bytes\&#34;&gt;memory_used_bytes&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#scan-aggr-error\&#34;&gt;scan-aggr-error&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#scan_basic_error\&#34;&gt;scan_basic_error&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#scan_ops_bg_error\&#34;&gt;scan_ops_bg_error&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#storage-enginedeviceixdefrag_q\&#34;&gt;storage-engine.device[ix].defrag_q&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#storage-enginefileixwrite_q\&#34;&gt;storage-engine.file[ix].write_q&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#batch_index_error\&#34;&gt;batch_index_error&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#heap_efficiency_pct\&#34;&gt;heap_efficiency_pct&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#rw_in_progress\&#34;&gt;rw_in_progress&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#abandoned\&#34;&gt;abandoned&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#lap_us\&#34;&gt;lap_us&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#latency_ms\&#34;&gt;latency_ms&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#recoveries\&#34;&gt;recoveries&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#recoveries_pending\&#34;&gt;recoveries_pending&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#retry_conn_reset\&#34;&gt;retry_conn_reset&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#retry_dest\&#34;&gt;retry_dest&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#retry_no_node\&#34;&gt;retry_no_node&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#success\&#34;&gt;success&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;p&gt;监控对于一个组件和系统来说是必不可少的，通常情况下，一个全面健康监控可以帮助我们在出现生产事故之前即时发现问题，并处理掉，下面汇总一些个人对 Aerospike 使用中关注的监控指标。&lt;/p&gt;\n&lt;!-- more --&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#client_delete_error\&#34;&gt;client_delete_error&lt;/a&gt; ：客户端 delete transaction 错误失败的个数。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#client_delete_timeout\&#34;&gt;client_delete_timeout&lt;/a&gt; ：客户端 delete transaction 超时个数。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#client_read_error\&#34;&gt;client_read_error&lt;/a&gt; ：客户端 read transaction 错误个数。例如：无效 set 名称，不可用(SC模式)， predexp filter 失败，key 不存在，设备错误（I/O 错误），key busy（SC 重复解析），bitwise期间问题，HLL OR CDT。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#client_read_timeout\&#34;&gt;client_read_timeout&lt;/a&gt; ：客户端 read transaction 超时个数。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#client_tsvc_error\&#34;&gt;client_tsvc_error&lt;/a&gt; ：在尝试处理 transaction 之前，transaction service 中失败的客户端 transaction 个数。例如 协议错误 或 权限校验错误。在 &#39;strong-consistency&#39; 开启的命名空间，这包含 &#39;unavailable_partitions&#39; 和 &#39;dead_partitions&#39;。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#client_tsvc_timeout\&#34;&gt;client_tsvc_timeout&lt;/a&gt; ：在尝试处理 transaction 之前，在 transaction service 中超时的客户端 transaction 个数。在这个阶段，transaction 还没有被识别为 read/write，但是 namespace 是已知的。4.7 之前的八本可能原因是 transaction 队列中阻塞（transaction 线程处理效率不够高）；4.7 及更高的版本中，可能没有足够的 service thread 来跟上工作负载。属于此类别的其他常见情况是在 rw-hash 中等待后必须重试的 transaction（例如热键）以及客户端设置的超时过于激进的用例。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#client_udf_error\&#34;&gt;client_udf_error&lt;/a&gt; ：客户端发起的失败的 udf  transaction 数。不包括超时。有关错误的更多信息，请参阅服务器日志文件。请注意，错误也会返回给客户端。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#client_udf_timeout\&#34;&gt;client_udf_timeout&lt;/a&gt; ：客户端发起的超时的 udf transaction 数。超时错误返回给客户端。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#client_write_error\&#34;&gt;client_write_error&lt;/a&gt; ：客户端 write transaction 错误失败数量。将包括常见错误，如 fail_generation、fail_key_busy、fail_record_too_big、fail_xdr_forbidden 以及其他一些不太常见的错误。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#client_write_timeout\&#34;&gt;client_write_timeout&lt;/a&gt; ：服务器上超时的客户端 write transaction 数。在没有正在进行迁移的稳定集群上，此指标将指示副本写入超时的数量。超时错误将返回给客户端。在启用强一致性的命名空间中，记录被标记为未复制并将重新复制。以下情况可能会导致此指标增加：每个写副本失败（master失败）最终都会增加 client_write_timeout 指标。如果为写入启用重复解析（默认），则在迁移期间，如果重复解析期间出现超时，并且可能在我们在 master 端应用写入之前发生超时，则 client_write_timeout 指标也会增加。有关服务器何时检查超时的详细信息，请参阅 transaction-max-ms 配置参数。transaction也可以在transaction flow中提前超时，在这种情况下，client_tsvc_timeout 统计数据会增加。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#clock_skew_stop_writes\&#34;&gt;clock_skew_stop_writes&lt;/a&gt; ：namespace 将在客户端停止写入时为 true。对于启用了强一致性的命名空间，如果时钟偏差超出容限（通常为 20 秒），则为 true。对于运行 4.5.1 或更高版本并启用 nsup（即 nsup-period 不为零）的可用模式 (AP) 命名空间，如果集群时钟偏差超过 40 秒，则为真。在这种情况下，nsup 也不会运行，禁用记录过期和驱逐，直到时钟偏差回落到可容忍的范围内。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#device_available_pct\&#34;&gt;device_available_pct&lt;/a&gt; ：测量命名空间中所有设备的最小连续磁盘空间。从 3.9 版开始替换 available_pct。如果此值低于 min-avail-pct，命名空间将是只读的（停止写入）。命名空间中所有配置的设备具有相同的大小很重要，否则，即使在其他设备之间有大量可用空间时，device_available_pct 也可能很低。不要与 device_free_pct 混淆，它表示命名空间中所有设备的可用空间量，并且不考虑碎片。下面是一个示例来表示 device_free_pct 和 device_available_pct 之间的区别。让我们假设给定命名空间有 5 个 100MB 的设备，其中每个设备有 25MB 的数据，分布在 50 个写入块中（假设写入块大小为 1MB）：device_free_pct 将是 75%。device_available_pct 将为 50%。如果分布不均匀（通常不是完全均匀），则 device_available_pct 将代表具有最少空闲块的设备。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#device_free_pct\&#34;&gt;device_free_pct&lt;/a&gt; ：此命名空间的可用磁盘容量百分比。这是命名空间中所有设备的可用存储量。当所有设备的使用百分比（由 100 - device_free_pct 表示）超过配置的 high-water-disk-pct 时，将触发驱逐。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#effective_replication_factor\&#34;&gt;effective_replication_factor&lt;/a&gt; ：命名空间的有效复制因子。配置的命名空间复制因子作为命名空间配置的一部分在服务器版本 3.15.1.3 及更高版本的 replication-factor 和早期版本的 repl-factor 下返回。如果集群大小小于设置的复制因子（在这种情况下，有效复制因子将与集群大小匹配）或达到 paxos-single-replica-limit 大小，则有效复制因子小于设置的复制因子（在这种情况下，有效复制因子为 1)。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#evict_ttl\&#34;&gt;evict_ttl&lt;/a&gt; ：当前驱逐深度，或已驱逐记录的最高 ttl，以秒为单位。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#evict_void_time\&#34;&gt;evict_void_time&lt;/a&gt; ：当前驱逐深度，表示为自 2010 年 1 月 1 日 UTC 以来的无效时间（以秒为单位）。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#evicted_objects\&#34;&gt;evicted_objects&lt;/a&gt; ：自服务器启动以来，从该节点上的该命名空间逐出的对象数。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#expired_objects\&#34;&gt;expired_objects&lt;/a&gt; ：自服务器启动以来，此节点上此命名空间中过期的对象数。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#fail_record_too_big\&#34;&gt;fail_record_too_big&lt;/a&gt; ：由于记录太大而导致 write transaction失败的次数超过了写入块大小或最大记录大小。只计算主端的客户端写入失败。从 3.9 版开始替换 err_write_fail_record_too_big。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#hwm_breached\&#34;&gt;hwm_breached&lt;/a&gt; ：如果为 true，则 Aerospike 已违反此命名空间的“high-water-[disk|memory]-pct”。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#memory_free_pct\&#34;&gt;memory_free_pct&lt;/a&gt; ：此命名空间的可用内存容量百分比。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#memory_used_bytes\&#34;&gt;memory_used_bytes&lt;/a&gt; ：此命名空间在此节点上使用的内存总字节数。这是针对 high-water-memory-pct 和 stop-writes-pct 阈值使用的指标。它代表以下值的总和： &lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html?show-removed=1#memory_used_data_bytes\&#34;&gt;memory_used_data_bytes&lt;/a&gt; 、[memory_used_index_bytes] (https://docs.aerospike.com/docs/reference/metrics/index.html?show-removed=1#memory_used_index_bytes)、&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html?show-removed=1#memory_used_set_index_bytes\&#34;&gt;memory_used_set_index_bytes&lt;/a&gt;(version 5.6+)、&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html?show-removed=1#memory_used_sindex_bytes\&#34;&gt;memory_used_sindex_bytes&lt;/a&gt;。节点上分配的内存总量（企业版中的 primary index 共享内存除外）请参考 heap_allocated_kbytes。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#memory_used_data_bytes\&#34;&gt;memory_used_data_bytes&lt;/a&gt; ：数据占用的内存量。有关命名空间占用的总内存，请参阅 memory_used_bytes。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#memory_used_index_bytes\&#34;&gt;memory_used_index_bytes&lt;/a&gt; ：此命名空间的索引占用的内存量。默认情况下，这将在企业版的共享内存中分配\\n（索引类型 shmem）。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#memory_used_set_index_bytes\&#34;&gt;memory_used_set_index_bytes&lt;/a&gt; ：此节点上此命名空间的集合索引占用的内存量。该命名空间占用的总内存请参阅memory_used_bytes。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#non_expirable_objects\&#34;&gt;non_expirable_objects&lt;/a&gt; ：此命名空间中具有不可过期 TTL（值 0 的 TTL）的记录数。从 3.9 版开始由 non_expirable_objects 替换。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#objects\&#34;&gt;objects&lt;/a&gt; ：此节点在此命名空间中的记录数。不包括tombstones。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#stop_writes\&#34;&gt;stop_writes&lt;/a&gt; ：如果为 true，则此命名空间当前不允许写入。将返回错误代码 22。请注意，仍然允许迁移写入以及配置文件写入。只有客户端发起的写入将被拒绝。如果违反以下任一条件，就会发生这种情况：min-avail-pct、stop-writes-pct 或 xdr-min-digestlog-free-pct。&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;storage-engine.device[ix].defrag_q&lt;/code&gt; ：排队等待在设备 [ix] 上进行碎片整理的 wblock 的数量。 &#39;ix&#39; 是设备索引。例如，storage-engine.device[0]=/dev/xvd1 和 storage-engine.device[1]=/dev/xvc1 用于配置中指定的 2 个设备。&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;storage-engine.device[ix].used_bytes&lt;/code&gt; ：用于设备 [ix] 上数据的字节数。 &#39;ix&#39; 是设备索引。例如，storage-engine.device[0]=/dev/xvd1 和 storage-engine.device[1]=/dev/xvc1 用于配置中指定的 2 个设备。&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;storage-engine.file[ix].defrag_q&lt;/code&gt; ：排队等待在文件 [ix] 上进行碎片整理的 wblock 的数量。 &#39;ix&#39; 是文件索引。例如，storage-engine.file[0]=/opt/aerospike/test0.dat 和 storage-engine.file[1]=/opt/aerospike/test2.dat 用于配置中指定的 2 个文件。&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;storage-engine.file[ix].used_bytes&lt;/code&gt; ：用于文件 [ix] 上数据的字节数。 &#39;ix&#39; 是文件索引。例如，storage-engine.file[0]=/opt/aerospike/test0.dat 和 storage-engine.file[1]=/opt/aerospike/test2.dat 用于配置中指定的 2 个文件。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#client_connections\&#34;&gt;client_connections&lt;/a&gt; ：与此节点的活动客户端连接数。也可在 fds proto 代码行的日志中找到。&amp;lt;5.6&amp;gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#client_connections_opened\&#34;&gt;client_connections_opened&lt;/a&gt; ：自节点启动以来创建到该节点的客户端连接数。应密切监视或警告 client_connections_opened 或 client_connections_closed 之一。也可在 fds proto 代码行的日志中找到。&amp;lt;5.6&amp;gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#cluster_clock_skew_ms\&#34;&gt;cluster_clock_skew_ms&lt;/a&gt; ：集群中节点之间的当前最大时钟偏差（以毫秒为单位）。违反 cluster_clock_skew_stop_writes_sec 阈值时将触发clock_skew_stop_writes。对于任何 Aerospike 版本上的强一致性命名空间，此阈值通常为 20 秒，对于启用 nsup（即 nsup-period 不为零）且 Aerospike 版本为 4.5.1 或更高版本的 AP 命名空间，此阈值通常为 40 秒。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#cluster_integrity\&#34;&gt;cluster_integrity&lt;/a&gt; ：如果为 false，则表示集群内部存在完整性问题，这意味着某些节点出现故障或死亡。如果该节点处于活动状态并且报告为孤立节点或属于某个其他集群的一部分，则该节点被视为有故障。故障节点的另一个条件是它处于活动状态，但具有与集群其余部分不匹配的集群协议标识符。当为 true 时，表示集群处于一个整体和完整的状态（就它看到的并且能够连接到所有相关的节点而言）。有关集群完整性故障的信息也会重复记录到服务器日志文件中。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#cluster_is_member\&#34;&gt;cluster_is_member&lt;/a&gt; ：为false时，表示该节点未加入集群；也就是说，它是一个孤儿。如果为 true，则表示该节点已加入集群。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#fabric_connections\&#34;&gt;fabric_connections&lt;/a&gt; ：与此节点的活动结构连接数。也可在 fds proto 代码行的日志中找到。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#fabric_connections_opened\&#34;&gt;fabric_connections_opened&lt;/a&gt; ：自节点启动以来创建到该节点的结构连接数。也可在 fds proto 代码行的日志中找到。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#heap_efficiency_pct\&#34;&gt;heap_efficiency_pct&lt;/a&gt; ：提供 jemalloc 堆碎片的指示。这表示 heap_allocated_kbytes / heap_mapped_kbytes 比率。较低的数字表示较高的碎片率。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#heartbeat_connections\&#34;&gt;heartbeat_connections&lt;/a&gt; ：与此节点的活动心跳连接数。也可在 fds proto 代码行的日志中找到。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#heartbeat_connections_opened\&#34;&gt;heartbeat_connections_opened&lt;/a&gt; ：自节点启动以来创建到该节点的心跳连接数。也可在 fds proto 代码行的日志中找到。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#process_cpu_pct\&#34;&gt;process_cpu_pct&lt;/a&gt; ：asd 进程的 CPU 使用率百分比。&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;https://docs.aerospike.com/docs/reference/metrics/index.html#query_long_running\&#34;&gt;query_long_running&lt;/a&gt; ：在系统中尝试过的长时间运行的查询数（查询所选记录超过 query_threshold）。&lt;/li&gt;\n&lt;/ul&gt;\n&#34;,&#34;fileName&#34;:&#34;aerospike-jiao-chong-yao-jian-kong-zhi-biao-hui-zong&#34;,&#34;abstract&#34;:&#34;&lt;p&gt;监控对于一个组件和系统来说是必不可少的，通常情况下，一个全面健康监控可以帮助我们在出现生产事故之前即时发现问题，并处理掉，下面汇总一些个人对 Aerospike 使用中关注的监控指标。&lt;/p&gt;\n&#34;,&#34;title&#34;:&#34;Aerospike较重要监控指标汇总&#34;,&#34;tags&#34;:[{&#34;index&#34;:-1,&#34;name&#34;:&#34;Aerospike&#34;,&#34;slug&#34;:&#34;VSeqxthmr&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://wenbozhangw.github.io/tag/VSeqxthmr/&#34;}],&#34;date&#34;:&#34;2022-01-19 10:37:28&#34;,&#34;dateFormat&#34;:&#34;2022-01-19&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://wenbozhangw.github.io/post/aerospike-jiao-chong-yao-jian-kong-zhi-biao-hui-zong/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;10 min read&#34;,&#34;time&#34;:586000,&#34;words&#34;:2607,&#34;minutes&#34;:10},&#34;description&#34;:&#34;监控对于一个组件和系统来说是必不可少的，通常情况下，一个全面健康监控可以帮助我们在出现生产事故之前即时发现问题，并处理掉，下面汇总一些个人对 Aerospike 使用中关注的监控指标。\n\n\nclient_delete_error ：客户端 ...&#34;,&#34;toc&#34;:&#34;&#34;},{&#34;content&#34;:&#34;&lt;p&gt;Java 8 引入了 Stream 流式处理与 lambda 表达式，本文从 API 层面介绍相关使用。&lt;/p&gt;\n&lt;!-- more --&gt;\n&lt;h2 id=\&#34;区别总览\&#34;&gt;区别总览&lt;/h2&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;名称&lt;/th&gt;\n&lt;th&gt;参数&lt;/th&gt;\n&lt;th&gt;返回值&lt;/th&gt;\n&lt;th&gt;实例&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;Consumer&lt;/td&gt;\n&lt;td&gt;有&lt;/td&gt;\n&lt;td&gt;无&lt;/td&gt;\n&lt;td&gt;Iterable上的forEach方法&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;Function&lt;/td&gt;\n&lt;td&gt;有&lt;/td&gt;\n&lt;td&gt;有&lt;/td&gt;\n&lt;td&gt;Optional的map方法&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;Predicate&lt;/td&gt;\n&lt;td&gt;有&lt;/td&gt;\n&lt;td&gt;有(bool)&lt;/td&gt;\n&lt;td&gt;Optional的filter方法&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;Supplier&lt;/td&gt;\n&lt;td&gt;无&lt;/td&gt;\n&lt;td&gt;有&lt;/td&gt;\n&lt;td&gt;懒加载、惰性求值、Stream和generator(静态)&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;h2 id=\&#34;详细解释\&#34;&gt;详细解释&lt;/h2&gt;\n&lt;h3 id=\&#34;supplier\&#34;&gt;Supplier&lt;/h3&gt;\n&lt;p&gt;在开发中，我们经常会遇到一些需要延迟计算的情形，比如某些运算非常消耗资源，如果提前算出来却没有用到，会得不偿失。在计算机科学中，有个专门的术语形容：惰性求值。惰性求值是一种求值策略，也就是把求值延迟到真正需要的时候。在Java里，我们有一个专门的设计模式几乎就是为了处理这种情形而生的：Proxy。不过，现在我们有了新的选择：Supplier。&lt;br&gt;\n简而言之，我们可以通过这个对象把耗资源运算放到get方法里，在程序里，我们传递的是Supplier对象，直到调用get方法时，运算才会执行，这就是所谓的惰性求值。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;static void randomZero(Integer[] coins, Supplier&amp;lt;Integer&amp;gt; randomSupplier){\n  coins[randomSupplier.get()] = 0;\n}\nInteger[] coins = {10, 10, 10, 10, 10, 10, 10, 10, 10, 10};\nrandomZero(coins, () -&amp;gt; (int) (Math.random() * 10));\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;但是，通常实现Proxy模式，我们只会计算一次，反复计算是没有必要的。Guava给我们提供了一个函数：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;Supplier&amp;lt;Object&amp;gt; memoize = Suppliers.memoize(new Supplier&amp;lt;Object&amp;gt;() {\n  @Override\n  public Object get() {\n    return null;\n  }\n});\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;memoize()函数帮我们打点了前面所说的一些事情：第一次get()的时候，它会调用真正Supplier，得到结果并保存下来，下次再访问就返回这个保存下来的值。&lt;br&gt;\n有时候，这个值只咋一段时间内是有效的，Guava还给我们提供了另外一个函数，让我们可以设定过期时间；&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;expirableUltimateAnswerSupplier = memoizeWithExpiration(target, 100, NANOSECONDS);\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;consumer\&#34;&gt;Consumer&lt;/h3&gt;\n&lt;p&gt;Consumer是一个函数式编程接口；Consumer意味着消费，即针对某个东西进行使用，因此它包含有一个输入而无输出的accept接口方法；&lt;br&gt;\n除accept方法，它还包含有andThen这个方法&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;default Consumer&amp;lt;T&amp;gt; andThen(Consumer&amp;lt;? super T&amp;gt; after) {\n    Objects.requireNonNull(after);\n    return (T t) -&amp;gt; { accept(t); after.accept(t); };\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;可见这个方法就是指定在调用当前Consumer后是否还要调用其他的Consumer&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;public static void consumerTest() {\n    Consumer f = System.out::println;\n    Consumer f2 = n -&amp;gt; System.out.println(n + &amp;quot;-F2&amp;quot;);\n\n    //执行完F后再执行F2的Accept方法\n    f.andThen(f2).accept(&amp;quot;test&amp;quot;);\n\n    //连续执行F的Accept方法\n    f.andThen(f).andThen(f).andThen(f).accept(&amp;quot;test1&amp;quot;);\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;function\&#34;&gt;Function&lt;/h3&gt;\n&lt;p&gt;Function也是一个函数式编程接口；它代表的含义是“函数”，而函数经常是有输入和输出的，因此它含有一个apply方法，包含一个输入与输出；&lt;br&gt;\n除apply方法外，它还有compose与andThen及indentity方法。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;/**\n * Function测试\n */\npublic static void functionTest() {\n    Function&amp;lt;Integer, Integer&amp;gt; f = s -&amp;gt; s++;\n    Function&amp;lt;Integer, Integer&amp;gt; g = s -&amp;gt; s * 2;\n\n    /**\n     * 下面表示在执行F时，先执行G，并且执行F时使用G的输出当作输入。\n     * 相当于以下代码：\n     * Integer a = g.apply(1);\n     * System.out.println(f.apply(a));\n     */\n    System.out.println(f.compose(g).apply(1));\n\n    /**\n     * 表示执行F的Apply后使用其返回的值当作输入再执行G的Apply；\n     * 相当于以下代码\n     * Integer a = f.apply(1);\n     * System.out.println(g.apply(a));\n     */\n    System.out.println(f.andThen(g).apply(1));\n\n    /**\n     * identity方法会返回一个不进行任何处理的Function，即输出与输入值相等； \n     */\n    System.out.println(Function.identity().apply(&amp;quot;a&amp;quot;));\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;predicate\&#34;&gt;Predicate&lt;/h3&gt;\n&lt;p&gt;Predicate为函数式接口，predicate的中文意思是“断定”，即判断的意思，判断某个东西是否满足某种条件；因此它包含test方法，根据输入值来做逻辑判断，其结果为True或者False。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;/**\n * Predicate测试\n */\nprivate static void predicateTest() {\n    Predicate&amp;lt;String&amp;gt; p = o -&amp;gt; o.equals(&amp;quot;test&amp;quot;);\n    Predicate&amp;lt;String&amp;gt; g = o -&amp;gt; o.startsWith(&amp;quot;t&amp;quot;);\n\n    /**\n     * negate: 用于对原来的Predicate做取反处理；\n     * 如当调用p.test(&amp;quot;test&amp;quot;)为True时，调用p.negate().test(&amp;quot;test&amp;quot;)就会是False；\n     */\n    Assert.assertFalse(p.negate().test(&amp;quot;test&amp;quot;));\n\n    /**\n     * and: 针对同一输入值，多个Predicate均返回True时返回True，否则返回False；\n     */\n    Assert.assertTrue(p.and(g).test(&amp;quot;test&amp;quot;));\n\n    /**\n     * or: 针对同一输入值，多个Predicate只要有一个返回True则返回True，否则返回False\n     */\n    Assert.assertTrue(p.or(g).test(&amp;quot;ta&amp;quot;));\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h2 id=\&#34;函数式编程接口的使用\&#34;&gt;函数式编程接口的使用&lt;/h2&gt;\n&lt;p&gt;通过Stream以及Optional两个类，可以进一步利用函数式接口来简化代码。&lt;/p&gt;\n&lt;h3 id=\&#34;java8的三个编程概念\&#34;&gt;Java8的三个编程概念&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;流处理\n&lt;ul&gt;\n&lt;li&gt;从输入流中一个一个读取数据项，然后以同样的方式将数据项写入输出流&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;用行为参数化把代码传递给方法\n&lt;ul&gt;\n&lt;li&gt;即函数作为第一公民，可以作为值传递&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;并行与共享可变数据&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h3 id=\&#34;stream\&#34;&gt;Stream&lt;/h3&gt;\n&lt;p&gt;Stream可以对多个元素进行一系列操作，也可以支持对某些操作进行并发处理。&lt;br&gt;\nStream API和Collection API的行为差不多，但Collection API主要为了访问和存储数据，而Stream API主要用于描述对数据的计算。&lt;br&gt;\n经典的Java程序只能利用单核进行计算，流提供了多核处理数据的能力。但前提是传递给Stream API的方法不会互动（即有可变的共享对象）时，才能多核工作。&lt;/p&gt;\n&lt;h3 id=\&#34;lambda\&#34;&gt;Lambda&lt;/h3&gt;\n&lt;p&gt;Lambda表达式由参数列表、箭头和主体组成。&lt;/p&gt;\n&lt;h3 id=\&#34;函数式接口\&#34;&gt;函数式接口&lt;/h3&gt;\n&lt;p&gt;Java8新引入了函数式编程方式，大大提高了编码效率。首先要清楚一个概念：函数式接口；&lt;br&gt;\n它指的是有且只有一个未实现的方法的接口，一般通过FunctionalInterface这个注解来表名某个接口是一个函数式接口。函数式接口是Java支持函数式编程的基础。&lt;br&gt;\n注：哪怕有再多默认方法，只要接口中之定义了一个抽象方法，它仍然是函数式接口。&lt;br&gt;\nLambda允许你直接以内联的形式为函数式接口的抽象方法提供实现，并把其作为函数式接口的实例。&lt;/p&gt;\n&lt;h4 id=\&#34;functionalinterface注解\&#34;&gt;FunctionalInterface注解&lt;/h4&gt;\n&lt;p&gt;@FunctionalInterface用于表示该接口为函数式接口。如果它不是函数式接口的话，编译器将返回一个提示原因的错误。&lt;br&gt;\n@FunctionalInterface不是必须的，但最好为函数式接口都标注@FunctionalInterface.&lt;/p&gt;\n&lt;h4 id=\&#34;函数描述符\&#34;&gt;函数描述符&lt;/h4&gt;\n&lt;p&gt;函数式接口的抽象方法的基本签名 本质上就是Lambda表达式的签名。Java8将这种抽象方法叫做函数描述符。&lt;br&gt;\nRunnable接口的run方法即不接受任何参数也不返回，其函数描述符为：() -&amp;gt; void。该函数描述符代表了函数类别为空且返回void函数。&lt;br&gt;\nScala、Kotlin等语言在其类型系统中提供显示的类型注释来描述函数的类型（即函数类型）&lt;/p&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;函数接口&lt;/th&gt;\n&lt;th&gt;函数描述符&lt;/th&gt;\n&lt;th&gt;基本类型特化&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;Predicate&lt;T&gt;&lt;/td&gt;\n&lt;td&gt;T -&amp;gt; boolean&lt;/td&gt;\n&lt;td&gt;IntPredicate, &lt;br /&gt;LongPredicate,&lt;br /&gt;DoublePredicate&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;Consumer&lt;T&gt;&lt;/td&gt;\n&lt;td&gt;T -&amp;gt; void&lt;/td&gt;\n&lt;td&gt;IntConsumer,&lt;br /&gt;LongConsumer,&lt;br /&gt;DoubleConsumer&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;Function&amp;lt;T , R&amp;gt;&lt;/td&gt;\n&lt;td&gt;T -&amp;gt; R&lt;/td&gt;\n&lt;td&gt;IntFunction,IntToDoubleFunction,&lt;br /&gt;IntToLongFunction,&lt;br /&gt;... , ToIntFunction,ToDoubleFunction&lt;br /&gt;ToLongFunction&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;Supplier&lt;T&gt;&lt;/td&gt;\n&lt;td&gt;() -&amp;gt; T&lt;/td&gt;\n&lt;td&gt;BooleanSupplier,IntSupplier,&lt;br /&gt;LongSupplier,DoubleSupplier&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;h3 id=\&#34;方法引用\&#34;&gt;方法引用&lt;/h3&gt;\n&lt;p&gt;方法引用可以把现有方法像Lambda一样传递。&lt;br&gt;\n方法引用主要分三类：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;- 指向静态方法的方法引用。（例如Integer的parseInt方法,写作Integer::parseInt）\n&lt;/code&gt;&lt;/pre&gt;\n&lt;ul&gt;\n&lt;li&gt;指向任意类型实例方法的方法引用。（例如String 的length，写作String::length）\n&lt;ul&gt;\n&lt;li&gt;适用于对象作为Lambda表达式的一个参数&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;指向现存对象或表达式实例方法的方法引用\n&lt;ul&gt;\n&lt;li&gt;适用于调用现存外部对象的方法\n&lt;ul&gt;\n&lt;li&gt;适用于内部的私有方法&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;注：构造函数、数组构造函数以及父类调用的方法引用形式比较特殊：&lt;br&gt;\n利用类名和关键字new来生成构造方法的方法引用。&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;对于默认构造函数，可以使用Supplier签名。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;Supplier&amp;lt;Apple&amp;gt; c1 = Apple::new;\n//等价于\nSupplier&amp;lt;Apple&amp;gt; c1 = () -&amp;gt; new Apple();\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;对于存在参数的构造方法，可根据参数情况寻找适合的函数式接口的签名。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;Function&amp;lt;Integer, Apple&amp;gt; c2 = Apple::new;\n//等价于\nFunction&amp;lt;Integer, Apple&amp;gt; c2 = (weight) -&amp;gt; new Apple(weight); \n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h3 id=\&#34;36-流\&#34;&gt;3.6 流&lt;/h3&gt;\n&lt;p&gt;从支持数据处理操作的源生成的元素序列——流&lt;br&gt;\n流允许以声明性方式处理数据集合。还可以透明地并行处理，无需写任何多线程代码。&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;流只遍历一次。遍历完之后，流就被消费了，需要重新从原始数据源那里再次获取一个新的流进行遍历。&lt;/li&gt;\n&lt;li&gt;只有触发终端操作，中间操作才会被执行。&lt;/li&gt;\n&lt;li&gt;中间操作一般都可以合并起来，在终端操作中一次性全部处理掉。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h4 id=\&#34;筛选\&#34;&gt;筛选&lt;/h4&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;filter方法：接收一个谓词（一个返回boolean的函数）作为参数，并返回一个包括所有符合谓词的元素的流。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;//输出结果：[1, 3, 0]\nList&amp;lt;Integer&amp;gt; numbers = Arrays.asList(1,3,8,6,0,7,5,6);\nnumber.stream()\n\t.filter(i -&amp;gt; i &amp;lt; 4)\n  .collect(Collectors.toList());\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;dsitinct方法：依据流所生产元素的hashCode和equals方法，返回一个元素各异的流。（即返回一个没有重复元素的流）&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;//输出结果[2, 4]\nList&amp;lt;Integer&amp;gt; numbers = Arrays.asList(1,2,1,3,3,2,4);\nnumber.stream()\n\t.filter(i -&amp;gt; i % 2 == 0)\n  .distinct()\n  .collect(Collectors.toList());\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h4 id=\&#34;流的切片\&#34;&gt;流的切片&lt;/h4&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;takeWhile方法：在第一个不符合要求的元素时停止处理。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;//输出结果[1, 2, 3, 4]\nList&amp;lt;Integer&amp;gt; numbers = Arrays.asList(1,2,3,3,4,4,5,6);\nnumber.stream()\n\t.takeWhile(i -&amp;gt; i &amp;lt; 4)\n  .collect(Collectors.toList());\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;dropWhile方法：在一个符合要求的元素时停止处理，并返回所有剩余的元素。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;//输出结果：[4, 4, 5, 6]\n//在初始列表中的数据已排序（由高到低）的情况下：\nList&amp;lt;Integer&amp;gt; numbers = Arrays.asList(1,2,3,3,4,4,5,6);\nnumber.stream()\n  //当发现第一个i &amp;lt; 4 为 true的元素时，则停止处理，并返回所有剩余的元素\n\t.dropWhile(i -&amp;gt; i &amp;lt; 4)\n  .collect(Collectors.toList());\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;limit方法：返回一个不超过给定长度的流。&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;如果流是有序的（如：源是List），则按顺序返回前n个元素。&lt;/li&gt;\n&lt;li&gt;如果流是无序的（如：源是set），则不会以任意顺序排序。&lt;/li&gt;\n&lt;li&gt;对于无限流，可以使用limit将其变成有限流。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;//输出结果[1, 3]\nList&amp;lt;Integer&amp;gt; numbers = Arrays.asList(1,3,8,6,0,7,5,6);\nnumbers.stream()\n  .filter(i -&amp;gt; i &amp;lt; 4)\n  //只返回前两个值\n  .limit(2)\n  .collect(Collectors.toList());\n&lt;/code&gt;&lt;/pre&gt;\n&lt;ul&gt;\n&lt;li&gt;shkip方法：返回一个扔掉前n个元素的流。\n&lt;ul&gt;\n&lt;li&gt;如果流中元素不足 n 个，则返回一个空流。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;//输出结果[0]\nList&amp;lt;Integer&amp;gt; numbers = Arrays.asList(1,3,8,6,0,7,5,6);\nnumbers.stream()\n  .filter(i -&amp;gt; i &amp;lt; 4)\n  //跳过前两个值\n  .skip(2)\n  .collect(Collectors.toList());\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h4 id=\&#34;映射\&#34;&gt;映射&lt;/h4&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;map方法：将流中的每一个元素映射成一个新的元素。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;//输出结果：[6, 2, 4, 1]\nList&amp;lt;String&amp;gt; languages = Arrays.asList(&amp;quot;Kotlin&amp;quot;, &amp;quot;Go&amp;quot;, &amp;quot;Java&amp;quot;, &amp;quot;C&amp;quot;);\nList&amp;lt;Integer&amp;gt; collect = languages.stream()\n  //将String转为int\n  .map(String::length)\n  .collect(Collectors.toList());\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;flatMap方法：把一个流中的每一个值转换成另一个流，然后把所有流连接起来成一个流。&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;简单说就是：把流中的元素（如：列表，数组）化为新的流，或把流中的元素结合外部的列表（数组）化为新的流，再把新的流的元素整合到一个流中。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;//输出结果：[K, o, t, l, i, n, G, J, a, v, C]\nList&amp;lt;String&amp;gt; languages = Arrays.asList(&amp;quot;Kotlin&amp;quot;, &amp;quot;Go&amp;quot;, &amp;quot;Ja\nList&amp;lt;String&amp;gt; collect = languages.stream()                  \n        .map(str -&amp;gt; str.split(&amp;quot;&amp;quot;))                         \n        //Arrays::stream 将 str.split(&amp;quot;&amp;quot;)返回的字符数组转化为流，再由flat\n        //flatMap本质也是对流的元素进行转换（map也是对流的元素进行转换）。将流的元素转换成新的流\n        //等价于：flatMap(strArray -&amp;gt; Arrays.stream(strArray))\n        .flatMap(Arrays::stream)                           \n        .distinct()                                       \n        .collect(Collectors.toList());                    \ncollect.stream().forEach(s -&amp;gt; System.out.print(s + &amp;quot;, &amp;quot;));\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;练习：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;List&amp;lt;Integer&amp;gt; numbers1 = Arrays.asList(1, 2, 3);\nList&amp;lt;Integer&amp;gt; numbers2 = Arrays.asList(3, 4);\nList&amp;lt;int[]&amp;gt; pairs = numbers1.stream()\n  .flatMap(i -&amp;gt;\n           numbers2.stream().map(j -&amp;gt; new int[]{i, j})\n          ).collect(Collectors.toList());\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h4 id=\&#34;查找与匹配\&#34;&gt;查找与匹配&lt;/h4&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;anyMatch方法：检查流中是否至少有一个元素匹配给定的谓词。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;//输出结果:true\nList&amp;lt;Integer&amp;gt; numbers = Arrays.asList(1,2,3,5,6,8);\nnumbers.stream().anyMatch(i -&amp;gt; i &amp;gt; 3);\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;allMatch方法：检查流中全部元素都匹配给定的谓词。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;//输出结果:true\nList&amp;lt;Integer&amp;gt; numbers = Arrays.asList(1,2,3,5,6,8);\nnumbers.stream().anyMatch(i -&amp;gt; i &amp;lt; 10);\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;noneMatch方法：检查流中全部元素都不匹配给定的谓词。（与allMatch相对）&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;//输出结果:true\nList&amp;lt;Integer&amp;gt; numbers = Arrays.asList(1,2,3,5,6,8);\nnumbers.stream().anyMatch(i -&amp;gt; i &amp;gt; 10);\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;findAny方法：返回当前流中的任意元素。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;//张三 17\nList&amp;lt;User&amp;gt; users = Arrays.asList(\n                new User(&amp;quot;张三&amp;quot;, 17),\n                new User(&amp;quot;张三&amp;quot;, 18),\n                new User(&amp;quot;王五&amp;quot;, 19));\n        Optional&amp;lt;User&amp;gt; u = users.stream()\n                .filter(user -&amp;gt; user.getName().equals(&amp;quot;张三&amp;quot;))\n                .findAny();\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;findFirst方法：返回当前流中的第一个元素。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;List&amp;lt;User&amp;gt; users = Arrays.asList(\n                new User(&amp;quot;张三&amp;quot;, 17),\n                new User(&amp;quot;张三&amp;quot;, 18),\n                new User(&amp;quot;王五&amp;quot;, 19));\n        Optional&amp;lt;User&amp;gt; u = users.stream()\n                .filter(user -&amp;gt; user.getName().equals(&amp;quot;张三&amp;quot;))\n                .findFirst();\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;注：&lt;/p&gt;\n&lt;ol&gt;\n&lt;li&gt;anyMatch、allMatch和noneMatch都属于终端操作。&lt;/li&gt;\n&lt;li&gt;anyMatch、allMatch、noneMatch、findFirst和findAny不用处理整个，只要找到一个元素，就可以得到结果。&lt;/li&gt;\n&lt;li&gt;findAny和findFirst同时存在的原因是并行。findAny在并行流中限制较少。&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h4 id=\&#34;归约\&#34;&gt;归约&lt;/h4&gt;\n&lt;p&gt;将流中所有元素反复结合起来，从而得到一个值的查询，可以被归类为归约操作。（用函数式编程语言的术语来说，这成为折叠）。&lt;br&gt;\nreduce方法：接收Lambda将列表中的所有元素进行处理并归约成一个新值。&lt;/p&gt;\n&lt;ol&gt;\n&lt;li&gt;\n&lt;p&gt;有初始值：&lt;/p&gt;\n&lt;p&gt;接收一个初始值和一个BinaryOperator&lt;T&gt;将两个元素结合起来产生一个新值。&lt;/p&gt;\n&lt;/li&gt;\n&lt;/ol&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;T reduce(T identity, BinaryOperator&amp;lt;T&amp;gt; accumulator);\n&lt;/code&gt;&lt;/pre&gt;\n&lt;ol start=\&#34;2\&#34;&gt;\n&lt;li&gt;\n&lt;p&gt;无初始值&lt;/p&gt;\n&lt;p&gt;一个BinaryOperator&lt;T&gt; 将两个元素结合起来产生一个新值。&lt;/p&gt;\n&lt;/li&gt;\n&lt;/ol&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;Optional&amp;lt;T&amp;gt; reduce(BinaryOperator&amp;lt;T&amp;gt; accumulator);\n&lt;/code&gt;&lt;/pre&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;求和&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;List&amp;lt;Integer&amp;gt; numbers = Arrays.asList(1, 2, 3);\n        Integer reduce = numbers.stream()\n                //等价于reduce(0, (a,b) -&amp;gt; a + b)\n                .reduce(0, Integer::sum);\n        Optional&amp;lt;Integer&amp;gt; reduce1 = numbers.stream().reduce(Integer::sum);\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;最大值&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;Optional&amp;lt;Integer&amp;gt; maxOptional = numbers.stream().reduce(Integer::max);\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;最小值&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;Optional&amp;lt;Integer&amp;gt; maxOptional = numbers.stream().reduce(Integer::min);\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h4 id=\&#34;数值流\&#34;&gt;数值流&lt;/h4&gt;\n&lt;p&gt;原先的归约求和代码中，Integer::sum暗含装箱和拆箱的成本。Stream API提供了原始类型流特化，专门支持处理数值流的方法。Java8引入原始类型特化接口解决数值流拆箱与装箱的问题：IntStream、DoubleStream和LongStream,分别将流中的元素特化为int、long和double。&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;映射到数值流&lt;/p&gt;\n&lt;p&gt;mapToInt、mapToDouble和mapToLong用于将流转换为特化流：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;List&amp;lt;Integer&amp;gt; numbers = Arrays.asList(1,2,3,4,5);\nint sum = numbers.stream().mapToInt(Integer::intValue).sum();\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;转换回对象流&lt;/p&gt;\n&lt;p&gt;当需要把原始流转换成对象流时（如：把int装箱回Integer），可以使用boxed。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;List&amp;lt;Integer&amp;gt; numbers = Arrays.asList(1,2,3,4,5);\nIntStream intStream = numbers.stream().mapToInt(Integer::intValue);\nStream&amp;lt;Integer&amp;gt; stream = intStream.boxed();\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;默认值OptionalInt&lt;/p&gt;\n&lt;p&gt;Optional也相应的提供原始类型特化版本：OptionalInt、OptionalLong和OptionalDouble。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;List&amp;lt;Integer&amp;gt; numbers = Arrays.asList(1,2,3,4,5);\nOptionalInt maxNumber = numbers.stream().mapToInt(Integer::intValue).max();\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h4 id=\&#34;数值范围\&#34;&gt;数值范围&lt;/h4&gt;\n&lt;p&gt;IntStream和LongStream提供产生生成数值范围的静态方法：range和rangeClosed。&lt;br&gt;\nrange方法生成半闭区间（左闭右开），rangeClosed方法生成闭区间。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;IntStream.range(1,100)\n\t.filter(n -&amp;gt; n % 2 == 0)\n\t.count();\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h4 id=\&#34;构建流\&#34;&gt;构建流&lt;/h4&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;由值创建流&lt;/p&gt;\n&lt;p&gt;静态方法Stream.of接收任意数量的参数，显示创建一个流。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;Stream s = Stream.of(&amp;quot;test&amp;quot;);\nStream s1 = Stream.of(&amp;quot;a&amp;quot;,&amp;quot;b&amp;quot;,&amp;quot;c&amp;quot;);\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;静态方法Stream.empty创建一个空流。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;Stream stream = Stream.empty();\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;由数组或集合创建流&lt;/p&gt;\n&lt;p&gt;静态方法Arrays.stream将数组创建为一个流。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;//asList只能用于包装类型，基本类型会变为List&amp;lt;int[]&amp;gt;对象\nList&amp;lt;String&amp;gt; list = Arrays.asList(arr);\n//获取串行stream对象\nStream listStream = list.stream();\nArrays.stream(arr);\n//获取串行stream对象\nStream parallelListStream = list.parallelStream();\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;由文件生成流&lt;/p&gt;\n&lt;p&gt;java.nio.file.Files中很多静态方法会返回一个流，以便利用Stream API处理文件等I/O操作。&lt;br&gt;\n如：Files.lines返回一个由指定文件中的各行构成的字符串流：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;long uniqueWords = 0;\n//流会自动关闭，不需要额外try-finally操作\ntry {\n  Stream&amp;lt;String&amp;gt; lines = Files.lines(Paths.get(&amp;quot;data.txt&amp;quot;), Charset.defaultCharset());\n  uniqueWords = lines.flatMap(line -&amp;gt; Arrays.stream(line.split(&amp;quot; &amp;quot;)))\n    .distinct()\n    .count();\n} catch (IOException e) {\n  e.printStackTrace();\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;由函数生成流：创建无限流&lt;/p&gt;\n&lt;p&gt;Stream API提供了两个静态方法用来从函数生成流：Stream.iterate()和Stream.generate()，不同于从集合创建的流，这两个静态方法创建的流没有固定的大小，成为无限流。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;//since java1.8\npublic static &amp;lt;T&amp;gt; Stream&amp;lt;T&amp;gt; iterate(final T seed, final UnaryOperator&amp;lt;T&amp;gt; f);\nstatic&amp;lt;T&amp;gt; Stream&amp;lt;T&amp;gt; generate(Supplier&amp;lt;? extends T&amp;gt; s);\n//since java1.9\npublic static &amp;lt;T&amp;gt; Stream&amp;lt;T&amp;gt; iterate(T seed, Predicate&amp;lt;? super T&amp;gt; hasNext, UnaryOperator&amp;lt;T&amp;gt; next);\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h5 id=\&#34;迭代\&#34;&gt;迭代：&lt;/h5&gt;\n&lt;p&gt;itreate 方法接收一个初始值（种子）作为流的一个元素。再接收一个Lambda一次应用在每一个产生的新值上。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;Stream.iterate(0, n -&amp;gt; n + 2)\n    .limit(10)\n    .forEach(System.out::println);\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;java9对iterate方法进行增加，接受多一个谓词作为判断迭代调用何时终止。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;IntStream.iterate(0, n -&amp;gt; n &amp;lt; 100, n -&amp;gt; n + 2)\n    .forEach(System.out::println);\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;也可以使用takeWhile对流执行短路操作（takeWhile函数Java9开始支持）:&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;IntStream.iterate(0, n -&amp;gt; n + 2)\n    .takeWhile(n -&amp;gt; n &amp;lt; 100)\n    .forEach(System.out::println);\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h5 id=\&#34;生成\&#34;&gt;生成&lt;/h5&gt;\n&lt;p&gt;generate 接受一个Supplier&lt;T&gt; 类型的Lambda提供新值。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;Stream.generate(Math::random)\n  .limit(5)\n  .forEach(System.out::println);\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h3 id=\&#34;用流收集数据\&#34;&gt;用流收集数据&lt;/h3&gt;\n&lt;p&gt;流支持两种类型的操作：中间操作 和 末端操作。&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;中间操作可以相互链接起来，将一个流转换为另一个流。中间操作不会消耗流，目的是建立一个流水线。&lt;/li&gt;\n&lt;li&gt;末端操作会消耗流，以产生一个最终结果。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h4 id=\&#34;归约和汇总\&#34;&gt;归约和汇总&lt;/h4&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;Collectors工厂类提供了很多归约的静态工厂方法。&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;Collectors.counting()用于统计总和。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;long count = menu.stream().collect(collections.countiong());\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Collectors.maxBy 和 Collectors.minBy用来计算流中的最大值和最小值。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;//张三 17\n        List&amp;lt;User&amp;gt; users = Arrays.asList(\n                new User(&amp;quot;张三&amp;quot;, 17),\n                new User(&amp;quot;张三&amp;quot;, 18),\n                new User(&amp;quot;王五&amp;quot;, 19));\n        Optional&amp;lt;User&amp;gt; collect = users.stream().collect(\n                Collectors.maxBy(\n                        Comparator.comparingInt(User::getAge)\n                )\n        );\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;同时Collectors类专门汇总提供了一些工厂方法类。&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;Collectors.summingInt、Collectors.summingLong和Collectors.summingDouble分别用于对int、long、double进行求和。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;Integer collect1 = users.stream().collect(Collectors.summingInt(User::getAge));\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Collectors.averagingInt、Collectors.averagingLong和Collectors.averagingDouble分别用于对int、long和double进行求平均值。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;Double collect2 = users.stream().collect(Collectors.averagingInt(User::getAge));\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Collectors.joining工厂方法会对流中每一个对象应用toString方法得到所有字符串连接成一个字符串。&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;String nameStr = users.stream().map(User::getName).collect(Collectors.joining());\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h4 id=\&#34;分组\&#34;&gt;分组&lt;/h4&gt;\n&lt;p&gt;Collections的groupingBy()方法会把流中的元素分成不同的组。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;1\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1642493678915.png\&#34; alt=\&#34;用流收集数据-分组\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;h4 id=\&#34;操作分组的元素\&#34;&gt;操作分组的元素&lt;/h4&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;过滤&lt;/p&gt;\n&lt;p&gt;如果在groupingBy()之前，使用filter()对流进行过滤操作，可能会造成键的丢失。&lt;br&gt;\n例如：&lt;br&gt;\n存在以下Map:&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-json\&#34;&gt;{ FISH = [prawns, salmon], OTHER = [french fries, rice], MEAT = [pork, beef, chicken]}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;如果在使用filter()后，再groupingBy()可能对某些键在结果映射中完全消失：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;{ OTHER = [french fries, rice], MEAT = [pork, beef, chicken]}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;为此，Collectors类提供了filtering()静态工厂方法，它接受一个谓词对每一个分组中的元素执行过滤操作。最后不符合谓词条件的键将得到空的列表：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;{FISH = [], OTHER = [french fries, rice], MEAT = [pork, beef, chicken]}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;Map&amp;lt;Dish.Type, List&amp;lt;Dish&amp;gt;&amp;gt; caloricDishesByType = menu.stream().collect( groupingBy(Dish::getType), filtering(dish -&amp;gt; dish.getCalories() &amp;gt; 500, toList()) )\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;注：&lt;/p&gt;\n&lt;p&gt;使用重载的groupingBy()方法和filtering()方法：先分组再过滤；&lt;/p&gt;\n&lt;p&gt;先使用filter()，再使用groupingBy()方法：先过滤再分组。&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;映射&lt;/p&gt;\n&lt;p&gt;Collectors提供mapping静态工厂方法，接受一个映射函数和另外一个Collectors函数作为参数。映射函数将分组中的元素进行转换，作为参数的Collectors函数会收集对每个元素执行该映射函数的结果。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;List&amp;lt;User&amp;gt; users = Arrays.asList(\n                new User(&amp;quot;张三&amp;quot;, 17),\n                new User(&amp;quot;张三&amp;quot;, 18),\n                new User(&amp;quot;王五&amp;quot;, 19));\n        Map&amp;lt;String, List&amp;lt;String&amp;gt;&amp;gt; collect = users.stream().collect(groupingBy(User::getName, mapping(User::getName, toList())));\n        collect.forEach((k , v) -&amp;gt; {\n            System.out.println(&amp;quot;k = &amp;quot; + k);\n            v.forEach(System.out::println);\n        });\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;Collectors工具类也提供了flatMapping，跟flatMap类似的功能。&lt;/p&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h4 id=\&#34;多级分组\&#34;&gt;多级分组&lt;/h4&gt;\n&lt;p&gt;同时Collectors工具类也提供了可以嵌套分组的groupingBy，用于进行多级分组&lt;br&gt;\n注：&lt;br&gt;\n可以理解为在进行完第一次分组后，再对每一组元素进行再次分组。&lt;br&gt;\ngroupingBy(f)（f是分类函数）实际上是groupingBy(f, toList())的简便写法。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;List&amp;lt;User&amp;gt; users = Arrays.asList(\n                new User(&amp;quot;张三&amp;quot;, 17),\n                new User(&amp;quot;张三&amp;quot;, 18),\n                new User(&amp;quot;王五&amp;quot;, 19));\n        Map&amp;lt;String, Map&amp;lt;String, List&amp;lt;User&amp;gt;&amp;gt;&amp;gt; collect = users.stream().collect(\n                groupingBy(\n                        User::getName,\n                        groupingBy(us -&amp;gt; {\n                                    if (us.getAge() &amp;gt;= 18) {\n                                        return &amp;quot;大于等于18&amp;quot;;\n                                    } else if (us.getAge() &amp;lt; 18) {\n                                        return &amp;quot;小于18&amp;quot;;\n                                    } else {\n                                        return &amp;quot;未知&amp;quot;;\n                                    }\n                                }\n                        )\n                )\n        );\n\n        collect.forEach((k , v) -&amp;gt; {\n            System.out.println(&amp;quot;k = &amp;quot; + k);\n            v.forEach((k1 , v1) -&amp;gt; {\n                System.out.println(k1);\n                v1.forEach(user -&amp;gt; System.out.println(user.getName()));\n            });\n        });\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h4 id=\&#34;按子组收集数据\&#34;&gt;按子组收集数据&lt;/h4&gt;\n&lt;p&gt;groupingBy()的第二个收集器可以是任何类型。例如可以使用counting()收集器作为它的第二个参数，统计分组的数量：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;List&amp;lt;User&amp;gt; users = Arrays.asList(\n                new User(&amp;quot;张三&amp;quot;, 17),\n                new User(&amp;quot;张三&amp;quot;, 18),\n                new User(&amp;quot;王五&amp;quot;, 19));\n        Map&amp;lt;String, Long&amp;gt; collect = users.stream().collect(\n                groupingBy(User::getName, counting())\n        );\n\n        collect.forEach((k , v) -&amp;gt; {\n            System.out.println(&amp;quot;k = &amp;quot; + k);\n            System.out.println(&amp;quot;v = &amp;quot; + v);\n        });\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;得到{ &amp;quot;张三&amp;quot; = 2， &amp;quot;王五&amp;quot; = 1 }&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;List&amp;lt;User&amp;gt; users = Arrays.asList(\n                new User(&amp;quot;张三&amp;quot;, 17),\n                new User(&amp;quot;张三&amp;quot;, 17),\n                new User(&amp;quot;王五&amp;quot;, 19));\n        Map&amp;lt;Integer, User&amp;gt; collect = users.stream().collect(\n                groupingBy(\n                        User::getAge,\n                        collectingAndThen(\n                                //maxby返回的是Optional类型对象\n                                maxBy(Comparator.comparingInt(User::getAge)),\n                                //当找到最大值后，会执行get操作\n                                Optional::get\n                        )\n                )\n        );\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;如果users中没有某个年龄，该类型不会对应一个Optional.empty()值，而且根本不会在Map的键中。所以转换函数Optional::get的操作是安全的。&lt;/p&gt;\n&lt;h4 id=\&#34;分区\&#34;&gt;分区&lt;/h4&gt;\n&lt;p&gt;Collectors工具类提供partitionedMenu()静态工厂函数来实现分区，分区是分组的特殊情况。由谓词作为分类函数，这意味着得到的分组Map的键类型是Boolean，最多分为true和false两组。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;Map&amp;lt;Boolean, List&amp;lt;User&amp;gt;&amp;gt; collect = users.stream().collect(\n                partitioningBy(\n                        u -&amp;gt; u.getAge() &amp;gt; 18\n                ));\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;同时，partitionedMenu()也和groupingBy()类似，可以进行二级分区。&lt;/p&gt;\n&lt;h4 id=\&#34;收集器接口\&#34;&gt;收集器接口&lt;/h4&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;public interface Collector&amp;lt;T, A, R&amp;gt;{\n\t//创建一个空的累加器\n\tSupplier&amp;lt;A&amp;gt; supplier();\n\t//将元素添加到结果容器\n\tBiConsumer&amp;lt;A, T&amp;gt; accumulator();\n\t//合并两个结果（定义了对流的各个子部分进行并行处理时，各个子部分归约所得的累加器如何并行）\n\tBinaryOperator&amp;lt;A&amp;gt; combiner();\n\t//对结果容器应用最终转换\n\tFunction&amp;lt;A, R&amp;gt; finisher();\n\t//定义收集器的行为\n\tSet&amp;lt;Characteristics&amp;gt; characteristics;\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;泛型的定义如下：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;T表示流中要收集的项目的泛型。&lt;/li&gt;\n&lt;li&gt;A表示累加器的类型。（累加器是收集过程中用于累积部分结果的对象）&lt;/li&gt;\n&lt;li&gt;R表示收集操作得到的对象的类型。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h4 id=\&#34;以tolistcollector为例\&#34;&gt;以ToListCollector为例&lt;/h4&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;public class ToListCollector&amp;lt;T&amp;gt; implements Collector&amp;lt;T, List&amp;lt;T&amp;gt;, List&amp;lt;T&amp;gt;&amp;gt; {\n\tpublic ToListCollector(){}\n  \n  //创建ArrayList对象作为累加器\n  public Supplier&amp;lt;List&amp;lt;T&amp;gt;&amp;gt; supplier(){\n    return ArrayList::new;\n  }\n  \n  //利用add函数将流中的元素添加到列表中\n  public BiConsumer&amp;lt;List&amp;lt;T&amp;gt;, T&amp;gt; accumulator(){\n    return List::add;\n  }\n  \n  //两个累加器（即两个ArrayList对象）进行相加\n  public BinaryOperator&amp;lt;List&amp;lt;T&amp;gt;&amp;gt; combiner(){\n    return (list, list2) -&amp;gt; {\n      list.addAll(list2);\n      return list;\n    };\n  }\n  \n  //累加器进行最终的转换\n  public Function&amp;lt;List&amp;lt;T&amp;gt;, List&amp;lt;T&amp;gt;&amp;gt; finisher(){\n    //Function.identity()表示给什么返回什么，也就是不进行转换\n    return Function.identity();\n  }\n  \n  //定义收集器的行为\n  public Set&amp;lt;Characteristics&amp;gt; characteristics(){\n    return Collections.unmodifiableSet(EnumSet.of(Characteristics.IDENTITY_FINISH, Characteristics.CONCURRENT));\n  }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;Characteristics的三个枚举：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;UNORDERED——归约结果不受流中项目的遍历和累积顺序的影响。&lt;/li&gt;\n&lt;li&gt;CONCURRENT——accumulator函数可以从多个线程同时调用，且该收集器可以并行归纳流。（仅仅只是数据源无序时才会并行处理）&lt;/li&gt;\n&lt;li&gt;IDENTITY_FINISH——表明完成器方法返回的函数是一个恒等函数，可以跳过。累加器对象会直接用作归约过程的最终结果。这也意味着，将累加器A不加检查的转换为结果R是安全的。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h4 id=\&#34;进行自定义收集而不去实现collector\&#34;&gt;进行自定义收集，而不去实现Collector&lt;/h4&gt;\n&lt;p&gt;对于IDENTITY_FINISH的收集操作，Stream重载的collect方法接收三个函数——supplier、accumulator和combiner。该collect方法创建的收集器的Characteristics永远是Characteristics.IDENTITY_FINISH和Characteristics.CONCURRENT。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;ArrayList&amp;lt;Object&amp;gt; collect = users.stream().collect(\n  //创建累加容器\n  ArrayList::new,\n  //将流元素添加到累加容器中\n  List::add,\n  //合并累加容器\n  List::addAll\n);\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;并行数据处理与性能\&#34;&gt;并行数据处理与性能&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;对顺序流调用parallel()方法并不意味着流本身有任何实际的变化，它仅仅在内部设置了一个boolean标志，表示你想让调用parallel()之后的所有操作都并行执行。对并行流调用sequential方法就可以把它变成顺序流。&lt;/li&gt;\n&lt;li&gt;并行流默认的线程数量等于你处理器的核数。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;使用并行流时，考虑以下因素：&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;留意自动装箱和拆箱。（应尽量将其转为原始类型流）&lt;/li&gt;\n&lt;li&gt;对于较小数据量，无需使用并行流。&lt;/li&gt;\n&lt;li&gt;考虑流背后的数据结构是否容易分解。&lt;/li&gt;\n&lt;li&gt;部分操作本身在并行流上的性能比顺序流差。如limit和findFirst&lt;/li&gt;\n&lt;li&gt;考虑合并步骤的代价是大是小。&lt;/li&gt;\n&lt;li&gt;考虑操作流水线的总操作成本。当单个元素通过流水线的成本较高时，使用并行流比较好。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;流的数据源和可分解性：&lt;/strong&gt;&lt;/p&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;源&lt;/th&gt;\n&lt;th&gt;可分解性&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;ArrayList&lt;/td&gt;\n&lt;td&gt;差&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;LinkedList&lt;/td&gt;\n&lt;td&gt;差&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;IntStream.range&lt;/td&gt;\n&lt;td&gt;极佳&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;Stream.iterate&lt;/td&gt;\n&lt;td&gt;差&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;HashSet&lt;/td&gt;\n&lt;td&gt;好&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;TreeSet&lt;/td&gt;\n&lt;td&gt;好&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;h3 id=\&#34;collection-api的增强功能\&#34;&gt;Collection API的增强功能&lt;/h3&gt;\n&lt;p&gt;Arrays.asList()创建一个固定大小的列表，列表的元素可以更新，但不可以增加或删除。&lt;br&gt;\nJava9引入以下工厂方法：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;List.of——创建一个只读列表，不可set、add等操作。&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Set.of——创建一个只读的Set集合。&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Map.of——接受的列表中，以键值交替的方式创建map的元素。&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;当创建Map的键值对过多时，可以使用map.ofEntries()和Map.entry()来创建map。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;Map.ofEntries(\n  entry(&amp;quot;zhangsan&amp;quot;, 10),\n  entry(&amp;quot;lisi&amp;quot;, 12),\n);\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h4 id=\&#34;重载与变参\&#34;&gt;重载与变参&lt;/h4&gt;\n&lt;p&gt;在 Java API中，List.of包含多个重载版本：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;static &amp;lt;E&amp;gt; List&amp;lt;E&amp;gt; of(E e1);\nstatic &amp;lt;E&amp;gt; List&amp;lt;E&amp;gt; of(E e1, E e2);\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;而不提供变参版本是因为需要额外的分配一个数组，这个数组被封装与列表中。使用变参版本的方法，就要负担分配数组、初始化以及最后进行垃圾回收的开销。（如果元素数量超过10个，实际调用的还是变参方法。）&lt;/p&gt;\n&lt;h4 id=\&#34;使用list-set和map\&#34;&gt;使用List、Set和Map&lt;/h4&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;removeIf——移除集合中匹配制定谓词的元素。（该方法由Collection接口提供默认方法，List和Set都可用）&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;default boolean removeIf(Predicate&amp;lt;? super E&amp;gt; filter)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;ul&gt;\n&lt;li&gt;当使用for-each遍历列表，进行移除操作时，会导致ConcurrentModificationException。因为遍历使用的迭代器对象和集合对象的状态同步。我们只能显示调用迭代器对象（Iterator对象）的remove方法。因此Java8提供removeIf方法， 安全简便的删除符合谓词的元素。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;replaceAll()——使用一个函数替换List或Map中的元素。（该方法由List接口提供默认方法）&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;default void replaceAll(UnaryOperator&amp;lt;E&amp;gt; operator)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;该函数只是在列表内部进行同类型的转换，并没有创建新的列表。也就是说初始为List&lt;String&gt;，函数执行完还是List&lt;String&gt;。&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;default void replaceAll(BiFunction&amp;lt; ? super K, ? super V, ? extends V&amp;gt; function)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;sort()——对列表自身进行排序。（该方法由List接口提供默认方法）&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;default void sort(Comparator&amp;lt;? super E&amp;gt; c)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;forEach——List和Set，甚至是Map在Java8中都支持forEach方法。而遍历提供的便捷，特别是Map的遍历。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;default void forEach(Consumer&amp;lt;? super T&amp;gt; action)\ndefault void forEach(BiConsumer&amp;lt;? super K, ? super V&amp;gt; action)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Entry.comparingByValue()和Entry.comparingByKey()——对Map的值或键进行排序。&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Map.compute——使用指定的键计算新的值，并将其存储到Map中，并返回新值。（指定一个key，再提供一个BiFunction，依据key和旧值，计算新值。如果新值为null，则不会加入到Map中并将旧值移除。）&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;default V compute(K key, BiFunction&amp;lt;? super K, ? super V, ? extends V&amp;gt; remappingFunction)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Map.computeIfAbsent——如果指定的键没有对应的值（没有该键或该键对应的值是空），使用该键计算新的值，并添加到Map中（如果新值为null，则不会加入到Map中并将旧值移除。），并返回新值。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;default V computeIfAbsent(K key, Function&amp;lt;? super K, ? extends V&amp;gt; mappingFunction)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;ul&gt;\n&lt;li&gt;该方法对值需要初始化时有用。比如Map&amp;lt;K, List&lt;V&gt;&amp;gt;添加一个元素（初始化对应的ArrayList，并返回该值）:&lt;/li&gt;\n&lt;/ul&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;map.computeIfAbsent(&amp;quot;daqi&amp;quot;, name -&amp;gt; new ArrayList&amp;lt;String&amp;gt;().add(&amp;quot;Java8&amp;quot;));\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Map.cumputeIfPresent——如果指定的键在Map中存在，依据该键的旧值计算该键的新值，并将其添加到Map中。(如果新值为null，则不会加入到Map中，并将旧值移除。)&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;default V computeIfPresent(K key, BiFunction&amp;lt;?  super K, ? super V, ? extends V&amp;gt; remappingFunction)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Map.remove——重载版本的remove可以删除Map中某个键对应某个特定值的映射对。（即key和value都匹配上，才从Map中移除）&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;default boolean remvoe(Object key, Object value) \n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Map.merge——如果指定的键在Map中存在，依据该键和旧值计算该键的新值，并将其添加到Map中；如果指定的键在Map中不存在，依据指定的value作为key的值，并将其添加到Map中。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;default V merge(K key, V value, BiFunction&amp;lt;? super V, ? super V, ? extends V&amp;gt; remappingFunction)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;ul&gt;\n&lt;li&gt;该函数可用于Map 的合并，或用于将Collector转换成Map。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;Map&amp;lt;String, Integer&amp;gt; languages = new HashMap();\nlanguages.put(&amp;quot;Java&amp;quot;, 8);\nlanguages.put(&amp;quot;kotlin&amp;quot;, 1);\nHashMap&amp;lt;String, Integer&amp;gt; languages2 = new HashMap();\nlanguages2.put(&amp;quot;Java&amp;quot;, 11);\nlanguages2.put(&amp;quot;Go&amp;quot;, 1);\n\nlanguages.forEach((k , v) -&amp;gt; {\n  if (v != null) {\n    languages2.merge(k, v, Integer::sum);\n  }\n});\n&lt;/code&gt;&lt;/pre&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;List&amp;lt;User&amp;gt; users = Arrays.asList(\n                new User(&amp;quot;张三&amp;quot;, 17),\n                new User(&amp;quot;张三&amp;quot;, 17),\n                new User(&amp;quot;王五&amp;quot;, 19));\n        Map&amp;lt;String, Integer&amp;gt; collect = users.stream().collect(toMap(User::getName, User::getAge, Integer::sum));\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h3 id=\&#34;重构\&#34;&gt;重构&lt;/h3&gt;\n&lt;h4 id=\&#34;改善代码可读性\&#34;&gt;改善代码可读性&lt;/h4&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;用lambda表达式取代匿名类&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;匿名类和lambda表达式中的this和super的含义不同。在匿名类中，this代表的是类自身；在lambda表达式中，this代表的是包含类。&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;匿名类可屏蔽包含类的变量，而lambda表达式不能（编译报错）&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;int a = 10;\n//lambda 表达式\nRunnable r1 = () -&amp;gt; {\n  //报错，提示：改变了已在作用域中被定义\n  int a = 1;\n};\n\n//匿名类\nRunnbale r2 = new Runnable(){\n  @Override\n  public void run(){\n    //编译正常\n    int a = 2;\n  }\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;匿名内部类的类型是在初始化时确定的，lambda的类型取决于它的上下文。当出现两个或以上方法参数的函数描述符与lambda的函数描述符匹配时，需要显式的类型转换来解决。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;interface daqiRunnable{\n\tpublic void action();\n}\n//无论Runnbale还是daqiRunnable，其函数描述符为() -&amp;gt; void\npublic static void doSomething(Runnable r){}\npublic static void doSomething(daqiRunnable r){}\n\npublic static void main(String[] args){\n  //显示类型转换\n  doSomething((daqiRunnable) () -&amp;gt; {} );\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;用方法引用重构lambda表达式，提高代码的可读性。&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;将较复杂的Lambda逻辑封装在方法中，使用方法引用代替该Lambda。&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;尽量使用静态辅助方法。比如：comparing和maxBy&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;list.sort((a1, a2) -&amp;gt; a1.getWeight().compareTo(a2.getWeight()));\n//替换成\nlist.sort(Comparator.comparing(Apple::getWeight));\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;很多通用的归约操作，都可以借助Collectors的辅助方法 + 方法引用代替。&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-java\&#34;&gt;list.stream().map(Dish::getCalories)\n\t\t\t\t.reduce(0, (c1,c2) -&amp;gt; c1 + c2);\n//替换成\nlist.stream()\n\t\t.collect(summingInt(Dish::getCalories));\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;用Stream API重构命令式的数据处理&lt;/p&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;,&#34;fileName&#34;:&#34;jdk8-zhi-stream-yu-han-shu-shi-bian-cheng&#34;,&#34;abstract&#34;:&#34;&lt;p&gt;Java 8 引入了 Stream 流式处理与 lambda 表达式，本文从 API 层面介绍相关使用。&lt;/p&gt;\n&#34;,&#34;title&#34;:&#34;JDK8 之 Stream 与 函数式编程&#34;,&#34;tags&#34;:[{&#34;index&#34;:-1,&#34;name&#34;:&#34;JDK&#34;,&#34;slug&#34;:&#34;WiGwDpD94&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://wenbozhangw.github.io/tag/WiGwDpD94/&#34;}],&#34;date&#34;:&#34;2022-01-18 16:09:39&#34;,&#34;dateFormat&#34;:&#34;2022-01-18&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://wenbozhangw.github.io/post/jdk8-zhi-stream-yu-han-shu-shi-bian-cheng/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;34 min read&#34;,&#34;time&#34;:2019000,&#34;words&#34;:7954,&#34;minutes&#34;:34},&#34;description&#34;:&#34;Java 8 引入了 Stream 流式处理与 lambda 表达式，本文从 API 层面介绍相关使用。\n\n区别总览\n\n\n\n名称\n参数\n返回值\n实例\n\n\n\n\nConsumer\n有\n无\nIterable上的forEach方法\n\n\nFuncti...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%8C%BA%E5%88%AB%E6%80%BB%E8%A7%88\&#34;&gt;区别总览&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E8%AF%A6%E7%BB%86%E8%A7%A3%E9%87%8A\&#34;&gt;详细解释&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#supplier\&#34;&gt;Supplier&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#consumer\&#34;&gt;Consumer&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#function\&#34;&gt;Function&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#predicate\&#34;&gt;Predicate&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B%E6%8E%A5%E5%8F%A3%E7%9A%84%E4%BD%BF%E7%94%A8\&#34;&gt;函数式编程接口的使用&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#java8%E7%9A%84%E4%B8%89%E4%B8%AA%E7%BC%96%E7%A8%8B%E6%A6%82%E5%BF%B5\&#34;&gt;Java8的三个编程概念&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#stream\&#34;&gt;Stream&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#lambda\&#34;&gt;Lambda&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%87%BD%E6%95%B0%E5%BC%8F%E6%8E%A5%E5%8F%A3\&#34;&gt;函数式接口&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#functionalinterface%E6%B3%A8%E8%A7%A3\&#34;&gt;FunctionalInterface注解&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%87%BD%E6%95%B0%E6%8F%8F%E8%BF%B0%E7%AC%A6\&#34;&gt;函数描述符&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%96%B9%E6%B3%95%E5%BC%95%E7%94%A8\&#34;&gt;方法引用&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#36-%E6%B5%81\&#34;&gt;3.6 流&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E7%AD%9B%E9%80%89\&#34;&gt;筛选&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%B5%81%E7%9A%84%E5%88%87%E7%89%87\&#34;&gt;流的切片&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%98%A0%E5%B0%84\&#34;&gt;映射&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%9F%A5%E6%89%BE%E4%B8%8E%E5%8C%B9%E9%85%8D\&#34;&gt;查找与匹配&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%BD%92%E7%BA%A6\&#34;&gt;归约&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%95%B0%E5%80%BC%E6%B5%81\&#34;&gt;数值流&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%95%B0%E5%80%BC%E8%8C%83%E5%9B%B4\&#34;&gt;数值范围&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%9E%84%E5%BB%BA%E6%B5%81\&#34;&gt;构建流&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E8%BF%AD%E4%BB%A3\&#34;&gt;迭代：&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E7%94%9F%E6%88%90\&#34;&gt;生成&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E7%94%A8%E6%B5%81%E6%94%B6%E9%9B%86%E6%95%B0%E6%8D%AE\&#34;&gt;用流收集数据&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%BD%92%E7%BA%A6%E5%92%8C%E6%B1%87%E6%80%BB\&#34;&gt;归约和汇总&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%88%86%E7%BB%84\&#34;&gt;分组&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%93%8D%E4%BD%9C%E5%88%86%E7%BB%84%E7%9A%84%E5%85%83%E7%B4%A0\&#34;&gt;操作分组的元素&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%A4%9A%E7%BA%A7%E5%88%86%E7%BB%84\&#34;&gt;多级分组&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%8C%89%E5%AD%90%E7%BB%84%E6%94%B6%E9%9B%86%E6%95%B0%E6%8D%AE\&#34;&gt;按子组收集数据&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%88%86%E5%8C%BA\&#34;&gt;分区&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%94%B6%E9%9B%86%E5%99%A8%E6%8E%A5%E5%8F%A3\&#34;&gt;收集器接口&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%BB%A5tolistcollector%E4%B8%BA%E4%BE%8B\&#34;&gt;以ToListCollector为例&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E8%BF%9B%E8%A1%8C%E8%87%AA%E5%AE%9A%E4%B9%89%E6%94%B6%E9%9B%86%E8%80%8C%E4%B8%8D%E5%8E%BB%E5%AE%9E%E7%8E%B0collector\&#34;&gt;进行自定义收集，而不去实现Collector&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%B9%B6%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%B8%8E%E6%80%A7%E8%83%BD\&#34;&gt;并行数据处理与性能&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#collection-api%E7%9A%84%E5%A2%9E%E5%BC%BA%E5%8A%9F%E8%83%BD\&#34;&gt;Collection API的增强功能&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E9%87%8D%E8%BD%BD%E4%B8%8E%E5%8F%98%E5%8F%82\&#34;&gt;重载与变参&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%BD%BF%E7%94%A8list-set%E5%92%8Cmap\&#34;&gt;使用List、Set和Map&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E9%87%8D%E6%9E%84\&#34;&gt;重构&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%94%B9%E5%96%84%E4%BB%A3%E7%A0%81%E5%8F%AF%E8%AF%BB%E6%80%A7\&#34;&gt;改善代码可读性&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;p&gt;本文介绍一下 aerospike 的基本概念以及相关数据类型。&lt;/p&gt;\n&lt;!-- more --&gt;\n&lt;h2 id=\&#34;什么是-aerospike-as\&#34;&gt;什么是 Aerospike （AS）&lt;/h2&gt;\n&lt;p&gt;Aerospike是一个分布式，可扩展，高可用的K-V类型的Nosql数据库。提供类似传统数据库的ACID操作。&lt;/p&gt;\n&lt;p&gt;采用混合架构，索引存储在RAM中，而数据存储在闪存/固态硬盘（SSD）上，自动感知集群，可以随意增加节点线性扩容，无需分片，无需人工干预（性能与节点成正比上升），支持多语言集成；与redis相比不会遇到性能瓶颈，客户端SQL介入对RDBMS支持友好。&lt;/p&gt;\n&lt;h2 id=\&#34;为什么要用-as\&#34;&gt;为什么要用 AS&lt;/h2&gt;\n&lt;p&gt;K-V类型的数据库必须要提的就是redis，redis数据完全存储在内存，虽然保证了查询的性能，但是成本太高。AS最大的卖点就是可以存储在SSD上，并且保证和redis相同的查询性能。AS内部在访问SSD屏蔽了文件系统层级，直接访问地址，保证了数据的读取速度。AS同时支持二级索引与聚合，支持简单的sql操作，相比于其他nosql数据库，有一定优势。&lt;/p&gt;\n&lt;h2 id=\&#34;基本概念\&#34;&gt;基本概念&lt;/h2&gt;\n&lt;h3 id=\&#34;namespaces\&#34;&gt;Namespaces&lt;/h3&gt;\n&lt;p&gt;AS数据存储的最高层级，类比于传统数据库的库层级，一个namespace包含记录（records），索引（indexes）及策略（policies）。其中策略决定namespace的行为，包括：&lt;br&gt;\n​\t\t1.数据的存储位置是内存还是SSD。&lt;br&gt;\n​\t\t2.一条记录存储的副本个数。&lt;br&gt;\n​\t\t3.过期时间（TTL）：不同于redis的针对key设置TTL，AS可以在库的层级进行全局设置，并且支持对于已存在的数据进行TTL的设置，方便了使用。&lt;/p&gt;\n&lt;h3 id=\&#34;set\&#34;&gt;Set&lt;/h3&gt;\n&lt;p&gt;存储namespace，是一个逻辑分区，类比于传统数据库的表。set的存储策略继承自namespace，也可以为set设置单独的存储策略。&lt;/p&gt;\n&lt;h3 id=\&#34;records\&#34;&gt;Records&lt;/h3&gt;\n&lt;p&gt;类比于传统数据库的行，包含key，Bins（value）和Metadata（元数据）。key全局唯一，作为K-V数据库一般也是通过key去查询。Bins相当于列，存储具体的数据。元数据存储一些基本信息，例如TTL等。&lt;/p&gt;\n&lt;h3 id=\&#34;key\&#34;&gt;Key&lt;/h3&gt;\n&lt;p&gt;提到key，有一个和key伴生的概念是摘要（Digests），当key被存入数据库，key与set信息一起被哈希化成一个160位的摘要。数据库中，摘要为所有操作定位记录。key主要用于应用程序访问，而摘要主要用于数据库内部查找记录。&lt;/p&gt;\n&lt;h3 id=\&#34;metadata\&#34;&gt;Metadata&lt;/h3&gt;\n&lt;p&gt;每一条记录包含以下几条元数据：&lt;/p&gt;\n&lt;ol&gt;\n&lt;li&gt;generation（代）：表示记录被修改的次数。该数字在程序读数据时返回，用来确认正在写入的数据从最后一次读开始未被修改过。&lt;/li&gt;\n&lt;li&gt;time-to-live（TTL）：AS会自动根据记录的TTL使其过期。每次在对象上执行写操作TTL就会增加。3.10.1版本以上，可以通过设置策略，使更新记录时不刷新TTL。&lt;/li&gt;\n&lt;li&gt;last-update-time（LUT）：上次更新时间，这是一个数据库内部的元数据，不会返回给客户端。&lt;/li&gt;\n&lt;/ol&gt;\n&lt;h3 id=\&#34;bins\&#34;&gt;Bins&lt;/h3&gt;\n&lt;p&gt;在一条记录里，数据被存储在一个或多个bins里，bins由名称和值组成。bins不需要指定数据类型，数据类型有bins中的值决定。动态的数据类型提供了很好的灵活性。AS中每条记录可以由不同的bins组成。记录无模式，你可以记录的任何生命周期或删除bins。&lt;br&gt;\n​在一个库中bins的名称最多包含32K，这是由内部字符串优化所致。（相比于HBase支持几百万列还是有一定差距，如果想直接将HBase表迁移到AS可能需要重新设计存储结构）&lt;/p&gt;\n&lt;h3 id=\&#34;数据类型\&#34;&gt;数据类型&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;integer&lt;/li&gt;\n&lt;li&gt;string&lt;/li&gt;\n&lt;li&gt;bytes&lt;/li&gt;\n&lt;li&gt;double&lt;/li&gt;\n&lt;li&gt;list&lt;/li&gt;\n&lt;li&gt;map&lt;/li&gt;\n&lt;li&gt;GeoJson&lt;/li&gt;\n&lt;li&gt;Native-language serialized（blobs）&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 id=\&#34;总结\&#34;&gt;总结&lt;/h2&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;Aerospike&lt;/th&gt;\n&lt;th&gt;RDBMS&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;namespace&lt;/td&gt;\n&lt;td&gt;类似于数据库，最多可设置32个。一个namespace可关联多块SSD，一块SSD只关联一个namespace，每个namespace下包含4096个分片&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;set&lt;/td&gt;\n&lt;td&gt;类似于数据库表，一个namespace最多1023个set&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;bin&lt;/td&gt;\n&lt;td&gt;类似于数据库字段，支持Java基本数据类型：List、Map、Blob，一个namespace下最多32767个bin&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;record&lt;/td&gt;\n&lt;td&gt;类似数据库中的一条记录，采用Schema-Less的方式&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;p&gt;​\t\t每个namespace包含多个set，每个set包含多条record，每个record包含多个bin(数据库列)，可通过索引key来查询record。不同的业务可以使用同一个集群的不同namespace来作做资源隔离，从而实现资源池化、最大化利用资源的目的。&lt;br&gt;\n​\t\tRedis和Aerospike对比：&lt;/p&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;&lt;/th&gt;\n&lt;th&gt;redis&lt;/th&gt;\n&lt;th&gt;Aerospike&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;运维&lt;/td&gt;\n&lt;td&gt;运维成本较高，扩容麻烦&lt;/td&gt;\n&lt;td&gt;部署和扩容都比较容易&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;性能&lt;/td&gt;\n&lt;td&gt;读写性能高&lt;/td&gt;\n&lt;td&gt;读性能高，写性能中高&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;使用成本&lt;/td&gt;\n&lt;td&gt;纯内存数据库，成本高&lt;/td&gt;\n&lt;td&gt;内存+ssd，成本较低&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;其他方面&lt;/td&gt;\n&lt;td&gt;内存浪费严重。数据结构丰富，应用场景广泛&lt;/td&gt;\n&lt;td&gt;支持二级索引，满足场景需求，支持聚合&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;排序&lt;/td&gt;\n&lt;td&gt;支持排序&lt;/td&gt;\n&lt;td&gt;不支持排序&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;集群管理&lt;/td&gt;\n&lt;td&gt;简单集群管理&lt;/td&gt;\n&lt;td&gt;相当强大，多个平等的节点，平摊存储所有数据，&lt;br /&gt;并且相互备份。集群节点的失效及添&lt;br /&gt;加完全自动化处理，不影响用户请求。&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;事务&lt;/td&gt;\n&lt;td&gt;支持简单事务&lt;/td&gt;\n&lt;td&gt;支持行事务&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;p&gt;&lt;strong&gt;Aerospike优点：&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;Aerospike是一个高性能、可扩展、可靠性强的NoSQL解决方案，支持RAM和SSD作为存储介质，并专门针对SSD特殊优化，广泛应用于实时竞价等实时计算领域。官方保证99%的操作在1ms内完成，并提供集群数据自动Rebalance、集群感知客户端等功能，且支持超大规模数据集(100T级别)的存储。&lt;/p&gt;\n&lt;p&gt;作为KV存储，Aerospike提供多种数据类型，其操作方式和Redis比较类似。除基础功能之外，Aerospike还支持AMC控制台、API等多种监控方式，有集群QPS、健康度、负载等多项监控指标，对运维比较友好。支持集群内数据的自动Rebalance，和Redis集群方案相比，维护成本下降不少。&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Aerospike缺点：&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;只支持batch read，不支持batch writes&lt;/li&gt;\n&lt;li&gt;记录大小有限制: &amp;lt;= 1M =&amp;gt; 有点小，不过对于我们的场景基本没问题&lt;/li&gt;\n&lt;li&gt;bin name长度: &amp;lt;= 14 Chars =&amp;gt; 一般来说单字段不会超过，嵌套属性如果拼接就很容易超长&lt;/li&gt;\n&lt;li&gt;没有内建的聚合函数(Aggregations: count, max, min, sum, group by, etc.)，通过UDFs可以支持（queryAggregate），但是使用方式不友好，效率也不高&lt;/li&gt;\n&lt;li&gt;namespace 下的sets限制1024，二级索引限制256，唯一binname限制32K，一个namespace下最多4 billion记录&lt;/li&gt;\n&lt;li&gt;范围查询只支持BETWEEN语句，没有小于，大于查询，并且RANGE结果只支持包含&lt;/li&gt;\n&lt;li&gt;范围查询只支持整数类型，不支持浮点数&lt;/li&gt;\n&lt;li&gt;Query不支持分页(no cursor or pagination..)&lt;/li&gt;\n&lt;li&gt;Query不支持排序(no order by..)&lt;/li&gt;\n&lt;li&gt;不支持动态创建namespace，只能通过修改配置文件、重启服务器&lt;/li&gt;\n&lt;li&gt;只有清空set数据接口，但是并没有真正drop掉sets（会留下empty set，然后一个namespace下只有有1024个sets..）&lt;/li&gt;\n&lt;/ul&gt;\n&#34;,&#34;fileName&#34;:&#34;aerospike-ji-ben-gai-nian&#34;,&#34;abstract&#34;:&#34;&lt;p&gt;本文介绍一下 aerospike 的基本概念以及相关数据类型。&lt;/p&gt;\n&#34;,&#34;title&#34;:&#34;Aerospike 基本概念&#34;,&#34;tags&#34;:[{&#34;index&#34;:-1,&#34;name&#34;:&#34;Aerospike&#34;,&#34;slug&#34;:&#34;VSeqxthmr&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://wenbozhangw.github.io/tag/VSeqxthmr/&#34;}],&#34;date&#34;:&#34;2022-01-18 15:56:13&#34;,&#34;dateFormat&#34;:&#34;2022-01-18&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://wenbozhangw.github.io/post/aerospike-ji-ben-gai-nian/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;7 min read&#34;,&#34;time&#34;:389000,&#34;words&#34;:1786,&#34;minutes&#34;:7},&#34;description&#34;:&#34;本文介绍一下 aerospike 的基本概念以及相关数据类型。\n\n什么是 Aerospike （AS）\nAerospike是一个分布式，可扩展，高可用的K-V类型的Nosql数据库。提供类似传统数据库的ACID操作。\n采用混合架构，索引存储...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%BB%80%E4%B9%88%E6%98%AF-aerospike-as\&#34;&gt;什么是 Aerospike （AS）&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%94%A8-as\&#34;&gt;为什么要用 AS&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5\&#34;&gt;基本概念&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#namespaces\&#34;&gt;Namespaces&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#set\&#34;&gt;Set&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#records\&#34;&gt;Records&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#key\&#34;&gt;Key&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#metadata\&#34;&gt;Metadata&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#bins\&#34;&gt;Bins&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B\&#34;&gt;数据类型&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%80%BB%E7%BB%93\&#34;&gt;总结&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;p&gt;ASCII（（American Standard Code for Information Interchange）：美国信息交换标准代码）是基于拉丁字母的一套电脑编码系统，主要用于现代英语和其他西欧语言。&lt;/p&gt;\n&lt;!-- more --&gt;\n&lt;h2 id=\&#34;ascii编码\&#34;&gt;ASCII编码&lt;/h2&gt;\n&lt;p&gt;ASCII（（American Standard Code for Information Interchange）：美国信息交换标准代码）是基于拉丁字母的一套电脑编码系统，主要用于现代英语和其他西欧语言。它是最通用的信息交换标准，并等同于国际标准 ISO/IEC 646。ASCII 第一次以规范标准的类型发表是在1967年，最后一次更新则是在1986年，到目前为止共定义了128个字符。&lt;/p&gt;\n&lt;h3 id=\&#34;产生原因\&#34;&gt;产生原因&lt;/h3&gt;\n&lt;p&gt;在计算机中，所有的数据在&lt;a href=\&#34;https://baike.baidu.com/item/%E5%AD%98%E5%82%A8\&#34;&gt;存储&lt;/a&gt;和运算时都要使用&lt;a href=\&#34;https://baike.baidu.com/item/%E4%BA%8C%E8%BF%9B%E5%88%B6/361457\&#34;&gt;二进制&lt;/a&gt;数表示（因为计算机用&lt;a href=\&#34;https://baike.baidu.com/item/%E9%AB%98%E7%94%B5%E5%B9%B3/9753092\&#34;&gt;高电平&lt;/a&gt;和&lt;a href=\&#34;https://baike.baidu.com/item/%E4%BD%8E%E7%94%B5%E5%B9%B3/6946314\&#34;&gt;低电平&lt;/a&gt;分别表示1和0），例如，像a、b、c、d这样的52个字母（包括大写）以及0、1等数字还有一些常用的符号（例如*、#、@等）在计算机中存储时也要使用&lt;a href=\&#34;https://baike.baidu.com/item/%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%95%B0/108101\&#34;&gt;二进制数&lt;/a&gt;来表示，而具体用哪些二进制数字表示哪个符号，当然每个人都可以约定自己的一套（这就叫&lt;a href=\&#34;https://baike.baidu.com/item/%E7%BC%96%E7%A0%81\&#34;&gt;编码&lt;/a&gt;），而大家如果要想互相通信而不造成混乱，那么大家就必须使用相同的编码规则，于是美国有关的标准化组织就出台了ASCII&lt;a href=\&#34;https://baike.baidu.com/item/%E7%BC%96%E7%A0%81/80092\&#34;&gt;编码&lt;/a&gt;，统一规定了上述常用符号用哪些二进制数来表示 [2] 。&lt;/p&gt;\n&lt;p&gt;美国信息交换标准代码是由&lt;a href=\&#34;https://baike.baidu.com/item/%E7%BE%8E%E5%9B%BD%E5%9B%BD%E5%AE%B6%E6%A0%87%E5%87%86%E5%AD%A6%E4%BC%9A/1351184\&#34;&gt;美国国家标准学会&lt;/a&gt;(American National Standard Institute , ANSI )制定的，是一种标准的单字节字符&lt;a href=\&#34;https://baike.baidu.com/item/%E7%BC%96%E7%A0%81\&#34;&gt;编码&lt;/a&gt;方案，用于基于&lt;a href=\&#34;https://baike.baidu.com/item/%E6%96%87%E6%9C%AC\&#34;&gt;文本&lt;/a&gt;的数据。它最初是美国国家标准，供不同计算机在相互通信时用作共同遵守的西文&lt;a href=\&#34;https://baike.baidu.com/item/%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81\&#34;&gt;字符编码&lt;/a&gt;标准，后来它被&lt;a href=\&#34;https://baike.baidu.com/item/%E5%9B%BD%E9%99%85%E6%A0%87%E5%87%86%E5%8C%96%E7%BB%84%E7%BB%87\&#34;&gt;国际标准化组织&lt;/a&gt;（International Organization for Standardization, ISO）定为国际标准，称为ISO 646标准。适用于所有拉丁文字字母。&lt;/p&gt;\n&lt;h3 id=\&#34;表达方式\&#34;&gt;表达方式&lt;/h3&gt;\n&lt;p&gt;ASCII 码使用指定的7 位或8 位&lt;a href=\&#34;https://baike.baidu.com/item/%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%95%B0\&#34;&gt;二进制数&lt;/a&gt;组合来表示128 或256 种可能的&lt;a href=\&#34;https://baike.baidu.com/item/%E5%AD%97%E7%AC%A6\&#34;&gt;字符&lt;/a&gt;。标准ASCII 码也叫基础ASCII码，使用7 位&lt;a href=\&#34;https://baike.baidu.com/item/%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%95%B0\&#34;&gt;二进制数&lt;/a&gt;（剩下的1位二进制为0）来表示所有的大写和小写字母，数字0 到9、标点符号，以及在美式英语中使用的特殊&lt;a href=\&#34;https://baike.baidu.com/item/%E6%8E%A7%E5%88%B6%E5%AD%97%E7%AC%A6\&#34;&gt;控制字符&lt;/a&gt; [1] 。其中：&lt;/p&gt;\n&lt;p&gt;**0～31及127(共33个)是&lt;a href=\&#34;https://baike.baidu.com/item/%E6%8E%A7%E5%88%B6%E5%AD%97%E7%AC%A6\&#34;&gt;控制字符&lt;/a&gt;或通信专用字符（其余为可显示字符），**如控制符：LF（换行）、CR（&lt;a href=\&#34;https://baike.baidu.com/item/%E5%9B%9E%E8%BD%A6\&#34;&gt;回车&lt;/a&gt;）、FF（换页）、DEL（&lt;a href=\&#34;https://baike.baidu.com/item/%E5%88%A0%E9%99%A4/13020275\&#34;&gt;删除&lt;/a&gt;）、BS（退格)、BEL（响铃）等；通信专用字符：SOH（文头）、EOT（文尾）、ACK（确认）等；ASCII值为8、9、10 和13 分别转换为&lt;a href=\&#34;https://baike.baidu.com/item/%E9%80%80%E6%A0%BC\&#34;&gt;退格&lt;/a&gt;、制表、换行和回车字符。它们并没有特定的图形显示，但会依不同的应用程序，而对&lt;a href=\&#34;https://baike.baidu.com/item/%E6%96%87%E6%9C%AC\&#34;&gt;文本&lt;/a&gt;显示有不同的影响 [1] 。&lt;/p&gt;\n&lt;p&gt;32～126(共95个)是&lt;a href=\&#34;https://baike.baidu.com/item/%E5%AD%97%E7%AC%A6\&#34;&gt;字符&lt;/a&gt;(32是空格），其中48～57为0到9十个阿拉伯数字。&lt;/p&gt;\n&lt;p&gt;65～90为26个大写英文字母，97～122号为26个小写英文字母，其余为一些标点符号、运算符号等。&lt;/p&gt;\n&lt;p&gt;同时还要注意，在标准ASCII中，其最高位(b7)用作&lt;a href=\&#34;https://baike.baidu.com/item/%E5%A5%87%E5%81%B6%E6%A0%A1%E9%AA%8C%E4%BD%8D\&#34;&gt;奇偶校验位&lt;/a&gt;。所谓奇偶校验，是指在代码传送过程中用来检验是否出现错误的一种方法，一般分&lt;a href=\&#34;https://baike.baidu.com/item/%E5%A5%87%E6%A0%A1%E9%AA%8C\&#34;&gt;奇校验&lt;/a&gt;和偶校验两种。&lt;a href=\&#34;https://baike.baidu.com/item/%E5%A5%87%E6%A0%A1%E9%AA%8C\&#34;&gt;奇校验&lt;/a&gt;规定：正确的代码一个&lt;a href=\&#34;https://baike.baidu.com/item/%E5%AD%97%E8%8A%82\&#34;&gt;字节&lt;/a&gt;中1的个数必须是奇数，若非奇数，则在最高位b7添1；偶校验规定：正确的代码一个字节中1的个数必须是&lt;a href=\&#34;https://baike.baidu.com/item/%E5%81%B6%E6%95%B0\&#34;&gt;偶数&lt;/a&gt;，若非偶数，则在最高位b7添1 [1] 。&lt;/p&gt;\n&lt;p&gt;后128个称为&lt;a href=\&#34;https://baike.baidu.com/item/%E6%89%A9%E5%B1%95ASCII\&#34;&gt;扩展ASCII&lt;/a&gt;码。许多基于&lt;a href=\&#34;https://baike.baidu.com/item/x86\&#34;&gt;x86&lt;/a&gt;的系统都支持使用扩展（或“高”）ASCII。扩展ASCII 码允许将每个字符的第8 位用于确定附加的128 个特殊符号字符、外来语字母和图形符号 [1] 。&lt;/p&gt;\n&lt;h3 id=\&#34;大小规则\&#34;&gt;大小规则&lt;/h3&gt;\n&lt;p&gt;常见ASCII码的大小规则：0~9&amp;lt;A~Z&amp;lt;a~z。&lt;/p&gt;\n&lt;p&gt;1）数字比字母要小。如 “7”&amp;lt;“F”；&lt;/p&gt;\n&lt;p&gt;2）数字0比数字9要小，并按0到9顺序递增。如 “3”&amp;lt;“8” ；&lt;/p&gt;\n&lt;p&gt;3）字母A比字母Z要小，并按A到Z顺序递增。如“A”&amp;lt;“Z” ；&lt;/p&gt;\n&lt;p&gt;4）同个字母的大写字母比小写字母要小32。如“A”&amp;lt;“a” 。&lt;/p&gt;\n&lt;p&gt;几个常见字母的ASCII码大小： “A”为65；“a”为97；“0”为 48 [4] 。&lt;/p&gt;\n&lt;h3 id=\&#34;问题\&#34;&gt;问题&lt;/h3&gt;\n&lt;p&gt;在英语中，用128个符号编码便可以表示所有，但是用来表示其他语言，128个符号是不够的。比如，在&lt;a href=\&#34;https://baike.baidu.com/item/%E6%B3%95%E8%AF%AD/660115\&#34;&gt;法语&lt;/a&gt;中，字母上方有注音符号，它就无法用 ASCII 码表示。于是，一些欧洲国家就决定，利用字节中闲置的最高位编入新的符号。比如，法语中的é的编码为130（二进制10000010）。这样一来，这些欧洲国家使用的编码体系，可以表示最多256个符号 [5] 。&lt;/p&gt;\n&lt;p&gt;但是，这里又出现了新的问题。不同的国家有不同的字母，因此，哪怕它们都使用256个符号的编码方式，代表的字母却不一样。比如，130在&lt;a href=\&#34;https://baike.baidu.com/item/%E6%B3%95%E8%AF%AD/660115\&#34;&gt;法语&lt;/a&gt;编码中代表了é，在&lt;a href=\&#34;https://baike.baidu.com/item/%E5%B8%8C%E4%BC%AF%E6%9D%A5%E8%AF%AD/2612441\&#34;&gt;希伯来语&lt;/a&gt;编码中却代表了字母Gimel (ג)，在&lt;a href=\&#34;https://baike.baidu.com/item/%E4%BF%84%E8%AF%AD/315852\&#34;&gt;俄语&lt;/a&gt;编码中又会代表另一个符号。但是不管怎样，所有这些编码方式中，0--127表示的符号是一样的，不一样的只是128--255的这一段 [5] 。&lt;/p&gt;\n&lt;p&gt;至于&lt;a href=\&#34;https://baike.baidu.com/item/%E4%BA%9A%E6%B4%B2/133681\&#34;&gt;亚洲&lt;/a&gt;国家的文字，使用的符号就更多了，汉字就多达10万左右。一个字节只能表示256种符号，肯定是不够的，就必须使用多个字节表达一个符号。比如，简体中文常见的编码方式是 &lt;a href=\&#34;https://baike.baidu.com/item/GB2312/483170\&#34;&gt;GB2312&lt;/a&gt;，使用两个字节表示一个汉字，所以理论上最多可以表示 256 x 256 = 65536 个符号 [5] 。&lt;/p&gt;\n&lt;h3 id=\&#34;扩展\&#34;&gt;扩展&lt;/h3&gt;\n&lt;ol&gt;\n&lt;li&gt;\n&lt;p&gt;1981年IBM PC ROM256个字符的字符集，即IBM扩展字符集 [5] 。&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;1985年11&lt;a href=\&#34;https://baike.baidu.com/item/Windows/165458\&#34;&gt;Windows&lt;/a&gt;字符集被称作“&lt;a href=\&#34;https://baike.baidu.com/item/ANSI/10401940\&#34;&gt;ANSI&lt;/a&gt;字符集”，遵循了ANSI草案和&lt;a href=\&#34;https://baike.baidu.com/item/ISO/10400\&#34;&gt;ISO&lt;/a&gt;标准（ANSI/ISO&lt;a href=\&#34;https://baike.baidu.com/item/8859-1\&#34;&gt;8859-1&lt;/a&gt;-1987，简“Latin 1” [5] 。&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;为了解决中国、日本和韩国的象形文字符和ASCII的某种兼容性，出现了双字节字符集（&lt;a href=\&#34;https://baike.baidu.com/item/DBCS/4572615\&#34;&gt;DBCS&lt;/a&gt;：double-byte character set）。DBCS从 第256 代码开始，就像ASCII一样，最初的128个代码是ASCII。然而，较高的128个代码中的某些总是跟随着第二个字节。这两个字节一起（称作首字节和跟随字节）定义一个字符，通常是一个复杂的象形文字 [6] 。&lt;/p&gt;\n&lt;/li&gt;\n&lt;/ol&gt;\n&lt;h3 id=\&#34;汉字编码\&#34;&gt;汉字编码&lt;/h3&gt;\n&lt;p&gt;目前的文字编码标准主要有 ASCII、&lt;a href=\&#34;https://baike.baidu.com/item/GB2312/483170\&#34;&gt;GB2312&lt;/a&gt;、&lt;a href=\&#34;https://baike.baidu.com/item/GBK/481954\&#34;&gt;GBK&lt;/a&gt;、&lt;a href=\&#34;https://baike.baidu.com/item/Unicode/750500\&#34;&gt;Unicode&lt;/a&gt;等。ASCII 编码是最简单的西文编码方案。GB2312、GBK、GB18030 是汉字字符编码方案的国家标准。ISO/IEC 10646 和 Unicode 都是全球字符编码的国际标准 [4] 。下面对与汉字相关的编码方案GB2312，GBK与GB18030做简要的分析。&lt;/p&gt;\n&lt;h4 id=\&#34;gb2312-80-标准\&#34;&gt;GB2312-80 标准&lt;/h4&gt;\n&lt;p&gt;GB2312-80 是 1980 年制定的中国汉字编码国家标准。共收录 7445 个字符，其中汉字 6763 个。GB2312 兼容标准 ASCII码，采用扩展 ASCII 码的编码空间进行编码，一个汉字占用两个字节，每个字节的最高位为 1。具体办法是：收集了 7445 个字符组成 94*94 的方阵，每一行称为一个“区”，每一列称为一个“位”，区号位号的范围均为 01-94，区号和位号组成的代码称为“区位码”。区位输入法就是通过输入区位码实现汉字输入的。将区号和位号分别加上 20H，得到的 4 位&lt;a href=\&#34;https://baike.baidu.com/item/%E5%8D%81%E5%85%AD%E8%BF%9B%E5%88%B6/4162457\&#34;&gt;十六进制&lt;/a&gt;整数称为&lt;a href=\&#34;https://baike.baidu.com/item/%E5%9B%BD%E6%A0%87%E7%A0%81/9886729\&#34;&gt;国标码&lt;/a&gt;，编码范围为 0x2121～0x7E7E。为了兼容标准 ASCII 码，给国标码的每个字节加 80H，形成的编码称为&lt;a href=\&#34;https://baike.baidu.com/item/%E6%9C%BA%E5%86%85%E7%A0%81/8481225\&#34;&gt;机内码&lt;/a&gt;，简称内码，是汉字在机器中实际的存储代码GB2312-80 标准的内码范围是 0xA1A1～0xFEFE [7] 。&lt;/p&gt;\n&lt;h4 id=\&#34;gbk-编码标准\&#34;&gt;GBK 编码标准&lt;/h4&gt;\n&lt;p&gt;《汉字内码扩展规范》(&lt;a href=\&#34;https://baike.baidu.com/item/GBK/481954\&#34;&gt;GBK&lt;/a&gt;) 于1995年制定，兼容GB2312、GB13000-1、BIG5 编码中的所有汉字，使用双字节编码，编码空间为 0x8140～0xFEFE，共有 23940 个码位，其中 GBK1 区和 GBK2 区也是 GB2312 的编码范围。收录了 21003 个汉字。&lt;a href=\&#34;https://baike.baidu.com/item/GBK/481954\&#34;&gt;GBK&lt;/a&gt;向下与 GB 2312 编码兼容，向上支持 ISO 10646.1&lt;a href=\&#34;https://baike.baidu.com/item/%E5%9B%BD%E9%99%85%E6%A0%87%E5%87%86/4495981\&#34;&gt;国际标准&lt;/a&gt;，是前者向后者过渡过程中的一个承上启下的产物。ISO 10646 是&lt;a href=\&#34;https://baike.baidu.com/item/%E5%9B%BD%E9%99%85%E6%A0%87%E5%87%86%E5%8C%96%E7%BB%84%E7%BB%87/779832\&#34;&gt;国际标准化组织&lt;/a&gt;ISO 公布的一个编码标准，即 Universal Multilpe-Octet Coded Character Set（简称UCS），大陆译为《通用多八位编码字符集》，台湾译为《广用多八位元编码字元集》，它与 Unicode 组织的&lt;a href=\&#34;https://baike.baidu.com/item/Unicode/750500\&#34;&gt;Unicode&lt;/a&gt;编码完全兼容。ISO 10646.1 是该标准的第一部分《体系结构与基本多文种平面》。我国 1993 年以 GB 13000.1 国家标准的形式予以认可（即 GB 13000.1 等同于 ISO 10646.1） [7] 。&lt;/p&gt;\n&lt;h4 id=\&#34;gb18030编码标准\&#34;&gt;GB18030编码标准&lt;/h4&gt;\n&lt;p&gt;国家标准GB18030-2000《信息交换用汉字编码&lt;a href=\&#34;https://baike.baidu.com/item/%E5%AD%97%E7%AC%A6%E9%9B%86/946585\&#34;&gt;字符集&lt;/a&gt;基本集的补充》是我国继GB2312-1980和GB13000-1993之后最重要的汉字编码标准，是我国计算机系统必须遵循的基础性标准之一。GB18030-2000编码标准是由信息产业部和&lt;a href=\&#34;https://baike.baidu.com/item/%E5%9B%BD%E5%AE%B6%E8%B4%A8%E9%87%8F%E6%8A%80%E6%9C%AF%E7%9B%91%E7%9D%A3%E5%B1%80/976606\&#34;&gt;国家质量技术监督局&lt;/a&gt;在2000年 3月17日联合发布的，并且将作为一项国家标准在2001年的1月正式强制执行。GB18030-2005《信息技术中文编码字符集》是我国制订的以汉字为主并包含多种我国少数民族文字（如藏、蒙古、傣、彝、朝鲜、维吾尔文等）的超大型中文编码字符集强制性标准，其中收入汉字70000余个 [8] 。&lt;/p&gt;\n&lt;h2 id=\&#34;latin1编码\&#34;&gt;Latin1编码&lt;/h2&gt;\n&lt;p&gt;Latin1是ISO-8859-1的别名，有些环境下写作Latin-1。Latin1编码是单字节编码，向下兼容ASCII，其编码范围是0x00-0xFF，0x00-0x7F之间完全和ASCII一致，0x80-0x9F之间是控制字符，0xA0-0xFF之间是文字符号。&lt;/p&gt;\n&lt;p&gt;ASCII编码是一个7位的容器，ISO-8859-1编码是一个8位的容器。&lt;/p&gt;\n&lt;p&gt;因为Latin1编码范围使用了单字节内的所有空间，在支持Latin1编码的系统中传输和存储其他任何编码的字节流都不会被抛弃。换言之，把其他任何编码的字节流当作Latin1编码看待都没有问题。这是个很重要的特性，MySQL数据库默认编码是Latin1就是利用了这个特性。&lt;/p&gt;\n&lt;h2 id=\&#34;unicode编码\&#34;&gt;Unicode编码&lt;/h2&gt;\n&lt;p&gt;世界上存在着多种编码方式，同一个二进制数字可以被解释成不同的符号。因此，要想打开一个文本文件，就必须知道它的编码方式，否则用错误的编码方式解读，就会出现乱码。为什么电子邮件常常出现乱码？就是因为发信人和收信人使用的编码方式不一样。&lt;/p&gt;\n&lt;p&gt;可以想象，如果有一种编码，将世界上所有的符号都纳入其中。每一个符号都给予一个独一无二的编码，那么乱码问题就会消失。这就是Unicode。&lt;/p&gt;\n&lt;p&gt;Unicode当然是一个很大的集合，现在的规模可以容纳100多万个符号。每个符号的编码都不一样需要注意的是，Unicode只是一个符号集，它只规定了符号的二进制代码，却没有规定这个二进制代码应该如何存储&lt;/p&gt;\n&lt;p&gt;如果所有字符都按照最大存储空间存储，那必然会浪费很大的空间，比如所有字符都按照3字节存储，但是英文字母只需要一个字节存储就够了，就等于说一个Unicode编码的英文文档是ASCII编码文档存储空间的三倍。&lt;br&gt;\n所以，便有了变长编码—-UTF-8。&lt;/p&gt;\n&lt;h2 id=\&#34;utf-8编码\&#34;&gt;UTF-8编码&lt;/h2&gt;\n&lt;p&gt;UTF-8就是在互联网上使用最广的一种Unicode的实现方式。其他实现方式还包括UTF-16和UTF-32，不过在互联网上基本不用。&lt;/p&gt;\n&lt;p&gt;UTF-8最大的一个特点，就是它是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。如ASCII编码的内容UTF-8中就是用一个字符存储的。&lt;/p&gt;\n&lt;h2 id=\&#34;gbk编码\&#34;&gt;GBK编码&lt;/h2&gt;\n&lt;p&gt;GBK编码是在GB2312-80(也称作GB2312，GB码)标准基础上的内码扩展规范，使用了双字节编码方案。&lt;/p&gt;\n&#34;,&#34;fileName&#34;:&#34;zi-fu-bian-ma&#34;,&#34;abstract&#34;:&#34;&lt;p&gt;ASCII（（American Standard Code for Information Interchange）：美国信息交换标准代码）是基于拉丁字母的一套电脑编码系统，主要用于现代英语和其他西欧语言。&lt;/p&gt;\n&#34;,&#34;title&#34;:&#34;字符编码&#34;,&#34;tags&#34;:[{&#34;index&#34;:-1,&#34;name&#34;:&#34;编码&#34;,&#34;slug&#34;:&#34;QHMcEoinG&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://wenbozhangw.github.io/tag/QHMcEoinG/&#34;}],&#34;date&#34;:&#34;2022-01-18 15:19:01&#34;,&#34;dateFormat&#34;:&#34;2022-01-18&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://wenbozhangw.github.io/post/zi-fu-bian-ma/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;12 min read&#34;,&#34;time&#34;:686000,&#34;words&#34;:3138,&#34;minutes&#34;:12},&#34;description&#34;:&#34;ASCII（（American Standard Code for Information Interchange）：美国信息交换标准代码）是基于拉丁字母的一套电脑编码系统，主要用于现代英语和其他西欧语言。\n\nASCII编码\nASCII（（...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#ascii%E7%BC%96%E7%A0%81\&#34;&gt;ASCII编码&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%BA%A7%E7%94%9F%E5%8E%9F%E5%9B%A0\&#34;&gt;产生原因&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E8%A1%A8%E8%BE%BE%E6%96%B9%E5%BC%8F\&#34;&gt;表达方式&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%A4%A7%E5%B0%8F%E8%A7%84%E5%88%99\&#34;&gt;大小规则&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E9%97%AE%E9%A2%98\&#34;&gt;问题&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%89%A9%E5%B1%95\&#34;&gt;扩展&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%B1%89%E5%AD%97%E7%BC%96%E7%A0%81\&#34;&gt;汉字编码&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#gb2312-80-%E6%A0%87%E5%87%86\&#34;&gt;GB2312-80 标准&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#gbk-%E7%BC%96%E7%A0%81%E6%A0%87%E5%87%86\&#34;&gt;GBK 编码标准&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#gb18030%E7%BC%96%E7%A0%81%E6%A0%87%E5%87%86\&#34;&gt;GB18030编码标准&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#latin1%E7%BC%96%E7%A0%81\&#34;&gt;Latin1编码&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#unicode%E7%BC%96%E7%A0%81\&#34;&gt;Unicode编码&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#utf-8%E7%BC%96%E7%A0%81\&#34;&gt;UTF-8编码&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#gbk%E7%BC%96%E7%A0%81\&#34;&gt;GBK编码&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;p&gt;Java 项目在使用 Aerospike 缓存时，会有 Error Code 8 : Server memory error 报错，导致缓存数据无法正常写入。&lt;/p&gt;\n&lt;!-- more --&gt;\n&lt;h2 id=\&#34;一-问题背景\&#34;&gt;一、问题背景&lt;/h2&gt;\n&lt;p&gt;在 Java 客户端出现 Error Code 8 : Server memory error 报错：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;com.aerospike.client.AerospikeClient : Error Code 8: Server memory error\n\ncom.aerospike.client.AerospikeException: Error Code 8: Server memory error\n        at com.aerospike.client.command.WriteCommand.parseResult(WriteCommand.java:54)\n        at com.aerospike.client.command.SyncCommand.execute(SyncCommand.java:84)\n        at com.aerospike.client.Aerospike.put(AerospikeClient.java:378)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;在 AMC 监控中发现 &lt;strong&gt;Avail&lt;/strong&gt; 过低：&lt;br&gt;\n&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1642484946989.png\&#34; alt=\&#34;amc-low-avail\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/p&gt;\n&lt;h2 id=\&#34;二-error-code-8-出现原因\&#34;&gt;二、Error Code 8 出现原因&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;当 stop_write 触发时，出现\n&lt;ol&gt;\n&lt;li&gt;memory - stop-write-pct ，即当内存达到 SW（stop-write）时，默认 90%。&lt;/li&gt;\n&lt;li&gt;disk - min-avail-pct，当为命名空间配置的 devices 之一 (或 pmem 文件) 上的 device_available_pct 低于此指定百分比时，禁止写入（删除，副本写入和迁移写入除外），默认 5%。&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/li&gt;\n&lt;li&gt;如果不能再分配内存（但 stop_writes 通常应该先命中），也可能发生。&lt;/li&gt;\n&lt;li&gt;命名空间将不再能够接受写入请求。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 id=\&#34;三-如何恢复连续的空闲块即可用百分比available-percent\&#34;&gt;三、如何恢复连续的空闲块，即可用百分比(available percent)&lt;/h2&gt;\n&lt;h3 id=\&#34;31-什么是-available-percent\&#34;&gt;3.1 什么是 available percent?&lt;/h3&gt;\n&lt;p&gt;可用百分比 (device_available_pct)是一个关键的 Aerospike 指标，用于测量最小连续可用磁盘空间（以块大小为单位 write-block-size）跨命名空间中的所有设备，即：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;  Avail_pct = min(命名空间中所有磁盘的 contig_disk)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;32-当命名空间的可用百分比很低时会发生什么\&#34;&gt;3.2 当命名空间的可用百分比很低时会发生什么？&lt;/h3&gt;\n&lt;p&gt;从应用程序的角度来看，可用百分比低的主要表现是，当访问某个节点的名称空间在其某个设备上没有足够的连续空闲磁盘空间时，写入将会失败。在这种情况下返回给客户端的错误是：&lt;/p&gt;\n&lt;p&gt;com.aerospike.client.AerospikeException: Error Code 8: Server memory error&lt;br&gt;\nThe server will log the following WARNING:&lt;/p&gt;\n&lt;p&gt;WARNING (rw): (write.c:770) {namespaceid}: write_master: drives full&lt;br&gt;\n更准确地说，当 device_available_pct 低于任何命名空间设备上的 min-avail-pct 配置阈值（默认为 5%）时，应用程序写入将开始失败。&lt;/p&gt;\n&lt;h3 id=\&#34;33-最常见的情况和补救措施\&#34;&gt;3.3 最常见的情况和补救措施&lt;/h3&gt;\n&lt;h4 id=\&#34;331-容量过度使用或磁盘真的已满\&#34;&gt;3.3.1 容量过度使用（或磁盘真的“已满”）&lt;/h4&gt;\n&lt;p&gt;如果由于每个块的使用百分比高于容量是 defrag-lwm-pct 阈值，而没有符合碎片整理条件的块，则会发生这种情况。&lt;/p&gt;\n&lt;p&gt;验证这种情况，可以检查每个设备的设备日志行：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt; INFO (drv_ssd): (drv_ssd.c:2115) {namespaceid} /dev/xvdb: used-bytes 1626239616 free-wblocks 28505 write-q 0 write (8203,23.0) defrag-q 0 defrag-read (7981,21.7) defrag-write (1490,3.0) shadow-write-q 0 tomb-raider-read (1615,59.6)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;ul&gt;\n&lt;li&gt;如果 defrag-q 较低或为 0，并且碎片整理写入速率也较低或为 0.0，则表明没有符合碎片整理条件的块。&lt;/li&gt;\n&lt;li&gt;如果磁盘使用百分比 ( device_used_bytes / device_total_bytes x 100 ) 大于配置 defrag-lwm-pct，磁盘高于正常碎片整理的安全操作阈值。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;以下是可能的补救措施：&lt;/p&gt;\n&lt;ol&gt;\n&lt;li&gt;删除记录（例如使用 truncate 命令）。&lt;/li&gt;\n&lt;li&gt;如果可接受，可以对数据进行驱逐。相关配置参数如下：&lt;/li&gt;\n&lt;/ol&gt;\n&lt;ul&gt;\n&lt;li&gt;evict-tenths-pct：（增加）每次逐出的最大数据量，默认 5，逐出总数据的千分之五，如果配置为 100，则逐出数据的百分之十。&lt;/li&gt;\n&lt;li&gt;high-water-disk-pct：（减少）磁盘高水位线，当磁盘使用率大于等于此值，将进行磁盘数据逐出，默认值 60。&lt;/li&gt;\n&lt;li&gt;high-water-memory-pct：（减少）内存高水位线，当内存使用率大于等于此值，将进行内存数据逐出，默认值 50。（关于逐出，默认逐出最接近过期的数据）&lt;/li&gt;\n&lt;li&gt;nsup-delete-sleep：（减少）在版本4.5.1中已删除，因为nsup不再用于 delete transactions 。生成 delete transactions 之间要休眠的微秒数。&lt;/li&gt;\n&lt;li&gt;nsup-period：（减少）主 expiration/eviction 线程（称为 nsup, namespace supervisor）唤醒以处理命名空间的时间间隔。 nsup-period 0 的默认值禁用命名空间的 namespace supervisor 。默认情况下，该值以秒为单位。您还可以用分钟，小时或天为单位设置此值，其表示法为 1m or 1h or 1d 。如果在 nsup 工作时将其 nsup-period 动态设置为 0，则 nsup 将在完成其当前周期，然后进入休眠状态。确保时间在集群中的各个节点之间是同步的。对于 Aerospike 4.5.1 或更高版本，对于启用 nsup (即 nsup-period 不为零)的每个命名空间，如果集群始终偏斜超过 40s , 写入将被挂起。确保已安装，配置并正常运行网络时间协议（NTP）或其他时间同步机制。   在Aerospike 4.9版之前，默认值为120。   从 Aerospike 4.9 版本开始，如果 nsup-period 为 0（默认值）但 default-ttl 为非零，则服务器将不会启动，除非 allow-ttl-without-nsup 设置为 true。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;ol start=\&#34;3\&#34;&gt;\n&lt;li&gt;添加额外容量（每个命名空间有更多节点或更多设备）。&lt;/li&gt;\n&lt;li&gt;逐渐增加 defrag-lwm-pct 临界点。鉴于这将导致非线性写入放大增加，请监控性能影响。&lt;/li&gt;\n&lt;/ol&gt;\n&lt;h4 id=\&#34;332-尺寸不匹配的设备\&#34;&gt;3.3.2 尺寸不匹配的设备&lt;/h4&gt;\n&lt;p&gt;鉴于整体可用百分比的定义 – Avail_pct = min(命名空间中所有磁盘的 contig_disk) ，当有一个非常小的尺寸的设备时，如果该设备触发 stop_writes，即使其他设备拥有很大的空闲空间，依旧会出现这种情况。&lt;/p&gt;\n&lt;p&gt;检查用于使用字节和空闲 wblock 的设备特定日志行应该可以快速确定是否是这种情况。当然，验证每个设备或分区的物理大小也会产生信息。&lt;/p&gt;\n&lt;h4 id=\&#34;333-碎片整理没有跟上\&#34;&gt;3.3.3 碎片整理没有跟上&lt;/h4&gt;\n&lt;p&gt;在某些情况下，有块需要进行碎片整理，但碎片整理跟不上。将碎片整理率与每个设备日志行上的写入率进行比较。碎片整理队列 (defrag-q) 不断增加是碎片整理没有跟上的迹象：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;INFO (drv_ssd): (drv_ssd.c:2143) {namespaceid} /dev/nvme0n1: used-bytes 1182271397376 free-wblocks 1212517 write-q 0 write (1304972843,497.1) defrag-q 6743042 defrag-read (1309698931,609.4) defrag-write (639136010,191.8)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;在这种情况下，可以增加碎片整理线程的速度。默认情况下，碎片整理线程在每次块读取之间休眠 1000 微秒。这可以通过 defrag-sleep 配置选项。建议逐渐减小该值，并观察对存储子系统（例如使用iostat）和应用程序性能的潜在影响。以下命令将使读取要进行碎片整理的块的默认速度加倍。&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt; $ asinfo -v &amp;quot;set-config:context=namespace;id=&amp;lt;namespace name&amp;gt;;defrag-sleep=500&amp;quot;\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h4 id=\&#34;334-过大的-post-write-queue\&#34;&gt;3.3.4 过大的 post-write-queue&lt;/h4&gt;\n&lt;p&gt;post-write-queue中的块（默认为每个设备 256 个块）不适合进行碎片整理。对于具有小设备和大 write-block-size的命名空间，post-write-queue可能是设备本身的重要部分，甚至更大。这显然会很快导致低的可用百分比情况。&lt;/p&gt;\n&lt;p&gt;例如，在大小为 4GiB 的设备上， post-write-queue 512 和 write-block-size 8M ，对于该命名空间，此时队列占用的总大小将是 512 * 8MiB = 4096 MiB = 4GiB，并且没有进行碎片整理。&lt;/p&gt;\n&lt;h4 id=\&#34;335-碎片整理的块没有及时释放不常见\&#34;&gt;3.3.5 碎片整理的块没有及时释放（不常见）&lt;/h4&gt;\n&lt;p&gt;从 3.16.0.1 版本开始，碎片整理的块在新块上重写的数据被刷新之前不会被释放：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;[AER-5776] - (STORAGE) 在清除碎片整理的所有数据之前不要释放碎片整理的写入块。&lt;br&gt;\n在某些极端情况下，通常在记录非常少且持续更新的设备上，可能会因为碎片整理线程正在写入的新块需要很长时间才能填充大量释放的块。这在 4.3.1.5 版中得到解决：&lt;/li&gt;\n&lt;li&gt;[AER-5950] - （STORAGE）当碎片整理负载极低时，定期刷新碎片整理缓冲区以释放源写入块。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 id=\&#34;四-如何从可用百分比-0-中恢复\&#34;&gt;四、如何从可用百分比 0 中恢复&lt;/h2&gt;\n&lt;h3 id=\&#34;41-调整碎片整理速度和阈值\&#34;&gt;4.1 调整碎片整理速度和阈值&lt;/h3&gt;\n&lt;p&gt;如果碎片整理没有跟上，可以使用以下 2 个设置调整碎片整理速度和密度：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt; $ asinfo -v &amp;quot;set-config:context=namespace;id=&amp;lt;namespace name&amp;gt;;defrag-lwm-pct=50&amp;quot;\n $ asinfo -v &amp;quot;set-config:context=namespace;id=&amp;lt;namespace name&amp;gt;;defrag-sleep=500&amp;quot;\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;42-增加对过期数据的驱逐\&#34;&gt;4.2 增加对过期数据的驱逐&lt;/h3&gt;\n&lt;p&gt;可能还需要增加驱逐以允许删除更多记录并允许更多块有资格进行碎片整理。&lt;/p&gt;\n&lt;p&gt;驱逐可以通过设置进行调整：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;evict-tenths-pct（增加）&lt;/li&gt;\n&lt;li&gt;high-water-disk-pct（减少）&lt;/li&gt;\n&lt;li&gt;high-water-memory-pct（减少）&lt;/li&gt;\n&lt;li&gt;nsup-delete-sleep （减少）&lt;/li&gt;\n&lt;li&gt;nsup-period（减少）&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h3 id=\&#34;43-通过添加新节点来增加容量\&#34;&gt;4.3 通过添加新节点来增加容量&lt;/h3&gt;\n&lt;p&gt;添加新节点以增加容量很简单。如果您的系统磁盘或分区上的可用连续空间已用完，则添加新节点允许当前节点卸载 1/（new cluster size）数据。这种方法的成功几率与集群的大小成反比。您可以通过停止应用程序层生成的新写入来进一步提高成功的机会。&lt;/p&gt;\n&lt;h3 id=\&#34;44-停止节点上的服务和零碎片持久存储\&#34;&gt;4.4 停止节点上的服务和零碎片持久存储&lt;/h3&gt;\n&lt;p&gt;如果您使用复制因子 1 运行，则“dd”方法通常是不可接受的，因为此方法需要从命名空间中删除 wblock，这会导致复制因子 1 的数据丢失。&lt;/p&gt;\n&lt;p&gt;复制因子 2 可以从数据丢失中正常恢复，因为当节点恢复时，删除的数据将通过迁移（重新平衡）重新填充回节点。这种方法需要冷重启（它将是空的）并且是唯一可以保证一次性释放 wblock 的方法。&lt;/p&gt;\n&lt;p&gt;这假设集群中的其他节点没有用完 avail pct 并且可以处理迁移。&lt;/p&gt;\n&lt;p&gt;DD 命令可用于将驱动器归零 ：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;`sudo dd if=/dev/zero of=/dev/DEVICE bs =1M\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;使用 blkdiscard&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt; sudo blkdiscard /dev/&amp;lt;INSERT DEVICE NAME HERE&amp;gt;\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;删除持久存储文件&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt; sudo rm &amp;lt;Aerospike persistent storage file&amp;gt;\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;45-cold-start-evict-ttl-方法\&#34;&gt;4.5 Cold-Start-Evict-TTL 方法&lt;/h3&gt;\n&lt;p&gt;cold-start-evict-ttl告诉系统在冷启动期间将忽略 TTL 低于特定值的任何内容。这通常用于加速冷启动。当你知道你的驱逐深度很深时。要运行您的驱逐深度：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt; $ asinfo -v &amp;quot;hist-dump:ns=&amp;lt;namespace name&amp;gt;;hist=ttl&amp;quot;\n value is &amp;lt;namespace name:ttl=100,51840,0,0,0,0,0,0,0,0,0,0,0, \\\n 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, \\\n 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,920023,10263488, \\\n 20000052,20319938,23861472,20052298,21612051,22163298, \\\n 24370589,34911006,27048399,29558473,27697235,21049529, \\\n 20300346,17539324,17954128,16932493,16265998,20131370, \\\n 15997368,18030184,17260295,16613023,21100184,18003700, \\\n 20814926,19660860,18829521,23601739,17515442,21490671, \\\n 19797821,19861895,24694092,11354573,14945634,14806583, \\\n 17064793,37144797;\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;此直方图中的第一个数字表示此直方图包含多少个桶，第二个值是每个桶的宽度（以秒为单位），其余 100 个值是落在各种 ttl 范围内的记录数，最后一个是更大的记录比（100 * 宽度）。&lt;/p&gt;\n&lt;p&gt;对于这个特定的直方图，我们可以看到每个桶是 51840 秒，14.4 小时，并且在宽度和第一个填充值之间有 60 个零。这意味着当前的驱逐深度是 (60 * 51840)。&lt;/p&gt;\n&lt;p&gt;我们必须增加驱逐深度才能使这种方法起作用，成功的几率与您使用冷启动 evict-ttl 增加驱逐深度的量成正比。&lt;/p&gt;\n&lt;h2 id=\&#34;五-后记\&#34;&gt;五、后记&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;在碎片整理速度成为问题的情况下，将 SSD 分区为多个分区可能是有益的。您将失去少量的存储空间，但会获得碎片整理线程。物理 SSD 及其分区都是&amp;quot;device&amp;quot;。每个设备有一个碎片整理线程。&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;在存储充满非过期对象 (TTL=0) 的情况下，碎片整理和逐出解决方案将无济于事。在这种情况下，我们建议与实施行方商议数据的最大保留时间，尽量不要设置default-ttl为零，防止数据无法逐出，并通过添加额外的存储或节点来增加容量。&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;不管您使用的是 SDD or HDD，如果可以直接使用挂载设备，请直接配置挂载设备，这将比配置file使用文件句柄的方式效率更高。&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;如果要保证应用可用，可暂时增加 max-write-cache ，不过这个只能暂时保证数据写入，如果写入速度一直很高，依旧会出现上述问题。&lt;/p&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;pre&gt;&lt;code&gt; asinfo -v &#39;set-config:context=namespace;id=namespaceName;max-write-cache=128M&#39;\n&lt;/code&gt;&lt;/pre&gt;\n&#34;,&#34;fileName&#34;:&#34;error-code-8-server-memory-error&#34;,&#34;abstract&#34;:&#34;&lt;p&gt;Java 项目在使用 Aerospike 缓存时，会有 Error Code 8 : Server memory error 报错，导致缓存数据无法正常写入。&lt;/p&gt;\n&#34;,&#34;title&#34;:&#34;Error Code 8 : Server memory error&#34;,&#34;tags&#34;:[{&#34;index&#34;:-1,&#34;name&#34;:&#34;Aerospike&#34;,&#34;slug&#34;:&#34;VSeqxthmr&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://wenbozhangw.github.io/tag/VSeqxthmr/&#34;}],&#34;date&#34;:&#34;2022-01-18 13:40:34&#34;,&#34;dateFormat&#34;:&#34;2022-01-18&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://wenbozhangw.github.io/post/error-code-8-server-memory-error/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;13 min read&#34;,&#34;time&#34;:737000,&#34;words&#34;:3108,&#34;minutes&#34;:13},&#34;description&#34;:&#34;Java 项目在使用 Aerospike 缓存时，会有 Error Code 8 : Server memory error 报错，导致缓存数据无法正常写入。\n\n一、问题背景\n在 Java 客户端出现 Error Code 8 : Serv...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%B8%80-%E9%97%AE%E9%A2%98%E8%83%8C%E6%99%AF\&#34;&gt;一、问题背景&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%BA%8C-error-code-8-%E5%87%BA%E7%8E%B0%E5%8E%9F%E5%9B%A0\&#34;&gt;二、Error Code 8 出现原因&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%B8%89-%E5%A6%82%E4%BD%95%E6%81%A2%E5%A4%8D%E8%BF%9E%E7%BB%AD%E7%9A%84%E7%A9%BA%E9%97%B2%E5%9D%97%E5%8D%B3%E5%8F%AF%E7%94%A8%E7%99%BE%E5%88%86%E6%AF%94available-percent\&#34;&gt;三、如何恢复连续的空闲块，即可用百分比(available percent)&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#31-%E4%BB%80%E4%B9%88%E6%98%AF-available-percent\&#34;&gt;3.1 什么是 available percent?&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#32-%E5%BD%93%E5%91%BD%E5%90%8D%E7%A9%BA%E9%97%B4%E7%9A%84%E5%8F%AF%E7%94%A8%E7%99%BE%E5%88%86%E6%AF%94%E5%BE%88%E4%BD%8E%E6%97%B6%E4%BC%9A%E5%8F%91%E7%94%9F%E4%BB%80%E4%B9%88\&#34;&gt;3.2 当命名空间的可用百分比很低时会发生什么？&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#33-%E6%9C%80%E5%B8%B8%E8%A7%81%E7%9A%84%E6%83%85%E5%86%B5%E5%92%8C%E8%A1%A5%E6%95%91%E6%8E%AA%E6%96%BD\&#34;&gt;3.3 最常见的情况和补救措施&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#331-%E5%AE%B9%E9%87%8F%E8%BF%87%E5%BA%A6%E4%BD%BF%E7%94%A8%E6%88%96%E7%A3%81%E7%9B%98%E7%9C%9F%E7%9A%84%E5%B7%B2%E6%BB%A1\&#34;&gt;3.3.1 容量过度使用（或磁盘真的“已满”）&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#332-%E5%B0%BA%E5%AF%B8%E4%B8%8D%E5%8C%B9%E9%85%8D%E7%9A%84%E8%AE%BE%E5%A4%87\&#34;&gt;3.3.2 尺寸不匹配的设备&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#333-%E7%A2%8E%E7%89%87%E6%95%B4%E7%90%86%E6%B2%A1%E6%9C%89%E8%B7%9F%E4%B8%8A\&#34;&gt;3.3.3 碎片整理没有跟上&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#334-%E8%BF%87%E5%A4%A7%E7%9A%84-post-write-queue\&#34;&gt;3.3.4 过大的 post-write-queue&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#335-%E7%A2%8E%E7%89%87%E6%95%B4%E7%90%86%E7%9A%84%E5%9D%97%E6%B2%A1%E6%9C%89%E5%8F%8A%E6%97%B6%E9%87%8A%E6%94%BE%E4%B8%8D%E5%B8%B8%E8%A7%81\&#34;&gt;3.3.5 碎片整理的块没有及时释放（不常见）&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%9B%9B-%E5%A6%82%E4%BD%95%E4%BB%8E%E5%8F%AF%E7%94%A8%E7%99%BE%E5%88%86%E6%AF%94-0-%E4%B8%AD%E6%81%A2%E5%A4%8D\&#34;&gt;四、如何从可用百分比 0 中恢复&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#41-%E8%B0%83%E6%95%B4%E7%A2%8E%E7%89%87%E6%95%B4%E7%90%86%E9%80%9F%E5%BA%A6%E5%92%8C%E9%98%88%E5%80%BC\&#34;&gt;4.1 调整碎片整理速度和阈值&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#42-%E5%A2%9E%E5%8A%A0%E5%AF%B9%E8%BF%87%E6%9C%9F%E6%95%B0%E6%8D%AE%E7%9A%84%E9%A9%B1%E9%80%90\&#34;&gt;4.2 增加对过期数据的驱逐&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#43-%E9%80%9A%E8%BF%87%E6%B7%BB%E5%8A%A0%E6%96%B0%E8%8A%82%E7%82%B9%E6%9D%A5%E5%A2%9E%E5%8A%A0%E5%AE%B9%E9%87%8F\&#34;&gt;4.3 通过添加新节点来增加容量&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#44-%E5%81%9C%E6%AD%A2%E8%8A%82%E7%82%B9%E4%B8%8A%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%92%8C%E9%9B%B6%E7%A2%8E%E7%89%87%E6%8C%81%E4%B9%85%E5%AD%98%E5%82%A8\&#34;&gt;4.4 停止节点上的服务和零碎片持久存储&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#45-cold-start-evict-ttl-%E6%96%B9%E6%B3%95\&#34;&gt;4.5 Cold-Start-Evict-TTL 方法&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%BA%94-%E5%90%8E%E8%AE%B0\&#34;&gt;五、后记&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;p&gt;在 Elasticsearch 中，一个健康的集群一定是平衡的：主分片(master)和副本分片(replica)分布在所有节点上，以便在节点发生故障时依旧保证可用性。&lt;/p&gt;\n&lt;p&gt;当时当你看到分片在一个 &lt;code&gt;UNASSIGNED&lt;/code&gt; 状态中时，你应该怎么做？&lt;/p&gt;\n&lt;!-- more --&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;1\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1642405625703.jpeg\&#34; alt=\&#34;1-too-many-shards-to-assign\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;在我们深入探究一些解决方案之前，让我们验证未分配(&lt;code&gt;UNASSIGNED&lt;/code&gt;)的分片是否包含我们需要保留的数据（如果没有，删除这些分片是解决问题的最直接方法）。如果您已经确认该分片存在有价值的数据，请跳转至解决方案：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%8E%9F%E5%9B%A0%E4%B8%80%E6%95%85%E6%84%8F%E5%BB%B6%E8%BF%9F%E5%88%86%E7%89%87%E5%88%86%E9%85%8D\&#34;&gt;分片分配被故意延迟&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%8E%9F%E5%9B%A0%E4%BA%8C%E5%88%86%E7%89%87%E5%A4%AA%E5%A4%9A%E8%8A%82%E7%82%B9%E4%B8%8D%E5%A4%9F\&#34;&gt;分片太多，节点不够&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%8E%9F%E5%9B%A0%E4%B8%89%E6%82%A8%E9%9C%80%E8%A6%81%E9%87%8D%E6%96%B0%E5%90%AF%E7%94%A8%E5%88%86%E7%89%87%E5%88%86%E9%85%8D\&#34;&gt;您需要重新启用分片分配&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%8E%9F%E5%9B%A0%E5%9B%9B%E9%9B%86%E7%BE%A4%E4%B8%AD%E4%B8%8D%E5%86%8D%E5%AD%98%E5%9C%A8-shard-%E6%95%B0%E6%8D%AE\&#34;&gt;分片数据不再存在于集群中&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%8E%9F%E5%9B%A0%E4%BA%94%E7%A3%81%E7%9B%98%E6%B0%B4%E4%BD%8D%E8%BF%87%E4%BD%8E\&#34;&gt;低磁盘水位线&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%8E%9F%E5%9B%A0%E5%85%AD%E5%A4%9A%E4%B8%AA-elasticsearch-%E7%89%88%E6%9C%AC\&#34;&gt;多个 Elasticsearch 版本&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;本文汇总的命令格式假设您在默认端口(9200)上运行每个 Elasticsearch 实例的 HTTP 服务。我们假设您在本地提交请求，所以它们被重定向到 &lt;code&gt;localhost&lt;/code&gt;；如果不是，您替换 &lt;code&gt;localhost&lt;/code&gt; 为您节点的 IP 地址。&lt;/p&gt;\n&lt;h2 id=\&#34;查明有问题的分片\&#34;&gt;查明有问题的分片&lt;/h2&gt;\n&lt;p&gt;Elasticsearch 的 &lt;a href=\&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/cat-shards.html\&#34;&gt;cat shards API&lt;/a&gt; 会告诉您哪些分片未分配，以及未分配的原因：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;curl -XGET localhost:9200/_cat/shards?h=index,shard,prirep,state,unassigned.reason| grep UNASSIGNED\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;每行列出索引的名称、分片编号、是主分片(p)还是副本(r)分片，以及未分配的原因：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;constant-updates 0 p UNASSIGNED NODE_LEFT node_left\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;如果您运行的是 Elasticsearch 5+ 版本，您还可以使用 &lt;a href=\&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-allocation-explain.html\&#34;&gt;cluster allocation explain API&lt;/a&gt; 来尝试获取有关分片分配问题的更多信息：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;curl -XGET localhost:9200/_cluster/allocation/explain?pretty\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;生成的输出将提供有用的详细信息，说明集群中的某些分配仍未分配：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;{\n  &amp;quot;index&amp;quot; : &amp;quot;testing&amp;quot;,\n  &amp;quot;shard&amp;quot; : 0,\n  &amp;quot;primary&amp;quot; : false,\n  &amp;quot;current_state&amp;quot; : &amp;quot;unassigned&amp;quot;,\n  &amp;quot;unassigned_info&amp;quot; : {\n    &amp;quot;reason&amp;quot; : &amp;quot;INDEX_CREATED&amp;quot;,\n    &amp;quot;at&amp;quot; : &amp;quot;2018-04-09T21:48:23.293Z&amp;quot;,\n    &amp;quot;last_allocation_status&amp;quot; : &amp;quot;no_attempt&amp;quot;\n  },\n  &amp;quot;can_allocate&amp;quot; : &amp;quot;no&amp;quot;,\n  &amp;quot;allocate_explanation&amp;quot; : &amp;quot;cannot allocate because allocation is not permitted to any of the nodes&amp;quot;,\n  &amp;quot;node_allocation_decisions&amp;quot; : [\n    {\n      &amp;quot;node_id&amp;quot; : &amp;quot;t_DVRrfNS12IMhWvlvcfCQ&amp;quot;,\n      &amp;quot;node_name&amp;quot; : &amp;quot;t_DVRrf&amp;quot;,\n      &amp;quot;transport_address&amp;quot; : &amp;quot;127.0.0.1:9300&amp;quot;,\n      &amp;quot;node_decision&amp;quot; : &amp;quot;no&amp;quot;,\n      &amp;quot;weight_ranking&amp;quot; : 1,\n      &amp;quot;deciders&amp;quot; : [\n        {\n          &amp;quot;decider&amp;quot; : &amp;quot;same_shard&amp;quot;,\n          &amp;quot;decision&amp;quot; : &amp;quot;NO&amp;quot;,\n          &amp;quot;explanation&amp;quot; : &amp;quot;the shard cannot be allocated to the same node on which a copy of the shard already exists&amp;quot;\n        }\n      ]\n    }\n  ]\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;在这种情况下，API 清楚地解释了为什么副本分配保持未分配：&amp;quot;the shard cannot be allocated to the same node on which a copy of the shard already exists（分片不能分配给已经存在分配副本的统一节点）&amp;quot;。要查看有关此特定问题的更多详细信息以及如何解决它，请 &lt;a href=\&#34;#%E5%8E%9F%E5%9B%A0%E4%BA%8C%E5%88%86%E7%89%87%E5%A4%AA%E5%A4%9A%E8%8A%82%E7%82%B9%E4%B8%8D%E5%A4%9F\&#34;&gt;跳转至&lt;/a&gt; 本文后面的部分。&lt;/p&gt;\n&lt;p&gt;如果未分配的分片属于您认为已删除的索引，或者您不再需要的过时索引，则可以删除索引以将集群状态恢复绿色：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;curl -XDELETE &#39;localhost:9200/index_name/&#39;\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;如果这不能解决问题，请继续阅读以尝试其他解决方案。&lt;/p&gt;\n&lt;h2 id=\&#34;原因一故意延迟分片分配\&#34;&gt;原因一：故意延迟分片分配&lt;/h2&gt;\n&lt;p&gt;当一个节点离开集群时，主节点会暂时延迟分片重新分配，以表面原始节点能够在一定时间内（&lt;a href=\&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/delayed-allocation.html\&#34;&gt;默认为一分钟&lt;/a&gt;）恢复，如果在此期间重新平衡分片，会造成不必要的资源浪费。如果是这种情况，您的日志应如下所示：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;[TIMESTAMP][INFO][cluster.routing] [PRIMARY NODE NAME] delaying allocation for [54] unassigned shards, next check in [1m]\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;您可以像这样动态修改延迟时间：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;curl -XPUT &amp;quot;localhost:9200/&amp;lt;INDEX_NAME&amp;gt;/_settings?pretty&amp;quot; -H &#39;Content-Type: application/json&#39; -d&#39;\n{\n  &amp;quot;settings&amp;quot;: {\n    &amp;quot;index.unassigned.node_left.delayed_timeout&amp;quot;: &amp;quot;5m&amp;quot;\n  }\n}&#39;\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;替换 &lt;code&gt;&amp;lt;INDEX_NAME&amp;gt;&lt;/code&gt; 为 &lt;code&gt;_all&lt;/code&gt; 将更新集群中所有索引的阈值。&lt;/p&gt;\n&lt;p&gt;延迟时间结束后，您应该开始看到主节点分配了这些分片。如果没有，请继续阅读以探索其他潜在原因的解决方案。&lt;/p&gt;\n&lt;h2 id=\&#34;原因二分片太多节点不够\&#34;&gt;原因二：分片太多，节点不够&lt;/h2&gt;\n&lt;p&gt;当节点加入和离开集群时，主节点会自动重新分配分片，确保一个分片的多个副本&lt;a href=\&#34;https://www.elastic.co/guide/en/elasticsearch/reference/2.4/_basic_concepts.html\&#34;&gt;不会分配给同一个节点&lt;/a&gt;。换句话说，主节点不会将主分片分配给与其副本相同的节点，也不会将同一分片的两个副本分配给同一个节点。如果没有足够的节点来相应地分配分片，分配可能会停留在未分配状态。&lt;/p&gt;\n&lt;p&gt;为避免此问题，请按照以下公式确保集群中的每个索引都初始化，且每个主分片的副本数少于集群中的节点数：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;N &amp;gt;= R + 1\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;其中 N 是集群中的节点数，R 是集群中所有索引的最大分片副本因子。&lt;/p&gt;\n&lt;p&gt;在下面的屏幕截图中，&lt;code&gt;many-shards&lt;/code&gt; 索引存储在四个主分片上，每个主分片有四个副本。索引的 20 个分片中有 8 个未分配，因为我们的集群仅包含三个节点，每个主分片的两个副本尚未分配，因为三个节点中的每个都已包含该分片的副本。&lt;br&gt;\n&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1642412584473.jpeg\&#34; alt=\&#34;1-too-many-shards-to-assign\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/p&gt;\n&lt;p&gt;要解决此问题，您可以向集群添加更多数据节点或减少副本数量。在我们的示例中，无门需要在集群中至少再添加两个节点或者将副本因子较少到两个，如下所示：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;curl -XPUT &amp;quot;localhost:9200/&amp;lt;INDEX_NAME&amp;gt;/_settings?pretty&amp;quot; -H &#39;Content-Type: application/json&#39; -d&#39; { &amp;quot;number_of_replicas&amp;quot;: 2 }&#39;\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;减少副本数量后，看看是否已分配所有分片&lt;br&gt;\n&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1642417786150.jpeg\&#34; alt=\&#34;2-reduced-replicas-green\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/p&gt;\n&lt;h2 id=\&#34;原因三您需要重新启用分片分配\&#34;&gt;原因三：您需要重新启用分片分配&lt;/h2&gt;\n&lt;p&gt;在下面的 Kopf 屏幕截图中，一个节点刚刚加入集群，但尚未分配任何分片。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;2\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1642471400721.jpeg\&#34; alt=\&#34;3-unassigned-allocation-disabled\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;p&gt;&lt;a href=\&#34;https://www.elastic.co/guide/en/elasticsearch/reference/7.5/shards-allocation.html\&#34;&gt;默认情况下在所有节点上启用&lt;/a&gt; 分片分配，但您可能在某些时候禁用了分片分配（例如，为了执行 &lt;a href=\&#34;https://www.elastic.co/guide/en/elasticsearch/guide/current/_rolling_restarts.html\&#34;&gt;滚动重启&lt;/a&gt; ），并且忘记重启启用它。&lt;/p&gt;\n&lt;p&gt;要启用分片分配，请更新&lt;a href=\&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-update-settings.html\&#34;&gt;集群更新设置API&lt;/a&gt; ：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;curl -X PUT &amp;quot;localhost:9200/_cluster/settings?pretty&amp;quot; -H &#39;Content-Type: application/json&#39; -d&#39;\n{\n    &amp;quot;transient&amp;quot; : {\n        &amp;quot;cluster.routing.allocation.enable&amp;quot; : &amp;quot;all&amp;quot;\n    }\n}\n&#39;\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;如果这解决了问题，您的 &lt;a href=\&#34;https://github.com/lmenezes/elasticsearch-kopf\&#34;&gt;Kopf&lt;/a&gt; 或 &lt;a href=\&#34;https://app.datadoghq.com/screen/integration/elasticsearch?_gl=1*1h3mwdy*_ga*MjA1NzQ5MzY1NS4xNjQxOTUxNjc2*_ga_KN80RDFSQK*MTY0MjQwNDAxMC41LjEuMTY0MjQwNDA1NC4w&amp;amp;_ga=2.82032019.409373510.1642404018-2057493655.1641951676\&#34;&gt;Datadog dashboard&lt;/a&gt; 应显示未分配分片数量随着它们成功分配给节点而减少。&lt;/p&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;3\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1642471844506.jpeg\&#34; alt=\&#34;4-unassigned-shards-datadog2\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;pre&gt;&lt;code&gt;此 Datadog 时间序列图显示重新启用分片分配后未分配的分片数量减少。\n&lt;/code&gt;&lt;/pre&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;4\&#34;&gt;&lt;img src=\&#34;https://wenbozhangw.github.io//post-images/1642471903524.jpeg\&#34; alt=\&#34;5-unassigned-after-allocation-enabled\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;pre&gt;&lt;code&gt;更新后的 Kopf 仪表盘显示，在重新启用分片分配后，许多以前未分配的分片已被分配。\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;看起来这解决了我们所有未分配的分片的问题，但有一个例外：&lt;code&gt;constant-updates&lt;/code&gt; 索引的分片 0。让我们探讨一下为什么分片仍未分配的其他可能原因。&lt;/p&gt;\n&lt;h2 id=\&#34;原因四集群中不再存在-shard-数据\&#34;&gt;原因四：集群中不再存在 Shard 数据&lt;/h2&gt;\n&lt;p&gt;&lt;code&gt;constant-updates&lt;/code&gt; 在这种情况下，索引的主分片 0 未分配。它可能是在没有任何副本的节点上创建的（一种用于&lt;a href=\&#34;https://www.datadoghq.com/blog/elasticsearch-performance-scaling-problems/\&#34;&gt;加速初始索引&lt;/a&gt; 过程的技术），并且该节点在数据被复制之前就离开了集群。主节点在其全局集群状态文件中检测到分片，但无法在集群中定位分片的数据。&lt;/p&gt;\n&lt;p&gt;另一种可能性是节点在重新启动时可能遇到了问题。通常，当一个节点恢复与集群的连接时，它会将有关其磁盘上的分片信息转发给主节点，然后主节点将这些分片从 &amp;quot;unassigned&amp;quot; 过渡到 &amp;quot;assigned/started&amp;quot;。当这个进程由于某种原因失败时（例如节点的存储以某种方式被破坏），分片可能仍然未分配。&lt;/p&gt;\n&lt;p&gt;在这种情况下，您必须决定如何继续：尝试让原始节点恢复并重新加入集群（不要执行强制分配主分片），或使用 &lt;a href=\&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-reroute.html\&#34;&gt;集群重路由API&lt;/a&gt;强制分配分片并使用原始数据源或备份文件重新索引丢失的数据。&lt;/p&gt;\n&lt;p&gt;如果您决定使用后者（强制分配分片），需要注意的是您&lt;a href=\&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-reroute.html\&#34;&gt;将分配一个&amp;quot;空&amp;quot;分片&lt;/a&gt;。如果包含原始主分片数据的节点稍后重新加入集群，则其数据&lt;a href=\&#34;https://github.com/elastic/elasticsearch/issues/16113\&#34;&gt;将被&lt;/a&gt;新创建的（空）主分片覆盖，因为它将被视为数据的&amp;quot;更新&amp;quot;版本。再继续此操作之前，您可能希望&lt;a href=\&#34;https://www.elastic.co/guide/en/elasticsearch/reference/6.8/cluster-reroute.html#_retrying_failed_allocations\&#34;&gt;重新分配&lt;/a&gt;，这将允许您保留存储在该分片上的数据。&lt;/p&gt;\n&lt;p&gt;如果您了解其中的含义，并且仍想强制分配未分配的主分片，则可以使用 &lt;code&gt;allocate_empty_primary&lt;/code&gt; 标志来执行此操作。以下命令将 &lt;code&gt;constant-updates&lt;/code&gt; 索引中的主分片 0 重新路由到特定节点：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;curl -XPOST &amp;quot;localhost:9200/_cluster/reroute?pretty&amp;quot; -H &#39;Content-Type: application/json&#39; -d&#39;\n{\n    &amp;quot;commands&amp;quot; : [\n        {\n          &amp;quot;allocate_empty_primary&amp;quot; : {\n                &amp;quot;index&amp;quot; : &amp;quot;constant-updates&amp;quot;, \n                &amp;quot;shard&amp;quot; : 0,\n                &amp;quot;node&amp;quot; : &amp;quot;&amp;lt;NODE_NAME&amp;gt;&amp;quot;, \n                &amp;quot;accept_data_loss&amp;quot; : &amp;quot;true&amp;quot;\n          }\n        }\n    ]\n}\n&#39;\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;请注意，您需要指定&lt;code&gt;&amp;quot;accept_data_loss&amp;quot;:&amp;quot;true&amp;quot;&lt;/code&gt;以确保您已准备好丢失分片上的数据。如果不包含此参数，您将看到如下错误：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;{\n  &amp;quot;error&amp;quot; : {\n    &amp;quot;root_cause&amp;quot; : [\n      {\n        &amp;quot;type&amp;quot; : &amp;quot;remote_transport_exception&amp;quot;,\n        &amp;quot;reason&amp;quot; : &amp;quot;[NODE_NAME][127.0.0.1:9300][cluster:admin/reroute]&amp;quot;\n      }\n    ],\n    &amp;quot;type&amp;quot; : &amp;quot;illegal_argument_exception&amp;quot;,\n    &amp;quot;reason&amp;quot; : &amp;quot;[allocate_empty_primary] allocating an empty primary for [constant-updates][0] can result in data loss. Please confirm by setting the accept_data_loss parameter to true&amp;quot;\n  },\n  &amp;quot;status&amp;quot; : 400\n}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;&lt;a href=\&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-snapshots.html\&#34;&gt;您现在需要重新索引丢失的数据，或使用 Snapshot and Restore API&lt;/a&gt; 从备份快照中尽可能多地恢复。&lt;/p&gt;\n&lt;h2 id=\&#34;原因五磁盘水位过低\&#34;&gt;原因五：磁盘水位过低&lt;/h2&gt;\n&lt;p&gt;如果没有足够的节点和足够的磁盘空间，主节点可能无法分配分片（它不会将分片分配给&lt;a href=\&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/disk-allocator.html\&#34;&gt;磁盘使用率超过85%&lt;/a&gt;的节点）。一旦一个节点达到了这个磁盘使用水平，或者 Elasticsearch 称之为 &amp;quot;low disk watermark&amp;quot;，他就不会被分配更多的分片。&lt;/p&gt;\n&lt;p&gt;您可以通过查询 &lt;a href=\&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/cat-allocation.html\&#34;&gt;cat API&lt;/a&gt; 检查集群中每个节点上的磁盘空间（并查看每个节点上存储了哪些分片）：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;curl -s &#39;localhost:9200/_cat/allocation?v&#39;\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;如果任何特定节点的磁盘空间不足（删除过时的数据并将其存储在集群外、添加更多节点、升级硬件等），请参阅&lt;a href=\&#34;https://www.datadoghq.com/blog/elasticsearch-performance-scaling-problems/#toc-problem-2-help-data-nodes-are-running-out-of-disk-space1\&#34;&gt;这篇文件以获取有关如何操作的选项&lt;/a&gt; 。&lt;/p&gt;\n&lt;p&gt;如果您的节点具有较大的磁盘容量，则默认的低水位线（85%的磁盘使用率）可能太低。您可以使用&lt;a href=\&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-update-settings.html\&#34;&gt;集群更新设置API&lt;/a&gt; 来更改 &lt;code&gt;cluster.routing.allocation.disk.watermark.low&lt;/code&gt; 和/或 &lt;code&gt;cluster.routing.allocation.disk.watermark.high&lt;/code&gt; 。例如，这个 &lt;a href=\&#34;http://stackoverflow.com/questions/33369955/low-disk-watermark-exceeded-on\&#34;&gt;Stack Overflow thread&lt;/a&gt; 指出，如果您的节点有 5TB 的磁盘容量，您可能可以安全地 &lt;strong&gt;增加低磁盘水位&lt;/strong&gt; 到 90%：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;curl -XPUT &amp;quot;localhost:9200/_cluster/settings&amp;quot; -H &#39;Content-Type: application/json&#39; -d&#39;\n{\n  &amp;quot;transient&amp;quot;: {\n    &amp;quot;cluster.routing.allocation.disk.watermark.low&amp;quot;: &amp;quot;90%&amp;quot;\n  }\n}&#39;\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;如果您希望配置更改在集群重新启动时保持不变，请将 &amp;quot;transient&amp;quot; 替换为 &amp;quot;persistent&amp;quot;，或在配置文件中更新这些值。您可以选择使用字节或百分比值来更新这些设置，但请务必记住&lt;a href=\&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/disk-allocator.html\&#34;&gt;Elasticsearch文档&lt;/a&gt; 中的这一重要说明：“百分比值指 &lt;strong&gt;使用的&lt;/strong&gt; 磁盘空间，而字节值是指 &lt;strong&gt;剩余&lt;/strong&gt; 磁盘空间”。&lt;/p&gt;\n&lt;h2 id=\&#34;原因六多个-elasticsearch-版本\&#34;&gt;原因六：多个 Elasticsearch 版本&lt;/h2&gt;\n&lt;p&gt;这个entinel只出现在运行多个 Elasticsearch 版本的集群中（可能在&lt;a href=\&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/rolling-upgrades.html\&#34;&gt;滚动升级&lt;/a&gt;的期间）。根据&lt;a href=\&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/rolling-upgrades.html\&#34;&gt;Elasticsearch文档&lt;/a&gt;，主节点不会将主分片的副本分配给任何运行旧版本的节点。例如，如果主分片在 1.4 版本上运行，则主节点将无法将该分片的副本分配给运行 1.4 之前的任何版本的任何节点。&lt;/p&gt;\n&lt;p&gt;如果您尝试手动将分片从较新版本的节点重新路由到较旧版本的节点，您将看到如下错误：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;[NO(target node version [XXX] is older than source node version [XXX])]\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;Elasticsearch &lt;a href=\&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/setup-upgrade.html\&#34;&gt;不支持回滚&lt;/a&gt; 到以前的版本，只支持升级。如果这确实是手头的问题，升级运行旧版本的节点应该可以解决问题。&lt;/p&gt;\n&lt;h2 id=\&#34;你试过把它关掉再打开吗\&#34;&gt;你试过把它关掉再打开吗？&lt;/h2&gt;\n&lt;p&gt;如果上述情况均不适用您的情况，您仍然可以选择从原始数据与重新索引丢失的数据，或从旧快照恢复受影响的索引，&lt;a href=\&#34;https://www.elastic.co/blog/introducing-snapshot-restore\&#34;&gt;参考链接&lt;/a&gt;。&lt;/p&gt;\n&#34;,&#34;fileName&#34;:&#34;elasticsearch-unassigned-shards&#34;,&#34;abstract&#34;:&#34;&lt;p&gt;在 Elasticsearch 中，一个健康的集群一定是平衡的：主分片(master)和副本分片(replica)分布在所有节点上，以便在节点发生故障时依旧保证可用性。&lt;/p&gt;\n&lt;p&gt;当时当你看到分片在一个 &lt;code&gt;UNASSIGNED&lt;/code&gt; 状态中时，你应该怎么做？&lt;/p&gt;\n&#34;,&#34;title&#34;:&#34;如何解决 Elasticsearch 中 unassigned shards&#34;,&#34;tags&#34;:[{&#34;index&#34;:-1,&#34;name&#34;:&#34;Elasticsearch&#34;,&#34;slug&#34;:&#34;aqWwdKBVh&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://wenbozhangw.github.io/tag/aqWwdKBVh/&#34;}],&#34;date&#34;:&#34;2022-01-14 13:39:15&#34;,&#34;dateFormat&#34;:&#34;2022-01-14&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://wenbozhangw.github.io/post/elasticsearch-unassigned-shards/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;12 min read&#34;,&#34;time&#34;:718000,&#34;words&#34;:3090,&#34;minutes&#34;:12},&#34;description&#34;:&#34;在 Elasticsearch 中，一个健康的集群一定是平衡的：主分片(master)和副本分片(replica)分布在所有节点上，以便在节点发生故障时依旧保证可用性。\n当时当你看到分片在一个 UNASSIGNED 状态中时，你应该怎么做？...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%9F%A5%E6%98%8E%E6%9C%89%E9%97%AE%E9%A2%98%E7%9A%84%E5%88%86%E7%89%87\&#34;&gt;查明有问题的分片&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%8E%9F%E5%9B%A0%E4%B8%80%E6%95%85%E6%84%8F%E5%BB%B6%E8%BF%9F%E5%88%86%E7%89%87%E5%88%86%E9%85%8D\&#34;&gt;原因一：故意延迟分片分配&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%8E%9F%E5%9B%A0%E4%BA%8C%E5%88%86%E7%89%87%E5%A4%AA%E5%A4%9A%E8%8A%82%E7%82%B9%E4%B8%8D%E5%A4%9F\&#34;&gt;原因二：分片太多，节点不够&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%8E%9F%E5%9B%A0%E4%B8%89%E6%82%A8%E9%9C%80%E8%A6%81%E9%87%8D%E6%96%B0%E5%90%AF%E7%94%A8%E5%88%86%E7%89%87%E5%88%86%E9%85%8D\&#34;&gt;原因三：您需要重新启用分片分配&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%8E%9F%E5%9B%A0%E5%9B%9B%E9%9B%86%E7%BE%A4%E4%B8%AD%E4%B8%8D%E5%86%8D%E5%AD%98%E5%9C%A8-shard-%E6%95%B0%E6%8D%AE\&#34;&gt;原因四：集群中不再存在 Shard 数据&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%8E%9F%E5%9B%A0%E4%BA%94%E7%A3%81%E7%9B%98%E6%B0%B4%E4%BD%8D%E8%BF%87%E4%BD%8E\&#34;&gt;原因五：磁盘水位过低&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%8E%9F%E5%9B%A0%E5%85%AD%E5%A4%9A%E4%B8%AA-elasticsearch-%E7%89%88%E6%9C%AC\&#34;&gt;原因六：多个 Elasticsearch 版本&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%BD%A0%E8%AF%95%E8%BF%87%E6%8A%8A%E5%AE%83%E5%85%B3%E6%8E%89%E5%86%8D%E6%89%93%E5%BC%80%E5%90%97\&#34;&gt;你试过把它关掉再打开吗？&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;}]";
  // var json = escape.substr(1, escape.length - 2);
  // var datas = json.split(',');
  // for (let i=0; i < datas.length; i++) {
  //   let item = datas[i];
  //   let attrs = item.split('34;:&#34')
  //   debugger
  //   console.log(datas[i])
  // }
  let escapeMap = new Map();
  escapeMap.set('&#34;', '"');
  escapeMap.set('&gt;', '>');
  escapeMap.set('&#39;', "'");
  escapeMap.set('&lt;', '<');
  escapeMap.set('&quot;', '"');
  escapeMap.set('&amp;', '&');
</script> -->

<script src="/media/js/mouse/love.js"></script>


</html>