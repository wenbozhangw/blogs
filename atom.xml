<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://wenbozhangw.github.io/</id>
    <title>wenbozhang&apos;s blogs</title>
    <updated>2022-09-20T09:40:46.204Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://wenbozhangw.github.io/"/>
    <link rel="self" href="https://wenbozhangw.github.io/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://wenbozhangw.github.io/images/avatar.png</logo>
    <icon>https://wenbozhangw.github.io/favicon.ico</icon>
    <rights>All rights reserved 2022, wenbozhang&apos;s blogs</rights>
    <entry>
        <title type="html"><![CDATA[理解同步器框架AbstractQueuedSynchronizer]]></title>
        <id>https://wenbozhangw.github.io/post/li-jie-tong-bu-qi-kuang-jia-abstractqueuedsynchronizer/</id>
        <link href="https://wenbozhangw.github.io/post/li-jie-tong-bu-qi-kuang-jia-abstractqueuedsynchronizer/">
        </link>
        <updated>2022-09-14T14:32:26.000Z</updated>
        <summary type="html"><![CDATA[<h2 id="一-背景">一、背景</h2>
<p>Java 在 1.5 版本引入了 <code>java.util.concurrent</code>包，用以支持并发编程，降低并发编程的复杂性；而其中大部分的同步器（例如 <code>lock</code>, <code>barriers</code> 等等）都是基于 <code>AbstractQueuedSynchronizer</code> 类，一般我们称为<code>AQS</code>。 <code>java.util.concurrent.locks.AbstractQueuedSynchronizer</code> 出自 <code>Doug Lea</code> 带佬，他的 <a href="https://gee.cs.oswego.edu/">个人博客</a> 上有一篇相关论文 <a href="https://gee.cs.oswego.edu/dl/papers/aqs.pdf">《The java.util.concurrent Synchronizer Framework》</a>，在我们深入研究 <code>AQS</code> 之前，有必要拜读一下该论文，翻译见笔者的另一篇博客<a href="https://wenbozhangw.github.io/post/lesslessthe-javautilconcurrent-synchronizer-frameworkgreatergreater-yuan-wen-fan-yi/">《The java.util.concurrent Synchronizer Framework》原文翻译</a> 之后结合相关源码实现进行分析。</p>
]]></summary>
        <content type="html"><![CDATA[<h2 id="一-背景">一、背景</h2>
<p>Java 在 1.5 版本引入了 <code>java.util.concurrent</code>包，用以支持并发编程，降低并发编程的复杂性；而其中大部分的同步器（例如 <code>lock</code>, <code>barriers</code> 等等）都是基于 <code>AbstractQueuedSynchronizer</code> 类，一般我们称为<code>AQS</code>。 <code>java.util.concurrent.locks.AbstractQueuedSynchronizer</code> 出自 <code>Doug Lea</code> 带佬，他的 <a href="https://gee.cs.oswego.edu/">个人博客</a> 上有一篇相关论文 <a href="https://gee.cs.oswego.edu/dl/papers/aqs.pdf">《The java.util.concurrent Synchronizer Framework》</a>，在我们深入研究 <code>AQS</code> 之前，有必要拜读一下该论文，翻译见笔者的另一篇博客<a href="https://wenbozhangw.github.io/post/lesslessthe-javautilconcurrent-synchronizer-frameworkgreatergreater-yuan-wen-fan-yi/">《The java.util.concurrent Synchronizer Framework》原文翻译</a> 之后结合相关源码实现进行分析。</p>
<!-- more -->
<h2 id="二-aqs概述">二、AQS概述</h2>
<p><code>AQS</code> 是 <code>j.u.c</code> 包中用来构建同步组件（例如 <code>ReentrantLock</code>、<code>Semaphore</code>）的基础框架。从实现上来看，<code>AQS</code> 提供了原子的同步状态管理、线程的阻塞及唤醒以及存储队列管理模型。基于 <code>AQS</code> 提供的强大功能，我们可以很简单的构建属于自己的同步器组件。同时，<code>AQS</code> 也提供了任务取消、阻塞超时以及<code>conditionObject</code>提供的管程风格的 <code>await/signal/signalAll</code>操作。并且根据所需策略的不同，<code>AQS</code> 还提供了<code>公平</code>/<code>非公平</code>、<code>独占</code>/<code>共享</code> 等特性。</p>
<h2 id="三-同步器框架原理">三、同步器框架原理</h2>
<p><code>AQS</code> 框架用来实现加锁和解锁的核心是基于 <code>acquire</code> 和 <code>release</code> 方法，通过这两个方法，从而去进行原子操作修改同步器状态变量，从而实现对共享资源的并发访问。在 《The java.util.concurrent Synchronizer Framework》 原文中有提到 <code>AQS</code> 的这两个核心操作实现的伪代码：</p>
<p><code>acquire</code> 操作如下：</p>
<pre><code>while(synchronization state does not allow acquire) {
  enqueue current thread if not already queued;
  possibly block current thread;
}
dequeue current thread if it was queued;
</code></pre>
<p>简单翻译一下：</p>
<pre><code>while(同步器状态获取失败) {
  if (当前线程未进入等待队列) {
    将当前线程入队；
  }
  可能尝试阻塞当前线程;
}
if (如果当前线程已经入队) {
  当前线程出队;
}
</code></pre>
<p><code>release</code> 操作如下：</p>
<pre><code>update synchronization state;
if(state may permit a blocked thread to acquire) 
  unblock one or more queued threads;
</code></pre>
<p>简单翻译一下：</p>
<pre><code>更新同步器状态;
if (同步器状态可以允许一个阻塞线程获取) {
  解除一个或多个队列线程的阻塞状态;
}
</code></pre>
<p>可以看到 <code>AQS</code> 的核心思想是，如果请求资源空闲（即同步器状态修改成功），将共享资源设置为锁定状态；如果共享资源被占用（即同步器状态修改失败），就需要对当前线程进行入队操作，之后通过阻塞等待唤醒机制来保证锁的分配。这个队列机制主要是通过 CLH 队列的变体来实现的。我们会在下文中对 CLH 队列进行讲述。</p>
<h3 id="31同步器状态">3.1同步器状态</h3>
<p><code>AQS</code> 类内部定义了一个<code>volatile</code>修饰的 <code>32</code> 位 <code>int</code> 类型的 <code>state</code> 变量用于维护同步器的状态：</p>
<pre><code class="language-java">    /**
     * 同步状态值
     */
    private volatile int state;

    /**
     * 返回同步状态的当前值。
     * 该操作的内存语义为{@code volatile} 读。
     * @return 当前同步状态值
     */
    protected final int getState() {
        return state;
    }

    /**
     * 设置同步状态的值。
     * 该操作具有 {@code volatile} 写的内存语义。
     * @param newState 新状态值
     */
    protected final void setState(int newState) {
        state = newState;
    }

    /**
     * 如果当前状态值等于预期值，则自动将同步状态设置为
     * 给定的更新值。该操作具有 {@code volatile} 读写
     * 的内存语义。
     *
     * @param expect 期望值
     * @param update 新值
     * @return 如果成功，返回{@code true}. 返回 false 表示实际值
     *	       与期望值不相等。
     */
    protected final boolean compareAndSetState(int expect, int update) {
        // 见下面的内部设置来支持这一点
        return unsafe.compareAndSwapInt(this, stateOffset, expect, update);
    }

</code></pre>
<p>同步器的状态 <code>state</code> 在不同的实现中会有不同的作用和意义，需要结合具体的使用进行分析（比如说 <code>ReentrantReadWriteLock</code> 中 <code>state</code> 的前 16 位记录读锁的数量（共享），后 16 位记录写锁的数量（独占））。另外，我们可以看到，上面关于 <code>state</code> 的几个方法都是 <code>final</code> 修饰的，说明子类无法重写它们。我们可以通过修改 <code>state</code> 字段来表示同步状态加锁的过程。</p>
<h3 id="32-clh-队列">3.2 CLH 队列</h3>
<p><code>CLH</code>队列：<code>Craig、Landin and Hagersten</code>队列，基础的 CLH 对列是一个单向链表，而 <code>AQS</code> 中是用的队列是 CLH 队列的变体——虚拟双向队列（FIFO），因此，该框架是不支持基于优先级的同步。使用同步队列的原因是，它是一种不需要使用低级锁来构造非阻塞数据结构。</p>
<p>CLH 队列实际上并不是很像队列，因为它的入队和出队操作都与其用途（作为锁）紧密相关。他通过两个字段 <code>tail</code> 和 <code>head</code> 来存取，同时这两个字段支持原子更新，两者在初始化时都指向的空节点。</p>
<p>当一个新节点通过原子操作入队：</p>
<pre><code class="language-java">do {
  pred = tail;
} while (!tail.compareAndSet(pred, node));
</code></pre>
<p>同时， 每个节点的 <code>release</code> 状态都保存在其前驱结点中。因此，当前节点可以通过自旋，直到前驱节点释放锁（但是，从实际上来看，过度的自旋会带来大量的 CPU 性能损耗）：</p>
<pre><code>while (pred.status != RELEASED); // spin
</code></pre>
<p>自旋后的出队操作只需将 <code>head</code> 字段指向刚刚得到锁的节点：</p>
<pre><code>head = node
</code></pre>
<p>CLH 的优点是：它的入队和出队操作是快速的、无锁的、无阻塞的（即使在竞争的情况下，也只会有一个线程赢得插入的机会，从而能进行下去）。检测是否有线程在等待也很快（只需要检测 <code>head</code> 和 <code>tail</code> 是否相等）；同时，<code>release</code> 是分散的，避免了一些不必要的内存竞争。</p>
<p><code>AQS</code>中的等待队列是 CLH 锁队列的变体。CLH 锁通常用于自旋锁。但是在 <code>AQS</code> 中将其作为阻塞同步器，但是根据其基本思想，即在其节点的前驱节点中保存有关线程的控制信息。每个节点的“状态”字段跟踪线程是否应该阻塞。节点在其前驱节点释放时发出 <code>signal</code> 。否则，队列中的每个节点都是持有单个线程的特定通知器。状态字段不用于控制线程是否持有锁。同时，线程可能会尝试获取队列中的第一个节点，但其并不保证一定成功，所以当前释放的竞争线程可能会重新被阻塞（如果没有获取到锁）。</p>
<p><code>AQS</code>使用的 CLH 变体中的 &quot;prev&quot; 连接（指向前驱节点）主要用于处理取消。如果一个节点被取消，它的后继节点（通常）需要重新连接到一个未取消的前驱节点。</p>
<p><code>AQS</code> 使用 CLH 的 &quot;next&quot; 连接（指向后继节点）来实现阻塞机制。每个节点的线程 id 保存在自身中，因此前驱节点通过遍历 next 连接来确定它是哪个线程来通知下一个节点的唤醒。设置当前节点的 next （后继节点）时，必须避免与新入队的节点竞争。当节点的后继节点为空时，通过从队列的 <code>tail</code> 向后检查来解决这个问题。（&quot;next&quot; 本来就是一种优化，通常情况下是不需要向后扫描的。）</p>
<p>CLH 队列需要一个虚拟头节点。但是我们不会在构建时创建它们，因为如果从不存在竞争，那将是浪费精力。相反，在第一次出现竞争时构造节点并设置 <code>head</code> 和 <code>tail</code> 指针。</p>
<p><code>Condition</code> 等待队列中的阻塞线程使用的是相同的 <code>Node</code> 结构，但是提供了另一个链表来存放，因此 <code>Condition</code> 等待队列的实现会更加复杂。</p>
<p>关于 CLH 队列的实现如下：</p>
<pre><code class="language-java">    static final class Node {
        /** 标记节点处于共享模式下的等待 */
        static final Node SHARED = new Node();
        /** 标记节点处于独占模式下的等待 */
        static final Node EXCLUSIVE = null;

        /** waitStatus 值，表示线程已经取消 */
        static final int CANCELLED =  1;
        /** waitStatus 值，表示后继线程需要唤醒 */
        static final int SIGNAL    = -1;
        /** waitStatus 值，表示线程需要等待条件 */
        static final int CONDITION = -2;
        /**
         * waitStatus 值，指示下一个 acquireShared 应该无条件传播
         */
        static final int PROPAGATE = -3;

        /**
         * Status 字段, 仅取以下值:
         *   SIGNAL:     该节点的后继节点被（或即将）阻塞（通过 park），因此当前
         *               节点在释放或取消时必须解除其后继节点的 park。为了避免
         *               竞争，acquire 方法必须首先表明它们需要 signal，然后重试
         *               原子获取，然后在失败时阻塞。
         *   CANCELLED:  由于超时或中断，该节点被取消。节点永远不会离开这个状态。
         *				 特别的是，被取消的节点的线程永远不会再次阻塞。
         *   CONDITION:  此节点当前位于条件队列中。在转换之前不会用作同步队列节点，
         *               此时状态将设置为 0。（此处使用此值与该字段的其他用途无关，但简化的机制）
         *   PROPAGATE:  releaseShared 应该传播到其他节点。这是在 doReleaseShared 中设置 
         *               的（仅针对头结点），以确保传播继续进行，即使其他操作已经介入。
         *   0:          以上都不是
         *
         * 这些值按数字排列以简化使用。非负值意味着节点不需要发出 signal。
         * 因此，大多数代码不需要检查特定值，只需检查 sign 即可。
         *
         * 对于正常同步节点，该字段初始化为 0，对于 CONDITION 节点，该字段初始化为 CONDITION。
         * 它使用 CAS 进行修改（或者在可能的情况下，无条件的 volatile 写入）
         */
        volatile int waitStatus;

        /**
         * 链接到当前节点/线程的前驱节点，用于检查 waitStatus。在入队时分配，
         * 并且仅在出队时设置为 null（为了 GC）。此外，在前驱节点取消时，我们短路，同时
         * 找到一个未取消的前驱节点（该前驱节点不会不存在），因为头结点不会被取消：一个节点
         * 只有在 acquire 成功时才会成为头结点。被取消的线程永远不会获取成功，同时
         * 一个线程只能取消自己，无法取消任何其他节点。
         */
        volatile Node prev;

        /**
         * 链接到当前节点/线程的后继节点，用于在 release 时 unpark 操作。在入队时分配，
         * 前驱节点取消时，会进行绕过调整，在出队时清空（为了 GC）。enq 操作在建立链接之前
         * 不会给前驱节点的 next 字段赋值，因此看到 next 字段为 null，并不一定意味着该节点在
         * 队尾。然而，如果 next 字段看起来是 null，我们可以从 tail 扫描 prev 节点，从而
         * 进行双重检查。取消的节点的 next 字段被设置为指向节点自身，而不是 null，
         * 从而使 isOnSyncQueue 的工作更容易。
         */
        volatile Node next;

        /**
         * 将 thread 放入当前节点。构造时初始化，使用后清空。
         */
        volatile Thread thread;

        /**
         * 链接到等待条件的下一个节点，或特定的 SHARED 值。因为条件队列只有在
         * 独占模式下被访问，所以我们只需要一个简单的链接队列来保存等待条件的节点。
         * 然后，它们被转移到队列中进行重新 acquire。因为条件只能是独占的，所以
         * 我们通过使用特殊值来保存特殊值，以表示共享模式。
         */
        Node nextWaiter;

        /**
         * 如果节点在共享模式下等待，则返回true。
         */
        final boolean isShared() {
            return nextWaiter == SHARED;
        }

        /**
         * 返回上一个节点，如果为空则抛出NullPointerException。
         * 当前驱节点不能为空时使用。null 检查可以省略，但它的存在是为了帮助 VM。
         *
         * @return 当前节点的前驱节点
         */
        final Node predecessor() throws NullPointerException {
            Node p = prev;
            if (p == null)
                throw new NullPointerException();
            else
                return p;
        }

        Node() {    // Used to establish initial head or SHARED marker
        }

        Node(Thread thread, Node mode) {     // Used by addWaiter
            this.nextWaiter = mode;
            this.thread = thread;
        }

        Node(Thread thread, int waitStatus) { // Used by Condition
            this.waitStatus = waitStatus;
            this.thread = thread;
        }
    }

    /**
     * 等待队列的头部，延迟初始化。除此之外，只能通过 setHead 方法进行修改，
     * 注意：如果 head 存在，它的 waitStatus 保证不会被 CANCELLED。
     */
    private transient volatile Node head;

  /**
   * 等待队列的尾部，延迟初始化。仅通过方法 enq 修改以添加新的等待节点。
   */
  private transient volatile Node tail;

  /**
   * 设置以用于支持 compareAndSet. 我们需要在这里本地实现这一点：
   * 为了允许未来的功能增强，我们不能显式地继承 AtomicInteger，不然这将是高效和有用的。
   * 因此，作为少有的弊端，我们本地使用 hotspot 内在的 API 实现。但我们这样做的时候，
   * 我们队其他 CASable 字段做同样的事情（否则可以用原子字段更新器来完成）。
   */
    private static final Unsafe unsafe = Unsafe.getUnsafe();
    private static final long stateOffset;
    private static final long headOffset;
    private static final long tailOffset;
    private static final long waitStatusOffset;
    private static final long nextOffset;

    static {
        try {
            stateOffset = unsafe.objectFieldOffset
                (class.getDeclaredField(&quot;state&quot;));
            headOffset = unsafe.objectFieldOffset
                (class.getDeclaredField(&quot;head&quot;));
            tailOffset = unsafe.objectFieldOffset
                (class.getDeclaredField(&quot;tail&quot;));
            waitStatusOffset = unsafe.objectFieldOffset
                (Node.class.getDeclaredField(&quot;waitStatus&quot;));
            nextOffset = unsafe.objectFieldOffset
                (Node.class.getDeclaredField(&quot;next&quot;));

        } catch (Exception ex) { throw new Error(ex); }
    }

    /**
     * CAS head field. Used only by enq.
     */
    private final boolean compareAndSetHead(Node update) {
        return unsafe.compareAndSwapObject(this, headOffset, null, update);
    }

    /**
     * CAS tail field. Used only by enq.
     */
    private final boolean compareAndSetTail(Node expect, Node update) {
        return unsafe.compareAndSwapObject(this, tailOffset, expect, update);
    }

    /**
     * CAS waitStatus field of a node.
     */
    private static final boolean compareAndSetWaitStatus(Node node,
                                                         int expect,
                                                         int update) {
        return unsafe.compareAndSwapInt(node, waitStatusOffset,
                                        expect, update);
    }

    /**
     * CAS next field of a node.
     */
    private static final boolean compareAndSetNext(Node node,
                                                   Node expect,
                                                   Node update) {
        return unsafe.compareAndSwapObject(node, nextOffset, expect, update);
    }
</code></pre>
<p>下面介绍一下 <code>Node</code> 类中的几个属性：</p>
<ul>
<li><code>waitStatus</code>：当前 <code>Node</code> 的等待状态，共有五个可选值：
<ul>
<li><code>0</code>：初始值，当前节点如果没有指定初始值，则默认为 <code>0</code>。</li>
<li><code>CANCELLED(1)</code>：表示当前节点因为超时或线程中断被取消。当节点被取消后，不会再转换为其他状态，被取消的节点的线程实例也不会阻塞。</li>
<li><code>SIGNAL(-1)</code>：表示当前节点的后继节点通过 <code>park()</code> 被阻塞，当前节点释放或取消时，必须 <code>unpark()</code> 它的后继节点。</li>
<li><code>CONDITION(2)</code>：表示当前节点是条件队列中的一个节点，当它转换为同步队列中节点时，<code>waitStatus</code> 会被重新设置为 <code>0</code>。</li>
<li><code>PROPAGATE(3)</code>：当节点为头结点，调用 <code>doReleaseShared()</code> 时，确保 <code>releaseShared()</code> 可以传播到其他节点。</li>
</ul>
</li>
<li><code>prev</code>：当前节点的前驱节点，用于检查 <code>waitStatus</code>。当前驱节点被取消时，通过 <code>prev</code> 找到一个未取消的前驱节点。</li>
<li><code>next</code>：当前节点的后继节点，当节点被取消或释放时，用于 <code>unpark</code> 取消后继节点的阻塞（会自动绕过取消的后继节点）。</li>
<li><code>thread</code>：当前节点持有的线程实例引用。</li>
<li><code>nextWaiter</code>：下一个等待节点，可能的取值有下面的几种情况：
<ul>
<li>当前实例为独占模式时，取值为 <code>Node.EXCLUSIVE</code> （即 <code>null</code>）。</li>
<li>当前实例为共享模式时，取值为 <code>Node.SHARED</code>。</li>
<li>非上面两种情况时，代表条件队列中当前节点的下一个等待节点。</li>
</ul>
</li>
</ul>
<h3 id="33-阻塞">3.3 阻塞</h3>
<p>在 JDK1.5 之前，线程的阻塞和唤醒只能依赖于 <code>Object</code> 类提供的 <code>wait()</code> 、<code>notify()</code>、<code>notifyAll()</code> 方法，它们都是由 JVM<br>
提供实现，并且使用的时候需要获取监视器锁（即需要在 <code>synchronized</code> 代码块中），没有 Java API 可以阻塞和唤醒线程。唯一可以选择的是 <code>Thread.suspend</code> 和 <code>Thread.resume</code><br>
，但是他们都有无法解决的竟态问题：当一个非阻塞线程在一个正准备阻塞的线程调用 <code>suspend</code> 之前调用 <code>resume</code>，<code>resume</code>操作将不起作用。</p>
<p><code>j.u.c</code> 包引入了 <code>LockSupport</code> 类，其底层是基于 <code>Unsafe</code> 类的 <code>park()</code> 和 <code>unpark()</code> 方法，<code>LockSupport.park</code><br>
阻塞当前线程，除非或直到发出 <code>LockSupport.unpark</code>（虚假唤醒是允许的）。<code>park</code> 方法同样支持可选的相对或绝对的超时设置，以及与<br>
JVM 的 <code>Thread.interrupt</code> 结合 —— 可通过中断来 <code>unpark</code> 一个线程。</p>
<h3 id="34-条件队列">3.4 条件队列</h3>
<p>在 <code>AQS</code> 中除了同步队列外，还提供了另一种更为复杂的条件队列，而条件队列是基于 <code>Condition</code>接口实现的，下面我们先浏览一下 <code>Condition</code> 接口的说明。</p>
<h4 id="341-condition-接口">3.4.1 Condition 接口</h4>
<p><code>Condition</code> 将 <code>Object</code> 的监视器方法（<code>wait</code>、<code>notify</code> 和 <code>notifyAll</code>） 分解到不同的对象，通过将它们与任意的 <code>Lock</code><br>
实现相结合，可以使每个对象具有多个等待集合。<code>Lock</code> 代替的 <code>synchronized</code> 方法和语句的使用，<code>Condition</code> 代替了 <code>Object</code><br>
监视器方法的使用。</p>
<p><code>Condition</code>（也称为 <em>条件队列(condition queue)</em> 或 <em>条件变量(condition variable)</em>）为线程提供了一种暂停执行（“等待”）的方法，直到另外一个线程通知说某个状态条件现在可能为 <code>true</code><br>
。由于对这种共享状态信息的访问会发生在多个不同线程中，所以它必须受到保护，因此需要某种形式的锁与条件相关联。等待条件提供的关键属性是它以 *<br>
原子* 方式释放关联的锁并挂起当前线程，就像 <code>Object.wait</code> 一样。</p>
<p><code>Condition</code> 实例本质上是需要绑定到锁。需要获取特定 <code>Lock</code> 实例的 <code>Condition</code> 实例，请使用其 <code>newCondition()</code> 方法。</p>
<p>例如，假设我们有一个支持 put 和 take 方法的有界缓冲区。如果 take 在空缓冲区上尝试获取，则线程将阻塞，知道缓冲区变得可用；如果在一个满的缓冲区上调用 <code>put</code>，则线程将阻塞，直到有空间可用。我们希望<br>
put 线程继续等待，并且与 take线程隔开在另一个等待集合中，以便当我们的缓冲区可用或有空间发生变化时通知对应的单个线程。这可以使用量 <code>Condition</code> 实例来实现。</p>
<pre><code class="language-java">class BoundedBuffer {
    final Lock lock = new ReentrantLock();
    final Condition notFull = lock.newCondition();
    final Condition notEmpty = lock.newCondition();
    
    final Object[] items = new Object[100];
    int putptr, takeptr, count;
    
    public void put(Object x) throws InterruptedException {
        lock.lock();
        try {
            while (count == items.length) 
                notFull.await();
            items[putptr] = x;
            if (++putptr == items.length) putptr = 0;
            ++count;
            notEmpty.signal();
        } finally {
            lock.unlock();
        }
    }
    
    public Object take() throws InterrputedException {
        lock.lock();
        try {
            while (count == 0) 
                notEmpty.await();
            Object x = items[takeptr];
            if (++takeptr == items.length) takeptr = 0;
            --count;
            notFull.signal();
            return x;
        } finally {
            lock.unlock;
        }
    }
}
</code></pre>
<p>(<code>java.util.concurrent.ArrayBlockingQueue</code> 类提供了这个功能，所以没有理由使用这个实例类。)</p>
<p><code>Condition</code> 的实现可以提供与 <code>object</code> 监视器方法不同的行为和语义，例如保证通知的顺序，或者在执行通知时不需要持有锁。如果实现提供了这种专门的语义，那么实现必须记录这些语义。</p>
<p>请注意，<code>Condition</code> 实例只是普通对象，它们本身可以用作 <code>synchronized</code> 语句中的目标，并且可以调用它们自己的监视器 <code>wait</code> 和 <code>notification</code> 方法。获取 <code>Condition</code> 实例的监视器锁，或使用其监视器方法，与获取和该 <code>Condition</code> 关联的 <code>Lock</code> 或使用其 <code>wait()</code> 和 <code>signal()</code> 方法没有指定关系。为避免混淆，建议不要以这种方式使用 <code>Condition</code> 实例，除非在它们自己的实现中。</p>
<p>除非另有说明，否则为任何参数传递 <code>null</code> 值将导致 <code>NullPointerException</code>。</p>
<p>实现注意事项：</p>
<p>在等待 <code>Condition </code> 时，通常允许发生 <em>”虚假唤醒“</em><br>
，作为对底层平台语义的让步。这对大多数应用程序几乎没有实际影响，因为应该始终在循环中等待 <code>Condition</code><br>
，测试正在等待的状态谓词是否为 <code>true</code>。一个实现可以自由地消除虚假唤醒的可能性，但建议应用程序的程序员总是假设它们可以发生，因此总是在循环中等待条件唤醒。</p>
<p>条件等待的三种形式（可中断、不可中断和定时）在某些平台上实现的难易程度和性能特征可能不同。特别是，可能难以提供这些功能并维护特定的语义，例如排序保证。此外，中断线程的实际挂起能力可能并不总是适用所有平台。</p>
<p>因次，实现不需要为所有三种等待形式定义完全相同的保证或语义，也不需要支持线程实际挂起的中断。</p>
<p>实现需要清楚地记录每个等待方法提供的语义和保证，并且当实现确实支持线程挂起的中断时，它必须遵守此接口中定义的中断语义。</p>
<p>由于中断通常意味着取消，并且对中断的检查通常不常见，因此实现可以倾向于响应中断而不是正常的方法返回。即使可以证明中断发生在另一个可能已经解除阻塞线程的操作之后也是如此。一个实现应该记录这个行为。</p>
<pre><code class="language-java">public interface Condition {

  /**
   * 使当前线程等待，直到它被 signal 或中断。
   *
   * 直到以下四种情况之一发生时，与此 Condition 关联的锁会被自动释放，并且当前线程
   * 由于线程调度会被禁用并处于休眠状态：
   * - 其他某个线程为此 Condition 调用了 signal() 方法，而当前线程恰好被选为要被唤醒的线程；
   * - 其他一些线程为此 Condition 调用了 signalAll() 方法；
   * - 其他一些线程中断当前线程，支持中断线程挂起；
   * - 发生“虚假唤醒”。
   *
   * 在所有情况下，在此方法可以返回之前，当前线程必须重新获取获取与此 Condition 关联的锁。
   * 当前线程返回时，它保证持有这个锁。
   *
   * 如果当前线程：
   * - 在进入此方法时设置其中断状态；或者，
   * - 等待过程中被中断，支持线程挂起的中断。
   *
   * 然后抛出 InterruptedException 并清除当前线程的中断状态。在第一种情况下，没有规定是否
   * 在释放锁之前进行中断判断。
   *
   * 实现注意事项：
   *
   * 调用此方法时，假定当前线程持有与此 Condition 关联的锁。由实现决定是否是这种情况，
   * 如果不是，如何响应。通常，将抛出异常（例如，IllegalMonitorStateException）并且
   * 实现必须记录该事实。
   *
   * 与响应 signal 的正常方法返回相比，实现更倾向于响应中断。在这种情况下，实现必须确保将
   * 信号量重定向到另一个等待线程（如果有的话）。
   *
   * @throws InterruptedException - 如果当前线程被中断（并且支持线程挂起的中断）
   */
  void await() throws InterruptedException;

  /**
   * 使当前线程等待，直到它被 signal。
   *
   * 直到以下三种情况之一发生时，与此 Condition 关联的锁会被自动释放，并且当前线程
   * 由于线程调度会被禁用并处于休眠状态：
   * - 其他某个线程为此 Condition 调用了 signal() 方法，而当前线程恰好被选为要被唤醒的线程；
   * - 其他一些线程为此 Condition 调用了 signalAll() 方法；
   * - 发生“虚假唤醒”。
   *
   * 在所有情况下，在此方法可以返回之前，当前线程必须重新获取获取与此 Condition 关联的锁。
   * 当前线程返回时，它保证持有这个锁。
   *
   * 如果当现场进入该方法时设置了中断状态，或者在等待过程中被中断，则继续等待直到被 signal 唤醒。
   * 当它最终从这个方法返回时，它的中断状态会依旧存在。
   *
   *
   * 实现注意事项：
   *
   * 调用此方法时，假定当前线程持有与此 Condition 关联的锁。由实现决定是否是这种情况，
   * 如果不是，如何响应。通常，将抛出异常（例如，IllegalMonitorStateException）并且
   * 实现必须记录该事实。
   *
   */
  void awaitUninterruptibly();

  /**
   * 使当前线程等待，直到它被 signal 或 中断，或者达到指定的等待时间。
   *
   * 直到以下五种情况之一发生时，与此 Condition 关联的锁会被自动释放，并且当前线程
   * 由于线程调度会被禁用并处于休眠状态：
   * - 其他某个线程为此 Condition 调用了 signal() 方法，而当前线程恰好被选为要被唤醒的线程；
   * - 其他一些线程为此 Condition 调用了 signalAll() 方法；
   * - 其他一些线程中断当前线程，支持中断线程挂起；
   * - 到达指定的等待时间；
   * - 发生“虚假唤醒”。
   *
   * 在所有情况下，在此方法可以返回之前，当前线程必须重新获取获取与此 Condition 关联的锁。
   * 当前线程返回时，它保证持有这个锁。
   *
   * 如果当前线程：
   * - 在进入此方法时设置其中断状态；或者，
   * - 等待过程中被中断，支持线程挂起的中断。
   *
   * 然后抛出 InterruptedException 并清除当前线程的中断状态。在第一种情况下，没有规定是否
   * 在释放锁之前进行中断判断。
   *
   * 在返回时提供给定的 nanosTimeout 值，该方法返回对剩余等待纳秒数的预估，如果超时，则返回
   * 小于或等于零的值。在等待返回但是等待的条件仍不成立的情况下，此值可用于确定是否重新等待以及
   * 重新等待多长时间。此方法的典型用途如以下形式：
   *
   * boolean aMethod(long timeout, TimeUnit unit) {
   *     long nanos = unit.toNanos(timeout);
   *     lock.lock();
   *     try {
   *         while (!conditionBeingWaitedFor()) {
   *             if (nanos &lt;= 0L) 
   *                 return false;
   *             nanos = theCondition.awaitNanos(nanos);
   *         }
   *         // ...
   *     } finally {
   *         lock.unlock();
   *     }
   * }
   *
   * 设计说明：此方法需要纳秒参数，以避免报告剩余时间时出现截断错误。这种精度损失将使程序员
   * 难以确保总等待时间不会系统地短于重新等待发生时指定的时间。
   *
   * 实现注意事项：
   *
   * 调用此方法时，假定当前线程持有与此 Condition 关联的锁。由实现决定是否是这种情况，
   * 如果不是，如何响应。通常，将抛出异常（例如，IllegalMonitorStateException）并且
   * 实现必须记录该事实。
   *
   * 与响应 signal 的正常方法返回相比，实现更倾向于响应中断。在这种情况下，实现必须确保将
   * 信号量重定向到另一个等待线程（如果有的话）。
   *
   * 参数： nanosTimeout - 等待的最长时间，以纳秒为单位。
   * 返回： nanosTimeout值减去从该方法返回时等待的时间的估计值。正值表示可以用作对该方法的
   *       后续调用以完成等待所需时间的参数。小于或等于零表示没有剩余的时间。
   * @throws InterruptedException - 如果当前线程被中断（并且支持线程挂起的中断）
   */
  long awaitNanos(long nanosTimeout) throws InterruptedException;

  /**
   * 使当前线程等待，直到它被 signal 或 中断，或者达到指定的等待时间。此方法在行为上等效于：
   *     awaitNanos(unit.toNanos(time)) &gt; 0 
   *
   * 参数： time - 等待的最长时间
   *       unit - time 参数的时间单位
   * 返回： 如果从方法返回之前已经到达指定时间，则为 false，否则为 true。
   * @throws InterruptedException - 如果当前线程被中断（并且支持线程挂起的中断）
   */
  boolean await(long time, TimeUnit unit) throws InterruptedException;

  /**
   * 使当前线程等待，直到它被 signal 或 中断，或者达到指定的等待时间。
   *
   * 直到以下五种情况之一发生时，与此 Condition 关联的锁会被自动释放，并且当前线程
   * 由于线程调度会被禁用并处于休眠状态：
   * - 其他某个线程为此 Condition 调用了 signal() 方法，而当前线程恰好被选为要被唤醒的线程；
   * - 其他一些线程为此 Condition 调用了 signalAll() 方法；
   * - 其他一些线程中断当前线程，支持中断线程挂起；
   * - 到达指定的等待时间；
   * - 发生“虚假唤醒”。
   *
   * 在所有情况下，在此方法可以返回之前，当前线程必须重新获取获取与此 Condition 关联的锁。
   * 当前线程返回时，它保证持有这个锁。
   *
   * 如果当前线程：
   * - 在进入此方法时设置其中断状态；或者，
   * - 等待过程中被中断，支持线程挂起的中断。
   *
   * 然后抛出 InterruptedException 并清除当前线程的中断状态。在第一种情况下，没有规定是否
   * 在释放锁之前进行中断判断。
   *
   * 返回值表示是否已经过了 deadline，可以如下使用：
   *
   * 实现注意事项：
   *
   * 调用此方法时，假定当前线程持有与此 Condition 关联的锁。由实现决定是否是这种情况，
   * 如果不是，如何响应。通常，将抛出异常（例如，IllegalMonitorStateException）并且
   * 实现必须记录该事实。
   *
   * 与响应 signal 的正常方法返回相比，实现更倾向于响应中断。在这种情况下，实现必须确保将
   * 信号量重定向到另一个等待线程（如果有的话）。
   * boolean aMethod(Date deadline) {
   *     boolean stillWaiting = true;
   *     lock.lock();
   *     try {
   *         while(!conditionBeingWaitedFor()) {
   *             if (!stillWaiting)
   *                 return false;
   *             stillWaiting = theCondition.awaitUntil(deadline);
   *         }
   *         // ...
   *     } finally {
   *         lock.unlock();
   *     }
   * }
   *
   * 参数： deadline - 等待的绝对时间。
   * 返回： 如果返回时已经超过最后期限，则为 false，否则为 true。
   * @throws InterruptedException - 如果当前线程被中断（并且支持线程挂起的中断）
   */
  boolean awaitUntil(Date deadline) throws InterruptedException;

  /**
   * 唤醒一个等待线程。
   *
   * 如果有任何线程在此 Condition 下等待，则选择一个用于唤醒。然后，该线程必须在从
   * await 返回之前重新获取锁。
   *
   * 实现注意事项
   *
   * 在调用此方法时，实现可能（并且通常确实）要求当前线程持有与此 Condition 关联的锁。
   * 实现必须记录此前提条件以及未持有锁时采取的任何操作。通常，会抛出 IllegalMonitorStateException。
   */
  void signal();

  /**
   * 唤醒所有等待线程。
   *
   * 如果有任何线程在此 Condition 下等待，则它们全部都会被唤醒。然后，每个线程必须在从
   * await 返回之前重新获取锁。
   *
   * 实现注意事项
   *
   * 在调用此方法时，实现可能（并且通常确实）要求当前线程持有与此 Condition 关联的锁。
   * 实现必须记录此前提条件以及未持有锁时采取的任何操作。通常，会抛出 IllegalMonitorStateException。
   */
  void signalAll();
}

</code></pre>
<p><code>Condition</code> 接口提供了与 JAVA 原生的监视器相同风格的 API，但是其并不依赖于 JVM 的实现，用户可以自定义实现 <code>Condition</code><br>
接口，提供更加强大和更加灵活的功能，<code>Condition</code> 在说明中建议和 <code>Lock</code><br>
共同使用，可以使每个对象具有多个等待集合，我们下面了解一下 <code>Lock</code> 接口 。</p>
<h4 id="342-lock-接口">3.4.2 Lock 接口</h4>
<p>与使用 <code>synchronized</code> 方法和语句相比，<code>Lock</code><br>
实现提供了更广泛的锁定操作。它们允许更灵活的结构，可能具有完全不同的属性，并且可能支持多个关联的 <code>Condition</code> 对象。</p>
<p><code>Lock</code> 是一种控制多线程访问共享资源的工具。通常，<code>Lock</code><br>
提供对共享资源的独占访问：一次只有一个线程可以获得锁，并且堆共享资源的所有访问都需要首先获取锁。但是，某些锁可能允许并发访问共享资源，例如 <code>ReadWriteLock</code><br>
的读锁。</p>
<p><code>synchronized</code> 方法或语句的使用提供了对于每个对象关键的隐式监视器锁的访问，但强制所有锁的获取和释放必须在块结构内发生：当获取多个锁时，它们必须以相反的顺序释放，并且所有锁必须在获得它们的相同词法范围内释放。</p>
<p>虽然 <code>synchronized</code><br>
方法和语句的作用域机制让使用监视器锁编程变得更加容易，并且有助于避免许多设计锁的常见编程错误，但在某些情况下，您需要以更加灵活的方式使用锁。例如，一些遍历并发访问的数据结构的算法需要使用 <code>hand-over-hand</code><br>
或 <code>chain locking</code>：你获取节点 A 的锁，然后获取节点 B 的锁，然后释放 A 并获取 C，然后释放 B 并获取 D 等等。<code>Lock</code><br>
接口的实现通过允许在不同范围内获取和释放锁以及允许以任意顺序获取和释放多个锁，来启用此类技术。</p>
<p>随着这种灵活性的增加，额外的责任也随之而来。块结构锁定的缺失消除了 <code>synchronized</code> 方法和语句发生的锁定和自动释放。在大多数情况下，应使用以下语句：</p>
<pre><code class="language-java">Lock l=...;
l.lock();
try{
    // access the resource protected by this lock
}finally{
    l.unlock;
}
</code></pre>
<p>当锁定和解锁发生在不同范围内时，必须注意确保所有在持有锁时执行的代码都受到 <code>try-finally</code> 或 <code>try-catch</code> 的保护，以确保在必要时释放锁。</p>
<p><code>Lock</code> 实现通过提供非阻塞获取锁定方式（<code>tryLock()</code>）、获取可中断锁的尝试（<code>lockInterruptibly()</code><br>
，以及获取锁的尝试）、还提供了超过使用 <code>synchronized</code> 方法和语句的附加功能 —— 可以超时（<code>tryLock(long, Timeunit)</code>）。</p>
<p><code>Lock</code> 类还可以提供与隐式监视器锁完全不同的行为和语义，例如保证排序、不可重入使用或死锁检测。如果实现提供了这种专门的语义，那么实现必须用文档记录这些语义。</p>
<p>请注意，<code>Lock</code> 实例只是普通对象，它们本身可以用作 <code>synchronized</code> 语句中的目标。获取 <code>Lock</code><br>
实例的监视器锁与调用该实例的任何 <code>lock() </code><br>
方法没有指定关系。建议为避免混淆，除非在它们自己的实现中，否则不要以这种方式使用 <code>Lock</code> 实例。</p>
<p>除非另有说明，否则任何参数传递 <code>null</code> 将导致 <code>NullPointerException</code>。</p>
<p><strong>内存同步</strong>：</p>
<p>所有 <code>Lock</code> 实现<em>必须</em><br>
强制执行与内置监视器锁提供的相同的内存同步语义。如 <a href="https://docs.oracle.com/javase/specs/jls/se7/html/jls-17.html#jls-17.4">《The Java Language Specification (17.4 Memory Model) 》</a><br>
中所述：</p>
<ul>
<li>成功的 <em>Lock</em> 动作与成功的 <code>lock()</code> 操作具有相同的内存同步效果。</li>
<li>成功的 <em>Unlock</em> 动作与成功的 <code>unlock()</code> 操作具有相同的内存同步效果。</li>
</ul>
<p>不成功的 lock 和 unlock 操作，以及重入 lock/unlock 操作，不需要任何内存同步效果。</p>
<p><strong>实现注意事项</strong>：</p>
<p>三种形式的锁获取（可中断、不可中断和超时）可能在它们的性能特征、顺序保证或其他实现质量方面有所不同。此外，中断 <em>正在进行</em><br>
的锁获取的能力在给定的 <code>Lock</code><br>
类中可能不可用。因此，实现不需要为所有的三种形式的锁获取给定完全相同的保证或语义，也不需要支持正在进行的锁获取的中断。实现需要清楚地记录每个锁定方法提供的语义和保证。它们必须遵守此接口中定义的中断语义，一直吃获取锁的中断：完全或仅在方法入口上。</p>
<p>由于中断通常意味着取消，并且对中断的检查通常不常见，因此实现可以倾向于响应中断而不是正常的方法返回。即使可以证明在另一个操作可能已解除阻塞线程之后发生中断也是如此。实现应该用文档记录这个行为。</p>
<pre><code class="language-java">public interface Lock {

  /**
   * 获取锁。
   *
   * 如果锁不可用，则当前线程处于线程调度的目的，将被禁用并处于休眠状态，直到获得锁为止。
   *
   * 实现注意事项
   *
   * Lock 实现可能能够检测到锁的错误使用，例如会导致死锁的调用，并且在这种情况下可能会抛出
   * （未经检查）的异常。该 Lock 实现必须描述和记录情况以及异常类型。
   */
  void lock();

  /**
   * 除非当前线程被中断，否则获取锁。
   *
   * 如果可用，则获取锁并立即返回。
   *
   * 如果锁不可用，则当前线程处于线程调度的目的，将被禁用并处于休眠状态，直到发生以下两种情况之一：
   * - 锁被当前线程获取；
   * - 其他一些线程中断当前线程，当前线程支持获取锁的中断。
   *
   * 如果当前线程：
   * - 在进入此方法时设置其中断状态；
   * - 获取锁时中断，并支持获取锁中断。
   *
   * 然后会抛出 InterruptedException 并清除当前线程的中断状态。
   *
   *
   * 实现注意事项
   *
   * 在某些实现中中断锁获取的能力可能是无法实现的，并且如果可能的话会是一个非常昂贵的操作。
   * 程序员应该意识到可能是这种情况，并详细记录和描述这种情况。。
   *
   * 与正常方法返回相比，实现更倾向于响应中断。
   *
   * Lock 实现可能能够检测到锁的错误使用，例如会导致死锁的调用，并且在这种情况下可能会抛出
   * （未经检查的）异常。该 Lock 实现必须详细记录情况和异常类型。
   *
   * @throws InterruptedException - 如果当前线程在获取锁时被中断（并且支持获取锁的中断）
   */
  void lockInterruptibly() throws InterruptedException;

  /**
   * 仅当调用时是空闲的，才获取到锁。
   *
   * 如果锁可用，则获取锁并立即返回 true。如果锁不可用，则此方法立即返回 false。
   *
   * 该方法的典型用法是：
   *
   * Lock lock = ...;
   * if (lock.tryLock()) {
   *     try {
   *         // manipulate protected state
   *     } finally {
   *         lock.unlock();
   *     }
   * } else {
   *     // perform alternative actions
   * }
   *
   * 这种方法确保锁在获得的情况下才解锁，并且在未获得的时候不进行解锁操作。
   *
   * 返回： 如果获得了锁返回 true，否则为 false。
   */
  boolean tryLock();

  /**
   * 如果在给定的等待时间内锁空闲并且当前线程没有被中断，则获取锁。
   *
   * 如果锁可用，则获取锁并立即返回 true。如果锁不可用，则当前线程处于线程调度的目的，
   * 将被禁用并处于休眠状态，直到发生以下三种情况之一：
   * - 锁被当前线程获取；
   * - 其他一些线程中断当前线程，当前线程支持获取锁的中断；
   * - 指定的等待时间已过。
   *
   * 如果获得锁，则返回 true。
   *
   * 如果当前线程：
   * - 在进入此方法时设置其为中断状态；或
   * - 获取锁时中断，并支持获取锁中断。
   *
   * 然后会抛出 InterruptedException 并清除当前线程的中断状态。
   *
   * 如果经过了指定的等待时间，则返回 false。如果时间小于或等于 0，则该方法不会等待。
   *
   * 实现注意事项
   *
   * 在某些实现中中断锁获取的能力可能是无法实现的，并且如果可能的话会是一个非常昂贵的操作。
   * 程序员应该意识到可能是这种情况，并详细记录和描述这种情况。。
   *
   * 与正常方法返回相比，实现更倾向于响应中断。
   *
   * Lock 实现可能能够检测到锁的错误使用，例如会导致死锁的调用，并且在这种情况下可能会抛出
   * （未经检查的）异常。该 Lock 实现必须详细记录情况和异常类型。
   *
   * 参数： time - 等待锁的最长时间
   *       unit - time 参数的时间单位
   * 返回： 如果获得了锁，返回 true；如果在获得锁之前超过了等待时间，返回 false
   * @throws InterruptedException - 如果当前线程在获取锁时被中断（并且支持获取锁的中断）
   */
  boolean tryLock(long time, TimeUnit unit) throws InterruptedException;

  /**
   * 释放锁。
   *
   * 实现注意事项
   *
   * Lock 实现通常会对哪个线程可以释放锁施加限制（通常只有锁的持有者可以释放它），
   * 并且如果违反限制可能会抛出（未经检查的）异常。该 Lock 实现必须详细记录情况和异常类型。
   */
  void unlock();

  /**
   * 返回绑定到此 Lock 实例的新 Condition 实例。
   *
   * 在等待条件之前，锁必须由当前线程持有。调用 Condition.await() 将在等待之前自动释放
   * 锁，并在等待返回之前重新获取锁。
   *
   * 实现注意事项
   *
   * Condition 实例的确切操作取决于 Lock 实现，并且必须由该实现描述。
   *
   *
   * 返回：此 Lock 实例的新 Condition 实例
   * @throws UnsupportedOperationException - 如果 Lock 实现不支持 Condition
   */
  Condition newCondition();
}
</code></pre>
<h2 id="四-aqs-的独占与共享">四、AQS 的独占与共享</h2>
<p>在 <code>AQS</code> 的设计中，为我们保留的扩展的能力，我们可以使用 <code>ConditionObject</code> 和 <code>AQS</code><br>
去实现共享资源的独占和共享，就和 <code>ReadWriteLock</code> 一样，下面我们根据 <code>AQS</code> 的源码来解析这两种模式是如何实现的。</p>
<h3 id="41-独占模式">4.1 独占模式</h3>
<p>独占模式：意味着同一时刻，共享资源只有唯一的单个节点可以获取访问，此时获取到锁的节点的线程是独享的，获取到锁的线程也就从阻塞状态可以继续运行，而同步队列的其他节点则需要继续阻塞。</p>
<p>独占模式的实现主要由 <code>AQS</code> 在初始化时， <code>status</code> 值来确定允许申请资源的数量上限，而对共享资源的获取和释放主要由以下方法进行操作：</p>
<ul>
<li><code>acquire(int)</code> ：获取 int 数量的资源，也就是原子修改 <code>status</code>。</li>
<li><code>acquireInterruptibly(int)</code>：获取 int 数量的资源，可以响应线程中断。</li>
<li><code>tryAcquireNanos(int, long)</code> ：在指定 long 时间内，获取 int 数量的资源。</li>
<li><code>release(int)</code> ：释放 int 数量的资源。</li>
</ul>
<h4 id="411-acquire">4.1.1 acquire</h4>
<p>下面我们根据源码，了解一下独占模式是如何运行的，首先是 <code>acquire</code>：</p>
<pre><code class="language-java">/**
 * 以独占模式获取锁，忽略中断。  通过调用至少一次 tryAcquire() 方法来实现，成功就返回。
 * 否则线程排队，调用 tryAcquire() 成功之前，可能重复阻塞和解除阻塞。此方法可用于实现
 * Lock.lock()。
 *
 * 参数：arg - acquire 参数。这个值被传递给 tryAcquire，你可以用此代表你喜欢的任何东西。
 */
public final void acquire(int arg){
    // 只有当加锁成功或以独占类型节点入队（同步队列，非条件队列）成功时返回，
    if(!tryAcquire(arg) &amp;&amp;
       // 加锁失败，则进行入队操作
       acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
         // 加锁失败，入队失败，则中断线程
         selfInterrupt();
}

/**
 * 尝试以独占模式 acquire。此方法应查询对象的状态，判断是否允许以独占模式获取它。
 *
 * 此方法始终由执行 acquire 的线程调用。如果此方法报告失败，且该线程尚未入队，
 * 则 acquire 方法可以将该线程排队，知道某个其他线程 release 并 signal。这
 * 可用于实现 Lock.tryLock 方法。
 *
 * 默认实现抛出 UnsupportedOperationException 。
 *
 * 参数：arg - acquire 参数.。该值始终是传递给 acquire 方法的值，或者是在进入条件等待时
 保存的值。该值可以表示你喜欢的任何东西。
 * 返回：如果成功，返回 true。成功后，该对象已 acquire。
 * @throws IllegalMonitorStateException  如果获取会将此同步器置于非法状态。
 *                                       必须以一致的方式抛出此异常，同步才能正常工作。
 * @throws UnsupportedOperationException 如果不支持独占模式
 */
protected boolean tryAcquire(int arg){
    throw new UnsupportedOperationException();
}


/**
 * 为当前线程和给定模式创建节点并入队节点。
 *
 * 参数：mode - Node.EXCLUSIVE 用于独占，Node.SHARED 用于共享
 * 返回：新节点
 */
private Node addWaiter(Node mode){
    // 创建当前线程和模式的新节点，此时 waitStatus 为 0
    Node node = new Node(Thread.currentThread(), mode);
    // 先尝试直接入队，当且仅当 tail 不为空时，直接将当前节点追加到 tail 后面
    Node pred = tail;
    if(pred != null){
        // 当前节点的前驱节点为 pred
        node.prev = pred;
        // 原子修改 tail 为当前节点
        if(compareAndSetTail(pred, node)){
            // pred 的后继节点指向当前节点
            pred.next = node;
            return node;
        }
    }
    // tail 为空，或入队失败，则进行自旋 enq 入队
    enq(node);
    return node;
}

/**
 * 将节点插入队列，必要时进行初始化。
 * 参数： node - 插入的节点
 * 返回： 节点的前驱节点
 */
private Node enq(final Node node){
    // 自旋进行插入操作
    for(;;){
        // 获取队列的 tail
        Node t = tail;
        // t 为空，说明队尾没有节点，说明还没有初始化
        if(t == null){ // Must initialize
            // 初始化操作，创建 head 节点
            if(compareAndSetHead(new Node()))
                // 将 tail 也指向 head
            tail = head;
        } else {
            // 将队尾指向当前节点的前驱节点
            node.prev = t;
            // 设置当前节点为队尾
            if(compareAndSetTail(t, node)){
                // 设置 t 的后继节点为当前节点
                t.next = node;
                return t;
            }
        }
    }
}


/**
 * 以独占模式且不中断，acquire 队列中的线程。由 condition 的 wait 和 acquire 方法使用。
 *
 * 参数：node - 节点
 *      arg - acquire 参数
 * 返回：如果在等待时被中断，返回 true
 */
final boolean acquireQueued(final Node node,int arg){
    // acquire 是否失败
    boolean failed = true;
    try {
        // 是否中断
        boolean interrupted = false;
        // 自旋尝试获取资源，每次自旋都会调用 tryAcquire 尝试获取资源，获取资源失败，则进入阻塞状态
        // 成功则跳出自旋
        for(;;){
            // 当前新入队节点的前驱节点
            final Node p = node.predecessor();
            // 前驱节点为头节点时，尝试获取资源。
            if(p == head &amp;&amp; tryAcquire(arg)){
                // 获取资源成功，将当前节点设置为头结点
                setHead(node);
                // 断开前一个节点的链接，帮助 GC
                p.next = null; // help GC
                // 获取成功
                failed = false;
                // 返回是否中断
                return interrupted;
            }
            // 判断在 acquire 失败后是否需要阻塞当前节点中的线程
            if(shouldParkAfterFailedAcquire(p,node)&amp;&amp;
                parkAndCheckInterrupt())
                interrupted =true;
            }
    } finally {
        if(failed)
            cancelAcquire(node);
    }
}

/**
 * 检查并更新 acquire 失败的节点的状态。如果线程应该阻塞，则返回 true。
 * 这是所有循环 acquire 获取资源的主要 signal 控制方法。要求 pred == node.prev。
 *
 * 参数：pred - 节点的前驱节点持有的状态
 *      node - 当前节点
 * 返回：如果线程应该阻塞，返回 true。
 */
private static boolean shouldParkAfterFailedAcquire(Node pred,Node node){
    // 前驱节点的等待状态
    int ws=pred.waitStatus;
    // 前驱结点状态为 SIGNAL，说明当前节点可以阻塞，pred 在完成后需要调用 release
    if(ws == Node.SIGNAL)
        /*
         * 前驱节点状态设置为 Node.SIGNAL，等待被 release 调用释放，后继节点可以安全地进入阻塞。
         */
        return true;
    if(ws &gt; 0) {
        /*
         * 前驱节点为 CANCELLED，尝试把所有 CANCELLED 的前驱节点移除，找到一个
         * 非取消的前驱节点。
         */
        do {
            node.prev = pred = pred.prev;
        } while (pred.waitStatus &gt; 0);
        pred.next=node;
    } else {
        /*
         * waitStatus 为 0 或 PROPAGATE.  表示我们需要一个 signal，
         * 而不是阻塞。调用者需要重试以确保在阻塞前无法 acquire。
         */
        compareAndSetWaitStatus(pred,ws,Node.SIGNAL);
    }
    return false;
}

/**
 * park 后检查是否中断的便捷方法
 *
 * 返回：如果中断，返回true
 */
private final boolean parkAndCheckInterrupt(){
    // park 当前线程
    LockSupport.park(this);
    // 判断是否中断
    return Thread.interrupted();
}


/**
 * 将队列 head 设置为 node，从而使之前的节点出队。仅由 acquire 方法调用。
 * 为了 GC 和抑制不必要的 signal 和遍历，同时也清空无用的字段。
 *
 * 参数：node - 节点
 */
private void setHead(Node node){
    head=node;
    node.thread=null;
    node.prev=null;
}
</code></pre>
<p>依旧使用上面的例子，当 <code>thread-1</code> 入队时，此时队列为空，需要初始化一个空节点，之后将调用 <code>addWaiter()</code> 将  <code>thread-1</code> 入队：</p>
<figure data-type="image" tabindex="1"><img src="/Users/wenbo.zhang/Desktop/images/AQS-thread-1-enq.png" alt="aqs-thread-1-enq" loading="lazy"></figure>
<p>此时，在 <code>thread-1</code> 等待过程中，将 <code>thread-2</code> 进行入队操作：</p>
<figure data-type="image" tabindex="2"><img src="/Users/wenbo.zhang/Desktop/images/AQS-thread-2-enq.png" alt="aqs-thread-2-enq" loading="lazy"></figure>
<p>以上就是 <code>tryAcquire</code> 失败后的入队逻辑，可以看到，在节点进行入队时，会修改前驱节点的 waitStatus，当前驱节点 <code>release</code><br>
时，会进行哪些操作呢？下面我们对 <code>release</code> 操作进行解析。</p>
<h4 id="412-release">4.1.2 release</h4>
<p>在独占模式中，<code>release()</code> 用来释放资源，下面我们根据源码来解读 <code>AQS</code> 如何进行释放操作。</p>
<pre><code class="language-java">/**
 * 释放独占模式。如果 tryRelease 返回 true，则通过解锁一个或多个线程实现。此方法可以
 * 用来实现方法 Lock.unlock.
 *
 * 参数：arg - release 参数。这个值被传递给 tryRelease，你可以用它表示任何你喜欢的东西。
 * 返回：tryRelease 返回的值
 */
public final boolean release(int arg){
    // 尝试释放资源
    if(tryRelease(arg)){
        Node h=head;
        // head 不为空，且 waitStatus 不为 0 的情况下，唤醒后继节点
        if(h!=null&amp;&amp;h.waitStatus!=0)
        // 后继节点解除阻塞
        unparkSuccessor(h);
        return true;
    }
    return false;
}

/**
 * 尝试设置状态，以体现独占模式下的 release。
 *
 * 该方法总是由执行 release 的线程调用。
 *
 * 默认实现抛出 UnsupportedOperationException。
 *
 * 参数：arg - release 参数。此值始终是传递给 release 方法的值，或者是进入条件等待时的
 *            当前状态值。该值是未解释的，可以表示任何你想要的内容。
 * 返回：如果当前对象现在完全释放，则返回 true，以便任何等待的线程都可以尝试 acquire；否则 false。
 * @throws IllegalMonitorStateException - 如果 release 会将此同步器置于非法状态。
 *                                        必须以一致的方式抛出此异常，同步器才能正常工作。
 * @throws UnsupportedOperationException - 如果不支持独占模式
 */
protected boolean tryRelease(int arg){
    throw new UnsupportedOperationException();
}

/**
 * 如果节点存在后继节点，则唤醒后继节点。
 *
 * 参数：node - 节点
 */
private void unparkSuccessor(Node node){
    /*
     * 如果状态为负数（即可能需要 signal），尝试 clear 以等待 signal。
     * 允许失败或等待线程更改状态。
     */
    int ws = node.waitStatus;
    if(ws &lt; 0)
        // 将当前节点的 waitStatus 置为 0
        compareAndSetWaitStatus(node, ws, 0);

    /*
     * 当前线程的后继节点 unpark ，通常只是下一个节点。但如果下个节点为空或
     * 已经取消，则从 tail 向后遍历以找到实际未取消的后继节点。
     */
    Node s=node.next;
    // 后继节点为空，或后继节点是 CANCELLED
    if(s == null || s.waitStatus &gt; 0){
        s = null;
    // 从 tail 开始，向 head 遍历，找到最接近 当前节点的不为空且未取消的节点
    for(Node t = tail;t != null &amp;&amp; t != node; t = t.prev)
        if(t.waitStatus &lt;= 0)
            s = t;
    }
    // 找到之后，unpark 节点线程阻塞状态
    if(s != null)
        LockSupport.unpark(s.thread);
}
</code></pre>
<p>当 <code>release</code> 操作成功 <code>unpark</code> 一个线程后，该线程在通过 <code>acquireQueued</code> 进行 <code>tryAcquire</code><br>
成功后，就会将头结点设置为当前节点，并将之前的头结点以及线程字段置空，以方便 GC 回收，<code>thread-1</code> 获取到锁在执行过程中，状态如下：</p>
<figure data-type="image" tabindex="3"><img src="/Users/wenbo.zhang/Desktop/images/AQS-thread-1-release.png" alt="aqs-thread-1-release" loading="lazy"></figure>
<p><code>thread-1</code> 执行完成后，对 <code>thread-2</code> 进行 unpark 后，状态如下：</p>
<figure data-type="image" tabindex="4"><img src="/Users/wenbo.zhang/Desktop/images/AQS-thread-2-release.png" alt="aqs-thread-2-release" loading="lazy"></figure>
<h4 id="413-acquireinterruptibly">4.1.3 acquireInterruptibly</h4>
<p>下面我们对 <code>acquire</code> 的变体，即带有响应中断版本的 <code>acquireInterruptibly</code> 方法进行解析：</p>
<pre><code class="language-java">/**
 * 以独占模式 acquire，如果线程中断则终止操作。通过首先检查中断状态，然后
 * 至少调用一次 tryAcquire，成功则直接返回。否则线程排队，可能会在 tryAcquire
 * 成功或线程被中断之前，多次重复阻塞和解除阻塞。该方法可用于实现 
 * Lock.lockInterruptibly 方法。
 *
 * 参数：arg - acquire 参数。这个值被传递给 tryAcquire，但并没有进行解释，
 *            你可以将其表示为任何你想要的值。  
 * @throws InterruptedException - 如果当前线程被中断
 */
public final void acquireInterruptibly(int arg)
        throws InterruptedException{
     // 判断当前线程是否中断，并清空线程中断标记位，中断直接抛出异常
    if(Thread.interrupted())
        throw new InterruptedException();
    // 尝试加锁，加锁失败则进行自旋阻塞 acquire
    if(!tryAcquire(arg))
        doAcquireInterruptibly(arg);
}

/**
 * 以独占且可中断模式 acquire。
 * 参数：arg - acquire 参数
 */
private void doAcquireInterruptibly(long arg)
        throws InterruptedException {
    // 新增当前线程节点并入队
    final Node node = addWaiter(Node.EXCLUSIVE);
    boolean failed = true;
    try {
        for (;;) {
            // 前驱节点
            final Node p = node.predecessor();
            // 前驱节点为头节点，且 acquire 成功，则将当前节点置为头节点
            if (p == head &amp;&amp; tryAcquire(arg)) {
                setHead(node);
                p.next = null; // help GC
                failed = false;
                return;
            }
            // 获取资源失败则进入阻塞状态
            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;
                    // park 当前线程，并判断是否中断
                    parkAndCheckInterrupt())
                throw new InterruptedException();
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}
</code></pre>
<p>可以看到，<code>acquireInterruptibly</code> 方法与 <code>acquire</code> 方法基本一致，区别在于在线程中断时是否抛出 <code>InterruptedException</code>。</p>
<h4 id="414-tryacquirenanos">4.1.4  tryAcquireNanos</h4>
<pre><code class="language-java">/**
 * 尝试以独占模式进行 acquire, 如果线程中断则终止操作, 如果超过给定的超时时间
 * 则返回 false。通过首先检查线程中断状态，然后至少调用一次 tryAcquire 方法，
 * 成功则返回 true。否则，线程排队，在调用 tryAcquire 直到成功、或线程被中断、
 * 或到达超时时间，可能重复多次阻塞和解除阻塞。此方法可用于实现 Lock.tryLock(long, TimeUnit)。
 *
 * 参数：arg - release 参数。此值始终是传递给 release 方法的值，或者是进入条件等待时的
 *            当前状态值。该值是未解释的，可以表示任何你想要的内容。
 *      nanosTimeout - 等待的最大纳秒数
 * 返回：如果成功 acquire，则返回 true；如果超时则返回 false
 * @throws InterruptedException 如果线程被中断
 */
public final boolean tryAcquireNanos(long arg, long nanosTimeout)
        throws InterruptedException {
    // 如果当前线程中断，清除中断状态，并抛出异常
    if (Thread.interrupted())
        throw new InterruptedException();
    // 首次先尝试获取资源，失败后以指定超时时间阻塞获取
    return tryAcquire(arg) ||
            doAcquireNanos(arg, nanosTimeout);
}

/**
 * 以独占且支持超时模式进行 acquire。
 *
 * 参数：arg - acquire 参数
 *      nanosTimeout - 最大等待时间
 * 返回：如果 acquire 成功，返回 true
 */
private boolean doAcquireNanos(long arg, long nanosTimeout)
        throws InterruptedException {
    // 如果超时时间小于等于 0，则直接加锁失败返回
    if (nanosTimeout &lt;= 0L)
        return false;
    // 最终超时时间线 = 当前系统时间的纳秒数 + 指定的超时纳秒数
    final long deadline = System.nanoTime() + nanosTimeout;
    // 以独占模式添加新节点并入队
    final Node node = addWaiter(Node.EXCLUSIVE);
    boolean failed = true;
    try {
        // 自旋进行 acquire 操作
        for (;;) {
            // 当前节点的前驱节点
            final Node p = node.predecessor();
            // 前驱节点为 head，尝试 acquire 操作，成功后，将当前节点设为 head，并清空节点无用字段
            if (p == head &amp;&amp; tryAcquire(arg)) {
                setHead(node);
                p.next = null; // help GC
                failed = false;
                return true;
            }
            // 获取本次循环的超时时间
            nanosTimeout = deadline - System.nanoTime();
            // 本次自旋超时到达，直接返回
            if (nanosTimeout &lt;= 0L)
                return false;
            // 当前节点在 acquire 失败后如果需要阻塞，且
            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;
                    // 当前超时时间大于 1000 纳秒，小于等于 1000 纳秒将会进入下一轮自旋获取锁
                    nanosTimeout &gt; spinForTimeoutThreshold)
                // 指定超时时间并 park
                LockSupport.parkNanos(this, nanosTimeout);
            // 如果线程中断，则抛出异常
            if (Thread.interrupted())
                throw new InterruptedException();
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}
</code></pre>
<p><code>tryAcquireNanos</code> 方法与 <code>doAcquireInterruptibly</code> 方法在对超时中断处理上是保持一致的，都会在线程中断后抛出 <code>InterruptedException</code>。<code>tryAcquireNanos</code> 在每轮的自旋加锁失败后，都会重新计算超时时间，当超时时间小于 <code>spinForTimeoutThreshold</code> 后，则会进入自旋进行 <code>acquire</code> 操作。</p>
<h4 id="415-独占模式的实现">4.1.5 独占模式的实现</h4>
<p>基于上述对独占模式的源码的解析，在 <code>j.u.c</code>  包中提供的独占模式的同步器有：</p>
<ul>
<li><code>ReentrantLock</code>可重入锁；</li>
<li><code>ReentrantReadWriteLock</code> 中的 <code>WriteLock</code>；</li>
<li><code>ThreadPoolExecutor</code> 中的 <code>Worker</code>。</li>
</ul>
<h3 id="42-共享模式">4.2 共享模式</h3>
<p>共享模式：即同一时刻，共享资源可以被多个线程获取，<code>status</code> 的状态大于或等于 0。共享模式在 <code>AQS</code> 中的体现为，如果有一个节点持有的线程 <code>acquire</code> 操作 <code>status</code> 成功，那么它会被解除阻塞，并且会把解除阻塞状态 <code>PROPAGATE</code> 给所有有效的后继节点。</p>
<p>共享模式的功能主要由以下四个方法提供，与独占模式相比，在方法命名上由 <code>Shared</code> 区分：</p>
<ul>
<li><code>acquireShared(int)</code> ：获取 int 数量的资源，也就是原子修改 <code>status</code>。</li>
<li><code>acquireSharedInterruptibly(int)</code>：获取 int 数量的资源，可以响应线程中断。</li>
<li><code>tryAcquireSharedNanos(int, long)</code> ：在指定 long 时间内，获取 int 数量的资源。</li>
<li><code>releaseShared(int)</code> ：释放 int 数量的资源。</li>
</ul>
<h4 id="421-acquireshared">4.2.1 acquireShared</h4>
<pre><code class="language-java">/**
 * 以共享模式 acquire，并忽略线程中断。通过首先最少调用一次 tryAcquireShared 实现，
 * 成功则直接返回。否则线程排队，在调用 tryAcquireShared 成功之前，可能会多次重复
 * 阻塞和解除阻塞。
 *
 * 参数：arg - acquire 参数。该值被传递给 tryAcquireShared，但并没有进行解释，
 *            你可以将其表示为任何你想要的值。  
 */
public final void acquireShared(long arg) {
    // 获取失败，返回负值；此时需要加入同步等待队列
    if (tryAcquireShared(arg) &lt; 0)
        doAcquireShared(arg);
}

/**
 * 尝试以共享模式 acquire。此方法应查询对象的状态是否允许以共享模式获取它，
 * 如果允许，则可以获取。
 *
 * 此方法始终由执行 acquire 的线程调用。如果此方法返回失败，且该线程尚未排队，
 * 则 acquire 方法可以将该线程入队，直到某个其他线程释放发出 signal。
 *
 * 默认实现抛出 UnsupportedOperationException。
 *
 * 参数：arg - acquire 参数。该值始终是传递给 acquire 方法的值，或者是在进入条件等待
 *            时保存的值。该值并没有进行解释，你可以将其表示为任何你想要的值。  
 * 返回：失败返回负值；如果以共享模式获取成功但后续的共享模式 acquire 不能成功，则为 0；
 *      如果在共享模式下获取成功并且后续共享模式也可能成功，则为正值，在这种情况下，后续等待
 *      线程必须检查可用性。（对于三种不同返回值的支持使此方法可以仅在 acquire 可用时的独占上下文中使用。）
 *      成功后，此对象已被获取。
 * @throws IllegalMonitorStateException - 如果 acquire 会将此同步器置于非法状态。
 *                                        必须以一致的方式抛出此异常，同步器才能正常工作。
 * @throws UnsupportedOperationException - 如果不支持共享模式
 */
protected long tryAcquireShared(long arg) {
    throw new UnsupportedOperationException();
}

/**
 * 以共享且不中断模式进行 acquire。
 * 参数：arg - acquire 的参数
 */
private void doAcquireShared(long arg) {
    // 为当前线程创建一个新的共享节点并入队
    final Node node = addWaiter(Node.SHARED);
    boolean failed = true;
    try {
        boolean interrupted = false;
        for (;;) {
            // 该节点的前驱节点
            final Node p = node.predecessor();
            // 如果前驱节点为 head
            if (p == head) {
                // 调用 tryAcquireShared 获取资源，只有在大于等于 0 时，才获取到资源，此时唤醒其他节点 
                long r = tryAcquireShared(arg);
                if (r &gt;= 0) {
                    // 设置头结点，并设置 `PROPAGATE 状态，确保唤醒传播到可用的后继节点
                    // 当任意等待节点晋升为 head，也会进行此操作，以此来进行链式唤醒
                    setHeadAndPropagate(node, r);
                    p.next = null; // help GC
                    if (interrupted)
                        selfInterrupt();
                    failed = false;
                    return;
                }
            }
            // acquire 失败判断是否需要 park，并校验线程中断
            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;
                    parkAndCheckInterrupt())
                interrupted = true;
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}

/**
 * 设置队列的 head，并检查后继节点是否可能在共享模式下等待，如果是这样，且设置了
 * propagate &gt; 0，则进行传播。
 *
 * 参数：node - 节点
 *      propagate - tryAcquireShared 的返回值
 *
 * 如果是共享模式下，在设置头结点后，会判断 propagate &gt; 0 || head.waiteStatus &lt; 0 情况下，
 * 进行共享模式下的资源释放操作。
 */
private void setHeadAndPropagate(Node node, long propagate) {
    Node h = head; // 记录旧 head 以供检查
    // 设置当前处理节点为 head
    setHead(node);
    /*
     * 如果出现以下情况，请尝试 signal 下一个排队节点：
     *  - 调用着指定了传播；
     *  - or 有先前的操作记录（在 setHead 之前或之后作为 h.waitStatus）（注意：这是用了 waitStatus 的符号检查，因为 PROPAGATE 状态可能会转换为 SIGNAL）。
     * and
     *  - 下一个节点在共享模式中等待，或者我们并不清楚，因为它显示为 null
     * 
     *
     * 这两种检查的保守性可能会导致不必要的唤醒，但只有在多个竞争的 acquires 和 releases 时才会这样，
     * 所以大多数节点无论如何都需要现在或很快得到 signal。
     */
    // 入参 propagate &gt; 0 || head 为 null || head 的状态为非 CANCELLED 和 0 || 再次校验 head 为空 || 再次校验 head 状态不为 CANCELLED 和 0
    if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 ||
            (h = head) == null || h.waitStatus &lt; 0) {
        Node s = node.next;
        // 当前节点（已经是头节点）的后继节点为 null，且为共享模式
        if (s == null || s.isShared())
            doReleaseShared();
    }
}

/**
 * 共享模式的 release 操作 -- signal 后继节点并保证 propagation。
 * （在独占模式下，如果需要 signal，release 就相当于调用 head 的 unparkSuccessor）。
 */
private void doReleaseShared() {
    /*
     * 确保 release 可以传播，即使还有其他正在进行的 acquire/release。
     * 如果需要 signal，这会以常用的方式尝试对 head 进行 unparkSuccessor。
     * 但如果没没有，则将状态设置为 &quot;PROPAGATE&quot; 确保在 release 时继续传播。
     * 此外，我们必须在循环中进行，以防止在我们执行此操作时，链表中添加新节点。
     * 此外，与 unparkSuccessor 的其他用法不同，我们需要知道 CAS 重置状态
     * 是否失败，如果是则重新检查。
     */
    for (;;) {
        Node h = head;
        // 头节点不为空，且头节点同时不是尾结点
        if (h != null &amp;&amp; h != tail) {
            // 头节点的 waitStatus
            int ws = h.waitStatus;
            // 如果为 SIGNAL，则 CAS 将其更新为 0，更新成功后唤醒其后继节点的阻塞
            if (ws == Node.SIGNAL) {
                // 更新失败，是因为会有并发情况，唤醒的线程也会调用 doReleaseShared
                // 如果更新失败，则跳过进行重新检查
                if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))
                    continue;            // loop to recheck cases
                unparkSuccessor(h);
            }
            // 头节点 waitStatus 已经为 0，则 CAS 将其更新为 -3
            // 此时可以分析 waitStatus 值为 0 的情况如下：
            // 1. 如果 head 节点没有及时被更新，另一个线程被唤醒后获得锁，此时另一个线程已经执行了
            // setHead，将头节点更新为了自己，（因为如果在下面的 h == head 判断中，头节点没有变化，
            // 会直接跳出循环）；此时，通过 unparkSuccessor 将 waitStatus 更新为 0。
            else if (ws == 0 &amp;&amp;
                    !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))
                continue;                // loop on failed CAS
        }
        // 1. head 没有变更，说明被唤醒的线程还没有执行完 setHead 操作，跳出循环。
        // 等新的节点执行 setHeadAndPropagate 操作后，也会调用 doReleaseShared
        // 2. 如果 head  变更了，那就可能会有多个线程（在当前循环被唤醒）都来执行
        // doReleaseShared，此时这个方法的 compareAndSetWaitStatus 就可能
        // 修改失败（当然，也可能会因为其他线程的 acquire/release 的竞争），那此时会
        // 自旋做重新检查。
        if (h == head)                   // loop if head changed
            break;
    }
}
</code></pre>
<p>我们对 <code>doReleaseShared</code> 进行一个说明：</p>
<ol>
<li>
<p>首先，该方法是一个死循环，每次循环中都会重新获取 <code>head</code>，只有当 <code>h == head</code> 时，才会<strong>跳出</strong>循环。而 <code>head</code> 发生变化一定是由于队列中的节点在 <code>acquire</code> 阻塞过程中被唤醒，之后成功获得锁资源，然后在调用 <code>setHeadAndPropagate</code> 方法中的 <code>setHead</code> 方法修改 <code>head</code>。</p>
</li>
<li>
<p>判断 <code>h != null &amp;&amp; h != tail</code> 说明队列中至少要存在两个节点，如果队列并没有因为竞争而初始化为 <code>head</code> 设置过值（<code>head</code> 为 <code>null</code>），或队列仅有一个节点（<code>head</code> 和 <code>tail</code> 指向同一个节点），那么将不进行操作，直接到最后去判断 <code>head</code> 是否发生了变化。</p>
</li>
<li>
<p>如果步骤 2 中的条件满足，说明队列有两个及以上节点，那么此时会根据 <code>h</code> 的 <code>waitStatus</code> 字段判断：</p>
<ol>
<li>如果状态为 <code>signal</code>，说明 <code>h</code> 节点的后继节点需要被通知，此时进行 CAS 操作 <code>compareAndSetWaitStatus(h, Node.SIGNAL, 0)</code>:
<ol>
<li>如果 CAS 操作成功，即将 <code>h</code> 的状态由 <code>SIGNAL</code> 改为 <code>0</code>，此时通过 <code>unparkSuccessor</code> 方法唤醒后继节点。</li>
<li>如果 CAS 操作失败，说明当前线程在修改时存在竞争（可能其他线程也在进行 <code>release/acquire</code> 操作，或者同样在进行 <code>doReleaseShared</code>），此时我们进行重新检查。</li>
</ol>
</li>
<li>如果状态为 <code>0</code> ，说明 <code>h</code> 节点的后继节点已经被唤醒或在唤醒的过程中了，因为当前为共享模式的释放，所以我们使用 CAS 操作将状态更新为 <code>PROPAGATE</code>传播唤醒其他节点。</li>
</ol>
</li>
</ol>
<p>下面我们分析一下 <code>h</code> 的 <code>waitStatus</code> 为 <code>0</code> 的情况：</p>
<ul>
<li>如果队列中只有一个节点，那么它的状态肯定为 0，此时 <code>head</code> 和 <code>tail</code> 都指向这个节点。</li>
<li>如果队列中有一个节点（它的状态为 0），此时另外一个线程由于 <code>acquire</code> 失败，那么失败线程会调用 <code>addWaiter</code> 方法将自己入队，此时队列中有两个节点，此时还没有来得及执行 <code>shouldParkAfterFailedAcquire</code> 中的 <code>compareAndSetWaitStatus(pred, ws, Node.SIGNAL);</code> 将第一个节点的状态改为 <code>signal</code></li>
<li>队列中有多个节点，此时，刚好有线程释放了锁，调用了 <code>releaseShared() -&gt; doReleaseShared() -&gt; unparkSuccessor() </code>  方法的 <code>compareAndSetWaitStatus(node, ws, 0)</code> 一行，将节点状态设置为了 0，之后唤醒 <code>head</code> 节点的后继节点，<code>head</code> 的后继节点将自己设置为队列的 <code>head</code> 的过程中（还没有设置为 <code>head</code>），当前 <code>head</code> 节点的状态为 0。</li>
</ul>
<p>综上，如果在释放共享锁的过程中，会执行 <code>doReleaseShared</code> 方法，而此时会对 <code>PROPAGATE</code> 状态进行传播，唤醒其后继节点，而后继节点唤醒后，也会执行相同的步骤，如果在 <code>if(h == head)</code> 判断前后继节点调用 <code>setHeadAndPropagte</code> 方法将 <code>head</code> 修改为自己，那就会可能有多个线程同时并发执行 <code>doReleaseShared</code> 方法，以此达到传播的目的，当 <code>head</code> 不发生变化时，唤醒的后继节点也会对后续的各个节点进行唤醒，直到全部唤醒完成或无共享资源可用（此时 <code>head</code> 节点不再发生变化）。</p>
<p>与独占模式的 <code>acquire</code> 方法相比，共享模式在当前节点获取资源成功后，除了会将自身设置为 <code>head</code> 之外，还会通过 CAS 将自身的 <code>waitStatus</code> 设置为 <code>PROPAGATE</code>，从而传播去唤醒其他等待节点。</p>
<h4 id="422-releaseshared">4.2.2 releaseShared</h4>
<pre><code class="language-java">/**
 * 以共享模式进行 release 操作。如果 tryReleaseShared 返回 true，则通过解锁一个或
 * 多个线程来实现。
 *
 * 参数：arg - release 参数。该值被传递给 tryReleaseShared，但并没有进行解释，
 *            你可以将其表示为任何你想要的值。 
 * 返回：tryReleaseShared 的返回值
 */
public final boolean releaseShared(int arg) {
    // 尝试释放资源
    if (tryReleaseShared(arg)) {
        // 进行 doReleaseShared 以传播方式唤醒其他节点
        doReleaseShared();
        return true;
    }
    return false;
}

/**
 * 尝试设置状态，以体现共享模式下的 release。
 *
 * 该方法总是由执行 release 的线程调用。
 *
 * 默认实现抛出 UnsupportedOperationException。
 *
 * 参数：arg - release 参数。此值始终是传递给 release 方法的值，或者是进入条件等待时的
 *            当前状态值。该值是未解释的，可以表示任何你想要的内容。
 * 返回：如果此共享模式的 release 可能允许等待 acquire 的其他线程成功（共享或独占）；否则 false。
 * @throws IllegalMonitorStateException - 如果 release 会将此同步器置于非法状态。
 *                                        必须以一致的方式抛出此异常，同步器才能正常工作。
 * @throws UnsupportedOperationException - 如果不支持独占模式
 */
protected boolean tryReleaseShared(int arg) {
    throw new UnsupportedOperationException();
}
</code></pre>
<p>可以看到，<code>releaseShared</code> 其实就是在 <code>tryReleaseShared</code> 返回 <code>true</code> 后，去调用 <code>doReleaseShared</code> 传播唤醒状态。</p>
<h4 id="423-acquiresharedinterruptibly">4.2.3 acquireSharedInterruptibly</h4>
<pre><code class="language-java">/**
 * 以共享模式 acquire，如果线程中断则终止操作。通过首先检查中断状态，然后
 * 至少调用一次 tryAcquireShared，成功则直接返回。否则线程排队，可能会在 
 * tryAcquireShared 成功或线程被中断之前，多次重复阻塞和解除阻塞。
 *
 * 参数：arg - acquire 参数。这个值被传递给 tryAcquire，但并没有进行解释，
 *            你可以将其表示为任何你想要的值。  
 * @throws InterruptedException - 如果当前线程被中断
 */
public final void acquireSharedInterruptibly(int arg)
        throws InterruptedException {
    // 判断线程中断并清除中断标志，如果中断，直接抛出异常终止
    if (Thread.interrupted())
        throw new InterruptedException();
    // 尝试加锁，小于 0 说明加锁失败，需要入队操作
    if (tryAcquireShared(arg) &lt; 0)
        doAcquireSharedInterruptibly(arg);
}

/**
 * 以共享且可中断模式 acquire。
 * 参数：arg - acquire 参数
 */
private void doAcquireSharedInterruptibly(int arg)
        throws InterruptedException {
    // 创建共享模式节点并入队
    final Node node = addWaiter(Node.SHARED);
    boolean failed = true;
    try {
        for (;;) {
            // 当前节点的前驱节点
            final Node p = node.predecessor();
            if (p == head) {
                // 加锁操作
                int r = tryAcquireShared(arg);
                if (r &gt;= 0) {
                    // 设置头结点并传播状态
                    setHeadAndPropagate(node, r);
                    p.next = null; // help GC
                    failed = false;
                    return;
                }
            }
            // 加锁失败后进行阻塞操作，如果线程中断，则抛出异常
            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;
                    parkAndCheckInterrupt())
                throw new InterruptedException();
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}
</code></pre>
<h4 id="424-tryacquiresharednanos">4.2.4 tryAcquireSharedNanos</h4>
<pre><code class="language-java">/**
 * 尝试以共享模式进行 acquire, 如果线程中断则终止操作, 如果超过给定的超时时间
 * 则返回 false。通过首先检查线程中断状态，然后至少调用一次 tryAcquireShared 方法，
 * 成功则返回 true。否则，线程排队，在调用 tryAcquireShared 直到成功、或线程被中断、
 * 或到达超时时间，可能重复多次阻塞和解除阻塞。
 *
 * 参数：arg - release 参数。此值始终是传递给 release 方法的值，或者是进入条件等待时的
 *            当前状态值。该值是未解释的，可以表示任何你想要的内容。
 *      nanosTimeout - 等待的最大纳秒数
 * 返回：如果成功 acquire，则返回 true；如果超时则返回 false
 * @throws InterruptedException 如果线程被中断
 */
public final boolean tryAcquireSharedNanos(int arg, long nanosTimeout)
        throws InterruptedException {
    if (Thread.interrupted())
        throw new InterruptedException();
    // 首次尝试，如果 tryAcquireShared &gt;= 0 说明加锁成功，可以直接返回
    return tryAcquireShared(arg) &gt;= 0 ||
            // 需要入队操作
            doAcquireSharedNanos(arg, nanosTimeout);
}

/**
 * 以共享且支持超时模式进行 acquire。
 *
 * 参数：arg - acquire 参数
 *      nanosTimeout - 最大等待时间
 * 返回：如果 acquire 成功，返回 true
 */
private boolean doAcquireSharedNanos(int arg, long nanosTimeout)
        throws InterruptedException {
    // 小于零不需要阻塞了，直接返回
    if (nanosTimeout &lt;= 0L)
        return false;
    // 计算当前线程的超时线
    final long deadline = System.nanoTime() + nanosTimeout;
    // 新增共享节点并入队
    final Node node = addWaiter(Node.SHARED);
    boolean failed = true;
    try {
        // 自旋并休眠，这段代码和 doAcquireShared 一致
        for (;;) {
            final Node p = node.predecessor();
            if (p == head) {
                int r = tryAcquireShared(arg);
                if (r &gt;= 0) {
                    setHeadAndPropagate(node, r);
                    p.next = null; // help GC
                    failed = false;
                    return true;
                }
            }
            // 自旋过程中，每次都重新计算新的超时时间
            nanosTimeout = deadline - System.nanoTime();
            // 超时则直接跳出，返回 false
            if (nanosTimeout &lt;= 0L)
                return false;
             // 当前节点在 acquire 失败后如果需要阻塞，且
            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;
                    // 当前超时时间大于 1000 纳秒，小于等于 1000 纳秒将会进入下一轮自旋获取锁
                    nanosTimeout &gt; spinForTimeoutThreshold)
                // 以自旋过程中计算的 nanosTimeout 阻塞
                LockSupport.parkNanos(this, nanosTimeout);
            // 线程中断直接退出
            if (Thread.interrupted())
                throw new InterruptedException();
        }
    } finally {
        if (failed)
            // 加锁失败，退出节点
            cancelAcquire(node);
    }
}
</code></pre>
<h4 id="425-共享模式的实现">4.2.5 共享模式的实现</h4>
<ul>
<li><code>ReentrantReadWriteLock</code> 中的 <code>ReadLock</code>;</li>
<li>信号量 <code>Semaphore</code>;</li>
<li>闭锁 <code>CountDownLatch</code>。</li>
</ul>
<h2 id="五-条件队列之-conditionobject">五、条件队列之 ConditionObject</h2>
<p>在 <code>AQS</code> 内部也存在这 <code>Condition</code> 接口的实现类，即 <code>ConditionObject</code>，它是 <code>AQS</code>的共有内部类，并且它是 <code>Lock</code><br>
实现的基础。<code>ConditionObject</code> 提供的条件队列的入队的方法如下。</p>
<h3 id="51-条件队列的入队和出队">5.1 条件队列的入队和出队</h3>
<pre><code class="language-java">public class ConditionObject implements Condition, java.io.Serializable {
    private static final long serialVersionUID = 1173984872572414699L;
    /**
     * 条件队列的第一个节点
     */
    private transient Node firstWaiter;
    /**
     * 条件队列的最后一个节点
     */
    private transient Node lastWaiter;

    /**
     * Creates a new {@code ConditionObject} instance.
     */
    public ConditionObject() {
    }

    /**
     * 为等待队列添加一个新的等待节点
     *
     * @return 新的等待节点
     */
    private Node addConditionWaiter() {
        // 本地变量保存 lastWaiter
        Node t = lastWaiter;
        // 如果 lastWaiter 不为条件等待状态，则说明 lastWaiter 是取消状态，清理
        if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) {
            // 解除所有取消的等待节点的连接
            unlinkCancelledWaiters();
            t = lastWaiter;
        }
        // 创建当前线程的新节点，类型为 CONDITION
        Node node = new Node(Thread.currentThread(), Node.CONDITION);
        // 在首次创建 Condition 时，lastWaiter 为 null，则把当前节点设置为 firstWaiter 
        if (t == null)
            firstWaiter = node;
        else
            // lastWaiter 不为空，则连接新节点
            t.nextWaiter = node;
        // 当前新增节点为 lastWaiter
        lastWaiter = node;
        return node;
    }

    /**
     * 从条件队列中取消连接已取消的等待节点。仅在持有锁时调用。当前方法会在条件等待期间
     * 发生取消时被调用，并且在 lastWaiter 已被取消时插入新的等待节点时调用。需要这种
     * 方法来避免在没有 signal 的情况下保留垃圾。因此，即使它可能需要完全遍历，它也只有
     * 在没有被 signal 的情况下发生超时或取消时才发挥作用。它遍历所有节点，而不是在特定
     * 目标处停止以取消连接到垃圾节点的所有指针，因此不会在取消风暴期间进行多次重新遍历。
     * &lt;p&gt;
     * 简单来说，此方法就是更新队列，移除所有 CANCELLED 的节点，期间会 firstWaiter 和
     * lastWaiter 的引用
     */
    private void unlinkCancelledWaiters() {
        // 保存当前的 firstWaiter 
        Node t = firstWaiter;
        // 跟踪节点，用于最后找到 lastWaiter
        Node trail = null;
        while (t != null) {
            // 从 firstWaiter 开始往后遍历
            Node next = t.nextWaiter;
            // 当前节点不是 CONDITION，那么就是 CANCELLED
            if (t.waitStatus != Node.CONDITION) {
                // 取消当前节点的引用
                t.nextWaiter = null;
                // trail 为空，说明当前还未遇到第一个 CONDITION 状态的节点
                if (trail == null)
                    // 将 firstWaiter 暂时设置为 下个节点
                    firstWaiter = next;
                else
                    // 将 next 链接到追踪节点
                    trail.nextWaiter = next;
                // 遍历结束
                if (next == null)
                    // lastWaiter 即 trail 的最后一个节点
                    lastWaiter = trail;
            } else
                // CONDITION 节点，记录当前节点
                trail = t;
            // 更新当前节点为 next
            t = next;
        }
    }
}
</code></pre>
<p>我们在观察 <code>ConditionObject</code> 类后可以发现，所有的 <code>await</code> 方法及其变体都会调用 <code>addConditionWaiter()</code><br>
方法，将阻塞线程添加到添加队列中。我们下面演示一下条件队列入队的情况下，假设存在两个线程 <code>thread-1</code> 和 <code>thread-2</code><br>
需要阻塞入队，首先是 <code>thread-1</code> 入队：</p>
<figure data-type="image" tabindex="5"><img src="/Users/wenbo.zhang/Desktop/images/condition-queue-thread-1-enq.png" alt="thread-1-enq" loading="lazy"></figure>
<p>在 <code>thread-1</code> 入队后等待过程中，<code>thread-2</code> 入队：</p>
<figure data-type="image" tabindex="6"><img src="/Users/wenbo.zhang/Desktop/images/condition-queue-thread-2-enq.png" alt="thread-2-enq" loading="lazy"></figure>
<p>之后线程入队就如上面操作一样，只需修改 lastWaiter 和 nextWaiter 指向新节点即可。</p>
<h3 id="52-condition-之-await">5.2 Condition 之 await</h3>
<p>实现 <code>Condition</code> 接口的 <code>await</code> 方法，主要用于条件等待操作。下面是关于接口中方法的说明：</p>
<p>使当前线程等待，直到它被 signal 或中断。</p>
<p>直到以下四种情况之一发生时，与此 Condition 关联的锁会被自动释放，并且当前线程由于线程调度会被禁用并处于休眠状态：</p>
<ul>
<li>其他某个线程为此 Condition 调用了 signal() 方法，而当前线程恰好被选为要被唤醒的线程；</li>
<li>其他一些线程为此 Condition 调用了 signalAll() 方法；</li>
<li>其他一些线程中断当前线程，支持中断线程挂起；</li>
<li>发生“虚假唤醒”。</li>
</ul>
<p>在所有情况下，在此方法可以返回之前，当前线程必须重新获取获取与此 Condition 关联的锁。当前线程返回时，它保证持有这个锁。</p>
<p>如果当前线程：</p>
<ul>
<li>在进入此方法时设置其中断状态；或者，</li>
<li>等待过程中被中断，支持线程挂起的中断。</li>
</ul>
<p>然后抛出 InterruptedException 并清除当前线程的中断状态。在第一种情况下，没有规定是否在释放锁之前进行中断判断。</p>
<p>实现注意事项：</p>
<p>调用此方法时，假定当前线程持有与此 Condition 关联的锁。由实现决定是否是这种情况，如果不是，如何响应。通常，将抛出异常（例如，IllegalMonitorStateException）并且实现必须记录该事实。</p>
<p>与响应 signal 的正常方法返回相比，实现更倾向于响应中断。在这种情况下，实现必须确保将信号量重定向到另一个等待线程（如果有的话）。</p>
<p>throws InterruptedException - 如果当前线程被中断（并且支持线程挂起的中断）</p>
<pre><code class="language-java">/** 该模式意味着退出等待时重新中断 */
private static final int REINTERRUPT =  1;
/** 该模式意味着在退出等待时抛出 InterruptedException */
private static final int THROW_IE    = -1;


/**
 * 实现支持中断的条件等待。
 * 1. 如果当前线程被中断，抛出 InterruptedException。
 * 2. 保存 getState 返回的锁状态。
 * 3. 使用保存状态作为参数调用 release，如果失败抛出 IllegalMonitorStateException。
 * 4. 线程入队阻塞，直到 signal 或 线程中断
 * 5. 通过使用保存状态作为参数调用特定的 acquire 方法来重新加锁。
 * 6. 如果在步骤 4 中被阻塞过程中被其他线程中断，则抛出 IntrrputedException。
 */
public final void await() throws InterruptedException {
    // 判断线程中断，清理中断标志
    if (Thread.interrupted())
        throw new InterruptedException();
    // 新增条件等待节点并进入条件等待队列
    Node node = addConditionWaiter();
    // 释放当前 AQS 的所有资源，并返回资源的 state
    int savedState = fullyRelease(node);
    // 中断模式
    int interruptMode = 0;
    // 如果新增节点不在同步队列，对当前节点线程进行阻塞。
    // 这里是个循环判断，当前节点被唤醒后，会将节点从条件队列转换到同步队列，
    // 所以在节点被唤醒后，如果加锁成功，将会被放入同步队列跳出循环
    while (!isOnSyncQueue(node)) {
        LockSupport.park(this);
        // 线程中断，转移当前节点
        if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)
            break;
    }
    // 节点进入同步队列后，如果此时线程没有中断，则以独占方式进入同步队列阻塞
    // 这里在 acquireQueued 中进行 tryAcquire 时使用的参数为 savedState
    if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE)
        interruptMode = REINTERRUPT;
    // 当前节点的 nextWaiter 不为空，则从等待队列中移除所有 CANCELLED 节点
    if (node.nextWaiter != null) // clean up if cancelled
        unlinkCancelledWaiters();
    // 根据 interruptMode 对中断进行对应处置
    if (interruptMode != 0)
        reportInterruptAfterWait(interruptMode);
}

/**
 * 使用当前的状态值调用 release；返回保存的状态值。
 * 失败则取消节点，并抛出异常。
 * 
 * 参数：node - 当前等待的条件节点
 * 返回：之前的同步状态
 */
final int fullyRelease(Node node) {
    boolean failed = true;
    try {
        int savedState = getState();
        // 释放资源，也就是解锁
        if (release(savedState)) {
            failed = false;
            return savedState;
        } else {
            throw new IllegalMonitorStateException();
        }
    } finally {
        if (failed)
            // 失败则取消节点
            node.waitStatus = Node.CANCELLED;
    }
}

/**
 * 如果一个节点（从最初就是放在条件队列中的节点）现在正在同步队列中等待 acquire 操作，
 * 则返回 true。
 * 
 * 参数：node - 节点
 * 返回：如果在同步队列中 acquire，返回 true
 */
final boolean isOnSyncQueue(Node node) {
    // 在同步队列，则说明当前节点肯定不是条件等待节点
    // 如果不是条件等待节点，但是节点的 prev 为空，说明节点可能在同步队列已出队
    if (node.waitStatus == Node.CONDITION || node.prev == null)
        return false;
    // 节点不是等待节点，且存在后继节点，说明一定在同步队列上
    if (node.next != null) // If has successor, it must be on queue
        return true;
    /*
     * node.prev 可以是非空的，但尚未在队列中，因为将其放入队列的 CAS 可能会失败。
     * 所以我们必须从队列 tail 遍历，以确保它确实成功了。在调用这个方法时，它总是在
     * tail 附近，除非 CAS 失败（这不太可能），所以我们几乎不会有太多的遍历。
     */
    // 从同步队列往前遍历查找节点
    return findNodeFromTail(node);
}

/**
 * 如果节点通过从 tail 向前搜索，出现在了同步队列上，则返回 true。
 * 仅在 isOnSyncQueue 需要调用。
 * 
 * 返回：如果存在，返回 true
 */
private boolean findNodeFromTail(Node node) {
    Node t = tail;
    for (;;) {
        if (t == node)
            return true;
        if (t == null)
            return false;
        t = t.prev;
    }
}

/**
 * 检查线程中断，如果在 signal 之前中断，则返回 THROW_IE，
 * 如果在 signal 之后中断，返回 REINTERRUPT，如果没有中断，
 * 返回 0。
 */
private int checkInterruptWhileWaiting(Node node) {
    return Thread.interrupted() ?
            // 如果是当前入队成功了，当前线程抛出异常
            (transferAfterCancelledWait(node) ? THROW_IE : REINTERRUPT) :
            // 线程未中断
            0;
}

/**
 * 如果有必要，在取消等待后将节点转移到同步队列。如果是在 signal 之前被
 * 取消等待，则返回 true。
 *
 * 参数：node - 节点。
 * 返回：如果在 signal 之前取消等待，返回 true。
 */
final boolean transferAfterCancelledWait(Node node) {
    // CAS 尝试将当前节点状态修改为 0
    if (compareAndSetWaitStatus(node, Node.CONDITION, 0)) {
        // 修改成功，转移到同步队列
        enq(node);
        return true;
    }
    /*
     * 如果我们由于竞争 CAS 修改失败，那在它完成 enq() 入队之前，我们不能继续。
     * 在传输未完成之前取消，这个很少见也很短暂，所以我们只需要自旋。
     */
    // 等待其他线程将节点加入同步队列
    while (!isOnSyncQueue(node))
        // 让出 CPU
        Thread.yield();
    return false;
}

/**
 * 根据 interruptMode 选择抛出 InterruptedException、重新中断、或不执行任何操作。
 */
private void reportInterruptAfterWait(int interruptMode)
        throws InterruptedException {
    // 抛出异常
    if (interruptMode == THROW_IE)
        throw new InterruptedException();
    else if (interruptMode == REINTERRUPT)
        selfInterrupt();
}
</code></pre>
<p>可以看到，当一个节点加入条件队列时，如果当前节点是同步队列的节点，首先会释放 <code>AQS</code> 同步队列的资源（此时线程是独占模式，因此不存在竞争），只有持有锁的线程可以进行 <code>fullyRelease</code>，此时这个节点就从同步队列转移到了条件队列（其实本质是将节点从同步队列移除，然后在条件队列新增一个节点）。之后，该节点就会在条件队列上阻塞，直到有其他线程调用 <code>signal</code> 或 <code>signal</code> 唤醒当前线程，当前线程就会从条件队列转移到同步队列中，当 <code>await</code> 方法被唤醒，并且当前节点成功转移到同步队列中，之后的操作就属于 <code>AQS</code> 中的同步队列阻塞及唤醒操作。</p>
<h3 id="53-condtion-之-signalsignalall">5.3 Condtion 之 signal/signalAll</h3>
<p><code>Condition</code> 接口的 <code>signal</code> 方法，主要用来唤醒阻塞的条件队列中的线程，其方法说明如下：</p>
<p>唤醒一个等待线程。</p>
<p>如果有任何线程在此 Condition 下等待，则选择一个用于唤醒。然后，该线程必须在从await 返回之前重新获取锁。</p>
<p>实现注意事项：</p>
<p>在调用此方法时，实现可能（并且通常确实）要求当前线程持有与此 Condition 关联的锁。实现必须记录此前提条件以及未持有锁时采取的任何操作。通常，会抛出 IllegalMonitorStateException。</p>
<pre><code class="language-java">/*
 * 将等待时间最长的线程（如果存在）从该条件队列转换到拥有锁的等待队列。
 *
 * @throws IllegalMonitorStateException 如果 isHeldExclusively 返回 false
 */
public final void signal() {
  // 当前同步器持有的线程是否是当前线程
  if (!isHeldExclusively())
    throw new IllegalMonitorStateException();
  // 等待时间最长的就是第一个入队的 fistWaiter
  Node first = firstWaiter;
  if (first != null)
    // 唤醒节点
    doSignal(first);
}

/**
 * 删除并转换节点，直到命中未取消的节点或 null。从 signal 中分离出来部分是为了
 * 编译器内联没有等待节点的情况。
 *
 * 参数：first - (非空) 条件队列中的第一个节点
 */
// 该方法目的就是唤醒成功一个节点，或条件队列为空时，执行结束
private void doSignal(Node first) {
  do {
    // 第一个节点的 nextWaiter 为空，说明目前只有一个等待节点
    if ((firstWaiter = first.nextWaiter) == null)
      lastWaiter = null;
    // 将当前处理节点从条件队列移除
    first.nextWaiter = null;
    // 转换当前节点
  } while (!transferForSignal(first) &amp;&amp;
          // 转换失败，此时的 firstWaiter 是 first 的 nextWaiter 节点
          (first = firstWaiter) != null);
}
</code></pre>
<p>下面是 <code>signalAll</code> 方法，与 <code>signal</code> 不同的是，<code>signalAll</code> 方法会唤醒所有等待节点：</p>
<pre><code class="language-java">/**
 * 将所有线程从该条件等待队列转换到拥有锁的等待队列。
 *
 * @throws IllegalMonitorStateException 如果 isHeldExclusively 返回 false
 */
public final void signalAll() {
  // // 当前同步器持有的线程是否是当前线程
    if (!isHeldExclusively())
      throw new IllegalMonitorStateException();
    Node first = firstWaiter;
    if (first != null)
        // 唤醒所有节点
        doSignalAll(first);
}

/**
 * 移除并转换所有节点
 * @param first (非空) 条件队列中的第一个节点
 */
private void doSignalAll(Node first) {
    // 全部转换，则将 lastWaiter 和 firstWaiter 置空
    lastWaiter = firstWaiter = null;
    do {
        // 获取下一个等待节点
        Node next = first.nextWaiter;
        // 下一个等待节点移除
        first.nextWaiter = null;
        // 处理当前节点
        transferForSignal(first);
        // 更新下个节点为处理节点
        first = next;
    } while (first != null);
}
</code></pre>
<p>可以看到，<code>signal</code> 和 <code>signalAll</code> 方法会将节点转换到同步队列，并将节点的状态修改为 <code>SINGAL</code>，之后解除节点线程阻塞状态。唯一不同的地方是，<code>signal</code> 方法只唤醒单个节点，而 <code>signalAll</code> 方法会唤醒全部节点。</p>
<h3 id="54-await-方法的几种变体">5.4 await 方法的几种变体</h3>
<p>下面我们简单看一下 <code>await</code> 方法的几种变体。</p>
<h4 id="541-awaituninterruptibly">5.4.1 awaitUninterruptibly</h4>
<p>使当前线程等待，直到它被 <code>signal</code>。</p>
<p>直到以下三种情况之一发生时，与此 <code>Condition</code> 关联的锁会被自动释放，并且当前线程由于线程调度会被禁用并处于休眠状态：</p>
<ul>
<li>其他某个线程为此 <code>Condition</code> 调用了 <code>signal()</code> 方法，而当前线程恰好被选为要被唤醒的线程；</li>
<li>其他一些线程为此 <code>Condition</code> 调用了 <code>signalAll()</code> 方法；</li>
<li>发生“虚假唤醒”。</li>
</ul>
<p>在所有情况下，在此方法可以返回之前，当前线程必须重新获取获取与此 <code>Condition</code> 关联的锁。当前线程返回时，它保证持有这个锁。</p>
<p>如果当现场进入该方法时设置了中断状态，或者在等待过程中被中断，则继续等待直到被 <code>signal</code> 唤醒。当它最终从这个方法返回时，它的中断状态会依旧存在。</p>
<p>实现注意事项：</p>
<p>调用此方法时，假定当前线程持有与此 <code>Condition</code> 关联的锁。由实现决定是否是这种情况，如果不是，如何响应。通常，将抛出异常（例如，IllegalMonitorStateException）并且实现必须记录该事实。</p>
<pre><code class="language-java">/**
 * 实现非中断的条件等待。
 *
 * 1. 保存 getStatus() 返回的锁定状态。
 * 2. 使用保存的状态作为参数调用 release()，如果失败抛出 IllegalMonitorStateException。
 * 3. 阻塞直到 signal。
 * 4. 将保存的状态作为参数调用特定版本的 acquire() 来重新获取锁。
 */
public final void awaitUninterruptibly() {
    // 添加新的等待节点
    Node node = addConditionWaiter();
    // release 当前 AQS 的所有资源，并返回资源的 state
    int savedState = fullyRelease(node);
    // 是否中断
    boolean interrupted = false;
    // 判断当前节点是否是同步队列节点，理论上新增的应当是不在同步队列，当被唤醒时，如果加锁成功则会在同步队列
    while (!isOnSyncQueue(node)) {
        // 阻塞当前节点
        LockSupport.park(this);
        // 判断当前线程是否中断
        if (Thread.interrupted())
            interrupted = true;
    }
    // 如果当前线程被中断，或在加锁过程中中断，则对当前线程进行中断操作
    if (acquireQueued(node, savedState) || interrupted)
        selfInterrupt();
}
</code></pre>
<h4 id="542-awaitnanos">5.4.2 awaitNanos</h4>
<p>使当前线程等待，直到它被 signal 或 中断，或者达到指定的等待时间。</p>
<p>直到以下五种情况之一发生时，与此 Condition 关联的锁会被自动释放，并且当前线程由于线程调度会被禁用并处于休眠状态：</p>
<ul>
<li>其他某个线程为此 Condition 调用了 signal() 方法，而当前线程恰好被选为要被唤醒的线程；</li>
<li>其他一些线程为此 Condition 调用了 signalAll() 方法；</li>
<li>其他一些线程中断当前线程，支持中断线程挂起；</li>
<li>到达指定的等待时间；</li>
<li>发生“虚假唤醒”。</li>
</ul>
<p>在所有情况下，在此方法可以返回之前，当前线程必须重新获取获取与此 Condition 关联的锁。当前线程返回时，它保证持有这个锁。</p>
<p>如果当前线程：</p>
<ul>
<li>在进入此方法时设置其中断状态；或者，</li>
<li>等待过程中被中断，支持线程挂起的中断。</li>
</ul>
<p>然后抛出 InterruptedException 并清除当前线程的中断状态。在第一种情况下，没有规定是否在释放锁之前进行中断判断。</p>
<p>在返回时提供给定的 nanosTimeout 值，该方法返回对剩余等待纳秒数的预估，如果超时，则返回小于或等于零的值。在等待返回但是等待的条件仍不成立的情况下，此值可用于确定是否重新等待以及重新等待多长时间。此方法的典型用途如以下形式：</p>
<pre><code class="language-java">boolean aMethod(long timeout, TimeUnit unit) {
    long nanos = unit.toNanos(timeout);
    lock.lock();
    try {
        while (!conditionBeingWaitedFor()) {
            if (nanos &lt;= 0L)
                return false;
            nanos = theCondition.awaitNanos(nanos);
        }
        // ...
    } finally {
        lock.unlock();
    }
}
</code></pre>
<p>设计说明：此方法需要纳秒参数，以避免报告剩余时间时出现截断错误。这种精度损失将使程序员难以确保总等待时间不会系统地短于重新等待发生时指定的时间。</p>
<p>实现注意事项：</p>
<p>调用此方法时，假定当前线程持有与此 Condition 关联的锁。由实现决定是否是这种情况，如果不是，如何响应。通常，将抛出异常（例如，IllegalMonitorStateException）并且实现必须记录该事实。</p>
<p>与响应 signal 的正常方法返回相比，实现更倾向于响应中断。在这种情况下，实现必须确保将信号量重定向到另一个等待线程（如果有的话）。</p>
<pre><code class="language-java">/**
 * 实现超时条件等待。
 * 1. 如果当前线程被中断，抛出 InterruptedException。
 * 2. 保存 getState 返回的锁状态。
 * 3. 使用保存状态作为参数调用 release，如果失败抛出 IllegalMonitorStateException。
 * 4. 线程入队阻塞，直到 signal、线程中断或超时。
 * 5. 通过使用保存状态作为参数调用特定的 acquire 方法来重新加锁。
 * 6. 如果在步骤 4 中被阻塞过程中被其他线程中断，则抛出 IntrrputedException。
 */
public final long awaitNanos(long nanosTimeout)
        throws InterruptedException {
    if (Thread.interrupted())
        throw new InterruptedException();
    // 增加条件等待节点，并加入条件等待队列
    Node node = addConditionWaiter();
    // 是否 AQS 中的全部资源
    int savedState = fullyRelease(node);
    // 计算超时的时间线
    final long deadline = System.nanoTime() + nanosTimeout;
    int interruptMode = 0;
    // 阻塞直到超时，或中断抛出异常、或同步入队成功
    while (!isOnSyncQueue(node)) {
        // 节点超时
        if (nanosTimeout &lt;= 0L) {
            // 移除条件等待队列，放入同步队列中
            transferAfterCancelledWait(node);
            break;
        }
        // 如果当前实现剩余比较多，这里是 1000 纳秒，那么阻塞
        if (nanosTimeout &gt;= spinForTimeoutThreshold)
            LockSupport.parkNanos(this, nanosTimeout);
        // 中断则跳出循环
        if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)
            break;
        // 重新计算剩余时间
        nanosTimeout = deadline - System.nanoTime();
    }
    // 节点在超时、中断、或 signal 出队后，会加入同步队列，这里在同步队列操作
    if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE)
        interruptMode = REINTERRUPT;
    // 下个节点不为空，则断开取消的节点
    if (node.nextWaiter != null)
        unlinkCancelledWaiters();
    // 根据中断模式进行中断处理
    if (interruptMode != 0)
        reportInterruptAfterWait(interruptMode);
    // 返回剩余时间
    return deadline - System.nanoTime();
}
</code></pre>
<h4 id="543-awaituntil">5.4.3 awaitUntil</h4>
<p>使当前线程等待，直到它被 signal 或 中断，或者达到指定的等待时间。</p>
<p>直到以下五种情况之一发生时，与此 Condition 关联的锁会被自动释放，并且当前线程由于线程调度会被禁用并处于休眠状态：</p>
<ul>
<li>其他某个线程为此 Condition 调用了 signal() 方法，而当前线程恰好被选为要被唤醒的线程；</li>
<li>其他一些线程为此 Condition 调用了 signalAll() 方法；</li>
<li>其他一些线程中断当前线程，支持中断线程挂起；</li>
<li>到达指定的等待时间；</li>
<li>发生“虚假唤醒”。</li>
</ul>
<p>在所有情况下，在此方法可以返回之前，当前线程必须重新获取获取与此 Condition 关联的锁。当前线程返回时，它保证持有这个锁。</p>
<p>如果当前线程：</p>
<ul>
<li>在进入此方法时设置其中断状态；或者，</li>
<li>等待过程中被中断，支持线程挂起的中断。</li>
</ul>
<p>然后抛出 InterruptedException 并清除当前线程的中断状态。在第一种情况下，没有规定是否在释放锁之前进行中断判断。</p>
<p>返回值表示是否已经过了 deadline，可以如下使用：</p>
<p>实现注意事项：</p>
<p>调用此方法时，假定当前线程持有与此 Condition 关联的锁。由实现决定是否是这种情况，如果不是，如何响应。通常，将抛出异常（例如，IllegalMonitorStateException）并且实现必须记录该事实。</p>
<p>与响应 signal 的正常方法返回相比，实现更倾向于响应中断。在这种情况下，实现必须确保将信号量重定向到另一个等待线程（如果有的话）。</p>
<pre><code class="language-java">boolean aMethod(Date deadline) {
    boolean stillWaiting = true;
    lock.lock();
    try {
        while(!conditionBeingWaitedFor()) {
            if (!stillWaiting)
                return false;
            stillWaiting = theCondition.awaitUntil(deadline);
        }
        // ...
    } finally {
        lock.unlock();
    }
}
</code></pre>
<p>参数： deadline - 等待的绝对时间。</p>
<p>返回： 如果返回时已经超过最后期限，则为 false，否则为 true。</p>
<p>@throws InterruptedException - 如果当前线程被中断（并且支持线程挂起的中断）</p>
<pre><code class="language-java">/**
 * 实现绝对超时时间的条件等待。
 * 1. 如果当前线程被中断，抛出 InterruptedException。
 * 2. 保存 getState 返回的锁状态。
 * 3. 使用保存状态作为参数调用 release，如果失败抛出 IllegalMonitorStateException。
 * 4. 线程入队阻塞，直到 signal、线程中断或超时。
 * 5. 通过使用保存状态作为参数调用特定的 acquire 方法来重新加锁。
 * 6. 如果在步骤 4 中被阻塞过程中被其他线程中断，则抛出 IntrrputedException。
 * 7. 如果在步骤 4 中被阻塞过程中超时，则返回 false，否则返回 true。
 */
public final boolean awaitUntil(Date deadline)
        throws InterruptedException {
    // 获取绝对时间的时间戳
    long abstime = deadline.getTime();
    if (Thread.interrupted())
        throw new InterruptedException();
    // 当前线程加入添加条件队列
    Node node = addConditionWaiter();
    // 释放 AQS 的全部资源
    int savedState = fullyRelease(node);
    boolean timedout = false;
    int interruptMode = 0;
    // 阻塞直到超时，或中断抛出异常、或同步入队成功
    while (!isOnSyncQueue(node)) {
        // 判断当前循环是否超时
        if (System.currentTimeMillis() &gt; abstime) {
            // 取消条件等待，跳出循环
            timedout = transferAfterCancelledWait(node);
            break;
        }
        // 阻塞
        LockSupport.parkUntil(this, abstime);
        // 中断则跳出循环
        if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)
            break;
    }
    // 节点在超时、中断、或 signal 出队后，会加入同步队列，这里在同步队列操作
    if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE)
        interruptMode = REINTERRUPT;
    if (node.nextWaiter != null)
        unlinkCancelledWaiters();
    if (interruptMode != 0)
        reportInterruptAfterWait(interruptMode);
    return !timedout;
}
</code></pre>
<h4 id="544-awaitlong-time-timeunit-unit">5.4.4 await(long time, TimeUnit unit)</h4>
<p>使当前线程等待，直到它被 signal 或 中断，或者达到指定的等待时间。此方法在行为上等效于：<code>awaitNanos(unit.toNanos(time)) &gt; 0 </code>。</p>
<pre><code class="language-java">/**
 * 实现超时条件等待。
 * 1. 如果当前线程被中断，抛出 InterruptedException。
 * 2. 保存 getState 返回的锁状态。
 * 3. 使用保存状态作为参数调用 release，如果失败抛出 IllegalMonitorStateException。
 * 4. 线程入队阻塞，直到 signal、线程中断或超时。
 * 5. 通过使用保存状态作为参数调用特定的 acquire 方法来重新加锁。
 * 6. 如果在步骤 4 中被阻塞过程中被其他线程中断，则抛出 IntrrputedException。
 * 7. 如果在步骤 4 中被阻塞过程中超时，则返回 false，否则返回 true。
 */
public final boolean await(long time, TimeUnit unit)
        throws InterruptedException {
    // 转为纳秒书剑
    long nanosTimeout = unit.toNanos(time);
    // 判断线程中断，并清空状态，中断则抛出异常
    if (Thread.interrupted())
        throw new InterruptedException();
    // 当前线程加入添加条件队列
    Node node = addConditionWaiter();
    // 释放所有 AQS 资源
    int savedState = fullyRelease(node);
    // 计算超时时间先
    final long deadline = System.nanoTime() + nanosTimeout;
    boolean timedout = false;
    int interruptMode = 0;
    while (!isOnSyncQueue(node)) {
        if (nanosTimeout &lt;= 0L) {
            timedout = transferAfterCancelledWait(node);
            break;
        }
        if (nanosTimeout &gt;= spinForTimeoutThreshold)
            LockSupport.parkNanos(this, nanosTimeout);
        if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)
            break;
        nanosTimeout = deadline - System.nanoTime();
    }
    if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE)
        interruptMode = REINTERRUPT;
    if (node.nextWaiter != null)
        unlinkCancelledWaiters();
    if (interruptMode != 0)
        reportInterruptAfterWait(interruptMode);
    return !timedout;
}
</code></pre>
<h2 id="七-aqs-中的-cancelacquire">七、AQS 中的 cancelAcquire</h2>
<p>当节点在下列几种状态时，会触发 <code>AQS</code> 进行 <code>cancelAcquire</code> 操作，具体如下：</p>
<ul>
<li>节点在队列自旋 <code>acquire</code>  过程中触发异常，如 <code>acquireQueue</code>、<code>doAcquireShared</code> 等方法；</li>
<li>节点在队列自旋 <code>acquire</code> 过程中触发线程中断，如 <code>doAcquireInterruptibly</code>、<code>doAcquireNanos</code> 、<code>doAcquireSharedInterruptibly</code>、<code>doAcquireSharedNanos</code> 等方法</li>
<li>节点在带有超时参数的 <code>acquire</code> 变体方法调用中，到达超时时间，且未成功 <code>acquire</code>，如 <code>doAcquireNanos</code> 、<code>doAcquireSharedNanos</code> 等方法。</li>
</ul>
<p>总的来说，当线程在 acquire 过程中触发各种异常，或带超时的接口调用触发超时时，就会在 <code>finally</code> 中调用 <code>cancelAcquire</code> 方法，用于取消该节点，将该节点从队列中移除。</p>
<pre><code class="language-java">/**
* 取消正在进行尝试的 acquire。
*
* 参数：node - 节点
*/
private void cancelAcquire(Node node) {
    // 当前节点不存在，直接忽略
    if (node == null)
        return;
	// 将当前节点持有的线程置空，释放资源
    node.thread = null;

    // 跳过取消的前驱节点，将当前节点的前驱节点和 pred 指向一个未被 CANCELLED 的节点
    Node pred = node.prev;
    // 从当前节点到找到节点之前，都为 CANCELLED 节点，全部需要断开
    // 此后，当前节点的前驱节点为非 CANCELLED 节点
    while (pred.waitStatus &gt; 0)
        node.prev = pred = pred.prev;

    // 很明显 predNext 是要断开链接的节点。如果不是，下面 CAS 将失败，
    // 在这种情况下，我们可能在竞争中输给了另一个 cancel 或 signal，
    // 我们不需要采取其他行动。
    Node predNext = pred.next;

    // 可以在这里使用无条件写入，而不是 CAS 操作。
    // 在这个原子步骤之后，其他节点可以跳过我们。
    // 在此之前，我们不受其他线程影响。
    // 将当前节点状态设置为 CANCELLED
    node.waitStatus = Node.CANCELLED;

    // 如果当前节点为 tail，直接移除当前节点，将 tail 置为 pred（当前节点的前驱节点，非CANCELLED）
    if (node == tail &amp;&amp; compareAndSetTail(node, pred)) {
        compareAndSetNext(pred, predNext, null);
    } else {
        // 当前节点的前驱节点非 head，需要将当前节点从同步队列中移除
        int ws;
        if (pred != head &amp;&amp;
                // 前驱节点状态为 SIGNAL
                ((ws = pred.waitStatus) == Node.SIGNAL ||
                        // 前驱节点状态为 0，将其置为 SIGNAL
                        (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp;
                pred.thread != null) {
            Node next = node.next;
            // 将当前节点从队列移除，即将 pred 节点（当前节点的前驱节点）的 next 指向当前节点的后继节点
            if (next != null &amp;&amp; next.waitStatus &lt;= 0)
                compareAndSetNext(pred, predNext, next);
        } else {
            // 当前节点的前驱节点为 head，则说明从 head 到 当前节点之间全部为 CANCELLED 节点，
            // 直接唤醒当前节点的后继节点
            unparkSuccessor(node);
        }

        // 断开当前节点引用
        node.next = node; // help GC
    }
}
</code></pre>
<h2 id="八-aqs-的锁实现">八、AQS 的锁实现</h2>
<p><code>AQS</code> 作为同步器框架，其提供的基础的功能给并发组件，下面我们将根据 <code>j.u.c</code> 包内置的同步组件，来了解 <code>AQS</code> 的使用。</p>
<h3 id="81-reentrantlock">8.1 ReentrantLock</h3>
<p>一种可重入的互斥 <code>Lock</code>，其基本行为和语义与使用 <code>synchronized</code> 方法和语句访问的隐式监视器锁相同，但具有扩展功能。</p>
<p><code>ReentrantLock</code> 被上次成功锁定但尚未解锁的线程 <em>持有</em>。当锁不被另一个线程持有时，调用 <code>lock</code> 的线程将返回，并成功获取锁。如果当前线程已经持有锁，该方法将立即返回。这可以使用方<code>isHeldByCurrentThread</code> 和 <code>getHoldCount</code> 方法来检查。</p>
<p>此类的构造函数接受一个可选的 <em>fair</em> 番薯。当设置为 <code>true</code> 时，在竞争情况下，锁会优先授予给等待时间最长的线程的访问。否则，锁将无法保证获得顺序。如果在多线程情况下使用公平锁，可能会比非公平锁的吞吐量低（即，会更慢；通常情况下会慢得多），但在获得锁和确保不会出现线程饥饿的情况会有更好的效果。但是请注意，锁的公平性并不能保证线程调度的公平性。因此，使用公平锁的多线程中，可能会有单个线程连续多次获得它，而其他活动线程无法获得锁，因此也无法执行。另请注意，没有超时参数的 <code>tryLock()</code> 方法不遵守公平设置。如果锁可用，即使其他线程正在等待，他也会成功。</p>
<p>推荐的做法是在 <code>lock</code> 加锁之后立即调用<code>try</code> 块，最常见的用法如下：</p>
<pre><code class="language-java">class X {
    private final ReentrantLock lock = new ReentrantLock();
    // ...
    
    public void m() {
        lock.lock(); // block until condition holds
        try {
            // ... method body
        } finally {
            lock.unlock();
        }
    }
}
</code></pre>
<p>除了实现 <code>Lock</code> 接口之外，该类还定义了许多 <code>public</code> 和 <code>protected</code> 的方法来检查锁的状态。其中一些方法仅对 instrumentation 和 monitoring 有用。</p>
<p>此类的序列化与内置锁的行为方式相同：反序列化锁处于未锁定状态，无论其在序列化时的状态如何。</p>
<p>此锁最多支持同一线程的 2147483647 个递归锁。尝试超过此限制会导致锁定方法抛出 <code>Error</code> 。</p>
<h4 id="811-sync">8.1.1 Sync</h4>
<p><code>ReentratLock</code> 的抽象类 <code>Sync</code> 作为 <code>AQS</code>框架实现类，用于同步控制的基础。可用于实现公平锁和非公平锁。主要通过使用 <code>AQS</code> 的状态来表示持有锁的次数，当 <code>AQS</code> 状态为 <code>0</code>，说明当前可能没有其他线程持有锁，<code>ReentrantLock</code>的每次获取锁都会讲 <code>AQS</code> 状态加一。下面是 <code>Sync</code> 的源码：</p>
<pre><code class="language-java">/**
 * 此锁的同步控制的基础。下面分为公平和非公平版本。使用 AQS 状态来表示
 * 持有锁的次数。
 */
abstract static class Sync extends AbstractQueuedSynchronizer {
    private static final long serialVersionUID = -5179523762034025860L;

    /**
     * 执行 Lock.lock。抽象方法的原因主要是非公平版本提供快速路径。
     */
    abstract void lock();

    /**
     * 执行非公平的 tryLock。tryAcquire 在子类中实现，但两者都需要对
     * tryLock 方法进行非公平尝试。
     */
    final boolean nonfairTryAcquire(int acquires) {
        // 获取当前执行线程
        final Thread current = Thread.currentThread();
        // 获取 AQS 当前状态
        int c = getState();
        // 当前状态为 0，说明锁可能没有被其他线程获取
        if (c == 0) {
            // cas 尝试加锁，将 AQS 状态修改为 acquires，成功后直接返回
            if (compareAndSetState(0, acquires)) {
                // 设置当前线程为独占
                setExclusiveOwnerThread(current);
                return true;
            }
        }
        // 如果当前线程已经持有了锁，即当前线程就是独占锁的线程
        else if (current == getExclusiveOwnerThread()) {
            // 将状态直接加上 acquires
            int nextc = c + acquires;
            // 状态溢出
            if (nextc &lt; 0) // overflow
                throw new Error(&quot;Maximum lock count exceeded&quot;);
            // 当前线程就是持有锁的线程，所以直接设置 AQS 状态
            setState(nextc);
            return true;
        }
        // 既不是独占线程，状态也不为 0，说明当前锁被其他线程持有
        return false;
    }

    /**
     * 释放资源操作
     */
    protected final boolean tryRelease(int releases) {
        // 计算释放后的状态值
        int c = getState() - releases;
        // 当前线程不是锁的持有者，抛出异常
        if (Thread.currentThread() != getExclusiveOwnerThread())
            throw new IllegalMonitorStateException();
        // 是否完全释放
        boolean free = false;
        // 释放后状态值为 0，说明当前线程已经完全释放资源
        // 如果不为 0，说明当前线程是重入操作的释放，还需要等执行完再次释放
        if (c == 0) {
            // 设置释放 flag
            free = true;
            // 取消当前线程的独占
            setExclusiveOwnerThread(null);
        }
        // 设置 AQS 状态值
        setState(c);
        return free;
    }

    /**
     * 当前线程是否是该独占锁的持有者
     */
    protected final boolean isHeldExclusively() {
        // 虽然我们通常必须在拥有锁之前读取状态值，但是我们不需要
        // 检查这样检查当前线程是否是持有者
        return getExclusiveOwnerThread() == Thread.currentThread();
    }

    /**
     * Condition 实例，用于和 Lock 一起使用
     */
    final ConditionObject newCondition() {
        return new ConditionObject();
    }

// 从外部类中集成的方法

    // 获取当前锁的独占线程
    final Thread getOwner() {
        return getState() == 0 ? null : getExclusiveOwnerThread();
    }

    // 获取当前 AQS 的状态值
    final int getHoldCount() {
        return isHeldExclusively() ? getState() : 0;
    }

    // 是否被锁定
    final boolean isLocked() {
        return getState() != 0;
    }

    /**
     * 从流中重构实例（即反序列化）。
     * 返回的实例为非锁定状态
     */
    private void readObject(java.io.ObjectInputStream s)
            throws java.io.IOException, ClassNotFoundException {
        s.defaultReadObject();
        setState(0); // reset to unlocked state
    }
}
</code></pre>
<h4 id="812-公平锁和非公平锁">8.1.2 公平锁和非公平锁</h4>
<p>公平锁和非公平锁在源码的实现中，差异很小，唯一的区别是公平锁会在加锁时，判断在自己之前是否有其他线程在等待，只有当自己是头结点（等待时间最长），之后才会尝试加锁。下面我们通过源码来了解一下，以下是非公平锁的实现：</p>
<pre><code class="language-java">/**
 * Sync 对象的非公平锁
 */
static final class NonfairSync extends Sync {
    private static final long serialVersionUID = 7316153563782823691L;

    /**
     * 执行锁定操作。尝试直接修改 AQS 状态加锁（快速路径），失败时恢复正常 acquire。
     */
    final void lock() {
        // CAS 尝试直接加锁，成功后将当前线程设置为独占线程
        if (compareAndSetState(0, 1))
            setExclusiveOwnerThread(Thread.currentThread());
        else
            // CAS 操作失败，正常进行 acquire 操作 
            acquire(1);
    }

    /**
     * tryAcquire 进行加锁操作，实现自 AQS，调用 Sync 进行非公平 tryAcquire
     */
    protected final boolean tryAcquire(int acquires) {
        return nonfairTryAcquire(acquires);
    }
}
</code></pre>
<p>下面是公平锁的实现：</p>
<pre><code class="language-java">/**
 * Sync 对象的公平锁
 */
static final class FairSync extends Sync {
    private static final long serialVersionUID = -3000897897090466540L;

    // 公平锁，直接 acquire，不尝试快速路径
    final void lock() {
        acquire(1);
    }

    /**
     * tryAcquire 的公平锁版本。除非递归调用，或者在没有等待节点时是第一个，否则不应该具有访问锁权限。
     */
    protected final boolean tryAcquire(int acquires) {
        // 获取当前线程
        final Thread current = Thread.currentThread();
        // 获取 AQS 状态
        int c = getState();
        // 可能没有加锁
        if (c == 0) {
            // 先判断队列中是否有在自己之前的节点
            if (!hasQueuedPredecessors() &amp;&amp;
                    // 自己就是第一个节点，CAS 尝试加锁
                    compareAndSetState(0, acquires)) {
                // 设置独占
                setExclusiveOwnerThread(current);
                return true;
            }
        }
        else if (current == getExclusiveOwnerThread()) {
            int nextc = c + acquires;
            if (nextc &lt; 0)
                throw new Error(&quot;Maximum lock count exceeded&quot;);
            setState(nextc);
            return true;
        }
        return false;
    }
}
</code></pre>
<p>可以看到，在 <code>tryAcquire</code> 时，公平锁会调用 <code>hasQueuedPredecessors()</code> 方法，先判断自己是否是头结点（头结点没有前驱节点），我们看下这个方法的源码：</p>
<pre><code class="language-java">/**
 * 查询是否有任何线程其他线程在队列中的等待时间大于当前线程。
 *
 * 调用此方法等效于（但是可能有更高效）：
 * getFirstQueuedThread() != Thread.currentThread() &amp;&amp;
 * hasQueuedThreads()
 *
 * 请注意，由于中断和超时可能随时会发生，从而导致节点取消，因此返回 true 并不代表着
 * 某些其他线程会在当前线程之获取到锁。同样，由于队列为空，在此方法返回 false 时，
 * 另一个线程可能会在竞争中先入队成功。
 *
 * 本方法目的在于供公平同步器的使用，从而避免”闯入“。如果一个同步器的 tryAcquire 
 * 方法应该返回 false，并且他的 tryAcquireShared 方法应该返回一个负值，这个方法
 * 返回 true（除非是可重入的获取）。
 *
 * protected boolean tryAcquire(int arg) {
 *   if (isHeldExclusively()) {
 *     // A reentrant acquire; increment hold count
 *     return true;
 *   } else if (hasQueuedPredecessors()) {
 *     return false;
 *   } else {
 *     // try to acquire normally
 *   }
 * }
 *
 * @return 如果当前线程之前有一个排队线程，则为true ，如果当前线程位于队列的头部或队列为空，则为false
 * @since 1.7
 */
public final boolean hasQueuedPredecessors() {
    // 之所以这么做是因为 head 在 tail 之前被初始化，
    // 先 tail 后 head，h.next 操作一定能获取到值。
    // 如果按照先 h 再 t 的方式取值，可能会发生这样的情况：
    // 此时队列为空 head 为 null，在 h 赋值完成后，其他线程
    // 入队，此时 head 和 tail 都不为空，就造成了 h 不存在，
    // 但是 t 却存在的情况。这种情况 h.next 就会抛出空指针了
    Node t = tail; // 以相反的顺序读取字段
    Node h = head;
    Node s;
    return h != t &amp;&amp;
            ((s = h.next) == null || s.thread != Thread.currentThread());
}
</code></pre>
<h4 id="813-reentrantlock-类的其他方法">8.1.3 ReentrantLock 类的其他方法</h4>
<p>除了核心的加锁和解锁方法外，<code>ReentrantLock</code> 还提供了其他的一些监控手段的方法，如下说明：</p>
<pre><code class="language-java">public class ReentrantLock implements Lock, java.io.Serializable {
    private static final long serialVersionUID = 7373984872572414699L;
    /** 提供实现所有机制的同步器 */
    private final Sync sync;

    /**
     * 创建 ReentrantLock 的实例。这相当于 ReentrantLock(false)。
     */
    public ReentrantLock() {
        sync = new NonfairSync();
    }

    /**
     * 使用给定的公平策略创建 ReentrantLock 实例。
     *
     * 参数：fair - 如果当前锁应该使用公平排序策略，则为 true
     */
    public ReentrantLock(boolean fair) {
        sync = fair ? new FairSync() : new NonfairSync();
    }

    /**
     * 获取锁。
     *
     * 如果没有被另一个线程持有，则获取锁并立即返回，将锁持有计数设置为 1。
     *
     * 如果当前线程已经持有锁，则持有次数加 1 并立即返回。
     *
     * 如果锁被另一个线程持有，那么当前线程出于线程调度的目的，将会被禁用并处于休眠状态，
     * 直到当前线程获得锁为止，此时锁持有计数设置为 1.
     */
     public void lock() {
         sync.lock();
     }

    /**
     * 除非当前线程被中断，否则一直 acquire 直到获取锁。
     *
     * 如果没有被另一个线程持有，则获取锁并立即返回，将锁持有计数设置为 1。
     *
     * 如果当前线程已经持有锁，则持有次数加 1 并立即返回。
     *
     * 如果锁被另一个线程持有，那么当前线程出于线程调度的目的，将会被禁用并处于休眠状态，
     * 直到发生以下两种情况之一：
     * - 当前线程获取锁成功；或者
     * - 其他线程中断当前线程。
     *
     * 如果当前线程获取到了锁，则锁持有计数设置为 1。
     *
     * 如果当前线程：
     * - 在进入此方法时设置其中断状态；或者
     * - 在获取锁过程中被中断，
     * 然后会抛出 InterruptedException 并清除当前线程的中断状态。
     *
     * 在此实现中，由于此方法明显表示出中断能力，因此优先响应中断而不是
     * 正常执行或可重入获取锁。
     *
     * @throws InterruptedException - 如果当前线程被中断
     */
    public void lockInterruptibly() throws InterruptedException {
        sync.acquireInterruptibly(1);
    }

    /**
     * 仅当调用时没有另一个线程持有时才获取锁。
     *
     * 如果锁没有被另一个线程持有，则获取锁，并立即返回 true，将锁持有计数设置为 1。
     * 即使此锁已设置为使用公平排队策略，调用 tryLock() 也会立即获取锁（如果可用），
     * 无论其他线程当前是否正在等待该锁。这种 “闯入” 行为在某些情况下可能很有用，
     * 即使它破坏了公平性。如果您想完全遵循公平设置，请使用几乎等效的 tryLock(9, TimeUnit.SECONDS)
     * （它也检测中断）。
     *
     * 如果当前线程已经持有了锁，那么持有计数加 1 并返回 true。
     * 
     * 如果锁被其他线程持有，则此方法立即返回 false。
     *
     * 返回：如果锁空闲并被当前线程获取成功，或锁已经被当前线程持有，则返回 true，否则返回 false。
     */
    public boolean tryLock() {
        return sync.nonfairTryAcquire(1);
    }

    /**
     * 如果在给定的等待时间内没有被其他线程持有锁，且当前线程没有被中断，则获取锁。
     *
     * 如果锁没有被另一个线程持有，则获取锁，并立即返回 true，且会将锁持有的计数设置为 1。如果
     * 此锁已设置为使用公平排序策略，则在该线程之前排队任何其他线程正在等待该锁，则不会获取到锁。
     * 这与 tryLock() 方法形成对比。如果你想要一个允许 “闯入” 公平锁的可超时 tryLock，则可以
     * 将超时和非超时方法相结合使用：
     *
     * if (lock.tryLock() ||
     *     lock.tryLock(timeout, unit)) {
     *     ...
     * }
     *
     *
     * 如果没有被另一个线程持有，则获取锁并立即返回，将锁持有计数设置为 1。
     *
     * 如果当前线程已经持有锁，则持有次数加 1 并立即返回。
     *
     * 如果锁被另一个线程持有，那么当前线程出于线程调度的目的，将会被禁用并处于休眠状态，
     * 直到发生以下三种情况之一：
     * - 当前线程获取锁成功；或者
     * - 其他线程中断当前线程；或者
     * - 达到了指定的超时等待时间。
     *
     * 如果当前线程获取到了锁，则锁持有计数设置为 1。
     *
     * 如果当前线程：
     * - 在进入此方法时设置其中断状态；或者
     * - 在获取锁过程中被中断，
     * 然后会抛出 InterruptedException 并清除当前线程的中断状态。
     *
     * 如果到达了指定的超时时间，则返回 false。如果时间小于或等于零，则该方法不会等待。
     *
     * 在此实现中，由于此方法明显表示出中断能力，因此优先响应中断而不是
     * 正常执行或可重入获取锁，同时也优先于报告超过等待时间。
     *
     *
     * 参数：timeout - 等待锁的时间
     *      unit - timeout 参数的时间单位
     * 返回：如果锁是空闲的并被当前线程获取到，或者锁已经被当前线程持有，则返回true；
     *      如果在获得锁之前达到了超时时间，则返回 false
     * @throws InterruptedException - 如果当前线程被中断
     * @throws NullPointerException - 如果时间单位为空
     */
    public boolean tryLock(long timeout, TimeUnit unit)
            throws InterruptedException {
        return sync.tryAcquireNanos(1, unit.toNanos(timeout));
    }

    /**
     * 尝试释放此锁。
     *
     * 如果当前线程是这个锁的持有者，那么持有计数就会递减。如果持有计数现在为 0，则直接释放锁。
     * 如果当前线程不是该锁的持有者，则抛出 IllegalMonitorStateException。
     *
     * @throws IllegalMonitorStateException - 如果当前线程没有持有这个锁。
     */
    public void unlock() {
        sync.release(1);
    }

    /**
     * 返回与当前 Lock 实例一起使用的 Condition 实例。
     *
     * 当与内置的监视器锁一起使用时，返回的 Condition 实例支持与 Object 监视器方法
     * （wait、notify 和 notifyAll） 相同的用法。
     *
     * - 如果在调用任何 Condition 的 await 和 signal 方法时，未持有锁，则会引发 
     *   IllegalMonitorStateException。
     * - 当 Condition 的 await 方法被调用时，锁被释放，在该线程返回前，锁会被其他线程
     *   重新获得，锁持有计数会恢复到调用方法时的状态。
     * - 如果线程在等待过程中被中断，则等待终止，并抛出 InterruptedException，并清除
     *   线程的中断状态。
     * - 以 FIFO 顺序 signal 等待线程。
     * - 从 await 方法返回的线程重新获取锁的顺序与最初获取锁的线程顺序相同，在默认情况下，
     *   非公平锁，未指定顺序；但对于公平锁，优先考虑那些等待时间长的线程。
     *
     * 返回：Condition 对象
     */
    public Condition newCondition() {
        return sync.newCondition();
    }

    /**
     * 查询当前线程持有该锁的次数。
     *
     * 如果解锁的次数和加锁的次数不匹配，那么该线程会持有该锁。
     *
     * 持有计数信息通常仅用于测试和调试目的。例如，如果某段代码不应该在已经持有锁的情况下输入，
     * 那么我们可以断言这个事实：
     * 
     * class X {
     *     ReentrantLock lock = new ReentrantLock();
     *     // ...
     *     public void m() {
     *         assert lock.getHoldCount() == 0;
     *         lock.lock();
     *         try {
     *             // ... method body
     *         } finally {
     *             lock.unlock();
     *         }
     *     }
     * }
     *
     * 返回：当前线程持有锁的次数，如果当前线程未持有锁，则为零
     */
    public int getHoldCount() {
        return sync.getHoldCount();
    }

    /**
     * 查询当前线程是否持有该锁。
     *
     * 类似于内置监视器锁的 Thread.holdsLock(Object) 方法，此方法通常用于调试和测试。
     * 例如，如果一个线程只有在持有锁时，才调用该方法，可以这样断言：
     *
     * class X{
     *     ReentrantLock lock = new ReentrantLock();
     *     // ...
     *     
     *     public void m(){
     *         assert lock.isHeldByCurrentThread();
     *         // ... method body
     *     }
     * }
     *
     * 它还可以用于确保以不可重入方式使用可重入锁，例如：
     *
     * class X{
     *     ReentrantLock lock = new ReentrantLock();
     *     // ...
     *     
     *     public void m(){
     *         assert !lock.isHeldByCurrentThread();
     *         lock.lock();
     *         try {
     *             // ... method body
     *         } finally {
     *             lock.unlock;
     *         }
     *     }
     * }
     *
     * 返回：如果当前线程持有该锁，返回 true；否则返回 false
     */
    public boolean isHeldByCurrentThread() {
        return sync.isHeldExclusively();
    }

    /**
     * 查询当前锁是否被持有。此方法设计用于监控系统状态，而不用于同步控制。
     *
     * 返回：任何线程持有此锁，返回 true；否则返回 false。
     */
    public boolean isLocked() {
        return sync.isLocked();
    }

    /**
     * 如果此锁的公平性设置为 true，则返回 true。
     *
     * 返回：如果此锁的公平性设置为 true，则返回 true。
     */
    public final boolean isFair() {
        return sync instanceof FairSync;
    }

    /**
     * 返回拥有此锁的线程，如果锁没有被持有，返回 null。如果当前线程不是锁的持有者，
     * 调用此方法会返回当前锁定状态的近似值。例如，即使有线程在尝试获取锁，但还没有
     * 获取成功，所有者也可能暂时为 null。此方法主要目的在于促进提供更广泛的锁监视
     * 设施的子类的构建。
     *
     * 返回：锁的持有者，如果没有，返回 null。
     */
    protected Thread getOwner() {
        return sync.getOwner();
    }

    /**
     * 查询是否有线程正在等待获取此锁。请注意，由于取消可能随时发生，因此返回 true，
     * 并不意味着其他线程就会获取锁。此方法主要设计用于监控系统状态。
     *
     * 返回：如果可能有其他线程等待获取锁，则为true。
     */
    public final boolean hasQueuedThreads() {
        return sync.hasQueuedThreads();
    }

    /**
     * 查询给定线程是否正在等待获取此锁。请注意，由于取消可能随时发生，因此返回 true，
     * 并不意味着该线程就会获取锁。此方法主要设计用于监控系统状态。
     *
     * 参数：thread - 线程
     * 返回：如果给定线程可能等待获取锁，则为true。
     * @throws NullPointerException thread 为 null
     */
    public final boolean hasQueuedThread(Thread thread) {
        return sync.isQueued(thread);
    }

    /**
     * 返回等待获取该锁的线程数的近似值。该值为一个预估值，因为在该方法遍历内部
     * 数据结构时，线程数可能会动态发生变化。此方法主要设计用于监控系统状态，而不
     * 是用于同步控制。
     *
     * 返回：等待此锁的预估线程数
     */
    public final int getQueueLength() {
        return sync.getQueueLength();
    }

    /**
     * 返回一个集合，其中包含正在等待获取此锁的线程。因为在构造这个结果时，实际的
     * 线程集合可能会动态变化，所以返回的集合只是预估值。返回集合的元素没有特定顺序。
     * 此方法主要目的在于促进提供更广泛的锁监视设施的子类的构建。
     *
     * 返回：线程集合。
     */
    protected Collection&lt;Thread&gt; getQueuedThreads() {
        return sync.getQueuedThreads();
    }

    /**
     * 查询是否有线程正在等待与当前锁关联的 Condition。请注意，
     * 由于超时和中断可能随时发生，因此返回 true，并不意味着将来 signal 无法唤醒等待线程。
     * 此方法主要设计用于监控系统状态。
     * 
     * 参数：condition - condition
     * 返回：如果有任何等待线程，返回 true
     * @throws IllegalMonitorStateException - 如果没有持有这个锁
     * @throws IllegalArgumentException - 如果给定条件与此锁没有关联
     * @throws NullPointerException - condition 为 null
     */
    public boolean hasWaiters(Condition condition) {
        if (condition == null)
            throw new NullPointerException();
        if (!(condition instanceof AbstractQueuedSynchronizer.ConditionObject))
            throw new IllegalArgumentException(&quot;not owner&quot;);
        // 判断当前 condition 是否存在等待节点
        return sync.hasWaiters((AbstractQueuedSynchronizer.ConditionObject)condition);
    }

    /**
     * 返回等待与当前锁关联的给定 condtion 的线程数的估计值。请注意，
     * 由于超时和中断可能随时发生，因此此值进作为实际等待节点的上限。
     * 此方法主要设计用于监控系统状态，不用来做同步控制。
     * 
     * 参数：condition - condition
     * 返回：预估的等待线程数
     * @throws IllegalMonitorStateException - 如果没有持有这个锁
     * @throws IllegalArgumentException - 如果给定条件与此锁没有关联
     * @throws NullPointerException - condition 为 null
     */
    public int getWaitQueueLength(Condition condition) {
        if (condition == null)
            throw new NullPointerException();
        if (!(condition instanceof AbstractQueuedSynchronizer.ConditionObject))
            throw new IllegalArgumentException(&quot;not owner&quot;);
        return sync.getWaitQueueLength((AbstractQueuedSynchronizer.ConditionObject)condition);
    }

    /**
     * 返回线程集合，其中包含可能正在等待与此锁相关联的指定 condition 的线程。因为在
     * 构造这个结果时，实际的线程集合可能会动态变化，所以该集合返回的只是一个近似值。
     * 返回集合的元素没有特定顺序。此方法主要目的在于促进提供更广泛的锁监视设施的子类的构建。
     *
     * 参数：condition - condition
     * 返回：线程集合
     * @throws IllegalMonitorStateException - 如果没有持有这个锁
     * @throws IllegalArgumentException - 如果给定条件与此锁没有关联
     * @throws NullPointerException - condition 为 null
     */
    protected Collection&lt;Thread&gt; getWaitingThreads(Condition condition) {
        if (condition == null)
            throw new NullPointerException();
        if (!(condition instanceof AbstractQueuedSynchronizer.ConditionObject))
            throw new IllegalArgumentException(&quot;not owner&quot;);
        return sync.getWaitingThreads((AbstractQueuedSynchronizer.ConditionObject)condition);
    }

    /**
     * 返回标识此锁的字符串及其锁状态。。括号中的状态包括字符串 &quot;Unlocked&quot; 或字符串
     * &quot;Locked by&quot; 后跟拥有锁的线程的名称。
     *
     * 返回：一个标识这个锁的字符串，以及它的锁状态
     */
    public String toString() {
        Thread o = sync.getOwner();
        return super.toString() + ((o == null) ?
                                   &quot;[Unlocked]&quot; :
                                   &quot;[Locked by thread &quot; + o.getName() + &quot;]&quot;);
    }
}
</code></pre>
<h3 id="82-reentantreadwritelock">8.2 ReentantReadWriteLock</h3>
<p>该锁实现了 <code>ReadWriteLock</code> 接口，并支持和 <code>ReentrantLock</code> 相似的语义。</p>
<p>此类具有以下属性：</p>
<ul>
<li>
<p><strong>顺序加锁</strong></p>
<p>此类不会为读锁和写锁的访问强加优先级顺序。但是，它支持可选的 <em>公平</em> 策略。</p>
<ul>
<li>
<p><strong>非公平模式（默认）</strong></p>
<p>当构造非公平（默认）锁时，进入读写锁的顺序是未指定的，并受到重入的约束。一直存在竞争的非公平锁可能会无限期地推迟一个或多个读锁或写锁线程，但通常比公平锁具有更高的吞吐量。</p>
</li>
<li>
<p><strong>公平模式</strong></p>
<p>当构造为公平锁时，线程使用近似到达顺序策略竞争入队。如果当前持有的锁被释放，要么为等待时间最长的单个写入线程分配写锁，要么如果有一组读取线程等待时间比写入线程长，则为读取线程分配读锁。</p>
<p>如果持有写锁或存在等待写入线程，则尝试获取公平锁（不可重入）的线程将阻塞。直到当前等待时间最长的写入线程获得写锁并释放之后，该线程才会获得读锁。当然，在没有线程获取写锁的情况下，如果一个等待的写入线程放弃等待，剩下的一个或多个读取线程将作为队列中等待时间最长的，被分配读锁。</p>
<p>除非读锁和写锁都空闲（这意味着没有等待的线程），否则试图获取公平写锁（不可重入）的线程将阻塞。（请注意，非阻塞 <code>ReentrantReadWriteLock.ReadLock.tryLock()</code> 和 <code>ReentrantReadWriteLock.WriteLock.tryLock()</code> 方法不遵守此公平设置，如果可能，将立即获取锁，而不管等待线程。）</p>
</li>
</ul>
</li>
<li>
<p><strong>重入</strong></p>
<p>此锁允许读取线程和写入线程以 <code>ReentrantLock</code> 一样的方式重新获取读锁或写锁。在写入线程持有的所有写锁都被释放之前，不允许非重入的读取线程。</p>
<p>此外，写入线程可以获取读锁，但反之则不行。在其他应用程序中，当对在读锁下执行读取操作的方法在调用或回调期间持有写锁时，可重入性可能很有用。如果一个读取线程试图获得写锁，它将永远不会成功。</p>
</li>
<li>
<p><strong>锁降级</strong></p>
<p>重入还允许从写锁降级为读锁，方法是获取写锁，然后获取读锁，然后释放写锁。但是，<strong>无法</strong> 从读锁升级为写锁。</p>
</li>
<li>
<p><strong>锁获取中断</strong></p>
<p>读锁和写锁都支持获取锁过程中的中断。</p>
</li>
<li>
<p><strong>Condition 支持</strong></p>
<p>写锁提供了一个 <code>Condition</code> 实现，就写锁而言，它的行为方式与 <code>ReentrantLock.newCondition</code> 提供的实现的行为方式相同。当然，这个 <code>Condition</code> 只能与写锁一起使用。读锁不支持 <code>Condition</code> 并且 <code>readLock().newCondition()</code> 抛出 <code>UnsupportedOperationException</code>。</p>
</li>
<li>
<p><strong>Instrumentation</strong></p>
<p>此类支持确定锁是否被持有或竞争的方法。这些方法是为监控系统状态而设计的，而不是为同步控制而设计的。</p>
</li>
</ul>
<p>此类的序列化与内置锁的行为方式相同：反序列化锁将处于未锁定状态，无论其在序列化时的状态如何。</p>
<p>示例用法。这是一个代码草图，展示了如果在更新缓存后执行锁降级（以非嵌套方式处理多个锁时，异常处理特别棘手）：</p>
<pre><code class="language-java">class CachedData {
    Object data;
    volatile boolean cacheVaild;
    final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();

    void processCachedData() {
        rwl.readLock().lock();
        if (!cacheVaild) {
            // Must release read lock before acquiring write lock
            rwl.readLock().unlock();
            rwl.writeLock().lock();
            try {
                // Recheck state because another thread might have
                // acquired write lock and changed state before we did.
                if (!cacheVaild) {
                    data = ...
                    cacheVaild = true;
                }
                // Downgrade by acquiring read lock before releasing write lock
                rwl.readLock().lock();
            } finally {
                rwl.writeLock().unlock(); // Unlock write, still hold read
            }
        }
        
        try {
            use(data);
        } finally {
            rwl.readLock().unlock();
        }
    }
}
</code></pre>
<p><code>ReentrantReadWriteLock</code> 可以用于在某些集合的某些用途中提高并发性能。通常，只有当集合预计很大、被很多线程读取，但对写入很少时，并且开销要超过同步开销的操作时，才值得这么做。例如，这里有一个使用 <code>TreeMap</code> 的类，该类预计会很大，并且可以并发访问。</p>
<pre><code class="language-java">class RWDictionary {
    private final Map&lt;String, Data&gt; m = new TreeMap&lt;String, Data&gt;();
    private final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();
    private final Lock r = rwl.readLock();
    private final Lock w = rwl.writeLock();

    public Data get(String key) {
        r.lock();
        try {
            return m.get(key);
        } finally {
            r.unlock();
        }
    }

    public String[] allKeys() {
        r.lock();
        try {
            return m.keySet().toArray();
        } finally {
            r.unlock();
        }
    }

    public Data put(String key, Data value) {
        w.lock();
        try {
            return m.put(key, value);
        } finally {
            w.unlock();
        }
    }

    public void clear() {
        w.lock();
        try {
            m.clear();
        } finally {
            w.unlock();
        }
    }
}
</code></pre>
<p><strong>实现注意事项</strong></p>
<p>该锁最多支持 65535 个重入写锁和 65535 个读锁。如果超出这些限制会导致 <code>lock</code> 方法引发 <code>Error</code>。</p>
<h4 id="821-sync">8.2.1  Sync</h4>
<p>和 <code>ReentrantLock</code> 相似，在 <code>ReentrantReadWriteLock</code> 类中同样有基于 <code>AQS</code> 框架实现的内部类 <code>Sync</code>。</p>
<pre><code class="language-java">/**
 * ReentrantReadWriteLock 的同步实现。
 * 分为公平和非公平版本。
 */
abstract static class Sync extends AbstractQueuedSynchronizer {
    private static final long serialVersionUID = 6317671515068378041L;

    /*
     * 读锁和写锁计数提取常量和函数。
     * 锁的状态在逻辑上分为两个无符号 short：
     * 较低的表示独占（写锁）锁持有计数，
     * 较高的表示共享（读锁）锁持有计数。
     */

    // 共享锁（读锁）的偏移量
    static final int SHARED_SHIFT   = 16;
    /**
     * 我们每次在进行读锁数量增加 +1 时，只需直接将 SHARED_UNIT 加上 state 即可。
     * 举个例子，在十进制中，如果我们只有四位，读锁只能操作高位的2个数字，写锁只能操作
     * 低位的两个数字，那么如果想要让读锁加一，那我们就需要加上 100，此时数字就是 01 | 00。
     * 如果我们还想要再次加一，此时同样是加上 100，就是 02 | 00，这样就实现了读锁加一的效果，
     * 而写锁，只需要直接加一即可。而这个 100 其实就是我们位数的偏移量，100 就是 1 左移 2 位即可，
     * 因为写锁占了低位，所以我们要偏移后，这个 SHARED_UNIT 就是我们每次增减的值。
     */
    static final int SHARED_UNIT    = (1 &lt;&lt; SHARED_SHIFT);
    // 读/写锁的最大数量，为什么减一，以上面的例子来说，两位只能是 00 ~ 99，
    // 也就是 1 &lt;&lt; SJARED_SHIFT - 1，因为再加的话，就溢出到高位了
    static final int MAX_COUNT      = (1 &lt;&lt; SHARED_SHIFT) - 1;
    // 低 16 位全部为 1，高 16 位全部是 0，当我们想要计算独占锁（读锁，占低 16 位）
    // 的数量时（因为可能会有重入），将 state &amp; EXCLUSIVE_MARK，进行 &amp; 操作，
    // （都为 1 才保留，其余全部为 0），高位数字会被清掉，所以就计算出了低 16 位.
    // 也就是写锁的数量
    static final int EXCLUSIVE_MASK = (1 &lt;&lt; SHARED_SHIFT) - 1;

    /** 返回读锁的数量  */
    static int sharedCount(int c)    { return c &gt;&gt;&gt; SHARED_SHIFT; }
    /** 返回写锁的数量  */
    static int exclusiveCount(int c) { return c &amp; EXCLUSIVE_MASK; }

    /**
     * 每个线程的读锁持有数量，维护为 ThreadLocal，缓存在 cachedHoldCounter
     */
    static final class HoldCounter {
        int count = 0;
        // 使用线程 id，而不是引用，避免垃圾滞留
        final long tid = getThreadId(Thread.currentThread());
    }

    /**
     * ThreadLocal 子类，为了反序列化，使用最简单明确的定义。
     */
    static final class ThreadLocalHoldCounter
        extends ThreadLocal&lt;HoldCounter&gt; {
        public HoldCounter initialValue() {
            return new HoldCounter();
        }
    }

    /**
     * 当前线程持有的可重入读锁数量。仅在构造函数和 readObject 中初始化。
     * 每当线程的读取计数减为 0 时删除。
     */
    private transient ThreadLocalHoldCounter readHolds;

    /**
     * 最后一个线程成功获取 readLock 的持有计数。这节省了 ThreadLocal
     * 查找，在通常情况下，下一个要 release 的线程是最后一个 acquire 的线程。
     * 这是非 volatile 的，因为它只是作为一种试探，对线程进行缓存有利。
     *
     * 该读取计数缓存的生命周期可能比线程更长，因为内部使用线程 id，而不是
     * 线程引用，来避免垃圾回收保留。
     *
     * 通过良性数据竞争访问；依赖于内存模型的 final 字段和 out-of-thin-air 的保证。
     */
    private transient HoldCounter cachedHoldCounter;

    /**
     * firstReader 是第一个获得读锁的线程。firstReaderHoldCount 是 first
     * 的持有计数。
     *
     * 更准确的说，firstReader 是最后一次将共享计数从 0 改为 1 的唯一线程，
     * 此后一直没有释放读锁；如果没有这样的线程，则为 null。
     *
     * 除非线程在没有放弃读锁的情况下终止，否则不会导致垃圾保留，因为 tryReleaseShared
     * 会将其设置为 null。
     *
     * 通过良性数据竞争访问；依赖于内存模型对引用的 out-of-thin-air 保证。
     *
     * 这使得对非竞争读锁的持有计数保存跟踪非常简单。
     */
    private transient Thread firstReader = null;
    private transient int firstReaderHoldCount;

    Sync() {
        // 初始化读锁的持有计数 ThreadLocal
        readHolds = new ThreadLocalHoldCounter();
        setState(getState()); // 确保 readHolds 的内存可见性
    }

    /*
     * 公平锁和非公平锁使用相同的 acquires 和 releases 代码，但在队列非空时，
     * 它们在是否允许插入方面会有所不同。
     */

    /**
     * 该方法返回当前线程请求获得读锁是否应该被阻塞，在公平和非公平策略下实现不同。
     * 在公平锁中，如果队列中当前线程之前 有 其他线程排队，则返回 true，当在队列头部
     * 或者队列为空则返回 false。
     * 在非公平锁中，如果队列头部的等待节点是写入线程，则返回 true，避免写入线程无限等待；
     * 如果写入线程不在队头，则返回 false，不影响其他线程进行读取。
     */
    abstract boolean readerShouldBlock();

    /**
     * 返回当前线程请求获得写锁是否应该被阻塞，在公平锁中，行为和 reader 一样，都会检查在
     * 自己之前是否有其他线程排队；在非公平锁中，总是返回 false，不阻塞。
     */
    abstract boolean writerShouldBlock();

    /*
     * 注意 tryRelease 和 tryAcquire 可以被 Condition 调用。因此，
     * 它们的参数可能会是包含所有的读锁计数和写锁计数，在条件等待期间全部释放并
     * tryAcquire 重新建立读锁和写锁持有计数。
     */
    // 读锁释放
    protected final boolean tryRelease(int releases) {
        // 判断当前线程是否是独占线程
        if (!isHeldExclusively())
            throw new IllegalMonitorStateException();
        // 读锁模式下是单线程，计算释放后的值
        int nextc = getState() - releases;
        // 判断是否全部释放
        boolean free = exclusiveCount(nextc) == 0;
        if (free)
            // 清空独占线程
            setExclusiveOwnerThread(null);
        // 写入新的 state
        setState(nextc);
        return free;
    }

    // 读锁获取
    protected final boolean tryAcquire(int acquires) {
        /*
         * 步骤：
         * 1. 如果读锁计数不为 0 或写锁计数不为 0，且当前线程不是锁持有者，失败。
         * 2. 如果计数饱和（溢出），失败（只有在计数不为 0 时才会出现）。
         * 3. 否则，如果该线程是可重入加锁或队列策略允许（非公平锁可以抢占，
         * 即 writerShouldBlock 返回 false），则该线程有资格获取锁。如果是这样，
         * CAS更新状态并设置独占线程。
         */
        Thread current = Thread.currentThread();
        int c = getState();
        // 独占（写）锁数量
        int w = exclusiveCount(c);
        // c 不为零，即存在读锁或写锁被持有（也可能是自己）
        if (c != 0) {
            // (注意: 如果 c != 0 且 w == 0 那么共享（读）锁数量不为 0)
            // 如果 w == 0 说明读锁不为零，读锁有则加锁失败。
            // 如果 w == 0 没有满足，说明现在写锁不为零，判断当前线程是不是
            // 独占线程，如果是，则尝试重入，如果不是则失败
            if (w == 0 || current != getExclusiveOwnerThread())
                return false;
            // 独占线程重入，检查是否超过最大重入数量
            if (w + exclusiveCount(acquires) &gt; MAX_COUNT)
                throw new Error(&quot;Maximum lock count exceeded&quot;);
            // 重入计数
            setState(c + acquires);
            return true;
        }
        // 判断当前写锁是否需要阻塞，如果需要阻塞，失败
        // 如果不需要阻塞，则 CAS 修改持有计数，加锁并设置独占线程
        if (writerShouldBlock() ||
                !compareAndSetState(c, c + acquires))
            return false;
        setExclusiveOwnerThread(current);
        return true;
    }

    // 共享（写）锁释放
    protected final boolean tryReleaseShared(int unused) {
        Thread current = Thread.currentThread();
        // 当前线程是否是 firstReader，在没有竞争的情况下，这个变量可以帮助我们
        // 更加简单快速的去确认读取所的持有数量
        if (firstReader == current) {
            // assert firstReaderHoldCount &gt; 0;
            // 如果只有一个读取锁持有数量，直接释放锁，并将 firstReader 置空
            if (firstReaderHoldCount == 1)
                firstReader = null;
            else
                // 将持有数量 -1
                firstReaderHoldCount--;
        } else {
            // 如果不是当前线程，说明现在有多个线程持有读锁
            // 如果缓存是 null 或者 缓存线程不是当前线程，说明当前线程不是最后一次获取
            // 持有读锁的线程，则从 threadLocal 读取
            HoldCounter rh = cachedHoldCounter;
            if (rh == null || rh.tid != getThreadId(current))
                rh = readHolds.get();
            // 当前的读锁计数
            int count = rh.count;
            // 如果当前持有的读锁计数小于等于 1，直接删除 ThreadLocal 值
            if (count &lt;= 1) {
                readHolds.remove();
                // 如果还没开始释放就 &lt;= 0，这说明有逻辑问题，抛出异常
                if (count &lt;= 0)
                    throw unmatchedUnlockException();
            }
            // 计数器减一
            --rh.count;
        }
        // 自旋 CAS 修改共享锁计数
        for (;;) {
            int c = getState();
            // c - SHARED_UNIT(共享锁的一个单元)，也就是对高 16 位进行减一操作
            int nextc = c - SHARED_UNIT;
            if (compareAndSetState(c, nextc))
                // 释放读锁对写锁没有影响，但如果读锁和写锁都空闲（nextc 为 0），
                // 则表示可以唤醒后面等待的线程
                return nextc == 0;
        }
    }

    private IllegalMonitorStateException unmatchedUnlockException() {
        return new IllegalMonitorStateException(
                &quot;attempt to unlock read lock, not locked by current thread&quot;);
    }

    // 共享（写）锁的获取
    protected final int tryAcquireShared(int unused) {
        /*
         * 步骤：
         * 1. 如果写锁被另一个线程持有，则失败。
         * 2. 否则，该线程有资格获得锁定状态，因此请询问它是否应该
         *    因为队列策略而阻塞。如果没有，请尝试通过 CAS 更新 state
         *    并更新计数。注意，该步骤不检查可重入 acquire，它被推迟
         *    在 fullTryAcquireShared 中，从而避免在更典型的
         *    不可重入的场景下，检查持有计数。
         * 3. 如果由于线程不符合条件或 CAS 失败或计数已经饱和，
         *    则步骤 2 失败，然后将会进行 fullTryAcquireShared 方法。
         */
        Thread current = Thread.currentThread();
        int c = getState();
        // 写锁数量不为 0，并且当前线程不为独占线程
        // 这一步就是我们进行锁降级时，持有写锁然后去获取读锁的基础
        if (exclusiveCount(c) != 0 &amp;&amp;
                getExclusiveOwnerThread() != current)
            return -1;
        // 获取读锁数量
        int r = sharedCount(c);
        // 判断读锁是否应该阻塞
        if (!readerShouldBlock() &amp;&amp;
                // 判断当前是否溢出
                r &lt; MAX_COUNT &amp;&amp;
                // CAS 尝试加锁
                compareAndSetState(c, c + SHARED_UNIT)) {
            // 加锁成功后，判断是否是首个获取读锁的线程
            if (r == 0) {
                // 将 firstReader 和 firstReaderHoldCount 赋值
                firstReader = current;
                firstReaderHoldCount = 1;
              // 当前线程是否是首个获取读锁的线程重入了
            } else if (firstReader == current) {
                // 持有计数递增
                firstReaderHoldCount++;
            } else {
                // 非首个线程，判断自己是否是上次来访问 AQS 加锁的线程
                HoldCounter rh = cachedHoldCounter;
                // 当自己也不是上次加锁的线程，那只能从 threadLocal 中读取
                if (rh == null || rh.tid != getThreadId(current))
                    // 更新 rh 和 cachedHoldCounter，因为自己是最后一次获取
                    // 读锁成功的线程
                    cachedHoldCounter = rh = readHolds.get();
                else if (rh.count == 0)
                    // 读锁数量为零，说明是同一个线程之前全部释放后，再次加锁
                    // 由于当线程释放完后，会清空 threadLocal，但是并不会清理
                    // cachedHoldCounter，所以，当同一个线程释放完，再次过来
                    // 获取（中间没有其他线程过来加锁），那 cachedHoldCounter 持有的
                    // 计数是仍然存在的，所以只需要将计数重新放回 threadLocal 即可
                    readHolds.set(rh);
                // 持有计数递增
                rh.count++;
            }
            return 1;
        }
        // 需要阻塞，或读锁移除，或 CAS 失败
        return fullTryAcquireShared(current);
    }

    /**
     * 读锁进行 acquire 的完整版本，它处理 CAS 失败和在 tryAcquireShared
     * 中未处理的重入获取
     */
    final int fullTryAcquireShared(Thread current) {
        /*
         * 此代码与 tryAcquireShared 中的代码部分冗余，但总体上更简单，
         * 因为不会使 tryAcquireShared 与重试和延迟读取持有计数之间的交互
         * 复杂化。
         */
        HoldCounter rh = null;
        // 自旋加锁
        for (;;) {
            int c = getState();
            // 独占锁数量不为零，则判断当前线程是否是独占线程，非独占则失败
            if (exclusiveCount(c) != 0) {
                if (getExclusiveOwnerThread() != current)
                    return -1;
                // 否则我们持有独占锁；如果我们在持有写锁的情况下，在这里阻塞会导致死锁。
                // 所以我们直接放行
              
              // 下面判断没有线程持有写锁，排队的情况
            } else if (readerShouldBlock()) {
                // 在这里面说明我们获取 readLock 需要阻塞的，说明在我们之前可能有其他排队线程
                // 确保我们没有以可重入的方式获取读锁
                // 如果当前线程是已经获取过读锁，再次重入的，直接放行
                if (firstReader == current) {
                    // assert firstReaderHoldCount &gt; 0;
                } else {
                    // 到这里，我们不是首次获取读锁的
                    // 首次自旋 rh 是 null，那需要给 rh 赋值
                    if (rh == null) {
                        // 先给 rh 赋为 cachedHoldCounter，即假设我们是最后一个获取的
                        rh = cachedHoldCounter;
                        // 如果 rh 为空，或者 rh 的线程并不是自己，则从 threadLocal 查找
                        if (rh == null || rh.tid != getThreadId(current)) {
                            // 查找获取 threadLocal 的值，如果我们没有持有锁，是首次获取
                            // 那这一步会导致 threadLocal 实例化 HoldCounter，实例化后
                            // 的 count 为 0，由于我们需要阻塞，所以肯定是失败的，目的就是
                            // 检查我们是不是重入，重入的话就成功，失败需要把 threadLocal
                            // 值清理掉
                            rh = readHolds.get();
                            // threadLocal 中的持有计数，如果为空，则移除 threadLocal
                            if (rh.count == 0)
                                readHolds.remove();
                        }
                    }
                    // 如果我们没有持有锁，并且需要阻塞，则失败
                    if (rh.count == 0)
                        return -1;
                }
            }
            // 如果限制持有锁数量达到最大，则失败
            if (sharedCount(c) == MAX_COUNT)
                throw new Error(&quot;Maximum lock count exceeded&quot;);
            // CAS 尝试加写锁
            if (compareAndSetState(c, c + SHARED_UNIT)) {
                // 加锁成功，判断加锁前读锁数量是不是为 0，为 0 说明自己是第一个加锁的
                if (sharedCount(c) == 0) {
                    // 设置 firstReader 和 firstReaderHoldCount 主要为了提高性能
                    firstReader = current;
                    firstReaderHoldCount = 1;
                // 不为零，判断当前线是否是 firstReader 重入
                } else if (firstReader == current) {
                    // 持有计数增加
                    firstReaderHoldCount++;
                } else {
                    // 如果非 firstReader，则获取 threadLocal 值
                    if (rh == null)
                        // 先假设我们是最后一个加锁的
                        rh = cachedHoldCounter;
                    // 如果我们不是最后一个加锁的，则从 threadLocal 查找
                    if (rh == null || rh.tid != getThreadId(current))
                        rh = readHolds.get();
                    // 我们是最后一个加锁的，则设置一下 threadLocal，因为
                    // 随时会有其他线程在加锁成功后将 cachedHoldCounter 更新掉，
                    // 这时候我们的计数就丢失了
                    else if (rh.count == 0)
                        readHolds.set(rh);
                    // 增加持有读锁计数
                    rh.count++;
                    // 将自己更新为最后一个获取读锁的线程，缓存下来，提高性能
                    cachedHoldCounter = rh; // cache for release
                }
                return 1;
            }
        }
    }

    /**
     * 对写锁执行 tryLock，在两种策略（公平和非公平）下都会“闯入”。
     * 这在效果上与 tryAcquire 相同，只是缺少对 writeShouldBlock
     * 的调用。
     */
    final boolean tryWriteLock() {
        Thread current = Thread.currentThread();
        int c = getState();
        // 说明有线程持有读/写锁
        if (c != 0) {
            // 判断读锁数量是否为 0，为 0 说明有其他线程持有写锁，那我们肯定失败
            // 不为 0，则判断当前线程是否是重入，非重入，则直接失败
            int w = exclusiveCount(c);
            if (w == 0 || current != getExclusiveOwnerThread())
                return false;
            if (w == MAX_COUNT)
                throw new Error(&quot;Maximum lock count exceeded&quot;);
        }
        // CAS 加锁
        if (!compareAndSetState(c, c + 1))
            return false;
        // 成功后更新独占线程
        setExclusiveOwnerThread(current);
        return true;
    }

    /**
     * 对读锁执行 tryLock，在两种策略下都会“闯入”。这在效果上与 
     * tryAcquireShared 相同，只是缺少对 readerShouldBlock 的调用。
     */
    final boolean tryReadLock() {
        Thread current = Thread.currentThread();
        // 自旋尝试获取读锁
        for (;;) {
            int c = getState();
            // 独占锁数量不为空，并且当前线程不是独占线程，则直接失败
            if (exclusiveCount(c) != 0 &amp;&amp;
                    getExclusiveOwnerThread() != current)
                return false;
            // 获取写锁数量
            int r = sharedCount(c);
            // 判断写锁数量是否已满
            if (r == MAX_COUNT)
                throw new Error(&quot;Maximum lock count exceeded&quot;);
            // CAS 尝试加锁
            if (compareAndSetState(c, c + SHARED_UNIT)) {
                // 加锁成功，判断当前线程是不是首个获得读锁的
                if (r == 0) {
                    // 设置 firstReader 和 firstReaderCount
                    firstReader = current;
                    firstReaderHoldCount = 1;
                // 读锁不为空，看看当前线程是否是 firstReader 重入，是的话直接增加计数
                } else if (firstReader == current) {
                    firstReaderHoldCount++;
                } else {
                    // 先从缓存中找，如果不是，则从 threadLocal 找
                    HoldCounter rh = cachedHoldCounter;
                    if (rh == null || rh.tid != getThreadId(current))
                        cachedHoldCounter = rh = readHolds.get();
                    else if (rh.count == 0)
                        readHolds.set(rh);
                    // 计数
                    rh.count++;
                }
                return true;
            }
        }
    }

    // 是否是独占线程
    protected final boolean isHeldExclusively() {
        // While we must in general read state before owner,
        // we don't need to do so to check if current thread is owner
        return getExclusiveOwnerThread() == Thread.currentThread();
    }

    // Methods relayed to outer class

    // 获取 condition
    final ConditionObject newCondition() {
        return new ConditionObject();
    }

    // 获取独占线程
    final Thread getOwner() {
        // Must read state before owner to ensure memory consistency
        return ((exclusiveCount(getState()) == 0) ?
                null :
                getExclusiveOwnerThread());
    }

    // 获取读锁数量
    final int getReadLockCount() {
        return sharedCount(getState());
    }

    // 写锁是否被占有
    final boolean isWriteLocked() {
        return exclusiveCount(getState()) != 0;
    }

    // 获取当前线程持有的写锁数量
    final int getWriteHoldCount() {
        return isHeldExclusively() ? exclusiveCount(getState()) : 0;
    }

    // 获取当前线程持有读锁数量
    final int getReadHoldCount() {
        if (getReadLockCount() == 0)
            return 0;

        // 先从 firstReader 里面找
        Thread current = Thread.currentThread();
        if (firstReader == current)
            return firstReaderHoldCount;

        // 再从 cachedHoldCounter 找，没有则从 threadLocal 找
        HoldCounter rh = cachedHoldCounter;
        if (rh != null &amp;&amp; rh.tid == getThreadId(current))
            return rh.count;

        int count = readHolds.get().count;
        if (count == 0) readHolds.remove();
        return count;
    }

    /**
     * 从流中读取对象（即反序列化）
     */
    private void readObject(java.io.ObjectInputStream s)
            throws java.io.IOException, ClassNotFoundException {
        s.defaultReadObject();
        readHolds = new ThreadLocalHoldCounter();
        setState(0); // reset to unlocked state
    }

    // 获取全部计数
    final int getCount() { return getState(); }
}
</code></pre>
<h4 id="822-公平锁和非公平锁">8.2.2 公平锁和非公平锁</h4>
<p>非公平锁：</p>
<pre><code class="language-java">static final class NonfairSync extends Sync {
    private static final long serialVersionUID = -8159625535654395037L;
    final boolean writerShouldBlock() {
        return false; // 非公平锁写入不需要阻塞
    }
    // 
    final boolean readerShouldBlock() {
        /* 作为避免写入线程饿死的启发式方法，如果队列头部暂时显示为写入线程，则阻塞。
         * 这只是一种概率效应，引入如果在写入线程之前有其他读取线程没有超时，则
         * 读取线程不会阻塞。
         */
        // 判断队列头部线程是否是独占线程
        return apparentlyFirstQueuedIsExclusive();
    }
}
</code></pre>
<p>公平锁：</p>
<pre><code class="language-java">static final class FairSync extends Sync {
    private static final long serialVersionUID = -2274990926593161451L;
    final boolean writerShouldBlock() {
        return hasQueuedPredecessors();
    }
    final boolean readerShouldBlock() {
        return hasQueuedPredecessors();
    }
}
</code></pre>
<h4 id="823-读锁和写锁">8.2.3 读锁和写锁</h4>
<h5 id="8231-readlock">8.2.3.1  ReadLock</h5>
<pre><code class="language-java">public static class ReadLock implements Lock, java.io.Serializable {
    private static final long serialVersionUID = -5992448646407690164L;
    private final Sync sync;

    /**
     * 子类使用的构造器
     *
     * 参数：lock - 外部锁对象
     * 参数：NullPointerException - 如果 lock 为空
     */
    protected ReadLock(ReentrantReadWriteLock lock) {
        sync = lock.sync;
    }

    /**
     * 获取读锁。
     *
     * 如果写锁没有被另一个线程持有，则获取读锁并立即返回。
     *
     * 如果写锁被另一个线程持有，那么当前线程处于调度目的将被禁用并处于休眠状态，
     * 直到获得读锁为止。
     */
    public void lock() {
        sync.acquireShared(1);
    }

    /**
     * 获取读锁，线程中断则终止。
     *
     * 如果写锁没有被另一个线程持有，则获取读锁并立即返回。
     *
     * 如果写锁被另一个线程持有，那么出于调度的目的，该线程将被禁用并
     * 进入休眠状态，直到发生以下两种状态之一：
     * - 该线程获取到读锁；或者
     * - 其他一些线程中断当前线程。
     *
     * 如果当前线程：
     * - 进入此方法时设置中断状态；或者
     * - 在线程获取读锁时被中断。
     *
     * 然后抛出InterruptedException并清除当前线程的中断状态。
     *
     * 在此实现中，由于此方法明显表示出中断能力，因此优先响应中断而不是
     * 正常执行或可重入获取锁。
     *
     * @throws InterruptedException - 如果当前线程被中断
     */
    public void lockInterruptibly() throws InterruptedException {
        sync.acquireSharedInterruptibly(1);
    }

    /**
     * 仅当调用时另一个线程未持有写锁时才获取锁。
     *
     * 如果写锁没有被另一个线程持有，则获取读锁，并返回 true。即使此锁已设置为
     * 使用公平排序策略，调用 tryLock() 将立即获取读锁（如果可用），无论其他
     * 线程当前是否正在等待。这种“闯入”行为在某些情况下可能很有用，即便它会破坏
     * 公平性。如果您想要要求此锁保证公平性设置，请使用与此几乎等效的 
     * tryLock(0, TimeUnit.SECONDS)（它也会检测线程中断）。
     *
     * 如果写锁被另一个线程持有，则此方法立即返回 false。
     *
     * 返回：如果获得了锁，则返回 true
     */
    public boolean tryLock() {
        return sync.tryReadLock();
    }

    /**
     * 如果在给定的等待时间内获取写锁没有超时、或当前线程没有中断，则获取读锁。
     *
     * 如果写锁没有被另一个线程持有，则获取读锁，并返回 true。如果此锁已设置为
     * 使用公平排序策略，则在此线程之前有任何其他线程等待锁，则不会获取锁。这与
     * tryLock() 方法形成对比。如果你想要一个允许 “闯入” 公平锁的可超时 tryLock
     * ，则可以将超时和非超时方法相结合使用：
     *
     * if (lock.tryLock() ||
     *     lock.tryLock(timeout, unit)) {
     *   ...
     * }
     *
     * 如果写锁被另一个线程持有，那么出于调度的目的，该线程将被禁用并
     * 进入休眠状态，直到发生以下三种状态之一：
     * - 该线程获取到读锁；或者
     * - 其他一些线程中断当前线程；或者
     * - 超过指定的等待时间。
     *
     * 如果当前线程：
     * - 进入此方法时设置中断状态；或者
     * - 在线程获取读锁时被中断。
     *
     * 然后抛出InterruptedException并清除当前线程的中断状态。
     *
     * 在此实现中，由于此方法明显表示出中断能力，因此优先响应中断而不是
     * 正常执行或可重入获取锁，以及报告等待超时。
     *
     * 参数：timeout - 等待读锁的时间
     *      unit - timeout 参数的时间单位
     * 返回：如果获得了读锁，则为 true
     * @throws InterruptedException - 如果当前线程被中断
     * @throws NullPointerException - 如果时间单位为空
     */
    public boolean tryLock(long timeout, TimeUnit unit)
            throws InterruptedException {
        return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout));
    }

    /**
     * 尝试释放此锁。
     *
     * 如果读锁的数量为零，则写锁可以尝试获取。
     */
    public void unlock() {
        sync.releaseShared(1);
    }

    /**
     * 抛出 UnsupportedOperationException，因为 ReadLock 不支持 Cindition。
     *
     * @throws UnsupportedOperationException 总是
     */
    public Condition newCondition() {
        throw new UnsupportedOperationException();
    }

    /**
     * 返回标识此锁的字符串及其锁状态。括号中的状态包括字符串&quot;Read locks =&quot; ，后跟持有的读锁数。
     *
     * 返回：一个标识这个锁的字符串，以及它的锁状态
     */
    public String toString() {
        int r = sync.getReadLockCount();
        return super.toString() +
                &quot;[Read locks = &quot; + r + &quot;]&quot;;
    }
}
</code></pre>
<h5 id="8232-writelock">8.2.3.2 WriteLock</h5>
<pre><code class="language-java">public static class WriteLock implements Lock, java.io.Serializable {
    private static final long serialVersionUID = -4992448646407690164L;
    private final Sync sync;

    /**
     * 子类使用的构造器
     *
     * 参数：lock - 外部锁对象
     * 参数：NullPointerException - 如果 lock 为空
     */
    protected WriteLock(ReentrantReadWriteLock lock) {
        sync = lock.sync;
    }

    /**
     * 获取写锁。
     * 
     * 如果其他线程既没有持有读锁也没有持有写锁，则获取写锁并立即返回，将写锁持有
     * 计数设置为 1。
     * 
     * 如果当前线程已经持有写锁，则持有计数加一并立即返回。
     *
     * 如果锁被另一个线程持有，那么当前线程处于调度目的将被禁用并处于休眠状态，
     * 直到获得写锁为止，此时写锁持有计数设置为 1。
     */
    public void lock() {
        sync.acquire(1);
    }

    /**
     * 获取写锁，线程中断则终止。
     *
     * 如果其他线程既没有持有读锁也没有持有写锁，则获取写锁并立即返回，
     * 将写锁持有计数设置为 1。
     *
     * 如果当前线程已经持有写锁，则持有计数加一并立即返回。
     *
     * 如果锁被另一个线程持有，那么出于调度的目的，该线程将被禁用并
     * 进入休眠状态，直到发生以下两种情况之一：
     * - 该线程获取到写锁；或者
     * - 其他一些线程中断当前线程。
     *
     * 如果当前线程获取到了写锁，则锁持有计数设置为 1。
     *
     * 如果当前线程：
     * - 进入此方法时设置中断状态；或者
     * - 在线程获取读锁时被中断。
     *
     * 然后抛出InterruptedException并清除当前线程的中断状态。
     *
     * 在此实现中，由于此方法明显表示出中断能力，因此优先响应中断而不是
     * 正常执行或可重入获取锁。
     *
     * @throws InterruptedException - 如果当前线程被中断
     */
    public void lockInterruptibly() throws InterruptedException {
        sync.acquireInterruptibly(1);
    }

    /**
     * 仅当调用时没有其他线程未持有锁时才获取写锁。
     *
     * 如果其他线程既没有持有读锁也没有持有写锁，则获取写锁并立即返回，将写锁持有
     * 计数设置为 1。即使此锁已设置为使用公平排序策略，调用 tryLock() 将立即获
     * 取该锁（如果可用），无论其他线程当前是否正在等待。这种“闯入”行为在某些情况
     * 下可能很有用，即便它会破坏公平性。如果您想要要求此锁保证公平性设置，请使用
     * 与此几乎等效的  tryLock(0, TimeUnit.SECONDS)（它也会检测线程中断）。
     *
     * 如果当前线程已经持有写锁，则持有计数加一并立即返回。
     * 
     * 如果锁被另一个线程持有，则此方法立即返回 false。
     *
     * 返回：如果获得了锁，则返回 true
     */
    public boolean tryLock( ) {
        return sync.tryWriteLock();
    }

    /**
     *
     * 如果在给定的等待时间内获取锁没有超时、或当前线程没有中断，则获取读锁。
     *
     * 如果其他线程既没有持有读锁也没有持有写锁，则获取写锁并立即返回，将写锁持有
     * 计数设置为 1。如果此锁已设置为使用公平排序策略，则在此线程之前有任何其他
     * 线程等待锁，则不会获取锁。这与 tryLock() 方法形成对比。如果你想要一个
     * 允许 “闯入” 公平锁的可超时 tryLock，则可以将超时和非超时方法相结合使用：
     *
     * if (lock.tryLock() ||
     *     lock.tryLock(timeout, unit)) {
     *   ...
     * }
     *
     * 如果当前线程已经持有写锁，则持有计数加一并立即返回。
     * 
     * 如果锁被另一个线程持有，那么出于调度的目的，该线程将被禁用并
     * 进入休眠状态，直到发生以下三种状态之一：
     * - 该线程获取到读锁；或者
     * - 其他一些线程中断当前线程；或者
     * - 超过指定的等待时间。
     *
     * 如果当前线程获取到了写锁，则锁持有计数设置为 1。
     *
     * 如果当前线程：
     * - 进入此方法时设置中断状态；或者
     * - 在线程获取读锁时被中断。
     *
     * 然后抛出InterruptedException并清除当前线程的中断状态。
     *
     * 在此实现中，由于此方法明显表示出中断能力，因此优先响应中断而不是
     * 正常执行或可重入获取锁，以及报告等待超时。
     *
     * 参数：timeout - 等待读锁的时间
     *      unit - timeout 参数的时间单位
     * 返回：如果获得了读锁，则为 true
     * @throws InterruptedException - 如果当前线程被中断
     * @throws NullPointerException - 如果时间单位为空
     */
    public boolean tryLock(long timeout, TimeUnit unit)
            throws InterruptedException {
        return sync.tryAcquireNanos(1, unit.toNanos(timeout));
    }

    /**
     * 尝试释放此锁。
     *
     * 如果当前线程是这个锁的持有者，那么持有计数就会递减。如果持有计数为零，
     * 则释放锁。如果当前线不是该锁的持有者，则抛出 IllegalMonitorStateException。
     *
     * @throws IllegalMonitorStateException - 如果当前线程没有持有该锁
     */
    public void unlock() {
        sync.release(1);
    }

    /**
     * 返回与此 Lock 实例一起使用的 Condition 实例。
     *
     * 当与内置监视器锁一起使用时，返回的 Condition 实例支持与 Object 监视器
     * 方法（wait、notify 和 notifyAll）相同的用法。
     *
     * - 如果在调用任何 Condition 方法时未持有此锁的写锁，则会抛出 
     *   IllegalMonitorStateException。（写锁和读锁持有是独立的，因此不会被
     *   检查或影响。但是，当前线程在持有写锁时，又获取读锁，同时调用条件等待方法本质上
     *   是错误的，因为其他可以解除阻塞的线程无法获取写锁。）
     * - 当 condition await 方法被调用时，写锁将被释放，在它们返回之前，写锁
     *   将被重新获得，所持有计数恢复到调用方法时的状态。
     * - 如果线程在等待过程中被中断，则等待将终止，将抛出 InterruptedException，
     *   并清除线程的中断状态。
     * - 等待线程以 FIFO 顺序 signal。
     * - 从 await 方法返回的线程重新获取锁的顺序与最初获取锁的线程顺序相同，在默认情况下
     *   未指定，但对于公平锁，会优先考虑哪些等待时间最长的线程。
     *
     * 返回：condition 对象
     */
    public Condition newCondition() {
        return sync.newCondition();
    }

    /**
     * 返回标识此锁的字符串及其锁状态。括号中的状态包括字符串&quot;Unlocked&quot;或
     * 字符串&quot;Locked by&quot;后跟拥有线程的名称。
     *
     * 返回：一个标识这个锁的字符串，以及它的锁状态
     */
    public String toString() {
        Thread o = sync.getOwner();
        return super.toString() + ((o == null) ?
                &quot;[Unlocked]&quot; :
                &quot;[Locked by thread &quot; + o.getName() + &quot;]&quot;);
    }

    /**
     * 查询当前线程是否持有该写锁。与 ReentrantReadWriteLock#isWriteLockedByCurrentThread 
     * 效果相同。
     *
     * 返回：如果当前线程持有此锁，则为true；否则为 false。
     * @since 1.6
     */
    public boolean isHeldByCurrentThread() {
        return sync.isHeldExclusively();
    }

    /**
     * 查询当前线程持有该写锁的次数。对于解锁操作不匹配的每个锁定操作，
     * 线程都持有一个锁。与 ReentrantReadWriteLock#getWriteHoldCount 的效果相同。
     *
     * 返回：当前线程持有此锁的次数，如果当前线程未持有此锁，则为零
     * @since 1.6
     */
    public int getHoldCount() {
        return sync.getWriteHoldCount();
    }
}
</code></pre>
<h4 id="823-其他方法">8.2.3 其他方法</h4>
<p>下面我们看一下 <code>ReentrantReadWriteLock</code> 中使用的线程 id 如何获取：</p>
<pre><code class="language-java">/**
 * 返回给定线程的 thread ID。我们必须直接访问它，因为通过方法 Thread.getId() 返回的
 * 并不是最终的，并且已知会以不保留唯一映射的方式被覆盖。
 */
static final long getThreadId(Thread thread) {
    return UNSAFE.getLongVolatile(thread, TID_OFFSET);
}

// Unsafe mechanics
private static final sun.misc.Unsafe UNSAFE;
private static final long TID_OFFSET;
static {
    try {
        UNSAFE = sun.misc.Unsafe.getUnsafe();
        Class&lt;?&gt; tk = Thread.class;
        TID_OFFSET = UNSAFE.objectFieldOffset
                (tk.getDeclaredField(&quot;tid&quot;));
    } catch (Exception e) {
        throw new Error(e);
    }
}
</code></pre>
<p>其他一些关于 ReentrantReadWriteLock 的基础监控方法，这里不在做描述。</p>
<h3 id="83-samphora">8.3 Samphora</h3>
<p>计数信号量。从概念上讲，信号量维护一组 permit（许可）。如果需要，每个 <code>acquire</code> 都会阻塞，直到 permit 可用，然后获得它。每个 <code>release</code> 都会添加一个 permit，可能会释放一个阻塞的获取者。但是，没有使用实际的 permit 对象；<code>Semaphore</code> 只是对可用数量进行计数并采取相应的措施。</p>
<p><code>Semaphore</code> 通常用于限制可以访问某些（物理或逻辑）资源的线程数。例如，这是一个使用 <code>Semaphore</code> 来控制对资源池访问的类：</p>
<pre><code class="language-java">class Pool {
  private static final int MAX_AVAILABLE = 100;
  private final Semaphore available = new Semaphore(MAX_AVAILABLE, true);
  
  public Object getItem() throws InterruptedException {
    available.acquire();
    return getNextAvailableItem();
  }
  
  public void putItem(Object x) {
    if (markAsUnused(x)) {
      available.release();
    }
  }
  
  // Not a particularly efficient data structure; just for demo
  
  protected Object[] items = ... whatever kinds of items being managed
  protected boolean[] used = new boolean[MAX_AVAILABLE];
  
  protected synchronized Object getNextAvailableItem(){
    for (int i = 0; i &lt; MAX_AVAILABLE; ++i) {
      if (!used[i]) {
        used[i] = true;
        return items[i];
      }
    }
    return null;// not reached
  }
  
  protected synchronized boolean markAsUnused(Object item) {
    for (int i = 0; i &lt; MAX_AVAILABLE; ++i) {
      if (item == items[i]) {
        if (used[i]) {
          used[i] = false;
          return true;
        } else {
          return false;
        }
      }
    }
    return false;
  }
}
</code></pre>
<p>在获取一个 item 之前，每个线程必须从 <code>Semaphore</code> 中获得一个 permit，保证一个 item 可供使用。当线程处理完该 tiem 时，它被返回到池中，一个 permit 返回给 <code>Semaphore</code>，允许另一个线程获取该 item。请注意，当调用 <code>acquire</code> 时，不会持有同步锁，因为这将阻塞 item 返回池中。<code>Semaphore</code> 封装了限制对池的访问所需的同步，与维护池本身的一致性所需的同步是分开的。</p>
<p>初始化为 1 的 <code>Semaphore</code>，使用时最多只有一个 permit 可用，可以作为互斥锁。这通常称为二进制信号量（binary semaphore），因为它只有两种状态：1 个 permit 可用，或 0 个 permit 可用。当以这种方式使用时，二进制信号量具有这样的属性（与许多 <code>java.util.concurrent.locks.Lock</code> 实现不同），即 “锁” 可以由所有者以外的线程释放（因为信号量没有所有权的概念）。这在一些专门的上下文中很有用，比如死锁恢复。</p>
<p>此类的构造函数可以选择接受一个 <em>公平</em> 参数。当设置为 false 时，此类不保证线程获取 permit 的顺序。特别是，允许“闯入”，也就是说，调用 <code>acquire</code> 的线程可以在一个一直等待的线程之前被允许分配一个 permit —— 从逻辑上来说，就是新线程将自己置于等待队列的头部。当 <code>fairness</code> 设置为 true时，信号量保证调用任何 <code>acquire</code> 方法的线程会按照这些线程被 <code>acquire</code> 方法处理的顺序获得 permit（先进先出；FIFO）。请注意，FIFO 排序必然适用于这些方法中的特定内部执行点。因此，一个线程可以在另一个线程之前调用 <code>acquire</code>，但在另一个线程之后到达排序点，并且从方法返回时类似。另外请注意，没有超时参数的 <code>tryAcquire</code> 方法不遵循公平设置，会直接获取任何可用的 permit。</p>
<p>通常，用于控制资源访问的信号量应该被初始化公平的，以确保没有线程因访问资源而被饿死。当使用信号量进行其他类型的同步控制时，非公平排序的吞吐量优势通常超过公平性考虑。</p>
<p>该类还提供了一次获取和释放多个 permit 的方便方法。当使用这些方法且不设置公平性时，要注意线程有无限延迟被饿死的风险会增加。</p>
<p>内存一致性影响：线程中调用“释放”方法（比如 <code>release()</code>）之前的操作 happen-before 另一线程中紧跟在成功的“获取”方法（比如 acquire()）之后的操作。</p>
<h4 id="831-sync">8.3.1 Sync</h4>
<p>信号量的同步实现。使用 <code>AQS</code> 的 <code>state</code> 来表示 permit。分为公平和非公平版本。</p>
<pre><code class="language-java">abstract static class Sync extends AbstractQueuedSynchronizer {
    private static final long serialVersionUID = 1192457210091910933L;

    Sync(int permits) {
        setState(permits);
    }

    final int getPermits() {
        return getState();
    }

    // 非公平尝试获取资源，注意此方法会自旋直到获取成功，或可用资源不够用，直接返回相减后的数量
    final int nonfairTryAcquireShared(int acquires) {
        // 自旋获取 permit
        for (;;) {
            // 获取当前可用的 permit 数量
            int available = getState();
            // 获取后的剩余数量
            int remaining = available - acquires;
            // remaining 大于等于 0 时，尝试 CAS 获取，成功则直接返回
            if (remaining &lt; 0 ||
                    compareAndSetState(available, remaining))
                return remaining;
        }
    }

    // 归还资源，同样，此方法会自旋直至成功
    protected final boolean tryReleaseShared(int releases) {
        // 自旋释放 permit
        for (;;) {
            // 获取当前的 permit 数量
            int current = getState();
            // 归还 permit
            int next = current + releases;
            // 判断归还后是否溢出
            if (next &lt; current) // overflow
                throw new Error(&quot;Maximum permit count exceeded&quot;);
            // CAS 归还
            if (compareAndSetState(current, next))
                return true;
        }
    }

    // 获取资源，注意此方法在 CAS 修改后直接返回。
    // 此方法在使用信号量来跟踪那些变为不可用资源的子类中很有用。
    // 此方法与 acquire 的不同之处在于它不会阻塞，等待 permit 可用。
    final void reducePermits(int reductions) {
        // 自旋减少 permit 
        for (;;) {
            int current = getState();
            int next = current - reductions;
            if (next &gt; current) // underflow
                throw new Error(&quot;Permit count underflow&quot;);
            if (compareAndSetState(current, next))
                return;
        }
    }

    // 获取全部可用资源
    final int drainPermits() {
        for (;;) {
            int current = getState();
            if (current == 0 || compareAndSetState(current, 0))
                return current;
        }
    }
}
</code></pre>
<h4 id="832-公平和非公平">8.3.2 公平和非公平</h4>
<p>非公平版：</p>
<pre><code class="language-java">static final class NonfairSync extends Semaphore.Sync {
    private static final long serialVersionUID = -2694183684443567898L;

    NonfairSync(int permits) {
        super(permits);
    }

    protected int tryAcquireShared(int acquires) {
        return nonfairTryAcquireShared(acquires);
    }
}
</code></pre>
<p>公平版：</p>
<pre><code class="language-java">static final class FairSync extends Sync {
    private static final long serialVersionUID = 2014338818796000944L;

    FairSync(int permits) {
        super(permits);
    }

    // 返回负数说明资源不够用
    protected int tryAcquireShared(int acquires) {
        // 自旋获取资源
        for (;;) {
            // 先判断队列中是否有等待阻塞的前驱节点
            if (hasQueuedPredecessors())
                return -1;
            int available = getState();
            int remaining = available - acquires;
            if (remaining &lt; 0 ||
                    compareAndSetState(available, remaining))
                return remaining;
        }
    }
}
</code></pre>
<h4 id="833-acquire-release">8.3.3 acquire &amp; release</h4>
<pre><code class="language-java">public class Semaphore implements java.io.Serializable {
    private static final long serialVersionUID = -3222578661600680210L;
    /** All mechanics via AbstractQueuedSynchronizer subclass */
    private final Sync sync;

    /**
     * 使用给定数量的 permit 创建信号量，并设置为非公平。
     *
     * 参数：permits - 可用的 permit 的初始数量。该值可能为负数，在
     *                这种情况下，必须在任何 acquire 之前进行 release。
     */
    public Semaphore(int permits) {
        sync = new NonfairSync(permits);
    }

    /**
     * 创建具有给定 permit 数量和给定公平设置的 Semaphore 。
     *
     * 参数：permits - 可用的 permit 的初始数量。该值可能为负数，在
     *                这种情况下，必须在任何 acquire 之前进行 release。
     *      fair - 此信号量保证竞争 permit 的 acquire 为先进先出，则为 true；否则为 false
     */
    public Semaphore(int permits, boolean fair) {
        sync = fair ? new FairSync(permits) : new NonfairSync(permits);
    }

    /**
     * 从信号量获取一个 permit，阻塞直到获取一个可用，线程被中断则终止。
     * 
     * 获得一个 permit，如果有可用则立即返回，并将可用 permit 数量减一。
     *
     * 如果没有可用的 permit，则处于线程调度目的，当前线程将被禁用并处于休眠状态，直到
     * 发生以下两种情况下之一：
     * - 其他一些线程调用此信号量的 release 方法，并且当前线接下来获得一个 permit；或者
     * - 其他线程中断当前线程。
     *
     * 如果当前线程：
     * - 在进入此方法时设置其中断状态；或者
     * - 在等待过程中被中断。
     *
     * 然后抛出InterruptedException并清除当前线程的中断状态。
     *
     * @throws InterruptedException - 如果当前线程被中断。
     */
    public void acquire() throws InterruptedException {
        sync.acquireSharedInterruptibly(1);
    }

    /**
     * 从信号量获取一个 permit，阻塞直至获取一个可用。
     *
     * 获取一个 permit，如果存在可用会立即返回，并将可用 permit 减一。
     *
     * 如果没有可用的 permit，则处于线程调度目的，当前线程将被禁用并处于休眠状态，直到
     * 某个其他线程调用此信号量的 release 方法并且当前线程被分配到可用的 permit。
     *
     * 如果当前线程在等待 permit 时发生中断，那么它将继续等待，但线程被分配 permit 的
     * 时间与它在没有中断发生时收到 permit 的时间相比可能会发生变化。当线程从此方法返回
     * 时，将设置其中断状态。
     */
    public void acquireUninterruptibly() {
        sync.acquireShared(1);
    }

    /**
     * 仅当在调用时有可用的 permit 时，才从此信号量获取 permit。
     *
     * 获取一个 permit，如果存在一个可用则立即返回 true，并将可用 permit 的数量减一。
     *
     * 如果没有可用的 permit，则此方法将立即返回 false。
     *
     * 即使次信号量已设置为公平排序策略，对于 tryAcquire() 的调用也会立即获得
     * permit（如果可用），无论其他线程当前是否正在等待。这种“闯入”行为在某些情况下
     * 可能很有用，即使它破坏了公平性。如果要尊重公平设置，请使用几乎等效的
     * tryAcquire(0, TimeUnit.SECONDS)（它也会检测中断）。
     *
     * 返回：如果获得了 permit，则为 true；否则为 false。
     */
    public boolean tryAcquire() {
        return sync.nonfairTryAcquireShared(1) &gt;= 0;
    }

    /**
     * 如果在给定超时时间内没有中断，且 permit 可用，则从信号量中获取一个 permit。
     *
     * 获取一个 permit，如果存在一个可用则立即返回 true，并将可用 permit 的数量减一。
     *
     * 如果没有可用的 permit，则处于线程调度目的，当前线程将被禁用并处于休眠状态，直到
     * 发生以下三种情况下之一：
     * - 其他一些线程调用此信号量的 release 方法，并且当前线接下来获得一个 permit；或者
     * - 其他线程中断当前线程；或者
     * - 超过指定的超时时间。
     *
     * 如果获得 permit，则返回 true。
     *
     * 如果当前线程：
     * - 在进入此方法时设置其中断状态；或者
     * - 在等待过程中被中断。
     *
     * 然后抛出InterruptedException并清除当前线程的中断状态。
     *
     * 如果经过指定的等待时间，则返回 false。如果时间小于等于零，则该方法不会等待。
     * 参数：timeout - 等待 permit 的最大时间
     *      unit - timeout 参数的时间单位
     * 返回：如果已经获得 permit，则为 true；如果获得之前超过等待时间，则为 false。
     * @throws InterruptedException - 如果当前线程被中断
     */
    public boolean tryAcquire(long timeout, TimeUnit unit)
            throws InterruptedException {
        return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout));
    }

    /**
     * 释放 permit，将其返回给信号量。
     *
     * 释放 permit，将可用 permit 数量加一。如果任何线程试图获取 permit，则选择一个
     * 线程给予刚释放的 permit。出于线程调度目的，该线程（重新）启用。
     *
     * 不要求线程必须先调用 acquire 获得 permit，之后才能 release 释放 permit。
     * 信号量的正确使用是通过应用程序中的编程约定建立的。
     */
    public void release() {
        sync.releaseShared(1);
    }

    /**
     * 从信号量中获取给定数量的 permits，阻塞直到有足够数量的 permits 可用，线程中断
     * 则终止。
     *
     * 获取给定数量的 permits，如果可用则立即返回 true，并将可用 permits 的数量减去
     * 给定的数量。
     *
     * 如果没有可用的 permits，或可用 permits 数量不足，则处于线程调度目的，当前线程将
     * 被禁用并处于休眠状态，直到发生以下量种情况下之一：
     * - 其他一些线程调用此信号量的 release 方法，并且当前线接下来获得足够数量的 permits；或者
     * - 其他线程中断当前线程。
     *
     * 如果当前线程：
     * - 在进入此方法时设置其中断状态；或者
     * - 在等待过程中被中断。
     *
     * 然后抛出InterruptedException并清除当前线程的中断状态。将分配给当前线程的 permits
     * 改为分配给尝试获取 permit 的其他线程，就好像通过调用 release() 使 permits 可用
     * 一样。
     *
     * 参数：permits - 获得的 permits 数量
     * @throws InterruptedException - 如果当前线程被中断
     * @throws IllegalArgumentException – 如果permits是负数
     */
    public void acquire(int permits) throws InterruptedException {
        if (permits &lt; 0) throw new IllegalArgumentException();
        sync.acquireSharedInterruptibly(permits);
    }

    /**
     * 从信号量获取给定数量的 permits，阻塞直至所有的 permits 可用。
     *
     * 获取给定数量的 permits，如果存在可用会立即返回，并将可用 permits 减去给定数量。
     *
     * 如果没有可用的 permits，或可用的 permits 不足则处于线程调度目的，当前线程将被禁
     * 用并处于休眠状态，直到某个其他线程调用此信号量的 release 方法并且当前线程被分配
     * 到足够数量可用的 permits。
     *
     * 如果当前线程在等待 permits 时发生中断，那么它将继续等待，并且它在队列中的位置不受
     * 影响。当线程确实从此方法返回时，将设置其中断状态。
     *
     * 参数：permits - permits 数量
     * @throws IllegalArgumentException - 如果 permits 为负数
     */
    public void acquireUninterruptibly(int permits) {
        if (permits &lt; 0) throw new IllegalArgumentException();
        sync.acquireShared(permits);
    }

    /**
     * 仅当调用时有给定数量的 permits 可用时，才从此信号量中获取到给定数量的 permits。
     *
     * 获取给定数量的 permits，如果存在可用会立即返回，并将可用 permit 减去给定数量。
     * 
     * 如果可用的 permits 不足，则此方法立即返回 false，并且可用 permits 数量不变。
     *
     * 即使次信号量已设置为公平排序策略，对于 tryAcquire() 的调用也会立即获得
     * permit（如果可用），无论其他线程当前是否正在等待。这种“闯入”行为在某些情况下
     * 可能很有用，即使它破坏了公平性。如果要尊重公平设置，请使用几乎等效的
     * tryAcquire(permits, 0, TimeUnit.SECONDS)（它也会检测中断）。
     *
     * 参数：permits - 获取的 permits 数量
     * 返回：如果获得了 permit，则为 true，否则为 false
     * @throws IllegalArgumentException - 如果 permits 为负数
     */
    public boolean tryAcquire(int permits) {
        if (permits &lt; 0) throw new IllegalArgumentException();
        return sync.nonfairTryAcquireShared(permits) &gt;= 0;
    }

    /**
     * 如果在给定超时时间内没有中断，且有足够的 permits 可用，则从信号量中获取 permits。
     *
     * 获取给定数量的 permits，如果存在足够数量可用则立即返回 true，并将可用 permits 的
     * 数量减去给定数值。
     *
     * 如果没有足够可用的 permits，则处于线程调度目的，当前线程将被禁用并处于休眠状态，直到
     * 发生以下三种情况下之一：
     * - 其他一些线程调用此信号量的 release 方法，并且当前线接下来获得足够数量 permits；或者
     * - 其他线程中断当前线程；或者
     * - 超过指定的超时时间。
     *
     * 如果获得 permits，则返回 true。
     *
     * 如果当前线程：
     * - 在进入此方法时设置其中断状态；或者
     * - 在等待过程中被中断。
     *
     * 然后抛出InterruptedException并清除当前线程的中断状态。将分配给当前线程的 permits
     * 改为分配给尝试获取 permit 的其他线程，就好像通过调用 release() 使 permits 可用
     * 一样。
     *
     * 如果经过指定的等待时间，则返回 false。如果时间小于等于零，则该方法不会等待。
     * 参数：permits - 获得的 permits 数量
     *      timeout - 等待 permit 的最大时间
     *      unit - timeout 参数的时间单位
     * 返回：如果已经获得 permits，则为 true；如果获得之前超过等待时间，则为 false。
     * @throws InterruptedException - 如果当前线程被中断
     * @throws IllegalArgumentException - 如果 permits 为负数
     */
    public boolean tryAcquire(int permits, long timeout, TimeUnit unit)
            throws InterruptedException {
        if (permits &lt; 0) throw new IllegalArgumentException();
        return sync.tryAcquireSharedNanos(permits, unit.toNanos(timeout));
    }

    /**
     * 释放给定数量的 permits，将其返回给信号量。
     *
     * 释放给定数量的 permits，将可用 permits 数量加上改数量。如果任何线程试图获取
     * permit，则选择一个线程给予刚释放的 permits。如果可用 permits 的数量满足该
     * 线程的要求，处于线程调度目的，该线程（重新）启用；否则线程将等待直到有足够的
     * permits 可用。如果在满足该线程的请求后仍然有可用的 permits，则这些 permits
     * 将依次分配给试图获取 permits 的线程。
     *
     * 不要求线程必须先调用 acquire 获得 permits 之后才能 release 释放 permits。
     * 信号量的正确使用是通过应用程序中的编程约定建立的。
     *
     * 参数：permits - 释放的 permits 数量
     * @throws IllegalArgumentException - permits 为负数
     */
    public void release(int permits) {
        if (permits &lt; 0) throw new IllegalArgumentException();
        sync.releaseShared(permits);
    }

    /**
     * 返回此信号量当前可用的 permits 数量。
     *
     * 此方法通常用于调试和测试。
     *
     * 返回：此信号量中可用的 permit 数量
     */
    public int availablePermits() {
        return sync.getPermits();
    }

    /**
     * 获取并返回当前所有的 permits。
     *
     * 返回：获得的 permits 数量
     */
    public int drainPermits() {
        return sync.drainPermits();
    }

    /**
     * 按照指定的 reduction 减少可用 permits 数量。此方法在使用信号量来跟踪
     * 子类中资源变得不可用情况会很有用。此方法与 acquire 的不同之处在于它不会
     * 阻塞等待 permits 可用。
     *
     * 参数：reduction - 移除的 permits 数量
     * @throws IllegalArgumentException - 如果 reduction 为负数
     */
    protected void reducePermits(int reduction) {
        if (reduction &lt; 0) throw new IllegalArgumentException();
        sync.reducePermits(reduction);
    }
}
</code></pre>
<p>其他一些用于监控的非核心方法不再展示。</p>
<h3 id="84-countdownlatch">8.4 CountDownLatch</h3>
<p>一种同步辅助工具，允许一个或多个线程等待，知道在其他线程中执行的一组操作完成。</p>
<p><code>CountDownLatch</code> 使用给定的 <em>计数（count）</em> 进行初始化。调用 <code>await</code> 方法将会一直阻塞，直到调用 <code>countDown</code> 方法将当前计数减少到零，只有所有等待的线程都被释放，任何后续的 <code>await</code> 方法调用将会立即返回。这是一次性使用的现象——计数是无法重置的。如果你需要能够重置计数的版本，请考虑使用 <code>CyclicBarrier</code>。</p>
<p><code>CountDownLatch</code> 是一种多功能同步工具，可用于多种用途。使用计数 1 初始化的 <code>CountDownLatch</code> 可以用作简单的开/关闩锁：所有调用 <code>await</code> 方法的线程都将在门处等待，直到它被调用 <code>countDown</code> 方法线程打开门。初始化为 N 的 <code>CountDownLatch</code>  可用于使一个线程等待，直到 N 个线程完成某个动作，或某个动作完成 N 次。</p>
<p><code>CountDownLatch</code> 的一个有用属性是它不需要调用 <code>countDown</code> 的线程等待计数变为零才能继续，它只是阻塞调用 <code>await</code> 方法的线程，直到所有线程都可以通过。</p>
<p><strong>示例用法：</strong> 这是一对类，其中一组工作线程使用两个 <code>CountDownLatch</code>：</p>
<ul>
<li>第一个是启动信号，它阻塞任何 worker 继续前进，直到 driver 准备好让他们继续。</li>
<li>第二个是完成信号，允许 driver 程序等待所有 worker 完成。</li>
</ul>
<pre><code class="language-java">class Driver {
  void main() throws InterruptedException {
    CountDownLatch startSignal = new CountDownLatch(1);
    CountDownLatch doneSignal = new CountDownLatch(N);
    
    for (int i = 0; i &lt; N; ++i) { // create and start threads
      new Thread(new Worker(startSignal, doneSignal)).start();
    }
    
    doSomethingElse(); // don't let run yet
    startSignal.countDown(); // let all threads proceed
    doSomethingElse(); 
    doSignal.await(); // wait for all to finish
  }
}

class Worker implements Runnable {
  private final CountDownLatch startSignal;
  private final CountDownLatch doneSignal;
  Worker(CountDownLatch startSignal, CountDownLatch doneSignal) {
    this.startSignal = startSignal;
    this.doneSignal = doneSignal;
  }
  
  public void run() {
    try {
      startSignal.await();
      doWork();
      doneSignal.countDown();
    } catch (InterruptedException ex) {} //return;
  }
  
  void doWork() { ... }
}
</code></pre>
<p>另一个典型的用法是将一个问题分成 N 个部分，用一个 <code>Runnable</code> 描述每个部分，该 <code>Runnable</code> 执行该部分并在完成后进行 <code>countDown</code> 操作，并将所有 <code>Runnables</code> 排队到一个 <code>Executor</code>。当所有的子任务执行完成后，协调线程就可以在 <code>await</code> 状态中被释放。（当线程必须以这种方式重复使用 <code>countDown</code> 时，请改用 <code>CyclicBarrier</code>）</p>
<pre><code class="language-java">class Driver2 { // ...
  void main() throws InterruptedException {
    CountDownLatch doneSignal = new CountDownLatch(N);
    Executor e = ...
    
    for (int i = 0; i &lt; N; ++i) { // create and start threads
      e.execute(new WorkerRunnable(doneSignal, i));
    }
    
    doneSignal.await(); // wait for all to finish
  }
}

class WorkRunnable implements Runnable {
  private final CountDownLatch doneSignal;
  private final int i;
  WorkerRunnable(CountDownLatch doneSignal, int i) {
    this.doneSignal = doneSignal;
    this.i = i;
  }
  
  public void run() {
    try {
      doWork(i);
      doneSignal.countDown();
    } catch (InterruptedException ex) {} // return;
  }
  
  void doWork() { ... }
}
</code></pre>
<p>内存一致性影响：直到计数到达零，调用 <code>countDown()</code> 之前的线程中的动作 <code>happen-before</code> 在另一个线程中从相应的 <code>await()</code> 成功返回之后的动作。</p>
<h4 id="841-sync">8.4.1 Sync</h4>
<p><code>CountDownLatch</code> 的同步控制。使用 <code>AQS</code> 状态来表示计数</p>
<pre><code class="language-java">private static final class Sync extends AbstractQueuedSynchronizer {
    private static final long serialVersionUID = 4982264981922014374L;

    Sync(int count) {
        setState(count);
    }

    int getCount() {
        return getState();
    }

    protected int tryAcquireShared(int acquires) {
        return (getState() == 0) ? 1 : -1;
    }

    protected boolean tryReleaseShared(int releases) {
        // Decrement count; signal when transition to zero
        for (;;) {
            int c = getState();
            if (c == 0)
                return false;
            int nextc = c-1;
            // CAS 递减，为零返回 true
            if (compareAndSetState(c, nextc))
                return nextc == 0;
        }
    }
}
</code></pre>
<h4 id="842-await-countdown">8.4.2 await &amp; countDown</h4>
<pre><code class="language-java">public class CountDownLatch {
    private final Sync sync;

    /**
     * 使用给定的计数初始化 CountDownLatch。
     *
     * 参数：count - 在线程可以通过 await 之前必须调用 countDown 的次数
     * @throws IllegalArgumentException - 如果 count 为负数
     */
    public CountDownLatch(int count) {
        if (count &lt; 0) throw new IllegalArgumentException(&quot;count &lt; 0&quot;);
        this.sync = new Sync(count);
    }

    /**
     * 阻塞当前线程，使其等待，直到 CountDownLatch 计数器为零，线程中断则终止。
     *
     * 如果当前计数为零，则此方法立即返回。
     *
     * 如果当前计数大于零，出于线程调度目的，当前线程将被禁用并处于休眠状态，直到以下
     * 两种情况下之一发生：
     * - 由于调用了 countDown 方法，计数达到零；或者
     * - 其他一些线程中断当前线程。
     *
     * 如果当前线程：
     * - 在进入此方法时设置其中断状态；或者
     * - 等待过程中被中断。
     *
     * 然后抛出InterruptedException并清除当前线程的中断状态。
     *
     * @throws InterruptedException - 如果当前线程在等待中被中断
     */
    public void await() throws InterruptedException {
        sync.acquireSharedInterruptibly(1);
    }

    /**
     *
     * 阻塞当前线程，使其等待，直到 CountDownLatch 计数器为零，或到达指定的等待时间，
     * 线程中断则终止。
     *
     * 如果当前计数为零，则此方法立即返回 true。
     *
     * 如果当前计数大于零，出于线程调度目的，当前线程将被禁用并处于休眠状态，直到以下
     * 三种情况下之一发生：
     * - 由于调用了 countDown 方法，计数达到零；或者
     * - 其他一些线程中断当前线程；或者
     * - 达到指定的等待时间。
     * 
     * 如果计数到达零，则该方法返回 true。
     *
     * 如果当前线程：
     * - 在进入此方法时设置其中断状态；或者
     * - 等待过程中被中断。
     *
     * 然后抛出InterruptedException并清除当前线程的中断状态。
     * 
     * 如果经过了指定的等待时间，则返回 false。如果时间小于或等于零，则该方法不会等待。
     * 
     * 
     * 参数：timeout - 等待的最长时间
     *      unit - timeout参数的单位
     * 返回：如果计数到达零，则返回 true；如果在计数到达零之前超过的等待时间，则返回 false
     * @throws InterruptedException - 如果当前线程在等待中被中断
     */
    public boolean await(long timeout, TimeUnit unit)
            throws InterruptedException {
        return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout));
    }

    /**
     * 减少 CountDownLatch 的计数，如果计数达到零，则释放所有等待线程。
     *
     * 如果当前计数大于零，则递减。如果新计数为零，出于线程调度重启所有等待线程。
     *
     * 如果当前计数为零，则不会发生任何事情。
     */
    public void countDown() {
        sync.releaseShared(1);
    }
}
</code></pre>
<h3 id="85-cyclicbarrier">8.5 CyclicBarrier</h3>
<p>一种同步辅助工具，它允许一组线程相互等待以达到共同的障碍点。<code>CyclicBarriers</code> 在涉及固定大小的线程组的程序中很有用，这些线程组必须偶尔相互等待。屏障被称为 <code>循环（Cyclic）</code> 的，因为它们可以在等待线程被释放后重新使用。</p>
<p><code>CyclicBarrier</code> 支持一个可选的 <code>Runnable</code> 命令，该命令在每个屏障点运行一次，在最后一个线程到达之后，但是在任何线程被释放之前。此屏障操作对于在任何一方继续执行之前更新共享状态很有用。</p>
<p><strong>示例用法：</strong> 以下是在并行分解设计中使用屏障的示例：</p>
<pre><code class="language-java">class Solver {
  final int N;
  final float[][] data;
  final CyclicBarrier barrier;
  
  class Worker implements Runnable {
    int myRow;
    Worker(int row) { myRow = row; }
    public void run() {
      while (!done()) {
        processRow(myRow);
        
        try {
          barrier.await();
        } catch (InterruptedException ex) {
          return;
        } catch (BrokenBarrierException ex) {
          return;
        }
      }
    }
  }
  
  public Solver(float[][] matrix) {
    data = matrix;
    N = matrix.length;
    Runnable barrierAction = new Runnable() {
      public void run() {
        margeRows(...);
      }
    };
    barrier = new CyclicBarrier(N, barrierAction);
    
    List&lt;Thread&gt; threads = new ArrayList&lt;Thread&gt;(N);
    for (int i = 0; i &lt; N; i++) {
      Thread thread = new Thread(new Worker(i));
      threads.add(thread);
      thread.start();
    }
    
    // wait until done
    for (Thread thread : threads) {
      thread.join();
    }
  }
}
</code></pre>
<p>在这里，每个工作线程处理矩阵的一行，然后在屏障处等待，直到处理完所有行。处理完所有行后，将执行提供的 <code>Runnable</code> 屏障操作，合并矩阵行。如果合并已经确定完成，那 <code>done()</code> 方法会返回 true ，每个工作线程将会终止。</p>
<p>如果 barrier action 在执行时不依赖于被挂起的各个线程，那么该方法中的任何线程都可以在它被释放时执行该动作。为了方便起见，每次调用 <code>await</code> 都会返回该线程在屏障处到达的索引。然后，您可以选择那个线程应该执行 barrier action，例如：</p>
<pre><code class="language-java">if (barrier.await() == 0) {
  // log the completion of this iteration
}
</code></pre>
<p><code>CyclicBarrier</code> 对失败的同步尝试使用 <code>all-or-none</code> 模型：如果线程由于中断、故障或超时而过早地离开屏障点，则在该屏障点等待的所有其他线程也会通过 <code>BrokenBarrierException</code>（或者如果它们也在同时被中断，抛出<code>InterruptedException</code> ）。</p>
<p>内存一致性效果：在调用 <code>await()</code> 之前线程中的操作 happen-before 作为 barrier action 的一部分的操作，而这些操作又 happen-before 从其他线程中的相应 <code>await()</code> 成功返回之后的操作。</p>
<h4 id="851-generation">8.5.1 Generation</h4>
<p>屏障的每次使用都会表现为 <code>generation</code> 实例。每当屏障被触发或重置时，<code>generation</code> 就会发生变化。可能有许多 <code>generation</code> 与使用屏障的线程相关联 —— 由于锁定可能会以不确定的方式分配给等待线程 —— 但一次只能使其中一个 <code>generation</code> 处于活动状态（count 使用的那个）并且所有其余的线程要么 broken，要么 trip（可能是指阻塞？）。如果有中断带没有后续重置，则不需要活动的 <code>generation</code>。</p>
<pre><code class="language-java">private static class Generation {
    boolean broken = false;
}
</code></pre>
<h4 id="852-实现详解">8.5.2 实现详解</h4>
<pre><code class="language-java">public class CyclicBarrier {

    // 忽略 Generation Class

    /** 用户保护屏障入口的锁 */
    private final ReentrantLock lock = new ReentrantLock();
    /** 等待直到 triped 的 condition */
    private final Condition trip = lock.newCondition();
    /** 分片数量 */
    private final int parties;
    /* tripped 时执行的命令 */
    private final Runnable barrierCommand;
    /** 当前 generation */
    private Generation generation = new Generation();

    /**
     * 仍在等待的 parties 数量。每个 generation 都会讲 parties 减少到 0。
     * 每次生成新的 generation 或 broken 时会重置。
     */
    private int count;

    /**
     * 更新屏障 trip 状态，并唤醒全部。只有当持有锁才可以调用。
     */
    private void nextGeneration() {
        // signal completion of last generation
        trip.signalAll();
        // set up next generation
        count = parties;
        generation = new Generation();
    }

    /**
     * 设置当前的 generation 为 broken，并唤醒全部。只有当持有锁才可以调用。
     */
    private void breakBarrier() {
        generation.broken = true;
        count = parties;
        trip.signalAll();
    }

    /**
     * 屏障的主要代码，涵盖各种策略。
     */
    private int dowait(boolean timed, long nanos)
        throws InterruptedException, BrokenBarrierException,
               TimeoutException {
        // 屏障入口，先获得锁
        final ReentrantLock lock = this.lock;
        lock.lock();
        try {
            // 获取当前的 generation
            final Generation g = generation;

            // 判断当前是否 broken，抛出异常
            if (g.broken)
                throw new BrokenBarrierException();

            // 判断线程是否中断
            if (Thread.interrupted()) {
                breakBarrier();
                throw new InterruptedException();
            }

            // 获取当前索引
            int index = --count;
            // 当最后一个任务到达 await 屏障点时，则执行 command
            if (index == 0) {  // tripped
                // 是否执行命令，执行失败（抛出异常）则跳出等待
                boolean ranAction = false;
                try {
                    final Runnable command = barrierCommand;
                    if (command != null)
                        command.run();
                    ranAction = true;
                    // 下一个 generation，也就是重置屏障
                    nextGeneration();
                    return 0;
                } finally {
                    if (!ranAction)
                        breakBarrier();
                }
            }

            // 说明不是最后一个到达屏障的任务，需要阻塞
            // loop until tripped, broken, interrupted, or timed out
            for (;;) {
                try {
                    // 如果没有超时，则直接阻塞；存在超时时间使用超时阻塞
                    // condition 的 await 会进行 fullyRelease，释放持有的锁
                    if (!timed)
                        trip.await();
                    else if (nanos &gt; 0L)
                        nanos = trip.awaitNanos(nanos);
                } catch (InterruptedException ie) {
                    // 如果当前 generation 没有被其他线程改变，且中断
                    if (g == generation &amp;&amp; ! g.broken) {
                        // 中断屏障
                        breakBarrier();
                        throw ie;
                    } else {
                        // 即使我们没有被中断，我们也即将完成等待，所以这个中断
                        // 被认为是 “属于” 后续执行的。
                        Thread.currentThread().interrupt();
                    }
                }

                if (g.broken)
                    throw new BrokenBarrierException();

                // generation 已经更换
                if (g != generation)
                    return index;

                // 超时则中断屏障
                if (timed &amp;&amp; nanos &lt;= 0L) {
                    breakBarrier();
                    throw new TimeoutException();
                }
            }
        } finally {
            lock.unlock();
        }
    }

    /**
     * 创建一个新的 CyclicBarrier，当给定数量的 parties （线程）正在等待它时，
     * 它将触发继续执行，他将执行给定的 barrierAction，由最后一个进入屏障的线程
     * 执行。
     *
     * 参数：parties - 在屏障被触发之前必须调用 await 的线程数
     *      barrierAction - 当屏障被触发时执行的命令，如果没有动作则为 null
     * @throws IllegalArgumentException - 如果 parties 小于 1
     */
    public CyclicBarrier(int parties, Runnable barrierAction) {
        if (parties &lt;= 0) throw new IllegalArgumentException();
        this.parties = parties;
        this.count = parties;
        this.barrierCommand = barrierAction;
    }

    /**
     * 创建一个新的 CyclicBarrier，当给定数量的 parties （线程）正在等待它时，
     * 它将触发继续执行，在触发屏障继续执行时不执行预定义操作。
     *
     * 参数：parties - 在屏障被触发之前必须调用 await 的线程数
     *      barrierAction - 当屏障被触发时执行的命令，如果没有动作则为 null
     * @throws IllegalArgumentException - 如果 parties 小于 1
     */
    public CyclicBarrier(int parties) {
        this(parties, null);
    }

    /**
     * 返回触发次屏障所需的 parties 数量。
     *
     * 返回：打破此屏障需要的 parties 数量。
     */
    public int getParties() {
        return parties;
    }

    /**
     * 等到所有 parties 都在此屏障上调用 await。
     *
     * 如果当前线程不是最后到达的，处于线程调度目的，将其禁用并处于休眠状态，
     * 直到发生以下情况之一：
     * - 最后一个线程到达；或者
     * - 其他线程中断当前线程；或者
     * = 其他线程中断了任意等待线程；或者
     * - 其他线程在等待屏障时超时；或者
     * - 其他一些线程调用此屏障的 reset 方法。
     *
     * 如果当前线程：
     * - 在进入此方法时设置其中断状态；或者
     * - 等待过程中被中断
     *
     * 然后抛出 InterruptedException 并清除当前线程的中断状态。
     *
     * 如果在任何线程等待时调用屏障的 reset 方法，或者在调用 await 或在任何线程
     * 在等待时屏障时，isBroken() 为 true，则抛出 BrokenBarrierException。
     *
     * 如果任何线程在等待时被中断，那么所有其他等待的线程都会抛出 BrokenBarrierException
     * 并将屏障的 generation 的 broken 状态设置为 true。
     *
     * 如果当前线程是最后到达的线程，并且在构造函数中提供了非空的 barrierAction，则允许当前
     * 在继续之前先执行 barrierAction 操作。如果在屏障操作期间发生了异常，则该异常将在当前
     * 线程中传播，并且屏障处于 broken 状态。
     *
     * 返回：当前线程的到达索引，其中索引 getParties - 1 表示第一个到达，0表示最后一个到达
     * @throws InterruptedException - 如果当前线程在等待时被中断
     * @throws BrokenBarrierException - 如果另一个线程在当前线程等待时中断或超时，或者
     *                                  屏障被重置，或者在调用 await 时屏障被破坏，或者
     *                                  barrierAction （如果存在） 由于异常失败
     */
    public int await() throws InterruptedException, BrokenBarrierException {
        try {
            return dowait(false, 0L);
        } catch (TimeoutException toe) {
            throw new Error(toe); // cannot happen
        }
    }

    /**
     * 等到所有 parties 都在此屏障上调用 await，或达到指定的超时时间。
     *
     * 如果当前线程不是最后到达的，处于线程调度目的，将其禁用并处于休眠状态，
     * 直到发生以下情况之一：
     * - 最后一个线程到达；或者
     * - 到达指定的超时时间；或者
     * - 其他线程中断当前线程；或者
     * = 其他线程中断了任意等待线程；或者
     * - 其他线程在等待屏障时超时；或者
     * - 其他一些线程调用此屏障的 reset 方法。
     *
     * 如果当前线程：
     * - 在进入此方法时设置其中断状态；或者
     * - 等待过程中被中断
     *
     * 然后抛出 InterruptedException 并清除当前线程的中断状态。
     *
     * 如果到达指定的超时时间，则抛出 TimeoutException。如果时间小于或等于零，则
     * 该方法不会等待。
     *
     * 如果在任何线程等待时调用屏障的 reset 方法，或者在调用 await 或在任何线程
     * 在等待时屏障时，isBroken() 为 true，则抛出 BrokenBarrierException。
     *
     * 如果任何线程在等待时被中断，那么所有其他等待的线程都会抛出 BrokenBarrierException
     * 并将屏障的 generation 的 broken 状态设置为 true。
     *
     * 如果当前线程是最后到达的线程，并且在构造函数中提供了非空的 barrierAction，则允许当前
     * 在继续之前先执行 barrierAction 操作。如果在屏障操作期间发生了异常，则该异常将在当前
     * 线程中传播，并且屏障处于 broken 状态。
     *
     * 参数：timeout - 等待屏障的时间
     *       unit - timeout 的单位
     * 返回：当前线程的到达索引，其中索引 getParties - 1 表示第一个到达，0表示最后一个到达
     * @throws InterruptedException - 如果当前线程在等待时被中断
     * @throws TimeoutException - 如果到达指定的超时时间。在这种情况下，屏障将被 broken。
     * @throws BrokenBarrierException - 如果另一个线程在当前线程等待时中断或超时，或者
     *                                  屏障被重置，或者在调用 await 时屏障被破坏，或者
     *                                  barrierAction （如果存在） 由于异常失败
     */
    public int await(long timeout, TimeUnit unit)
        throws InterruptedException,
               BrokenBarrierException,
               TimeoutException {
        return dowait(true, unit.toNanos(timeout));
    }

    /**
     * 查询当前屏障是否处于 broken 状态。
     *
     * 返回：一个或多个 parties 在上次屏障重置后，由于超时或中断而使此屏障 broken，
     *      或者由于异常而导致 barrierAction 失败，则为 true；否则为 false。
     */
    public boolean isBroken() {
        final ReentrantLock lock = this.lock;
        lock.lock();
        try {
            return generation.broken;
        } finally {
            lock.unlock();
        }
    }

    /**
     * 将屏障重置为初始状态。如果任何 parties 在当前屏障处等待，他们将返回 BrokenBarrierException。
     * 请注意，由于其他原因发生 broken 后的重置可能会很复杂；线程需要以其他方式重新同步，并选择一个
     * 线程执行 reset 操作。相反，最好为后续使用创建一个新的屏障。
     */
    public void reset() {
        final ReentrantLock lock = this.lock;
        lock.lock();
        try {
            breakBarrier();   // break the current generation
            nextGeneration(); // start a new generation
        } finally {
            lock.unlock();
        }
    }

    /**
     * 返回当前在屏障处等待的 parties 数量。此方法主要用于调试和断言。
     *
     * 返回，当前在 await 中被阻塞的 parties 数量
     */
    public int getNumberWaiting() {
        final ReentrantLock lock = this.lock;
        lock.lock();
        try {
            return parties - count;
        } finally {
            lock.unlock();
        }
    }
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[《The java.util.concurrent Synchronizer Framework》原文翻译]]></title>
        <id>https://wenbozhangw.github.io/post/lesslessthe-javautilconcurrent-synchronizer-frameworkgreatergreater-yuan-wen-fan-yi/</id>
        <link href="https://wenbozhangw.github.io/post/lesslessthe-javautilconcurrent-synchronizer-frameworkgreatergreater-yuan-wen-fan-yi/">
        </link>
        <updated>2022-09-01T14:31:43.000Z</updated>
        <summary type="html"><![CDATA[<h2 id="摘要">摘要</h2>
<p>在 J2SE1.5 的 <code>java.util.concurrent</code>包（下面简称为 <code>j.u.c</code> 包 ）中，大多数的同步器（例如锁、栅栏等。）都是使用基于 <code>AbstractQueuedSynchronizer</code>类（下面简称为 <code>AQS</code> 类），这个简单的小型框架构建的。这个框架提供了原子管理同步状态、线程的阻塞和解除阻塞、以及排队的通用机制。本文描述了该框架的基本原理、设计、实现、使用和性能。</p>
]]></summary>
        <content type="html"><![CDATA[<h2 id="摘要">摘要</h2>
<p>在 J2SE1.5 的 <code>java.util.concurrent</code>包（下面简称为 <code>j.u.c</code> 包 ）中，大多数的同步器（例如锁、栅栏等。）都是使用基于 <code>AbstractQueuedSynchronizer</code>类（下面简称为 <code>AQS</code> 类），这个简单的小型框架构建的。这个框架提供了原子管理同步状态、线程的阻塞和解除阻塞、以及排队的通用机制。本文描述了该框架的基本原理、设计、实现、使用和性能。</p>
<!-- more -->
<h2 id="类别和主题描述符">类别和主题描述符</h2>
<p><strong>D.1.3 [编程技术]</strong>：并发编程 —— 并行编程</p>
<h2 id="一般术语">一般术语</h2>
<p>算法、策略、性能、设计。</p>
<h2 id="关键字">关键字</h2>
<p>同步，Java</p>
<h2 id="1-介绍">1. 介绍</h2>
<p>Java<sup>TM</sup> 发布版本 J2SE-1.5 引入了 <code>j.u.c</code> 包，这是通过 JCP （Java社区进程）的 JSR（Java规范请求）166 规范创建的，这个包提供了支持中等并发成都的并发类合集。这些组件包括一组<em>同步器</em>——维护内部<em>同步状态</em>（例如，表示锁的状态是获取还是释放）的抽象数据类型（ADT）类、更新和检查该状态的操作。以及至少会有一个方法会导致调用现存在同步状态被获取时阻塞，并在其他线程更改同步状态时解除阻塞。实例包括各种形式的互斥锁、读写锁、信号量、屏障、Future、时间指示器和传送队列等（exclusion locks, read-write locks, semaphores, barriers, futures, event indicators, and handoff queues）。</p>
<p>众所周知，几乎任何同步器都可以用于实现其他形式的同步器。例如，可以用可重入锁实现信号量，反之亦然。然而，这样做通常会增加复杂性、开销和不灵活性，使其至多只能是个二流工程。且缺乏吸引力。此外，它在概念上没有吸引力。如果任何这样的构造方式不能在本质上比其他形式更简洁，那么开发者就不应该随意地选择其中的某个来作为基础构建另一个同步器。取而代之，JSR166 建立了一个以 <code>AQS</code> 类为中心的小型框架，它为用户自定构造器以及<code>j.u.c</code> 包中大多数提供的同步器提供了一种通用的机制。</p>
<p>本文的其余部分将讨论该框架的需求、设计和实现背后的主要思想、示例用法以及一些性能指标的测量。</p>
<h2 id="2-需求">2 需求</h2>
<h3 id="21-功能">2.1 功能</h3>
<p>同步器有一般包含两种方法：一种是 <code>acquire</code> 操作 ，用于阻塞调用的线程，除非/直到同步状态允许它继续；另一种是 <code>release</code> 操作，用于通过某种方式改变同步状态，以允许一个或多个被 <code>acquire</code> 的线程解除阻塞。</p>
<p><code>j.u.c</code> 包没有为同步器定义一个统一的 API。有些是通过公共接口定义的（例如，Lock），而另外一些则定义了其特有的版本。因此，在不同的类中，<code>acquire</code> 和 <code>release</code> 操作的名字和形式会有不同。例如：<code>Lock.lock</code>、<code>Semaphore.acquire</code>、<code>CountDownLatch.await</code> 和 <code>FutureTask.get</code>，在这个框架里，这些方法都是 <code>acquire</code> 操作。但是，<code>j.u.c</code>包确实保持了跨类的一致约定，以支持一系列常见的使用选项。如果有意义，每个同步器都支持以下操作：</p>
<ul>
<li>非阻塞同步尝试（例如，<code>tryLock</code>）以及阻塞版本。</li>
<li>可选超时，因此应用程序可以放弃等待。</li>
<li>通过中断实现任务取消，通常分为可取消的 <code>acquire</code> 版本和不可取消的 <code>acquire</code> 版本。</li>
</ul>
<p>同步器可能根据它们是否管理  <em>exclusive</em> 状态 （一次只有一个线程可以通过阻塞点）和可能的 <em>shared</em> 状态（多个线程至少在某些情况下可以继续）而有所不同。当然，常规的锁类往往只维护 <em>exclusive</em> 状态，但是计数信号量在数量许可的情况下，允许多个线程同时执行。为了使框架使用能够更加广泛，这两种模式都要支持。</p>
<p><code>j.u.c</code> 包还定义了 <code>Condition</code> 接口，用于支持监控形式的 await/singal 操作，这些操作可能与独占的 <code>Lock</code> 类相关联，并且其本质上与其相关 <code>Lock</code> 类交织在一起。</p>
<h3 id="22-性能目标">2.2 性能目标</h3>
<p>Java 内置锁（使用 <code>synchronized</code> 的方法或代码块）的性能问题长期以来一直被人们关注，有关它们的构造有相当多的文献（例如，[<a href="#1">1</a>]、[<a href="#3">3</a>] ）。然而，大部分的研究主要关注的是在单核处理器上，大部分时间使用与单线程上下文环境中，如何尽量降低其空间（因为任何 Java 对象都可以充当锁）和时间的开销。对于同步器来说，这两个都不是特别重要的问题：程序员仅在需要的时候才会使用同步器，因此并不需要压缩空间来避免浪费，并且同步器几乎只用于多线程设计（特别是在多核处理器上），在这种设计下，偶尔的竞争是在意料之中的。因此，常规的 JVM 锁优化策略主要是针对零竞争的场景，而其他场景则使用缺乏可预测的”慢速路径（slow paths）“[<a href="#12">12</a>]，对于严重依赖 <code>j.u.c</code> 的典型多线程服务器应用程序来说，这不是正确的策略选择。</p>
<p>相反，这里的主要性能目标是可伸缩性：即使在同步器发生竞争的情况下，也要可预测地保持效率。理想情况下，不管有多少线程试图通过同步点，通过同步点所需的开销应该是恒定的。其中一个主要目标是，在某一线程被允许通过同步点但还没有通过的情况下，使其耗费的总时间最少。但是，者必须与资源考虑相平衡，包括总的 CPU 时间需求、内存流量和线程调度开销。例如，自旋锁通常比阻塞锁所需要的时间更短，但是通常也会浪费 CPU 时钟周期，并且造成内存竞争，因此通常不适用。</p>
<p>实现同步器的这些目标包含了两种不同的使用类型。大多数应用程序应该最大限度地提高总吞吐量和容错性，并且最好保证尽量减少接的情况。然而，对于那些控制资源分配的程序来说，更重要的是去维持多线程读取的公平性，可以接受较差的总吞吐量。没有框架能够代表用户在这些冲突的目标之前做出决定；相反，必须适应不同的公平策略。</p>
<p>无论同步器内部设计得多么好，在某些应用程序中都会产生性能瓶颈。因此，框架必须能够监控和检查基本操作，以允许用户发现和缓解瓶颈。这至少（也是最有用的）需要提供一种方法来确定有多少线程被阻塞。</p>
<h2 id="3-设计和实现">3. 设计和实现</h2>
<p>同步器背后的基本思想非常简单。<code>acquire</code> 操作如下：</p>
<pre><code class="language-java">while(synchronization state does not allow acquire) {
  enqueue current thread if not already queued;
  possibly block current thread;
}
dequeue current thread if it was queued;
</code></pre>
<p><code>release</code> 操作如下：</p>
<pre><code class="language-java">update synchronization state;
if(state may permit a blocked thread to acquire) 
  unblock one or more queued threads;
</code></pre>
<p>为了支持上述操作，需要下面三个基本组件相互协作：</p>
<ul>
<li>同步状态的原子性原理；</li>
<li>线程的阻塞与解除阻塞；</li>
<li>队列的管理；</li>
</ul>
<p>也许可以创建一个框架，允许这三个部分各自独立变化。然而，这既不高效也不实用。例如，保存在队列节点中的信息必须与解除阻塞所需要的信息一致，而暴露出的方法签名必须依赖于同步状态的特性。</p>
<p>同步器框架中的核心设计决策是这三个组件选择一个具体实现，同时在使用方式上仍然有大量的选择可用。这有意地限制了其适用范围，但是提供了足够的效率，是的实际上没有理由在合适的情况下不用这个框架而去重新造一个。</p>
<h3 id="31-同步状态">3.1 同步状态</h3>
<p><code>AQS</code>类仅使用单个 <code>int</code>（32 bit）来保存同步状态，并暴露出 <code>getState</code>、<code>setState</code> 以及 <code>compareAndSet</code> 操作来读取和更新这个状态。这些方法都依赖于 <code>java.util.concurrent.atomic</code> 支持，这个包提供了兼容 JSR133 中 <code>volatile</code> 在读和写上的语义，并且通过使用本地的 compare-and-swap 或 load-linked/store-conditional 指令来实现 <code>compareAndSetState</code>，只有当它持有给定的期望值时，才会自动将状态设置为给定的新值。</p>
<p>将同步状态限定为 32 位 <code>int</code> 是出于实践上的考量。虽然 JSR166 也提供了 64 位 <code>long</code> 字段的原子操作，但是这些操作在很多平台上还是使用内部锁的方式来模拟实现的，以至于会使同步器的性能不佳。将来，很可能会添加第二个基类，专门用于 64 位状态（使用 <code>long</code> 控制参数）。然而，现在还没有一个令人信服的理由将其纳入计划。目前，32 位足以满足大多数应用，只有一个 <code>j.u.c</code> 同步器类 <code>CyclicBarrier</code> 需要更多的位来维护状态，所以它使用了锁（该包中大多数更高层次的 工具也是如此）。</p>
<p>基于 <code>AQS</code> 的具体类必须根据这些暴露出的状态相关的方法定义 <code>tryAcquire</code> 和 <code>tryRelease</code> 方法，以控制 <code>acquire</code> 和 <code>release</code> 操作。当同步状态满足时，<code>tryAcquire</code> 方法必须返回 <code>true</code>，而当新的同步状态允许后续 <code>acquire</code> 时，<code>tryRelease</code> 方法也必须返回 <code>true</code>。这些方法都接受一个 <code>int</code> 类型的参数，该参数可用于传递想要的状态。例如：可重入锁，当某个线程从条件等待中返回，然后重新获取锁时，为了重新建立循环计数的场景。很多同步器并不需要这样的参数，因此忽略它即可。</p>
<h3 id="32-阻塞">3.2 阻塞</h3>
<p>在 JSR166 之前，除了创建基于内置监视器的同步器，没有 Java API 可以阻塞和解锁线程。唯一可以选择的是 <code>Thread.suspend</code> 和 <code>Thread.resume</code>，但是它们都有无法解决的竟态问题，所以也没办法使用：当一个非阻塞线程在一个正准备阻塞的线程调用 <code>suspend</code> 之前调用 <code>resume</code>，<code>resume</code>操作将不起作用。</p>
<p><code>java.util.concurrent.locks</code> 包包含一个 <code>LockSupport</code> 类，其中包含解决这个问题的方法。方法 <code>LockSupport.park</code> 阻塞当前线程，除非或直到发出 <code>LockSupport.unpark</code>（虚假唤醒也是允许的） 。对 <code>unpark</code> 的调用是不 ”计数“的，所以一个 <code>park</code> 之前的多个 <code>unpark</code> 只会解除一个 <code>park</code> 操作。此外，这适用于每个线程，而不是每个同步器。一个线程在一个新的同步器上调用 <code>park</code> 操作可能会立即返回，因为在此之前可能有“剩余的” <code>unpark</code> 操作。但是，在缺少一个 <code>unpark</code> 操作时，下一次调用 <code>park</code> 就会阻塞。虽然可以显式地消除这个状态，但并不值得这样做。在需要的时候多次调用 <code>park</code> 会更高效。</p>
<p>这个简单的机制在某种程度上类似于 Solaris-9 的线程库 [<a href="#11">11</a>]，WIN32的 “可消费事件”，以及 Linux 中的 NPTL 线程库，因此最常见的运行 Java 的平台上都有相对应的有效实现，（但目前 Solaris 和 Linux 上的 Sun Hotspot JVM 参考实现实际上是使用一个 pthread 的 condvar 来适应目前的运行时设计的）。<code>park</code> 方法同样支持可选的相对或绝对的超时设置，以及与 JVM 的 <code>Thread.interrupt</code> 结合 —— 可通过中断来 <code>unpark</code> 一个线程。</p>
<h3 id="33-队列">3.3 队列</h3>
<p>整个框架的核心是维护阻塞线程的队列，这里仅限于 FIFO 队列。因此，该框架不支持基于优先级的同步。</p>
<p>如今，对于同步队列最合适的选择是不需要使用低级锁来构造的非阻塞数据结构，这一点几乎没有争议。其中，有两个主要的候选：一个是 Mellor-Crummey 和 Scott锁（MCS锁）[<a href="#9">9</a>] 的变体，另一个是Craig，Landin 和 Hagersten锁（CLH锁）[<a href="#5">5</a>] [<a href="#8">8</a>] [<a href="#10">10</a>]的变体。一直以来，CLH 锁只用于旋转锁。然而，它们似乎比 MCS 更适合在同步框架器中使用，因为它们更容易处理取消和超时，所以作为实现的基础。最终的设计与最初的 CLH 结构相差甚远，因此下文将对此做出解释。</p>
<p>CLH 队列实际上并不是很像队列，因为它的入队和出队操作都与它的用途（即用作锁）紧密相关。他是一个链表队列，通过两个字段 <code>head</code> 和 <code>tail</code> 来存取，这两个字段支持原子更新，两者在初始化时都指向了空节点。</p>
<figure data-type="image" tabindex="1"><img src="https://wenbozhangw.github.io//post-images/1662043146964.png" alt="CLHNode" loading="lazy"></figure>
<p>一个新节点，<code>node</code>，通过一个原子操作入队：</p>
<pre><code class="language-java">do {
    pred = tail;
} while (!tail.compareAndSet(pred, node));
</code></pre>
<p>每一个节点的 <code>release</code> 状态都保存在其前驱节点中。因此，自旋锁的“自旋”操作如下：</p>
<pre><code class="language-java">while (pred.status != RELEASED); // spin
</code></pre>
<p>自旋后的出队操作只需将 <code>head</code> 字段指向刚刚得到锁的节点：</p>
<pre><code class="language-java">head = node
</code></pre>
<p>CLH 锁的优点之一是：其入队和出队操作是快速的、无锁的、无阻塞的（即使在竞争情况下，也只会有一个线程赢得插入机会，从而能继续进行）；检测是否有线程在等待也很快（只需要检测 <code>head</code> 和 <code>tail</code> 是否相等）；同时，<code>release</code> 是分散的，避免了一些不必要的内存竞争。</p>
<p>在 CLH 锁的原始版本中，节点之间甚至都没有链接。在自旋锁中，<code>pred</code> 变量可以作为局部变量保存。然而，Scott 和 Scherer [<a href="#10">10</a>] 证明，通过在节点中显式的维护 <code>pred</code> 字段，CLH 锁可以处理超时和各种形式的取消：如果节点的前驱结点取消，节点可以滑动去使用前一个节点的状态字段。</p>
<p>使用 CLH 队列阻塞同步器，需要做的主要修改是提供一种高效的方式定位某个节点的后继节点。在自旋锁中，一个节点只需要改变其状态，下一次自旋中其后继节点就能注意到这个改变，所有节点间的链接操作并不是必须的。但是在阻塞同步器中，一个节点需要显式地唤醒（<code>unpark</code>）其后继节点。</p>
<p><code>AQS</code> 队列的节点包含一个 <code>next</code> 链接到它的后继节点。但是，由于没有针对双向链表节点的类似 <code>compareAndSet</code> 的原子性无锁插入指令，因此这个 <code>next</code> 链接的设置并非作为原子性插入操作的一部分，而仅是在节点被插入后简单赋值：</p>
<pre><code class="language-java">pred.next = node;
</code></pre>
<p>这反映在所有的用法中。<code>next</code> 链接仅是一种优化。如果一个节点的后继节点通过它的 <code>next</code> 字段看起来不存在（或看起来被取消了），总是可以从尾部开始，使用 <code>pred</code> 字段向前遍历来检查是否真的有后继节点。</p>
<p>第二组修改是使用保存在每个节点中的状态字段来控制阻塞，而非自旋。在同步器框架中，仅在线程调用具体子类的 <code>tryAcquire</code> 方法返回 <code>true</code> 时，队列中的线程才能从 <code>acquire</code> 操作中返回；而单个 <code>release</code> 位是不够的。但是仍然需要控制，以确保活动线程只允许在队列的头部调用 <code>tryAcquire</code>；在这种情况下，<code>acquire</code> 可能会失败，然后（重新）阻塞。这种情况不需要读取状态标识，因为可以通过检查当前节点的前驱是否为 <code>head</code> 来确定权限。与自旋锁不同，这里会读取 <code>head</code>  的副本以保证不会有太多的内存竞争。但是，取消状态必须仍然存在于状态字段中。</p>
<p>队列节点的状态字段还用于避免不必要的 <code>park</code> 和 <code>unpark</code> 调用。虽然这些方法相对于阻塞原语来说比较快，但是它们在跨 Java 和 JVM 运行时和/或操作系统边界时仍有可避免的开销。在调用 <code>park</code> 之前，线程设置一个 “唤醒（signal me）” 位，然后再次检查同步和节点状态。一个释放的线程会清空其自身状态。这样线程就不必频繁地尝试阻塞，尤其对于锁类，在这些锁类中，等待下一个合格线程获取锁的时间会加重其他竞争。除非后继线程已经设置了 <code>signal</code> 位，否则这也可以避免正在 <code>release</code> 的线程去判断其后继节点。这也消除了除非 <code>signal</code> 和 <code>cancel</code> 一起发生，否则必须遍历多个节点来处理明显为空的 <code>next</code> 字段的情况。</p>
<p>同步器框架中使用的 CLH 锁的变体与其他语言中使用的变体之间的主要区别可能是，依靠垃圾收集来挂你节点的存储回收，这避免了复杂性和开销。然而，即使依赖 GC，也仍然需要在确定链接字段永远不会被需要时，将其置为 null。这往往可以与出队操作一起完成。否则，无用的节点仍然可达，就导致它们不可回收。</p>
<p>J2SE1.5 版本的源代码文档中描述了一些更进一步的微调，包括 CLH 队列在第一次争用时所需的初始空节点的延迟初始化等。</p>
<p>抛开这些细节，基本的 <code>acquire</code> 操作的最终实现的一般形式如下（互斥，非中断，无超时）：</p>
<pre><code class="language-java">if (!tryAcquire(arg)) {
    node = create and enqueue new node;
    pred = node's effective predecessor;
    while (pred is not head node || !tryAcquire(arg)) {
        if (pred's signal bit is set)
            park()
        else 
            compareAndSet pred's signal bit to true;
        pred = node's effective predecessor;
    }
    head = node;
}
</code></pre>
<p><code>release</code> 操作：</p>
<pre><code class="language-java">if (tryRelease(arg) &amp;&amp; head node's signal bit is set) {
	compareAndSet head's signal bit to false;
    unpark head's successor, if one exists
}
</code></pre>
<p><code>acquire</code> 操作的主循环次数依赖于具体实现类中 <code>tryAcquire</code> 的实现方式。另一方面，在没有 <code>cancel</code> 操作的情况下，每一个组件的 <code>acquire</code> 和 <code>cancel</code> 都是在一个 O(1) 常数时间内操作，不考虑 <code>park</code> 中发生的所有操作系统线程调度。</p>
<p>支持 <code>cancel</code> 操作主要是要在 <code>acquire</code> 循环里的 <code>park</code> 返回时检查中断或超时。由于超时或中断而被取消等待的线程会设置其节点状态，然后 <code>unpark</code> 其后继节点。在有 <code>cancel</code> 的情况下，判断其前驱结点和后继节点以及重置状态可能需要 O(n) 的遍历（n 是队列的长度）。由于 <code>cancel</code> 操作，该线程再也不会被阻塞，节点的连接和状态字段可以被快速重建。</p>
<h3 id="34-条件队列">3.4 条件队列</h3>
<p>同步器框架提供了一个 <code>ConditionObject</code> 类，给维护独占同步的类以及实现 <code>Lock</code> 接口的类使用。一个锁对象可以管理任意数量的 <code>ConditionObject</code>，可以提供典型的监视器风格的 <code>await</code>、<code>signal</code> 和 <code>singalAll</code> 操作，包括那些带有超时的操作，以及一些检测和监控的方法。</p>
<p>同样是通过修正一些设计决策，<code>ConditionObject</code> 类使条件能够与其他同步操作有效地集成。该类仅支持 Java 风格的监视器访问规则，在这些规则中，只有当拥有条件的锁被当前线程持有时，条件操作才是合法的（参见 [<a href="#4">4</a>] 对替代方法的讨论）。因此，一个 <code>ConditionObject</code> 关联到一个 <code>ReentrantLock</code> 上就表现的跟内置监视器的行为方式相同（通过 <code>Object.await</code> 等），不同之处仅在与方法名、额外的功能以及用户可以为每个锁声明多个条件。</p>
<p><code>ConditionObject</code> 使用与同步器相同的内部队列节点，但在单独的条件队列中维护它们。<code>signal</code>操作是通过将节点从条件队列转移到锁队列中来实现的，而没有必要在需要唤醒的线程重新获取到锁之前将其唤醒。</p>
<p>基本的 <code>await</code> 操作如下：</p>
<pre><code class="language-java">create and add new node to condition queue;
release lock;
block until node is on lock queue;
re-acquire lock;
</code></pre>
<p><code>signal</code> 操作如下：</p>
<pre><code class="language-java">transfer the first node from condition queue to lock queue;
</code></pre>
<p>因为这些操作仅在持有锁时执行，所以它们可以使用顺序链表队列操作（在节点中使用 <code>nextWaiter</code> 字段）来维护条件队列。转移操作仅仅把第一个节点从条件队列中的链接移除，然后通过 CLH 插入操作将其插入到锁队列上。</p>
<p>实现这些操作的主要复杂性是处理由于超时或 <code>Thread.interrupt</code> 而导致的条件等待的取消。<code>cancel</code> 和 <code>signal</code>几乎同时发生就会有竞争问题，最终的结果遵照内置监视器的规范。JSR133 修订后，就要求如果中断发生在 <code>signal</code> 操作之前，<code>await</code> 方法必须在重新获取到锁后，抛出 <code>InterruptedException</code>。但是，如果中断发生在 <code>signal</code> 后，<code>await</code> 必须返回且不抛异常，同时设置线程的中断状态。</p>
<p>为了保持正确的顺序，队列节点状态变量中的一个位记录了该节点是否已经（或正在）被转移。<code>cancel</code> 和 <code>signal</code> 相关的代码都会尝试用 <code>compareAndSet</code> 修改这个状态。如果某次 <code>signal</code> 操作修改失败，就会转移队列中的下一个节点（如果存在的话）。如果某次 <code>cancel</code> 操作修改失败，就必须终止此次转移，然后等待重新获得锁。后面的情况采用了一个潜在的无限的自旋等待。在节点成功的被插入到锁队列之前，被 <code>cancel</code> 的等待不能重新获得锁，所以必须自旋等待 CLH 队列插入（即 <code>compareAndSet</code> ）成功，被 <code>signal</code> 线程成功执行。这里很少需要自旋，并且使用 <code>Thread.yield</code> 来提供一个调度提示其他线程（理想情况下是发出 <code>signal</code> 的线程）应该运行。虽然在这里可以为 <code>cancel</code> 实现一个帮助策略来插入节点，但是这种情况非常罕见，以至于无法证明这样做所带来的额外开销是合理的。在所有其他情况下，这里和其他地方的基本机制不使用自旋或<code>yield</code>，在因此在但处理器上保持了合理的性能。</p>
<h2 id="4-用例">4. 用例</h2>
<p><code>AQS</code> 类将上述功能组合在一起，并作为同步器的“模板方法模式”[<a href="#6">6</a>]基类。子类只需定义状态的检查和更新的相关方法，实现控制 <code>acquire</code> 和 <code>release</code>  操作。然而，<code>AQS</code> 的子类本身用作同步器 ADT 并不合适，因为该类必须暴露出内部内部控制 <code>acquire</code> 和 <code>release</code> 的规则，这些都不应该对用户可见。所有 <code>j.u.c</code> 包中的同步器类都声明了一个 <code>private</code> 且继承 <code>AQS</code>的内部类，并且把所有同步方法都委托给这个内部类。这样，各个同步器类的公开方法就可以使用适合自己的名称。</p>
<p>例如，这里有一个最简单的 <code>Mutex</code> 类，它使用同步状态 <code>0</code> 表示未锁定，使用同步状态 <code>1</code> 表示锁定。这个类不需要同步方法中的参数，因此这里在调用的时候使用 <code>0</code> 作为实参，方法实现里将其忽略。</p>
<pre><code class="language-java">class Mutex {
  class Sync extends AbstractQueuedSynchronizer {
    public boolean tryAcquire(int ingore) {
      return compareAndSetState(0, 1);
    }
    public boolean tryRelease(int ignore) {
      setState(0);
      return true;
    }
  }
  
  private final Sync sync = new Sync();
  
  public void lock(){
    sync.acquire(0);
  }
  public void unlock(){
    sync.release(0);
  }
}
</code></pre>
<p>这个例子的完整版本，以及其他使用指南可以在 J2SE 文档中找到。还有可以有一些其他变体。例如，<code>tryAcquire</code> 可以使用 “test-and-test-and-set” 策略，即在改变状态值之前先对状态进行校验。</p>
<p>令人诧异的是，像互斥锁这样对性能敏感的东西，也打算通过委托和虚方法结合的方式来定义。然而，这正是现代动态编译器长期关注的面向对象设计结构。它们往往擅长优化掉这种开销，起码会优化频繁调用同步器的哪些代码。</p>
<p><code>AQS</code> 类还提供了许多方法来帮助同步器类进行策略控制。例如，基础的 <code>acquire</code> 方法有可超时和可中断的版本。虽然到目前为止的讨论都集中在独占模式的同步器上（如锁），但 <code>AQS</code> 类也包含一组并行的方法（如<code>acquireShared</code>），不同之处在于 <code>tryAcquireShared</code> 和 <code>tryReleaseShared</code> 方法可以通知框架（同步它们的返回值）可以接受更多的请求，最终框架会通过级联的 <code>signal</code> 唤醒多个线程。</p>
<p>虽然序列化（持久存储或传输）同步器通常来说没有太大意义，但这些类经常被用来构造其他类，如线程安全的集合，它们通常是可序列化的。<code>AQS</code> 和 <code>ConditionObject</code> 类提供了序列化同步状态的方法，但不会序列化潜在的被阻塞的线程，也不会序列化其他内部暂时性的 bookkeeping。即使如此，在反序列化时，大部分同步器类也只是仅将同步状态重置为初始值，这与内置锁的隐式策略一直 —— 总是反序列化到一个解锁状态。这相当于一个空操作，但仍必须显式地支持以便 ·<code>final</code> 字段能够反序列化。</p>
<h3 id="41-公平调度的控制">4.1 公平调度的控制</h3>
<p>即使它们基于 FIFO 队列，同步器也不一定是公平的。请注意，在基础的 <code>acquire</code> 算法（第 3.3 节）中，<code>tryAcquire</code> 检查是在排队之前执行的。因此，新的 <code>acquire</code> 线程可以“窃取”本该属于队列头部第一个线程通过同步器的机会。</p>
<p>可 <em>闯入的FIFO</em> 策略通常比其他技术提供更高的总吞吐量。当一个存在竞争的锁已经空闲，而下一个准备获取锁的线程正在解除阻塞的过程中，此时没有线程可以获取到这个锁，如果使用<em>闯入策略</em>，则可以减少这之间的时间。与此同时，这种策略还可以避免过多的、无效的竞争（只允许一个（第一个）排队的线程被唤醒，然后尝试 <code>acquire</code> 操作导致）。如果是短时间持有同步器的场景，创建同步器的开发人员在可以通过定义 <code>tryAcquire</code> ，在控制权返回之前重复调用自己若干次，来进一步凸显<em>闯入</em>效果。</p>
<figure data-type="image" tabindex="2"><img src="https://wenbozhangw.github.io//post-images/1662043201211.png" alt="fifo" loading="lazy"></figure>
<p>可闯入的 FIFO 同步器只有概率性的公平属性。在锁队列的头部一个解除了阻塞的线程拥有一次无偏向的机会来赢得与闯入线程之间的竞争，如果竞争失败，那么要么重新阻塞，要么进行重试。然而，如果闯入的线程到达的速度比队头的线程解除阻塞更快，俺么在队列中的第一个线程将会很难赢得竞争，以及于几乎总是要重新阻塞，并且它的后继节点也会一直保持阻塞。对于短暂持有的同步器来说，在队列中第一个线程被解除阻塞的期间，多处理器上很可能发生过多次闯入和 <code>release</code>。如下文所述，最终结果就是保持一个或多个线程的高速进展的同时，在一定概率是避免了饥饿的发生。</p>
<p>当需要更高的公平性需求时，实现起来也很简单。如果需要严格的公平性，程序员可以定义 <code>tryAcquire</code> 为：如果当前线程不是队列的头结点（可以通过 <code>getFirstQueuedThread</code>方法检查这一点，这是框架提供的为数不多的几个检测方法之一），则立即返回失败（返回 <code>false</code>）。</p>
<p>一种更快、不太严格的方法是，如果队列（暂时）为空，也允许 <code>tryAcquire</code> 成功。在这种情况下，遇到空队列的多个线程可能会争取第一个获得锁，这样，通常至少有一个线程是不需要放入队列的。所有支持 <code>fair</code> 模式的 <code>j.u.c</code> 同步器都采用这种策略。</p>
<p>尽管公平性设置在实践中很有用，当时它们并没有保障，因为 Java Language Specification 没有提供这样的调度保证。例如：即使是严格公平的同步器，如果一组线程永远不需要阻塞来达到相互等待，那么 JVM 也可以决定完全按照顺序方式运行它们。实际上，在单处理上，在抢占式上下文切换之前，这样的线程有可能是各自运行了一段时间。如果这样的线程正持有某个互斥锁，它将很快被切换回来，仅仅是为了释放其持有的锁，然后会继续阻塞，因为它知道有另一个线程需要这把锁，这更增加了同步器可用但没有线程能来获取直接的间隔。同步器公平性设置在多处理器上的影响可能会更大，因为在这种环境中会产生更多的交错，因此一个线程就会有更多的机会发现锁被另一个线程请求。</p>
<p>在高度竞争的情况下，当保护短暂持有的代码体时，尽管可能性能不佳，但公平锁仍然能有效地工作。例如，当公平锁保护的是相对长的代码体和/或具有相对较长的锁间（inter-lock）间隔时，在这种情况下，闯入只能带来很小的性能优势，但却可能会大大增加无限等待的风险。同步器框架将这些工程决策留给用户来确定。</p>
<h3 id="42-同步器">4.2 同步器</h3>
<p>下面是 <code>j.u.c</code> 包中同步器定义方式的概述：</p>
<p><code>ReentrantLock</code> 类使用同步状态来保存锁（重复）持有的次数。当锁被一个线程获取时，<code>ReentrantLock</code> 也会记录下当前获得锁的线程标识，以便检查是否是重复获取，以及当前错误的线程试图进行解锁操作时检测是否存在非法状态异常。<code>ReentrantLock</code> 还是用了 <code>AQS</code> 提供的 <code>ConditionObject</code>，并向外暴露了其他监控和检查的方法。<code>ReentrantLock</code> 通过在内部声明的两个不同的 <code>AQS</code> 实现类（提供公平模式的那个回禁用 <em>闯入</em> 策略 ）来实现可选的公平模式，在创建 <code>ReentrantLock</code> 实例的时候根据配置使用相应的 <code>AQS</code> 实现类。</p>
<p><code>ReentrantReadWriteLock</code> 类使用同步状态的 16 位来保存写锁计数，剩余的 16 位保存读锁计数。<code>WriteLock</code> 在其他方面的结构与 <code>ReentrantLock</code> 相同。<code>ReadLock</code> 使用 <code>acquireShared</code> 方法来启用多个读线程。</p>
<p><code>Semaphore</code> 类（计数信号量）使用同步状态来保存当前计数。它里面定义的 <code>acquireShared</code> 方法会减少计数，或当计数为非正值时阻塞线程；<code>tryRelease</code> 方法会增加计数，如果计数现在是正数，可能还要解除线程的阻塞。</p>
<p><code>CountDownLatch</code> 类使用同步状态来表示计数。当它达到零时，所有 <code>acquire</code> 都通过。</p>
<p><code>FutureTask</code> 类使用同步状态来表示未来的运行状态（初始化、运行、取消、完成）。设置或取消一个 <code>FutureTask</code> 时，会调用 <code>AQS</code> 的 <code>release</code> 操作；等待计算结果的线程解除阻塞是通过 <code>AQS</code> 的 <code>acquire</code> 操作。</p>
<p><code>SynchronousQueue</code> 类（一种 CSP（Communication Sequential Processes）形式的传递）使用了内部的等待节点，这些节点可以用于协调生产者和消费者。同时，它使用 <code>AQS</code>  同步状态来控制当某个消费者消费前一项时，允许一个生产者继续生产，反之亦然。</p>
<p><code>j.u.c</code> 包的用户当然可以为自定义的应用定义自己的同步器。例如，那些曾考虑到过的，但没有采纳进这个包的同步器包括提供 WIN32 事件风格的语义类，binary latches、集中管理的锁以及基于树的屏障。</p>
<h2 id="5-性能">5. 性能</h2>
<p>尽管同步器框架除了互斥锁之外，还支持许多其他类型的同步方式，但锁的性能是最容易测量和比较的。即便如此，仍由许多不同的测量方法。这里的实验主要目的在于展示开销和吞吐量。</p>
<p>在每个测试中，所有线程都重复的更新一个伪随机数，该随机数由 <code>nextRandom(int seed)</code> 方法计算：</p>
<pre><code class="language-java">int t = (seed % 127773) * 16807 - (seed / 127773) * 2836;
return (t &gt; 0) ? t : t + 0x7fffffff;
</code></pre>
<p>在每次迭代中，线程以概率 S 在一个互斥锁下更新共享的生成器，否则更新其自己局部的生成器，此时是不需要锁的。因此，锁的占用是短暂的，这就会导致线程在持有锁期间被抢占时的外界干扰降到了最小。这个函数的随机性主要为了两个目的：确定是否需要使用锁（这个生成器足以应付这里的需求），以及使用循环中的代码不可能被轻易的优化掉。</p>
<p>这里比较了四种锁：内置的，用的是 <code>synchronized</code> 块；互斥锁，使用一个简单的 <code>Mutex</code> 类，如第四节所示；可重入锁，用的是 <code>ReentrantLock</code>；以及公平锁，用的是 <code>ReentrantLock</code> 的公平模式。所有测试都运行在 J2SE1.5 JDK build46（大致与beta2相同）的 server 模式下。在收集测试数据之前，测试程序执行了 20 次无竞争运行，以消除预热效应。除了公平模式测试只运行了一百万次迭代，其他每个线程测试运行一千万次迭代。</p>
<p>该测试运行在四台 X86 机器和四台 UltraSparc 机器上。所有 X86 机器都运行的是 RedHat 基于 NPTL 2.4 内核和库的 Linux 系统。所有的 UltraSparc 机器都运行的是 Solaris-9。测试时所有系统的负载都很轻。根据该测试的特征，并不要求操作系统完全空闲。“4P” 这个名字反映出双核超线程的 Xeon 更像是 4 路处理器，而不是 2 路处理器。这里没有将测试数据规范化。如下所示，同步的相对开销与处理器的数量、类型、速度之间不具备简单的关系。</p>
<center><b>表1 测试的平台</b></center>
<table>
<thead>
<tr>
<th>名字</th>
<th>处理器数量</th>
<th>类型</th>
<th>速度（Mhz）</th>
</tr>
</thead>
<tbody>
<tr>
<td>1P</td>
<td>1</td>
<td>Pentium3</td>
<td>900</td>
</tr>
<tr>
<td>2P</td>
<td>2</td>
<td>Pentium3</td>
<td>1400</td>
</tr>
<tr>
<td>2A</td>
<td>2</td>
<td>Athlon</td>
<td>2000</td>
</tr>
<tr>
<td>4P</td>
<td>2HT</td>
<td>Pentium4/Xeon</td>
<td>2400</td>
</tr>
<tr>
<td>1U</td>
<td>1</td>
<td>UltraSparc2</td>
<td>650</td>
</tr>
<tr>
<td>4U</td>
<td>4</td>
<td>UltraSparc2</td>
<td>450</td>
</tr>
<tr>
<td>8U</td>
<td>8</td>
<td>UltraSparc3</td>
<td>750</td>
</tr>
<tr>
<td>24U</td>
<td>24</td>
<td>UltraSparc3</td>
<td>750</td>
</tr>
</tbody>
</table>
<h3 id="51-开销">5.1 开销</h3>
<p>通过只只运行一个线程，从 S=1 时的每次迭代时间减去 S=0 （访问共享内存的概率为零）时的每次迭代时间得到的。表 2 显示了在非竞争的场景下每次锁操作的开销（以纳秒为单位）。<code>Metux</code> 类最接近于框架的基本耗时，可重入锁的额外开销是记录当前所有者线程和错误检查时的耗时，对于公平锁来说还会包含开始时检查队列是否为空的耗时。</p>
<p>表 2 还显示了 <code>tryAcquire</code> 与内置锁的“快速路径（fast path）”的耗时对比。这里的差异主要反映了各种锁和机器中使用的不同的原子指令以及内存屏障的耗时。在多处理器上，这些指令常常是完全优于所有其他指令的。内置锁和同步器类之间的主要差别，显然是由于 Hotspot 锁使用 <code>compareAndSet</code> 锁定和解锁，而同步器的 <code>acquire</code> 操作使用了一次 <code>compareAndSet</code>，但 <code>release</code> 操作用的是一次 <code>volatile</code> 写（即，多处理器上的一次内存屏障以及所有处理器上的重排序限制）。每个锁的绝对和相对耗时因机器的不同而不同。</p>
<center><b>表2 无竞争时的单锁开销（单位：纳秒）</b></center>
<table>
<thead>
<tr>
<th>机器</th>
<th>内置</th>
<th>互斥</th>
<th>可重入</th>
<th>公平可重入</th>
</tr>
</thead>
<tbody>
<tr>
<td>1P</td>
<td>18</td>
<td>9</td>
<td>31</td>
<td>37</td>
</tr>
<tr>
<td>2P</td>
<td>58</td>
<td>71</td>
<td>77</td>
<td>81</td>
</tr>
<tr>
<td>2A</td>
<td>13</td>
<td>21</td>
<td>31</td>
<td>30</td>
</tr>
<tr>
<td>4P</td>
<td>116</td>
<td>95</td>
<td>109</td>
<td>117</td>
</tr>
<tr>
<td>1U</td>
<td>90</td>
<td>40</td>
<td>58</td>
<td>67</td>
</tr>
<tr>
<td>4U</td>
<td>122</td>
<td>82</td>
<td>100</td>
<td>115</td>
</tr>
<tr>
<td>8U</td>
<td>160</td>
<td>83</td>
<td>103</td>
<td>123</td>
</tr>
<tr>
<td>24U</td>
<td>161</td>
<td>84</td>
<td>108</td>
<td>119</td>
</tr>
</tbody>
</table>
<p>在另一个极端，表 3 显示了在 S=1 的情况下，运行 256 个并发线程时产生了大规模的锁竞争下每个锁的开销。在完全饱和的情况下，可闯入的 FIFO 锁比内置锁的开销少了一个数量级（相当于更大的吞吐量），比公平锁少了两个数量级。这证明了即使在极端争用的情况下，可闯入FIFO策略在保持线程进度方面的有效性。</p>
<p>表 3 也说明了即使在内部开销比较低的情况下，公平锁的性能也完全是由上下文切换的时间所决定的。列出的时间大致上都与各平台上线程阻塞和解除线程阻塞的时间成比例。</p>
<p>此外，后续增加的一个实验（仅使用机器 4P）显示，对于这里使用的非常短暂的锁，公平性设置对总体方差只有很小的影响。这里将线程终止时间的差异被记录为可变性的粗粒度度量。在机器 4P 上，公平锁的时间度量的标准差平均为 0.7%，可重入锁平均为 6.0%。作为对比，为模拟一个产时间持有锁的场景，测试中使每个线程在持有锁的情况下计算了 16K 次随机数。这时，总运行时间几乎是相同的（公平锁：9.79s，可重入锁：9.72s）。公平模式下的差异依然很小，标准差平均为 0.1%，而可重入锁上升到了平均 29.5%。</p>
<center><b>表格3 饱和时的单锁开销（单位：纳秒）</b></center>
<table>
<thead>
<tr>
<th>机器</th>
<th>内置</th>
<th>互斥</th>
<th>可重入</th>
<th>公平可重入</th>
</tr>
</thead>
<tbody>
<tr>
<td>1P</td>
<td>521</td>
<td>46</td>
<td>67</td>
<td>8327</td>
</tr>
<tr>
<td>2P</td>
<td>930</td>
<td>108</td>
<td>132</td>
<td>14967</td>
</tr>
<tr>
<td>2A</td>
<td>748</td>
<td>79</td>
<td>84</td>
<td>33910</td>
</tr>
<tr>
<td>4P</td>
<td>1146</td>
<td>188</td>
<td>247</td>
<td>15328</td>
</tr>
<tr>
<td>1U</td>
<td>879</td>
<td>153</td>
<td>177</td>
<td>41394</td>
</tr>
<tr>
<td>4U</td>
<td>2590</td>
<td>347</td>
<td>368</td>
<td>30004</td>
</tr>
<tr>
<td>8U</td>
<td>1274</td>
<td>157</td>
<td>174</td>
<td>31084</td>
</tr>
<tr>
<td>24U</td>
<td>1983</td>
<td>160</td>
<td>182</td>
<td>32291</td>
</tr>
</tbody>
</table>
<h3 id="52-吞吐量">5.2 吞吐量</h3>
<p>大多数同步器的使用范围在无竞争和饱和竞争这两个极端之间。这可以用实验在两个方面进行检查，通过修改固定数量线程的竞争概率，和/或通过向一组具有固定竞争概率的线程添加更多的线程。为了说明这些影响，测试运行在不同的竞争概率和不同的线程数目下，都用的是可重入锁。附图使用了一个 <em>slowdown</em> 度量标准：</p>
<figure data-type="image" tabindex="3"><img src="https://wenbozhangw.github.io//post-images/1662043242519.jpg" alt="formula" loading="lazy"></figure>
<p>这里，t 是总运行时间，b 是一个线程在没有竞争或同步的情况下的基线时间，n 是线程的数量，p 是处理器的数量，S 是共享访问的比例。计算结果是实际执行时间与理想执行时间（通常是无法达到的）的比率，理想执行时间是通过使用 Amdahl's 定律对顺序和并行任务的混合计算得到。理想的时间模型是在没有任何同步开销的情况下，没有线程因为与其他线程冲突而阻塞。即便如此，在竞争非常少的情况下，一些测试结果显示，与理想情况相比，有些测试结果表现出了很小的速度增长，大概是由于基线和测试之间的优化、流水线等方面有着轻微的差别。</p>
<p>图中用以 2 为底的对数为比例进行了缩放。例如，值为 1 表示实际时间是理想时间的两倍，4 表示慢 16 倍。使用对数就不需要依赖一个随意的基线时间（这里是计算随机数的时间），因此，基于不同底数的计算结果表现出的趋势应该是类似的。这些测试使用的竞争概率从 1/128（标识为 “0.008”）到 1，以 2 的幂为步长，线程的数量从 1 到 1024，以 2 的幂的一半为步长。</p>
<p>在单处理器上（1P 和 1U），性能会随着竞争的增加而降低，但通常不会随着线程数量的增加而降低。多处理器在竞争的情况下，通常会遇到更糟糕的性能下降。根据多处理器相关的图表显示，开始出现的峰值处虽然只有几个线程的竞争，但相对性能通常却最差。这反映出了一个性能的 <em>过渡区域</em>，在这里闯入的线程和被唤醒的线程都准备获取锁，这会让它们频繁的迫使对方阻塞。在大部分时候，过渡区域后面会紧接着一个 <em>平滑区域</em>，因为此时几乎没有空闲的锁，所以会与单处理器上的顺序执行模式差不多；在多处理器上会较早进入平滑区域。例如，请注意，在处理器数量较少的机器上，满竞争（标记为 “1.000”）表现出相对较差的速度下降。</p>
<figure data-type="image" tabindex="4"><img src="https://wenbozhangw.github.io//post-images/1662043305229.jpg" alt="slowndown-1" loading="lazy"></figure>
<figure data-type="image" tabindex="5"><img src="https://wenbozhangw.github.io//post-images/1662043318498.jpg" alt="slowndown-2" loading="lazy"></figure>
<figure data-type="image" tabindex="6"><img src="https://wenbozhangw.github.io//post-images/1662043328452.jpg" alt="slowndown-3" loading="lazy"></figure>
<figure data-type="image" tabindex="7"><img src="https://wenbozhangw.github.io//post-images/1662043337590.jpg" alt="slowndown-4" loading="lazy"></figure>
<p>基于这些结果，进一步调整阻塞（<code>park/unpark</code>）以减少上下文切换和相关的开销，这会给本框架带来小但显著的提升。此外，在多处理上为短时间持有的但高竞争的锁采用某种形式的适应性自旋，可以避免这里看到的一些波动，这对同步器类有很大好处。虽然在跨不同上下文时适应性自旋很难很好的工作，但可以使用本框架为遇到这类使用配置的特定应用构建一个自定义形式的锁。</p>
<h2 id="6-结论">6. 结论</h2>
<p>在撰写本文时，<code>j.u.c</code>同步器框架还太新，无法在实践中进行使用。因此在 J2SE 1.5 最终发布之前，它不太可能被广泛使用，而且他的设计、API 实现以及性能肯定还有无法预料的后果。但是，此时，这个框架明显能胜任其基本目标，即为创建新的同步器提供一个高效的基础。</p>
<h2 id="7-致谢">7. 致谢</h2>
<p>Thanks to Dave Dice for countless ideas and advice during the development of this framework, to Mark Moir and Michael Scott for urging consideration of CLH queues, to David Holmes for critiquing early versions of the code and API, to Victor Luchangco and Bill Scherer for reviewing previous incarnations of the source code, and to the other members of the JSR166 Expert Group (Joe Bowbeer, Josh Bloch, Brian Goetz, David Holmes, and Tim Peierls) as well as Bill Pugh, for helping with design and specifications and commenting on drafts of this paper. Portions of this work were made possible by a DARPA PCES grant, NSF grant EIA-0080206 (for access to the 24way Sparc) and a Sun Collaborative Research Grant.</p>
<h2 id="8-引用">8. 引用</h2>
<ul>
<li><span id="1">[1]</span> Agesen, O., D. Detlefs, A. Garthwaite, R. Knippel, Y. S.Ramakrishna, and D. White. An Efficient Meta-lock for Implementing Ubiquitous Synchronization. ACM OOPSLA Proceedings, 1999.</li>
<li><span id="2">[2]</span> Andrews, G. Concurrent Programming. Wiley, 1991.</li>
<li><span id="3">[3]</span> Bacon, D. Thin Locks: Featherweight Synchronization for Java. ACM PLDI Proceedings, 1998.</li>
<li><span id="4">[4]</span> Buhr, P. M. Fortier, and M. Coffin. Monitor Classification,ACM Computing Surveys, March 1995.</li>
<li><span id="5">[5]</span> Craig, T. S. Building FIFO and priority-queueing spin locks from atomic swap. Technical Report TR 93-02-02,Department of Computer Science, University of Washington, Feb. 1993.</li>
<li><span id="6">[6]</span> Gamma, E., R. Helm, R. Johnson, and J. Vlissides. Design Patterns, Addison Wesley, 1996.</li>
<li><span id="7">[7]</span> Holmes, D. Synchronisation Rings, PhD Thesis, Macquarie University, 1999.</li>
<li><span id="8">[8]</span> Magnussen, P., A. Landin, and E. Hagersten. Queue locks on cache coherent multiprocessors. 8th Intl. Parallel Processing Symposium, Cancun, Mexico, Apr. 1994.</li>
<li><span id="9">[9]</span> Mellor-Crummey, J.M., and M. L. Scott. Algorithms for Scalable Synchronization on Shared-Memory Multiprocessors. ACM Trans. on Computer Systems,February 1991</li>
<li><span id="10">[10]</span> M. L. Scott and W N. Scherer III. Scalable Queue-Based Spin Locks with Timeout. 8th ACM Symp. on Principles and Practice of Parallel Programming, Snowbird, UT, June 2001.</li>
<li><span id="11">[11]</span> Sun Microsystems. Multithreading in the Solaris Operating Environment. White paper available at http://wwws.sun.com/software/solaris/whitepapers.html 2002.</li>
<li><span id="12">[12]</span> Zhang, H., S. Liang, and L. Bak. Monitor Conversion in a Multithreaded Computer System. United States Patent 6,691,304. 2004.</li>
</ul>
<h2 id="9-参考">9. 参考</h2>
<p><a href="https://gee.cs.oswego.edu/dl/papers/aqs.pdf">《The java.util.concurrent Synchronizer Framework》</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Chapter 2. Grammars]]></title>
        <id>https://wenbozhangw.github.io/post/chapter-2-grammars/</id>
        <link href="https://wenbozhangw.github.io/post/chapter-2-grammars/">
        </link>
        <updated>2022-08-11T08:52:42.000Z</updated>
        <summary type="html"><![CDATA[<p>本章描述了本规范中用于定义程序词法和语法结构的上下文无关语法（context-free grammars）。</p>
]]></summary>
        <content type="html"><![CDATA[<p>本章描述了本规范中用于定义程序词法和语法结构的上下文无关语法（context-free grammars）。</p>
<!-- more -->
<h2 id="21-context-free-grammars">2.1 Context-Free Grammars</h2>
<p>一个上下文无关的语法由许多 <em>productions</em> 组成。每一个 productions 都有一个称为 <em>nonterminal</em> 的抽象符号在它 <em>left-hand side</em>，一个或多个 nonterminal 和 <em>terminal</em> 符号的序列在他的 <em>right-hand side</em>。对于每种语法，终止符号都是从指定的 <em>alphabet</em> 中抽取的。</p>
<p>从由单个可识别的非终结符（称为 <em>goal symbol</em>）组成的句子开始，给定的与上下文无关的语法指定了一种语言，即，通过将序列中的任何非终止符重复替换为以非终止符为左边的 productions 的右手边而产生的可能的终止符序列集。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Chapter 1. Interduction]]></title>
        <id>https://wenbozhangw.github.io/post/chapter-1-interduction/</id>
        <link href="https://wenbozhangw.github.io/post/chapter-1-interduction/">
        </link>
        <updated>2022-07-12T09:41:16.000Z</updated>
        <summary type="html"><![CDATA[<p>Java® 编程语言是一种通用的、并发的、基于类的、面向对象的语言。它被设计得足够简单，以至于许多程序员都能熟练使用该语言。Java 编程语言与 C 和 C++ 有关，但其组织方式却截然不同，它省略了 C 和 C++ 的许多方面，并包含了其他语言的一些思想。它是一种生产语言，而不是一种研究语言，因此，正如 C. A. R. Hoare 在他关于语言设计的经典论文中建议的那样，设计避免包含新的和未经测试的功能。</p>
]]></summary>
        <content type="html"><![CDATA[<p>Java® 编程语言是一种通用的、并发的、基于类的、面向对象的语言。它被设计得足够简单，以至于许多程序员都能熟练使用该语言。Java 编程语言与 C 和 C++ 有关，但其组织方式却截然不同，它省略了 C 和 C++ 的许多方面，并包含了其他语言的一些思想。它是一种生产语言，而不是一种研究语言，因此，正如 C. A. R. Hoare 在他关于语言设计的经典论文中建议的那样，设计避免包含新的和未经测试的功能。</p>
<!-- more -->
<p>Java 编程语言是强类型和静态类型的。该规范清楚地区分了编译时错误（可以且必须在编译时检测到）和运行时发生的错误、编译时通常包括将程序装换为与机器无关的字节码表示形式。运行时活动包括加载和链接执行程序所需的类、可选的机器底阿妈生成和程序的动态优化、以及实际的程序执行。</p>
<p>Java 编程语言是一种相对高级的语言，因为通过该语言无法获得机器表示的细节。它包括自动存储管理，通常使用垃圾收集器以避免显式释放的安全问题（如 C 的 <code>free</code> 或 C++ 的 <code>delete</code> ）。高性能的垃圾收集实现可以有有限的暂停，以支持系统编程和实施应用程序。该语言不包括任何不安全的结构，例如不进行索引检查的数组访问，因为这种不安全的结构将导致程序以未指定的方式运行。</p>
<p>Java 编程语言通常被编译成* Java 虚拟机规范 Java SE 8 版* 定义的字节码指令集和二进制格式。</p>
<h2 id="11-organization-of-the-specification">1.1 Organization of the Specification</h2>
<p>第 2 章描述了语法和用来表示语言的词汇语法和句法语法的符号。</p>
<p>第 3 章描述了基于 C 和 C++ 的 Java 编程语言的词法结构。该语言是用 Unicode 字符集编写的、它支持在只支持 ASCII 的系统上编写 Unicode 字符。</p>
<p>第 4 章描述了类型、值和变量、类型被细分为基本类型（primitive types）和引用类型（reference types）。</p>
<p>基本类型被定义为在所有机器和所有实现中是相同的，并且是各种大小的二进制补码整数、单精度和双精度 IEEE 754 标准浮点数、布尔类型和 Unicode 字符 char 类型。基本类型的值不共享状态。</p>
<p>引用类型是类（class）类型、接口（interface）类型和数组（array）类型。引用类型由动态创建的对象实现，这些对象可以是类或数组的实例。可以存在对每个对象的许多引用。所有对象（包括数组）都支持类对象的方法，类对象是类层次结构的（单一）根。预定义的字符串（<code>String</code>）类支持 Unicode 字符串。存在用于在对象内部包装原始值的类。在许多情况下，包装和解包是由编译器自动执行的（在这种情况想，包装称为装箱（boxing），解包成为拆箱（unboxing））。类和接口声明可以是泛型的，也就是说，它们可以被其他引用类型参数化。然后可以用特定的类型参数来调用这样的声明。</p>
<p>变量是类型化的存储位置。一个原始类型的变量保存该原始类型的值。一个类类型的变量可以包含一个空引用或一个对象的引用，该对象的类型是该类类型或该类类型的任何子类。接口类型的变量可以包含一个空引用或对实现该接口的任何类的实例的引用。数组类型的变量可以包含空引用或对数组的引用。<code>Object</code> 类类型的变量可以包含一个空引用或对任何对象的引用，无论是类实例还是数组。</p>
<p>第 5 章描述了转换和数字提升（numeric promotions）。转换会改变编译时类型，有时还会改变表达式的值。这些转换包括基本类型和引用类型之间的装箱和拆箱转换。数值提升用于将数值运算符的操作数转换为可执行运算的通用类型。语言上没有漏洞；在运行时检查引用类型的强制转换，以确保类型安全。</p>
<p>第 6 章描述了声明和命名，以及如何确定名字的含义。语言不要求在使用类型或其成员变量之前声明它们。声明顺序只对局部变量、局部类以及类或接口中字段的初始值设定项的顺序有意义。</p>
<p>Java 编程语言提供了对命名作用域的控制，并支持对包、类和接口成员的外部访问的限制。这对于大型项目中区分类型的用户和谁能扩展类型提供了很大的帮助。同时这里也给出了更加具有可读性程序的命名习惯。</p>
<p>第 7 章描述了程序的结构，程序的结构被组织成了各种包，这就像模块化概念中的各种模块。包的成员是类、接口和子包。每个包都是一个编译单元。每个编译单元包含类型声明的短名称和从其他包里导入的类型的短名称。包是以一个层次性命名空间进行命名的，因特网域名系统通常被用来组成唯一的包名。</p>
<p>第 8 章描述了类。类的成员包括类、接口、字段（变量）和方法。类方法的调用可以不使用对象的引用。实例变量是在作为类实例的对象中动态创建的。实例方法在类的实例上被调用；在方法执行期间实例就成为当前对象 this，以此支持面向对象的编程风格。</p>
<p>类支持单个实现继承，其中每个实现类派生于单个父类，最终都派生于类 <code>Object</code>。类类型的遍历可以引用该类或该类的任何子类的实例，允许新类型以多种形式与现有方法一起使用。</p>
<p>类支持使用同步方法进行并发编程。方法声明了在执行过程中可能出现的检查异常，这允许编译时检查以确保异常情况得到处理。对象可以声明一个 <code>finalize</code> 方法，该对象将在对象被垃圾收集器丢弃之前被调用，从而允许对象清理它们的状态。</p>
<p>为了简单起见，Java 语言没有将声明头文件（C 和 C++ 用头文件提前声明类名，函数名）和类的实现分开，也没有分开的类型和类层次结构。</p>
<p>一种特殊形式的类，枚举，支持小型值集的定义，以及以类型安全的方式对它们进行操作。与其他语言中的枚举不同，枚举是对象，可能有自己的方法。</p>
<p>第 9 章描述了接口类型，它声明了一组抽象方法、成员类型和常量。在其他方面不相关的类可以实现相同的接口类型。接口类型的变量可以包含对实现该接口的任何对象的引用。支持多接口继承。</p>
<p>注解类型属于特殊接口用来做注解声明。Java 程序语言中这种注解任何方面都不会影响程序的语义。然而，注解给各种工具提供了非常有用的输入。</p>
<p>第 10 章描述了数组。数组访问包括边界检查。数组是动态创建的对象，可以赋值给 <code>Object</code> 类型的变量。Java 语言支持数组的数组，而不是多维数组。</p>
<p>第 11 章描述了异常，它是不可恢复的，并与语言的语义和并发机制完全集成。Java 语言提供了三种类型的异常：收件异常（checked exception）、运行时异常（run-time exception）、错误（error）。编译器只保证方法和构造器上具有受检异常声明的哪些异常会被合适的处理。者提供了编译使其检查异常处理器的存在，极大的保证了程序正常。大多数用户定义的异常都应该是受检异常。Java 虚拟机检测到的程序中的无效操作会导致运行时异常，例如 <code>NullPointerException</code>。错误是由 Java 虚拟机检测到的错误导致的，比如 <code>OutOfMemoryError</code>。大多数简单的程序不会去处理错误异常。</p>
<p>第 12 章描述了在程序执行过程中发生的活动。程序通常存储为已编译类和接口的二进制文件。这些二进制文件可以加载到 Java 虚拟机中，链接到其他类和接口，并进行初始化。</p>
<p>在初始化后，可以使用类方法和类变量。可以实例化一些类以创建类类型的新对象。作为类实例的对象还包含类的每个父类的一个实例，对象的创建涉及到这些父类实例的递归创建。</p>
<p>当一个对象不再被引用时，他可能会被垃圾收集器回收。如果对象声明了终结器（finalizer），则在对象被回收之前会执行终结器，以给对象最后一次机会来清理，否则那些资源无法被释放。当不再需要某个类时，可以将其卸载。</p>
<p>第 13 章描述了二进制兼容性，说明了对于那些还没有重新编译，但是引用了修改类的类的影响。这些考虑因素是开发人员感兴趣的，开发人员通常会通过 Internet 在一系列连续的版本中广泛分发这些类型的产品。好的程序开发环境会在类型改变时自动重新编译相关代码，所以大多数程序员不需要关心这些细节。</p>
<p>第 14 章描述了基于 C 和 C++ 的块（block）和语句（statements）。该语言没有 <code>goto</code> 语句，但是有带标签的 <code>break</code> 和 <code>continue</code> 语句。与 C 不同，Java 编程语言要求在控制流语句中使用布尔（或布尔）表达式，并且不隐式地将类型转换为布尔（除了通过拆箱），希望在编译时捕捉更多的错误。<code>synchronized</code> 语句提供基本的对象级监视器锁定。<code>try</code> 语句可以包含 <code>catch</code> 和 <code>finally</code> 子句，以防止非本地控制转移（内部 Exception 会直接打断当前代码执行的流程）。</p>
<p>第 15 章描述了表达式。为了增加确定性和可移植性，这个文档明确了表达式求值的（明显的）顺序。重载的方法和构造函数会在编译时被解析到合适的而且最具体的方法和构造函数上。</p>
<p>第 16 章描述了语言确保局部变量在使用前被明确设置的精确方式。虽然所有其他变量都自动初始化为默认值，但 Java 编程语言不会自动初始化局部变量，以避免掩盖程序错误。</p>
<p>第 17 章描述了线程和锁的语义，这些都是基于源自 Mesa 程序语言提出的 monitor-based 并发性。Java 编程语言为支持高性能实现的共享内存多处理器指定了内存模型。</p>
<p>第 18 章描述了各种类型推断算法，用于测试泛型方法的实用性和推断泛型方法调用中的类型。</p>
<p>第 19 张介绍了 Java 语言的语法。</p>
<h2 id="12-example-programs">1.2 Example Programs</h2>
<p>正文中给出的大多数示例程序都可以执行，并且在形式上类似于：</p>
<pre><code class="language-java">class Test {
    public static void main(String[] args) {
        for (int i = 0; i &lt; args.length; i++)
            System.out.print(i == 0 ? args[i] : &quot; &quot; + args[i]);
        System.out.println();
    }
}
</code></pre>
<p>在安装了 Oracle JDK 的机器上，可以通过给出以下命令来编译和执行这个存储在文件 <code>Test.java</code> 中的类：</p>
<pre><code class="language-shell">javac Test.java
java Test Hello, world.
</code></pre>
<p>产生输出：</p>
<pre><code>Hello, world.
</code></pre>
<h2 id="13-notation">1.3 Notation</h2>
<p>在本规范中，我们只的是来自 Java SE 平台 API 的类和接口。每当我们使用单个标识符 <code>N</code> 引用一个类或接口（除了在实例中声明的那些）时，意图引用的是 <code>java.lang</code> 包中名为 <code>N</code> 的类或接口。对于 <code>java.lang</code> 之外的包中的类或接口，我们使用规范名称（canonical name，<a href="https://docs.oracle.com/javase/specs/jls/se8/html/jls-6.html#jls-6.7">§6.7</a> ）。</p>
<p>旨在阐明规范的非规范性信息以较小的缩进文本给出。</p>
<p><em>这是非规范性信息。它提供直觉、基本原理、建议、例子等。</em></p>
<p>Java 编程语言的类型系统有时依赖于<em>替换</em>的概念。符号 [F<sub>1</sub>:=T<sub>1</sub>, ..., F<sub>n</sub>:=T<sub>n</sub>] 表示 1 ≤ i ≤ n 是 T<sub>i</sub> 对 F<sub>i</sub> 的替换。</p>
<h2 id="14-relationship-to-predefined-classes-and-interfaces">1.4 Relationship to Predefined Classes and Interfaces</h2>
<p>如上所述，该规范经常引用 Java SE 平台 API 的类。特别是，有些类与 Java 编程语言有着特殊的关系。例如 <code>Object</code>、<code>Class</code>、<code>ClassLoader</code>、<code>String</code>、<code>Thread</code> 等类，以及 <code>java.lang.reflect</code> 包中的类和接口等。改规范约束了这些类和接口的行为，但没有为它们提供完整的规范。读者可以参考 Java SE 平台 API 文档。</p>
<p>因此，本规范没有详细描述反射。许多语言结构在核心反射 API（<code>java.lang.reflect</code>）和语言模型 API（<code>javax.lang.model</code>）中都有类似的内容，但这里一般不讨论这些内容。例如，当我们列出创建一个对象的方法时，我们通常不包括核心反射 API 完成这个任务的方法。读者应该知道这些额外的机制，即使它们在正文中没有提到。</p>
<h2 id="15-feedback">1.5 Feedback</h2>
<p>欢迎读者向 jls-jvms-spec-comments@openjdk.java.net 报告 Java 语言规范中的技术错误和歧义。</p>
<p>有关 <code>javac</code> （Java 编程语言的参考编译器） 的行为，特别是它是否符合本规范的问题，可以发送给 compiler-dev@openjdk.java.net。</p>
<h2 id="16-references">1.6 References</h2>
<h3 id="bibliography">Bibliography</h3>
<p>Apple Computer. <em>Dylan Reference Manual.</em> Apple Computer Inc., Cupertino, California. September 29, 1995.</p>
<p>Bobrow, Daniel G., Linda G. DeMichiel, Richard P. Gabriel, Sonya E. Keene, Gregor Kiczales, and David A. Moon.* Common Lisp Object System Specification*, X3J13 Document 88-002R, June 1988; appears as Chapter 28 of Steele, Guy. <em>Common Lisp: The Language</em>, 2nd ed. Digital Press, 1990, ISBN 1-55558-041-6, 770-864.</p>
<p>Ellis, Margaret A., and Bjarne Stroustrup. <em>The Annotated C++ Reference Manual</em>. Addison-Wesley, Reading, Massachusetts, 1990, reprinted with corrections October 1992, ISBN 0-201-51459-1.</p>
<p>Goldberg, Adele and Robson, David. <em>Smalltalk-80: The Language</em>. Addison-Wesley, Reading, Massachusetts, 1989, ISBN 0-201-13688-0.</p>
<p>Harbison, Samuel. <em>Modula-3</em>. Prentice Hall, Englewood Cliffs, New Jersey, 1992, ISBN 0-13-596396.</p>
<p>Hoare, C. A. R. <em>Hints on Programming Language Design</em>. Stanford University Computer Science Department Technical Report No. CS-73-403, December 1973. Reprinted in SIGACT/SIGPLAN Symposium on Principles of Programming Languages. Association for Computing Machinery, New York, October 1973.</p>
<p><em>IEEE Standard for Binary Floating-Point Arithmetic</em>. ANSI/IEEE Std. 754-1985. Available from Global Engineering Documents, 15 Inverness Way East, Englewood, Colorado 80112-5704 USA; 800-854-7179.</p>
<p>Kernighan, Brian W., and Dennis M. Ritchie. <em>The C Programming Language</em>, 2nd ed. Prentice Hall, Englewood Cliffs, New Jersey, 1988, ISBN 0-13-110362-8.</p>
<p>Madsen, Ole Lehrmann, Birger Møller-Pedersen, and Kristen Nygaard. <em>Object-Oriented Programming in the Beta Programming Language</em>. Addison-Wesley, Reading, Massachusetts, 1993, ISBN 0-201-62430-3.</p>
<p>Mitchell, James G., William Maybury, and Richard Sweet. <em>The Mesa Programming Language, Version 5.0</em>. Xerox PARC, Palo Alto, California, CSL 79-3, April 1979.</p>
<p>Stroustrup, Bjarne. <em>The C++ Progamming Language</em>, 2nd ed. Addison-Wesley, Reading, Massachusetts, 1991, reprinted with corrections January 1994, ISBN 0-201-53992-6.</p>
<p>Unicode Consortium, The. <em>The Unicode Standard, Version 6.2.0</em>. Mountain View, California, 2012, ISBN 978-1-936213-07-8.</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Preface to the Java SE 8 Edition]]></title>
        <id>https://wenbozhangw.github.io/post/preface-to-the-java-se-8-edition/</id>
        <link href="https://wenbozhangw.github.io/post/preface-to-the-java-se-8-edition/">
        </link>
        <updated>2022-07-12T09:11:16.000Z</updated>
        <content type="html"><![CDATA[<p><strong>Alex Buckley</strong></p>
<p>1996 年，James Gosling、Bill Joy 和 Guy Steele 为 <em>Java® 语言规范</em> 的第一版写了：<br>
“我们相信 Java 编程语言是一种成熟的语言，可以广泛使用。尽管如此，我们预计未来几年该语言会发生一些演变。我们打算以与现在应用程序完全兼容的方式管理这种演变。”</p>
<p>Java SE 8 代表了 Java 语言历史上最大的一次金华。相对较少的特性 —— lambda 表达式、方法引用和函数式接口 —— 结合起来提供了一个融合面向对象和函数式风格的编程模型。在 Brian Goetz 的领导下，这种融合以一种鼓励最佳实践的方式完成 —— 不变性、无状态、组合性 —— 同时保留“Java的感觉” —— 可读性、简单性、通用性。</p>
<p>至关重要的是，Java SE 平台的库与 Java 语言共同发展。这意味着使用 lambda 表达式和方法引用来表示行为 —— 例如，应用于列表中每个元素的操作 —— 是 &quot;开箱即用&quot; 的高效和高性能。以类似的方式，Java 虚拟机与 Java 语言共同进化，以确保在独立编译的约束条件下， default 方法在编译时和运行时尽可能一致地支持库的发展。</p>
<p>自 20 世纪 90 年代以来，向 Java 语言添加一级函数的计划就已经出现了。2007 年左右的 BGGA 和 CICE 提案为这个话题带来了新的活力，而 2009 年左右在 OpenJDK 中创建的项目 Lambda 吸引了前所未有的兴趣。Java SE 7 中向 JVM 添加的方法句柄为新的实现技术打开了大门，同时保留了“一次编写，随处运行”的原则。随着时间的过去，语言的变化由 JSR 335 —— Java编程语言的Lambda表达式 —— 监督，其专家组包括 Joshua Bloch、Kevin Bourrillion、Andrey Breslav、Rémi Forax、Dan Heidinga、Doug Lea、Bob Lee、David Lloyd、Sam Pullara、Srikanth Sankaran 和 Vladimir Zakharov。</p>
<p>编程语言设计通常涉及处理完全不为语言用户所知的复杂程度。（因此，它经常被比作冰山：它 90% 的部分是看不见的。）在 JSR 335 中，最大的复杂性隐藏在隐式类型 lambda 表达式与重载解析的交互中。在这一领域和许多其他领域，Oracle 的 Dan Smith 做了一项出色的工作，彻底地指定了所需的行为。他的话可以在整个规范中找到，包括一个关于类型推断的全新章节。</p>
<p>Java SE 8 中的另一个举措是增强注解的实用性，这是 Java 语言最流行的特性之一。首先，Java 语法已经扩展到允许在许多语言结构中对类型进行注解，从而形成了新的静态分析工具（如 Checker 框架）的基础。这个特性由 JSR 308 “Java类型注解” 指定，由 Michael Ernst 和我自己、Doug Lea 和 Srikanth Sankaran 组成的专家组负责。该规范中涉及的变化是广泛的，Michael Ernst 和 Werner Dietl 多年来的不懈努力得到了热烈的认可。其次，注解可以在语言构造上“重复”，这对用注解类型建模特定领域配置的 api 有很大的好处。Java EE 的 Michael Keith 和 Bill Shannon 发起并指导了这个特性。</p>
<p>Oracle Java 平台组的许多同事已经为该规范提供了宝贵的支持：Leonid Arbouzov, Mandy Chung, Joe Darcy, Robert Field, Joel Borggrén-Franck, Sonali Goel, Jon Gibbons, Jeannette Hung, Stuart Marks, Eric McCorkle, Matherey Nunez, Mark Reinhold, Vicente Romero, John Rose, Georges Saab, Steve Sides, Bernard Traversat和Michel Trudeau。</p>
<p>也许最应该感谢的是编译器工程师，他们把规范变成了真正的软件。Oracle 的 Maurizio Cimadamore 从最早开始就英勇地致力于 lambda 表达式的设计和在 javac 中的实现。Eclipse 中对 Java SE 8 特性的支持由 Jayaprakash Arthanareeswaran、Shankha Banerjee、Anirban Chakraborty、Andrew Clement、Stephan Herrmann、Markus Keller、Jesper Møller、Manoj Palat、Srikanth Sankaran 和 Olivier Thomann 贡献；Anna Kozlova, Alexey Kudravtsev 和 Roman Shevchenko 合著的 IntelliJ 。他们值得整个 Java 社区的感谢。</p>
<p>Java SE 8 是 Java 语言的复兴。虽然有些人在寻找“下一个伟大的语言”，但我们相信，用 Java 编程比以往任何时候都更令人兴奋和高效。我们希望它继续适合你。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[HttpClient连接无法释放问题]]></title>
        <id>https://wenbozhangw.github.io/post/httpclient-lian-jie-wu-fa-shi-fang-wen-ti/</id>
        <link href="https://wenbozhangw.github.io/post/httpclient-lian-jie-wu-fa-shi-fang-wen-ti/">
        </link>
        <updated>2022-06-08T04:28:12.000Z</updated>
        <summary type="html"><![CDATA[<p>在中银消金三方服务平台，数据源配置中可以配置数据源调用的<strong>超时时间</strong>，代码中使用这个用户配置的<strong>超时时间</strong>作为 <code>connectionRequestTimeout</code>、<code>connectionTimeout</code> 和 <code>socketTimeout</code> 参数。在数据源调用明细中，明显可以看出数据源的调用时长有远大于配置的<strong>超时时间</strong>，客户提出不符合预期，要求数据源的调用时间在超过配置的<strong>超时时间</strong>后能够终止。</p>
]]></summary>
        <content type="html"><![CDATA[<p>在中银消金三方服务平台，数据源配置中可以配置数据源调用的<strong>超时时间</strong>，代码中使用这个用户配置的<strong>超时时间</strong>作为 <code>connectionRequestTimeout</code>、<code>connectionTimeout</code> 和 <code>socketTimeout</code> 参数。在数据源调用明细中，明显可以看出数据源的调用时长有远大于配置的<strong>超时时间</strong>，客户提出不符合预期，要求数据源的调用时间在超过配置的<strong>超时时间</strong>后能够终止。</p>
<!-- more -->
<h2 id="httpclient-超时参数">httpclient 超时参数</h2>
<p>上面提到，代码中使用配置的超时时间作为 httpclient 的 <code>connectionRequestTimeout</code>、<code>connectionTimeout</code> 和 <code>socketTimeout</code> 参数，下面简单介绍一下这三个参数的含义。</p>
<ul>
<li><code>connectionRequestTimeout</code>：指从连接池获取连接的超时时间（当请求并发数量大于连接池中的连接数量时，则获取不到连接的请求会被放入 pending 队列等待，如果超过设定的时间，则抛出超时异常）。</li>
<li><code>connectionTimeout</code>：指客户端和服务器建立连接的超时时间。（当客户端和服务器在建立链接时，如果在指定时间内无法成功建立链接，则抛出 <code>ConnectionTimeoutException</code>）。</li>
<li><code>socketTimeout</code>：指客户端从服务器读取数据的超时时间，即客户端和服务器 socket 通信的超时时间，其实这个时间是客户端两次读取数据的最长时间，如果客户端在网络抖动的情况下，每次返回部分数据，两次数据包的时间在设定时间之内，也是不会超时的。</li>
</ul>
<h2 id="问题背景">问题背景</h2>
<p>为了保证计时的准确性，我们采用异步提交线程池，用 <code>Future.get(timeout)</code> 的方式保证任务可以在超过设定时间后，计时的准确性，大致代码如下：</p>
<pre><code class="language-java">public class Main {

    private static final Logger logger = LoggerFactory.getLogger(Main.class);

    private static final ThreadPoolExecutor executor = new ThreadPoolExecutor(10, 10, 60,
            java.util.concurrent.TimeUnit.SECONDS, new java.util.concurrent.LinkedBlockingQueue&lt;&gt;(10), new ThreadPoolExecutor.CallerRunsPolicy());

    public static void main(String[] args) throws IOException, InterruptedException {

        for (int i = 0; i &lt; 10; i++) {
            // 请求一个阻塞接口，不会返回数据，必定超时
            HttpGet httpGet = new HttpGet(&quot;*****&quot;);
            CloseableHttpResponse response = null;
            Future&lt;CloseableHttpResponse&gt; future = null;
            try {
                future = executor.submit(() -&gt; {
                    try {
                        return HttpClientUtil.execute(httpGet);
                    } catch (Exception e) {
                        logger.error(&quot;&quot;, e);
                        return null;
                    }
                });
                response = future.get(5, TimeUnit.SECONDS);
                System.out.println(&quot;response = &quot; + response);
            } catch (Exception e) {
                if (e instanceof TimeoutException &amp;&amp; future != null) {
                    logger.info(Thread.currentThread().getName() + &quot; start cancel future&quot;);
                    logger.error(&quot;&quot;, e);
                }
            } finally {
                httpGet.abort();
                httpGet.releaseConnection();
                if (null != response) {
                    EntityUtils.consume(response.getEntity());
                }
            }
        }
    }
}
</code></pre>
<p>在功能上线的两周后，现场反馈说有大量超时，导致大量调用返回超时异常，出现异常</p>
<pre><code>org.apache.http.conn.ConnectionPoolTimeoutException: Timeout waiting for connection from pool
        at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.leaseConnection(PoolingHttpClientConnectionManager.java:313)
        at org.apache.http.impl.conn.PoolingHttpClientConnectionManager$1.get(PoolingHttpClientConnectionManager.java:279)
        at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:191)
        at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:185)
        at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
        at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:110)
        at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
        at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
        at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108)
        at cn.tongdun.freyr.http.SimpleGetRequestExecutor.lambda$execute$0(SimpleGetRequestExecutor.java:56)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
</code></pre>
<p>出现大量异常后，服务就无法使用了，即任何接口的调用都是超时状态。此时通过 debug 发现，即使没有调用，连接也依旧处于 <code>lease</code> 状态。</p>
<h3 id="问题排查">问题排查</h3>
<p>首先，出现 <code>Timeout waiting for connection from pool</code> 是由于 httpclient 在从连接池获取连接时，在 <code>connectionRequectTimeout</code> 时间内没有获取到连接，而抛出的异常信息，从连接池获取连接的流程如下。</p>
<h4 id="httpclient-从连接池获取连接">httpclient 从连接池获取连接</h4>
<p>首先，根据请求的路由和 token 构建 <code>ConnectionRequest</code> 对象，此对象保存了获取从连接池获取连接的 <code>get</code> 方法，代码如下：</p>
<pre><code class="language-java">@Override
    public CloseableHttpResponse execute(
            final HttpRoute route,
            final HttpRequestWrapper request,
            final HttpClientContext context,
            final HttpExecutionAware execAware) throws IOException, HttpException {
        // ......
        Object userToken = context.getUserToken();

        final ConnectionRequest connRequest = connManager.requestConnection(route, userToken);
        if (execAware != null) {
            if (execAware.isAborted()) {
                connRequest.cancel();
                throw new RequestAbortedException(&quot;Request aborted&quot;);
            } else {
                execAware.setCancellable(connRequest);
            }
        }

        // .....
}        
</code></pre>
<p>我们可以看到，此时使用的超时时间就是我们传入配置的 <code>connectionRequestTimeout</code>，下面我们看下 <code>ConnectionRequest</code> 对象的构建。</p>
<pre><code class="language-java">    @Override
    public ConnectionRequest requestConnection(
            final HttpRoute route,
            final Object state) {
        Args.notNull(route, &quot;HTTP route&quot;);
        if (this.log.isDebugEnabled()) {
            this.log.debug(&quot;Connection request: &quot; + format(route, state) + formatStats(route));
        }
        final Future&lt;CPoolEntry&gt; future = this.pool.lease(route, state, null);
        return new ConnectionRequest() {

            @Override
            public boolean cancel() {
                return future.cancel(true);
            }

            @Override
            public HttpClientConnection get(
                    final long timeout,
                    final TimeUnit tunit) throws InterruptedException, ExecutionException, ConnectionPoolTimeoutException {
                final HttpClientConnection conn = leaseConnection(future, timeout, tunit);
                if (conn.isOpen()) {
                    final HttpHost host;
                    if (route.getProxyHost() != null) {
                        host = route.getProxyHost();
                    } else {
                        host = route.getTargetHost();
                    }
                    final SocketConfig socketConfig = resolveSocketConfig(host);
                    conn.setSocketTimeout(socketConfig.getSoTimeout());
                }
                return conn;
            }

        };

    }

    protected HttpClientConnection leaseConnection(
            final Future&lt;CPoolEntry&gt; future,
            final long timeout,
            final TimeUnit tunit) throws InterruptedException, ExecutionException, ConnectionPoolTimeoutException {
        final CPoolEntry entry;
        try {
            entry = future.get(timeout, tunit);
            if (entry == null || future.isCancelled()) {
                throw new InterruptedException();
            }
            Asserts.check(entry.getConnection() != null, &quot;Pool entry with no connection&quot;);
            if (this.log.isDebugEnabled()) {
                this.log.debug(&quot;Connection leased: &quot; + format(entry) + formatStats(entry.getRoute()));
            }
            return CPoolProxy.newProxy(entry);
        } catch (final TimeoutException ex) {
            throw new ConnectionPoolTimeoutException(&quot;Timeout waiting for connection from pool&quot;);
        }
    }
</code></pre>
<p>我们可以看到，代码中捕获了 <code>TimeoutException</code>，并重新构建 <code>ConnectionPoolTimeoutException</code>，也就是说，<code>future.get</code> 会在超时的时候抛出 <code>TimeoutException</code>，然后被外层的 <code>catch</code> 捕获，下面我们看 <code>final Future&lt;CPoolEntry&gt; future = this.pool.lease(route, state, null);</code> 中的 <code>Future</code> 是如何实现的：</p>
<pre><code class="language-java">    /**
     * {@inheritDoc}
     * &lt;p&gt;
     * Please note that this class does not maintain its own pool of execution
     * {@link Thread}s. Therefore, one &lt;b&gt;must&lt;/b&gt; call {@link Future#get()}
     * or {@link Future#get(long, TimeUnit)} method on the {@link Future}
     * returned by this method in order for the lease operation to complete.
     */
    @Override
    public Future&lt;E&gt; lease(final T route, final Object state, final FutureCallback&lt;E&gt; callback) {
        Args.notNull(route, &quot;Route&quot;);
        Asserts.check(!this.isShutDown, &quot;Connection pool shut down&quot;);

        return new Future&lt;E&gt;() {

            private final AtomicBoolean cancelled = new AtomicBoolean(false);
            private final AtomicBoolean done = new AtomicBoolean(false);
            private final AtomicReference&lt;E&gt; entryRef = new AtomicReference&lt;E&gt;(null);

            @Override
            public boolean cancel(final boolean mayInterruptIfRunning) {
                if (cancelled.compareAndSet(false, true)) {
                    done.set(true);
                    lock.lock();
                    try {
                        condition.signalAll();
                    } finally {
                        lock.unlock();
                    }
                    if (callback != null) {
                        callback.cancelled();
                    }
                    return true;
                } else {
                    return false;
                }
            }

            @Override
            public boolean isCancelled() {
                return cancelled.get();
            }

            @Override
            public boolean isDone() {
                return done.get();
            }

            @Override
            public E get() throws InterruptedException, ExecutionException {
                try {
                    return get(0L, TimeUnit.MILLISECONDS);
                } catch (final TimeoutException ex) {
                    throw new ExecutionException(ex);
                }
            }

            @Override
            public E get(final long timeout, final TimeUnit tunit) throws InterruptedException, ExecutionException, TimeoutException {
                final E entry = entryRef.get();
                if (entry != null) {
                    return entry;
                }
                synchronized (this) {
                    try {
                        for (;;) {
                            final E leasedEntry = getPoolEntryBlocking(route, state, timeout, tunit, this);
                            if (validateAfterInactivity &gt; 0)  {
                                if (leasedEntry.getUpdated() + validateAfterInactivity &lt;= System.currentTimeMillis()) {
                                    if (!validate(leasedEntry)) {
                                        leasedEntry.close();
                                        release(leasedEntry, false);
                                        continue;
                                    }
                                }
                            }
                            entryRef.set(leasedEntry);
                            done.set(true);
                            onLease(leasedEntry);
                            if (callback != null) {
                                callback.completed(leasedEntry);
                            }
                            return leasedEntry;
                        }
                    } catch (final IOException ex) {
                        done.set(true);
                        if (callback != null) {
                            callback.failed(ex);
                        }
                        throw new ExecutionException(ex);
                    }
                }
            }

        };
    }

 private E getPoolEntryBlocking(
            final T route, final Object state,
            final long timeout, final TimeUnit tunit,
            final Future&lt;E&gt; future) throws IOException, InterruptedException, TimeoutException {

        Date deadline = null;
        if (timeout &gt; 0) {
            deadline = new Date (System.currentTimeMillis() + tunit.toMillis(timeout));
        }
        this.lock.lock();
        try {
            final RouteSpecificPool&lt;T, C, E&gt; pool = getPool(route);
            E entry;
            for (;;) {
                Asserts.check(!this.isShutDown, &quot;Connection pool shut down&quot;);
                for (;;) {
                    entry = pool.getFree(state);
                    if (entry == null) {
                        break;
                    }
                    if (entry.isExpired(System.currentTimeMillis())) {
                        entry.close();
                    }
                    if (entry.isClosed()) {
                        this.available.remove(entry);
                        pool.free(entry, false);
                    } else {
                        break;
                    }
                }
                if (entry != null) {
                    this.available.remove(entry);
                    this.leased.add(entry);
                    onReuse(entry);
                    return entry;
                }

                // New connection is needed
                final int maxPerRoute = getMax(route);
                // Shrink the pool prior to allocating a new connection
                final int excess = Math.max(0, pool.getAllocatedCount() + 1 - maxPerRoute);
                if (excess &gt; 0) {
                    for (int i = 0; i &lt; excess; i++) {
                        final E lastUsed = pool.getLastUsed();
                        if (lastUsed == null) {
                            break;
                        }
                        lastUsed.close();
                        this.available.remove(lastUsed);
                        pool.remove(lastUsed);
                    }
                }

                if (pool.getAllocatedCount() &lt; maxPerRoute) {
                    final int totalUsed = this.leased.size();
                    final int freeCapacity = Math.max(this.maxTotal - totalUsed, 0);
                    if (freeCapacity &gt; 0) {
                        final int totalAvailable = this.available.size();
                        if (totalAvailable &gt; freeCapacity - 1) {
                            if (!this.available.isEmpty()) {
                                final E lastUsed = this.available.removeLast();
                                lastUsed.close();
                                final RouteSpecificPool&lt;T, C, E&gt; otherpool = getPool(lastUsed.getRoute());
                                otherpool.remove(lastUsed);
                            }
                        }
                        final C conn = this.connFactory.create(route);
                        entry = pool.add(conn);
                        this.leased.add(entry);
                        return entry;
                    }
                }

                boolean success = false;
                try {
                    if (future.isCancelled()) {
                        throw new InterruptedException(&quot;Operation interrupted&quot;);
                    }
                    pool.queue(future);
                    this.pending.add(future);
                    if (deadline != null) {
                        success = this.condition.awaitUntil(deadline);
                    } else {
                        this.condition.await();
                        success = true;
                    }
                    if (future.isCancelled()) {
                        throw new InterruptedException(&quot;Operation interrupted&quot;);
                    }
                } finally {
                    // In case of 'success', we were woken up by the
                    // connection pool and should now have a connection
                    // waiting for us, or else we're shutting down.
                    // Just continue in the loop, both cases are checked.
                    pool.unqueue(future);
                    this.pending.remove(future);
                }
                // check for spurious wakeup vs. timeout
                if (!success &amp;&amp; (deadline != null &amp;&amp; deadline.getTime() &lt;= System.currentTimeMillis())) {
                    break;
                }
            }
            throw new TimeoutException(&quot;Timeout waiting for connection&quot;);
        } finally {
            this.lock.unlock();
        }
    }
</code></pre>
<p>通过代码，我们可以看到 lease 方法返回了 <code>Future</code> 接口的匿名内部类实现，其中 <code>get(final long timeout, final TimeUnit tunit)</code> 方法会在同步代码块下循环从连接池获取连接，即 <code>getPoolEntryBlocking</code> 方法。</p>
<p>在 <code>getPoolEntryBlocking</code> 方法中，会在加锁情况下，循环获取连接，当获取连接为空时（即连接池中没有 <code>available</code> 的连接），会执行 <code>success = this.condition.awaitUntil(deadline)</code>，即阻塞到超时的死亡时间线，如果在阻塞过程中，有其他连接释放（释放的代码后面我们会看到），则会把 <code>success</code> 置为 <code>true</code>，如果没有在死亡线达到之前获取到连接，则 <code>success</code> 为 <code>false</code>，在最后，<code>(!success &amp;&amp; (deadline != null &amp;&amp; deadline.getTime() &lt;= System.currentTimeMillis())</code> 会跳出循环，抛出 <code> throw new TimeoutException(&quot;Timeout waiting for connection&quot;)</code>，被外层捕获。</p>
<p>这就是 httpclient 从连接池获取连接的过程，以及在超时情况下抛出的异常信息。</p>
<h4 id="httpclient-归还连接">httpclient 归还连接</h4>
<p>我们看到在使用 httpclient 的时候，在 <code>finally</code> 代码块中，我们调用了 <code>abort</code> 和 <code>releaseConnection</code> 方法，用来释放 httpclient 连接，下面我们分析下如何释放连接归还连接池。</p>
<h5 id="abort-释放连接">abort 释放连接</h5>
<p>首先看 <code>abort</code> 方法：</p>
<pre><code class="language-java">    @Override
    public void abort() {
        if (this.aborted.compareAndSet(false, true)) {
            final Cancellable cancellable = this.cancellableRef.getAndSet(null);
            if (cancellable != null) {
                cancellable.cancel();
            }
        }
    }
</code></pre>
<p>代码中，将 <code>abort</code> 变量从 <code>false</code> 置为 <code>true</code>，之后获取 <code>Cancellable</code>，并将其置空，调用 <code>cancel</code> 方法，我们看下在何处会放入 <code>Cancellable</code>：</p>
<pre><code class="language-java">    @Override
    public CloseableHttpResponse execute(
            final HttpRoute route,
            final HttpRequestWrapper request,
            final HttpClientContext context,
            final HttpExecutionAware execAware) throws IOException, HttpException {
       //  ......
        Object userToken = context.getUserToken();

        final ConnectionRequest connRequest = connManager.requestConnection(route, userToken);
        if (execAware != null) {
            if (execAware.isAborted()) {
                connRequest.cancel();
                throw new RequestAbortedException(&quot;Request aborted&quot;);
            } else {
                // ① 将 ConnectionRequest 放入 Cancellable
                execAware.setCancellable(connRequest);
            }
        }

        final RequestConfig config = context.getRequestConfig();

        final HttpClientConnection managedConn;
        try {
            final int timeout = config.getConnectionRequestTimeout();
            managedConn = connRequest.get(timeout &gt; 0 ? timeout : 0, TimeUnit.MILLISECONDS);
        } catch(final InterruptedException interrupted) {
            Thread.currentThread().interrupt();
            throw new RequestAbortedException(&quot;Request aborted&quot;, interrupted);
        } catch(final ExecutionException ex) {
            Throwable cause = ex.getCause();
            if (cause == null) {
                cause = ex;
            }
            throw new RequestAbortedException(&quot;Request execution failed&quot;, cause);
        }

        context.setAttribute(HttpCoreContext.HTTP_CONNECTION, managedConn);

        if (config.isStaleConnectionCheckEnabled()) {
            // validate connection
            if (managedConn.isOpen()) {
                this.log.debug(&quot;Stale connection check&quot;);
                if (managedConn.isStale()) {
                    this.log.debug(&quot;Stale connection detected&quot;);
                    managedConn.close();
                }
            }
        }

        final ConnectionHolder connHolder = new ConnectionHolder(this.log, this.connManager, managedConn);
        try {
            if (execAware != null) {
                // ② 将 ConnectionHolder 放入 Cancellable
                execAware.setCancellable(connHolder);
            }
    // .....
    }
</code></pre>
<p>第一处，将 <code>ConnectionRequest</code> 放入。也就是说，如果此时是在执行从连接池获取连接之前调用了 <code>Cancellable.cancel</code>，则会在构建好请求后，直接释放请求，抛出 <code>throw new RequestAbortedException(&quot;Request aborted&quot;);</code> 异常；如果此时在连接获取过程中，在 <code>getPoolEntryBlocking</code> 中调用 <code>Cancellable.cancel</code>，在循环中会调用 <code>future.isCancelled()</code> 判断是否取消任务，抛出 <code>throw new InterruptedException(&quot;Operation interrupted&quot;)</code> 。</p>
<p>第二处，即获取到连接后，将 <code>HttpClientConnection</code> 的持有者 <code>ConnectionHolder</code> 放入。此时，我们看 <code>ConnectionHolder</code> 的 <code>cancel</code> 方法的实现：</p>
<pre><code class="language-java">    @Override
    public boolean cancel() {
        final boolean alreadyReleased = this.released.get();
        log.debug(&quot;Cancelling request execution&quot;);
        abortConnection();
        return !alreadyReleased;
    }

    @Override
    public void abortConnection() {
        if (this.released.compareAndSet(false, true)) {
            synchronized (this.managedConn) {
                try {
                    this.managedConn.shutdown();
                    log.debug(&quot;Connection discarded&quot;);
                } catch (final IOException ex) {
                    if (this.log.isDebugEnabled()) {
                        this.log.debug(ex.getMessage(), ex);
                    }
                } finally {
                    this.manager.releaseConnection(
                            this.managedConn, null, 0, TimeUnit.MILLISECONDS);
                }
            }
        }
    }
</code></pre>
<p><code>ConnectionHolder</code> 的 <code>cancel</code> 方法调用了 <code>abortConnection</code> 方法，在此方法中，首先将 <code>release</code> 置为 <code>true</code>，之后在同步代码块情况下，先调用 <code>this.managedConn.shutdown()</code> 以下是该方法的源码：</p>
<pre><code class="language-java">    @Override
    public void shutdown() throws IOException {
        final Socket socket = this.socketHolder.getAndSet(null);
        if (socket != null) {
            // force abortive close (RST)
            try {
                socket.setSoLinger(true, 0);
            } catch (final IOException ex) {
            } finally {
                socket.close();
            }
        }
    }
</code></pre>
<p>主要功能是为了将 <code>Connection</code> 的 Socket 对象置空，之后将 <code>socket</code> 关闭。</p>
<p>之后，在 <code>finally</code> 中，调用 <code>manager.releaseConnection</code> 方法，源码如下：</p>
<pre><code class="language-java">    @Override
    public void releaseConnection(
            final HttpClientConnection managedConn,
            final Object state,
            final long keepalive, final TimeUnit tunit) {
        Args.notNull(managedConn, &quot;Managed connection&quot;);
        synchronized (managedConn) {
            final CPoolEntry entry = CPoolProxy.detach(managedConn);
            if (entry == null) {
                return;
            }
            final ManagedHttpClientConnection conn = entry.getConnection();
            try {
                if (conn.isOpen()) {
                    final TimeUnit effectiveUnit = tunit != null ? tunit : TimeUnit.MILLISECONDS;
                    entry.setState(state);
                    entry.updateExpiry(keepalive, effectiveUnit);
                    if (this.log.isDebugEnabled()) {
                        final String s;
                        if (keepalive &gt; 0) {
                            s = &quot;for &quot; + (double) effectiveUnit.toMillis(keepalive) / 1000 + &quot; seconds&quot;;
                        } else {
                            s = &quot;indefinitely&quot;;
                        }
                        this.log.debug(&quot;Connection &quot; + format(entry) + &quot; can be kept alive &quot; + s);
                    }
                    conn.setSocketTimeout(0);
                }
            } finally {
                this.pool.release(entry, conn.isOpen() &amp;&amp; entry.isRouteComplete());
                if (this.log.isDebugEnabled()) {
                    this.log.debug(&quot;Connection released: &quot; + format(entry) + formatStats(entry.getRoute()));
                }
            }
        }
    }
</code></pre>
<p>在 <code>finally</code> 中的 <code>pool.release</code> 方法中：</p>
<pre><code class="language-java">    @Override
    public void release(final E entry, final boolean reusable) {
        this.lock.lock();
        try {
            if (this.leased.remove(entry)) {
                final RouteSpecificPool&lt;T, C, E&gt; pool = getPool(entry.getRoute());
                pool.free(entry, reusable);
                if (reusable &amp;&amp; !this.isShutDown) {
                    this.available.addFirst(entry);
                } else {
                    entry.close();
                }
                onRelease(entry);
                Future&lt;E&gt; future = pool.nextPending();
                if (future != null) {
                    this.pending.remove(future);
                } else {
                    future = this.pending.poll();
                }
                if (future != null) {
                    this.condition.signalAll();
                }
            }
        } finally {
            this.lock.unlock();
        }
    }
</code></pre>
<p>我们可以看到，连接对象从 <code>lease</code> 队列移除，并调用 <code>pool.free</code> 方法，将连接重新放回 <code>available</code> 队列的第一个：</p>
<pre><code class="language-java">    public void free(final E entry, final boolean reusable) {
        Args.notNull(entry, &quot;Pool entry&quot;);
        final boolean found = this.leased.remove(entry);
        Asserts.check(found, &quot;Entry %s has not been leased from this pool&quot;, entry);
        if (reusable) {
            this.available.addFirst(entry);
        }
    }
</code></pre>
<p>注意，此处分别是 <code>ConnectionPool</code> 和 <code>RouteSpecificPool</code>，<code>ConnectionPool</code> 包含了 <code>RouteSpecificPool</code>。</p>
<p>在将连接放回 <code>available</code> 队列后，<code>pool.nexPending</code> 获取待获取连接的挂起队列，移除一个获取连接，之后 <code>condition.signalAll()</code> 通知所有的等待的 <code>future</code> 获取连接。</p>
<h5 id="releaseconnection-释放连接">releaseConnection 释放连接</h5>
<p>我们来看 <code>releaseConnection</code> 的代码：</p>
<pre><code class="language-java">    /**
     * A convenience method to simplify migration from HttpClient 3.1 API. This method is
     * equivalent to {@link #reset()}.
     *
     * @since 4.2
     */
    public void releaseConnection() {
        reset();
    }

    /**
     * Resets internal state of the request making it reusable.
     *
     * @since 4.2
     */
    public void reset() {
        final Cancellable cancellable = this.cancellableRef.getAndSet(null);
        if (cancellable != null) {
            cancellable.cancel();
        }
        this.aborted.set(false);
    }
</code></pre>
<p>我们可以看到，此处也是使用和 <code>abort</code> 一样的方式调用 <code>Cancellable.cancel</code> 方法，但是，在方法最后，将 <code>aborted</code> 设置为了 <code>false</code>。</p>
<p>简单翻一下方法注释，<code>Resets internal state of the request making it reusable.</code>，即重置请求的内部状态，使其可以重新使用。 我们发现，<code>releaseConnection</code> 的作用是使请求可以重用，所以将 <code>aborted</code> 重新置为了 <code>false</code>。</p>
<h2 id="问题处理">问题处理</h2>
<p>通过上面分析，我们发现，调用 <code>abort</code> 方法时，将请求的 <code>aborted</code> 标志设为了 <code>true</code>，而调用 <code>releaseConnection</code> 后，请求的 <code>aborted</code> 标志被重置为了 <code>false</code>。而在代码中，会通过 <code>aborted</code> 标志判断当前请求是否可用：</p>
<pre><code class="language-java">    @Override
    public CloseableHttpResponse execute(
            final HttpRoute route,
            final HttpRequestWrapper request,
            final HttpClientContext context,
            final HttpExecutionAware execAware) throws IOException, HttpException {
        // 使用 aborted 判断是否需要取消 ConnectionRequest
        final ConnectionRequest connRequest = connManager.requestConnection(route, userToken);
        if (execAware != null) {
            if (execAware.isAborted()) {
                connRequest.cancel();
                throw new RequestAbortedException(&quot;Request aborted&quot;);
            } else {
                execAware.setCancellable(connRequest);
            }
        }

        // ......
      
        final ConnectionHolder connHolder = new ConnectionHolder(this.log, this.connManager, managedConn);
        try {
            if (execAware != null) {
                execAware.setCancellable(connHolder);
            }

            HttpResponse response;
            for (int execCount = 1;; execCount++) {

                if (execCount &gt; 1 &amp;&amp; !RequestEntityProxy.isRepeatable(request)) {
                    throw new NonRepeatableRequestException(&quot;Cannot retry request &quot; +
                            &quot;with a non-repeatable request entity.&quot;);
                }

        // 使用 aborted 判断请求是否丢弃
                if (execAware != null &amp;&amp; execAware.isAborted()) {
                    throw new RequestAbortedException(&quot;Request aborted&quot;);
                }

                // ......

                final int timeout = config.getSocketTimeout();
                if (timeout &gt;= 0) {
                    managedConn.setSocketTimeout(timeout);
                }

                // 使用 aborted 判断请求是否丢弃
                if (execAware != null &amp;&amp; execAware.isAborted()) {
                    throw new RequestAbortedException(&quot;Request aborted&quot;);
                }

                if (this.log.isDebugEnabled()) {
                    this.log.debug(&quot;Executing request &quot; + request.getRequestLine());
                }

                if (this.log.isDebugEnabled()) {
                    this.log.debug(&quot;Executing request &quot; + request.getRequestLine());
                }

                if (!request.containsHeader(AUTH.WWW_AUTH_RESP)) {
                    if (this.log.isDebugEnabled()) {
                        this.log.debug(&quot;Target auth state: &quot; + targetAuthState.getState());
                    }
                    this.authenticator.generateAuthResponse(request, targetAuthState, context);
                }
                if (!request.containsHeader(AUTH.PROXY_AUTH_RESP) &amp;&amp; !route.isTunnelled()) {
                    if (this.log.isDebugEnabled()) {
                        this.log.debug(&quot;Proxy auth state: &quot; + proxyAuthState.getState());
                    }
                    this.authenticator.generateAuthResponse(request, proxyAuthState, context);
                }

                response = requestExecutor.execute(request, managedConn, context);

                // The connection is in or can be brought to a re-usable state.
                if (reuseStrategy.keepAlive(response, context)) {
                    // Set the idle duration of this connection
                    final long duration = keepAliveStrategy.getKeepAliveDuration(response, context);
                    if (this.log.isDebugEnabled()) {
                        final String s;
                        if (duration &gt; 0) {
                            s = &quot;for &quot; + duration + &quot; &quot; + TimeUnit.MILLISECONDS;
                        } else {
                            s = &quot;indefinitely&quot;;
                        }
                        this.log.debug(&quot;Connection can be kept alive &quot; + s);
                    }
                    connHolder.setValidFor(duration, TimeUnit.MILLISECONDS);
                    connHolder.markReusable();
                } else {
                    connHolder.markNonReusable();
                }

                if (needAuthentication(
                        targetAuthState, proxyAuthState, route, response, context)) {
                    // Make sure the response body is fully consumed, if present
                    final HttpEntity entity = response.getEntity();
                    if (connHolder.isReusable()) {
                        EntityUtils.consume(entity);
                    } else {
                        managedConn.close();
                        if (proxyAuthState.getState() == AuthProtocolState.SUCCESS
                                &amp;&amp; proxyAuthState.isConnectionBased()) {
                            this.log.debug(&quot;Resetting proxy auth state&quot;);
                            proxyAuthState.reset();
                        }
                        if (targetAuthState.getState() == AuthProtocolState.SUCCESS
                                &amp;&amp; targetAuthState.isConnectionBased()) {
                            this.log.debug(&quot;Resetting target auth state&quot;);
                            targetAuthState.reset();
                        }
                    }
                    // discard previous auth headers
                    final HttpRequest original = request.getOriginal();
                    if (!original.containsHeader(AUTH.WWW_AUTH_RESP)) {
                        request.removeHeaders(AUTH.WWW_AUTH_RESP);
                    }
                    if (!original.containsHeader(AUTH.PROXY_AUTH_RESP)) {
                        request.removeHeaders(AUTH.PROXY_AUTH_RESP);
                    }
                } else {
                    break;
                }
            }

            if (userToken == null) {
                userToken = userTokenHandler.getUserToken(context);
                context.setAttribute(HttpClientContext.USER_TOKEN, userToken);
            }
            if (userToken != null) {
                connHolder.setState(userToken);
            }

            // check for entity, release connection if possible
            final HttpEntity entity = response.getEntity();
            if (entity == null || !entity.isStreaming()) {
                // connection not needed and (assumed to be) in re-usable state
                connHolder.releaseConnection();
                return new HttpResponseProxy(response, null);
            } else {
                return new HttpResponseProxy(response, connHolder);
            }
        } catch (final ConnectionShutdownException ex) {
            final InterruptedIOException ioex = new InterruptedIOException(
                    &quot;Connection has been shut down&quot;);
            ioex.initCause(ex);
            throw ioex;
        } catch (final HttpException ex) {
            connHolder.abortConnection();
            throw ex;
        } catch (final IOException ex) {
            connHolder.abortConnection();
            if (proxyAuthState.isConnectionBased()) {
                proxyAuthState.reset();
            }
            if (targetAuthState.isConnectionBased()) {
                targetAuthState.reset();
            }
            throw ex;
        } catch (final RuntimeException ex) {
            connHolder.abortConnection();
            if (proxyAuthState.isConnectionBased()) {
                proxyAuthState.reset();
            }
            if (targetAuthState.isConnectionBased()) {
                targetAuthState.reset();
            }
            throw ex;
        } catch (final Error error) {
            connManager.shutdown();
            throw error;
        }
    }
</code></pre>
<p>在同步状态下，由于调用 <code>abort</code> 和 <code>releaseConnection</code> 时，此时客户端请求已经结束，所以修改状态不会造成问题（由于项目中每次都是重新构建请求，所以也没有重用请求）。但是当请求在异步执行时，在执行请求的同时如果丢弃连接（执行 <code>finally</code> 的 <code>abort</code> 和 <code>releaseConnection</code>），此时可能在连接获取的阻塞阶段，<code>cancel</code> 可能取消的是 <code>future</code>，而如果此时 <code>future</code> 已经获取并返回连接，由于后面调用 <code>releaseConnection</code> 将请求的 <code>aborted</code> 置为 <code>false</code>，判断中断失效，不会抛出异常，那么已获取的连接就不会被释放。</p>
<h3 id="修复方法">修复方法</h3>
<h4 id="删除-releaseconnection">删除 releaseConnection</h4>
<p>如果在使用中不会复用请求，那么我们可以不再调用 <code>releaseConnection</code>，因为 <code>abort</code> 已经调用了 <code>Cancellable</code> 的 <code>cancel</code> 方法，因此，相当于 <code>releaseConnection</code> 只会执行 <code>this.aborted.set(false)</code>，而这会导致执行请求的线程在判断时不抛出异常，也就不会被捕获然后释放连接。</p>
<h4 id="将-abort-和-releaseconnection-放入异步方法的-finally-执行">将 abort 和 releaseConnection 放入异步方法的 finally 执行</h4>
<p>当我们想要复用连接时，我们可以将外面的释放连接方法放入异步方法的 <code>finally</code> 中执行，如下：</p>
<pre><code class="language-java">            try {
                future = executor.submit(() -&gt; {
                    try {
                        return HttpClientUtil.execute(httpGet);
                    } catch (Exception e) {
                        logger.error(&quot;&quot;, e);
                        return null;
                    } finally {
                        httpGet.abort();
                        httpGet.releaseConnection();
                    }
                });
                response = future.get(5, TimeUnit.SECONDS);
                System.out.println(&quot;response = &quot; + response);
            } catch (Exception e) {
                if (e instanceof TimeoutException &amp;&amp; future != null) {
                    logger.info(Thread.currentThread().getName() + &quot; start cancel future&quot;);
                    logger.error(&quot;&quot;, e);
                    }
                }
            } finally {
                if (null != response) {
                    EntityUtils.consume(response.getEntity());
                }
            }
</code></pre>
<p>注意，在 <code>Future.get</code> 方法超时后，不会终止任务，而是丢弃任务执行的结果，因此，当调用结束时，方法依旧会执行 <code>finally</code> 释放连接，但是要通过 <code>Futrue.isDone</code> 判断 <code>Future</code> 是否执行结束，才能重新复用请求对象。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Chapter 12. Execution]]></title>
        <id>https://wenbozhangw.github.io/post/chapter-12-execution/</id>
        <link href="https://wenbozhangw.github.io/post/chapter-12-execution/">
        </link>
        <updated>2022-06-02T06:37:24.000Z</updated>
        <summary type="html"><![CDATA[<p>此章节规定了程序执行期间发生的活动。他围绕 Java 虚拟机以及构成程序的类、接口和对象的声明周期进行组织编写。</p>
<p>Java 虚拟机通过加载指定的类然后调用该类中的 <code>main</code> 方法来启动。第 <a href="#121-java-virtual-machine-startup">12.1</a> 节概述了执行 main 所涉及的加载、链接和初始化步骤，作为本章节的概念的介绍。下一个部分讲述了加载 <a href="#122-loading-of-classes-and-interfaces">12.2</a> 、链接  <a href="#123-linking-of-classes-and-interfaces">12.3</a> 和初始化  <a href="#124-initialization-of-classes-and-interfaces">12.4</a>  的细节。</p>
<p>本章后续部分说明创建新类实例的过程（第 <a href="#125-creation-of-new-class-instances">12.5</a> 节 ）；和类实例的最终确定（ <a href="#126-finalization-of-class-instances">12.6</a> ）。它通过描述类的卸载（第 <a href="#127-unloading-of-classes-and-interfaces">12.7</a> 节 ）和程序退出时遵循的过程（第 <a href="#128-program-exit">12.8</a> 节 ）来结束。</p>
]]></summary>
        <content type="html"><![CDATA[<p>此章节规定了程序执行期间发生的活动。他围绕 Java 虚拟机以及构成程序的类、接口和对象的声明周期进行组织编写。</p>
<p>Java 虚拟机通过加载指定的类然后调用该类中的 <code>main</code> 方法来启动。第 <a href="#121-java-virtual-machine-startup">12.1</a> 节概述了执行 main 所涉及的加载、链接和初始化步骤，作为本章节的概念的介绍。下一个部分讲述了加载 <a href="#122-loading-of-classes-and-interfaces">12.2</a> 、链接  <a href="#123-linking-of-classes-and-interfaces">12.3</a> 和初始化  <a href="#124-initialization-of-classes-and-interfaces">12.4</a>  的细节。</p>
<p>本章后续部分说明创建新类实例的过程（第 <a href="#125-creation-of-new-class-instances">12.5</a> 节 ）；和类实例的最终确定（ <a href="#126-finalization-of-class-instances">12.6</a> ）。它通过描述类的卸载（第 <a href="#127-unloading-of-classes-and-interfaces">12.7</a> 节 ）和程序退出时遵循的过程（第 <a href="#128-program-exit">12.8</a> 节 ）来结束。</p>
<!-- more -->
<h2 id="121-java-virtual-machine-startup">12.1 Java Virtual Machine Startup</h2>
<p>Java 虚拟机通过调用某个指定类的 <code>main</code> 方法开始执行，并传递给它一个参数，该参数是一个字符串数组。在本规范的示例中，这个特定类通常称为 <code>Test</code>。</p>
<p>Java 虚拟机启动的精确语义在 <em>Java Virtual Machine Specification, Java SE 8 Edition</em>  的第 5 章中给出。在这里，我们从 Java 编程语言的角度概述了该过程。</p>
<p>将初始类指定给 Java 虚拟的方式超出了本规范的范围，但在使用命令行的主机环境中，这是典型的，对于作为命令行参数指定的类的全限定名，以及将后面的命令参数作为字符串提供给方法 <code>main</code> 。</p>
<p>例如，在 UNIX 实现中，命令行：</p>
<pre><code>java Test reboot Bob Dot Enzo
</code></pre>
<p>通常会通过调用类 <code>Test</code>（未命名包中的类）的方法 <code>main</code> 类启动 Java 虚拟机，并向其传递包含四个字符串 &quot;reboot&quot;、&quot;Bob&quot;、&quot;Dot&quot; 和 &quot;Enzo&quot; 的数组。</p>
<p>我们现在概述 Java 虚拟机执行 <code>Test</code> 可能采取的步骤，作为加载、连接和初始化过程的例子，这些过程将在后面的部分中进一步描述。</p>
<h3 id="1211-load-the-class-test">12.1.1 Load the Class Test</h3>
<p>最初尝试执行类 <code>Test</code> 和 <code>main</code> 方法时，发现没有加载类 <code>Test</code> —— 也就是说，Java 虚拟机当前不包含这个类的二进制表示。然后，Java 虚拟机使用类加载器来尝试找到这样的二进制表示。如果这个过程失败，就会抛出一个错误。该加载张将在 <a href="#122-loading-of-classes-and-interfaces">12.2</a> 中进一步描述。</p>
<h3 id="1212-link-test-verify-prepare-optionally-resolve">12.1.2 Link Test: Verify, Prepare, (Optionally) Resolve</h3>
<p>加载 <code>Test</code> 后，必须调用 <code>main</code> 之前对其进行初始化。和所有（类或接口）类型一样，<code>Test</code> 在初始化之前必须被连接。连接包括<strong>验证</strong>、<strong>准备</strong> 和 <strong>（可选）解析</strong> 。链接将在 <a href="#123-linking-of-classes-and-interfaces">12.3</a> 中进一步描述。</p>
<p><strong>验证</strong>会检查 <code>Test</code> 的加载表示是否格式良好，是否有正确的符号表。验证还检查实现 <code>Test</code> 的代码是否符合 Java 编程语言和 Java 虚拟机的语义要求。如果在验证过程中检测到问题，就会抛出一个错误。<a href="#1231-verification-of-the-binary-representation">12.3.1</a> 中进一步描述了验证。</p>
<p><strong>准备</strong>包括静态存储和 Java 虚拟机实现内部使用的任何数据结构的分配，比如方法表。<a href="#1232-preparation-of-a-class-or-interface-type">12.3.2</a> 中进一步描述了准备工作。</p>
<p><strong>解析</strong>是检查从 <code>Test</code> 到其他类和接口的符号引用的过程，通过加载提到的其他类和接口并检查引用使用正常。</p>
<p>在初始化连接时，解析步骤是可选的。一种实现可以从很早就被链接的类或接口中解析符号引用，甚至可以从被引用的类和接口中进一步递归解析所有符号引用。（该解决方案可能会导致这些进一步加载和链接步骤的错误。）这种实现选择代表了一个极端，类似于在 C 语言的简单实现中已经做了多年的这种“静态”链接。。（在这些实现中，编译后的程序通常被表示为 “a.out” 文件，改文件包含该程序的完全链接版本，包括到该程序所使用的程序例程的完全解析的连接。这些库例程的副本包含在 “a.out” 文件中。）</p>
<p>一种实现可以选择仅在符号引用被主动使用时解析它；对所有符号引用一致使用这种策略将代表的是“最懒惰”的解决方式。在这种情况下，如果 Test 有几个对另一个类的符号引用，那么这些引用可能会在使用时一次解析一个，或者如果这些引用的程序执行期间从未使用过，则可能根本不解析。</p>
<p>对何时执行解析的唯一要求是，在解析过程中检测到的任何错误都必须在程序中的某个点抛出，在该点上，程序将采用一些可能直接或间接地采取一些操作，这些操作可能需要链接到设计错误的类或接口。使用上面描述的 “静态” 示例实现选择，如果加载和链接错误涉及类 Test 或任何进一步递归引用的类和接口中提到的类和接口，那么它们可能在程序执行之前发生。在实现“最懒惰”解析的系统中，只有在积极使用不正确的符号引用时才会抛出这些错误。</p>
<p>解析过程在第 <a href="#1233-resolution-of-symbolic-references">12.3.3</a> 节中进一步描述。</p>
<h3 id="1213-initialize-test-execute-initializers">12.1.3 Initialize Test: Execute Initializers</h3>
<p>在我们接下来的示例中，Java 虚拟机仍在尝试执行 <code>Test</code> 类的 <code>main</code> 方法。仅当类已初始化时才允许这样做（第 <a href="#1241-when-initialization-occurs">12.4.1</a> 节 ）。</p>
<p>初始化包括按文本顺序执行类 <code>Test</code> 的任何类变量初始化程序和静态初始化程序。但是在初始化 <code>Test</code> 之前，它的直接超类必须被初始化，以及它的直接超类的直接超类，以此递归类推。在最简单的情况下，<code>Test</code> 将 <code>Object</code> 作为其隐式直接超类；如果类 <code>Object</code> 尚未初始化，则必须初始化 <code>Test</code> 之前对齐进行初始化。类 <code>Object</code> 没有超类，所以递归在这里终止。</p>
<p>如果类 <code>Test</code> 有另一个类 <code>Super</code> 作为它的父类，那么 <code>Super</code> 必须在 <code>Test</code> 之前初始化。这需要加载、验证和准备 <code>Super</code> （如果还没有这样做的话），根据实现的不同，可能涉及递归地解析来自 <code>Super</code> 的符号引用等等。</p>
<p>因此，初始化可能会导致加载、连接和初始化错误，包括涉及其他类型的此类错误。</p>
<p>初始化过程在第 <a href="#124-initialization-of-classes-and-interfaces">12.4</a> 节中进一步描述。</p>
<h3 id="1214-invoke-testmain">12.1.4 Invoke Test.main</h3>
<p>最后，在 <code>Test</code> 类的初始化完成后（在此期间可能发生了其他相应的加载、连接和初始化），调用 <code>Test</code> 的 <code>main</code> 方法。</p>
<p>方法 <code>main</code> 必须声明为 <code>public</code>、<code>static</code> 和 <code>void</code>。它必须指定一个声明类型为字符串数组 的形式参数（第 8.4.1 节）。因此，可以接受以下任一声明：</p>
<pre><code class="language-java">public static void main(String[] args)
</code></pre>
<pre><code class="language-java">public static void main(String... args)
</code></pre>
<hr>
<h2 id="122-loading-of-classes-and-interfaces">12.2 Loading of Classes and Interfaces</h2>
<p><strong>加载</strong> 指的是找到具有特定名称的类和接口类型的二进制形式的过程，可能是通过即时计算，但更常见的是通过检索 Java 编译器先前从源代码计算的二进制表示，并根据该二进制形式构造表示类或接口的 <code>Class</code> 对象。</p>
<p>*Java Virtual Machine Specification, Java SE 8 Edition * 的第 5 章给出了加载的精确语义。在这里，我们从 Java 编程语言的角度概述了该过程。</p>
<p>类或接口的二进制格式通常是上面引用的 *Java Virtual Machine Specification, Java SE 8 Edition *  中描述的类文件格式，但是其他格式也是可能的，只要它们满足 13.1 中指定的要求。<code>ClassLoader</code> 类的 <code>defineClass</code> 方法可用于从 <code>class</code> 文件格式的二进制表示中构造 <code>Class</code> 对象。</p>
<p>行为良好的类加载器维护以下属性：</p>
<ul>
<li>给定相同的名称，一个好的类加载器总是返回相同的类对象。</li>
<li>如果一个类加载器 <code>L1</code> 将类 <code>C</code> 的加载委托给另一个加载器 <code>L2</code>，那么对于 <code>C</code> 的直接超类或直接超接口，或者作为 <code>C</code> 中的字段类型，或者作为 <code>C</code> 中的方法或构造函数的形参类型，或者作为 <code>C</code> 中方法的返回类型出现的任何 <code>T</code> 类型，<code>L1</code> 和 <code>L2</code> 应该返回相同的 <code>Class</code> 对象。</li>
</ul>
<p>恶意的类加载器可能会破坏这些属性。然而，它不能破坏类型系统的安全性，因为 Java 虚拟机防止了这一点。</p>
<p>进一步讨论这些问题，请参阅 <em>Java Virtual Machine Specification, Java SE 8 Edition and the paper Dynamic Class Loading in the Java Virtual Machine, by Sheng Liang and Gilad Bracha, in Proceedings of OOPSLA '98, published as ACM SIGPLAN Notices, Volume 33, Number 10, October 1998, pages 36-44</em> 。Java 编程语言设计的一个基本原则是，运行时类型系统不能被用 Java 编程语言编写的代码破坏，甚至不能被诸如 <code>ClassLoader</code> 和 <code>SecurityManager</code> 之类的敏感系统类的实现破坏。</p>
<h3 id="1221-the-loading-process">12.2.1 The Loading Process</h3>
<p>加载过程由 <code>ClassLoader</code> 类及其子类实现。</p>
<p><code>ClassLoader</code> 的不同子类可以实现不同的加载策略。特别是，类加载器可以缓存类和接口的二进制表示，根据预期的使用情况预读取它们，或者一起加载一组相关的类。这些活动对于正在运行的应用程序可能不是完全透明的，例如，如果因为类加载器缓存了旧版本而找不到类的新编译版本。然而，类加载器的责任是旨在程序中没有预读取或分组加载的地方反映加载错误。</p>
<p>如果在类加载过程中出现错误，则在程序中（直接或间接）使用该类型的任何点都会引发 <code>LinkageError</code> 类的子类之一的实例：</p>
<ul>
<li><code>ClassCircularityError</code>：无法加载类或接口，因为它将是其自己的超类或超接口（第 8.1.4 节、第 9.1.3 节、第 13.4.4 节）。</li>
<li><code>ClassFormatError</code>：声明指定所请求的编译类或接口的二进制数据格式不正确。</li>
<li><code>NoClassDefFoundError</code>：相关的类加载器找不到请求的类或接口的定义。</li>
</ul>
<p>因为加载涉及新数据结构的分配，所以它可能会因 <code>OutOfMemoryError</code> 而失败。</p>
<h2 id="123-linking-of-classes-and-interfaces">12.3 Linking of Classes and Interfaces</h2>
<p><strong>链接</strong> 是获取类或接口类型的二进制形式，并将其组合到 Java 虚拟机的运行时状态中，以便可以执行的过程。类或接口类型总是在连接之前加载。</p>
<p>链接设计三种不同的活动：验证、准备和解析符号引用。</p>
<p><em>Java Virtual Machine Specification, Java SE 8 Edition</em> 的第 5 章中给出了链接的精确语义。在这里，我们从 Java 编程语言的角度概述了这个过程。</p>
<p>如果考虑到 Java 编程语言的语义，类或接口在初始化之前就被完全验证和准备，并且在链接期间检测到的错误在程序中的某个点被抛出，在该点处程序采取了可能需要链接到错误中涉及的类或接口的一些动作，则该规范允许关于链接活动（以及由于递归，加载）何时发生的实现灵活性。</p>
<p>例如，一个实现可以选择仅当一个类或接口被使用时（惰性或延迟解析），单独解析它当的每个符号引用，或者在类被验证时一次性解析它们（静态解析）。这意味着，在一些实现中，在类或接口被初始化之后，解析过程可以继续。</p>
<p>因为链接涉及新数据结构的分配，所以它可能会因 <code>OutOfMemoryError</code> 而失败。</p>
<h3 id="1231-verification-of-the-binary-representation">12.3.1 Verification of the Binary Representation</h3>
<p><strong>验证</strong>确保类或接口的二进制表示在接口上是正确的。例如，它检查每条指令都有一个有效的操作码；每个分支指令都分支到其他指令的开始，而不是一条指令的中间；每个方法都具有结构正确的签名；并且每条指令都遵守 Java 虚拟机语言的类型规则。</p>
<p>如果在验证过程中出现错误，那么将在程序中导致该类在被验证的点处抛出 <code>LinkageError</code> 类的以下子类的实例：</p>
<ul>
<li><code>VerifyError</code>：类或接口的二进制定义未能通过一组必须的检查，以验证它符合 Java 虚拟机语言的语义，并且不会破坏 Java 虚拟机的完整性。（一些示例见 13.4.2、13.4.4、13.4.9 和 13.4.17。 ）</li>
</ul>
<h3 id="1232-preparation-of-a-class-or-interface-type">12.3.2 Preparation of a Class or Interface Type</h3>
<p><strong>准备</strong>工作包括为类或接口创建 <code>static</code> 字段（类变量和常量），并将这些字段初始化为默认值（4.12.5）。这不需要执行任何源代码；静态字段的显式初始化器作为初始化（12.4）的一部分执行，而不是准备。</p>
<p><em>Java 虚拟机的实现可以在准备时预先计算额外的数据结构，以便使以后对类或接口的操作更有效。一种特别有用的数据结构是“方法表”或其他数据结构，它允许在一个类的实例上调用任何方法，而不需要在调用时搜索超类。</em></p>
<h3 id="1233-resolution-of-symbolic-references">12.3.3 Resolution of Symbolic References</h3>
<p>类或接口的二进制表示引用其他类和接口（13.1）的二进制名称（13.1），象征性地引用其他类和接口及其字段、方法和构造函数。对于字段和方法，这些符号引用包括字段或方法所属的类或接口类型的名称，以及字段或方法本身的名称，以及适当的类型信息。</p>
<p>在符号引用可以被使用之前，它必须经过解析，其中符号引用被检查为正确的，并且通常被替换为直接引用，如果引用被重复使用，则直接引用可以被更有效地处理。</p>
<p>如果在解析过程中出现错误，那么将会抛出一个错误。最典型的情况是，这将是 <code>IncompatibleClassChangeError</code> 类的下列子类之一的实例，但也可能是 <code>IncompatibleClassChangeError</code> 的其他子类的实例，甚至是 <code>IncompatibleClassChangeError</code> 类本身的实例。此错误可能在程序中直接或间接使用对该类型的符号引用的任何位置引发：</p>
<ul>
<li><code>IllegalAccessError</code>：遇到了指定字段的使用或赋值、方法的调用或类实例的创建的符号引用，而包含该引用的代码无权访问这些引用，因为该字段 <code>private</code> 、<code>protected</code> 或 <code>package</code> 访问权限（非 <code>public</code>）声明的，或者因为该类未声明为 <code>public</code>。<br>
例如，如果一个最初声明为 <code>public</code> 的字段在另一个引用该字段的类被编译后被更改为 <code>private</code>，就会发生这种情况（13.4.7）。</li>
<li><code>InstantiationError</code>：遇到了在类创建表达式中使用的符号引用，但无法创建实例，因为该引用引用了接口或抽象类。<br>
例如，如果一个原本不是抽象的类在另一个引用该类的类被编译后变成了抽象的，就会发生这种情况（13.4.1）。</li>
<li><code>NoSuchFieldError</code>：遇到了引用特定类或接口的特定字段的符号引用，但该类或接口不包含该名称的字段。<br>
例如，如果在编译了引用某个字段的另一个类之后，从该类中删除了该字段声明，就会出现这种情况(13.4.8)。</li>
<li><code>NoSuchMethodError</code>：遇到了引用特定类或接口的特定方法的符号引用，但该类或接口不包含该签名的方法。<br>
例如，如果在编译了引用某个方法的另一个类之后，从该类中删除了该方法声明，就会出现这种情况(13.4.12)。</li>
</ul>
<p>此外，如果某个类声明了一个无法找到实现的 <code>native</code> 方法，则可能会引发 <code>UnsatisfiedLinkError</code>，<code>LinkageError</code>的子类。根据 Java 虚拟机（12.3）的实现所使用的解析策略的类型，如果使用了方法，或者更早，就会出现错误。</p>
<h2 id="124-initialization-of-classes-and-interfaces">12.4 Initialization of Classes and Interfaces</h2>
<p><strong>初始化</strong>类包括执行它的静态初始化器和在类中声明的 <code>static</code> 字段（类变量）的初始化器。</p>
<p><strong>初始化</strong>接口包括为接口中声明的字段（常量）执行初始化器。</p>
<h3 id="1241-when-initialization-occurs">12.4.1 When Initialization Occurs</h3>
<p>类或接口类型 T 将在第一次出现以下任何一种情况之前立即初始化：</p>
<ul>
<li>T 是一个类并且创建了 T 的一个实例。</li>
<li>调用由 T 声明的 <code>static</code> 方法。</li>
<li>分配一个由 T 声明的 <code>static</code> 字段。</li>
<li>使用由 T 声明的 <code>static</code> 字段，并且该字段不是常量变量（4.12.4）。</li>
<li>T 是顶级类（7.6），并且执行了断言语句（14.10），它在词法上嵌套在 T （8.1.3）中。</li>
</ul>
<p>当一个类被初始化时，它的超类（如果它们之前没有被初始化），以及声明任何默认方法的超接口（8.1.5）（如果它们之前没有被初始化）也会被初始化。接口的初始化本身不会导致它的任何超接口的初始化。</p>
<p>引用 <code>static</code> 字段（8.3.1.1）只会初始化实际声明静态字段的类或接口，即使它可能通过子类，子接口或实现接口的类的名称被引用。</p>
<p>在类 <code>Class</code> 和包 <code>java.lang.reflect</code> 中调用某些反射方法也会导致类或接口初始化。</p>
<p>类或接口在任何其他情况下都不会初始化。</p>
<p><em>注意，编译器可以在接口中生成合成的默认方法，也就是说，既没有显示声明也没有隐式声明的默认方法（13.1）。这些方法将触发接口的初始化，尽管源代码没有给出应该初始化接口的指示。</em></p>
<p>目的是一个类或接口类型有一组初始化器，使它处于一致的状态，并且这个状态是其他类观察到的第一个状态。静态初始值设定项和类变量初始值设定项是按文本顺序执行的，可能不会引用在勒种声明的类变量，这些类变量的声明在使用后以文本形式出现，即使这些类变量在作用域内（8.3.3）。这种限制旨在编译时检测大多数循环或错误的初始化。</p>
<p>初始化代码是不受限制的，这一事实允许构造这样的例子，其中在评估初始化表达式之前，当类变量仍然具有其初始默认值时，可以观察到类变量的值，但是这样的例子在实践中很少。（这样的例子也可以构造为变量初始化（<a href="#125-creation-of-new-class-instances">12.5</a>）。）Java 编程语言的全部功能都可以在这些初始化器中获得；程序员必须小心谨慎。这种能力给代码生成器带来了额外的负担，但是这种负担在任何情况下都会出现，因为 Java 编程语言是并发的（<a href="#1242-detailed-initialization-procedure">12.4.2</a>）。</p>
<p>例子 12.4.1-1，超类在子类之前初始化：</p>
<pre><code class="language-java">class Super {
    static { System.out.print(&quot;Super &quot;); }
}
class One {
    static { System.out.print(&quot;One &quot;); }
}
class Two extends Super {
    static { System.out.print(&quot;Two &quot;); }
}
class Test {
    public static void main(String[] args) {
        One o = null;
        Two t = new Two();
        System.out.println((Object)o == (Object)t);
    }
}
</code></pre>
<p>此程序输出：</p>
<pre><code>Super Two false
</code></pre>
<p>类 <code>One</code> 永远不会被初始化，因为它没有被主动使用，因此永远不会被链接到。类 <code>Two</code> 仅在其超类 <code>Super</code> 被初始化后才被初始化。</p>
<p>例子 12.4.1-2，只有声明 <code>static</code> 字段的类被初始化：</p>
<pre><code class="language-java">class Super {
    static int taxi = 1729;
}
class Sub extends Super {
    static { System.out.print(&quot;Sub &quot;); }
}
class Test {
    public static void main(String[] args) {
        System.out.println(Sub.taxi);
    }
}
</code></pre>
<p>此程序输出：</p>
<pre><code>1729
</code></pre>
<p>因为 <code>Sub</code> 类从未初始化；对 <code>Sub.taxi</code> 的引用是对 <code>Super</code> 类中实际声明的字段的引用，不会触发 <code>Sub</code> 类的初始化。</p>
<p>例子 12.4.1-3，接口初始化不初始化超接口：</p>
<pre><code class="language-java">interface I {
    int i = 1, ii = Test.out(&quot;ii&quot;, 2);
}
interface J extends I {
    int j = Test.out(&quot;j&quot;, 3), jj = Test.out(&quot;jj&quot;, 4);
}
interface K extends J {
    int k = Test.out(&quot;k&quot;, 5);
}
class Test {
    public static void main(String[] args) {
        System.out.println(J.i);
        System.out.println(K.j);
    }
    static int out(String s, int i) {
        System.out.println(s + &quot;=&quot; + i);
        return i;
    }
}
</code></pre>
<p>该程序产生输出：</p>
<pre><code>1
j=3
jj=4
3
</code></pre>
<p>对 <code>J.i</code> 的引用是对作为常量变量的字段引用（4.12.4）；因此，他不会导致 <code>I</code> 被初始化（13.4.9）。</p>
<p>对 <code>K.j</code> 的引用是对接口 <code>J</code>  中实际声明的不是常量变量的字段的引用；这导致接口 <code>J</code> 的字段初始化，但不初始化其超接口 <code>I</code> 的字段，也不初始化接口 <code>K</code> 的字段。</p>
<p>尽管名称 <code>K</code> 用于引用接口 <code>J</code> 的字段 <code>j</code>，但接口 <code>K</code> 并未初始化。</p>
<h3 id="1242-detailed-initialization-procedure">12.4.2 Detailed Initialization Procedure</h3>
<p>因为 Java 编程语言是多线程的，所以类或接口的初始化需要小心的同步，因为其他一些线程可能同时视图初始化相同的类或接口。还存在这样的可能性，即类或接口的初始化可以作为该类或接口初始化的一部分被递归地请求；例如，类 A 中的变量初始化器可能会调用不相关的类 B 的方法，这有可能会调用类 A 的方法。</p>
<p>该过程假设 <code>Class</code> 对象已经被验证和准备，并且该对象包含指示四种情况之一的状态：</p>
<ul>
<li>该 <code>Class</code> 对象已经过验证和准备，但尚未初始化。</li>
<li>该 <code>Class</code> 对象正在被某个特定的线程 <code>T</code> 初始化。</li>
<li>该 <code>Class</code> 对象已经完全初始化，可以使用了。</li>
<li>该 <code>Class</code> 对象处于错误状态，可能是因为初始化尝试失败。</li>
</ul>
<p>对于每个类或接口 <code>C</code>，都有一个唯一的初始化锁 <code>LC</code>。从 <code>C</code> 到 <code>LC</code> 的映射由 Java 虚拟机实现决定。初始化 <code>C</code> 的过程如下：</p>
<ol>
<li>对 <code>C</code> 的初始化锁 <code>LC</code> 进行同步，这包括等待，直到当前线程可以获取 <code>LC</code>。</li>
<li>如果 <code>C</code> 的 <code>Class</code> 对象指示某个其他线程正在对 <code>C</code> 进行初始化，那么释放 <code>LC</code> 并阻塞当前线程，直到通知正在进行的初始化已经完成，此时重复该步骤。</li>
<li>如果 <code>C</code> 的 <code>Class</code> 对象指示当前线程正在对 <code>C</code> 进行初始化，那么这一定是一个递归的初始化请求。释放 <code>LC</code> 并正常完成。</li>
<li>如果 <code>C</code> 的 <code>Class</code> 对象指示 <code>C</code> 已经被初始化，那么不需要进一步的动作。释放 <code>LC</code> 并正常完成。</li>
<li>如果 <code>C</code> 的 <code>Class</code> 对象处于错误状态，那么初始化是不可能的。释放 <code>LC</code> 并抛出一个 <code>NoClassDefFoundError</code>。</li>
<li>否则，记录当前线程正在初始化 <code>C</code> 的 <code>Class</code> 对象，并释放 <code>LC</code>。</li>
</ol>
<p>然后，初始化 <code>C</code> 的 <code>static</code> 字段，它们是常量变量（4.12.4，8.3.2，9.3.1）。</p>
<ol start="7">
<li>接下来，如果 <code>C</code> 是一个类而不是一个接口，它的超类还没有初始化，那么设 <code>SC</code> 是它的超类，设 SI<sub>1</sub>，... ...，SI<sub>n</sub>是声明了至少一个默认方法的 <code>C</code> 的所有超接口。超接口的顺序由 C 直接实现的每个接口的超接口层次结构上的递归枚举给出（按照 <code>C</code> 的 <code>implements</code> 子句从左到右的顺序 ）。对于 <code>C</code> 直接实现的每个接口 <code>I</code> ，枚举在返回 <code>I</code> 之前在 <code>I</code> 的超接口上递归（按照 <code>I</code> 的 <code>extends</code> 子句从左到右的顺序）。</li>
</ol>
<p>对于列表 [SC，SI<sub>1</sub>，... ...，SI<sub>n</sub>]，递归地对 <code>S</code> 执行整个过程，如有必要，首先验证并准备 <code>S</code>。</p>
<p>如果 <code>S</code> 的初始化因为一个抛出的异常而突然完成，那么获取 <code>LC</code>，将 <code>C</code> 的类对象标记为错误，通知所有等待的线程，释放 <code>LC</code>，然后突然完成，抛出与初始化 <code>S</code> 相同的异常。</p>
<ol start="8">
<li>接下来，通过查询 <code>C</code> 的定义类加载器来确定 <code>C</code> 是否启用了断言（14.10）。</li>
<li>接下来，按照文本顺序执行类的类变量初始值设定项和静态初始值设定项，或者接口的字段初始值设定项，就好像它们是单个块一样。</li>
<li>如果初始化器的执行正常完成，那么获取 <code>LC</code>， 将 <code>C</code> 的 <code>Class</code> 对象标记为完全初始化，通知所有等待的线程，释放 <code>LC</code>，然后正常完成这个过程。</li>
<li>否则，初始值设定项一定是通过抛出某个异常 <code>E</code> 而突然完成的，如果 <code>E</code> 的类不是 <code>Error</code> 或它的某个子类，则创建 <code>ExceptionInInitializerError</code> 类的新实例，使用 <code>E</code> 作为参数，并在下面的步骤中使用此对象代替 <code>E</code>。如果由于发生 <code>OutOfMemoryError</code> 而无法创建 <code>ExceptionInInitializerError</code> 的新实例，则在下面的步骤中使用 <code>OutOfMemoryError</code> 对象代替 <code>E</code>。</li>
<li>获取 <code>LC</code>，将 <code>C</code> 的 <code>Class</code> 对象标记为错误，通知所有等待的线程，释放 <code>LC</code>，并突然完成此过程，原因为 <code>E</code> 或其替换，如前一步骤中所确定的。</li>
</ol>
<p><em>当实现可以确定类的初始化已经完成时，它可以通过取消步骤 1 中的锁获取（以及步骤 4/5 中的释放）来优化该过程，前提是，就存储器模型而言，如果锁被获取，则所有的 happens-before 排序在执行优化时仍然存在。</em></p>
<p><em>代码生成器需要保留类或接口的可能初始化点，插入刚才描述的初始化过程的调用。如果这个初始化过程正常完成，并且 * <code>Class</code> * 对象被完全初始化并准备好使用，那么初始化过程的调用不再是必要的，并且它可以从代码中消除——例如，通过修补它或以其他方式重新生成代码。</em></p>
<p><em>在某些情况下，如果可以确定一组相关类型的初始化顺序，编译时分析可能能够从生成代码中消除许多类型已初始化的检查。然而，这种分析必须充分考虑到并发性和初始化代码不受限制的事实。</em></p>
<h2 id="125-creation-of-new-class-instances">12.5 Creation of New Class Instances</h2>
<p>当对一个类实例创建表达式求值（15.9）导致一个类被实例化时，一个新的类实例被显示地创建。</p>
<p>在以下情况下可以隐式创建一个新的类实例：</p>
<ul>
<li>加载一个包含 <code>String</code> 字面量（3.10.5）的类或接口可能会创建一个新的 <code>String</code> 对象来表示该字面量。（如果同一个 <code>String</code> 之前已经被保留，这可能不会发生（3.10.5）。）</li>
<li>导致装箱转换的操作的执行（5.1.7）。装箱转换可以创建于原语类型之一相关联的包装类的新对象。</li>
<li>执行不属于常量表达式（15.28）的字符串连接运算符 <code>+</code> （15.18.1）时，总是会创建一个新的字符串来表示结果。字符串串联运算也可以为原始类型的值创建临时包装对象。</li>
<li>评估方法引入表达式（15.13.3）或 lambda 表达式（15.27.4）可能需要创建实现函数式接口类型的类的新实例。</li>
</ul>
<p>作为类实例创建过程的一部分，这些情况中的每一种都标识了一个特定的构造函数（8.8），改构造函数将使用指定的参数（可能没有）来调用。</p>
<p>每当一个新的类实例被创建时，内存空间被分配给它，其中包括在类类型中声明所有实例变量，以及在类类型的每个超类中声明的所有实例变量，包括所有可能隐藏的实例变量（8.3）。</p>
<p>如果没有足够的可用空间分配内存，那么类实例的创建就会突然结束，并发出 <code>OutOfMemoryError</code>。否则，新对象中的所有实例变量，包括在超类中声明的实例变量，都被初始位它们的默认值（4.12.5）。</p>
<p>就在返回新创建对象的引用作为结果之前，处理指定的构造函数，使用以下过程初始化新对象：</p>
<ol>
<li>将构造函数的参数赋给为这个构造函数调用新创建的参数变量。</li>
<li>如果这个构造函数是从同一个类中的另一个构造函数的显式构造函数调用（8.8.7.1）开始的（使用 <code>this</code>），那么使用这五个步骤计算参数并递归地处理构造函数调用。如果构造函数调用突然完成，那么这个过程也会因为同样的原因而突然完成；否则，继续执行步骤 5。</li>
<li>此构造函数不以同一个类中的另一个构造函数的显式构造函数调用开始（使用 <code>this</code>）。如果这个构造函数是针对 <code>Object</code> 之外的类，那么这个构造函数将以一个超类构造函数的显式或隐式调用开始（使用 <code>super</code>）。使用相同的五个步骤评估参数并递归处理超类构造函数调用。如果构造函数调用突然完成，那么这个过程也会因同样的原因而突然完成。否则，继续执行步骤 4。</li>
<li>执行该类的实例初始值设定项和实例变量初始值设定项，将实例变量初始值设定项的值分配给相应的实例变量，按照它们在该类的源代码中以文本形式出现的从左到右的顺序。如果这些初始化器中的任何一个执行导致了异常，俺么就不再处理进一步的初始化器，并且这个过程以同样的异常突然结束。否则，继续执行步骤 5。</li>
<li>执行该构造函数体的其余部分。如果该执行突然完成，那么该过程也由于同样的原因而突然完成。否则，此过程正常完成。</li>
</ol>
<p>与 C++ 不同，Java 编程语言在创建新的类实例期间没有为方法分派指定更改规则。如果调用的方法在被初始化的对象的子类中被重写，那么这些重写的方法将被使用，甚至在新对象被完全初始化之前。</p>
<p>例子 12.5-1，实例创建评估：</p>
<pre><code class="language-java">class Point {
    int x, y;
    Point() { x = 1; y = 1; }
}
class ColoredPoint extends Point {
    int color = 0xFF00FF;
}
class Test {
    public static void main(String[] args) {
        ColoredPoint cp = new ColoredPoint();
        System.out.println(cp.color);
    }
}
</code></pre>
<p>这里，创建了一个新的 <code>ColoredPoint</code> 实例。首先，为新的 <code>ColoredPoint</code> 分配空间，以保存字段 <code>x</code>、<code>y</code> 和 <code>color</code>。然后将所有这些字段初始化为它们的默认值（在本例中，每个字段为 0）。接下来，首先调用没有参数的 <code>ColoredPoint</code> 构造函数。由于 <code>ColoredPoint</code> 没有声明构造函数，因此隐式声明了一下形势的默认构造函数：</p>
<pre><code class="language-java">ColoredPoint() { super(); }
</code></pre>
<p>然后，这个构造函数调用不带参数的 <code>Point</code> 构造函数。<code>Point</code> 构造函数并不以调用构造函数开始，因此 Java 编译器提供了对其超类构造函数的隐式调用，不带参数，就像已经编写的那样：</p>
<pre><code class="language-java">Point() { super(); x = 1; y = 1; }
</code></pre>
<p>因此，将调用不带参数的 <code>Object</code> 构造函数。</p>
<p>类 <code>Object</code> 没有父类，因此递归到此结束。接下来，调用 <code>Object</code> 的任何实例初始化器和实例变量的初始化器。接下来，执行不带参数的 <code>Object</code> 构造函数体。<code>Object</code> 中没有声明这样的构造函数，所以 Java 编译器提供了一个默认构造函数，在这个特殊情况下是：</p>
<pre><code class="language-java">Object() { }
</code></pre>
<p>此构造函数执行无效并返回。</p>
<p>接下来，执行类 <code>Point</code> 的实例变量的所有初始化器。当它发送时，<code>x</code> 和 <code>y</code> 的声明不提供任何初始化值，因此示例的这一步不需要任何操作。然后执行 <code>Point</code> 构造函数体，将 <code>x</code> 设为 <code>1</code>，将 <code>y</code> 设为 <code>1</code>。</p>
<p>接下来，执行 <code>ColoredPoint</code> 类的实例变量和初始化器。这一步将值 <code>0xFF00FF</code> 分配给 <code>color</code>。最后，执行 <code>ColoredPoint</code> 构造函数体的其余部分（调用 <code>super</code> 之后的部分）；在主题的其他部分中碰巧没有语句，因此不需要进一步操作，初始化完成。</p>
<p>例子 12.5-2，实例创建期间的动态调度：</p>
<pre><code class="language-java">class Super {
    Super() { printThree(); }
    void printThree() { System.out.println(&quot;three&quot;); }
}
class Test extends Super {
    int three = (int)Math.PI;  // That is, 3
    void printThree() { System.out.println(three); }

    public static void main(String[] args) {
        Test t = new Test();
        t.printThree();
    }
}
</code></pre>
<p>该程序产生输出：</p>
<pre><code>0
3
</code></pre>
<p>这表明在类 <code>Super</code> 的构造函数中调用 <code>printThree</code> 并没有调用类 <code>Super</code> 中 <code>printThree</code> 的定义，而是调用了类 <code>Test</code> 中 <code>printThree</code> 的覆盖定义。因此，该方法在 <code>Test</code> 的字段初始化器执行之前允许，这就是为什么第一个输出值是 0，<code>Test</code> 的字段 <code>three</code> 初始化的默认值。之后在方法 <code>main</code> 中对 <code>printThree</code> 的调用，调用了 <code>printThree</code> 的相同的定义，但此时已经执行了实例变量 <code>three</code> 的初始化器，因此输出了值 <code>3</code>。</p>
<h2 id="126-finalization-of-class-instances">12.6 Finalization of Class Instances</h2>
<p><code>Object</code> 类有一个 <code>protected</code> 的方法 <code>finalize</code>；这个方法可以被其他类重写。可为对象调用的 <code>finalize</code> 的特定定义成为该对象的<em>终结器(finalizer)</em>。在垃圾收集器回收对象的存储之前，Java 虚拟机将调用该对象的 finalizer 。</p>
<p>finalizer 提供了释放自动存储管理器无法自动释放的资源的机会。在这种情况下，仅仅回收对象使用的内存并不能保证回收对象所持有的资源。</p>
<p>Java 编程语言没有指定调用 finalizer 的时间，只是说将在重用对象的存储志强调用 finalizer。</p>
<p>Java 编程语言没有指定哪个线程将为任何给定对象调用 finalizer。</p>
<p>*重要的是 要注意，许多 finalizer 线程可能是活动的（在大型共享内存多处理器上有时需要这样），如果一个大型连接的数据结构变成垃圾，那么该数据结构中每个对象的所有 *  <code>finalize</code> <em>方法都可能同时被调用，每个 finalizer 调用在不同的线程中运行。</em></p>
<p>Java 编程语言没有对 <code>finalize</code> 方法调用进行排序。finalizer 可以按任何顺序调用，甚至可以并发调用。</p>
<p><em>例如，如果循环链接的未终结对象组变得不可达（或 finalizer 可达），则所有对象可以一起变得可终结。最终，这些对象的 finalizer 可以以任何顺序调用，甚至可以使用多线程并发调用。如果自动存储管理器来发现对象不可达，那么它们的存储可以被回收。</em></p>
<p><em>实现一个类是很简单的，当所有对象都变得不可访问时，它将导致一组类似 finalizer 的方法以指定的顺序为一组对象调用。定义这样一个类留给读者作为练习。</em></p>
<p>保证在调用 finalizer 时，调用该 finalizer 的线程不会持有任何用户可见的同步锁。</p>
<p>如果在终结期间引发了未捕获异常，则该异常将被忽略，该对象的终结将终止。</p>
<p>一个对象的构造函数的完成发生在（17.4.5）它的 <code>finalize</code> 方法的执行之前（在 happens-before 的正式意义上）。</p>
<p>在类对象中声明的 <code>finalize</code> 方法不执行任何操作。<code>Object</code> 类声明 <code>finalize</code> 方法的事实意味着任何类的 <code>finalize</code> 方法都可以调用其超类的 <code>finalize</code> 方法。除非程序员有意使超类中 finalizer 的动作无效，否则应该总是这样做。（与构造函数不同，finalizer 不会自动调用超类的 finalizer；这种调用必须显式编码。）</p>
<p><em>为了提高效率，实现可以跟踪哪些不覆盖</em>  <code>Object</code><em>类的</em> <code>finalize</code> <em>方法的类对象，或者以一种简单 方式覆盖它。</em></p>
<p>例如：</p>
<pre><code class="language-java">protected void finalize() throws Throwable {
    super.finalize();
}
</code></pre>
<p>如 <a href="#1261-implementing-finalization">12.6.1</a> 所述，我们鼓励实现将这一的对象视为具有未被覆盖的 finalizer，并更有效的终结它们。</p>
<p>可以显示调用 finalizer，就像任何其他方法一样。</p>
<p><code>java.lang.ref</code> 包描述了弱引用，它与垃圾收集和终结进行交互。与任何与 Java 编程语言有特殊交互的 API 一样，实现者必须了解 <code>java.lang.ref</code> API 提出的任何要求。本规范不以任何方式讨论弱引用。读者可以参考 API 文档了解详细信息。</p>
<h3 id="1261-implementing-finalization">12.6.1 Implementing Finalization</h3>
<p>每个对象都可以用两个属性来描述：它可以是 <em>可到达的（reachable）</em>，<em>终结器可到达的（finalizer-reachable）</em> 或 <em>不可到达的（unreachable）</em>，也可以是 <em>未终结的（unfinalized）</em>，<em>可终结的（finalizable）</em> 或 <em>终结的（finalized）</em>。</p>
<p>**可达（reachable）**对象是可以在任何潜在的持续计算中从任何活动线程访问的任何对象。</p>
<p>**终结器可访问（finalizer-reachable）**的对象可以通过某个引用链从某个可终结的对象访问，但不能从任何活动线程访问。</p>
<p>**不可达（unreachable）**对象无论用哪种方法都不可达。</p>
<p>**未终结（unfinalized）**对象从未自动调用其 finalizer。</p>
<p>**终结（finalized）**对象已经自动调用了它的 finalizer。</p>
<p><strong>可终结（finalizable）</strong> 对象从未自动调用其终结器，但 Java 虚拟机最终可能会自动调用其终结器。</p>
<p>直到对象 <code>o</code> 的构造函数调用了 <code>o</code> 上层的 <code>Object</code> 的构造函数，并且该调用成功完成（即没有引发异常），对象 <code>o</code> 才是 <strong>可终结的（finaliable）</strong>。对一个对象的字段的每一个预终结（pre-finalization）写入必须对该对象的终结（finalization）可见。此外，对该对象的字段的预终结（pre-finalization）读取都会看到在该对象的终结被启动之后发生的写入。</p>
<p>程序的优化转换可以设计成减少可到达对象的数量，使之少于那些天真地认为可到达的对象的数量。例如，Java 编译器或代码生成器可能会选择将一个不再使用的变量或参数设置为 <code>null</code>，从而使此类对象的存储可能更快速地被回收。</p>
<p>另一个例子是对象字段中的值存储在寄存器中。然后程序可以访问寄存器而不是对象，并且不在访问该对象。这意味着该对象是垃圾。注意，只有当引用在栈上，而不是存储在堆中时，才允许这种优化。</p>
<p>例如，考虑 Finalizer Guardian 模式：</p>
<pre><code class="language-java">class Foo {
    private final Object finalizerGuardian = new Object() {
        protected void finalize() throws Throwable {
            /* finalize outer Foo object */
        }
    }
} 
</code></pre>
<p>如果子类重写 <code>finalize</code> 并且没有显示调用 <code>super.finalize</code>，finalizer guardian 会强制调用 <code>super.finalize</code>。</p>
<p>如果允许对存储在堆上的引用进行这些优化，那么 Java 编译器可以检测到 <code>finalizerGuardian</code> 字段从未被读取，将其清空，理解回收对象，并提前调用 finalizer。这与初衷背道而驰：当 <code>Foo</code> 实例变得不可访问时，程序员可能想调用 <code>Foo</code> 的 finalizer。因此，这种转换是不合法的：只要外部类对象是可达的，内部类对象就应该是可达的。</p>
<p>这种类型的转换可能会导致 <code>finalizer</code> 方法的调用比预期的要早。为了允许用户防止这种情况，我们强调了同步可以保持对象存活的概念。如果一个对象的 finalizer 可以导致该对象上的同步，那么该对象必须是活动的，并且在它被锁定时被认为是可访问的。</p>
<p>请注意，这并不妨碍同步消除：只有当 finalizer 可能对一个对象进行同步时，同步才会使该对象保持活动状态。由于终结器出现在另一个线程中，因此许多情况下，无论如何都无法移除同步。</p>
<h3 id="1262-interaction-with-the-memory-model">12.6.2 Interaction with the Memory Model</h3>
<p>内存模型（17.4）必须能够决定何时提交发生在 finalizer 中的操作。本节描述 finalization 与内存模型的交互。</p>
<p>每个执行都与许多可达性决策点，标记为 <code>di</code>。每个动作要么发生在 <code>di</code>之前，要么发生在 <code>di</code> 之后。除了明确提到的以外，本节中描述的先来后到排序与内存模型中的所有其他排序无关。</p>
<p>如果 <code>r</code> 是看到写 <code>w</code> 的读，并且 <code>r</code> 在 <code>di</code> 之前，那么 <code>w</code> 必须在 <code>di</code> 之前。</p>
<p>如果 <code>x</code> 和 <code>y</code> 是对同一变量或监视器的同步操作，使得 <code>so(x, y)</code> （17.4.4）和 <code>y</code> 在 <code>di</code> 之前，那么 <code>x</code> 必须在 <code>di</code> 之前。</p>
<p>在每个可达性决策点，一些对象集被标记为不可达，而这些对象的一些子集被标记为可终结。这些可达性决策点也是根据 <code>java.lang.ref</code> 包的 API 文件中提供的规则检查、加入队列和清除引用的点。</p>
<p>唯一被认为在 <code>di</code> 点绝对可达的对象是那些可以通过应用这些规则证明可达的对象：</p>
<ul>
<li>如果存在对类 <code>C</code> 的 <code>static</code> 字段 <code>v</code> 的写入 <code>w1</code>，使得 <code>w1</code> 写入的值是对 <code>B</code> 的引用，类 <code>C</code> 有可到达的类加载器加载，并且不存在对 <code>v</code> 的写入 <code>w2</code>，使得 <code>hb(w2, w1)</code> 不为 true，并且 <code>w1</code> 和 <code>w2</code> 都在 <code>di</code> 之前，则对象 <code>B</code> 在 <code>di</code> 处肯定是可达的。</li>
<li>如果存在对 <code>A</code> 的元素 <code>v</code> 的写 <code>w1</code>，使得由 <code>w1</code> 写的值是对 <code>B</code> 的引用，并且不存在对 <code>v</code> 的写 <code>w2</code> ，使得 <code>hb(w2, w1)</code> 不为 true，并且 <code>w1</code> 和 <code>w2</code> 都在 <code>di</code> 之前，则对象 <code>B</code> 在 <code>di</code> 处肯定是从 <code>A</code> 可达的。</li>
<li>如果一个对象 <code>C</code> 从一个对象 <code>B</code> 肯定是可达的，并且对象 <code>B</code> 从一个对象 <code>A</code> 肯定是可达的，那么 <code>C</code> 从 <code>A</code> 肯定是可达的。</li>
</ul>
<p>如果对象 <code>X</code> 在 <code>di</code> 被标记位不可达，则：</p>
<ul>
<li>从 <code>static</code> 字段到 <code>di</code>， <code>X</code> 一定不可达；以及</li>
<li>线程 <code>t</code> 中所有在 <code>di</code> 之后对 <code>X</code> 的所有活动使用必须发生在 <code>X</code> 的 finalizer 调用中，或者线程 <code>t</code> 在 <code>di</code> 之后执行对 <code>X</code> 的引用的读取的结果；以及</li>
<li>所有在 <code>di</code> 之后的读操作，如果看到对 <code>X</code> 的引用，就必须看到在 <code>di</code> 处不可达的对象元素的写操作，或者在 <code>di</code> 之后看到对象的写操作。</li>
</ul>
<p>动作 <code>a</code> 是对 <code>X</code> 的主动使用，当且仅当以下至少有一个为 true：</p>
<ul>
<li>读取或写入 <code>X</code> 的元素</li>
<li><code>a</code> 锁定或解锁 <code>X</code>，并且在调用 <code>X</code> 的 finalizer 之后，会在 <code>X</code> 上发生一个锁定操作</li>
<li><code>a</code> 写入一个对 <code>X</code> 的引用</li>
<li><code>a</code> 是一个对象 <code>Y</code> 的主动使用，<code>X</code> 从 <code>Y</code> 肯定是可达的</li>
</ul>
<p>如果对象 <code>X</code> 在 <code>di</code> 被标记为可终结，则：</p>
<ul>
<li><code>X</code> 必须在 <code>di</code> 处被标记为不可达；以及</li>
<li><code>di</code> 必须是 <code>X</code> 被标记为可终结的唯一位置；以及</li>
<li>在 finalizer 调用之后发生的动作必须在 <code>di</code> 之后。</li>
</ul>
<hr>
<h2 id="127-unloading-of-classes-and-interfaces">12.7 Unloading of Classes and Interfaces</h2>
<p>Java 编程语言的实现可以<strong>卸载</strong>类。</p>
<p>当前仅当类或接口的定义类加载可以被垃圾回收期回收时，类或接口才可以被卸载，如 <a href="#126-finalization-of-class-instances">12.6</a> 中所讨论的。</p>
<p>Bootstrap loader 加载的类和接口不能被卸载。</p>
<p><em>类卸载是一种优化，有助于减少内存使用。显然，程序的语义不应该依赖于系统是否以及如何选择实现优化，比如类卸载。否则会损害程序的可移植性。因此，一个类或接口是否被卸载对程序来说应该是透明的。</em></p>
<p><em>然而，如果一个类或接口</em> <code>C</code> <em>在它的定义加载器潜在地可达时被卸载，那么</em> <code>C</code> <em>可能被重新装载。谁也不能保证这不会发生。即使该类没有被任何其他当前加载的类引用，他也可能被尚未加载的某个类或接口</em> <code>D</code> <em>引用。当</em> <code>D</code> <em>被</em> <code>C</code> <em>的定义加载器加载时，它的执行可能会导致</em> <code>C</code> <em>的重新加载。</em></p>
<p><em>例如，如果类有</em>  <code>static</code> <em>变量（其状态会丢失），静态初始值设定项（可能有副作用）或</em> <code>native</code> <em>方法（可能保留静态状态），则重新加载可能不透明。此外，类对象的哈希值依赖它的身份。因此，一般来说，以完全透明的方式重新加载一个类或接口是不可能的。</em></p>
<p><em>因为我们永远不能保证卸载一个类或接口（其加载器是潜在可达的）不会导致重新加载，重新加载从来都不是透明的，但是卸载必须是透明的，所以当一个类或接口加载器是潜在可达的时候，我们不能卸载它。类似的推理可以用来推断由 Bootstrap loader 装载的类和加快永远不能被卸载。</em></p>
<p><em>人们还必须讨论为什么卸载一个类</em> <code>C</code> <em>是安全的，如果它的定义类加载器可以被回收的话。如果定义类加载器可以被回收，那么永远不会有对它的任何活动引用（这包括不活动的引用，但可能被 finalizer 复活）。反过来，只有当加载器定义的任何类（包括）</em> <code>C</code> <em>都不能有任何活动引用时，这种情况才会发送，无论是从它们的实例还是从代码。</em></p>
<p><em>类卸载是一种优化，它仅在对加载大量类并在一段时间后停止使用这些类的应用程序有意义。这种应用程序的一个主要例子是 web 浏览器，但还有其他应用程序。这种应用程序的一个特点是，它们通过显式使用类加载器来管理类。因此，上述政策对他们来说非常有效。</em></p>
<p><em>严格来说，本规范并没有讨论类卸载的问题，因为类卸载仅仅是一种优化。然而，这个问题非常精妙，因此在此作为澄清提及。</em></p>
<h2 id="128-program-exit">12.8 Program Exit</h2>
<p>当发生以下两种情况之一时，程序终止其所有活动并退出：</p>
<ul>
<li>所有不是守护线程的线程都会终止。</li>
<li>某线程调用类 <code>Runtime</code> 或类 <code>System</code> 的 <code>exit</code> 方法，安全管理器不禁止 <code>exit</code> 操作。</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[《TCP/IP 详解 卷一：协议》第五章：Internet 协议]]></title>
        <id>https://wenbozhangw.github.io/post/lesslesstcpip-xiang-jie-juan-yi-xie-yi-greatergreater-di-wu-zhang-internet-xie-yi/</id>
        <link href="https://wenbozhangw.github.io/post/lesslesstcpip-xiang-jie-juan-yi-xie-yi-greatergreater-di-wu-zhang-internet-xie-yi/">
        </link>
        <updated>2022-05-26T07:34:07.000Z</updated>
        <summary type="html"><![CDATA[<h2 id="51-引言">5.1 引言</h2>
<p>IP是 TCP/IP 协议族中的核心协议。所有 TCP、 UDP、 ICMP 和 IGMP 数据都通过 IP 数据报传输。 IP 提供了一种尽力而为、无连接的数据报交付服务。 “尽力而为”的含义是不保证 IP 数据报能成功到达目的地。虽然 IP 不是简单丢弃所有不必要流量，但它也不对自己尝试交付的数据报提供保证。当某些错误发生时，例如一台路由器临时用尽缓冲区， IP 提供一个简单的错误处理方法： 丢弃一些数据（通常是最后到达的数据报）。任何可靠性必须由上层（例如 TCP）提供。 IPv4 和 IPv6 都使用这种尽力而为的基本交付模式。</p>
<p>“<strong>无连接</strong>”意味着 IP 不维护网络单元（即路由器）中数据报相关的任何链接状态信息，每个数据报独立于其他数据报来处理。这也意味着 IP 数据报可不按顺序交付。如果一个源主机向同一目的地发送两个连续的数据报（第一个为 A，第二个为 B），每个数据报可以独立路由，通过不同路径，并且 B 可能在 A 之前到达。 IP 数据报也可能发生其他问题：它们可能在传输过程中被复制，可能改变内容从而导致错误。此外， IP 之上的一些协议（通常是 TCP）需要处理这些潜在问题，以便为应用提供无差错的交付。</p>
]]></summary>
        <content type="html"><![CDATA[<h2 id="51-引言">5.1 引言</h2>
<p>IP是 TCP/IP 协议族中的核心协议。所有 TCP、 UDP、 ICMP 和 IGMP 数据都通过 IP 数据报传输。 IP 提供了一种尽力而为、无连接的数据报交付服务。 “尽力而为”的含义是不保证 IP 数据报能成功到达目的地。虽然 IP 不是简单丢弃所有不必要流量，但它也不对自己尝试交付的数据报提供保证。当某些错误发生时，例如一台路由器临时用尽缓冲区， IP 提供一个简单的错误处理方法： 丢弃一些数据（通常是最后到达的数据报）。任何可靠性必须由上层（例如 TCP）提供。 IPv4 和 IPv6 都使用这种尽力而为的基本交付模式。</p>
<p>“<strong>无连接</strong>”意味着 IP 不维护网络单元（即路由器）中数据报相关的任何链接状态信息，每个数据报独立于其他数据报来处理。这也意味着 IP 数据报可不按顺序交付。如果一个源主机向同一目的地发送两个连续的数据报（第一个为 A，第二个为 B），每个数据报可以独立路由，通过不同路径，并且 B 可能在 A 之前到达。 IP 数据报也可能发生其他问题：它们可能在传输过程中被复制，可能改变内容从而导致错误。此外， IP 之上的一些协议（通常是 TCP）需要处理这些潜在问题，以便为应用提供无差错的交付。</p>
<!-- more -->
<p>本章我们首先看一下 IPv4 （见图 5-1）和 IPv6 （见图 5-2）头部中的字段，然后描述 IP 如何转发。[<a href="#RFC0791">RFC0791</a>] 是针对 IPv4 的正式规范。描述 IPv6 的一系列 RFC 从 [<a href="#RFC2460">RFC2460</a>] 开始。</p>
<figure data-type="image" tabindex="1"><img src="https://wenbozhangw.github.io//post-images/1653556210920.png" alt="图 5-1" loading="lazy"></figure>
<p>图 5-1   IPv4 数据报。头部大小可变， 4 位的 IHL 字段被限制为 15 个 32 位字（60字节）。一个典型的 IPv4 头部包含 20 字节（没有选项）。源地址和目的地址的长度为 32 位。第二个 32 位字的大部分用于 IPv4 分片功能。头部校验和有助于确保头部字段被正确发送到目的地，但不保护数据内容</p>
<figure data-type="image" tabindex="2"><img src="https://wenbozhangw.github.io//post-images/1653556327941.png" alt="图 5-2" loading="lazy"></figure>
<p>图 5-2    IPv6 头部大小固定（40 字节），并包含 128 位源地址和目的地址。下一个头部字段用于说明 IPv6 头部之后其他扩展头部的存在和类型，它们形成一条包括特殊扩展或处理指令的头部链。应用数据跟在这条头部链之后，通常紧跟着是一个传输层头部</p>
<hr>
<h2 id="52-ipv4-头部和-ipv6-头部">5.2 IPv4 头部和 IPv6 头部</h2>
<p>图 5-1 显示了 IPv4 数据报格式。正常的 IPv4 头部大小为 20 字节，除非存在选项（这种情况很少见）。 IPv6 头部长度是它的两倍，但没有任何选项。它可以有扩展头部，可提供类似的功能，我们将在后面看到。在关于 IP 头部和数据报的印象中，最高有效位在左侧且编号为 0，一个 32 位值的最低有效位在右侧且编号为 31。</p>
<p>一个 32 位值的 4 字节按以下顺序传输：首先是 0 ~ 7 位，然后是 8 ~ 15 位，接着是 16 ~ 23 位，最后是 24 ~ 31 位。这就是所谓的<strong>高位优先</strong>字节序，它是 TCP/IP 头部中所有二进制整数在网络中传输时所需的字节顺序。它也被称为网络字节序。计算机的 CPU 使用其他格式存储二进制整数，例如大多数 PC 使用低位优先字节序，在传输时必须将头部值转换为网络字节序，并在接收时再转换回来。</p>
<h3 id="521-ip-头部字段">5.2.1 IP 头部字段</h3>
<p>第一个字段（只有 4 位或半个字节）是版本字段。它包含 IP 数据报的版本号：IPv4 为 4， IPv6 为 6。IPv4 头部和 IPv6 头部除版本字段位置相同外再无其他是一样的。因此，这两个协议不能直接互操作，主机或路由器必须分别处理 IPv4 或 IPv6 （或两者，称为<strong>双栈</strong>）。虽然也提出并发展了其他 IP 版本，但只有版本 4 和 6 经常使用。 IANA 负责保存这些版本号的正式注册信息 [<a href="#IV">IV</a>]。</p>
<p>**Internet 头部长度（IHL）**字段保存 IPv4 头部中 32 位字的数量，包括任何选项。由于它是一个 4 位的字段，所以 IPv4 头部被限制为最多 15 个 32 位字，即 60 字节。后面，我们将看到，这种限制使一些选项（例如“记录路由”选项）当前几乎无法使用。这个字段的正常值（当没有选项时）是 5。 IPv6 中不存在这个字段，其头部长度固定为 40 字节。</p>
<p>在头部长度之后， IPv4 [<a href="#RFC0791">RFC0791</a>] 的最初规范指定了一个<strong>服务类型（ToS）<strong>字段，IPv6 [<a href="#RFC2460">RFC2460</a>] 指定了一个等效的</strong>通信类型</strong>字段。由于它们从来没被广泛使用，因此最终这个 8 位长的字段被分为两个部分，并由一组 RFC（ [<a href="#RFC3260">RFC3260</a>] [<a href="#RFC3168">RFC3168</a>] [<a href="#RFC2474">RFC2474</a>] 和其他 RFC）重新定义。目前，前 6 位被称为<strong>区分服务</strong>字段（DS字段），后 2 位是**显式拥塞通知（ECN）**字段或指示位。现在，这些 RFC 适用于 IPv4 和 IPv6。这些字段被用于数据报转发时的特殊处理。我们将在 5.2.3 节中详细讨论它们。</p>
<p><strong>总长度</strong>字段是 IPv4 数据报的总长度（以字节为单位）。通过这个字段和 IHL 字段，我们知道数据报的数据部分从哪里开始，以及它的长度。由于它是一个 16 位的字段，所以 IPv4 数据报的最大长度（包括头部）为 65535 字节。由于一些携带 IPv4 数据报的低层协议不能（精确）表达自己封装的数据报大小，所以需要在头部中给出总长度字段。例如，以太网会将短帧填充到最小长度（64 字节）。虽然以太网最小有效载荷为 46 字节（见第 3 章），但一个 IPv4 数据报也可能会更小（20 字节）。如果没有提供总长度字段， IPv4 实现将无法知道一个 46 字节的以太网帧是一个 IP 数据报，还是经过填充的 IP 数据报，这样可能会导致混淆。</p>
<p>尽管可发送一个 65535 字节的IP数据报，但大多数链路层（例如以太网）不能携带这么大的数据，除非将它分（拆）成更小的片。另外，主机不需要接收大于 576 字节的 IPv4 数据报。 （在 IPv6 中，主机需要能处理所连接链路 MTU 大小的数据报，而最小链路 MTU 为 1280 字节。）很多使用 UDP 协议（见第 10 章）传输数据（例如 DNS、DHCP 等）的应用程序，限制为使用 512 字节大小的数据，以避免 576 字节的 IPv4 限制。 TCP 根据额外信息（见第 15 章）选择自己的数据报大小。</p>
<p>当一个 IPv4 数据报被分为多个更小的分片时，每个分片自身仍是一个独立的 IP 数据报，总长度字段反映具体的分片长度。第 10 章中将详细介绍分片和 UDP。IPv6 头部不支持分片，其长度可由<strong>负载长度</strong>字段获得。这个字段提供 IPv6 数据报长度，不包括头部长度，但扩展头部包括在<strong>负载长度</strong>中。对于 IPv4，这个 16 位的字段限制其最大值为 65535。对于 IPv6，<strong>负载长度</strong>被限制为 64KB，而不是整个数据报。另外， IPv6 还支持一个超长数据报选项（见 5.3.1.2 节），它至少在理论上提供了可能性，即单个分组的有效载荷可达到 4GB （4294967295 字节）!</p>
<p><strong>标识</strong>字段帮助标识由 IPv4 主机发送的数据报。为了避免将一个数据报分片和其他数据报分片混淆，发送主机通常在每次（从它的一个 IP 地址）发送数据报时都将一个内部计数器加 1，并将该计数器值复制到 <strong>IPv4 标识</strong> 字段。这个字段对实现分片很重要，因此我们将在第 10 章中进一步讨论，另外还会讨论标志和分片偏移字段。在 IPv6 中，这个字段显示在分片扩展头部中，我们将在 5.3.3 节中讨论。</p>
<p>**生存期（TTL）**字段用于设置一个数据报可经过的路由器数量的上限。发送方将它初始化为某个值（[<a href="#RFC1122">RFC1122</a>] 建议为 64，但 128 或 255 也不少见），每台路由器在转发数据报时将该值减 1。当这个字段值达到 0 时，该数据报被丢弃，并使用一个 ICMP 消息通知发送方（见第 8 章）。.这可以防止由于出现不希望的路由环路而导致数据报在网络中永远循环。</p>
<pre><code>注意    TTL 字段最初指定 IP 数据报的最大生存期在几秒钟内，但路由器总需要将
这个值至少减 1。 实际上，当前路由器在正常操作下通常不会持有数据报超过 1 秒
钟，因此较早的规则现在已被忽略或遗忘，这个字段在 IPv6 中根据实际用途已被
重新命名为跳数限制。
</code></pre>
<p>IPv4 头部中的<strong>协议</strong>字段包含一个数字，表示数据报有效载荷部分的数据类型。最常用的值为 17 （UDP）和 6 （TCP）。这提供了多路分解的功能，以便 IP 协议可用于携带多种协议类型的有效载荷。虽然该字段最初仅用于指定数据报封装的传输层协议，但它现在用于识别其中封装的协议是否为一种传输层协议。其他封装也是可能的，例如 IPv4-in-IPv4 （值为 4）。数字分配页面 [<a href="#AN">AN</a>] 给出了可能的协议字段值的正式列表。 IPv6 头部中的下一个<strong>头部</strong>字段给出了 IPv4 中的协议字段。它用于指出 IPv6 头部之后的头部类型。这个字段可能包含由 IPv4 协议字段定义的任何值，或 5.3 节中描述的 IPv6 扩展头部的相关值。</p>
<p><strong>头部校验和</strong>字段仅计算 IPv4 头部。理解这一点很重要，因为这意味着 IP 协议不检查 IPv4 数据报有效载荷（例如 TCP 或 UDP 数据）的正确性。为了确保 IP 数据报的有效载荷部分已正确传输，其他协议必须通过自己的数据完整性检验机制来检查重要数据。我们看到，封装在 IP 中的几乎所有协议（ICMP、 IGMP、 UDP 和 TCP）在自己头部中都有一个涵盖其头部和数据的校验和，也涵盖它们认为重要的 IP 头部的某些部分（一种“违反分层”的形式）。令人惊讶的是， IPv6 头部没有任何校验和字段。</p>
<pre><code>注意    IPv6 头部省略校验和字段是一个有争议的决定。这个行动背后的理由大致
如下：在 IP 头部中，更高层协议为确定正确性，必须计算它们自己的校验和，这
需要涵盖它们认为重要的数据。 IP 头部中的错误带来的后果是：数据被投递到错误
的目的地、指示数据来源错误，或在交付过程中错位。由于位错误比较少见（受益
于 Internet 流量的光纤传输），而且其他字段提供了更有力的确保正确性的机制（更
高层次的校验和或其他检查），因此决定从 IPv6 头部中删除这个字段。
</code></pre>
<p>大多数使用校验和的其他 Internet 相关协议也使用该校验和计算算法，因此有时称之为 <strong>Internet 校验和</strong>。注意，当一个 IPv4 数据报经过一台路由器时， TTL 字段减 1 带来的结果是其头部校验和必须改变。找们将在 5.2.2 节详细讨论校验和计算方法。</p>
<p>每个 IP 数据报包含发送者的<strong>源 IP 地址</strong>和接收者的<strong>目的 IP 地址</strong>。这些针对 IPv4 的 32 位地址和针对 IPv6 的 128 位地址，通常标识一台计算机的一个接口，但组播地址和广播地址（见第 2 章）不符合本规则。虽然一个 32 位地址可容纳看似很多 Internet 实体（2<sup>32</sup> 个），但一个广泛的共识是这个数字仍不够，这是向 IPv6 迁移的一个主要动机。 IPv6 的 128 位地址可容纳数量庞大的 Internet 实体。 [<a href="#H05">H05</a>] 进行了重新统计， IPv6 拥有 3.4 × 10<sup>38</sup> 个地址。引用 [<a href="#H05">H05</a>]  和其他人的话：“乐观估计将使地球上每平方米表面拥有 3 911 873 538 269 506 102 个地址。”这确实看起来可持续很长一段时间。</p>
<h3 id="522-internet-校验和">5.2.2 Internet 校验和</h3>
<p>Internet 校验和是一个 16 位的数字和，它能以相当高的概率确定接收的消息或其中的部分内容是否与发送的相匹配。注意，Internet 校验和算法与常见的<strong>循环冗余校验（CRC）</strong>[<a href="#PB61">PB61</a>] 不同，后者提供了更强的保护功能。</p>
<p>为了给输出的数据报计算 IPv4 头部校验和，首先将数据报的校验和字段值设置为 0。然后，对头部（整个头部被认为是一个 16 位字的序列）计算 16 位二进制反码和。这个 16 位二进制反码和被存储在<strong>校验和</strong>字段中。二进制反码加法可通过“循环进位（end-round-carry）加法”实现：当使用传统（二进制补码）加法产生一个进位时，这个进位以二进制值 1 加在高位。图 5-3 显示了这个例子，消息内容使用十六进制表示。</p>
<p>图 5-3    Internet 校验和是一个被校验数据（如果被计算的字节数为奇数，用 0 填充）的 16 位反码和的反码。如果被计算数据包括一个校验和字段，该字段在计算校验和运算之前被设置为 0，然后将计算出的校验和填充到该字段。为了检查一个包含校验和字段（头部、有效载荷等）的数据输入是否有效，需要对整个数据块（包含校验和字段）同样计算校验和。由于校验和字段本质上是其余数据校验和的反码，对正确接收的数据计算校验和应产生一个值 0</p>
<p>当一个 IPv4 数据报被接收时，对整个头部计算出一个校验和，包括校验和字段自身的值。假设这里没有错误，计算出的校验和值为 0 （值 FFFF 的反码）。注意，对于任何不正常的分组或头部，分组中的校验和字段值不为 FFFF。如果是这样，这个和（在发送方的最后一次反码运算之前）将为 0。通过反码加法得到的和不能永远为 0，除非所有字节都是 0，这在任何合法 IPv4 头部中都不可能出现。当发现一个头部出错（计算的校验和不为 0）时， IPv4 实现将丢弃接收到的数据报。但是，不会生成差错信息。更高层以某种方式检测丢失的数据报，并在必要时重新传输。</p>
<h4 id="5221-internet-校验和数学性质">5.2.2.1 Internet 校验和数学性质</h4>
<p>在数学上， 16 位的十六进制值集合 V = {0001， …， FFFF} 与其反码和运算“+”共同形成一个阿贝尔群。将一个集合和一个运算符组合到一组时，必须符合以下性质：闭包、结合性、存在一个恒等元素，以及存在可逆。要形成一个阿贝尔（可交换的）群，还必须满足交换性。如果我们仔细观察，可看到所有特性实际上都服从：</p>
<ul>
<li>对于 V 中的任何 X、Y、（X + Y） 在 V 中  [闭包]</li>
<li>对于 V 中的任何 X、Y、Z，X +（Y + Z） = （X + Y） + Z                 [结合性]</li>
<li>对于 V 中的任何 X，e + X = X + e = X，其中 e = FFFF                 [恒等]</li>
<li>对于 V 中的任何 X，有一个 X' 在 V 中，使得 X + X' = e                  [可逆]</li>
<li>对于 V 中的任何 X、Y，（X + Y）=（Y +X）                      [交换性]</li>
</ul>
<p>关于集合 V 和组 &lt;V， +&gt;，有趣的是我们已删除 0000。如果我们将数字 0000 放入集合 V，这时 &lt;V， +&gt; 不再是一个组。为了看清这点，我们首先观察 0000 和 FFFF 作为 0 （加性恒等）出现在使用“+”的运算中的情况。例如，AB12 + 0000= AB1 2= AB12+FFFF。但是，在一个组中只能有一个恒等元素。如果我们包含元素 12AB，并假设恒等元素为 0000，那么我们就需要某个可逆数 X′ 使得 （12AB  + X′）= 0000，但我们发现，在 V 中没有满足此条件的 X' 存在。因此，我们需要排除 0000 作为&lt;V， +&gt; 中的恒等元素，通过将它从集合 V 中删除，使得这种结构成为一个满足要求的组。这里仅对抽象代数做一个简单介绍，读者若希望详细阅读这方面内容，可参考 Pinter [<a href="#P90">P90</a>] 的畅销书。</p>
<h3 id="523-ds-字段和-ecn-以前称为-tos-字节或-ipv6-流量类别">5.2.3 DS 字段和 ECN （以前称为 ToS 字节或 IPv6 流量类别）</h3>
<p>IPv4 头部的第 3 和第 4 字段（IPv6 头部的第 2 和第 3 字段）分别是<strong>区分服务（称为 DS 字段）<strong>和 <strong>ECN 字段</strong>。区分服务（称为 DiffServ）是一个框架和一组标准，用于支持 Internet [<a href="#RFC2474">RFC2474</a>] [<a href="#RFC2475">RFC2475</a>] [<a href="#RFC3260">RFC3260</a>] 上不同类型的服务（即不只是尽力而为服务）。 IP 数据报以某种方式（通过预定义模式设置某些位）被标记，使它们的转发不同于（例如以更高的优先级）其他数据报。这样做可能导致网络中排队延时的增加或减少，以及出现其他特殊效果（可能与 ISP 收取的特殊费用相关）。 <strong>DS 字段</strong>中的数字称为</strong>区分服务代码点（DSCP）</strong>。 “代码点”指的是预定义的具有特定含义的位。在通常情况下，如果数据报拥有一个分配的 DSCP，它在通过网络基础设施交付过程中会保持不变。但是，某些策略（例如在一段时间内可发送多少个高优先级的分组）可能导致一个数据报中的 DSCP 在交付过程中改变。</p>
<p>当通过一台具有内部排队流量的路由器时，头部中的 2 位 ECN 位用于为数据报标记<strong>拥塞标识符</strong>。一台持续拥塞的具有 ECN 感知能力的路由器在转发分组时会设置这两位。这种功能的设计思路是，当一个被标记的分组被目的节点接收时，有些协议（例如 TCP）会发现分组被标记并将这种情况通知发送方，发送方随后会降低发送速度，这样可在路由器因过载而被迫丢弃流量之前缓解拥塞。这种机制是避免或处理网络拥塞的方法之一，我们将在第 16 章中详细探讨。虽然 <strong>DS 字段</strong>和 <strong>ECN 字段</strong>并不密切相关，但它们被用作代替以前定义的** IPv4 服务类型<strong>和</strong> IPv6 流量类别**字段。因此，它们经常被放在一起讨论，术语“ToS 字节”和“流量类别字节”仍在广泛使用。</p>
<p>尽管原来的 ToS 和流量类别字节没得到广泛支持，但 DS 字段结构仍提供了一些对它们的兼容能力。为了对其如何工作有更清楚的了解，我们首先回顾服务类型字段 [<a href="#RFC0791">RFC0791</a>] 的原始结构，如图 5-4 所示。</p>
<figure data-type="image" tabindex="3"><img src="https://wenbozhangw.github.io//post-images/1653567934848.png" alt="图 5-4" loading="lazy"></figure>
<p>图 5-4    原来的 <strong>IPv4 服务类型</strong> 和 <strong>IPv6 流量类别</strong> 字段结构。<strong>优先级</strong>子字段用于表示哪些分组具有更高优先级（较大的值意味着更高的优先级）。D、T 和 R 子字段分别用于表示延时、吞吐量和可靠性。如果这些字段值为 1，分别对应于低延时、高吞吐量和高可靠性</p>
<p>D、 T 和 R 子字段表示数据报在延时、吞吐量和可靠性方面得到良好的处理。相应值为 1 表示更好的处理（分别为低延时、高吞吐量和高可靠性）。优先级取值范围是从 000 （常规）到 111 （网络控制），表示优先级依次递增（见表 5-1）。它们都基于一个称为**多级优先与抢占（MLPP）**的方案，该方案可追溯到美国国防部的 AUTOVON 电话系统 [<a href="#A92">A92</a>]，其中较低优先级的呼叫可被更高优先级的呼叫抢占。这些术语仍在使用，并被纳入 VoIP 系统中。</p>
<center> 表 5-1    原来的 IPv4 服务类型和 IPv6 流量类别 的优先级子字段值 </center>
<table>
<thead>
<tr>
<th>值</th>
<th>优先级名称</th>
</tr>
</thead>
<tbody>
<tr>
<td>000</td>
<td>常规</td>
</tr>
<tr>
<td>001</td>
<td>优先级</td>
</tr>
<tr>
<td>010</td>
<td>立即</td>
</tr>
<tr>
<td>011</td>
<td>瞬间</td>
</tr>
<tr>
<td>100</td>
<td>瞬间覆盖</td>
</tr>
<tr>
<td>101</td>
<td>严重</td>
</tr>
<tr>
<td>110</td>
<td>网间控制</td>
</tr>
<tr>
<td>111</td>
<td>网络控制</td>
</tr>
</tbody>
</table>
<p>在定义 <strong>DS 字段</strong>时，优先级的值已定义在 [<a href="#RFC2474">RFC2474</a>] 中，以提供有限的兼容性。在图 5-5 中， 6 位 <strong>DS 字段</strong>用于保存 DSCP，提供对 64 个代码点的支持。特定 DSCP 值可通知路由器对接收的数据报进行转发或特殊处理。不同类型的转发处理表示为<strong>每跳行为（PHB）</strong>，因此 DSCP 值可有效通知路由器哪种 PHB 被应用于数据报。 DSCP 的默认值通常为 0，对应于常规的尽力而为的 Internet 流量。 64 个可能的 DSCP 值分为不同用途，它们可从 [<a href="#DSCPREG">DSCPREG</a>] 中获得，如表 5-2 所示。</p>
<figure data-type="image" tabindex="4"><img src="https://wenbozhangw.github.io//post-images/1653568463910.png" alt="图 5-5" loading="lazy"></figure>
<p>图 5-5    <strong>DS 字段</strong>包含 6 位（其中 5 位当前是标准的，表示当前接收的数据报应转发时，可由一台兼容的路由器转发）。后面 2 位用作 ECN，当数据报通过持续拥塞的路由器时设置。当这些数据报到达目的地时，稍后发送一个包含拥塞指示的数据报给发送方，通知该数据报经过一台或多台拥塞的路由器</p>
<center> 表 5-2    DSCP 值被分成 3 个池：标准的、实验/本地用途的（EXP/LU）和最终打算标准化的实验/本地用途的（*） </center>
<table>
<thead>
<tr>
<th>池</th>
<th>代码店前缀</th>
<th>策略</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>xxxxx0</td>
<td>标准的</td>
</tr>
<tr>
<td>2</td>
<td>xxxx11</td>
<td>EXP/LU</td>
</tr>
<tr>
<td>3</td>
<td>xxxx01</td>
<td>EXP/LU（*）</td>
</tr>
</tbody>
</table>
<p>这个方案供研究人员和操作人员用于实验或本地用途。以 0 作为结尾的 DSCP 用于标准用途，以 1 作为结尾的 DSCP 用于实验或本地用途。以 01 作为结尾的 DSCP 最初打算用于实验或本地用途，但最终会走向标准化。</p>
<p>在图 5-5 中， <strong>DS 字段</strong>中的类别部分包含前 3 位，并基于较早定义的<strong>服务类型</strong>的优先级子字段。路由器通常先将流量分为不同类别。常见类别的流量可能有不同的丢弃概率，如果路由器被迫丢弃流量，允许路由器确定首先丢弃哪些流量。 3 位的类别选择器提供了 8 个定义的代码点（称为<strong>类别选择代码点</strong>），它们对应于一个指定最小功能集的 PHB，提供与早期的 IP 优先级相似的功能。它们称为<strong>类别选择兼容的 PHB</strong>，目的是支持部分兼容的最初定义的 IP 优先级子字段 [<a href="#RFC0791">RFC0791</a>] 。 <code>xxx000</code> 形式的代码点总被映射为这种 PHB，但是其他值也可映射到相同 PHB。</p>
<p>表 5-3 给出了类别选择器的 DSCP 值，以及 [<a href="#RFC0791">RFC0791</a>] 定义的 IP 优先级字段的相应术语。<strong>保证转发（AF）<strong>组对固定数量的独立 AF 类别的 IP 分组提供转发，它有效地概括了优先级的概念。某个类别的流量与其他类别的流量分别转发。在一个流量类别中，数据报被分配一个</strong>丢弃优先级</strong>。在一个类别中，较高丢弃优先级的数据报优先于那些较低丢弃优先级的数据报处理（即以较高优先级转发）。结合流量类别和丢弃优先级，名称 AFij 对应于保证转发类别 i 的丢弃优先级 j。例如，一个标记为 AF32 的数据报的流量类别为 3，丢弃优先级为 2。</p>
<center>表 5-3 DS 字段值设计为兼容服务类型和 IPv6 流量类别字段中指定的 IP 优先级字段。 AF 和 EF 提供比简单的“尽力而为”更好的服务</center>
<table>
<thead>
<tr>
<th>名称</th>
<th>值</th>
<th>参考文献</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>CS0</td>
<td>000000</td>
<td>[<a href="#RFC2474">RFC2474</a>]</td>
<td>类别选择（尽力而为/常规）</td>
</tr>
<tr>
<td>CS1</td>
<td>001000</td>
<td>[<a href="#RFC2474">RFC2474</a>]</td>
<td>类别选择（优先）</td>
</tr>
<tr>
<td>CS2</td>
<td>010000</td>
<td>[<a href="#RFC2474">RFC2474</a>]</td>
<td>类别选择（立即）</td>
</tr>
<tr>
<td>CS3</td>
<td>011000</td>
<td>[<a href="#RFC2474">RFC2474</a>]</td>
<td>类别选择（瞬间）</td>
</tr>
<tr>
<td>CS4</td>
<td>100000</td>
<td>[<a href="#RFC2474">RFC2474</a>]</td>
<td>类别选择（瞬间覆盖）</td>
</tr>
<tr>
<td>CS5</td>
<td>101000</td>
<td>[<a href="#RFC2474">RFC2474</a>]</td>
<td>类别选择（CRITIC/ECP）</td>
</tr>
<tr>
<td>CS6</td>
<td>110000</td>
<td>[<a href="#RFC2474">RFC2474</a>]</td>
<td>类别选择（网间控制）</td>
</tr>
<tr>
<td>CS7</td>
<td>111000</td>
<td>[<a href="#RFC2474">RFC2474</a>]</td>
<td>类别选择（控制）</td>
</tr>
<tr>
<td>AF11</td>
<td>001010</td>
<td>[<a href="#RFC2597">RFC2597</a>]</td>
<td>保证转发（1，1）</td>
</tr>
<tr>
<td>AF12</td>
<td>001100</td>
<td>[<a href="#RFC2597">RFC2597</a>]</td>
<td>保证转发（1，2）</td>
</tr>
<tr>
<td>AF13</td>
<td>001110</td>
<td>[<a href="#RFC2597">RFC2597</a>]</td>
<td>保证转发（1，3）</td>
</tr>
<tr>
<td>AF21</td>
<td>010010</td>
<td>[<a href="#RFC2597">RFC2597</a>]</td>
<td>保证转发（2，1）</td>
</tr>
<tr>
<td>AF22</td>
<td>010100</td>
<td>[<a href="#RFC2597">RFC2597</a>]</td>
<td>保证转发（2，2）</td>
</tr>
<tr>
<td>AF23</td>
<td>010110</td>
<td>[<a href="#RFC2597">RFC2597</a>]</td>
<td>保证转发（2，3）</td>
</tr>
<tr>
<td>AF31</td>
<td>011010</td>
<td>[<a href="#RFC2597">RFC2597</a>]</td>
<td>保证转发（3，1）</td>
</tr>
<tr>
<td>AF32</td>
<td>011100</td>
<td>[<a href="#RFC2597">RFC2597</a>]</td>
<td>保证转发（3，2）</td>
</tr>
<tr>
<td>AF33</td>
<td>011110</td>
<td>[<a href="#RFC2597">RFC2597</a>]</td>
<td>保证转发（3，3）</td>
</tr>
<tr>
<td>AF41</td>
<td>100010</td>
<td>[<a href="#RFC2597">RFC2597</a>]</td>
<td>保证转发（4，1）</td>
</tr>
<tr>
<td>AF42</td>
<td>100100</td>
<td>[<a href="#RFC2597">RFC2597</a>]</td>
<td>保证转发（4，2）</td>
</tr>
<tr>
<td>AF43</td>
<td>100110</td>
<td>[<a href="#RFC2597">RFC2597</a>]</td>
<td>保证转发（4，3）</td>
</tr>
<tr>
<td>EF PHB</td>
<td>101110</td>
<td>[<a href="#RFC3246">RFC3246</a>]</td>
<td>加速转发</td>
</tr>
<tr>
<td>VOICE-ADMIT</td>
<td>101100</td>
<td>[<a href="#RFC5865">RFC5865</a>]</td>
<td>容量许可的流量</td>
</tr>
</tbody>
</table>
<p>**加速转发（EF）**提供了非拥塞的网络服务，也就是说， EF 流量应享受较低的延时、抖动和丢包率。直观地说， EF 流量要求路由器的输出速率至少比输入速率大。因此，在一台路由器的队列中， EF 流量仅排在其他 EF 流量之后。</p>
<p>为了在 Internet 中提供差异化服务，目前已持续进行十多年的努力。虽然大部分机制的标准化开始于 20 世纪 90 年代末，但其中有些功能直到 21 世纪才被实现。 [<a href="#RFC4594">RFC4594</a>] 给出了一些关于如何配置系统以利用该功能的指导。差异化服务的复杂性在于：差异化服务和假设的差异化定价结构之间的联系，以及由此产生的公平问题。这种经济关系是复杂的，并且不在我们讨论的范围内。关于这个问题和相关主题的更多信息，详见 [<a href="#MB97">MB97</a>] 和 [<a href="#W03">W03</a>] 。</p>
<h3 id="524-ip-选项">5.2.4 IP 选项</h3>
<p>IP 支持一些可供数据报选择的选项。 [<a href="#RFC0791">RFC0791</a>] 介绍了大多数的选项，当时处于 IPv4 设计阶段， Internet 的规模相当小，对来自恶意用户的威胁关注较少。由于 IPv4 头部大小的限制以及相关的安全问题，因此很多选项不再是实用或可取的。在 IPv6 中，大部分选项已被删除或改变，不再是 IPv6 基本头部的一部分，而被放在 IPv6 头部之后的一个或多个扩展头部中。 IP 路由器接收到一个包含选项的数据报，通常需要对该数据报进行特殊处理。在某些情况下，尽管 IPv6 路由器可以处理扩展头部，但很多头部被设计为仅由终端主机处理。在有些路由器中，带选项或扩展的数据报不会像普通数据报那样被快速转发。作为相关的背景知识，我们简要讨论 IPv4 选项，以及 IPv6 如何实现扩展头部和选项。表 5-4 显示了经过多年标准化的 IPv4 选项。</p>
<p>表 5-4 给出了保留的 IPv4 选项，它们可在描述性的 RFC 中找到。这个完整的列表会定期更新，并可在 [<a href="#IPPARAM">IPPARAM</a>] 中在线查看。选项的范围总是以 32 位为界。如果有必要，数值 0 作为填充字节被添加。这确保 IPv4 头部始终是 32 位的倍数（IHL 字段的要求）。表 5-4 中的“编号”列是选项编号。 “值”列给出了放在<strong>类型</strong>字段中的编号，以表示该选项的存在。由于<strong>类型</strong>字段有另外的结构，所以这两列中的相应值不必相同。特别指出的是，第 1 （高序）位表示如果相关数据报被分片，该选项是否被复制到分片中。后面 2 位表示该选项的类别。目前，除了“时间戳”和“跟踪”使用类别 2 （调试和测量）外，表 5-4 中的所有选项使用类别 0 （控制）。类别 1 和 3 被保留。</p>
<center>表 5-4    如果选项存在，它在 IPv4 分组中紧跟在基本 IPv4 头部之后。选项由一个 8 位的类型字段标识。这个字段被细分为 3 个子字段：复制（1 位）、类别（2 位）和编号（5 位）。选项 0 和 1 的长度是 1 字节，多数的其他选项长度可变。可变选项包括 1 字节的类型标识符、1 字节的长度以及选项自身</center>
<table>
<thead>
<tr>
<th>名称</th>
<th>编号</th>
<th>值</th>
<th>长度</th>
<th>描述</th>
<th>参考文献</th>
<th>注释</th>
</tr>
</thead>
<tbody>
<tr>
<td>列表结尾</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>表示没有更多选项</td>
<td>[<a href="#RFC0791">RFC0791</a>]</td>
<td>如果需要</td>
</tr>
<tr>
<td>没有操作</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>表示没有操作执行（用于填充）</td>
<td>[<a href="#RFC0791">RFC0791</a>]</td>
<td>如果需要</td>
</tr>
<tr>
<td>源路由</td>
<td>3 <br/>9</td>
<td>131 <br/>137</td>
<td>可变</td>
<td>发送方列出分组转发时遍历的路由器“航点”。松散意味着其他路由器可以包含在航点（3，131）中。严格意味着（9，137）中的所有航点都有按顺序遍历</td>
<td>[<a href="#RFC1108">RFC1108</a>]</td>
<td>很少，经常被过滤</td>
</tr>
<tr>
<td>安全和处理标签</td>
<td>2 <br/>5</td>
<td>130 <br/>133</td>
<td>11</td>
<td>在美国军事环境下如何为 IP 数据包指定安全标签和处理闲置</td>
<td>[<a href="#RFC0791">RFC0791</a>]</td>
<td>很少</td>
</tr>
<tr>
<td>记录路由</td>
<td>7</td>
<td>7</td>
<td>可变</td>
<td>在分组的头部中记录经过的路由器</td>
<td>[<a href="#RFC0791">RFC0791</a>]</td>
<td>很少</td>
</tr>
<tr>
<td>时间戳</td>
<td>4</td>
<td>68</td>
<td>可变</td>
<td>在分组的源和目的地记录日期和时间</td>
<td>[<a href="#RFC0791">RFC0791</a>]</td>
<td>很少</td>
</tr>
<tr>
<td>流 ID</td>
<td>8</td>
<td>136</td>
<td>4</td>
<td>携带 16 位的 SATNET 流标识符</td>
<td>[<a href="#RFC0791">RFC0791</a>]</td>
<td>历史的</td>
</tr>
<tr>
<td>EIP</td>
<td>17</td>
<td>145</td>
<td>可变</td>
<td>扩展 Internet 协议（20 世纪 90 年代早期的一个实验）</td>
<td>[<a href="#RFC1385">RFC1385</a>]</td>
<td>历史的</td>
</tr>
<tr>
<td>跟踪</td>
<td>18</td>
<td>82</td>
<td>可变</td>
<td>增加一个路由跟踪选项和 ICMP 报文（20 世纪 90 年代早期的一个实验）</td>
<td>[<a href="#RFC1393">RFC1393</a>]</td>
<td>历史的</td>
</tr>
<tr>
<td>路由器警告</td>
<td>20</td>
<td>148</td>
<td>4</td>
<td>表示一个路由器需要解释数据报的内容</td>
<td>[<a href="#RFC2113">RFC2113</a>] [<a href="#RFC5350">RFC5350</a>]</td>
<td>偶然</td>
</tr>
<tr>
<td>快速启动</td>
<td>25</td>
<td>25</td>
<td>8</td>
<td>表示启动快速传输协议（实验性的）</td>
<td>[<a href="#RFC4782">RFC4782</a>]</td>
<td>很少</td>
</tr>
</tbody>
</table>
<p>目前，多数标准化选项在 Internet 中很少或从未使用。例如，源路由和记录路由选项需要将 IPv4 地址放在 IPv4 头部中。由于头部（总计 60 字节，其中 20 字节是基本 IPv4 头部）空间有限，这些选项在当前基于 IPv4 的 Internet 中用处不大，其中一条 Internet 路径的平均路由器跳步数约为 15 [<a href="#LFS07">LFS07</a>]。另外，这些选项主要用于诊断目的，它们为防火墙的构建带来麻烦和风险。因此， IPv4 选项通常在企业网络边界处被防火墙拒绝或剥离（见第 7 章）。</p>
<p>在企业网络内部，路径的平均长度更小，对恶意用户的防护可能考虑得更少，这些选项仍然可以使用。另外，<strong>路由器警告</strong>选项提示可能由于在 Internet 上使用其他选项而有异常问题。由于它的设计目标主要是优化性能，并不会改变路由器的基本行为，所以该选项通常比其他选项更常用。正如前面所提到的，有些路由器会实现高度优化的内部路径，用于那些不包含选项的 IP 流量转发。路由器警告选项用于通知路由器，一个分组需使用超出常规的转发算法来处理。在表 5-4 的结尾处，实验性的“快速启动”选项适用于 IPv4 和 IPv6 ，我们将在下一节讨论 IPv6 扩展头部和选项时介绍它。</p>
<hr>
<h2 id="53-ipv6-扩展头部">5.3 IPv6 扩展头部</h2>
<p>在 IPv6 中，那些由 IPv4 选项提供的特殊功能，通过在 IPv6 头部之后增加扩展头部实现。IPv4 路由和时间戳功能都采用这种方式，其他功能（例如分片和超大分组）很少在 IPv6 中使用（但仍需要），因此没有为它们在 IPv6 头部分配相应的位。基于这种设计， IPv6 头部固定为 40 字节，扩展头部仅在需要时添加。在选择 IPv6 头部为固定大小时，要求扩展头部仅由终端主机（仅有一个例外）处理， IPv6 设计者简化了高性能路由器的设计和实现，这是因为 IPv6 路由器处理分组所需的命令比 IPv4 简单。实际上，分组处理性能受很多因素影响，包括协议复杂性、路由器硬件和软件功能，以及流量负载等。</p>
<p>扩展头部和更高层协议（例如 TCP 或 UDP）头部与 IPv6 头部链接起来构成级联的头部（见图 5-6）。每个头部中的下一个头部字段表示紧跟着的头部的类型，它可能是一个 IPv6 扩展头部或其他类型。值 59 表示这个头部链的结尾。下一个头部字段的可能值定义在 [<a href="#IP6PARAM">IP6PARAM</a>] 中，并在表 5-5 中列出了其中的大多数。</p>
<figure data-type="image" tabindex="5"><img src="https://wenbozhangw.github.io//post-images/1653631363785.png" alt="图 5-6" loading="lazy"></figure>
<p>图 5-6    IPv6 头部使用下一个头部字段形成一个链。链中的头部可以是 IPv6 扩展头部或传输层头部。 IPv6 头部出现在数据报的开头，并且长度始终为 40 字节</p>
<center>表 5-5    IPv6 下一个头部字段值可能表示扩展头部或其他协议头部。在适当情况下，它与 IPv4 协议字段使用相同值</center>
<table>
<thead>
<tr>
<th>头部类型</th>
<th>顺序</th>
<th>值</th>
<th>参考文献</th>
</tr>
</thead>
<tbody>
<tr>
<td>IPv6 头部</td>
<td>1</td>
<td>41</td>
<td>[<a href="#RFC2460">RFC2460</a>] [<a href="#RFC2473">RFC2473</a>]</td>
</tr>
<tr>
<td>逐跳选项（HOPOPT）</td>
<td>2</td>
<td>0</td>
<td>[<a href="#RFC2460">RFC2460</a>]，紧跟在 IPv6 头部之后</td>
</tr>
<tr>
<td>目的地选项</td>
<td>3，8</td>
<td>60</td>
<td>[<a href="#RFC2460">RFC2460</a>]</td>
</tr>
<tr>
<td>路由</td>
<td>4</td>
<td>43</td>
<td>[<a href="#RFC2460">RFC2460</a>] [<a href="#RFC5095">RFC5095</a>]</td>
</tr>
<tr>
<td>分片</td>
<td>5</td>
<td>44</td>
<td>[<a href="#RFC2460">RFC2460</a>]</td>
</tr>
<tr>
<td>封装安全载荷（ESP）</td>
<td>7</td>
<td>50</td>
<td>（见第 18 章）</td>
</tr>
<tr>
<td>认证（AH）</td>
<td>6</td>
<td>51</td>
<td>（见第 18 章）</td>
</tr>
<tr>
<td>移动（MIPv6）</td>
<td>9</td>
<td>135</td>
<td>[<a href="#RFC6275">RFC6275</a>]</td>
</tr>
<tr>
<td>（无——没有下一个头部）</td>
<td>最后</td>
<td>59</td>
<td>[<a href="#RFC2460">RFC2460</a>]</td>
</tr>
<tr>
<td>ICMPv6</td>
<td>最后</td>
<td>58</td>
<td>（见第 8 章）</td>
</tr>
<tr>
<td>UDP</td>
<td>最后</td>
<td>17</td>
<td>（见第 10 章）</td>
</tr>
<tr>
<td>TCP</td>
<td>最后</td>
<td>6</td>
<td>（见第 13 ~ 17 章）</td>
</tr>
<tr>
<td>各种其他高层协议</td>
<td>最后</td>
<td>——</td>
<td>见 [<a href="#AN">AN</a>] 中的完整列表</td>
</tr>
</tbody>
</table>
<p>我们从表 5-5 中可以看到， IPv6 扩展头部机制将一些功能（例如路由和分片）与选项加以区分。除了“逐跳选项”的位置之外（它是强制性的），扩展头部的顺序是建议性的，因此一个 IPv6 实现必须按接收的顺序处理扩展头部。只有“目的地选项”头部可以使用两次，第一次是指出包含在 IPv6 头部中的目的 IPv6 地址，第二次（位置 8）是关于数据报的最终目的地。在某些情况下（例如使用路由头部），当数据报被转发到最终目的地时， IPv6 头部中的<strong>目的 IP 地址</strong>字段将会改变。</p>
<h3 id="531-ipv6-选项">5.3.1 IPv6 选项</h3>
<p>我们已经看到，相对于 IPv4， IPv6 提供了一种更灵活和可扩展的方式，将扩展和选项相结合。由于 IPv4 头部空间的限制，那些来自 IPv4 的选项已停止使用，而 IPv6 可变长度的扩展头部或编码在特殊扩展头部中的选项可适应当前更大的 Internet。如果选项存在，可放入<strong>逐跳选项</strong>（与一个数据报传输路径上的每个路由器相关）或<strong>目的地选项</strong>（仅与接收方相关）。逐跳选项（称为HOPOPT）是唯一由分组经过的每个路由器处理的选项。逐跳选项和目的地选项的编码格式一样。</p>
<p>逐跳选项和目的地选项头部的出现可以超过一次。这些选项均被编码为 <strong>类型 - 长度 - 值（TLV）</strong> 集合，对应于 图5-7 中所示格式。</p>
<figure data-type="image" tabindex="6"><img src="https://wenbozhangw.github.io//post-images/1653638926599.png" alt="图 5-7" loading="lazy"></figure>
<p>图 5-7    逐跳选项和目的地选项编码为 TLV 集合。第一字节给出了选项类型，包括一些子字段，在选项没被识别时指示一个 IPv6 节点如何动作，以及在数据报转发时选项数据是否改变。<strong>选项数据长度</strong>字段给出了选项数据的字节长度</p>
<p>TLV 结构如图 5-7 所示，它的长度为 2 字节，后面是可变长度的数据字节。第一字节表示选项类型，其中包括 3 个子字段。当 5 位的<strong>类型子字段</strong>无法由选项识别时，第一个子字段给出了一个 IPv6 节点尝试执行的动作。表 5-6 显示了所有可能的值。</p>
<center>表 5-6    一个 IPv6 的 TLV 选项类型的 2 个高序位，表示如果这个选项没有被识别，一个 IPv6 节点是转发还是丢弃该数据报，以及是否向发送方返回一个消息，提示这个数据报的处理结果</center>
<table>
<thead>
<tr>
<th>值</th>
<th>动作</th>
</tr>
</thead>
<tbody>
<tr>
<td>00</td>
<td>跳过选项，继续处理</td>
</tr>
<tr>
<td>01</td>
<td>丢弃这个数据报（沉默）</td>
</tr>
<tr>
<td>10</td>
<td>丢弃这个数据报，并向原地址发送一个“ICMPv6 参数问题”消息</td>
</tr>
<tr>
<td>11</td>
<td>与 10 相同，但仅在分组的目的地不是组播时，发送这个 ICMPv6 消息</td>
</tr>
</tbody>
</table>
<p>如果一个发往组播目的地的数据报中包括一个未知选项，那么大量节点将生成返回源节点的流量。这可通过将<strong>动作子字段</strong>设置为 11 来避免。<strong>动作子字段</strong>的灵活性在开发新的选项时是有用的。一个新的选项可携带在一个数据报中，并被那些无法理解它的路由器所忽略，这样有助于促进新选项的增量部署。当选项数据可能在数据报转发过程改变时，<strong>改变</strong>位字段（图 5-7 中的 Chg）设置为 1。表 5-7 中所示的选项已被 IPv6 定义。</p>
<center>表 5-7    IPv6 选项携带在逐跳（H）选项或目的地（D）选项扩展头部中。选项类型字段包含来自“类型”列以及动作和改变子字段中的二进制值。“长度”列包含来自图 5-7 的选项数据长度字节中的值。填充 1 是唯一没有该字节的选项</center>
<table>
<thead>
<tr>
<th>选项名</th>
<th>头部</th>
<th>动作</th>
<th>改变</th>
<th>类型</th>
<th>长度</th>
<th>参考文献</th>
</tr>
</thead>
<tbody>
<tr>
<td>填充 1</td>
<td>HD</td>
<td>00</td>
<td>0</td>
<td>0</td>
<td>N/A</td>
<td>[<a href="#RFC2460">RFC2460</a>]</td>
</tr>
<tr>
<td>填充 N</td>
<td>HD</td>
<td>00</td>
<td>0</td>
<td>1</td>
<td>可变</td>
<td>[<a href="#RFC2460">RFC2460</a>]</td>
</tr>
<tr>
<td>超大有效载荷</td>
<td>H</td>
<td>11</td>
<td>0</td>
<td>194</td>
<td>4</td>
<td>[<a href="#RFC2675">RFC2675</a>]</td>
</tr>
<tr>
<td>隧道封装限制</td>
<td>D</td>
<td>00</td>
<td>0</td>
<td>4</td>
<td>4</td>
<td>[<a href="#RFC2473">RFC2473</a>]</td>
</tr>
<tr>
<td>路由器警告</td>
<td>H</td>
<td>00</td>
<td>0</td>
<td>5</td>
<td>4</td>
<td>[<a href="#RFC2711">RFC2711</a>]</td>
</tr>
<tr>
<td>快速启动</td>
<td>H</td>
<td>00</td>
<td>1</td>
<td>5</td>
<td>8</td>
<td>[<a href="#RFC4782">RFC4782</a>]</td>
</tr>
<tr>
<td>CALIPSO</td>
<td>H</td>
<td>00</td>
<td>0</td>
<td>7</td>
<td>8+</td>
<td>[<a href="#RFC5570">RFC5570</a>]</td>
</tr>
<tr>
<td>家乡地址</td>
<td>D</td>
<td>11</td>
<td>0</td>
<td>201</td>
<td>16</td>
<td>[<a href="#RFC6275">RFC6275</a>]</td>
</tr>
</tbody>
</table>
<h4 id="5311-填充-1-和填充-n">5.3.1.1 填充 1 和填充 N</h4>
<p>由于 IPv6 选项需要与 8 字节的偏移量对齐，因此较小的选项用 0 填充到长度为 8 字节。这里有两个填充选项，分别称为填充 1 和填充 N。填充 1 选项（类型 0）是唯一缺少<strong>长度</strong>字段和<strong>值</strong>字段的选项。它仅有 1 字节长，取值为 0。填充 N 选项（类型 1）向头部的选项区域填充 2 字节或更多字节，它使用图 5-7 所示格式。对于″个填充字节，<strong>选项数据长度</strong>字段包含的值为（n - 2）。</p>
<h4 id="5312-ipv6-超大有效载荷">5.3.1.2 IPv6 超大有效载荷</h4>
<p>在某些 TCP/IP 网络中，例如那些用于互连超级计算机的网络，由于正常的 64KB 的 IP 数据报大小限制，在传输大量数据时会导致不必要的开销。 IPv6 超大有效载荷选项指定了一种有效载荷大于 65535 字节的 IPv6 数据报，称为<strong>超大报文</strong>。这个选项无法由 MTU 小于 64KB 的链路连接的节点来实现。超大有效载荷选项提供了一个 32 位的字段，用于携带有效载荷在 65535 ~ 4294967295 字节之间的数据报。</p>
<p>当一个用于传输的超大报文形成时，其正常<strong>负载长度</strong>字段被设置为 0。我们将在后面看到， TCP 协议使用<strong>负载长度</strong>字段，计算由前面所述的 Internet 校验和算法得到的校验和。当使用超大有效载荷选项时， TCP 必须使用来自选项的长度值，而不是基本头部中的长度字段值。虽然这个过程并不困难，但更大有效载荷使得未检测出错误的可能性增大 [<a href="#RFC2675">RFC2675</a>]。</p>
<h4 id="5313-隧道封装限制">5.3.1.3 隧道封装限制</h4>
<p><strong>隧道</strong>是指将一个协议封装在另一个协议中（见第 1 章和第 3 章）。例如， IP 数据报可能被封装在另一个 IP 数据报的有效载荷部分。隧道可用于形成虚拟的覆盖网络，在覆盖网络中，一个网络（例如 Internet）可作为另一个 IP 的链路层使用 [<a href="#TWEF03">TWEF03</a>]。隧道可以嵌套，从这个意义上来说，一条隧道中的数据报本身也可采用递归方式封装在另一条隧道中。</p>
<p>在发送一个 IP 数据报时，发送者通常无法控制最终用于封装的隧道层次。发送者可使用这个选项设置一个限制。一台路由器打算将一个 IPv6 数据报封装在一条隧道中，它首先检查<strong>隧道封装限制</strong>选项是否存在并置位。如果这个限制选项的值为 0，该数据报被丢弃，并将一个“ICMPv6 参数间题”消息（见第 8 章）发送到数据报源端（即之前的隧道入口点）。如果这个限制选项的值不为 0，该数据报可进行隧道封装，但新形成（封装）的 IPv6 数据报必须包括一个<strong>隧道封装限制</strong>选项，其值比封装之前的数据报中的封装限制选项值减 1。实际上，封装限制行动类似于 IPv4 的 TTL 和 IPv6 的<strong>跳数限制</strong>字段，只不过采用隧道封装层次代替转发跳步。</p>
<h4 id="5314-路由器警告">5.3.1.4 路由器警告</h4>
<p><strong>路由器警告</strong>选项指出数据报包含需要路由器处理的信息。它与 IPv4 的路由器警告选项的目的相同。 [<a href="#RAOPTS">RAOPTS</a>] 给出了这个选项的当前设置值。</p>
<h4 id="5315-快速启动">5.3.1.5 快速启动</h4>
<p>**快速启动（QS）**选项和 [<a href="#RFC4782">RFC4782</a>] 定义的 TCP/IP 实验性“快速启动”程序配合使用。它适用于 IPv4 和 IPv6，但目前建议仅用于专用网络，而不是全球性的 Internet。选项包括发送者需要的以比特/秒为单位的传输速率的编码值、 QS TTL 值和一些额外信息。如果沿途的路由器认为可以接受所需的速率，在这种情况下它们将递减 QS TTL，并在转发数据报时保持所需的速率不变。如果路由器不同意（即其支持的速率较低），它将该速率减小到一个可接受的速率。如果路由器不能识别 QS 选项，它将不递减 QS TTL。接收方将向发送方提供反馈，包括接收到的数据报的 IPv4 TTL 或 <strong>IPv6 跳数限制</strong>字段和自己的 QS TTL 之间的差异，以及获得的速率可能被沿途的路由器所调整。这个信息被发送方用于确定发送速率（否则可能超出 TCP 使用的速率）。对 TTL 值进行比较的目的是确保沿途每台路由器参与 QS 谈判。如果发现任何路由器递减 IPv4 TTL （或 <strong>IPv6 跳数限制</strong>）字段，但没有修改 QS TTL 值，则说明它没有启用 QS。</p>
<h4 id="5316-calipso">5.3.16 CALIPSO</h4>
<p>这个选项用于在某些专用网络中支持<strong>通用体系结构标签 IPv6 安全选项（CALIPSO）</strong> [<a href="#RFC5570">RFC5570</a>]。它提供了一种为数据报做标记的方法，包括一个安全级别标识符和一些额外的信息。需要注意的是，它用于多级安全网络环境（例如，政府、军队和银行），其中所有数据的安全级别必须以某种形式的标签注明。</p>
<h4 id="5317-家乡地址">5.3.1.7 家乡地址</h4>
<p>当使用 IPv6 移动选项时，这个选项保存发送数据报的 IPv6 节点的“家乡”地址。移动 IP （见 5.5 节）规定了 IP 节点的一系列处理过程，这些节点可能改变自已的网络接入点，同时不会断开自已的高层网络连接。这里存在一个节点的“家乡”的概念，它来自其典型位置的地址前缀。当远离家乡漫游时，通常为该节点分配一个不同的 IP 地址。该选项允许这个节点提供自己正常的家乡地址，以及它在漫游时的新地址（通常是临时分配）。当其他 IPv6 节点需要与移动节点通信时，它可以使用该节点的家乡地址。如果<strong>家乡地址</strong>选项存在，包含它的<strong>目的地选项头部</strong>必须出现在路由头部之后，并且在<strong>分片、认证</strong>和 <strong>ESP 头部</strong>（见第 18 章）之前（如果这些头部也存在）。我们将在移动 IP 中详细讨论这个选项。</p>
<h3 id="532-路由头部">5.3.2 路由头部</h3>
<p>IPv6 路由头部为发送方提供了一种 IPv6 数据报控制机制，以控制（至少部分控制）数据报通过网络的路径。目前，路由扩展头部有两个不同版本，分别称为类型 0 （RH0）和类型 2 （RH2）。 RH0 出于安全方面的考虑已被否决 [<a href="#RFC5095">RFC5095</a>]， RH2 被定义为与移动 IP 共同使用。为了更好地理解路由头部，我们首先讨论 RH0，然后研究它为什么被放弃，以及它和 RH2 的不同之处。 RH0 规定了数据报转发时可“访问”的一个或多个 IPv6 节点。图 5-8 显示了这个头部。</p>
<figure data-type="image" tabindex="7"><img src="https://wenbozhangw.github.io//post-images/1653651957371.png" alt="图 5-8" loading="lazy"></figure>
<p>图 5-8    目前已废弃的路由头部类型 0（RH0）涵盖了 IPv4 的宽松和严格的<strong>源路由</strong>和<strong>记录路由</strong>选项。它在数据报转发时由发送方构造，其中包括转发路径上的 IPv6 节点地址。每个地址可指定为一个宽松或严格的地址。一个严格的地址必须经过一个 IPv6 跳步到达，而一个松散的地址可能经过一个或多个其他跳步到达。在 IPv6 基本头部中，<strong>目的 IP 地址</strong>字段修改为包含数据报转发的下一个转发地址</p>
<p>图 5-8 所示的 IPv6 路由头部涵盖了来自 IPv4 的<strong>宽松源路由</strong>和<strong>记录路由</strong>选项。它还支持采用 IPv6 地址之外的其他标识符路由的可能性，这个功能是不规范的，这里没有进一步讨论。对于标准化的 IPv6 地址的路由， RH0 允许发送方指定一个指向目的地址的向量。</p>
<p>这个头部包含一个 8 位的<strong>路由类型</strong>标识符和一个 8 位的<strong>剩余部分</strong>字段。对于 RH0， IPv6 地址类型标识符为 0 ；对于 RH2，该标识符为 2。<strong>剩余部分</strong>字段指出还有多少段路由需要处理，也就是说，在到达最终目的地之前仍需访问的中间节点数。它是一个 32 位的从保留字段开始的地址块，由发送方设置为 0，并由接收方忽略。在数据报转发时，这些地址并非可访问的组播 IPv6 地址。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[《TCP/IP 详解 卷一：协议》第四章：地址解析协议]]></title>
        <id>https://wenbozhangw.github.io/post/lesslesstcpip-xiang-jie-juan-yi-xie-yi-greatergreater-di-si-zhang-di-zhi-jie-xi-xie-yi/</id>
        <link href="https://wenbozhangw.github.io/post/lesslesstcpip-xiang-jie-juan-yi-xie-yi-greatergreater-di-si-zhang-di-zhi-jie-xi-xie-yi/">
        </link>
        <updated>2022-05-19T16:48:06.000Z</updated>
        <summary type="html"><![CDATA[<h2 id="41-引言">4.1 引言</h2>
<p>IP 协议的设计目标是为跨越不同类型物理网络的分组交换提供互操作。这需要网络层软件使用的地址和底层网络硬件使用的地址之间进行转换。网络接口硬件通常有一个主要的硬件地址（例如以太网或 802.11 无线接口的 48 位地址）。由硬件交换的帧需要使用正确的硬件地址定位到正确的接口；否则，无法传输数据。但是，一个传统 IPv4 网络需要使用自己的地址：32 位的 IPv4 地址。如果一台主机要将一个帧发送到另一台主机，仅知道这台主机的 IP 地址是不够的，还需要知道主机在网络中的有效硬件地址。操作系统软件（即以太网驱动程序）必须知道目的主机的硬件地址，以便直接向它发送数据。对于 TCP/IP 网络，<strong>地址解析协议（ARP）</strong> [<a href="#RFC0826">RFC0826</a>] 提供了一种在 IPv4 地址和各种网络技术使用的硬件地址之间的映射。 ARP 仅用于 IPv4， IPv6 使用邻居发现协议，它被合并入 ICMPv6 （见第 8 章）。</p>
]]></summary>
        <content type="html"><![CDATA[<h2 id="41-引言">4.1 引言</h2>
<p>IP 协议的设计目标是为跨越不同类型物理网络的分组交换提供互操作。这需要网络层软件使用的地址和底层网络硬件使用的地址之间进行转换。网络接口硬件通常有一个主要的硬件地址（例如以太网或 802.11 无线接口的 48 位地址）。由硬件交换的帧需要使用正确的硬件地址定位到正确的接口；否则，无法传输数据。但是，一个传统 IPv4 网络需要使用自己的地址：32 位的 IPv4 地址。如果一台主机要将一个帧发送到另一台主机，仅知道这台主机的 IP 地址是不够的，还需要知道主机在网络中的有效硬件地址。操作系统软件（即以太网驱动程序）必须知道目的主机的硬件地址，以便直接向它发送数据。对于 TCP/IP 网络，<strong>地址解析协议（ARP）</strong> [<a href="#RFC0826">RFC0826</a>] 提供了一种在 IPv4 地址和各种网络技术使用的硬件地址之间的映射。 ARP 仅用于 IPv4， IPv6 使用邻居发现协议，它被合并入 ICMPv6 （见第 8 章）。</p>
<!-- more -->
<p>这里需要注意的是，网络层地址和链路层地址是由不同部门分配的。对于网络硬件，主地址是由设备制造商定义的，并存储在设备的永久性内存中，所以它不会改变。因此，工作在特定硬件技术上的任意协议族，必须利用特定类型的地址。这允许不同协议族中的网络层协议<strong>同时运行</strong>。另一方面，网络接口的 IP 地址是由用户或网络管理员分配的，并且可以接需选择。为便携设备分配的 IP 地址可能改变，例如设备移动时。 IP 地址通常从维护附近网络连接点的地址池中获得，它在系统启用或配置时分配（见第 6 章）。当两个局域网的主机之间传输的以太网帧包含 IP 数据报时，由 48 位以太网地址确定该帧的目的接口。</p>
<p><strong>地址解析</strong>是发现两个地址之间的映射关系的过程。对于使用 IPv4 的 TCP/IP 协议族，这是由运行的 ARP 来实现的。 ARP 是一个通用的协议，从这个意义上来看，它被设计为支持多种地址之间的映射。实际上， ARP 几乎总是用于 32 位 IPv4 地址和以太网的 48 位 MAC 地址之间的映射。这种情况在 [<a href="#RFC0826">RFC0826</a>] 中进行描述，它也是我们感兴趣的。在本章中，我们将互换使用以太网地址和 MAC 地址。</p>
<p>ARP 提供从网络层地址到相关硬件地址的动态映射。我们使用动态这个术语是因为它会自动执行和随时间变化，而不需要系统管理员重新配置。也就是说，如果一台主机改变它的网络接口卡，从而改变了它的硬件地址（但保留其分配的 IP 地址）， ARP 可以在一定延时后继续正常运作。 ARP 操作通常与用户或系统管理员无关。</p>
<p>注意    提供 ARP 反向映射的协议称为 RARP，它用于缺少磁盘驱动器（通常是无盘工作站或 X 终端）的系统。它在当前已很少使用，而且需要系统管理员手功配置。详情见 [<a href="#RFC0903">RFC0903</a>] 。</p>
<hr>
<h2 id="42-一个例子">4.2 一个例子</h2>
<p>当我们使用 Internet 服务时，例如在浏览器中打开一个网页，本地计算机必须确定如何与相关的服务器联系。它首先是判断该服务位于本地（同一 IP 子网的一部分）还是远程。如果是远程的，需要一台可到达目的地的路由器。仅在到达位于同一 IP 子网的系统时，ARP 才能工作。那么对于这个例子，我们假设使用 Web 浏览器打开以下网址：</p>
<pre><code>http://10.0.0.1
</code></pre>
<p>注意，这个 URL 包含一个 IPv4 地址，而不是更常见的域名或主机名。这里使用地址的原因是要强调一个事实，例子中是共享相同 IPv4 前缀的相关系统（见第 2 章）。这里，我们使用包含地址的 URL，以确定一个本地的 Web 服务器，并探索 <strong>直接交付</strong> 的运行原理。随着嵌入式设备（例如打印机和 VoIP 适配器）使用内置 Web 服务器进行配置，这种本地服务器越来越常见。</p>
<h3 id="421-直接交付和-arp">4.2.1 直接交付和 ARP</h3>
<p>在本节中，我们列出了直接交付的步骤，重点集中在 ARP 的运行上。直接交付发生在一个 IP 数据报被发送到一个 IP 地址，而该地址与发送方具有相同 IP 前缀的情况下。在 IP 数据报转发（见第 5 章）的常见方式中，它扮演着一个重要角色。下面用前面的例子列出 IPv4 直接交付的基本操作：</p>
<ol>
<li>在这种情况下，应用程序是一个 Web 浏览器，调用一个特殊函数来解析 URL，看它是否包含主机名。这里不是，应用程序使用 32 位 IPv4 地址 <code>10.0.0.1</code>。</li>
<li>应用程序要求 TCP 协议建立一条到 <code>10.0.0.1</code> 的连接。</li>
<li>通过向 <code>10.0.0.1</code> 发送一个 IPv4 数据报，TCP 尝试向远程主机发送一个连接请求（第 15 章将介绍细节）。</li>
<li>我们假设地址 <code>10.0.0.1</code> 使用与发送主机相同的网络前缀，数据报可被直接发送到这个地址而不经过任何路由器。</li>
<li>假设以太网兼容地址被用于 IPv4 子网，发送主机必须将 32 位的 IPv4 目的地址转换为 48 位的以太网地址。使用 [<a href="#RFC0826">RFC0826</a>] 的术语，就是需要从 <strong>逻辑 Internet</strong> 地址向对应 <strong>物理</strong> 硬件地址进行转换。这是 ARP 功能。ARP 工作在正常模式下，仅适用于 <strong>广播网络</strong>，链路层能将一个消息交付到它连接的所有网络设备。这是 ARP 运行的一个重要要求。在非广播网络（有时被称为 <strong>非广播多路访问（NBMA）</strong>）中，可能需要更复杂的映射协议 [<a href="#RFC2332">RFC2332</a>] 。</li>
<li>在一个共享的链路层网段上，ARP 向所有主机发送一个称为 <strong>ARP 请求</strong> 的以太网帧。这被称为 <strong>链路层广播</strong>。图 4-1 的斜线阴影中显示了一个<strong>广播域</strong>。ARP 请求包含目的主机的 IPv4 地址（<code>10.0.0.1</code>），并寻找以下问题的答案：“如果你将 IPv4 地址 <code>10.0.0.1</code> 配置为自己的地址，请向我回应你的 MAC 地址。”</li>
<li>通过 ARP，同一广播域中的所有系统可接收 ARP 请求。这包括可能根本不允许 IPv4 或 IPv6 协议的系统，但不包括位于不同 VLAN 中的系统，即使支持它们（VLAN 详细信息见第 3 章）。如果某个系统使用请求中指出的 IPv4 地址，它仅需要响应一个 <strong>ARP 应答</strong>。这个应答包含 IPv4 地址（与请求相匹配）和对应的 MAC 地址。这个应答通常不是广播，而是仅直接发送给请求的发送方。同时，接收 ARP 请求的主机学习 IPv4 到 MAC 地址的映射，并记录在内存中供以后使用（见 4.3 节）。</li>
<li>ARP 应答被原始请求的发送方接收，现在可发送引起这次 ARP 请求/应答交换过程的数据报。</li>
<li>发送方可将数据报封装在以太网帧中直接发送到目的主机，并使用由 ARP 交换学到的以太网地址作为目的地址。由于这个以太网地址仅指向正确的目的主机，所有其他主机或路由器不会接收到这个数据报。因此，当仅使用直接交付时，并不需要经过路由器。</li>
</ol>
<figure data-type="image" tabindex="1"><img src="https://wenbozhangw.github.io//post-images/1653399568330.png" alt="图 4-1" loading="lazy"></figure>
<p>图 4-1    以太网主机在同一广播域中。ARP 查询使用链路层广播帧发送，并被所有主机接收。 IP 地址匹配的主机直接向请求主机返回响应。 IP 地址不匹配的主机主动丢弃 ARP 查询</p>
<p>ARP 用于运行 IPv4 的多接入链路层网络，每个主机都有自己首选的硬件地址。点到点链路（例如 PPP）不使用 ARP （见第 3 章）。当这些链路被建立后（通常是由用户或系统来发起创建），在链路两端通知正在使用的地址。由于不涉及硬件地址，因此不需要地址解析或 ARP。</p>
<hr>
<h2 id="43-arp-缓存">4.3 ARP 缓存</h2>
<p>ARP 高效运行的关键是维护每个主机和路由器上的 <strong>ARP 缓存</strong>（或表）。该缓存使用地址解析为每个接口维护从网络层地址到硬件地址的最新映射。当 IPv4 地址映射到硬件地址时，它对应于高速缓存中的一个条目，其正常到期时间是条目创建开始后的20分钟，这在 [<a href="#RFC1122">RFC1122</a>] 中描述。</p>
<p>我们可在 Linux 或 Windows 中使用 arp 命令查看 ARP 缓存。选项 -a 用于显示这两个系统的缓存中的所有条目。在 Linux 中，运行 arp 会产生以下输出：</p>
<pre><code>Linux% arp
Address                  HWtype  HWaddress           Flags Mask            Iface
gw.home            ether   00:0D:66:4F:60:00   C                     eth0
printer.home              ether   00:0A:95:87:38:6A   C                     eth0
Linux% arp -a
printer.home (10.0.0.4) at 00:0A:95:87:38:6A [ether] on eth1
gw.home (10.0.0.1) at 00:0D:66:4F:60:00 [ether] on eth1
</code></pre>
<p>在 Windows 中，运行 arp 会产生以下类似的输出：</p>
<pre><code>c:\&gt; arp -a
Interface: 10.0.0.56 --- 0x2
  Internet Address         Physical Address              Type
  10.0.0.1            00-0d-66-4f-60-00     dynamic
  10.0.0.4            00-0a-95-87-38-6a     dynamic
</code></pre>
<p>这里，我们看到的是 IPv4 到硬件地址的缓存。在第一个（Linux）例子中，每个映射是一个包含 5 个元素的条目：主机名（对应一个 IP 地址）、硬件地址类型、硬件地址、标志和本地网络接口（它对于这个映射是活跃的）。<strong>标志</strong>列包含一个符号：C、 M 或 P。 C 类条目由 ARP 协议动态学习， M 类条目通过手工输入（arp -s ；见 4.9 节），而 P 类条目的含义是“发布”。也就是说，对于任何 P 类条目，主机对输入的 ARP 请求返回一个 ARP 应答。这个选项用于配置代理 ARP（见 4.7 节）。第二个 Linux 的例子显示了使用“BSD 风格”的类似信息。这里，给出了主机名和地址，对应的地址类型（[<a href="#ether">ether</a>] 表示一个以太网类型的地址），以及映射活跃在哪个接口上。</p>
<p>Windows 的 arp 程序显示了接口的 IPv4 地址，它的接口号是十六进制数（这里的 <code>0x2</code>）。Windows 版本还指出地址是手动输入还是 ARP 学习。在这个例子中，两个条目都是动态的，这意味着它们来自 ARP 学习（如果通过手工输入，它们是静态的）。注意， 48 位 MAC 地址被显示为 6 个十六进制数，在 Linux 中使用冒号分隔，在 Windows 中使用短杠（dash）分隔。在传统上， UNIX 系统一直使用冒号，而 IEEE 标准和其他操作系统倾向于使用短杠。我们在 4.9 节中讨论 arp 命令的附加功能和其他选项。</p>
<hr>
<h2 id="44-arp-帧格式">4.4 ARP 帧格式</h2>
<p>图 4-2 显示了在以太网中转换一个 IPv4 地址时常用的 ARP 请求和应答分组的格式（正如前面所说， ARP 通常也能用于 IPv4 以外的地址，虽然这是非常少见的）。前 14 字节构成标准的以太网头部，假设没有 802.1p/q 或其他标记，其余部分由 ARP 协议来定义。 ARP 帧的前 8 个字节是通用的，这个例子中的剩余部分专门用于将 IPv4 地址映射到 48 位的以太网地址。</p>
<figure data-type="image" tabindex="2"><img src="https://wenbozhangw.github.io//post-images/1653401432482.png" alt="图 4-2" loading="lazy"></figure>
<p>图 4-2    IPv4 地址映射到 48 位的 MAC（以太网）地址时使用的 ARP 帧格式</p>
<p>在图 4-2 所示的 ARP 帧的以太网头部中，前两个字段包含目的和源以太网地址。对于 ARP 请求，目的以太网地址 <code>ff:ff:ff:ff:ff:ff</code> （全部为 1）是广播地址，在同一广播域中的所有以太网接口可接收这些帧。在以太网帧中，对于 ARP （请求或应答）， 2 字节的<strong>长度</strong>或<strong>类型</strong>字段必须为 <code>0x0806</code>。</p>
<p><strong>长度/类型</strong>字段之后的前 4 个字段指定了最后 4 个字段的类型和大小。这些值由 IANA [<a href="#RFC5494">RFC5494</a>] 来指定。 术语<strong>硬件</strong>和<strong>协议</strong>用于描述 ARP 分组中的字段。例如，一个 ARP 请求询问协议地址（在这种情况下是 IPv4 地址）对应的硬件地址（在这种情况下是以太网地址）。这些术讳很少被用于 ARP 之外。相对来说，硬件地址的常见术语有 MAC、<strong>物理</strong>或<strong>链路层地址</strong>（或<strong>以太网</strong>地址，当网络基于 IEEE 802.3/以太网的一系列规范时）。 <strong>硬件类型</strong>字段指出硬件地址类型。 对于以太网，该值为 1。 <strong>协议类型</strong>字段指出映射的协议地此类型。 对于 IPv4 地址，该值为 <code>0x0800</code>。 当以太网帧包含 IPv4 数据报时，这可能与以太网帧的<strong>类型</strong>字段值一致。对于下面两个 1 字节的字段，<strong>硬件大小</strong>和<strong>协议大小</strong>分别指出硬件地址和协议地址的字节数。对于以太网中使用 IPv4 地此的 ARP 请求或应答，它们的值分别为 6 和 4。 Op 字段指出该操作是 ARP 请求（值为 1）、 ARP 应答（2）、 RARP 请求（3）或 RARP应答（4）。由于 ARP 请求和 ARP 应答的<strong>长度/类型</strong>字段相同，因此这个字段是必需的。</p>
<p>紧跟在后面的 4 个字段是<strong>发送方硬件地址</strong>（在这个例子中是以太网 MAC 地址）、<strong>发送方协议地址</strong>（lPv4 地址）、<strong>目的硬件地址</strong>（MAC/以太网地址）和<strong>目的协议地址</strong>（IPv4 地址）。注意，这里存在一些重复的信息：以太网头部和 ARP 消息都包含发送方硬件地址。对于一个 ARP 请求，除了<strong>目的硬件地址</strong>（设为 0）之外，其他字段都需要填充。当一个系统接收到一个 ARP 请求，它填充自己的硬件地址，将两个发送方地址和两个接收方地址互换，将 Op 字段设置为 2，然后发送生成的应答。</p>
<hr>
<h2 id="45-arp-例子">4.5 ARP 例子</h2>
<p>在本节中，我们将使用 tcpdump 命令查看在执行一个正常 TCP/IP 应用（例如 Telnet）时运行 ARP 所实际发生的过程。Telnet 是一个简单的应用程序，可用于在两个系统之间建立一条 TCP/IP 连接。</p>
<h3 id="451-正常的例子">4.5.1 正常的例子</h3>
<p>为了查看 ARP 运行，我们将执行 telnet 命令，使用 TCP 端口 80 （称为 www）连接到主机 10.0.0.3 上的 Web 服务器。</p>
<pre><code>C:\&gt; arp -a                    // 验证 arp 缓存为空
No ARP Entries Found
C:\&gt; telnet 10.0.0.3 www                    // 连接到 Web 服务器 [端口80]
Connecting to 10.0.0.3...
Escape character is '^]'.
</code></pre>
<p>按下 CTRL + 右括号键获得 Telnet 客户机的提示。</p>
<pre><code>Welcome to Microsoft Telnet Client
Escape Character is 'CTRL+]'
Microsoft Telnet&gt; quit
</code></pre>
<p>指令 quit 用于退出程序。</p>
<p>在这些命令执行的同时，我们在另一个系统上预习呢 tcpdump 命令，并观察交换的流量信息。使用 -e 选项可以显示 MAC 地址（这个例子中是 48 位以太网地址）。</p>
<p>下面列出的内容包含来自 tcpdump 的输出。我们删除了输出的最后 4 行，它们用于终止连接（我们将在第 13 章中详细讨论），但与这里的讨论无关。注意，不同系统中的 tcpdump 版本提供的输出细节可能稍有不同。</p>
<pre><code>Linux# tcpdump -e
1       0.0    0:0:c0:6f:2d:40    ff:ff:ff:ff:ff:ff    arp   60:
        arp    who-has    10.0.0.3    tell   10.0.0.56
2        0.002174    (0.0022)0:0:c0:c2:9b:26    0:0:c0:6f:2d:40    arp    60:
        arp    reply    10.0.0.3    is-at    0:0:c0:c2:9b:26

3       0.002831    (0.0007)0:0:c0:6f:2d:40    0:0:c0:c2:9b:26    ip    60:
        10.0.0.56.1030    &gt;    10.0.0.3.www:    S    596459521:596459521(0)
        win    4096    &lt;ms    1024&gt;    [tos    0x10]
4       0.007834    (0.0050)0:0:c0:c2:9b:26    0:0:c0:6f:2d:40    ip    60:
        10.0.0.3.www    &gt;    10.0.0.56.1030:    S    3562228225:3562228225(0)
        ack    596459522    win    4096    &lt;mss    1024&gt;
5       0.009615    (0.0018)0:0:c0:6f:2d:40    0:0:c0:c2:9b:26    ip    60:
        10.0.0.56.1030    &gt;    10.0.0.3.discard:    .    ack    1    win    [tos    0x10]
</code></pre>
<p>在分组 1 中，源硬件地址为 <code>0:0:c0:6f:2d:40</code>。 目的硬件地址为<code>ff:ff:ff:ff:ff:ff</code>。 它是一个以太网广播地址。同一广播域（在同一局域网或 VLAN 中的所有主机，无论它们是否运行 TCP/IP）中的所有以太网接口接收并处理该帧，如图 4-1 所示。分组 1 的下一个输出字段为 arp，意味着帧类型字段为 <code>0x0806</code>。表明它是 ARP 请求或 ARP 应答。在前 5 个分组中， arp 和 ip 后面打印的值 60 是以太网帧的长度。 ARP 请求或 ARP 应答的大小是 42 字节（ARP 消息为 28 字节，以太网头部为 14 字节）。每个帧均填充为最小以太网帧：60 字节数据和 4 字节 CRC （见第 3 章）。</p>
<p>分组 1 的下一部分（即 arp who-has）用于标识该帧是 ARP 请求，目的地址是 IPv4 地址 <code>10.0.0.3</code>，源地址是 IPv4 地址 <code>10.0.0.56</code>。tcpdump 显示默认 IP 地址对应的主机名，但在这里没有显示（由于没有为它们建立反向 DNS 映射；第 11 章介绍 DNS 的细节）。接下来，我们使用 -n 选项查看 ARP 请求中的 IP 地址，无论它们是否进行 DNS 映射。</p>
<p>我们从分组 2 中看到，虽然 ARP 请求是广播的，但 ARP 应答的目的地址是（单播）MAC 地址 <code>0:0:c0:6f:2d:40</code>。因此，ARP 应答是直接发送到请求主机，它并不是通常的广播（在 4.8 节的一些情况下，这个规则可能会改变）。tcpdump 显示出该帧的 ARP 应答，以及响应者的 IPv4 地址和硬件地址。第 3 行是请求建立的第一个 TCP 段。其目的硬件地址属于目的主机（<code>10.0.0.3</code>）。我们将在第 13 章涉及这部分的细节。</p>
<p>对于每个分组，分组号后面的数字是 tcpdump 接收分组的相对时间（秒）。除第一个之外的每个分组都包含从前一段时间到现在的时间差（秒），该值放在括号中。我们可以看到发送 ARP 请求和接受 ARP 应答之间的时间约为 2.2ms。第一个 TCP 段在此后 0.7ms 发送。在这个例子中，ARP 动态地址解析的开销少于 3ms。注意，如果主机 10.0.0.3 的 ARP 表项在 10.0.0.56 的 ARP 缓存中是有效的，最初的 ARP 交换并不会发生，最初的 TCP 段可能已使用目的以太网地址立即发送。</p>
<p>有关 tcpdump 输出的一个微妙问题是，在向 <code>10.0.0.56</code> （第 4 行）发送自己的第一个 TCP 段之前，我们没看到来自 <code>10.0.0.3</code> 的 ARP 请求。<code>10.0.0.3</code> 在自己的 ARP 缓存中可能已有一个 <code>10.0.0.56</code> 的条目，通常当系统接收到发送给它的 ARP 请求时，除了发送 ARP 应答外，它还会在 ARP 缓存中保存请求者的硬件地址和 IP 地址。这是一个基于逻辑假设的优化，如果请求者发送一个数据报，该数据报的接收者可能发送一个应答。</p>
<h3 id="452-对一个不存在的主机的-arp-请求">4.5.2 对一个不存在的主机的 ARP 请求</h3>
<p>如果 ARP 请求中指定的主机关闭或不存在，将会发生什么？为了查看这种情况，我们尝试访问一个不存在的本地 IPv4 地址，其前缀对应本地子网，但没有主机使用该地址。在这个例子中，我们使用 IPv4 地址  <code>10.0.0.99</code>。</p>
<pre><code>Linux% date ; telnet 10.0.0.99 ; date
Fri Jan 29 14:46:33 PST 2010
Trying 10.0.0.99...
telnet: connect to address 10.0.0.99: No route to host
Fri Jan 29 14:46:36 PST 2010               // 3s after previous date

Linux% arp -a
? (10.0.0.99) at &lt;incomplete&gt; on eth0
</code></pre>
<p>这是 tcpdump 的输出：</p>
<pre><code>1    21:12:07.440845 arp who-has 10.0.0.99 tell 10.0.0.56
2    21:12:08.436842 arp who-has 10.0.0.99 tell 10.0.0.56
3    21:12:09.436836 arp who-has 10.0.0.99 tell 10.0.0.56
</code></pre>
<p>由于我们已知使用广播地址发送 ARP 请求，因此本次并没有指定 -e 选项。 ARP 请求的频率接近每秒一次，这是 [<a href="#RFC1122">RFC1122</a>] 建议的最大值。 Windows 系统中（没有给出图示）的测试显示出不同的行为。不是 3 个请求之间各间隔 1 秒，而是根据使用的应用程序或其他协议改变间隔。对于 ICMP 和 UDP （分别见第 8 章和第 10 章），使用的间隔约为 5 秒，而 TCP 使用的间隔为 10 秒。对于 TCP，在 TCP 放弃尝试建立一条连接之前， 10 秒间隔足以发送 2 个无须应答的 ARP 请求。</p>
<hr>
<h2 id="46-arp-缓存超时">4.6 ARP 缓存超时</h2>
<p>超时通常与 ARP 缓存中的每个条目相关（我们在后面将会看到， arp 命令允许管理员设置缓存条目永远不超时）。在大多数实现中，完整条目的超时为 20 分钟，而不完整条目的超时为 3 分钟（我们在前面的例子中看到一个不完整条目，它强迫执行一次到不存在主机的 ARP 请求）。这些实现通常在每次使用一个条目后为它重新启动 20 分钟的超时。 [<a href="#RFC1122">RFC1122</a>] 是描述主机需求的 RFC，它规定每个条目即使在使用也应启动超时，但很多实现并不这样做，它们在每次使用条目后重新启动超时。</p>
<p>注意，这是关于<strong>软状态</strong>的一个重要例子。软状态是指在超时到达前没有更新而被丢弃的信息。如果网络条件发生玫变，软状态有助于启动自动重新配置，因此很多 Internet 协议使用软状态。软状态的成本是协议必须刷新状态以避免过期。在一些协议设计中，经常包括“软状态刷新”，以保持软状态的活跃。</p>
<hr>
<h2 id="47-代理-arp">4.7 代理 ARP</h2>
<p><strong>代理 ARP</strong> [<a href="#RFC1027">RFC1027</a>] 使一个系统（通常是一台专门配置的路由器）可回答不同主机的 ARP 请求。它使 ARP 请求的发送者认为做出响应的系统就是目的主机，但实际上目的主机可能在其他地方（或不存在）。ARP 代理并不场景，通常应尽量避免使用它。</p>
<p>代理 ARP 也被成为 <strong>混杂 ARP</strong> 或 <strong>ARP 黑客</strong>。这些名称来自 ARP 代理的历史用途：两个物理网络相互隐蔽自己。在这种情况下，两个物理网络可使用相同的 IP 前缀，只要将中间的路由器配置为一个代理 ARP，在一个网络中由代理响应对其他网络中主机的 ARP 请求。这种技术可用于向一组主机隐藏另一组主机。从前，这样做有两个常见原因：有些系统无法进行子网划分，有些系统使用比较旧的广播地址（全 0 的主机 ID，而不是当前全 1 的主机 ID）。</p>
<p>Linux 支持一种称为<strong>自动代理 ARP</strong> 的功能。它可通过在文件 <code>/proc/sys/net/ipv4/confys/proxy_aap</code> 中写入字符 1，或使用 sysctl 命令来启用。它支持使用代理 ARP 功能，而不必为被代理的每个可能的 IPv4 地址手工输入 ARP 条目。这样做允许自动代理一个地址范围，而不是单个地址。</p>
<hr>
<h2 id="48-免费-arp-和地址冲突检测">4.8 免费 ARP 和地址冲突检测</h2>
<p>ARP 的另一个功能被称为<strong>免费 ARP</strong>。它发生在一台主机发送 ARP 请求以寻找自己的地址时。它通常出现在启动时，当接口被配置为“上行”时常这样做。下面是一个例子，在一台 Linux 机器上跟踪显示 Windows 主机的启动：</p>
<pre><code>Linux# tcpdump -e -n arp
1        0.0    0:0:c0:6f:2d:40    ff:ff:ff:ff:ff:ff    arp    60:
        arp who-has 10.0.0.56    tell    10.0.0.56
</code></pre>
<p>（我们为 tcpdump 增加 -n 标志，以打印数字化的点分十进制地址而不是主机名。）就 ARP 请求字段而言，发送方协议地址和目的协议地址相同：<code>10.0.0.56</code>。另外，以太网头部中的源地址字段被 tcpdump 显示为 <code>0:0:c0:6f:2d:40</code>，它等于发送方硬件地址。免费 ARP 需要达到两个目标：</p>
<ol>
<li>允许一台主机确定另一台主机是否配置相同的 IPv4 地址。发送免费 ARP 的主机并不期望它的请求获得应答。但是，如果它接收到一个应答，通常显示的是错误消息“从以太网地址......发送的重复 IP 地址”。这是对系统管理员和用户的警告，在同一广播域（例如局域网或 VLAN）中有一个系统配置出错。</li>
<li>如果发送免费 ARP 的主机已改变硬件地址（关闭主机或替换接口卡，然后重新启动主机），该帧导致任何接收广播并且其缓存中有该条目的其他主机，将该条目中的旧硬件地址更新为与该帧一致。如前面所述，如果一台主机接收到一个 ARP 请求，该请求来自一个已存在接收方缓存中的 IPv4 地址，则缓存条目更新为 ARP 请求中发送方的硬件地址。这由接收到 ARP 请求的主机完成，免费 ARP 正好利用这个特性。</li>
</ol>
<p>虽然免费 ARP 提供的一些迹象显示，多个站可尝试使用相同 IPv4 地址，但它实际上没有对这种情况提供解决机制（除了显示一个消息，实际由系统管理员完成）。为了解决这个问题， [<a href="#RFC5227">RFC5227</a>] 描述了 <strong>IPv4 地址冲突检测（ACD）</strong>。 ACD 定义了 <strong>ARP 探测</strong>分组和 <strong>ARP 通告</strong>分组。ARP 探测分组是一个 ARP 请求分组，其中<strong>发送方协议（IPv4）地址</strong>字段被设置为 0。探测分组用于查看一个候选 IPv4 地址是否被广播域中的任何其他系统所使用。通过将<strong>发送方协议地址</strong>字段设置为 0，避免候选 IPv4 地址被另一台主机使用时的缓存污染，这是它与免费 ARP 工作方式的一个差别。ARP 通告与 ARP 探测相同，除了其<strong>发送方协议地址</strong>和<strong>目的协议地址</strong>字段被填充为候选 IPv4 地址外。它用于通告发送方使用侯选 IPv4 地址的意图。</p>
<p>为了执行 ACD，当一个接口被启用或从睡眠中唤醒，或一个新链路建立（例如，当一个新的无线网络关联建立）时，这台主机发送一个 ARP 探测分组。在发送 3 个探测分组之前，首先需要等待一个随机时间（范围为 0 ~ 1 秒，均匀分布）。当多个系统同时启用时，通过延迟来避免启用带来的拥塞，否则都立即执行 ACD，这将导致网络流量激增。探测分组之间存在一个随机的时间间距，大约 1 ~ 2 秒的延迟（均匀分布）。</p>
<p>当请求站发送探测的探测时，它可能接收到 ARP 请求或应答。对其探测的应答表明其他站已使用候选 IP 地址。从不同系统发送的请求，其<strong>目的协议地址</strong>字段中包含相同的候选 IPv4 地址，表明其他系统也在同时尝试获得候选 IPv4 地址。在这两种情况下，该系统将会显示一个地址冲突消息，并采用其他可选地址。例如，当使用 DHCP （见第 6 章）分配地址时，这是推荐的行为。 [<a href="#RFC5227">RFC5227</a>] 对尝试获得地址设置了 10 次的冲突限制，在请求的主机进入限速阶段之前，它被允许每 60 秒执行一次 ACD，直至成功。</p>
<p>根据前面所描述的过程，如果发送请求的主机没有发现冲突，它会间隔 2 秒向广播域中发送 2 个 ARP 通告，以表明它现在使用这个 IPv4 地址。在这个通告中，<strong>发送方协议地址</strong>和<strong>目的协议地址</strong>字段被设置为其声称的地址。发送这些通告的目的是确保更新缓存地址映射，以正确反映发送方当前使用的地址。</p>
<p>ACD 被认为是一个持续的过程，这是它与免费 ARP 的区别。当一台主机通告它正使用的地址后，它会继续检查输入的 ARP 流量（请求和应答），查看自己的地址是否出现在<strong>发送方协议地址</strong>字段中。如果是的话，说明其他系统与自己在使用相同的地址。在这种情况下，[<a href="#RFC5227">RFC5227</a>] 提供了 3 种可能的解决方案：停止使用这个地址；保留这个地址，但发送一个“防御性” ARP 通告，如果冲突继续，则停止使用它；不理会冲突，仍继续使用。对于最后一个选择，仅建议那些真正需要一个固定、稳定地址的系统（例如打印机或路由器等嵌入式设备）使用。</p>
<p>[<a href="#RFC5227">RFC5227</a>] 还说明了使用链路层广播发送 ARP 应答的潜在好处。虽然这不是传统的 ARP 工作方式，但同一网段中所有站需处理 ARP 流量时，这样做可带来一些好处。广播应答可以更快地执行 ACD，这是由于所有站都会注意到这个应答，并在发现冲突时使自己的缓存无效。</p>
<hr>
<h2 id="49-arp-命令">4.9 arp 命令</h2>
<p>在 Windows 和 Linux 中，我们使用带有 -a 标志的 arp 命令显示 ARP 缓存中的所有条目（在 Linux 上，我们可不使用 -a 而获得类似信息）。超级用户或管理员可指定 -d 选项来删除 ARP 缓存中的条目（这在运行一些例子前用于强制执行一次 ARP 交换。）</p>
<p>我们也可以使用 -s 选项增加条目。它需要一个 IPv4 地址（或使用 DNS 从 IPv4 地址转换的主机名）和一个以太网地址。这个 IPv4 地址和以太网地址作为一个条目被添加在缓存中。这个条目是半永久性的（即它在缓存中不会超时，但在系统重启时消失）。</p>
<p>Linux 版本的 arp 比 Windows 版本提供更多功能。当在命令行结尾使用关键字 temp，并使用 -s 增加一个条目时，这个条目被认为是临时的，并与其他 ARP 条目一样会超时。当在命令行结尾使用关键字 pub 并使用 -s 时，系统对该条目做出 ARP 应答。系统对 ARP 请求的 IPv4 地址以相应的以太网地址来应答。如果通告地址是系统自己的地址之一，该系统可作为一个指定 IPv4 地址的代理 ARP （见 4.7 节）。如果 arp -s 用于启用代理 ARP， Linux 对指定地址做出应答，在 <code>/proc/sys/net/ipv4/conf/*/proxy_arp</code> 文件中写人 0。</p>
<hr>
<h2 id="410-使用-arp-设置一台嵌入式设备的-ipv4-地址">4.10 使用 ARP 设置一台嵌入式设备的 IPv4 地址</h2>
<p>随着越来越多的嵌入式设备与以太网、 TCP/IP 协议兼容，那些无法直接输入网络配置信息的联网设备越来越普遍（例如，它们没有键盘，难以输入自已使用的 IP 地址）。这些设备通常采用以下两种方式之一配置：一种是使用 DHCP 自动分配地址和其他信息（见第 6 章）；另一种是使用 ARP 设置 IPv4 地址，虽然这种方法并不常见。</p>
<p>通过 ARP 为嵌入式设备配置 IPv4 地址不是协议的初衷，这是由于它不是完全自动的。它的基本思路是为设备手动建立一个 ARP 映射（使用 arp -s 命令），然后向这个地址发送一个 IP 分组。由于相应 ARP 条目已存在，因此不会产生 ARP 请求/应答。相反，硬件地址可以立即使用。当然，设备的以太网（MAC）地址必须已知。它通常印在设备上，有时兼作制造商的设备序列号。当设备接收到一个目标为自身硬件地址的分组时，这个数据报包含的目的地址用于指定其初始 IPv4 地址。此后，这台设备可用其他方式（例如通过一个嵌入式 Web 服务器）完成配置。</p>
<hr>
<h2 id="411-与-arp-相关的攻击">4.11 与 ARP 相关的攻击</h2>
<p>目前已有一系列涉及 ARP 的攻击。最直接的是使用代理 ARP 功能假扮主机，对 ARP 请求做出应答。如果受害主机不存在，这很直观，而且可能难以发现。如果该主机仍在运行，这被认为更困难，因为每个 ARP 请求可能有多个应答，这样比较容易发现。</p>
<p>一种更巧妙的攻击可被 ARP 触发，它涉及一台主机被连接到多个网络，并且一个接口的 ARP 条目被其他 ARP 表“遗漏”的情况，这是由 ARP 软件的一个错误造成的。利用这种漏洞可将流量引导到错误网段上。 Linux 提供了一个直接影响该行为的方式，可通过修改文件 <code>/proc/sys/net/ipv4/conf/*/arp_filter</code> 实现。如果将数值 1 写入这个文件，当输入的 ARP 请求到达一个接口时，就进行一次 IP 转发检查。这时需要查找请求者的 IP 地址，以确定哪个接口将用于发送返回的 IP 数据报。如果到达的 ARP 请求与返回发送方的 IP 数据报使用不同的接口，这个 ARP 应答被抑制（触发它的 ARP 请求被丢弃）。</p>
<p>更具破坏性的 ARP 攻击涉及静态条目处理。如前所述，当查找对应一个特定 IP 地址的以太网（MAC）地址时，静态条目可用于避免 ARP 请求/应答。这种条目已被用于尝试增强安全性。它的思路是在 ARP 缓存中对重要主机使用静态条目，以快速检测任何针对该 IP 地址的主机欺骗。不幸的是，大多数 ARP 实现通常用 ARP 应答提供的条目代替静态缓存条目。这样的后果是，接收到 ARP 应答（即使它没发送 ARP 请求）的主机被欺骗，并使用攻击者提供的条目代替自己的静态条目。</p>
<hr>
<h2 id="412-总结">4.12 总结</h2>
<p>ARP 是 TCP/IP 实现中的一个基本协议，但它通常在应用程序或用户没有察觉的情况下运行。 ARP 用于确定本地可达的 IPv4 子网使用的 IPv4 地址对应的硬件地址。它在数据报的目的地与发送方处于同一子网时使用，还用于数据报的目的地不在当前子网（在第 5 章详细说明）时将其转发到一台路由器。 ARP 缓存是其运行的基础，我们可使用 arp 命令查看和处理缓存。缓存中每个条目都有一个计时器，用于清除不完整的条目和完整的条目。 arp 命令可显示和修改 ARP 缓存中的条目。</p>
<p>我们深入了解特殊 ARP 的正常运行：代理 ARP （一台路由器回答主机通过另一台路由器接口访问的 ARP 请求）和免费 ARP （发送自己拥有的 IP 地址的 ARP 请求，通常用于引导）。我们还讨论了 IPv4 地址冲突检测，采用一种持续运行的类似免费 ARP 的交换，来避免在同一广播域中地址重复。最后，我们讨论了一系列涉及 ARP 的攻击。如果高层协议没有强大的安全措施，这可能会导致高层协议出现问题（见第 18 章）。</p>
<hr>
<h2 id="413-参考文献">4.13 参考文献</h2>
<p><span id="RFCO826">[RFCO826]</span> D. Plummer, &quot;Ethernet Address Resolution Protocol: Or Converting Network Protocol Addresses to 48.bit Ethernet Address for Transmission on Ethernet Hardware,&quot; Internet RFC 0826/STD 0037, Nov.1982.</p>
<p><span id="RFCO903">[RFCO903]</span>R. Finlayson, T. Mann,J. C. Mogul, and M. Theimer, &quot;A Reverse Address Resolution Protocol,&quot; Internet RFC 0903/STD 0038,June 1984.</p>
<p><span id="RFC1027">[RFC1027]</span> S. Carl-Mitchell and J. S. Quarterman, &quot;Using ARP to Implement Transparent Subnet Gateways,&quot; Internet RFC 1027,Oct. 1987.</p>
<p><span id="RFC1122">[RFC1122]</span>R. Braden, ed., &quot;Requirements for Internet Hosts,&quot; Internet RFC 1122/STD 0003,Oct. 1989.</p>
<p><span id="RFC2332">[RFC2332]</span> J. Luciani, D. Katz, D. Piscitello, B. Cole, and N. Doraswamy, &quot;NBMA Next Hop Resolution Protocol (NHRP),&quot; Internet RFC 2332,Apr. 1998.</p>
<p><span id="RFC5227">[RFC5227]</span> S. Cheshire, &quot;IPv4 Address Conflict Detection,&quot; Internet RFC 5227, July. 1998.</p>
<p><span id="RFC5494">[RFC5494]</span> J.Arkko and C. Pignataro, &quot;IANA Allocation Guidelines for the Address Resolution Protocol(ARP)&quot; Internet RFC 5494,Apr. 2009.</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[《TCP/IP 详解 卷一：协议》第三章：链路层]]></title>
        <id>https://wenbozhangw.github.io/post/lesslesstcpip-xiang-jie-juan-yi-xie-yi-greatergreater-di-san-zhang-lian-lu-ceng/</id>
        <link href="https://wenbozhangw.github.io/post/lesslesstcpip-xiang-jie-juan-yi-xie-yi-greatergreater-di-san-zhang-lian-lu-ceng/">
        </link>
        <updated>2022-04-28T03:10:17.000Z</updated>
        <content type="html"><![CDATA[<h2 id="31-引言">3.1 引言</h2>
<p>在第 1 章中，我们知道 TCP/IP 协议族中设计链路层的目的是为 IP 模块发送和接收 IP 数据报。它可用于携带一些支持 IP 的辅助性协议，例如 ARP （见第 4 章）。 TCP/IP 支持多种不同的链路层，它依赖于使用的网络硬件类型：有线局域网，例如以太网；<strong>城域网（MAN）</strong>，例如服务供应商提供的有线电视和 DSL 连接；有线语音网络，例如支持调制解调器的电话线；无线网络，例如Wi-Fi （无线局域网）；基于蜂窝技术的各种无线数据服务，例如 HSPA、EV-DO、LTE 和 WiMAX。在本章中，我们将详细讨论以下内容：在以太网和 Wi-Fi 的链路层中，如何使用<strong>点到点协议（PPP）</strong>，如何在其他（链路或更高层）协议中携带链路层协议，以及一种称为隧道的技术等。详细描述当前使用的每种链路技术需要专门一本书才行，因此我们将注意力集中在一些常用的链路层协议，以及 TCP/IP 中如何使用它们。</p>
<p>大多数链路层技术都有一个相关的协议，描述由网络硬件传输的相应 PDU 格式。在描述链路层的 PDU 时，我们通常使用术语<strong>帧</strong>，以区分那些更高层的 PDU 格式，例如描述网络层和传输层 PDU 的分组和段。帧格式通常支持可变的帧长度，范围从几字节到几千字节。这个范围的上限称为<strong>最大传输单元（MTU）</strong>，我们将在后续章节中提到链路层的这一特点。有些网络技术（例如调制解调器和串行线路）不强制规定最大的帧，因此它们可以由用户来配置。</p>
<h2 id="32-以太网和-ieee-802-局域网城域网标准">3.2 以太网和 IEEE 802 局域网/城域网标准</h2>
<p><strong>以太网</strong>这个术语通常指一套标准，由 DEC、 Intel 公司和 Xerox 公司在 1980 年首次发布，并在 1982 年加以修订。第一个常见格式的以太网，目前被称为“10Mb/s 以太网”或“共享以<br>
太网”，它被 IEEE 采纳（轻微修改）为 802.3 标准。这种网络的结构通常如图 3-1 所示。</p>
<figure data-type="image" tabindex="1"><img src="https://wenbozhangw.github.io//post-images/1651118328245.png" alt="图 3-1" loading="lazy"></figure>
<p>图 3-1   基本的共享以太网包含一个或多个站（例如工作站、超级计算机），它们都被连接到一个共享的电缆段上。当介质被确定为空闲状态时，链路层的 PDU（帧）可以从一个站发送到一个或更多其他站。如果多个站同时发送数据，可能因信号传播延迟而发生碰撞。碰撞可以被检测到，它会导致发送站等待一个随机事件，然后重新发送数据。这种常见的方法称为带冲突检测的载波侦听多路访问</p>
<p>由于多个站共享同一网络，该标准需要在每个以太网接口实现一种分布式算法，以控制一个站发送自己的数据。这种特定方法称为<strong>带冲突（或称碰撞）检测的载波侦听多路访问（CSMA/CD）</strong>，它协调哪些计算机可访问共享的介质（电缆），同时不需要其他特殊协议或同步。这种相对简单的方法有助于降低成本和促进以太网投术普及。</p>
<p>采用 CSMA/CD，一个站（例如计算机）首先检测目前网络上正在发送的信号，并在网络空闲时发送自己的帧。这是协议中的“载波侦听”部分。如果其他站碰巧同时发送，发生重叠的电信号被检测为一次碰撞。在这种情况下，每个站等待一个随机时间，然后再次尝试发送。这个时间量的选择依据一个统一的概率分布，随后每个碰撞被检测到的时间长度加倍。最终，每个站会得到机会发送，或者在尝试一定次数（传统以太网为 16）后超时。采用 CSMA/CD，在任何给定的时间内，网络中只能有一个帧传输。如 CSMA/CD 这样的访问方法更正式的名称为<strong>介质访问控制(MAC)协议</strong>。 MAC 协议有很多类型，有些基于每个站尝试独立使用网络（例如 CSMA/CD 的基于竞争的协议），有些基于预先安排的协调（例如依据为每个站分配的时段发送） 。</p>
<p>随着 10Mb/s 以太网的发展，更快的计算机和基础设施使得局域网速度不断提升。由于以太网的普及，已取得以下显著创新和成果：其速度从 10Mb/s 增加到 100Mb/s、 1000Mb/s、10Gb/s，现在甚至更高。 10Gb/s 技术在大型数据中心和大型企业中越来越普遍，并且已被证实可达到 100Gb/s 的速度。最早（研究）的以太网速度为 3Mb/s，但 DIX （Digital、 Intel、 Xerox）标准可达到 10Mb/s，它在一条共享的物理电缆或由电子中继器互联的一组电缆上运行。 20 世纪 90 年代初，共享的电缆已在很大程度上被双绞线（类似电话线，通常称为“10BASE-T”）代替。随着 100Mb/s （也称为“快速以太网”，最流行的版本是“100BASE-TX”）的发展，基于竞争的 MAC 协议已变得不流行。相反，局域网中每个站之间的线路通常不共享，而是提供了一个专用的星形拓扑结构。这可以通过以太网<strong>交换机</strong>来实现，如图 3-2 所示</p>
<figure data-type="image" tabindex="2"><img src="https://wenbozhangw.github.io//post-images/1651120249525.png" alt="图 3-2" loading="lazy"></figure>
<p>图 3-2   一个交换式以太网包含一个或多个站，每个站使用一条专用的线路连接到一个交换机端口。在大多数情况下，交换式以太网以全双工方式运行，并且不需要使用 CSMA/CD 算法。交换机可以通过交换机端口级联形成更大的以太网，该端口有时也称为“上行”端口</p>
<p>目前，交换机为以太网中的每个站提供同时发送和接收数据的能力（称为“全双工以太网”）。虽然 1000Mb/s 以太网（1000BASE-T）仍支持半双工（一次一个方向）操作，但相对于全双工以太网来说，它很少使用。下面我们将详细讨论交换机如何处理 PDU。</p>
<p>当前连接 Internet 的最流行技术之一是无线网络，常见的无线局域网（WLAN） IEEE 标准称为无线保真或 Wi-Fi，有时也称为“无线以太网”或 802.11。虽然这个标准与 802 有线以太网标准不同，但帧格式和通用接口大部分来自 802.3，并且都是 IEEE 802 局域网标准的一部分。因此， TCP/IP 用于以太网的大部分功能，也可用于 Wi-Fi 网络。我们将详细探讨这些功能。首先，我们描绘一个建立家庭和企业网络的所有 IEEE 802 标准的蓝图。这里也包括那些涉及城域网的 IEEE 标准，例如 IEEE 802.16（WiMAX）和蜂窝网络中的异构网络无缝切换标准（IEEE 802.21）。</p>
<h3 id="321-ieee-802-局域网城域网标准">3.2.1 IEEE 802 局域网/城域网标准</h3>
<p>原始的以太网帧格式和工作过程由前面提到的行业协议所描述。这种格式被称为 DIX 格式或 Ethernet II 格式。对这种类型的以太网稍加修改后，由 IEEE 标准化为一种 CSMA/CD 网络，称为 802.3。在 IEEE 标准中，带 802 前缀的标准定义了局域网和城域网的工作过程。当前最流行的 802 标准包括 802.3 （以太网）和 802.11（WLAN/Wi-Fi）。这些标准随着时间推移而演变，经过独立修订后名称发生改变（例如 802.11g），并最终被纳入修订过的标准。表 3-1 显示了一个相当完整的列表，包括截至 2011 年年中支持 TCP/IP 的相关 IEEE 802 局域网和城域网标准。</p>
<center>表 3-1   有关 TCP/IP 协议的局域网和城域网 IEEE 802 标准（2011）</center>
<table>
<thead>
<tr>
<th>名称</th>
<th>描述</th>
<th>官方参考</th>
</tr>
</thead>
<tbody>
<tr>
<td>802.1ak</td>
<td>多注册协议（MRP）</td>
<td>[<a href="#802.1AK-2007">802.1AK-2007</a>]</td>
</tr>
<tr>
<td>802.1AE</td>
<td>MAC 安全（MACSec）</td>
<td>[<a href="#802.AE-2006">802.AE-2006</a>]</td>
</tr>
<tr>
<td>802.1AX</td>
<td>链路聚合（以前的 802.3ad）</td>
<td>[<a href="#802.AX-2008">802.AX-2008</a>]</td>
</tr>
<tr>
<td>802.1d</td>
<td>MAC 网桥</td>
<td>[<a href="#802.1D-2004">802.1D-2004</a>]</td>
</tr>
<tr>
<td>802.1p</td>
<td>流量类/优先级/QoS</td>
<td>[<a href="#802.1D-2004">802.1D-2004</a>]</td>
</tr>
<tr>
<td>802.1q</td>
<td>虚拟往前的局域网/MRP的更正</td>
<td>[<a href="#802.1Q-2005/Corl-2008">802.1Q-2005/Corl-2008</a>]</td>
</tr>
<tr>
<td>802.1s</td>
<td>多生成树协议（MSTP）</td>
<td>[<a href="#802.1Q-2005">802.1Q-2005</a>]</td>
</tr>
<tr>
<td>802.1w</td>
<td>快速生成树协议（RSTP）</td>
<td>[<a href="#802.1D-2004">802.1D-2004</a>]</td>
</tr>
<tr>
<td>802.1X</td>
<td>基于端口的网络控制访问（PNAC）</td>
<td>[<a href="#802.1X-2010">802.1X-2010</a>]</td>
</tr>
<tr>
<td>802.2</td>
<td>逻辑链路控制（LLC）</td>
<td>[<a href="#802.2-1998">802.2-1998</a>]</td>
</tr>
<tr>
<td>802.3</td>
<td>基本以太网和 10 Mb/s 以太网</td>
<td>[<a href="#802.3-2008">802.3-2008</a>] （第 1 节）</td>
</tr>
<tr>
<td>802.3u</td>
<td>100 Mb/s 以太网（“快速以太网”）</td>
<td>[<a href="#802.3-2008">802.3-2008</a>] （第 2 节）</td>
</tr>
<tr>
<td>802.3x</td>
<td>全双工运行和流量控制</td>
<td>[<a href="#802.3-2008">802.3-2008</a>]</td>
</tr>
<tr>
<td>802.3z/802.3ab</td>
<td>1000 Mb/s 以太网（“千兆以太网”）</td>
<td>[<a href="#802.3-2008">802.3-2008</a>] （第 3 节）</td>
</tr>
<tr>
<td>802.3ae</td>
<td>10 Gb/s 以太网</td>
<td>[<a href="#802.3-2008">802.3-2008</a>] （第 4 节）</td>
</tr>
<tr>
<td>802.3ad</td>
<td>链路聚合</td>
<td>[<a href="#802.1AX-2008">802.1AX-2008</a>]</td>
</tr>
<tr>
<td>802.3af</td>
<td>以太网供电（PoE，15.4W）</td>
<td>[<a href="#802.3-2008">802.3-2008</a>] （第2 节）</td>
</tr>
<tr>
<td>802.3ah</td>
<td>以太网接入（第一公里以太网）</td>
<td>[<a href="#802.3-2008">802.3-2008</a>] （第 5 节）</td>
</tr>
<tr>
<td>802.3as</td>
<td>帧格式扩展（2000 字节）</td>
<td>[<a href="#802.3-2008">802.3-2008</a>]</td>
</tr>
<tr>
<td>802.3at</td>
<td>以太网供电增强（“PoE+”，30W）</td>
<td>[<a href="#802.3at-2009">802.3at-2009</a>]</td>
</tr>
<tr>
<td>802.3ba</td>
<td>40/100Gb/s 以太网</td>
<td>[<a href="#802.3ba-2010">802.3ba-2010</a>]</td>
</tr>
<tr>
<td>802.11a</td>
<td>运行在 5GHz 的 54Mb/s 的无线局域网</td>
<td>[<a href="#802.11-2007">802.11-2007</a>]</td>
</tr>
<tr>
<td>802.11b</td>
<td>运行在 2.4GHz 的 11Mb/s 的无线局域网</td>
<td>[<a href="#802.11-2007">802.11-2007</a>]</td>
</tr>
<tr>
<td>802.11e</td>
<td>针对 802.11 的 QoS 增强</td>
<td>[<a href="#802.11-2007">802.11-2007</a>]</td>
</tr>
<tr>
<td>802.11g</td>
<td>运行在 2.4GHz 的 54Mb/s 的无线局域网</td>
<td>[<a href="#802.11-2007">802.11-2007</a>]</td>
</tr>
<tr>
<td>802.11h</td>
<td>频谱/电源管理扩展</td>
<td>[<a href="#802.11-2007">802.11-2007</a>]</td>
</tr>
<tr>
<td>802.11i</td>
<td>安全增强/代替 WEP</td>
<td>[<a href="#802.11-2007">802.11-2007</a>]</td>
</tr>
<tr>
<td>802.11j</td>
<td>运行在 4.9 ~ 5.0GHz（日本）</td>
<td>[<a href="#802.11-2007">802.11-2007</a>]</td>
</tr>
<tr>
<td>802.11n</td>
<td>预先在 2.4GHz 和 5GHz 的 6.5 ~ 600Mb/s 的无线局域网，<br/>使用可选的 MIMO 和 40MHz 管道</td>
<td>[<a href="#802.11n-2009">802.11n-2009</a>]</td>
</tr>
<tr>
<td>802.11s（草案）</td>
<td>网状网，拥塞控制</td>
<td>开发中</td>
</tr>
<tr>
<td>802.11y</td>
<td>运行在 3.7GHz 的 54Mb/s 的无线局域网（许可的）</td>
<td>[<a href="#802.11y-2008">802.11y-2008</a>]</td>
</tr>
<tr>
<td>802.16</td>
<td>微波存取全球互通技术（WiMAX）</td>
<td>[<a href="#802.16-2009">802.16-2009</a>]</td>
</tr>
<tr>
<td>802.16d</td>
<td>固定的无线城域网标准（WiMAX）</td>
<td>[<a href="#802.16-2009">802.16-2009</a>]</td>
</tr>
<tr>
<td>802.16e</td>
<td>固定/移动的无限城域网标准（WiMAX）</td>
<td>[<a href="#802.16-2009">802.16-2009</a>]</td>
</tr>
<tr>
<td>802.16h</td>
<td>改进的共存机制</td>
<td>[<a href="#802.16h-2010">802.16h-2010</a>]</td>
</tr>
<tr>
<td>802.16j</td>
<td>802.16 中的多跳中继</td>
<td>[<a href="#802.16j-2009">802.16j-2009</a>]</td>
</tr>
<tr>
<td>802.16k</td>
<td>802.16 网桥</td>
<td>[<a href="#802.16k-2007">802.16k-2007</a>]</td>
</tr>
<tr>
<td>802.21</td>
<td>介质无关切换</td>
<td>[<a href="#802.21-2008">802.21-2008</a>]</td>
</tr>
</tbody>
</table>
<p>除了 802.3、 802.11、 802.16 标准定义的特定类型的局域网之外，还有一些相关标准适用于所有 IEEE 标准的局域网技术。最常见的是定义**逻辑链路控制（LLC）**的 802.2 标准，其帧头部在 802 网络的帧格式中常见。在 IEEE 的术语中， LLC 和 MAC 是链路层的“子层”，LLC （多数帧格式）对每种网络都是通用的，而 MAC 层可能有所不同。虽然最初的以太网使用 CSMA/CD，但无线局域网常使用  CSMA/CA （CA 是“冲突避免”）。</p>
<p>注意 不幸的是， 802.2 和 802.3 共同定义了与 Ethemet II 不同的帧格式，这个情况直到 802.3x 才最终纠正。它已经被纳入 [<a href="#802.3-2008">802.3-2008</a>] 。在 TCP/IP 世界中，[<a href="#RFC0894">RFC0894</a>] 和 [<a href="#RFC2464">RFC2464</a>] 定义了针对以太网的 IP 数据报封装，但旧的 LLC/SNAP 封装仍发布在 [<a href="#RFC1042">RFC1042</a>] 中。虽然这不再是一个大问题，但它曾经令人关注，并偶尔出现类似问题 [<a href="#RFC4840">RFC4840</a>]。</p>
<p>直到最近，帧格式在本质上还一直相同。为了获得该格式的详细信息，并了解它是如何演变的，我们现在将焦点转向这些细节。</p>
<h3 id="322-以太网帧格式">3.2.2 以太网帧格式</h3>
<p>所有的以太网（802.3）帧都基于一个共同的格式。在原有规范的基础上，帧格式已被改进以支持额外功能。图 3-3 显示了当前的以太网帧格式，以及它与 IEEE 提出的一个相对新的术语 IEEE 分组（一个在其他标准中经常使用的术语）的关系。</p>
<p>以太网帧开始是一个<strong>前导</strong>字段，接收器电路用它确定一个帧的到达时间，并确定编码位（称为<strong>时钟恢复</strong>）之间的时间量。由于以太网是一个异步的局域网（即每个以太网接口卡中不保持精确的时钟同步），从一个接口到另一个接口的编码位之间的间隔可能不同。前导是一个公认的模式（典型值为 <code>0xAA</code>），在发现**帧起始分隔符（SFD）**时，接收器使用它“恢复时钟”。 SFD 的固定值为 <code>0xAB</code>。</p>
<figure data-type="image" tabindex="3"><img src="https://wenbozhangw.github.io//post-images/1651207095547.png" alt="图 3-3" loading="lazy"></figure>
<p>图 3-3   以太网（IEEE802.3）帧格式包含一个源地址和目的地址、一个重载的<strong>长度/类型</strong>字段、一个数据字段和一个帧校验序列（CRC32）。另外，基本帧格式提供了一个标签，其中包含一个 VLAN ID 和优先级信息（802.1p/q），以及一个最近出现的可扩展标签。前导和 SFD 被用于接收器同步。当以太网以半双工模式运行在 100Mb/s 或以上速率时，其他位可能被作为载体扩展添加到短帧中，以确保冲突检测电路的正常运行</p>
<pre><code>注意  最初以太网的位编码使用两个电压等级的曼彻斯特相位编码（MPE）。通过 MPE，
每位被编码为电压变化，而不是绝对值。例如， 0 位被编码为从 -0.85V 到 +0.85V 的变化，
1 位被编码为从 +0.85V 到 -0.85V 的变化（0V 指共享线路处于空闲状态）。 10Mb/s 
以太网规范要求网络硬件使用 20MHz 振荡器，因为 MPE 的每位需要两个时钟周期。
字节 0xAA （二进制为10101010）在以太网的前导中，表示为一个 +0.85 和 -0.85V 之间
的 10MHz 频率的方波。在其他以太网标准中，曼彻斯特编码被替换为不同编码，以提高效率。
</code></pre>
<p>这个基本的帧格式包括 48 位（6 字节）的**目的地址（DST）<strong>和</strong>源地址（SRC）**字段。这些地址有时也采用其他名称，例如“MAC地址”、“链路层地址”、“802 地址”、“硬件地址”或“物理地址”。以太网帧的目的地址也允许寻址到多个站点（称为“广播”或“组播”，见第 9 章）。广播功能用于 ARP 协议（见第 4 章），组播功能用于 ICMPv6 协议（见第 8 章），以实现网络层地址和链路层地址之间的转换。</p>
<p>源地址后面紧跟着一个<strong>类型</strong>字段，或一个<strong>长度</strong>字段。在多数情况下，它用于确定头部后面的数据类型。 TCP/IP 网络使用的常见值包括IPv4 （<code>0x0800</code>）、 IPv6 （<code>0x86DD</code>）和 ARP （<code>0x0806</code>）。 <code>0x8100</code> 表示一个 Q 标签帧（可携带一个“虚拟局域网”或 802.1q 标准的 VLAN ID）。一个以太网帧的基本大小是 1518 字节，但最近的标准将该值扩大到 2000 字节。</p>
<pre><code>注意   最初的 IEEE （802.3）规范将长度/类型字段作为长度字段而不是类型字段使用。
因此，这个字段被重载（可用于多个目的）。关键是看字段值。目前，如果字段值大于
或等于 1536，则该字段表示类型，它是由标准分配的超过 1536 的值。如果字段值等于
或小于 1500，则该字段表示长度。 [ETHERTYPES] 给出了类型的完整列表。
</code></pre>
<p>在上述字段之后， [<a href="#802.3-2008">802.3-2008</a>] 提供了多种标签包含由其他 IEEE 标准定义的各种协议字段。其中，最常见的是那些由 802.1p 和 802.1q 使用的标签，它提供虚拟局域网和一些 **服务质量（Qos）**指示符。这些在 3.2.3 节讨论。</p>
<pre><code>注意   当前的 [802.3-2008] 标准采用修改后的 802.3 帧格式，提供最大为 482 字节的
“标签”，它携带在每个以太网帧中。这些较大的帧称为信封帧，长度最大可能达到
2000 字节。包含 802.1p/q 标签的帧称为 Q 标签帧，也是信封帧。但是，并非所有
信封帧必然是 Q 标签帧。
</code></pre>
<p>在这些讨论过的字段之后，是帧的数据区或<strong>有效载荷</strong>部分。这里是放高层 PDU （例如IP数据报）的地方。传统上，以太网的有效载荷一直是 1500 字节，它代表以太网的 MTU。 目前，大多数系统为以太网使用 1500 字节的 MTU，虽然在必要时它也可设置为一个较小的值。有效载荷有时被<strong>填充</strong>（添加）数个 0，以确保帧总体长度符合最小长度要求，这些我们将在 3.2.2.2 节讨论。</p>
<h4 id="3221-帧校验序列循环冗余校验">3.2.2.1 帧校验序列/循环冗余校验</h4>
<p>在以太网帧格式中，有效载荷区域之后的最后字段提供了对帧完整性的检查。<strong>循环冗余校验（CRC）<strong>字段位于尾部，有 32 位，有时称之为 IEEE/ANSI 标准的 CRC32 [<a href="#802.3-2008">802.3-2008</a>]。要使用一个 n 位 CRC 检测数据传输错误，被检查的消息首先需要追加 n 位 0 形成一个</strong>扩展消息</strong>。然后，扩展消息（使用模 2 除法）除以一个（n + 1）位的值，这个作为除数的值称为<strong>生成多项式</strong>。放置在消息的 CRC 字段中的值是这次除法计算中余数的二进制反码（商被丢弃）。生成多项式已被标准化为一系列不同的 n 值。以太网使用 <code>n=32</code>， CRC32 的生成多项式是 33 位的二进制数<code>100000100110000010001110110110111</code>。为了理解如何使用（mod 2）二进制除法计算<br>
余数，我们看一个 CRC4 的简单例子。国际电信联盟（ITU）将 CRC4 的生成多项式值标准化为<code>10011</code>，这是在 G.704 [<a href="#G704">G704</a>] 标准中规定的。如果我们要发送 16 位的消息<br>
<code>1001111000101111</code>，首先开始进行图 3-4 所示的（mod2）二进制除法。</p>
<figure data-type="image" tabindex="4"><img src="https://wenbozhangw.github.io//post-images/1652281247055.png" alt="图 3-4" loading="lazy"></figure>
<p>图 3-4   长（mod2）二进制除法延时了 CRC4 的计算过程</p>
<p>在该图中，我们看到这个除法的余数是 4 位的值 <code>1111</code>。通常，该余数的反码（0000）将放置在帧的 CRC 或**帧校验序列（FCS）**字段中。在接收到数据之后，接收方执行相同的除法计算出余数，并判断该值与 FCS 字段的值是否匹配。如果两者不匹配，帧可能在传输过程中受损，通常被丢弃。 CRC 功能可用于提示信息受损，因为位模式的任何改变极可能导致余数的改变。</p>
<h4 id="3222-帧大小">3.2.2.2 帧大小</h4>
<p>以太网帧有最小和最大尺寸。最小的帧是 64 字节，要求数据区（有效载荷）长度（无标签）最小为 48 字节。当有效载荷较小时，填充字节（值为0）被添加到有效载荷尾部，以确保达到最小长度。</p>
<pre><code>注意   最小长度对最初的 10Mb/s 以太网的 CSMA/CD 很重要。为了使传输数据的
站能知道哪个帧发生了冲突，将一个以太网的最大长度限制为 2500m（通过4个
中继器连接的 5 个 500m 的电缆段）。根据电子在铜缆中传播速度约为 0.77c （约
2.31×108m/s），可得到 64 字节采用 10Mb/s 时的传输时间为 64×8/10000000=
51.2 μs，最小尺寸的帧能在电缆中传输约 11000m。如果采用一条最长为 2500m 
的电缆，从一个站到另一个站之间的最大往返距离为 5000m。以太网设计者确定最
小帧长度基于安全因素，在完全兼容（和很多不兼容）的情况下，一个输出帧的最
后位在所需时间后仍处于传输过程中，这个时间是信号到达位于最大距离的接收器
并返回的时间。如果这时检测到一个冲突，传输中的站能知道哪个帧发生冲突，即
当前正在传输中的那个帧。在这种情况下，该站发送一个干扰信号（高电压）提醒
其他站，然后启动一个随机的二进制指数退避过程。
</code></pre>
<p>传统以太网的最大帧长度是 1518 字节（包括 4 字节 CRC 和 14 字节头部）。选择这个值出于一种折中：如果一个帧中包括一个错误（接收到不正确的 CRC 校验），只需重发 1.5kB 以修复该问题。另一方面， MTU 大小限制为 1500 字节。为了发送一个更大的消息，则需要多个帧（例如，对于 TCP/IP 网络常用的较大尺寸 64KB，需要至少 44 个帧）。</p>
<p>由多个以太网帧构成一个更大的上层 PDU 的后果是，每个帧都贡献了一个固定开销（14 字节的头部和 4 字节的 CRC）。更糟的是，为了允许以太网硬件接收电路正确恢复来自网络的数据，并为其他站提供将自己的流量与已有流量区分开的机会，以太网帧在网络中不能无缝地压缩在一起。 Ethernet II 规范除了在帧开始处定义了 7 字节前导和 1 字节 SFD 之外，还指定了 12 字节的包间距（IPG）时间（10Mb/s 为9.6μs， 100Mb/s 为 960ns， 1000Mb/s 为 96ns， 10000Mb/s 为 9.6ns）。因此， Ethernet II 的每帧效率最多为 <code>1500/(12 + 8 + 14 + 1500 + 4)=0.975293</code>，约 98%。一种提高效率的方式是，在以太网中传输大量数据时，尽量使帧尺寸更大一些。这可采用以太网<strong>巨型帧</strong> [<a href="#JF">JF</a>] 来实现，它是一种非标准的以太网扩展（主要在 1000Mb/s 以太网交换机中使用），通常允许帧尺寸高达 9000 字节。有些环境使用的帧称为<strong>超级巨型帧</strong>，它们通常超过 9000 字节。在使用巨型帧时要谨慎，这些较大的帧无法与较小的 1518 字节的帧互操作，因为它们无法由大多数传统以太网设备处理。</p>
<h3 id="323-8021pq虚拟局域网和-qos-标签">3.2.3 802.1p/q：虚拟局域网和 QoS 标签</h3>
<p>随着交换式以太网的使用越来越多，位于同一以太网中的每台主机互连已成可能。这样做的好处是，任何主机都可直接与其他主机通信，它们使用 IP 和其他网络层协议，并很少或根本不需要管理员配置。另外，广播和组播流量（见第 9 章）被分发到所有希望接收的主机，而不必建立特殊的组播路由协议。虽然这是很多主机位于同一以太网的优势，但在很多主机使用广播时，广播到每台主机将带来大量网络流量，并出于某些安全因素可能要禁止任意站之间通信。</p>
<p>为了解决大型多用途交换网络运行中的问题， IEEE 采用一种称为**虚拟局域网（VLAN）**的功能扩展 802 LAN 标准，它被定义在 802.1q [<a href="#802.1Q-2005">802.1Q-2005</a>]标准中。兼容的以太网交换机将主机之间的流量分隔为常见的 VLAN。注意，正是由于这种分隔，连在同一交换机但在不同 VLAN 中的两台主机，它们之间的流量需要一台路由器来传递。已研发出交换机/路由器组合设备来满足这种需求，路由器性能最终得到改进以匹配 VLAN 交换性能。因此， VLAN 的吸引力已有所减弱，现代高性能路由器逐渐取代它们。尽管如此，它们仍在使用，在某些环境中仍受欢迎，因此有必要了解它们。</p>
<p>工作站到 VLAN 的映射有几种方法。通过端口分配 VLAN 是一种简单而常见的方法，交换机端口所连接的站被分配在一个特定 VLAN 中，这样连接的任意站就都成为 VLAN 中的成员。其他选择包括基于 MAC 地址的 VLAN，以太网交换机使用表将一个站的 MAC 地址映射到一个 VLAN。如果有些站改变它们的 MAC 地址（由于某些用户行为，有时需要这样做），它们可能变得难以管理。 IP 地址也可用作分配 VLAN 的基础。</p>
<p>当不同 VLAN 中的站连接在同一交换机时，交换机确保流量不在两个 VLAN 之间泄漏，无论这些站使用哪种类型的以太网接口。当多个 VLAN 跨越多个交换机（<strong>中继</strong>）时，在以太网帧发送到另一台交换机之前，需要使用 VLAN 来标记该帧的归属。本功能使用一个称为 <strong>VLAN标签</strong>（或头部）的标记，其中包含 12 位 <strong>VLAN 标识符</strong>（提供 4096 个 VLAN，但保留 VLAN 0 和 VLAN 4095）。它还包含支持 QoS 的 3 位优先级（定义在 802.1p 标准中），如图 3-3 所示。在很多情况下，管理员必须配置交换机端口，以便发送 802.1p/q 帧时能中继到适当的端口。为了使这项工作更加容易，有些交换机通过中继端口支持<strong>本地 VLAN</strong> 选项，这意味着未标记的帧默认与本地 VLAN 相关。中继端口用于互连带 VLAN 功能的交换机，其他端口通常用于直接连接工作站。有些交换机还支持专用的 VLAN 中继方法，例如思科 <strong>内部交换链路（ISL）</strong> 协议。</p>
<p>802.1p 规定了在帧中表示 QoS 标识符的机制。802.1p 头部包括一个 3 位优先级字段，它用于表明一个 QoS 级别。这个标准是 802.1q VLAN 标准的扩展。这两个标准可以一起工作，并在同一头部中共享某些位。它用 3 个有效位定义了 8 个服务级别。 0 级为最低优先级，用于传统的尽力而为的流量。 7 级为最高优先级，可用于关键路由或网管功能。这个标准规定了优先级如何被编码在分组中，但没指定如何控制哪些分组采用哪个级别，以及实现优先级服务的底层机制，这些可由具体的实现者来定义。因此，一个优先级流量相对于另一个的处理方式是由实现或供应商定义的。注意，如果 802.1p/q 头部中的 VLAN ID 字段被设置为 0， 802.1p 可以独立于 VLAN 使用。</p>
<p>控制 802.1p/q 信息的 Linux 命令是 <code>vconfig</code>。它可用来添加和删除虚拟接口，即与物理接口相关联的 VLAN ID。它也可用来设置 802.1p 优先级，更改虚拟接口确定方式，改变由特定 VLAN ID 标记的分组之间的映射，以及协议在操作系统中处理时如何划分优先级。下面的命令为 VLAN ID 为 2 的接口 eth1 添加、删除虚拟接口，修改虚拟接口的命名方式并添加新接口：</p>
<pre><code>Linux# vconfig add eth1 2
Added VLAN with VID == 2 to IF -:eth1:-
Linux# ifconfig eth1.2
ethl.2 Link encap:Ethernet HWaddr 00:04:5A:9F:9E:80
            BROADCAST MULTICAST MTU:1500 Metric:1
            RX packets:0 errors:0 dropped:0 overruns:0 frame:0
            TX packets:0 errors:0 dropped:0 overruns:0 carrier:O
            collisions:0 txqueuelen:0
            RX bytes:0 (0.0 b) TX bytes:0 (0.0 b)
Linux# vconfig rem eth1.2
Removed VLAN -:eth1.2:-
Linux# vconfig set_name_type VLAN_PLUS_VID
Set name-type for VLAN subsystem. Should be visible in
            /proc/net/vlan/config
Linux# vconfig add eth1 2
Added VLAN with VID == 2 to IF -:eth1:-
Linux# ifconfig vlan0002
vlan0002 Link encap:Ethernet HWaddr 00:04:5A:9F:9E:80
            BROADCAST MULTICAST MTU:1500 Metric:1
            RX packets:0 errors:0 dropped:0 overruns:0 frame:0
            TX packets:0 errors:0 dropped:0 overruns:0 carrier:O
            collisions:0 txqueuelen:0
            RX bytes:0 (0.0 b) TX bytes:0 (0.0 b)
</code></pre>
<p>这里，我们可以看到在 Linu x中，虚拟接口命名的默认方法是将相关物理接口与 VLAN ID 串联。例如， VLAN ID 2 与接口 eth1 关联为 eth1.2。这个例子还显示了另一种命名方法，VLAN 被枚举为名称  <code>vlan &lt;n&gt;</code>，其中 <code>&lt;n&gt;</code> 是 VLAN 的标识符。一旦这样设置， VLAN 设备发送帧会如期望的那样被标记为VLAN ID。我们可通过 Wireshark 看到，如图 3-5 所示。</p>
<figure data-type="image" tabindex="5"><img src="https://wenbozhangw.github.io//post-images/1652326011999.png" alt="图 3-5" loading="lazy"></figure>
<p>图 3-5   VLAN ID 标记的帧显示在 Wireshark 中。默认的列和设置已被修改，以显示 VLAN ID 和原始以太网地址</p>
<p>本图显示了一个在 VLAN 2 中传输的 ARP 分组（见第 4 章）。我们可以看到，该帧大小为 60 字节（不包括 CRC）。该帧用 Ethemet II 封装（类型 0x8100），表示一个 VLAN。另外，VLAN 头部表明该帧属于 VLAN 2，优先级为 0，并且是普通帧。其他字段如我们预期的是一个普通 ARP 分组。</p>
<h3 id="324-8021ax链路聚合以前的-8023ad">3.2.4 802.1AX：链路聚合（以前的 802.3ad）</h3>
<p>有些系统配备多个网络接口，具有 <strong>绑定（bonding）</strong> 或 <strong>链路聚合</strong> 能力。通过链路聚合，两个或更多接口被视为一个，通过冗余或将数据分割（分拆）到多个接口，提高性能并获得更好的可靠性。 IEEE修订的 802.1AX [<a href="#802.1AX-2008">802.1AX-2008</a>] 定义了最常用的链路聚合方法，以及可管理这些链路的<strong>链路聚合控制协议（LACP）</strong>。 LACP 使用一种特定格式的 IEEE 802 帧（称为LACPDU）。</p>
<p>以太网交换机支持的链路聚合是一个替代方案，它比支持更高速网络接口的性价比高。如果多个端口聚合能提供足够的带宽，则可能并不需要高速接口。链路聚合不仅可被网络交换机支持，而且可在一台主机上跨越多个<strong>网络接口卡（NIC）</strong>。在通常情况下，聚合的端口必须是同一类型，并工作在同一模式（半双工或全双工）下。</p>
<p>Linux 可实现跨越不同类型设备的链路聚合（绑定），使用以下命令：</p>
<pre><code>Linux# modporbe bonding
Linux# ifconfig bond0 10.0.0.111 netmask 255.255.255.128
Linux# ifenslave bond0 eth0 wlan0
</code></pre>
<p>这组命令中的第一个用于加载绑定驱动，它是一个支持链路聚合的特殊设备驱动程序。第二个命令使用 IPv4 地址来创建 bond0 接口。虽然 IP 相关信息对创建聚合接口不是必需的，但它是典型的。在 <code>ifenslave</code> 命令执行后，绑定设备 bond0 用 MASTER 标志来标记，而设备 eth0 和 wlan0 用 SLAVE 标志来标记：</p>
<pre><code>bond0 Link encap:Ethernet HWaddr 00:11:A3:00:2C:2A
            inet addr:10.0.0.111 Bcast:10.0.0.127 Mask:255.255.255.128
            inet6 addr: fe80::211:a3ff:fe00:2c2a/64 Scope:Link
            UP BROADCAST RUNNING MASTER MULTICAST MTU:1500 Metric:1
            RX packets:2146 errors:0 dropped:0 overruns:0 frame:0
            TX packets:985 errors:0 dropped:0 overruns:0 carrier:O
            collisions:18 txqueuelen:0
            RX bytes:281939 (275.3 Kib) TX bytes:141391 (138.0 Kib)
eth0 Link encap:Ethernet HWaddr 00:11:A3:00:2C:2A
            UP BROADCAST RUNNING SLAVE MULTICAST MTU:1500 Metric:1
            RX packets:1882 errors:0 dropped:0 overruns:0 frame:0
            TX packets:961 errors:0 dropped:0 overruns:0 carrier:O
            collisions:18 txqueuelen:1000
            RX bytes:244231 (238.5 Kib) TX bytes:136561 (133.3 Kib)
            Interrupt:20 Base address:0x6c00
wlan0 Link encap:Ethernet HWaddr 00:11:A3:00:2C:2A
            UP BROADCAST RUNNING SLAVE MULTICAST MTU:1500 Metric:1
            RX packets:269 errors:0 dropped:0 overruns:0 frame:0
            TX packets:24 errors:0 dropped:0 overruns:0 carrier:O
            collisions:18 txqueuelen:1000
            RX bytes:38579 (37.6 Kib) TX bytes:4830 (4.7 Kib)
</code></pre>
<p>在这个例子中，我们将一个有线以太网接口和一个 Wi-Fi 接口绑定在一起。为主设备 bond0 分配了 IPv4 地址信息，通常分配给两个独立接口之一，它默认使用第一个从设备的 MAC 地址。当 IPv4 流量通过 bond0 虚拟接口发送时，很可能使用不同的从设备来发送。在 Linux 中，当绑定的驱动程序被加载时，可使用系统提供的参数选择选项。例如，模式选项决定了能否做以下工作：在接口之间使用循环交付，一个接口作为另一个接口的备份使用，基于对 MAC 源地址和目的地址执行的异或操作选择接口，将帧复制到所有接口，执行 802.3ad 标准的链路聚合，或采用更先进的负载平衡选项。第二种模式用于高可用性系统，当一个链路停止运行时（由 MII 监控来检测；更多细节见 [<a href="#BOND">BOND</a>] ），这种系统将故障部分转移到冗余的网络基础设施上。第三种模式是基于流量的流向选择从接口。如果目的地完全不同，两个站之间的流量被固定到一个接口。在希望尽量少尝试重新排序，并保证多个接口负载平衡的情况下，这种模式可能是有效的。第四种模式针对容错。第五种模式用于支持 802.3ad 的交换机，在同类链路上实现动态聚合能力。</p>
<p>LACP 协议旨在通过避免手工配置，以简化链路聚合的建立工作。在 LACP “主角” （客户端）和“参与者” （服务器）启用后，它们通常每秒都会发送 LACPDU。 LACP 自动确定哪些成员链路可被聚合成一个<strong>链路聚合组（LAG）</strong>，并将它们聚合起来。这个过程的实现需要通过链路发送一系列信息（MAC地址、端口优先级、端口号和密钥）。一个接收站可比较来自其他端口的值，如果匹配就执行聚合。 LACP 协议的细节见[<a href="#802.1AX-2008">802.1AX-2008</a>]。</p>
<hr>
<h2 id="33-全双工-省电-自动协商和-8021x-流量控制">3.3 全双工、省电、自动协商和 802.1X 流量控制</h2>
<p>当以太网最初被开发出来时，它仅工作在半双工模式，并使用一条共享的电缆。也就是说，同一时间内只能在一个方向发送数据，因此在任何时间点只有一个站可发送一个帧。随着交换式以太网的发展，网络不再是单一的共享线路，而代之以很多链路的组合。因此，多个站之间可以同时进行数据交换。另外，以太网被修改为全双工操作，这样可以有效禁用冲突检测电路。这样也可以增加以太网的物理长度，因为半双工操作和冲突检测的相关时间约束被取消。</p>
<p>在 Linux 中， <code>ethtool</code> 程序可用于查询是否支持全双工，以及是否正在执行全双工操作。这个工具也可显示和设置以太网接口的很多属性：</p>
<pre><code>Linux# ethtool eth0
Settings for eth0:
            Supported ports: [ TP MII ]
            supported link modes: 10baseT/Half 10baseT/Full
                                100baseT/Half 100baseT/Full
            Supports auto-negotiation: Yes
            Advertised link modes: 10baseT/Half 10baseT/Full
                                100baseT/Half 100baseT/Full
            Advertised auto-negotiation: Yes
            Speed: 10Mb/s
            Duplex: Half
            Port: MII
            PHYAD: 24
            Transceiver: internal
            Auto-negotiation: on
            Current message level: 0x00000001 (1)
            Link detected: yes
Linux# ethtool eth1
Settings for eth1:
            Supported ports: [ TP ]
            supported link modes: 10baseT/Half 10baseT/Full
                                100baseT/Half 100baseT/Full
                                1000baseT/Full
            Supports auto-negotiation: Yes
            Advertised link modes: 10baseT/Half 10baseT/Full
                                100baseT/Half 100baseT/Full
                                1000baseT/Full
            Advertised auto-negotiation: Yes
            Speed: 100Mb/s
            Duplex: Full
            Port: Twisted Pair
            PHYAD: 0
            Transceiver: internal
            Auto-negotiation: on
            Supports Wake-on: umbg
            Wake-on: g
            Current message level: 0x00000007 (7)
            Link detected: yes
</code></pre>
<p>在这个例子中，第一个以太网接口（eth0）连接到一个半双工的 10Mb/s 网络。我们看到它能够<strong>自动协商</strong>，这是一种来源于 802.3u 的机制，使接口能交换信息（例如速度）和功能（例如半双工或全双工运行）。自动协商信息在物理层通过信号交换，它可在不发送或接收数据时发送。我们可以看到，第二个以太网接口（eth1）也支持自动协商，它的速率为 100Mb/s，工作模式为全双工。其他值（Port、PHYAD、 Transceiver）指出物理端口类型、地址，以及物理层电路在 NIC 内部还是外部。当前消息级别用于配置与接口操作模式相关的日志消息，它的行为由使用的驱动程序指定。我们在下面的例子讨论如何设置这些值。</p>
<p>在 Windows 中，我们可以看到以下细节，首先进入“控制面板”中的“网络连接”，然后在感兴趣的接口上单击鼠标右键并选择“属性”，然后单击“配置”框并选择“高级”选项卡。这时，将打开一个类似图 3-6 （这个例子来自 Windows 7 机器上的以太网接口）所示的对话框。</p>
<figure data-type="image" tabindex="6"><img src="https://wenbozhangw.github.io//post-images/1652338313157.png" alt="图 3-6" loading="lazy"></figure>
<p>图 3-6   Windows (7) 的网络接口属性的“高级”选项卡。该控件允许用户提供网络设备驱动程序的运行参数</p>
<p>在图 3-6 中，我们可看到通过适配器的设备驱动程序来配置的特殊功能。对于这个特殊的适配器和驱动程序， 802.1p/q 标签可启用或禁用，也可提供流量控制和唤醒功能（见 3.3.2 节）。我们可以手工设置速率和双工模式，或使用更典型的自动协商选项。</p>
<h3 id="331-双工不匹配">3.3.1 双工不匹配</h3>
<p>自动协商曾经有一些互操作性问题，特别是一台计算机及其相关的交换机端口使用不同的双工配置时，或者当自动协商只在链路的一端被禁用时。在这些情况下，可能会发生双工不匹配。令人惊讶的是，当这种状况发生时，连接不会完全失败，但可能带来显著的性能下降。当网络中出现中等程度的双向流量繁忙时（例如，在大数据传输期间），一个半双工接口会将输入的流量检测为冲突，从而触发以太网 MAC 的 CSMA/CD 的指数退避功能。同时，导致这个冲突的数据被丢弃，这可能需要更高层协议（例如 TCP）重传。因此，性能下降可能只在半双工接口发送数据，同时又有大量流量需要接收时才是明显的，站处于轻负载时通常不会发生这种情况。一些研究者已试图开发分析工具来检测这种问题 [<a href="#SC05">SC05</a>]。</p>
<h3 id="332-局域网唤醒wol-省电和魔术分组">3.3.2 局域网唤醒（WoL）、省电和魔术分组</h3>
<p>在 Linux 和 Windows 的例子中，我们看到一些电源管理方面的功能。** Windows 唤醒功能**和 <strong>Linux 唤醒</strong> 选项用于使网络接口或主机脱离低功耗（睡眠）状态，这是基于某类分组的传输来实现的。这种分组用来触发可配置的功率状态改变。在 Linux 中，用于唤醒的值可以是零，或者是多个用于低功耗状态唤醒的位，它们可以被以下几种帧所触发：任何物理层（PHY）活动（p）、发往站的单播帧（u）、组播帧（m）、广播帧（b）、 ARP 帧（a）、魔术分组帧（g），以及包括密码的魔术分组帧。这些都可以使用 <code>ethtool</code> 的选项来配置。例如，可以使用以下命令：</p>
<pre><code>Linux# ethtool -s eth0 wol umgb
</code></pre>
<p>当接收到任何 u、 m、 g 或 b 类型的帧时，这个命令将 eth0 设备配置为发送一个唤醒信号。Windows 提供了类似的功能，但标准的用户接口只支持魔术分组帧，以及一个预定义的 u、m、b和a类型帧的子集。魔术分组包含一个字节值 <code>0xFF</code> 的特定重复模式。在通常情况下，这种帧采用 UDP 分组（见第 10 章）形式封装在以太网广播帧中发送。有几个工具可以生成它们，包括 wol [<a href="#WOL">WOL</a>] ：</p>
<pre><code>Linux# wol 00:08:74:93:C8:3C
Waking up 00:08:74:93:C8:3C...
</code></pre>
<p>这个命令的结果是构造一个魔术分组，我们可以使用 Wireshark 查看( 见图 3-7 )。</p>
<figure data-type="image" tabindex="7"><img src="https://wenbozhangw.github.io//post-images/1652346183244.png" alt="图 3-7" loading="lazy"></figure>
<p>图 3-7   Wireshark 中的一个魔术分组帧，开始是 6 字节的 0xFF，然后重复 MAC 地址 16 次</p>
<p>图 3-7 中显示的分组多数是传统的 UDP 分组，但端口号（1126 和 40000）是任意的。分组中最特别的是数据区域。它以一个 6 字节的值 0xFF 开始，其余部分包含重复 16 次的目的 MAC 地址<code>00:08:74:93:C8:3C</code>。该数据的有效载荷模式定义了魔术分组。</p>
<h3 id="333-链路层流量控制">3.3.3 链路层流量控制</h3>
<p>以全双工模式运行扩展的以太网和跨越不同速率的网段时，可能需要由交换机将帧缓存（保存）一段时间。例如，当多个站发送到同一目的地（称为输出端口争用），这种情况可能发生。如果一个站聚合的流量速率超过该站的链路速率，那么帧就开始存储在中间交换机中。如果这种情况持续一段时间，这些帧可能被丢弃。</p>
<p>缓解这种情况的一种方法是在发送方采取<strong>流量控制</strong>（使它慢下来）。一些以太网交换机（和接口）通过在交换机和网卡之间发送特殊信号帧来实现流量控制。流量控制信号被发送到发送方，通知它必须放慢传输速率，但规范将这些细节留给具体实现来完成。以太网使用** PAUSE 消息（也称为PAUSE帧）**实现流量控制，它由 802.3x [<a href="#802.3-2008">802.3-2008</a>] 来定义。</p>
<p>PAUSE 消息包含在 MAC 控制帧中，通过将以太网<strong>长度/类型</strong>字段值设为 <code>0x8808</code>，以及使用 MAC 控制操作码 <code>0x0001</code> 来标识。如果一个站接收到这种帧，表示建议它减缓发送速度。 PAUSE 帧总是被发送到 MAC 地址 <code>01:80:C2:00:00:01</code>，并且只能在全双工链路上使用。它包含一个保持关闭（hold-off）时间值（指定量为 512 比特的时间），表明发送方在继续发送之前需要暂停多长时间。</p>
<p>MAC 控制帧采用如图 3-3 所示的常规封装的帧格式，但紧跟在<strong>长度/类型</strong>字段后的是一个 2 字节的操作码。 PAUSE 帧实际上是唯一一种使用 MAC 控制帧的帧类型。它包括一个 2 字节的保持关闭时间。 “整个” MAC 控制层（基本只是 802.3x 流量控制）的实现是可选的。</p>
<p>以太网层次的流量控制可能有重大负面影响，因此通常并不使用它。当多个站通过一台过载的交换机发送时（见下一节），该交换机通常向所有主机发送 PAUSE 帧。不幸的是，交换机的内存使用可能对发送主机不均衡，因此有些主机可能被惩罚（流量控制），即使它们对交换机流量过载没有多少责任。</p>
<hr>
<h2 id="34-网桥和交换机">3.4 网桥和交换机</h2>
<p>IEEE 802.1d 标准规定了网桥的操作，交换机本质上是高性能的网桥。网桥或交换机用于连接多个物理的链路层网络（例如一对物理的以太网段）或成组的站。最基本的设置涉及连接两个交换机来形成一个扩展的局域网，如图 3-8 所示。</p>
<figure data-type="image" tabindex="8"><img src="https://wenbozhangw.github.io//post-images/1652347179551.png" alt="图 3-8" loading="lazy"></figure>
<p>图 3-8   一个包括两台交换机的扩展以太网。每个交换机端口有一个编号，每个站（包括每个交换机）有自己的 MAC 地址</p>
<p>图中的交换机 A 和 B 互连形成一个扩展的局域网。在这个特定例子中，客户端系统都连接到 A，服务器都连接到 B，端口编号供参考。注意，每个网络单元（包括每个交换机）有自己的 MAC 地址。每个网桥经过一段时间对域外 MAC 地址的“学习”后，最终每个交换机会知道每个站可由哪个端口到达。每个交换机基于每个端口（也可能是每个 VLAN）的列表被存储在一张表（称为<strong>过滤数据库</strong>）中。图 3-9 显示每个交换机了解每个站的位置后，形成的包含这些信息的数据库例子。</p>
<figure data-type="image" tabindex="9"><img src="https://wenbozhangw.github.io//post-images/1652349458178.png" alt="图 3-9" loading="lazy"></figure>
<p>当第一次打开一个交换机（网桥）时，它的数据库是空的，因此它不知道除自己之外的任何站的位置。当它每次接收到一个目的地不是自己的帧时，它为除该帧到达的端口之外的所有端口做一个备份，并向所有端口发送这个帧的备份。如果交换机（网桥）未学习到站的位置，每个帧将会被交付到每个网段，这样会导致不必要的开销。学习能力可以显著降低开销，它是交换机和网桥的一个基本功能。</p>
<p>目前，多数操作系统支持网络接口之间的网桥功能，这意味着具有多个接口的计算机可用作网桥。例如，在 Windows 中，多个接口可被桥接，进入“控制面板”的“网络连接”菜单，选中（突出显示）需要桥接的接口，点击鼠标右键，并选择“网桥连接”。这时，出现一个表示网桥功能的新图标。许多接口相关的正常网络属性消失，取而代之的是网桥设备（见图 3-10）。</p>
<figure data-type="image" tabindex="10"><img src="https://wenbozhangw.github.io//post-images/1652350474031.png" alt="图 3-10" loading="lazy"></figure>
<p>图 3-10   在 Windows 中，通过选中需要桥接的网络接口，鼠标右击并选择桥接网络接口，可创建网桥设备。在网桥建立之后，可进一步修改网桥设备</p>
<p>图 3-10 显示 Windows 7 中的虚拟网桥设备的属性面板。网桥设备的属性包括一个被桥接的相关设备列表，以及在网桥上运行的一组服务（例如， Microsoft网络客户端、文件和打印机共享等）。 Linux 以类似方式工作，它使用命令行参数。在这个例子中，我们使用图 3-11 所示的拓扑结构。</p>
<figure data-type="image" tabindex="11"><img src="https://wenbozhangw.github.io//post-images/1652350584033.png" alt="图 3-11" loading="lazy"></figure>
<p>图 3-11   在这个简单的拓扑中，一台基于 Linux 的 PC 被配置为网桥，它在两个以太网之间实现互联。作为一个处于学习中的网桥，它不断积累并建立一些表，其中包含有关哪个端口可到达扩展局域网中的其他系统的信息</p>
<p>在图 3-11 中，这个简单的网络使用一台基于 Linux、带两个端口的 PC 作为网桥。只有一个站连接到端口 2，网络其他部分都连接到端口 1。以下命令可启用网桥：</p>
<pre><code>Linux# brctl addbr br0
Linux# brctl addif br0 eth0
Linux# brctl addif br0 eth1
Linux# ifconfig eth0 up
Linux# ifconfig eth1 up
Linux# ifconfig br0 up
</code></pre>
<p>以下几个命令可创建一个网桥设备 br0，并为网桥增加接口 eth0 和 eth1。 <code>brctl delif</code> 命令可用于删除接口。在建立接口之后， <code>brctl showmacs</code> 命令可用于检查过滤数据库（称为<strong>转发数据库</strong>，用 Linux 的术语称为 fdbs）：</p>
<pre><code>Linux# brctl show
bridge name  bridge id           STP     enabled     interfaces
br0          8000.0007e914a9cl   no       eth0          eth1
Linux# brctl showmacs br0
port no mac addr is local? ageing timer
1 00:04:5a:9f:9e:80 no 0.79
2 00:07:e9:14:a9:cl yes 0.00
1 00:08:74:93:c8:3c yes 0.00
2 00:14:22:f4:19:5f no 0.81
1 00:17:f2:e7:6d:91 no 2.53
1 00:90:f8:00:90:b7 no 17.13
</code></pre>
<p>这个命令的输出显示关于网桥的其他细节。由于站可能出现移动、网卡更换、 MAC 地址改变或其他情况，所以就算网桥曾发现一个 MAC 地址可通过某个端口访问，这个信息也不能假设永远是正确的。为了解决这个问题，在每次学习一个地址后，网桥启动一个计时器（通常默认为5分钟）。在 Linux 中，每个学习条目使用一个与网桥相关的固定时间。如果在指定的“有效期”内，没有再次看到该条目中的地址，则将这个条目删除，如下所示：</p>
<pre><code>Linux# brctl setageing br0 1
Linux# brctl showmacs br0
port no mac addr is local? ageing timer
1 00:04:5a:9f:9e:80 no 0.79
2 00:07:e9:14:a9:cl yes 0.00
1 00:08:74:93:c8:3c yes 0.00
2 00:14:22:f4:19:5f no 0.78
1 00:17:f2:e7:6d:91 no 0.00
</code></pre>
<p>为了方便演示，我们选择了一个比平时数值低的值作为<strong>有效期</strong>。当一个条目因有效期满而被删除时，后续的帧将被发送到接收端口之外的所有端口（称为<strong>洪泛</strong>），并更新过滤数据库中的这个条目。实际上，过滤数据库的使用和学习有利于优化性能，如果表是空的，网络将花费更多开销，但仍能履行职责。下一步，我们将注意力转移到两个以上的网桥通过冗余链路互联的情况。在这种情况下，帧的洪泛可能导致帧永远循环的洪泛灾难。显然，我们需要一种方法来解决这个问题。</p>
<h3 id="341-生成树协议">3.4.1 生成树协议</h3>
<p>网桥可能单独或与其他网桥共同运行。当两个以上的网桥使用（或交换机端口交叉连接）时，由于存在级联的可能性，因此可能形成很多组的循环帧。我们看如图 3-12 所示的网络。</p>
<figure data-type="image" tabindex="12"><img src="https://wenbozhangw.github.io//post-images/1652351442343.png" alt="图 3-12" loading="lazy"></figure>
<p>图 3-12   一个扩展的以太网包括 4 台交换机和多条冗余链路。如果在这个网络中采用简单的洪泛转发帧，由于多余的倍增流量（所谓的广播风暴），将会导致一场大的灾难。这种情况需要使用 STP</p>
<p>假设图 3-12 中的多个交换机刚被打开，并且它们的过滤数据库为空。当站 S 发送一个帧时，交换机 B 在端口 7、 8 和 9 复制该帧。这时，最初的帧已被“放大” 3 倍。这些帧被交换机 A、 D 和 C 接收。交换机 A 在端口 2 和 3 生成该帧的副本。交换机 D 和 C 分别在端口 20、 22 和 13、 14 生成更多副本。当这些副本在交换机 A、 C 和 D 之间双向传输，这时放大倍数已增大为6。 当这些帧到达时，<br>
转发数据库开始出现震荡，这是由于网桥反复尝试查找通过哪些端口可到达站 S。显然，这种情况是不能容忍的。如果允许这种情况发生，采用这种配置的网桥将无法使用。幸运的是，有一种协议可避免这种情况，这种协议称为<strong>生成树协议（STP）</strong>。我们将介绍 STP 的一些细节，解释网桥和交换机采用哪些方法抑制放大。在当前的标准 [<a href="#802.1D-2004">802.1D-2004</a>] 中，传统的 STP 被**快速生成树协议（RSTP）**代替，我们将在了解传统 STP 的基础上再介绍它。</p>
<p>STP 通过在每个网桥禁用某些端口来工作，这样可避免拓扑环路（即两个网桥之间不允许出现重复路径），但如果拓扑结构未分区，则仍可到达所有站。在数学上，一个生成树是一张图中所有节点和一些线的集合，从任何节点到其他节点（跨越图）有一条路径或路由，但是没有环路（这些线的集合构成一棵树）。一张图可能存在多个生成树。 STP 用于找出这张图的其中一个生成树，该图将网桥作为节点并将链路作为线（或称“边”）。图 3-13 说明了这个想法。</p>
<figure data-type="image" tabindex="13"><img src="https://wenbozhangw.github.io//post-images/1652352139379.png" alt="图 3-13" loading="lazy"></figure>
<p>图 3-13   通过 STP，链路 B-A、 A-C 和 C-D 在生成树中是活跃的。端口 6、7、 1、2、 13、14 和 20 处于转发状态；所有其他端口被阻塞（即不转发）。这样可以防止帧循环，避免广播风暴。如果配置发生变化或某台交换机故障，则将阻塞端口改变为转发状态，并由网桥计算一个新生成树</p>
<p>在本图中，粗线表示网络中被 STP 选择用于转发帧的链路。其他链路没有被使用，端口 8、9、 12、21、22 和 3 被<strong>阻塞</strong>。通过使用 STP，早期的各种问题并没有出现，这些帧只是作为另一个抵达帧的副本而被创建。这里没有出现放大的问题。由于任意两个站之间只有一条路径，因此可以避免循环。生成树的形成和维护由多个网桥完成，在每个网桥上运行一个分布式算法。</p>
<p>用于转发数据库时， STP 必须处理以下情况，例如网桥启用和关闭、接口卡更换或 MAC 地址改变。显然，这种变化可能影响生成树运行，因此 STP 必须适应这些变化。这种适应通过交换一种称为**网桥协议数据单元（BPDU）**的帧来实现。这些帧用来形成和维护生成树。这棵树“生长”自一个网桥——该网桥由其他网桥选举为“根网桥”。</p>
<p>如前所述，一个网络可能存在多个生成树。如何确定哪棵生成树最适于转发帧，这基于每条链路和根网桥位置的相关成本。这个成本是一个与链路速度成反比的整数（建议）。例如，一条 10Mb/s 链路的成本为 100， 100Mb/s 和 1000Mb/s 链路的成本分别为 19 和 4。 STP 计算到根网桥的成本最小的路径。如果必须遍历多条链路，相关成本是这些链路成本之和。</p>
<h4 id="3411-端口状态和角色">3.4.1.1 端口状态和角色</h4>
<p>为了理解 STP 的基本操作，我们需要了解网桥端口的状态机，以及 BPDU 内容。网桥端口可能有 5 个状态：阻塞、侦听、学习、转发和禁用。在图 3-14 所示的状态转换图中，我们可以看出它们之间的关系。</p>
<figure data-type="image" tabindex="14"><img src="https://wenbozhangw.github.io//post-images/1652353538285.png" alt="图 3-14" loading="lazy"></figure>
<p>图 3-14   在正常的 STP 操作中，端口在 4 个主要状态之间转换。在阻塞状态下，帧不被转发，但一次拓扑变化或超时可能导致向侦听状态转换。转发状态是活跃的交换机端口承载数据流量的正常状态。括号中的状态名用于表示 RSTP 相关的端口状态</p>
<p>在图 3-14 显示的生成树中，实线箭头表示端口的正常转换，小的虚线箭头表示由管理配置引起的改变。在初始化后，一个端口进入阻塞状态。在这种状态下，它不进行地址学习、数据转发或 BPDU 发送，但它会监控接收的 BPDU，并在它需要被包含在将到达的根网桥的路径中的情况下，使端口转换到侦听状态。在侦听状态下，该端口允许发送和接收 BPDU，但不进行地址学习或数据转发。经过一个典型的 15 秒的转发延迟，端口进入学习状态。这时，它被允许执行数据转发之外的所有操作。在进入转发状态并开始转发数据之前，需要等待另一个转发延迟。</p>
<p>相对于端口状态机，每个端口都扮演一定的<strong>角色</strong>。由于 RSTP （见 3.4.1.6 节）的出现，这个术语变得越来越重要。端口可能扮演<strong>根端口</strong>、<strong>指定端口</strong>、<strong>备用端口</strong>或<strong>备份端口</strong>等角色。根端口是生成树中位于指向根的线段终点的那些端口。指定端口是指处于转发状态，并与根相连线段中路径成本最小的端口。备用端口是与根相连线段中成本更高的端口。它们不处于转发状态。备份端口是指连接到同一线段中作为同一网桥指定端口使用的端口。因此，备份端口可轻易接管一个失效的指定端口，而不影响生成树拓扑的其余部分，但是它不能在全部网桥失效的情况下提供一条到根的备用路径。</p>
<h4 id="3412-bpdu-结构">3.4.1.2 BPDU 结构</h4>
<p>为了确定生成树中的链路， STP 使用图 3-15 所示的 BPDU。</p>
<figure data-type="image" tabindex="15"><img src="https://wenbozhangw.github.io//post-images/1652354174126.png" alt="图 3-15" loading="lazy"></figure>
<p>图 3-15   BPDU 被放置在 802 帧的有效载荷区，并在网桥之间交换以建立生成树。重要的字段包括源、根节点、到根的成本和拓扑变化提示。在 802.1w 和 [<a href="#802.1D-2004">802.1D-2004</a>] 中（包括快速 ST P或 RSTP），附加字段显示端口状态</p>
<p>图 3-15 所示的格式适用于最初的 STP，以及新的 RSTP （见 3.4.1.6 节）。 BPDU 总被发送到组地址 <code>01:80:C2:00:00:00</code> （链路层组和因特网组播寻址的详细信息见第 9 章），并且不会通过一个未修改的网桥转发。在该图中， DST、 SRC 和 L/T （长度/类型）字段是携带 BPDU 的传统以太网（802.3）帧头部的一部分。 3 字节的 LLC/SNAP 头部由 802.1 定义，并针对 BPDU 被设置为常数 <code>0x424203</code>。并非所有 BPDU 都使用 LLC/SNAP 封装，但这是一个常见的选项。</p>
<p><strong>协议（Prot）</strong> 字段给出协议 ID 号，它被设置为 0。<strong>版本（Vers）</strong> 字段被设置为 0 或 2，取决于使用 STP 还是 RSTP。<strong>类型（rtype）</strong> 字段的分配与版本类似。<strong>标志（Flags）</strong> 字段包含<strong>拓扑变化（TC）</strong> 和 <strong>拓扑变化确认（TCA）</strong> 位，它们由最初的 802.1d 标准定义。附加位被定义为 <strong>建议（P）</strong>、<strong>端口角色（00 为未知， 01 为备用， 10 为根， 11 为指定）</strong>、<strong>学习（L）</strong>、<strong>转发（F）<strong>和</strong>协议（A）</strong>。这些都作为 RSTP 内容在 3.4.1.6 节中讨论。根 ID 字段给出发送方使用的根网桥标识符，即从网桥 ID 字段中获得的 MAC 地址。这些 ID 字段都用一种特殊方式编码，包括 MAC 地址之前的一个 2 字节的优先级字段。优先级的值可通过管理软件来设置，以强制要求生成树采用某个特定网桥作为根（例如， Cisco 在自己的 Catalyst 交换机中使用默认值 <code>0x8000</code>）。</p>
<p>根路径成本是在 <strong>根 ID</strong> 字段中指定的计算出的到达某个网桥的成本。 PID 字段是端口标识符和由发送帧给出的端口号，它被附加在一个可配置的 1 字节的<strong>优先级</strong>字段（默认为 <code>0x80</code>）之后。<strong>消息有效期（MsgA）</strong> 字段指出消息有效期。<strong>最大有效期（MaxA）</strong> 字段指出超时（默认为 20 秒）的最大期限。<strong>欢迎时间（HelloTime）</strong> 字段指出配置帧的传输周期。<strong>转发延迟</strong>字段指出处于学习和侦听状态的时间。所有的有效期和时间字段可在 1/256 秒内获得。</p>
<p><strong>消息有效期</strong>字段不像其他的时间字段那样是固定值。当根网桥发送一个 BPDU 时，它将该字段设置为 0。 网桥转发接收到的不是根端口的帧，并将<strong>消息有效期</strong>字段加1。从本质上来说，该字段是一个跳步计数器，用于记录 BPDU 经过的网桥数量。当一个 BPDU 被一个端口接收时，其包含的信息在内存和 STP 算法参与者中被保存至超时（超时发生在（MaxA-MsgA）时刻）。如果超过这个时间，根端口没有接收到另一个 BPDU，根网桥被宣布“死亡”，并重新开始根网桥选举过程。</p>
<h4 id="3413-建立生成树">3.4.1.3 建立生成树</h4>
<p>STP 的第一个工作是选举根网桥。根网桥是在网络（或 VLAN）中标识符最小（优先级与 MAC 地址结合）的网桥。当一个网桥初始化时，它假设自己是根网桥，并用自己的网桥 ID 作为根 ID 字段的值发送配置 BPDU 消息，如果它检测到一个 ID 更小的网桥，则停止发送自己的帧，并基于接收到的 ID 更小的帧构造下一步发送的 BPDU。发出根 ID 更小的 BPDU 的端口被标记为根端口（即端口在到根网桥的路径上）。剩余端口被设置为阻塞或转发状态。</p>
<h4 id="3414-拓扑变化">3.4.1.4 拓扑变化</h4>
<p>STP 的另一个重要工作是处理拓扑变化。虽然可用前面所述的数据库有效期机制适应拓扑变化，但这是一个比较差的方法，因为有效期计时器需要花费很长时间（5分钟）删除错误条目。相反， STP 采用一种方法检测拓扑变化，并快速通知它们所在的网络。在 STP 中，当一个端口进入阻塞或转发状态时，意味着发生拓扑变化。当网桥检测到一个连接变化（例如一条链路故障），它向根端口之外的端口发送<strong>拓扑变化通知（TCN）</strong> BPDU，通知自己在树中的父网桥，直到根为止。树中通向根的下一个网桥向发送通知的网桥确认 TCN BPDU，并将它们转发到根。当接收到拓扑变化通知时，根网桥在后续的周期性配置消息中设置 TC 位。这种消息被网络中的每个网桥所转发，并被处于阻塞或转发状态的端口接收。设置这个位允许网桥减小转发延时计时器的有效期，将有效期以秒代替推荐的 5 分钟。这样，数据库中已有的错误条目可被快速清除和重新学习，同时允许访问那些被误删除的条目。</p>
<h4 id="3415-例子">3.4.1.5 例子</h4>
<p>在 Linux 中，网桥功能默认禁用 STP。假设在多数情况下拓扑相对简单，一台普通计算机可被用作网桥。可执行以下命令为当前使用的网桥启用 STP：</p>
<pre><code>Linux# brctl stp br0 on
</code></pre>
<p>执行该命令的结果如下：</p>
<pre><code>Linux# brctl stp br0 on
br0
bridge id       8000.0007e914a9c1
designated root     8000.0007e914a9c1
root port       0       path cost       0
max age     19.99       bridge max age      19.99
hello time      1.99        bridge hello time       1.99
forward delay       14.99       bridge forward delay        14.99
ageing time     0.99
hello timer     1.26        tcn timer       0.00
topology change timer       3.37        gc timer        3.26
flags       TOPOLOGY_CHANGE TOPOLOGY_CHANGE_DETECTED

eth0 (0)
port id       0000      state       forwarding
designated root     8000.0007e914a9c1       path cost       100
designated bridge     8000.0007e914a9c1     message age timer       0.00
designated port       8001       forward delay timer 0.00

designated cost       0       hold timer 0.26

flags

eth1 (0)
port id       0000      state       forwarding
designated root     8000.0007e914a9c1       path cost       19
designated bridge     8000.0007e914a9c1     message age timer       0.00
designated port       8002       forward delay timer 0.00
designated cost       0       hold timer 0.26

flags
</code></pre>
<p>我们看到一个简单的桥接网络的 STP 设置。网桥设备 br0 保存网桥的整体信息。这些信息包括网桥 ID （8000.0007e914a9cl），它由图 3-11 中基于 PC 的网桥（端口 1）的最小 MAC 地址生成。可在几秒钟内获得主要的配置参数（例如欢迎时间、拓扑变化计时器等）。标志值表示最近的拓扑变化，用于获得最近的网络连接变化的实际情况。输出的其余部分描述每个端口的信息，即 eth0（网桥端口 1）和 eth1（网桥端口 2）。注意， eth0 的路径成本大约是 eth1 成本的 10 倍。这个结果与 eth0 是一个 10Mb/s 以太网而 eth1 是一个100Mb/s 全双工网络是一致的。</p>
<p>我们可使用 Wireshark 查看一个BPDU。在图 3-16 中，我们看到一个 52 字节的消息内容。消息长度为 52 字节（由于 Linux 捕获功能会拆除填充，因此它小于以太网的 64 字节的最小限制），这个长度是由以太网头部中的<strong>长度/类型</strong>字段加 14 得到的。目的地址是预期的组地址 <code>01:80:C2:00:00:00</code>。有效载荷长度是 38 字节，这个值包含在<strong>长度</strong>字段中。 SNAP/LLC字段包含常数 <code>0x424243</code>，并且封装帧是一个生成树（版本 0）帧。其余协议字段表明站 <code>00:07:e9:14:a9:c1</code> 认为自己是生成树的根，优先级为 32768 （低优先级），并且 BPDU 从端口 2 以优先级 <code>0x80</code> 发送。另外，最大有效期是 20 秒，欢迎时间是 2 秒，转发延迟是 15 秒。</p>
<figure data-type="image" tabindex="16"><img src="https://wenbozhangw.github.io//post-images/1652356336887.png" alt="图 3-16" loading="lazy"></figure>
<p>图 3-16   Wireshark 显示一个 BPDU。以太网帧的目的地址是一个通过网桥（<code>01:80:C2:00:00:00</code>）的组地址</p>
<h4 id="3416-快速生成树协议以前的-8021w">3.4.1.6 快速生成树协议（以前的 802.1w）</h4>
<p>传统 STP 的问题之一是在拓扑变化之后，只能通过一定时间内未接收到 BPDU 来检测。如果这个超时很大，收敛时间（沿着生成树重新建立数据流的时间）可能比预期大。 IEEE 802.1w标准（[<a href="#802.1D-2004">802.1D-2004</a>] 的一部分）改进了传统 STP，它定义了采用新名称的 <strong>快速生成树协议（Rapid Sparming Tree Protocol， RSTP）</strong> 。在 RSTP 中，对 STP 的主要改进是监视每个端口的状态，并在故障时立即发送一个拓扑变化通知。另外， RSTP 使用 BPDU 的标志字段中的全部 6 位来支持网桥之间的协议，以避免由计时器来启动协议操作。它将正常的 STP 端口状态由 5 个减少到 3 个（丢弃、学习和转发，由图 3-14 的括号中的状态名表示）。 RSTP 的丢弃状态代替了传统 STP 的禁止、阻塞和侦听状态。 RSTP 创建了一个称为<strong>备用端口</strong>的新角色，作用是在根端口停止运行时立即代替它。</p>
<p>由于 RSTP 只使用一种类型的 BPDU，因此这里没有专门的拓扑变化 BPDU。正如所说的那样， RSTP 的 BPDU 使用版本和类型号 2 而不是 0。在 RSTP 中，检测到一次拓扑变的交换机会发送一个表示拓扑变化的 BPDU，任何接收到它的交换机立即清除自己的过滤数据库。这个改变可显著影响协议的收敛时间。这时，无须等待拓扑变化传递到根网桥再经过转发延迟后返回，而是立即清除相关条目。总之，在大多数情况下，收敛时间可从几十秒减少到几分之一秒。</p>
<p>RSTP 使<strong>边缘端口</strong>（只连接到端站的端口）和正常的生成树端口之间，以及点到点链路和共享链路之间都有区别。边缘端口和点到点链路上的端口通常不会形成循环，因此允许它们跳过侦听和学习状态，直接进入转发状态。当然，如果假设一个边缘端口可能被入侵，例如两个端口交叉连接，它们可携带任何形式的BPDU （简单的端站通常不处理 BPDU），这时它们将被重新分类为生成树端口。点到点链路可根据接口操作模式来识别。如果这个接口运行在全双工模式下，则这条链路是点到点链路。</p>
<p>在普通的 STP 中， BPDU 通常由一个通知网桥或根网桥来转发。在 RSTP 中， BPDU 为了“保持活跃”而由所有网桥来定期发送，以便确定相连的邻居是否正常运行。大多数高层路由协议也会这样做。注意，在 RSTP 中，拓扑变化没有像普通 STP 那样包括边缘端口连接或断开。当检测到一次拓扑变化时，通知网桥发送 TC 位被设置的 BPDU，不仅到根网桥而且到所有网桥。这样做允许将拓扑变化通知整个网络，并且比传统 STP 更快速。当一个网桥接收到这些消息时，它会更新除边缘端口之外的所有相关条目。</p>
<p>RSTP 的很多功能由 Cisco 和其他公司开发，他们有时需要在自己的产品中为普通 STP做专门的扩展。 IEEE 委员会将这些扩展纳入 802.1d 标准的更新中，该标准涵盖所有类型的 STP，因此扩展局域网可在某些网段中运行传统 STP，同时在其他部分中运行 RSTP （虽然 RSTP 的优势将丧失）。 RSTP 已被扩展到 VLAN [<a href="#802.1Q-2005">802.1Q-2005</a>] 中，它采用一种称为多生成树协议（MSTP）的协议。这个协议保留了RSTP （和 STP）报文格式，因此它有可能做到向后兼容，也支持形成多个生成树（每个 VLAN 一个生成树）。</p>
<h3 id="342-8021ak多注册协议">3.4.2 802.1ak：多注册协议</h3>
<p>**多注册协议（Multiple Registration Protocol， MRP）**提供了在桥接局域网环境中的站之间注册属性的通用方法。 [<a href="#802.1ak-2007">802.1ak-2007</a>]定义了两个特殊的 MRP “应用程序”，称为 MVRP（用于注册 VLAN）和 MMRP （用于注册组 MAC 地址）。 MRP 代替了早期的 GARP 框架;MVRP 和 MMRP 分别代替了旧的 GVRP 和 GMRP 协议。这些协议最初都由 802.1q 定义。</p>
<p>在使用 MVRP 时，当一个站被配置为一个 VLAN 成员时，该信息被传输到它所连接的交换机，并由该交换机将站加入 VLAN 通知其他交换机。这允许交换机根据站的 VLAN ID 添加自己的过滤表，也允许 VLAN 拓扑变化不必通过 STP 而重新计算现有生成树。避免重新计算 STP 是从 GVRP 向 MVRP 迁移的原因之一。</p>
<p>MMRP 是一个站注册其感兴趣的组 MAC 地址（组播地址）的方法。这个信息可能被用于交换机建立端口，组播流量必须通过该端口来交付。如果没有这样的功能，交换机将不得不广播所有的组播流量，这样可能导致不必要的开销。 MMRP 是一个第 2 层协议，它与第 3 层协议 IGMP 和 MLD 相似，并在很多交换机中支持“  IGMP/MLD 探听”能力。我们将在第 9 章讨论 IGMP、MLD 和探听。</p>
<hr>
<h2 id="35-无线局域网ieee-80211wi-fi">3.5 无线局域网——IEEE 802.11（Wi-Fi）</h2>
<p>目前，<strong>无线保真（Wi-Fi）</strong> 是访问 Intemet 的最流行技术之一，其众所周知的 IEEE 标准名称为 802.11，它是一种常用的无线以太网标准。 Wi-Fi 已发展成为一种廉价、高效、便捷的方式，为大多数应用提供可接受的连通性和性能。 Wi-Fi 网络很容易建立。当前多数的便携式电脑和智能手机包含接入 Wi-Fi 基础设施的必要硬件。很多咖啡馆、机场、宾馆和其他公共设施提供了 Wi-Fi “热点”， Wi-Fi 在那些可能难以提供其他基础设施的发展中国家发展甚至更快。图 3-17 显示了 IEEE 802.11 网络体系结构。</p>
<figure data-type="image" tabindex="17"><img src="https://wenbozhangw.github.io//post-images/1652419793689.png" alt="图 3-17" loading="lazy"></figure>
<p>图 3-17   一个无线局域网的 802.11 术语。接入点可采用一种分布式服务（一个无线或有线的主干）来连接，以形成一个扩展的无线局域网（称为一个 ESS）。站（包括 AP 和移动设备）之间的通信构成一个基本服务集。在通常情况下，每个 ESS 有一个指定的 ESSID，它的功能是作为一个网络的名称</p>
<p>图 3-17 中的网络包括多个<strong>站（STA）</strong>。在通常情况下，站和<strong>接入点（AP）<strong>组成一个操作子集。一个 AP 和相关的站被称为一个</strong>基本服务集（BSS）</strong>。 AP 之间通常使用一种有线的<strong>分布式服务</strong>（称为 DS，基本是“主干”）连接，形成一个<strong>扩展服务集（ESS）</strong>。这种方式通常被称为<strong>基础设施模式</strong>。 802.11 标准也提供了一种 Ad hoc （自组织）模式。在这种配置中没有 AP 或 DS，而是直接采用站到站（对等）的通信。在 IEEE 的术语中，加入一个 Ad hoc 网络的 STA 形成一个<strong>独立基本服务集（IBSS）</strong>。由 BSS 或 IBSS 的集合形成的无线局域网称为<strong>服务集</strong>，它由一个**服务集标识符（SSID）**来标识。**扩展服务集标识符（ESSID）**是由 SSID 命名的一个 BSS 集合，它实际上是一个最长 32 个字符的局域网名称。在 WLAN 第一次建立时，该名称通常分配给 AP。</p>
<h3 id="351-80211-帧">3.5.1 802.11 帧</h3>
<p>802.11 网络有一个常见的总体框架，但包括多种类型的帧格式。每种类型的帧不一定包含所有字段。图 3-18 显示了常见帧格式和（最大尺寸的）数据帧。</p>
<figure data-type="image" tabindex="18"><img src="https://wenbozhangw.github.io//post-images/1652420491239.png" alt="图 3-18" loading="lazy"></figure>
<p>图 3-18   802.11 基本数据帧格式（见 [<a href="#802.11n-2009">802.11n-2009</a>]）。 MPDU 格式类似于以太网，但取决于接入点之间使用的 DS 类型：帧是发送到 DS 还是来自它，以及帧是否被聚合。 QoS 控制字段用于特殊功能， HT 控制字段用于控制 802.11n 的“高吞吐量”功能</p>
<p>图 3-18 所示的帧包括一个用于同步的前导码，它取决于正在使用的 802.11 协议类型。接下来，**物理层会聚程序（PLCP）**头部以独立于物理层的方式提供特定的物理层信息。帧的 PLCP 部分的传输速率通常比其余部分低。这样做有两个目的：提高正确交付的概率（较低速度通常具有更好的容错性能），提供对传统设备的兼容性和防止慢速操作的干扰。帧的 MAC PDU（MPDU）与以太网相似，但是有一些额外的字段。</p>
<p>MPDU 以帧控制字开始，其中包括 2 位的<strong>类型</strong>字段，用于识别该帧的类型。这里有三种类型的帧：<strong>管理帧</strong>、<strong>控制帧</strong>和<strong>数据帧</strong>。每种类型有不同的子类型。 [<a href="#802.11n-2009">802.11n-2009，表 7-1</a>]给出了有关类型和子类型的完整列表。剩余字段由帧类型（如果有的话）来决定，后面将单独讨论。</p>
<h4 id="3511-管理帧">3.5.1.1 管理帧</h4>
<p>管理帧用于创建、维持、终止站和接入点之间的连接。它们也被用于确定是否采用加密，传输网络名称（SSID 或 ESSID），支持哪种传输速率，以及采用的时间数据库等。当一个 Wi-Fi 接口“扫描”临近的接入点时，这些帧被用于提供必要的信息。</p>
<p>扫描是一个站发现可用的网络及相关配置信息的过程。这涉及每个可用频率和流量的侦听过程，以确定可用的接入点。一个站可以主动探测网络，在扫描时传输一个特殊的管理帧（“探测请求”）。这些探测请求有一定的限制，以保证 802.11 流量不在非 802.11 （例如医疗服务）频率上传输。下面是在 Linux 系统中手工启动扫描的例子：</p>
<pre><code>Linux# iwlist wlan0 scan
wlan0 Scan completed :
                Cell 01 - Address: 00:02:6F:20:B5:84
                        ESSID: &quot;Grizzly-5354-Aries-802.11b/g&quot;
                        Mode:Master
                        Channel:4
                        Frequency:2.427 GHz (Channel 4)
                        Quality=5/100 Signal level=47/100
                        Encryption key:on
                        IE : WPA Version 1
                            Group Cipher : TKIP
                            Pairwise Ciphers (2) : CCMP TKIP
                            Authentication Suites (1) : PSK
                        Bit Rates:1 Mb/s; 2 Mb/s; 5.5 Mb/s; 11 Mb/s;
                                6 Mb/s; 12 Mb/s; 24 Mb/s; 36 Mb/s; 9 Mb/s;
                                18 Mb/s; 48 Mb/s; 54 Mb/s
                        Extra:tsf=0000009d832ff037
</code></pre>
<p>这里，我们看到在无线接口 wlan0 上手工启动扫描的结果。一个 MAC 地址为 <code>00:02:6F:20:B5:84</code>的 AP 作为主角（即在基础设施模式中作为 AP）工作。它在信道 4 （2.427GHz）上广播 ESSID “Grizzly-5354-Aries-802.11b/g” （更多细节见 3.5.4 节讨论信道和频率时对信道选择的描述）。信号质量和强度决定执行扫描的站从 AP 接收信号的好坏，但相应值的含义可能因设备生产商而不同。 WPA 加密被用于这种链路（见3.5.5节），传输速率从 1Mb/s 到 54Mb/s 不等。 <strong>tsf（时间、同步、功能）</strong> 的值表示 AP 的时间概念，它被用于需要同步的各种功能，例如省电模式（见3.5.2节）。</p>
<p>当一个 AP 广播它的 SSID 时，任何站可尝试与 AP 建立连接。当一个连接建立时，大多数 Wi-Fi 网络会提供必要的配置信息，以便为站提供 Internet 接入（见第 6 章）。但是， AP 的运营商可能希望控制使用网络的站。有些运营商故意使连接变得更困难， AP 不广播其 SSID 被作为一项安全措施。这种方法提供了有限的安全性，这是由于 SSID 可以被猜测。链路加密和密码可提供更可靠的安全性，我们将在 3.5.5 节讨论。</p>
<h4 id="3512-控制帧rtscts-和-ack">3.5.1.2 控制帧：RTS/CTS 和 ACK</h4>
<p>控制帧与帧确认被用于一种流量控制方式。流量控制有助于接收方使一个过快的发送方降低发送速度。帧确认有助于发送方知道哪些帧已正确接收。这些概念也适用于传输层的 TCP 协议（见第15章）。 802.11 网络支持可选的<strong>请求发送/明确发送（RTS/CTS）</strong>，通过放缓传输来进行流量控制。当 RTS/CTS 启用时，一个站在发送数据帧之前发送一个 RTS 帧，当接收方愿意接收额外的流量时，它会响应一个 CTS 帧。在 RTS/CTS 交换之后，这个站开启一个时间窗口（在 CTS 帧中标识），用于向确认接收的站发送数据帧。这种协同传输方法在无线网络中是常见的，模拟流量控制信号多年前已被用于有线的串行线路（有时称为硬件流量控制）。</p>
<p>RTS/CTS 交换有助于避免隐藏终端问题，通过在允许发送时对每个站加以指导，以便发现对方站同时进行的传输。由于 RTS 和 CTS 帧比较短，因此它们不会长期使用信道。如果一个分组的大小足够大， AP 通常为每个分组启动一次 RTS/CTS 交换。在通常情况下， AP 提供一个称为<strong>分组大小阈值</strong>（或类似）的配置选项。超过阈值的帧将会导致一个 RTS 帧优先于数据帧发送。如果需要执行 RTS/CTS 交换，大多数设备生产商设置的默认值为 500 字节。在 Linux 中， RTS/CTS 阈值可通过以下方式设置：</p>
<pre><code>Linux# iwconfig wlan0 rts 250
wlan0 IEEE 802.11g ESSID:&quot;Grizzly-5354-Aries-802.11b/g&quot;
        Mode : Managed
        Frequency:2.427 GH
        Access Point: 00:02:6F:20:B5:84
        Bit Rate=24 Mb/s Tx-Power=0 dBm
        Retry min limit:7 RTs   thr=250 B    Fragment thr=2346 B
        Encryption key:xxxx- ... 一xxxx [3]
        Link Quality=100/100    Signal level=46/100
        Rx invalid nwid:0    Rx invalid crypt:0    Rx invalid frag:0
        Tx excessive retries:0    Invalid misc:0    Missed beacon:0
</code></pre>
<p><code>iwconfig</code> 命令可用于设置多种变量，包括 RTS 和分片阈值（见 3.5.1.3 节）。它也可用于确定统计数据，例如错误的网络 ID （ESSID）或加密密钥而导致的帧出错数量。它也可用于给出过多的重试次数（即重传次数），这是一个用于衡量链路可靠性的粗略指标，在无线网络中常用于指导路由决策 [<a href="#ETX">ETX</a>]。在覆盖范围有限的 WLAN 中，隐藏终端问题通常很少发生，可将站的 RTS 阈值设置为很大（1500 或更大）来禁用 RTS/CTS。这可避免每个分组执行 RTS/CTS 交换带来的开销。</p>
<p>在有线的以太网中，冲突较少意味着正确接收帧的概率较高。在无线网络中，更多的因素导致帧交付可能出错，例如信号不够强或受到干扰。为了帮助解决这些潜在问题， 802.11 采用一种重传/确认（ACK）方法来扩展 802.3 重传机制。确认是对预期在一定时间内接收的一个单播帧（802.11a/b/g）或一组帧（802.11n 或带“块确认”的 802.11e）的响应。组播或广播帧没有相关的确认，以避免出现“ACK爆炸”问题（见第 9 章）。在指定时间内没有接收到对应的 ACK 会导致帧的重传。</p>
<p>重传可能在网络中形成重复的帧。当任何帧是某个帧的一次重传时，<strong>帧控制字</strong>中的 <strong>重试（Retry）</strong> 位需要设置为相应的值。接收站可通过它删除重复的帧。每个站需要保持一个小的缓存条目，以说明最近查看的地址和序列号/分片号。当一个接收帧与一个条目匹配时，则丢弃该帧。</p>
<p>发送一个帧和接收一个 ACK 所需时间与链路距离和<strong>时隙</strong>（802.11 MAC 协议的一个基本时间单位，见 3.5.3 节）相关。在大多数系统中，可配置等待的 ACK 时间（以及时隙），我们可采用不同方法完成配置。在大多数情况下，例如在家庭或办公室中使用，默认值是足够的。在长距离的 Wi-Fi 中，这些值可能需要调整（例如见 [<a href="#MWLD">MWLD</a>] ）。</p>
<h4 id="3513-数据帧-分片和聚合">3.5.1.3 数据帧、分片和聚合</h4>
<p>在一个繁忙的网络中看到的帧大多数是数据帧，它们如大家所期望的那样携带数据。在通常情况下， 802.11 帧和链路层（LLC）帧之间存在一对一关系，它们保证更高层协议（例如 IP）是可用的。但是，802.11 支持帧<strong>分片</strong>，可将一个帧分为多个分片。根据 802.11n 的规定，它也支持帧聚合，可将多个帧合并发送以减少开销。</p>
<p>当使用帧分片时，每个分片有自己的 MAC 头部和尾部的 CRC，并且它们独立于其他分片处理。例如，到不同目的地的分片可以交错。当信道有明显的干扰时，分片有助于提高性能。除非使用块确认功能，否则每个分片将被单独发送，并由接收方为每个分片产生一个 ACK。 由于分片小于全尺寸的帧，如果需要启动一次重传，则只需要重传少量数据。</p>
<p>分片仅用于目的地址为单播（非广播或组播）的帧。为了具备这种能力，顺序控制字段包含一个<strong>分片号</strong>（4 位）和一个<strong>序列号</strong>（12 位）。如果一个帧经过分片，所有分片包含相同的序列号值，而每个相邻的分片的分片号之差为 1。 由于分片号字段长度为 4 位，同一帧最多可能有 15 个分片。<strong>帧控制字</strong>中的<strong>更多标志</strong>字段表示更多分片还没有到达。最后一个分片将这个位设置为 0。接收方将接收到的同一序列号的分片根据分片号重组成原始帧。当所有包含同一序列号的分片被接收，并且最后一个分片将更多标志字段设为 0 时，这个帧被重组并交给更高层协议来处理。</p>
<p>分片并不常使用，因为它需要经过调整。如果不调整就使用，可能导致性能下降。当帧大小更小的情况下，出现位差错的概率（参见下一段）更小。分片大小通常可设为 256 字节至 2048 字节，并作为一个阈值（只有那些超过阈值的帧才被分片）。很多 AP 通常设置更高的阈值（例如 Linksys 品牌 AP 的 2437 字节），这样就会默认不使用分片。</p>
<p>分片有用的原因在于其出错的概率。如果 <strong>误码率（Bit Error Rate， BER）</strong> 为 P， 1 位数据成功交付的概率为 <code>(1-P)</code> ， N 位成功交付的概率为 (1-P)<sup>N</sup> 。随着 N 的增长，这个值逐渐减小。因此，如果我们减小一个帧的大小，理论上可改善错误交付的概率。当然，如果我们将一个 N 位大小的帧分成 K 个分片，我们可发送至少 <code>N/K</code> 个分片。我们给出一个具体的例子，假设要发送一个 1500 字节（12000 位）的帧。如果假设 P= 10<sup>-4</sup> （一个相对较高的误码率），不分片时的成功交付概率为 (1-10<sup>-4</sup>)<sup>12000</sup>=0.301 ，那么只有约 30% 机会将这个帧成功交付，即平均发送三或四次可使它成功接收。</p>
<p>如果我们对同样的例子使用分片，并将分片阈值设置为 500，这时将产生 3 个 4000 位的分片。每个分片成功交付的概率为 (1-10<sup>-4</sup>)<sup>4000</sup> = 0.670。因此，每个分片约有 67% 的机会成功交付。当然，我们必须在交付成功后重组该帧。 3 个分片、 2 个分片、 1 个分片与 0 个分片成功交付的概率分别为 (0.67)<sup>3</sup>= 0.30、 3(0.67)<sup>2</sup>(0.33) = 0.44、 3(0.67)(0.33)<sup>2</sup>= 0.22、 (0.33)<sup>3</sup>=0.04。 因此，虽然所有分片未重传而被成功交付的概率与未分片被成功交付的概率相同，但两个或三个分片被成功交付的机会相对较大。如果发生这种情况，顶多是一个分片需要重传，这比发送 1500 字节的未分片帧显然节省时间（大约三分之一）。当然，每个分片需要花费一些开销，如果误码率实际为 0 ，分片只会因创建更多帧而降低性能。</p>
<p>802.11n 提供的增强功能之一是支持两种形式的帧聚合。一种形式称为<strong>聚合的 MAC 服务数据单元（A-MSDU）</strong>，它可将多个完整的 802.3 （以太网）帧聚合在一个 802.11 帧中。另一种形式称为<strong>聚合的 MAC 协议数据单元（A-MPDU）</strong>，它可将多个具有相同的源、目的和 QoS 的 MPDU 聚合为短帧。图 3-19 描述了两种类型的聚合。</p>
<figure data-type="image" tabindex="19"><img src="https://wenbozhangw.github.io//post-images/1652429598770.png" alt="图 3-19" loading="lazy"></figure>
<p>图 3-19   802.11n 中的帧聚合包括 A-MSDU 和 A-MPDU。 A-MSDU 使用一个 FCS 聚合多个帧。A-MPDU 在聚合的每个 802.11 帧之间使用一个 4 字节的分隔符。每个 A-MPDU 子帧拥有自己的 FCS，并可以分别使用 ACK 确认，以及在必要时重传</p>
<p>对于一次单一的聚合， A-MSDU 方法在技术上更有效率。每个 802.3 头部通常为 14 字节，相对 36 字节的 802.11 MAC 头部更短。因此，仅一个 802.11 MAC 头部对应于多个 802.3 帧，每聚合一个帧最多可节约 22 字节。一个 A-MSDU 可能高达 7935 字节，可容纳 100 多个小（例如 50 字节）的分组，但只能容纳少数（5 个）较大（1500 字节）的数据分组。 A-MSDU 仅对应一个 FCS。更大的 A-MSDU 帧会增大交付出错的概率，由于整个聚合只是针对一个 FCS，因此在出错时将不得不重传整个帧。</p>
<p>A-MPDU 聚合是另一种形式的聚合，多个（最多 64 个） 802.11 帧可聚合起来，每个帧有自己的 802.11 MAC 头部和 FCS，每个帧最多 4095 字节。 A-MPDU 可携带最多 64KB 的数据，足够包含 1000 多个小的分组和大约 40 个较大（1.5KB）的分组。由于每个子帧都携带自己的 FCS，因此可有选择地重传那些出错的子帧。这使得 802.11n （最初在 802.11e）中的块确认功能成为可能，它是一种扩展的确认形式，为发送方提供哪个 A-MPDU 子帧交付成功的反馈信息。这种功能在目的上类似，但在细节上不同，我们将在 TCP （见第 14 章）中介绍选择确认。因此， A-MSDU 提供的聚合类型在无差错网络中传输大量小的分组时可能更有效率，但在实际运行中可能不如 A-MPDU 聚合好 [<a href="#S08">S08</a>] 。</p>
<h3 id="352-省电模式和时间同步功能">3.5.2 省电模式和时间同步功能</h3>
<p>802.11 规范提供一种使站进入有限电源状态的方式，称为<strong>省电模式（PSM）</strong>。 PSM 的设计目标是为了节省电源， STA 可在某个时间关闭无线电收发器电路。在不使用 PSM 时，收发器电路将始终运行，并消耗能量。在使用 PSM 时， STA 的输出帧在帧控制字中设置 1 位。当 AP 发现某些帧的该位被设置时，它会缓冲该帧直到该站需要时为止。 AP 发送信标帧（一种管理帧）提供不同信息，例如 SSID、信道和认证信息。当某个站使用 PSM 时， AP 可向该站提示存在缓冲的帧，只需在发送帧的<strong>帧控制字</strong>中设置一个标识。在某个站执行 PSM 后，它会一直保持这样，直到接收到下一个 AP 信标帧，这时它将苏醒过来，并确定 AP 中是否有为它缓存的帧。</p>
<p>我们应了解和关注 PSM 的使用。虽然它可能延长电池寿命，但是在大多数无线设备中，NIC 不是唯一可节约电源的模块。系统其他部分（例如屏幕和硬盘驱动器）也是电源的主要消耗者，因此总的电池寿命可能不会延长太多。另外， PSM 可能显著影响在帧传输之间空闲期间的吞吐量，时间被过多花费在模式切换上 [<a href="#SHK07">SHK07</a>] 。</p>
<p>在正确的时间（即一个 AP 打算发送一个信标帧时）唤醒 STA 检查等候帧的能力，取决于这个 AP 和它所服务的站对时间的感知。 Wi-Fi 采用<strong>时间同步功能（TSF）</strong>。每个站保持一个 64 位计数器的参考时间（微秒），这个时间与网络中的其他站保持同步。同步保持在 4μs 加 PHY （速率为 1Mb/s 或以上）最大传播延迟之内。这是通过多个站接收一个 TSF 更新（另一个站发送的 64 位计数器副本），并检查其中的值是否比自己的值更大来实现。如果是，接收站将自己的时间更新为更大的值。这种方法可确保时钟总是向前走，但它也会带来一些问题，如果不同站的时钟速率稍有差异，较慢的站就会被最快的站的时钟所同步。</p>
<p>通过将 802.11e （QoS）功能纳入 802.11 中， 802.11 的 PSM 扩展为提供定期批处理缓冲帧功能。这个频率用信标帧的数量来表示。这个功能被称为<strong>自动省电交付模式（APSD）</strong>，它使用 QoS 控制字中的一些子字段。 APSD 对电源有限的设备可能非常有用，因为它们不像传统 802.11 PSM 那样，并不需要在每个信标间隔都被唤醒。相反，它们可选择在自己所选的较长时间内关闭无线电收发器电路。 802.11n 也扩展了 PSM 基本功能，允许一个 STA 装备的多个射频电路（见 3.5.4.2 节 MIMO）共同工作，关闭所有而不是其中一个电路，直到准备好一个帧为止。这被称为<strong>空间复用</strong>省电模式。这个规范还包括称为<strong>省电多重轮询</strong>的增强型 APSD，它提供同时双向（例如，到达 AP 和来自 AP）传输帧的方法。</p>
<h3 id="353-80211-介质访问控制">3.5.3 802.11 介质访问控制</h3>
<p>与有线网络（例如 802.3 局域网）相比，在无线网络中检测“冲突”具有更大挑战性。实际上，介质是相对单一的，无论是集中方式还是分布方式，都需要协同传输，避免多个站同时发送。 802.11 标准采用三种方法控制共享的无线介质，它们分别称为<strong>点协调功能（PCF）</strong>、<strong>分布式协调功能（DCF）<strong>和</strong>混合协调功能（HCF）</strong>。 HCF 被纳入 802.11 规范 [<a href="#802.11-2007">802.11-2007</a>] ，在 802.11e 中增加支持 QoS，它也被用于 802.11n。某些类型的站或 AP 强制实现 DCF，也可选择实现 PCF，但 PCF 使用得并不广泛（因此我们不详细讨论）。相对较新的支持 QoS 的 Wi-Fi 设备通常会实现 HCF，例如 802.11n 的 AP 和更早的 802.11e 的 AP。现在，我们将注意力转移到 DCF 上，并在下面的 QoS 内容中描述 HCF。</p>
<p>DCF 是一种 CSMA/CA 类型，是基于竞争的介质访问方法。它可用于基础设施和 Ad hoc 网络。通过 CSMA/CA，一个站可查看介质是否空闲，如果空闲，它将有机会传输。如果不空闲，它在一段随机的时间内避免发送，直到它再次查看介质是否空闲为止。这个行为与有线局域网中使用的 CSMA/CD 检测方法相似。 802.11 信道仲裁是对 CSMA/CA 的改进，提供优先访问某些站或帧的功能。</p>
<p>802.11 载波侦听能以物理和虚拟方式实现。一个站在准备发送时，通常需要等待一段时间（称为<strong>分布式帧间间隔（DIFS）</strong>），以允许更高优先级的站访问信道。如果信道在 DIFS 期间变得繁忙，该站再次开始一个等待时间。当介质出现空闲时，希望发送数据的站将启动 3.5.3.3 节所述的冲突避免/退避过程。这个过程在一次成功（失败）的传输后，通过一个 ACK 知道数据被接收（或没有接收）后启动。在传输不成功的情况下，经过不同时间（称为<strong>扩展帧间间隔（EIFS）</strong>）启动退避过程。现在，我们将详细地讨论 DCF 实现，包括虚拟和物理载波侦听机制。</p>
<h4 id="3531-虚拟载波侦听-rtscts-和网络分配向量">3.5.3.1 虚拟载波侦听、RTS/CTS 和网络分配向量</h4>
<p>在 802.11 MAC 协议中，虚拟载波侦听机制会检查每个 MAC 帧中的<strong>持续时间</strong>字段。这通过站的侦听而非引导流量来实现。 RTS 和 CTS 帧中都有一个<strong>持续时间</strong>字段，它们像普通帧那样在传输之前可选择是否交换，并估计介质将处于繁忙状态的时间。</p>
<p>发送方基于帧长度、传输速率和 PHY 特性（例如速率等）设置<strong>持续时间</strong>字段。每个站保持一个称为<strong>网络分配向量（NAV）<strong>的本地计数器，它被用于估计介质传输当前帧所需的时间，以及尝试下一次传输之前需等待的时间。当一个站侦听到一个</strong>持续时间</strong>大于自己的 NAV 时，它将自己的 NAV 更新为这个值。由于 RTS 和 CTS 帧中都有<strong>持续时间</strong>字段，如果使用 NAV，在其范围内的任何站（无论是发送方还是接收方）都能看到<strong>持续时间</strong>字段值。 NAV 采用单位时间来维护，并基于本地时钟递减。当本地 NAV 不为 0 时，介质被认为是繁忙的。在接收到一个 ACK 后，本地 NAV 将复位为 0。</p>
<h4 id="3532-物理载波侦听cca">3.5.3.2 物理载波侦听（CCA）</h4>
<p>每个 802.11 PHY 规范（例如，对于不同的频率和无线电技术）需提供一种评估信道是否空闲的功能，它基于能量和波形识别（通常是一个完好的 PLCP）。这个功能称为<strong>空闲信道评估（Clear Channel Assessment， CCA）</strong>，它的实现依赖于 PHY。 CCA 功能是针对 802.11 MAC 的物理载波侦听功能，用于了解介质当前是否繁忙。它通常与 NAV 结合使用，以确定一个站在传输之前是否需要推迟（等待）。</p>
<h4 id="3533-dcf-冲突避免退避过程">3.5.3.3 DCF 冲突避免/退避过程</h4>
<p>在确定某个信道可能空闲时（已到达 NAV 持续时间，并且 CCA 没有提示信道繁忙），一个站在传输之前需推迟访问该信道。由于很多站可能在等待信道变空闲，每个站在发送之前需计算和等待一个<strong>退避时间</strong>。退避时间等于一个随机数和<strong>时隙</strong>的乘积（除非该站已有一个非零的退避时间尝试传输，在这种情况下无须重新计算）。时隙依赖于 PHY，通常是几十微秒。随机数是一个在区间 <code>[0，CW]</code> 中均匀分布的数值，**竞争窗口（CW）**是一个整数，其中包含许多等待时隙，且 <code>aCWmin ≤ CW ≤ aCWmax</code> （该限制由 PHY 定义）。 CW 值的集合从 PHY 指定的常数 aCWmin 开始，以 2 的幂（减 1）增加，直到每个连续传输尝试次数的常数 aCWmax 为止。这样做与以太网中由冲突检测事件引发的退避过程相似。</p>
<p>在无线环境中，冲突检测是不实际的。由于难以发现发送方和接收方同时发送，也难以监听自己之外的传输，因此采用<strong>冲突避免</strong>来代替冲突检测。另外， ACK 是针对单播帧的响应，以确定一个帧是否成功传递。当一个站正确接收一个帧时，在等待一小段时间（称为<strong>短帧间间隔（SIFS）</strong>）后开始传输 ACK，并且不考虑介质的忙碌/空闲状态。这样做不会导致问题，由于 SIFS 的值始终比 DIFS 小，因此该站产生的 ACK 可优先访问信道，以完成接收确认。源站在一定时间内没有接收到 ACK，则意味着一次传输失败。在失败后，源站启动前面讨论的退避过程，并重新尝试发送帧。如果在一定时间（CTStimeout 常数）内没有接收到对较早 RTS 响应的 CTS，则启动同样的过程。</p>
<h4 id="3534-hcf-和-80211en-的-qos">3.5.3.4 HCF 和 802.11e/n 的 QoS</h4>
<p>802.11标准 [<a href="#802.11-2007">802.11-2007</a>] 中的条款 5、 6、 7 和 9 都基于 IEEE 802.11e 工作组的部分工作，常用的术语有 802.11e、Wi-Fi QoS和 WMM（基于Wi-Fi的多媒体）。它们涉及 QoS 功能：修改 802.11 MAC 层和系统接口以支持多媒体应用，例如 IP 语音（VoIP）和流媒体。 QoS 功能实际是否必要，取决于网络层拥塞和应用类型。如果网络利用率较低，可能不必要支持 QoS 的 MAC，虽然其他 802.11e 功能可能有用（例如块确认和 APSD）。在网络利用率和拥塞较高的情况下，需要为 VoIP 等服务提供低抖动交付能力，这时支持 QoS 可能是可取的。这些规范相对较新，支持 QoS 的 Wi-Fi 设备通常比不支持 QoS 的设备更昂贵和更复杂。</p>
<p>QoS 功能引入了新的术语，例如 QoS 站（QSTA）、 QoS 接入点（QAP）和 QoS BSS（QBSS，支持QoS 的 BSS）。在一般情况下，支持 QoS 功能的设备也支持传统的非 QoS 操作。 802.11n “高吞吐量”站（又称为 HTSTA）也是 QSTA。<strong>混合协调功能（HCF）<strong>是一种新的协调功能，支持基于竞争和可控制的信道访问，尽管可控制的信道访问技术很少使用。在 HCF 中，有两种专门的信道访问方法可协同工作：<strong>HFCA 控制信道访问（HCCA）<strong>和更流行的</strong>增强型 DCF 信道访问（EDCA）</strong>，它们分别对应于基于预约和基于竞争的访问。这里也有一些对</strong>准入控制</strong>的支持，它们可在高负载下完全拒绝访问。</p>
<p>EDCA 建立在基本的 DCF 访问之上。通过 EDCA， 8 个<strong>用户优先级（UP）<strong>被映射为 4 个</strong>访问类别（AC）</strong>。用户优先级使用与 802.1d 优先级标记相同的结构，并被编号为 1 至 7 （在 2 和 3 之间还有一个优先级 0），其中 7 为最高优先级。 4 个访问类别分别为背景、尽力而为、视频和音频流量。优先级 1 和 2 用于背景 AC，优先级 0 和 3 用于尽力而为 AC，优先级 4 和 5 用于视频 AC，优先级 6 和 7 用于音频 AC。对于每个 AC， DCF 的一个变种竞争信道访问许可，称为<strong>传输机会（TXOP）</strong>，为较高优先级的流量使用可选的 MAC 参数。在 EDCA 中，很多来自 DCF 的 MAC 参数（例如， DIFS、 aCWmin、 aCWmax）作为配置参数是可调整的。这些值可通过管理帧传输给 QSTA。</p>
<p>HCCA 松散地建立在 PCF 之上，并使用轮询来控制信道访问。它属于同步方式的访问控制，并优先于基于竞争的 EDCA 访问。<strong>混合协调（HC）<strong>位于一个 AP 中，并优先于信道访问分配。在一次传输之前，一个站可为其流量发布一个</strong>流量规范（TSPEC）</strong>，并使用 8 和 15 之间的 UP 值。 HC 可为这种请求分配保留的 TXOP，它被用于基于 EDCA 的帧传输之前的短期控制访问阶段的帧交换。 HC 可拒绝 TXOP 的基于网络管理员设置的管理控制策略的 TSPEC。 HCF 利用前面讨论过的虚拟载波侦听机制和 DCF，以避免基于竞争的站被不基于竞争的访问所干扰。注意，在包括 QSTA 和常规站的网络中，可同时运行 HCF 和 DCF，并在两者之间切换，但 Ad hoc 网络不支持 HC，因此它不处理 TSPEC 和不执行管理控制。这种网络可能仍运行 HCF，但 TXOP 通过基于 EDCA 的竞争来获得。</p>
<h3 id="354-物理层的细节速率-信道和频率">3.5.4 物理层的细节：速率、信道和频率</h3>
<p>目前， [<a href="#802.11-2007">802.11-2007</a>] 标准包括以下较早的修订版：802.11a、 802.11b、 802.11d、 802.11g、802.11h、 802.11i、 802.11j 和 802.11e。 802.11n 标准在 2009 年被采纳为 802.11 的修订版 [<a href="#802.11n-2009">802.11n-2009</a>]。大多数的修订版为 802.11 网络提供额外的调制、编码和工作频率，但 802.11n 还增加了多种数据流和一种聚合多帧方法（见3.5.1.3节）。我们尽量避免详细讨论物理层，这里只是看一下可选的内容。表 3-2 包括 802.11 标准中特别描述的物理层部分。</p>
<center>表 3-2   802.11 标准中描述的物理层部分</center>
<table>
<thead>
<tr>
<th>标准（条款）</th>
<th>速率（Mb/s）</th>
<th>频率范围；调制</th>
<th>信道设置</th>
</tr>
</thead>
<tbody>
<tr>
<td>802.11a（第 17 条）</td>
<td>6、9、12、18、24、36、48、54</td>
<td>5.16GHz ~ 5.35GHz 和 5.725 ~ 5.825GHz；OFDM</td>
<td>37 ~ 168（根据国家不同），20MHz/10MHz/5MHz 信道宽度选项</td>
</tr>
<tr>
<td>802.11b（第 18 条）</td>
<td>1、2 、5.5、11</td>
<td>2.401GHz ~ 2.495GHz；DSSS</td>
<td>1 ~ 14（根据国家不同）</td>
</tr>
<tr>
<td>802.11g（第 19 条）</td>
<td>1、2 、5.5、6、9、11、12、18、24、36、48、54（加 22、23）</td>
<td>2.401GHz ~ 2.495GHz；OFDM</td>
<td>1 ~ 14（根据国家不同）</td>
</tr>
<tr>
<td>802.11n</td>
<td>6.5 ~ 600，很多选项（最多 4 个 MIMO 流）</td>
<td>2.4GHz 和 5GHz 模式，信道宽度 20MHz 或 40MHz；OFDM</td>
<td>1 ~ 13（2.4GHz 频段）；36 ~ 196（5GHz 频段）（根据国家不同）</td>
</tr>
<tr>
<td>802.11y</td>
<td>（与 802.11-2007 相同）</td>
<td>3.650GHz ~ 3.700GHz （需许可）；OFDM</td>
<td>1 ~ 25；36 ~ 64；100 ~ 161（根据国家不同）</td>
</tr>
</tbody>
</table>
<p>第一列给出了标准的原有名称和在 [<a href="#802.11-2007">802.11-2007</a>] 中的当前位置，并增 802.11n 和 802.11y 修订版的细节。在这个表中，需要注意的是， 802.11b/g 工作在 2.4GHz 的**工业、科学和医疗（ISM）<strong>频段， 802.11 仅工作在更高的 5GHz 的</strong>无须许可的国家信息基础设施（U-NII）**频段，而 802.11n 可工作在这两个频段。 802.11y 修订版在美国工作在需要许可的 3.65 ~ 3.70GHz频段。我们应注意的一个重要的实践结论是：802.11b/g 设备与 802.11a 设备不会互操作或干扰，但是如果不认真进行部署， 802.11n 设备可能被任何设备干扰。</p>
<h4 id="3541-信道和频率">3.5.4.1 信道和频率</h4>
<p>监管机构（例如美国联邦通信委员会）将电磁波谱划分为不同频率范围，并分配给世界各地的不同应用。对于每个频率范围及其用途，根据本地政策可能需要或不需要申请许可证。在 802.11 中，多个信道可能以不同方式、不同功率水平工作，这取决于所在地区或国家的监管。 Wi-Fi 信道在某个基本中心频率的基础上以 5MHz 为单位进行编号。例如，信道 36 的基本中心频率为 5.00GHz，则信道 36 的中心频率为 <code>5000 + 36*5 = 5180MHz</code>。虽然信道的中心频率之间以 5MHz 为间隔，但信道宽度可能超过 5MHz（802.11n 高达 40MHz）。因此，信道集中的某些频段内的信道经常重叠。实际上，这意味着一个信道上的传输可能干扰附近信道上的传输。</p>
<p>图 3-20 给出了 802.11b/g 信道在 2.4GHz 的 ISM 频段内的信道与频率映射。每个信道宽度为 22MHz。并非所有信道都可在每个国家合法使用。例如，信道 14 仅被授权在日本使用，信道 12 和 13 被授权在欧洲使用，而美国只能使用信道1 ~ 11。其他国家可能更严格（见 802.11 标准的 Annex J 和修订版）。注意，政策和许可要求可能随时间而改变。</p>
<figure data-type="image" tabindex="20"><img src="https://wenbozhangw.github.io//post-images/1652883012661.png" alt="图 3-20" loading="lazy"></figure>
<p>图 3-20   802.11b 和 802.11g 标准使用 2.4GHz 和 2.5GHz 之间的频段。这个频段被划分为 14 个 22MHz 宽的重叠信道，其中一些子集是否可合法使用取决于所在国家。在同一地区运行多个基站，分配非重叠的信道是可取的做法，例如美国的 1、 6 和 11。只有一个 40MHz 的 802.11n 信道可用于此频段而不会发生重叠</p>
<p>如图 3-20 所示，重叠信道的影响是明显的。例如，一个传输方工作在信道 1 上，它与信道 2、 3、 4 和 5 重叠，但与更高的信道不重叠。在可使用多个接入点的环境中，选择使用哪条信道是很重要的，当同一区域中有多个接入点为多个网络提供服务时，如何选择信道至关重要。在美国，常用方法是同一区域中的 3 个 AP 使用不重叠的信道 1、 6 和 11，信道 11 在美国是无须许可即可使用的最高频率信道。在其他无线局域网也在同一频段运行的情况下，应该由所有受影响的 WLAN 管理员共同规划信道。</p>
<p>如图 3-21 所示， 802.11a/n/y 共享一个有些复杂的信道设置，但提供了更多的不重叠信道（即美国的 12 个无须许可的 20MHz 信道）。</p>
<p>在图 3-21 中，信道以 5MHz 为单位递增，但存在不同的信道宽度：5MHz、 10MHz、20MHz 和 40MHz。 40MHz 信道宽度是 802.11n 的一个选项（见 3.5.4.2 节），可将几个不同所有者的 Wi-Fi 系统聚合为 2 个 20MHz 信道（称为信道绑定）。</p>
<figure data-type="image" tabindex="21"><img src="https://wenbozhangw.github.io//post-images/1652883308062.png" alt="图 3-21" loading="lazy"></figure>
<p>图 3-21   20MHz 信道中的一些可用的 802.11 信道号和中心频率。最常见的无须许可使用的频率范围包括 U-NII 频段，它们均在 5GHz 之上。较低频段被批准可用于大多数国家。 “欧洲”频段被批准用于大多数欧洲国家，高频段被批准用于美国和中国。 802.11a/y 信道的典型宽度为 20MHz，但 802.11n 的信道宽度可能为 40MHz。另外，在日本也可使用窄信道和某些信道（未显示）</p>
<p>对于典型的 Wi-Fi 网络，在 AP 安装过程中需要指定其运行信道，并由用户所在的站修改信道以便连接到 AP。当运行在 Ad hoc 模式时，没有起控制作用的 AP，因此一个站通常需要为 AP 手工配置信道。可用的信道和运行功率可能受限于监管环境、硬件功能，以及所支持的驱动程序软件。</p>
<h4 id="3542-更高吞吐量的-80211802211n">3.5.4.2 更高吞吐量的 802.11/8022.11n</h4>
<p>2009 年年底， IEEE 将 [<a href="#802.11-2007">802.11-2007</a>] 修订为802.11n [<a href="#802.11n-2009">802.11n-2009</a>]。它对 802.11 做了一些重要改变。为了支持更高吞吐量，它采用<strong>多输入多输出（MIMO）<strong>管理</strong>空间流（Spatial Stream）</strong>，即由多个天线同时传输的多个数据流。一个给定信道上最多支持 4 个这种空间流。802.11n 信道宽度可以是 40MHz （使用两个相邻的 20MHz 信道），这是传统 802.11a/b/g/y 信道宽度的两倍。因此，它可将 802.11a/g 的最大传输速率（54Mb/s）提高 8 倍，达到 432Mb/s。802.11n 也提高了单个流的性能，使用一种更高效的调制方案（802.11n采用 MIMO-正交频分复用（OFDM），每个 20MHz 信道最多承载 52 个数据载波，每个 40MHz 信道最多承载 108 个数据载波，代替 802.11a 和 802.11g 中的 48 个），以及一种更有效的转发纠错编码（以编码率 5/6 代替 3/4），将每个流性能提升到 65Mb/s （20MHz 信道）或 135Mb/s （40MHz信道）。通过将<strong>保护间隔</strong>（GI，一个强制的符号之间的空闲时间）从传统的 800ns 减少到 400ns，每个流的最大性能可提高到 72.2Mb/s （20MHz信道）和 150Mb/s （40MHz信道）。通过 4 个空间流的完美协同操作，这样可提供最高 600Mb/s 的传输速率。</p>
<p>802.11n 标准支持大约 77 种调制和编码选项组合，其中包括 8 种对应单个流的选项， 24 种可在所有流中使用的**平等调制（EQM）<strong>选项，以及 43 种可在多个流上使用的</strong>不平等调制（UEQM）<strong>选项。表 3-3 给出了调制和编码方案的一些组合，对应于</strong>调制和编码方案（MCS）**的前 33 个值。更大的值（33 - 76）包括 2 个信道（值 33 - 38）、3 个信道（39 - 52）和 4 个信道（53 - 76）的组合。 MCS 值 32 是一个特殊组合，即 40MHz 信道的两路信号包含相同信息。每行给出了 2 个数据传输速率，一个使用早期的 800ns GI，一个使用较短的 400ns GI 以获得更大传输速率。两个带下划线的值 6Mb/s 和 600Mb/s，分别表示最小和最大吞吐率。</p>
<center>表 3-3   802.11n 的 MCS 值包括平等和不平等调制，不同的 FEC 编码率，使用 20MHz 或 40MHz 信道宽度的 4 个空间流，以及 800ns 或 400ns GI 的组合。77 种组合提供从 6Mb/s 到 600Mb/s 的数据传输速率</center>
<table>
<thead>
<tr>
<th>MCS 值</th>
<th>调制类型</th>
<th>FEC 编码率</th>
<th>空间流</th>
<th>速率（Mb/s）（20MHz）[800/400ns]</th>
<th>速率（Mb/s）（40MHz）[800/400ns]</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>BPSK</td>
<td>1/2</td>
<td>1</td>
<td>6.5/7.2</td>
<td>13.5/15</td>
</tr>
<tr>
<td>1</td>
<td>QPSK</td>
<td>1/2</td>
<td>1</td>
<td>13/14.4</td>
<td>27/30</td>
</tr>
<tr>
<td>2</td>
<td>QPSK</td>
<td>3/4</td>
<td>1</td>
<td>19.4/21.7</td>
<td>40.5/45</td>
</tr>
<tr>
<td>3</td>
<td>16-QAM</td>
<td>1/2</td>
<td>1</td>
<td>26/28.9</td>
<td>54/60</td>
</tr>
<tr>
<td>4</td>
<td>16-QAM</td>
<td>3/4</td>
<td>1</td>
<td>39/43.3</td>
<td>81/90</td>
</tr>
<tr>
<td>5</td>
<td>16-QAM</td>
<td>2/3</td>
<td>1</td>
<td>52/57.8</td>
<td>108/120</td>
</tr>
<tr>
<td>6</td>
<td>16-QAM</td>
<td>3/4</td>
<td>1</td>
<td>58.5/65</td>
<td>121.5/135</td>
</tr>
<tr>
<td>7</td>
<td>16-QAM</td>
<td>5/6</td>
<td>1</td>
<td>65/72.2</td>
<td>135/150</td>
</tr>
<tr>
<td>8</td>
<td>BPSK</td>
<td>1/2</td>
<td>2</td>
<td>13/14.4</td>
<td>27/30</td>
</tr>
<tr>
<td>...</td>
<td>....</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr>
<td>15</td>
<td>64-QAM</td>
<td>5/6</td>
<td>2</td>
<td>130/144.4</td>
<td>270/300</td>
</tr>
<tr>
<td>16</td>
<td>BPSK</td>
<td>1/2</td>
<td>3</td>
<td>19.5/21.7</td>
<td>40.5/45</td>
</tr>
<tr>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr>
<td>31</td>
<td>64-QAM</td>
<td>5/6</td>
<td>4</td>
<td>260/288.9</td>
<td>540/600</td>
</tr>
<tr>
<td>32</td>
<td>BPSK</td>
<td>1/2</td>
<td>1</td>
<td>N/A</td>
<td>6/6.7</td>
</tr>
<tr>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr>
<td>76</td>
<td>64x3/16x1-QAM</td>
<td>3/4</td>
<td>4</td>
<td>214.5/238.3</td>
<td>445.5/495</td>
</tr>
</tbody>
</table>
<p>表 3-3 显示了可用于 802.11n 的各种编码组合，包括<strong>二进制相移键控（BPSK）</strong>、<strong>正交相移键控（QPSK）</strong>，以及各种<strong>正交幅度调制（16-QAM和64-QAM）</strong>。这些调制方案为给定的信道提供更大的传输速率。但是，性能更高和更复杂的调制方案，通常更容易受到噪声干扰。**转发纠错（FEC）**包括一套方法，在发送方引入一些冗余位，用于检测和修改传输过程中的错误。对于 FEC，编码率是可用传输速率与底层信道规定速率之比。例如， 1/2 编码率表示每发送 2 位数据，只有 1 位有效交付。</p>
<p>802.11n 可工作在 3 种模式下。在 802.11n 环境中，可选择所谓的<strong>绿地模式</strong>， PLCP 包含特殊位序列（“训练序列”），它仅被 802.11n 设备获得，不与传统设备进行互操作。为了保持兼容性， 802.11n 提供了 2 种互操作模式。但是，这些模式对纯 802.11n 设备会带来性能损失。一种模式称为<strong>非 HT 模式</strong>，禁止所有 802.11n 功能，但仍与原有设备兼容。这不是一种很有趣的模式，因此我们不再进一步讨论。另一种模式称为 <strong>HT 混合模式</strong>，支持 802.11n 和传统操作，这取决于与哪个站进行通信。 PLCP 给出了向 HT STA 提供 AP 的802.11n 功能和保护传统 STA 所需的信息， PLCP 被修订为包含 HT 和传统信息，并以一个比绿地模式慢的速度传输，以便传统设备来得及处理。在一个传统站使用共享信道时， HT 保护还要求 HTAP 使用自定向 CTS 帧（或 RTS/CTS 帧交换）以传统速率通知传统站。尽管 RTS/CTS 帧是短的，但由于它们是以传统速率（6Mb/s）发送，所以这将显著降低 802.11n WLAN 性能。</p>
<p>在部署一个 802.11n AP 时，应考虑分配适当的信道。在使用 40MHz 信道时， 802.11n AP 应运行在 5GHz 以上的 U-NII 频段， 2.4GHz 的 ISM 频段中根本没有足够的可用频段提供这么宽的信道。一种可选的 BSS 功能称为<strong>分阶段共存操作（PCO）</strong>，允许一个 AP 定期在 20MHz 和 40MHz 信道宽度之间切换，更好地提供 802.11n AP 之间的共存，以一些额外流量代价为附近的传统设备提供服务。最后值得一提的是， 802.11n AP 通常比传统 AP 消耗更多能量。这种比基本的 15W 更高的电源功率，可由 **802.3af 以太网供电（PoE）**系统提供，这意味着需要使用 PoE+ （802.3at 能提供 30W），除非有其他形式的电源（例如一个外接电源）。</p>
<h3 id="355-wi-fi-安全">3.5.5 Wi-Fi 安全</h3>
<p>802.11 网络的安全模型有很大变化。早期， 802.11 采用一种称为**有线等效保密（WEP）**的加密方法。 WEP 后来被证明安全性薄弱，并出现了替换它的需求。工业界通过 <strong>Wi-Fi 保护访问（WPA）<strong>来回应，它使用加密块（见第 18 章的密码学基础知识）代替密钥方式。在 WPA 中，采用一种称为</strong>临时密钥完整性协议（TKIP）<strong>的方案，确保每个帧都用不同密钥加密。它还包括一种称为 Michael 的消息完整性检查，以弥补 WEP 中的主要弱点之一。 WPA 被创建为一个占位符，可通过硬件升级方式使设备支持 WEP 功能。 IEEE 802.11i 工作组制定了一个功能更强的标准，最终被吸收到 [<a href="#802.11-2007">802.11-2007</a>] 的第 8 条，并被工业界称为“WPA2”。WEP 和 WPA 都使用 RC4 加密算法 [<a href="#S96">S96</a>]。 WPA2 使用</strong>高级加密标准</strong>（AES）算法 [<a href="#AES01">AES01</a>]。</p>
<p>我们刚才讨论的加密技术，用于在站和 AP 之间提供隐私保护（假设站拥有访问网络的合法授权）。在使用 WEP、 WPA 或 WPA2 的小规模环境中，授权通常通过预先设置一个共享密钥或密码来实现，它在每个站和 AP 的配置过程中生成。知道这个密钥的用户拥有访问网络的合法授权。这些密钥常用于保护隐私的加密密钥的初始化。这种<strong>预共享密钥（PSK）<strong>具有局限性。例如，管理员为授权用户提供密钥，这可能是相当麻烦的事。如果一个新的用户被授权，必须更换 PSK 并通知所有合法用户。这种方法难以用于有很多用户的环境。因此， WPA 和后期标准支持</strong>基于端口的网络访问控制</strong>标准，称为 802.1x [<a href="#802.1x-2010">802.1x-2010</a>]。它提供了一种在 IEEE 802 局域网（称为 EAPOL，包括 802.3 和 802.11 [<a href="#RFC4017">RFC4017</a>]）中使用<strong>扩展身份验证协议（EAP）</strong>  [<a href="#RFC3748">RFC3748</a>] 的方式。 EAP 可使用多种标准和非标准化的认证协议。它也可用于建立密钥，包括 WEP 密钥。第 18 章将详细讨论这些协议。我们在 3.6 节讨论 PPP 时也会看到 EAP 的使用。</p>
<p>随着 IEEE 802.11i 工作组的工作完成， WPA 和 RC4/TKIP 组合扩展为一个称为 CCMP 的新方案，它被作为 WPA2 的一部分。 CCMP 是基于<strong>计数器模式</strong>（CCM [<a href="#RFC3610">RFC3610</a>]）的 AES ，以确保用于认证和完整性的<strong>密码块链接消息认证码</strong>（CBC-MAC；注意术语MAC在这里的“其他”用途）的安全。 AES 采用 128 位的块和 128 位的密钥。 CCMP 和 TKIP 形成了 Wi-Fi 安全体系结构的基础，称为<strong>强健安全网络（RSN）</strong>，并支持<strong>强健安全网络访问（RSNA）</strong>。早期的一些方法（如 WEP）称为预 RSNA 方法。 RSNA 要求支持 CCMP （TKIP 可选），而 802.11n 标准完全不使用 TKIP。表 3-4 总结了这种复杂情况。</p>
<center>表 3-4   Wi-Fi 安全已从不安全的 WEP 演变到 WPA，再到当前标准的 WPA2 方案</center>
<table>
<thead>
<tr>
<th>名称/标准</th>
<th>密码</th>
<th>密钥流管理</th>
<th>认证</th>
</tr>
</thead>
<tbody>
<tr>
<td>WEP（预 RSNA）</td>
<td>RC4</td>
<td>（WEP）</td>
<td>PSK，（802.1X/EAP）</td>
</tr>
<tr>
<td>WPA</td>
<td>RC4</td>
<td>TKIP</td>
<td>PSK，802.1X/EAP</td>
</tr>
<tr>
<td>WPA2/802.11(i)</td>
<td>CCMP</td>
<td>CCMP，（TKIP）</td>
<td>PSK，802.1X/EAP</td>
</tr>
</tbody>
</table>
<p>在所有情况下，预共享密钥和 802.1X 可用于认证和初始化密钥。 802.1X/EAP 的主要吸引力在于其可管理的认证服务器，它基于 AP 为每个用户提供访问控制决策。出于这个原因，使用 802.1X 的认证有时称为“企业” （例如 WPA 企业）。 EAP 本身可封装各种认证协议，我们将在第 18 章详细讨论这些协议。</p>
<h3 id="356-wi-fi-网状网80211s">3.5.6 Wi-Fi 网状网（802.11s）</h3>
<p>IEEE 正在制定 802.11s 标准，其中包括 Wi-Fi 的<strong>网状网（Mesh）<strong>操作。通过 Mesh 操作，无线站点可用作数据转发代理（像 AP 那样）。在作者编写本书期间（2011 年中期），这个标准仍未完成。 802.11s 草案定义了</strong>混合无线路由协议（HWRP）</strong>，它基于 <strong>Ad hoc 按需距离向量（AODV）<strong>路由 [<a href="#RFC3561">RFC3561</a>] 和</strong>优化链路状态路由（OLSR）<strong>协议 [<a href="#RFC3626">RFC3626</a>] 等 IETF 标准。Mesh 站（Mesh STA）是一种 QoS 站，它可能参与 HWRP 或其他路由协议，但兼容节点必须包括 HWRP 实现和相关</strong>通话时间链路度量</strong>。 Mesh 节点使用 EDCA 来协同工作，或使用一种可选的称为 <strong>Mesh 确定性访问</strong>的协同功能。 Mesh 点（MP）是与邻居形成 Mesh 连接的那些节点。那些包含 AP 功能的 Mesh 点称为 Mesh AP （MAP）。常规 802.11 站可使用 AP 或 MAP 访问无线局域网的其他部分。</p>
<p>802.11s 草案为 RSNA 制定了一种可选的新安全方案，称为基于对等同时认证（SAE）的认证 [<a href="#SAE">SAE</a>]。这种安全协议与其他协议有些区别，它并不需要一个特定的发起者和响应者之间的操作同步。相反，所有站都被平等对待，先发现其他站的任何站可启动一次安全交换（这可能导致两个站同时启动一次交换）。</p>
<hr>
<h2 id="36-点到点协议">3.6 点到点协议</h2>
<p>PPP 表示点到点协议 [<a href="#RFC1661">RFC1661</a>] [<a href="#RFC1662">RFC1662</a>] [<a href="#RFC2153">RFC2153</a>] 。这是一种在串行链路上传输 IP 数据报的流行方法，从低速的拨号调制解调器到高速的光链路 [<a href="#RFC2615">RFC2615</a>]。它被一些 DSL 服务供应商广泛部署，也可分配 Internet 系统的参数（例如，最初的 IP 地址和域名服务器；见第 6 章）。</p>
<p>PPP 实际上是一个协议集合，而不是一个单一的协议。它支持建立链接的基本方法——称为<strong>链路控制协议（Link Control Protocol， LCP）</strong>，以及一系列 NCP 协议，在 LCP 建立了基本链路之后，用于为各种协议（包括 IPv4、 IPv6 和非 IP 协议）建立网络层链路。一些相关标准涉及对 PPP 的压缩和加密控制，以及在链接建立后的一些认证方法。</p>
<h3 id="361-链路控制协议">3.6.1 链路控制协议</h3>
<p>PPP 的 LCP 用于在点到点链路上建立和维护低层的双方通信路径。因此， PPP 操作只需关注一条链路的两端，它不需要像以太网和 Wi-Fi 的 MAC 层协议那样处理共享资源访问的问题。</p>
<p>PPP 通常对底层的点到点链路有最低要求，LCP 更是这样。链路必须支持双向操作（LCP 使用的确认），以及异步或同步操作。通常， LCP 使用简单的位级别帧格式，基于<strong>高级数据链路控制（HDLC）<strong>建立链路协议。在 PPP 设计时， HDLC 就已建立了一种良好的帧格式 [<a href="#ISO3309">ISO3309</a>] [<a href="#ISO4335">ISO4335</a>] 。 IBM 将它修改为</strong>同步数据链路控制（SDLC）</strong>，在其专用的**系统网络体系结构（SNA）**协议族中用作链路层协议。 HDLC 协议还用作 802.2 中 LLC 标准的基础，并最终被用于 PPP。 图 3-22 显示了这种格式。</p>
<figure data-type="image" tabindex="22"><img src="https://wenbozhangw.github.io//post-images/1652887335410.png" alt="图 3-22" loading="lazy"></figure>
<p>图 3-22   PPP 基本帧格式借用了 HDLC 的格式。它包括一个协议标识符、有效载荷区域，以及 2 或 4 字节的 FCS。其他字段是否存在取决于压缩选项</p>
<p>在通常情况下， PPP 帧格式类似于图 3-22 所示的 HDLC 帧，由 2 个 1 字节的包含固定值 <code>0x7E</code> 的<strong>标志</strong>字段“包围” 。点到点链路的两个端点使用这些字段来发现一个帧的开始和结束。如果 <code>0x7E</code> 值出现在帧内部，这时会带来一个小问题。它可通过两种方式来处理，这取决于 PPP 工作在异步还是同步链路上。对于异步链路， PPP 使用<strong>字符填充</strong>（也称为字节填充）。如果标志字符出现在帧中其他地方，则用 2 字节序列 <code>0x7D5E</code> （ <code>0x7D</code> 称为“ppp转义字符”）替换。如果转义字符本身出现在帧中，则用 2 字节序列 <code>0x7D5D</code>  替换。因此，接收方用 <code>0x7E</code> 替换接收的 <code>0x7D5E</code> ，并用 <code>0x7D</code> 替换接收的 <code>0x7D5D</code>。 在同步链路（例如 T1 线路、 T3 线路）上， PPP 使用<strong>位填充</strong>。注意，标志字符的位模式为 <code>01111110</code> （连续 6 个 1 的位序列），在除了标志字符之外的任何地方，位填充在 5 个连续 1 之后填充一个 0。这样做意味着，发送的字节可能超过 8 位，但这通常是正常的，因为低层串行处理硬件能去掉填充的比特流，并将它恢复成未填充时的样子。</p>
<p>在第一个标志字段之后， PPP 采用 HDLC 的<strong>地址</strong>（Addr）和控制字段。在 HDLC 中，地址字段用于指定哪个站正在处理，但是由于 PPP 只关心一个目的地，这个字段总是被设置为 <code>0xFF</code> （所有站）。 HDLC 控制字段用于指示帧序列和重传行为。由于这些链路层的可靠性功能通常不是由 PPP 实现，所以控制字段设置为固定值 <code>0x03</code>。 由于地址和控制字段在 PPP 中都是固定的常数，所以在传输过程中经常通过一个称为**地址和控制字段压缩（ACFC）**的选项来省略它们，该选项实质上是消除了这两个字段。</p>
<pre><code>注意   链路层网络应提供多少可靠性，多年来一直存在相当大的争议。在以太网
中，在放弃之前可尝试重传多达 16 次。通常， PPP 被配置为不重传，尽管确实
有增加重传的规范 [RFC1663]。折中方案是巧妙的，但它依赖于携带的流量类型。
[RFC3366] 详细讨论了要考虑的有关因素。
</code></pre>
<p>PPP 帧的<strong>协议</strong>字段表明携带的数据类型。在一个 PPP 帧中，可携带多种不同类型的协议。正式列表和用于<strong>协议</strong>字段的分配号显示在“点到点协议字段分配”文档中 [<a href="#PPPn">PPPn</a>] 。根据 HDLC 规范，协议号的分配方式为：高位字节的最低有效位为 0，低位字节的最低有效位为1。 <code>0x0000 ~ 0x3FFF</code> （十六进制）范围内的值表示网络层协议， <code>0x8000 ~ 0xBFFF</code> 范围内的值表示 NCP 的相关数据。 <code>0x4000 ~ 0x7FFF</code> 范围内的值用于 NCP 不相关的“很少使用的”协议。 <code>0xC000 ~ 0xEFFF</code> 范围内的值表示控制协议，例如 LCP。在某些情况下，如果**协议字段压缩（PFC）**选项在链路建立时协商成功，<strong>协议</strong>字段可被压缩为 1 字节。 <code>0x0000 ~ 0x00FF</code> 范围内的协议号适用于包括大多数流行的网络层协议在内的协议。注意， LCP 分组总是使用 2 字节的未压缩格式。</p>
<p>PPP 帧的最后部分包含一个 16 位的 FCS（一个 CRC16，生成多项式为 <code>10001000000100001</code>），涵盖除 FCS 字段本身和标志字节之外的整个帧。注意， FCS 的值涵盖任何字节或位被填充之前的帧。 LCP 选项（见 3.6.1.2 节）可将 CRC 从 16 位扩展到 32 位。在这种情况下，可采用与前面提到的以太网相同的 CRC32 多项式。</p>
<h4 id="3611-lcp-操作">3.6.1.1 LCP 操作</h4>
<p>LCP 在基本 PPP 分组之上进行了简单的封装。如图 3-23 所示。</p>
<figure data-type="image" tabindex="23"><img src="https://wenbozhangw.github.io//post-images/1652888191158.png" alt="图 3-23" loading="lazy"></figure>
<p>图 3-23   LCP 分组采用很普通的格式，能识别封装数据的类型和长度。 LCP 帧主要用于建立 PPP 链路，这种格式已成为很多网络控制协议的基础</p>
<p>LCP 的 PPP 协议字段值始终是 <code>0xC021</code>，它不能用 PFC 删除，以免产生歧义。<strong>标识</strong>字段是由 LCP 请求帧的发送方提供的序列号，并随着每个后续消息进行递增。在生成一个回复（ACK、 NACK 或 REJECT 响应）时，这个字段通过复制响应分组请求中包含的值来构造。采用这种方式，请求方可通过匹配标识符来识别相应请求的应答。<strong>代码</strong>字段给出了请求或响应的操作类型：配置请求（<code>0x01</code>）、配置 ACK （<code>0x02</code>）、配置 NACK （<code>0x03</code>）、配置 REJECT（<code>0x04</code>）、终止请求（<code>0x05</code>）、终止 ACK （<code>0x06</code>）、代码 REJECT（<code>0x07</code>）、协议REJECT（<code>0x08</code>）、回送请求（<code>0x09</code>）、回送应答 （<code>0x0A</code>）、放弃请求 （<code>0x0B</code>）、标识（<code>0x0C</code>）和剩余时间（<code>0x0D</code>）。 ACK 消息通常表明接受一组选项， NACK 消息用建议选项表明部分拒绝。 REJECT 消息完全拒绝一个或多个选项。拒绝代码表明前一个分组包含的某些字段值未知。长度字段给出了 LCP 分组的字节长度，它不能超过链路的<strong>最大接收单元（MRU）</strong>，我们稍后讨论一种建议的最大帧限制。注意，长度字段是 LCP 协议的一部分；PPP 协议通常不提供这种字段。</p>
<p>LCP 的主要工作是使一条点到点链路达到最低要求。<strong>配置</strong>消息使链路两端开始基本配置过程，并建立商定的选项。<strong>终止</strong>消息用于在完成后清除一条链路。 LCP 也提供了前面提到的一些附加功能。<strong>回送请求/应答</strong>消息可由 LCP 在一条活跃链路上随时交换，以验证对方的操作。<strong>放弃请求</strong>消息可用于性能测试，指示对方丢弃没有响应的分组。<strong>标识</strong>和<strong>剩余时间</strong>消息用于管理目的：了解对方的系统类型，指出链路保持建立的时间（例如出于管理或安全原因）。</p>
<p>从历史上来看，如果一个远程工作站处于<strong>环回模式</strong>（或者说“回路”），这时点到点链路会出现一个常见问题。电话公司的广域数据线路有时会为了测试而设置成环回模式，由一方发送的数据直接由另一方返回。虽然这可能对线路测试有用，但它对数据通信完全没有帮助，所以 LCP 包括一种发送<strong>魔术数字</strong>（由发送方选择的任意数字）的方式，并查看是否立即返回相同类型的消息。如果是的话，该线路被检测为处于回路，并可能需要进行维护。</p>
<p>为了对 PPP 链路建立和选项协商有一个更好的认识，图 3-24 显示了一个简化的分组交换时间表和一个简化的状态机（在链路两端实现）。</p>
<p>一旦底层协议表明一个关联变为活跃（例如调制解调器检测到载波），则认为这个链路已被建立。链路质量测试包含链路质量报告和确认交换（见 3.6.1.2 节），它也可以在此期间完成。如果链接需要认证（这是常见的），例如当拨号到一个 ISP 时，可能需要一些额外的信息交换，以认证链路上的一方或双方的身份。当底层协议或硬件表明一个关联已停止（例如载波消失），或发送一个链路终止请求，并从对方接收到一个终止响应，则认为这个链路已被终止。</p>
<figure data-type="image" tabindex="24"><img src="https://wenbozhangw.github.io//post-images/1652888802627.png" alt="图 3-24" loading="lazy"></figure>
<p>图 3-24   LCP 用于建立 PPP 链路和各方商定选项。典型的交换过程包括一对包含选项列表的配置请求和配置确认、一个认证交换、数据交换（未画出）和一个终止交换。因为 PPP 是一个包括很多部分的通用协议，所以在一条链路建立和终止之间可能发生很多其他类型的操作</p>
<h4 id="3612-lcp-选项">3.6.1.2 LCP 选项</h4>
<p>当 LCP 建立一条由一个或多个 NCP 使用的链路时，可以对一些选项进行协商。我们将讨论两种或更多的常见情况。**异步控制字符映射（ACCM）**或简称“ asyncmap”选项定义哪些控制字符（即 <code>0x00 ~ 0x1F</code> 范围内的 ASCII 字符）需要被“转义”为 PPP 操作。转义一个字符表示不发送这个字符的真实值，而将 PPP 转义字符（<code>0x7D</code>）放在控制字符原始值和 <code>0x2D</code> 异或形成的值之前。例如， XOFF 字符（<code>0x13</code>）将转换为（<code>0x7D33</code>）发送。 ACCM 用于控制字符可能影响底层硬件操作的情况。例如，如果软件流控制能够使用 XON/XOFF 字符，而 XOFF 字符未经转义就通过链路传输，则硬件直到看到一个 XON 字符才停止数据传输。asyncmap 选项通常是一个 32 位的十六进制数，其中第 n 个最低有效位被设置为 1 ，表示值为 n 的控制字符应被转义。因此， asyncmap 为 <code>0xffffffff</code> 表示转义所有控制字符，为 <code>0x00000000</code>表示不转义任何控制字符，为 <code>0x000A0000</code> 表示转义 XON （<code>0x11</code>）和 XOFF （<code>0x13</code>）。虽然 <code>0xffffffff</code> 是默认值，但当前很多链路可在 asyncmap 被设置为 <code>0x00000000</code> 时安全运行。</p>
<p>由于 PPP 缺少一个长度字段，并且串行线路通常不提供帧封装，所以在理论上对一个 PPP 帧的长度没有硬性限制。实际上，最大帧大小通常由 MRU 指定。当一台主机指定一个 MRU 选项（<code>0x01</code>）时，它要求对方不发送比 MRU 选项提供的值更长的帧。 MRU 值是数据字段的字节长度，它不计算其他 PPP 开销字段（即协议、 FCS、标志字段）。它的典型值是 1500 或 1492，但也可能多达 65535。 1Pv6 操作需要的长度最小为 1280。 PPP 标准要求具体实现能接收最大 1500 字节的帧， MRU 更多的是建议对方选择帧大小，而不是硬性限制帧大小。当小分组和大分组在同一条 PPP 链路上交错传输时，较大分组可能占用一条低带宽链路的大部分带宽，并影响小分组的正常传输。这可能导致抖动（延迟变化），对交互式应用（例如远程登录和 VoIP）产生负面影响。配置较小的 MRU （或 MTU）有助于缓解这个问题，但会产生更大的开销。</p>
<p>PPP 支持一种交换链路质量报告信息的机制。在选项协商期间，可能包括一个包含所请求的特定质量协议的配置信息。选项中的第 16 位被保留给特定协议，但最常见的是一个包括**链路质量报告（LQR）**的 PPP 标准 [<a href="#RFC1989">RFC1989</a>] ，它在 PPP 协议字段中使用值 <code>0xC025</code>。如果启用该选项，则要求对方按某个周期间隔提供 LQR。 LQR 请求之间的最大周期间隔被编码为一个 32 位数字，它被保存在配置选项中，并以 1/100 秒为单位表示。对方可能比这个要求更频繁地生成 LQR。LQR 包括以下信息：一个魔术数字、发送和接收的分组数和字节数、出错的输入分组数和丢弃的分组数，以及交换的 LQR 总数。在一个典型的实现中，允许用户设置对方发送 LQR 的频繁程度。如果链路质量无法满足某些配置阈值，有些实现也提供了终止链路的方法。 LQR 可在 PPP 链路进入建立状态后请求。每个 LQR 被赋予一个序列号，因此它能确定一段时间内的趋势，甚至在 LQR 重新排序时也能确定。</p>
<p>很多 PPP 实现支持一种<strong>回叫</strong>功能。在一次典型的回叫建立过程中， PPP 拨号回叫客户端呼叫 PPP 回叫服务器，并提供认证信息，而服务器断开连接并回叫客户端。在呼叫费用不对称或对于某些安全级别的情况下，这种做法可能是有用的。 LCP 选项针对用于协商回叫的协议，该选项值为 <code>0x0D</code>  [<a href="#RFC1570">RFC1570</a>]。如果许可，**回叫控制协议（CBCP）**完成协商。</p>
<p>PPP 使用的一些压缩和加密算法在处理时需要一定的最小字节数，称为<strong>块大小</strong>。在数据不够长的情况下，通过填充增加数据长度，达到一个甚至多个块的大小。如果存在填充，它通常位于数据区后面，并位于 PPP FCS 字段之前。一种填充方法称为<strong>自描述填充</strong> [<a href="#RFC1570">RFC1570</a>]，它将填充值变为非零值。这时，每个字节获得填充区域的偏移量值。因此，填充的第一个字节值为 <code>0x01</code>，最后一个字节包含填充字节数。最多支持 255 字节的填充。自描述填充选项（类型 10）用于让对方了解填充类型和<strong>最大填充值（MPV）</strong>，它是这个关联允许的最大填充值。由于基本 PPP 帧缺少一个明确的长度字段，因此一个接收方可使用自描述填充，以确定应从接收的数据区删除多少填充字节。</p>
<p>为了减小每个帧包含一个头部的固定开销，提出了一种将多个不同协议的有效载荷聚合成 PPP 帧的方法，称为 PPPMux [<a href="#RFC3153">RFC3153</a>] 方法。主要 PPP 头部的协议字段被设置为聚合帧（<code>0x0059</code>），然后每个有效载荷块被插入帧中。通过在每个有效载荷块之前插入 1 ~ 4 字节的子帧头部来实现。在子帧头部中， 1 位（称为 PFF）说明子帧头部中是否包含协议字段，1 位（称为 LXT）说明后面的长度字段是 1 字节还是 2 字节。除此之外， 1 或 2 字节的协议 ID 使用与外部的 PPP 头部相同的值和压缩方法。在子帧与默认 PID （该 PID 在配置阶段通过 **PPPMux 控制协议（PPPMuxCP）**建立）匹配时， PFF 可以为 0 （意味着不存在 PID 字段）。</p>
<p>PPP 帧格式如图 3-19 所示，普通 PPP/HDLC 的 FCS 可以是 16 或 32 位。默认的 FCS 为 16 位，但 32 位的 FCS 值可通过 32 位的 FCS 选项来启用。其他的 LCP 选项包括使用 PFC 和 ACFC，以及认证算法的选择。</p>
<p>国际化 [<a href="#RFC2484">RFC2484</a>] 提供了一种使用语言和字符集的表示方式。字符集是一个来自“字符集注册表” [<a href="#IANA-CHARSET">IANA-CHARSET</a>] 的标准值，并从 [<a href="#RFC5646">RFC5646</a>] [<a href="#RFC4647">RFC4647</a>] 的列表中选择语言。</p>
<h3 id="362-多链路-ppp">3.6.2 多链路 PPP</h3>
<p>PPP 的一个特殊版本称为<strong>多链路PPP （MP）</strong> [<a href="#RFC1990">RFC1990</a>]，可用于将多条点到点链路聚合为一条链路。这种想法与前面讨论过的链路聚合相似，并被用于多个电路交换信道（例如 ISDNB 信道）的聚合。 MP 包含一个特殊的 LCP 选项，表示支持多链路，以及一个用于多链路上 PPP 帧分片与重组的协商协议。一条聚合链路（称为一个<strong>捆绑</strong>）可作为一条完整的虚拟链路来操作，并包含自己的配置信息。链路捆绑由大量<strong>成员链路</strong>组成。每个成员链路可能有自己的选项集。</p>
<p>实现 MP 的典型方法是使分组轮流经过各个成员链路传输。这种方法称为<strong>银行柜员算法</strong>，它可能导致分组重新排序，可能为其他协议带来不良的性能影响。 （例如，虽然 TCP/IP 可以正确处理重新排序后的分组，但也可能不如没有重新排序处理得好。） MP 在每个分组中添加一个 2 ~ 4 字节的<strong>序列头部</strong>，而远程 MP 接收方的任务是重建正确的顺序。图 3-25 显示了这种数据帧。</p>
<figure data-type="image" tabindex="25"><img src="https://wenbozhangw.github.io//post-images/1652953897257.png" alt="图 3-25" loading="lazy"></figure>
<p>图 3-25   一个 MP 分片包含一个序列头部，允许在一个多链路捆绑的远端对分片重新排序。这个头部支持 2 种格式：短头部（2 字节）和长头部（4 字节）</p>
<p>在图 3-25 中，我们看到一个 MP 分片的开始分片（B）、结束分片（E）位字段和<strong>序列号</strong>字段。这里，需要注意的是长格式（4 字节用于分片信息）和短格式（2 字节用于分片信息）。在选项协商阶段，  LCP 的<strong>短序列号</strong>选项（类型 18）用于选择使用的格式。如果一个帧没有被分片，但使用这种格式传输，则 B 和 E 位都被置位，表明该分片是第一个和最后一个（即它是整个帧）。否则，第一个分片的 B、 E 位组合被设置为 <code>10</code>，最后一个分片的 B、 E位 组合被设置为 <code>01</code> ，它们之间的所有分片被设置为 <code>00</code>。序列号给出相对第一个分片的分组号偏移量。</p>
<p>MP 使用一个称为多链路<strong>最大接收重构单元</strong>（MRRU，类型 18）的 LCP 选项，它可将一系列更大的 MRU 应用于捆绑中。大于成员链路 MRU 的帧仍被允许通过这个 MP 链路，直到达到这个值的上限为止。</p>
<p>由于一个 MP 捆绑可能跨越多条成员链路，因此需要一种方法来确定成员链路属于同一捆绑。同一捆绑中的成员链路由 LCP <strong>端点鉴别</strong>（类型 19）选项识别。端点鉴别可使用电话号码、从 IP 或 MAC 地址中提取的数字，以及其他可管理的字符串。除了每个成员链路的常见内容，对这个选项的格式没有多少限制。</p>
<p>建立 MP 的基本方法定义在 [<a href="#RFC1990">RFC1990</a>] 中，希望各个成员链路可对称使用，相近数量的分片被分配到号码固定的每条链路上。为了实现更复杂的分配， [<a href="#RFC2125">RFC2125</a>] 中规定了<strong>带宽分配协议（BAP）<strong>和</strong>带宽分配控制协议（BACP）</strong>。 BAP 用于为一个捆绑动态添加或删除链路，而 BACP 用于交换如何使用 BAP 添加或删除链路的信息。这种功能有助于实现<strong>按需带宽（BOD）</strong>。在一些需要分配固定资源以满足应用（例如一定数量的电话连接）对带宽需求的网络中， BOD 通常需要监测流量，在应用需求高时创建新的连接，以及在应用需求低时删除连接。在某些开销和连接数量相关的情况下，这种功能是有用的。</p>
<p>BAP/BACP 使用一种新的<strong>链路鉴别</strong> LCP 选项（LCP 选项类型为 23）。这个选项包含一个 16 位的数字值，一个捆绑中的每条成员链路有不同的值。它被 BAP 用于确定需要添加或删除哪些链路。在一条 PPP 链路的网络阶段，每个捆绑都需要使用 BACP 协商。它的主要目的是找出<strong>首选对端</strong>。也就是说，如果在多个对端之间同时建立多个捆绑时，将会优先为首选对端分配成员链路。</p>
<p>BAP 包括 3 种分组类型：请求、响应和标识。请求用于向一个捆绑添加一条链路，或从一个捆绑中删除一条链路。标识用于为原始或被确认的请求返回结果。响应是对这些请求的 ACK 或 NACK。更多细节见 [<a href="#RFC2125">RFC2125</a>] 。</p>
<h3 id="363-压缩控制协议">3.6.3 压缩控制协议</h3>
<p>从历史上来看， PPP 是相对较慢的拨号调制解调器使用的协议。因此，针对 PPP 链路上压缩后发送数据已提出一些方法。压缩类型是不同的，无论是调制解调器硬件支持的压缩类型（例如 V.42bis、 V.44），还是我们以后讨论的协议头部压缩。目前，有几个压缩选项可选。可在一条 PPP 链路的两个方向做出选择， LCP 可协商一个使<strong>压缩控制协议（CCP）</strong> [<a href="#RFC1962">RFC1962</a>] 生效的选项。 CCP 的作用就像 NCP （见 3.6.5 节），只不过在 LCP 链路建立交换阶段指明压缩选项时才开始处理配置压缩细节。</p>
<p>CCP 在行为上很像 NCP，仅在链路进入网络状态时协商。它使用与 LCP 相同的分组交换过程和格式（除协议字段被设置为 <code>0x80FD</code> 之外），另外还有一些特殊选项，并对常见的<strong>代码</strong>字段值（1 ~ 7）定义了 2个 新的操作：复位请求（<code>0x0e</code>）和复位确认（<code>0x0f</code>）。如果在一个压缩帧中检测到一个错误，复位请求可用于要求对方复位压缩状态（例如字典、状态变量、状态机等）。在复位后，对方响应一个复位确认。</p>
<p>一个或多个压缩帧可作为一个 PPP 帧的一部分（即包括 LCP 数据和可能的填充部分）。压缩帧携带的<strong>协议</strong>字段值为 <code>0x00FD</code>，但是如何指明存在多个压缩帧，这依赖于使用的特定压缩算法（见 3.6.6 节）。当 CCP 与 MP 结合使用时，既可用于一个捆绑，也可用于多条成员链路的某些组合。如果只用于成员链路，<strong>协议</strong>字段设置为 <code>0x00FB</code> （单个的链路压缩数据报）。</p>
<p>CCP 可使用十几个压缩算法之一 [<a href="#PPPn">PPPn</a>] 。大多数算法是官方标准的 IETF 文档，虽然它们可能已在 RFC 中加以描述（例如， [<a href="#RFC1977">RFC1977</a>] 描述了 BSD 压缩方案， [<a href="#RFC2118">RFC2118</a>] 描述了 Microsoft <strong>点对点压缩协议</strong>（MPPC））。如果使用压缩， PPP 帧在进一步处理之前需要重构，因此高层的 PPP 操作通常不关心压缩帧的细节。</p>
<h3 id="364-ppp-认证">3.6.4 PPP 认证</h3>
<p>在一条 PPP 链路处于网络状态之前，通常有必要使用某种<strong>认证</strong>（身份验证）机制，以识别建立链路的对方身份。基本的 PPP 规范默认不提供认证，因此图 3-24 中的认证交换在这种情况下不会出现。但是，某种形式的认证在多数时候是需要的，一些经过多年演变的协议被用于应对这种情况。在本章中，我们仅从高层的角度展开讨论，并将细节留给关于安全的章节（第 18 章）。与不提供认证相比，最简单、安全性最低的认证方案是<strong>密码认证协议（PAP）</strong>。这种协议非常简单，一方请求另一方发送一个密码。由于该密码在 PPP 链路上未加密传输，窃听者在线路上可轻易捕获密码并使用它。由于这个重大的漏洞，不建议使用 PAP 进行认证。 PAP 分组像 LCP 分组那样编码，协议字段值设置为 <code>0xC0230</code>。</p>
<p><strong>查询——握手认证协议（CHAP）</strong> [<a href="#RFC1994">RFC1994</a>] 提供了一种更安全的认证方法。在使用 CHAP 时，一个随机值从一方（称为认证方）发送到另一方。响应通过一种特殊的<strong>单向</strong>（即不可逆）功能，将一个随机值和一个共享密钥（通常由密码生成）结合形成响应中的一个数字。在接收到这个响应之后，认证方能更可靠地验证对方密钥是否正确。这个协议在链路上不会以明文（未加密）形式发送密钥或密码，因此窃听者难以了解相关信息。由于每次使用不同的随机值，每个查询/响应的结果会改变，即使一个窃听者有可能捕捉到这个值，也无法通过重新使用（回放）来欺骗对方。</p>
<p>EAP [<a href="#RFC3748">RFC3748</a>] 是一个可用于各种网络的认证框架。它支持很多（约 40 个）不同的认<br>
证方法，从简单密码（例如 PAP 和 CHAP）到更可靠的认证类型（例如智能卡、生物识别）。EAP 定义了一种携带各种认证的消息格式，但需要额外的规范定义 EAP 消息如何在特定的链路上传输。</p>
<p>当 EAP 被用于 PPP 时，前面讨论过的基本认证方法不变。 EAP 不是在链路建立（LCP 建立）阶段协商一种认证方法，认证操作将被推迟到认证状态（网络状态的前一个状态）。这允许更多信息类型用于影响**远程访问服务器（RAS）**的访问控制决策。当某种标准的协议用于执行各种认证机制，网络访问服务器可能无须处理 EAP 消息内容，但可依靠其他基础设施的认证服务器（例如 RADIUS 服务器 [<a href="#RFC2865">RFC2865</a>] ）确定访问控制决策。这是当前的企业网和 ISP 设计中的首选方案。</p>
<h3 id="365-网络控制协议">3.6.5 网络控制协议</h3>
<p>虽然多种 NCP 可用于一条 PPP 链路（甚至同时），但我们将关注支持 IPv4 和 IPv6 的 NCP。 对于 IPv4， NCP 被称为<strong>IP控制协议（IPCP）</strong> [<a href="#RFC1332">RFC1332</a>] 。对于 IPv6， NCP 被称为 IPV6CP [<a href="#RFC5072">RFC5072</a>] 。在 LCP 完成链路建立和认证之后，该链路每端都进入网络状态，并使用一个或多个 NCP （例如典型的是一个 IPCP）进行网络层的相关协商。</p>
<p>IPCP （针对 IPv4 的标准 NCP）可用于在一条链路上建立 IPv4 连接，以及配置 <strong>Van Jacobson 头部压缩（VJ 压缩）</strong> [<a href="#RFC1144">RFC1144</a>] 。 IPCP 分组在 PPP 状态机进入网络状态之后交换。IPCP 分组使用与 LCP 相同的分组交换机制和分组格式，除非协议字段被设置为 <code>0x8021</code>，并且代码字段被限制在范围 0 ~ 7。代码字段的值对应于消息类型：特定供应商（见 [<a href="#RFC2153">RFC2153</a>] ）、配置请求、配置 ACK、配置 REJECT、终止请求、终止 ACK和代码 REJECT。 IPCP 可协商一系列选项，包括 IP 压缩协议（2）、 IPv4 地址（3）和移动 IPv4 （4） [<a href="#RFC2290">RFC2290</a>]。其他选项可用于获得主要和次要的域名服务器（见第 11 章）。</p>
<p>IPV6CP 使用与 LCP 相同的分组交换机制和分组格式，但它有两种不同的选择：接口标识符和 IPv6 压缩协议。接口标识符选项用于传输一个 64 位的 IID 值（见第 2 章），它作为形成一个链路本地 IPv6 地址的基础。由于它仅在本地链路上使用，因此不需要具有全球唯一性。这通过在 IPv6 地址的高位使用标准链路本地前缀，在低位设置某种功能的接口标识符来实现。这里模拟了 IPv6 自动配置过程（见第 6 章）。</p>
<h3 id="366-头部压缩">3.6.6 头部压缩</h3>
<p>PPP 拨号线路的速率一直较慢（54000b/s 或更少），很多小的分组通常使用 TCP/IP （例如 TCP 确认，见第 15 章）。这些分组大部分包含 TCP 和 IP 头部，同一 TCP 连接上的分组之间变化不大。其他高层协议的行为相似。因此，压缩（或消除）高层协议头部是一种有用的方法，这样以来就可在相对较慢的点到点链路上传输更少字节。现代的压缩或消除头部方法一直在随着时间演变。我们将从前面提到的 VJ 压缩开始，按时间顺序讨论它们。</p>
<p>在 VJ 压缩中，部分高层（TCP 和 IP）头部被 1 字节的连接标识符代替。 [<a href="#RFC1144">RFC1144</a>] 讨论了这种方法的起源，它最初来源于一种旧的、称为 CSLIP （压缩串行线路 IP）的点到点协议。一个典型 IPv4 头部的长度是 20 字节，一个没有选项的 TCP 头部的长度也是 20 字节。因此，一个常见的 TCP/IPv4 头部组合是 40 字节，并且很多字段在分组间没有变化。另外，很多字段在分组间只有很小或有限的变化。如果不变的值通过一条链路（或一段时间内）传输并被保存在一张表中，则在后续分组中可用一个小的索引代替该值。变化有限的值可以仅编码差异部分（即仅发送变化的部分）。因此，整个 40 字节头部通常可有效压缩到 3 或 4 字节。这样可显著提高在低速链路上的 TCP/IP 性能。</p>
<p>头部压缩的下一步演化简称为 IP 头部压缩 [<a href="#RFC2507">RFC2507</a>] [<a href="#RFC3544">RFC3544</a>] 。它提供了一种压缩多个分组头部的方式，使用 TCP 或 UDP 传输层协议，以及 IPv4 或 IPv6 网络层协议。这种技术是 VJ 压缩技术的一种逻辑上的扩展，可用于多种协议以及 PPP 链路之外的其他链路。 [<a href="#RFC2507">RFC2507</a>] 指出了底层链路层的一些强大的差错检测机制的必要性，因为，如果压缩头部在运输过程中损坏，出错的分组可在离开链路层时被构造。我们需要认识到，当头部压缩用于链路上时，可能不会像 PPP 的 FCS 计算那样强大。</p>
<p>头部压缩的最新改进方案称为<strong>鲁棒性头部压缩（ROHC）</strong> [<a href="#RFC5225">RFC5225</a>]。它进一步改进了 IP 头部压缩以涵盖更多的传输协议，并允许同时处理多种头部压缩方式。前面提到的 IP 头部压缩可适用于不同类型的链路，包括 PPP。</p>
<h3 id="367-例子">3.6.7 例子</h3>
<p>我们查看一台 PPP 服务器的调试输出，它通过拨号的调制解调器与客户机交互。客户机是一台有 IPv6 功能的运行 Microsoft Windows Vista 的计算机，服务器是一台运行 Linux 的计算机。客户机配置为可在单一链路上协商多链路功能（属性|选项IPPP 设置），出于演示目的，服务器配置为使用 CCP 协商加密协议（见以下代码清单中的 MPPE）：</p>
<p><img src="https://wenbozhangw.github.io//post-images/1652962371471.png" alt="" loading="lazy"><br>
<img src="https://wenbozhangw.github.io//post-images/1652962559431.png" alt="" loading="lazy"></p>
<p>这里，我们可看到一些涉及 PPP 的交换，它是从服务器的角度来看的。 PPP 服务器进程创建的（虚拟）网络接口为 ppp0，它在连接串行端口 ttyS0 的拨号调制解调器上等待连接请求（称为“输入连接”）。当有连接请求到达时，服务器依次发送 <code>0x0</code> 的异步控制字符映射（asyncmap）、 EAP 认证、 PFC 和ACFC 请求。客户拒绝 EAP 认证，并建议使用 MS-CHAP-v2 （ConENak） [<a href="#RFC2759">RFC2759</a>]。服务器再次尝试发送请求，并使用 MS-CHAP-v2，这请求被接受和确认（ConfAck）。接下来，“输入”请求包括 CBCP，一个与 MP 支持相关的 1614 字节的 MRRU，以及一个端点 ID。 服务器拒绝 CBCP 和多链路操作（ConfRej）请求。客户机发送不带 MRRU 的端点鉴别请求，并被接收和确认。下一步，服务器发送一个名为 dialer 的 CHAP 查询。在该查询的响应到达之前，两个标识消息到达，表明对方以字符串 MSRASV5.20 和 MSRAS-0-VISTA 来标识。最后， CHAP 响应到达并验证通过，表明许可访问。这时， PPP 转换为网络状态。</p>
<p>当进入网络状态时， CCP、 IPCP 和 IPV6CP NCP 被交换。 CCP 尝试协商<strong>微软点对点加密（MPPE）</strong> [<a href="#RFC3078">RFC3078</a>] 。MPPE 有些不同之处，因为它是一种加密协议，而不是一种压缩协议，它实际将分组扩大了 4 字节。但是，它提供了一个相对简单的方法，早在协商过程中就完成了加密。选项 <code>+H -M +S +L -D -C</code> 表明 MPPE 是否采用无状态操作（H）、使用哪种加密密钥强度（安全， S；中等， M；低， L）、是否存在过时的 D 位，以及是否需要单独、专用的 MPPC 的压缩协议（C） [<a href="#RFC2118">RFC2118</a>] 。最终，双方同意在有状态模式下使用强大的 128 位密钥（-H， +S）。注意，在这次协商过程中，客户机尝试发送一个 IPCP 请求，但服务器响应的是一个主动的 TermAck （一个 LCP 定义、 ICPC 采纳的消息）。它用于向对方指出服务器“需要重新谈判”         [<a href="#RFC1661">RFC1661</a>]。</p>
<p>在 MPPE 协商成功之后，服务器请求使用 VJ 头部压缩，并提供它的 IPv4 地址和 IPv6 地址，分别为 <code>192.168.0.1</code> 和 <code>fe80::0206:5bff:fedd:c5c3</code>。这个 IPv6 地址是从服务器的以太网 MAC 地址 <code>00:06:5B:DD:C5:C3</code> 而来。客户机最初使用 IPCP 建议的 IPv4 地址和域名服务器<code>0.0.0.0</code>，但被拒绝。客户机请求使用 <code>fe80::0000:0000:dead:beef</code> 作为 IPv6 地址，这个请求被接受和确认。最后，客户机确认服务器的 IPv4 和 IPv6 地址，并且表明自己已建立 IPv6 地址。接着，客户机再次请求 IPv4 和服务器地址 <code>0.0.0.0</code> ，再次被拒绝。 <code>192.168.0.1</code> 被接受和确认。</p>
<p>我们从这次交换中可看到， PPP 协商是既灵活又烦琐的。很多选项可以尝试、拒绝和重新协商。虽然在低延时链路上这可能不是一个大间题，但这种交换中的每个消息都需要花费几秒（或更长）到达目的地。如果在一条卫星链路上，则可能出现很大的超时。对用户来说，链路建立明显是一个太长的过程。</p>
<hr>
<h2 id="37-环回">3.7 环回</h2>
<p>尽管可能看起来很奇怪，但在很多情况下，客户机可能希望使用 Internet 协议（例如 TCP/IP）与同一计算机上的服务器通信。为了实现这个目标，大多数实现支持一种工作在网络层的<strong>环回</strong>（或称“回送”）能力——通常使用一个虚拟的环回网络接口来实现。它就像一个真正的网络接口，但实际上是一个由操作系统提供的专用软件，可通过 TCP/IP 与同一主机的其他部分通信。以 127 开始的 IPv4 地址就是为这个目的而保留， IPv6 地址 <code>::1</code> （见第 2 章的 IPv4 和 IPv6 寻址约定）用于同样目的。传统上，类 UNIX 系统（包括 Linux）为环回接口分配的 IPv4 地址为 <code>127.0.0.1</code> （IPv6 地址为 <code>::1</code>），为它分配的名称为 <code>localhost</code>。发送到环回接口的 IP 数据报不会出现在任何网络中。尽管我们可以想象传输层检测到另一端是一个环回地址，并跳过某些传输层逻辑和所有网络层逻辑，但大多数的实现在传输层和网络层对数据执行完整的处理流程，并仅在数据报离开网络层时将其回送给网络层协议栈。这种处理对于性能测试可能有用，例如在没有任何硬件开销的情况下，测量执行协议栈软件所需的时间。在 Linux 中，环回接口被称为 <code>Io</code>。</p>
<pre><code>lo Link encap:Local Loopback
        inet  addr:127.0.0.1  Mask:255.0.0.0
        inet6 addr:  ::1/128  Scope:Host
        UP LOOPBACK RUNNING MTU:16436 Metric:1
        RX packets:458511 errors:0 dropped:0 overruns:0 frame:0
        TX packets:458511 errors:0 dropped:0 overruns:0 carrier:0
        collisions:0  txqueuelen:0
        RX bytes:266049199 (253.7 MiB)
        TX bytes:266049199 (253.7 MiB)
</code></pre>
<p>这里，我们看到本地环回接口的 IPv4 地址为 <code>127.0.0.1</code>，子网掩码为 <code>255.0.0.0</code>（对应于分级寻址中的 A 类网络号 127）。 IPv6 地址1有一个128位的前缀，它表示只有一个地址。这个接口支持 16KB 的 MTU （可配置为更大尺寸，最大可达 2GB）。从主机在两个月前初始化开始，巨大的流量（接近 50 万个分组）无差错地通过该接口。我们不希望在本地环回设备上看到错误，假设它实际上没有在任何网络上发送分组。</p>
<p>在 Windows 中，默认情况下没安装 Microsoft 环回适配器，尽管这样仍支持 IP 环回功能。这个适配器可用于测试各种网络配置，甚至在一个物理网络接口不可用的情况下。在 Windows XP 下安装该适配器，可选择“开始 | 控制面板 | 添加硬件 | 从列表中选择网络适配器 | 选择 Microsoft 作为制造商 | 选择 Microsoft 环回适配器” 。对于 Windows Vista 或 Windows 7，在命令提示符下运行程序 hdwwiz，并手动添加 Microsoft 环回适配器。在执行上述操作后， ipconfig 命令显示如下（这个例子来自 Windows Vista 环境）：</p>
<pre><code>C:\&gt; ipconfig /all
...
Ethernet adapter Local Area Connection 2:
   Connection-specific DNS Suffix  . . . . . . . :
   Description . . . . . . . . . . . . . . . : Microsoft Loopback Adapter
   Physical Address. . . . . . . . . . . . . : 02-00-4C-4F-4F-50
   DHCP Enabled . . . . . . . . . . . : Yes
   Autoconfiguration Enabled. . . . . . . . . . : Yes
   Link-local IPv6 Address. . . . . . . . : fe80::9c0d:77a:52b8:39f0%18(Preferred)
   Autoconfiguration IPv4 Address . . . . . . . . . . . . : 169.254.57.240(Preferred)
   Subnet Mask  . . . . . . . . . . . . : 255.255.0.0
   Default Gateway. . . . . . . . . . . . . : 
   DHCPv6 IAID . . . . . . . . . . . : 302121036
   DNS Servers  . . . . . . . . . . . : fec0:0:0:ffff::1%1
                                       fec0:0:0:ffff::2%1
                                       fec0:0:0:ffff::3%1
    NetBIOS over Tcpip  . . . . . . . : Enabled
</code></pre>
<p>这里，我们可看到该接口已被创建，分配了 IPv4 和 IPv6 地址，并显示为一系列的虚拟以太网设备。现在，这台计算机具有以下环回地址：</p>
<pre><code>C:\&gt; ping 127.1.2.3
Pinging 127.1.2.3 with 32 bytes of data:
Reply from 127.1.2.3: bytes=32 time&lt;1ms TTL=128
Reply from 127.1.2.3: bytes=32 time&lt;1ms TTL=128
Reply from 127.1.2.3: bytes=32 time&lt;1ms TTL=128
Reply from 127.1.2.3: bytes=32 time&lt;1ms TTL=128

Ping statistics for 127.1.2.3:
    Packets: Sent = Received = Lost = 0 (0% loss)，
Approximate round trip times in milli-seconds:
    Mininum = 0ms，Maximum = 0ms，Average = 0ms

C:\&gt; ping ::1
Pinging ::1 with 32 bytes of data:
Reply from ::1: bytes=32 time&lt;1ms TTL=128
Reply from ::1: bytes=32 time&lt;1ms TTL=128
Reply from ::1: bytes=32 time&lt;1ms TTL=128
Reply from ::1: bytes=32 time&lt;1ms TTL=128

Ping statistics for ::1:
    Packets: Sent = Received = Lost = 0 (0% loss)，
Approximate round trip times in milli-seconds:
    Mininum = 0ms，Maximum = 0ms，Average = 0ms

C:\&gt; ping 169.254.57.240
Pinging 169.254.57.240 with 32 bytes of data:
Reply from 169.254.57.240: bytes=32 time&lt;1ms TTL=128
Reply from 169.254.57.240: bytes=32 time&lt;1ms TTL=128
Reply from 169.254.57.240: bytes=32 time&lt;1ms TTL=128
Reply from 169.254.57.240: bytes=32 time&lt;1ms TTL=128

Ping statistics for 169.254.57.240:
    Packets: Sent = Received = Lost = 0 (0% loss)，
Approximate round trip times in milli-seconds:
    Mininum = 0ms，Maximum = 0ms，Average = 0ms
</code></pre>
<p>我们可以看到， IPv4 中以 127 开始的目的地址被环回。但是，对于 IPv6，只有地址 <code>::1</code> 被定义用于环回操作。我们还可以看到，地址为 <code>169.254.57.240</code> 的环回适配器如何立即返回数据。我们将在第 9 章讨论组播或广播数据报是否被复制并返回给发送主机（通过环回接口）。每个应用程序都可做出这种选择。</p>
<hr>
<h2 id="38-mtu-和路径-mtu">3.8 MTU 和路径 MTU</h2>
<p>我们可以从图 3-3 中看到，在很多链路层网络（例如以太网）中，携带高层协议 PDU 的帧大小是有限制的。以太网有效载荷的字节数通常被限制为 1500， PPP 通常采用相同大小以保持与以太网兼容。链路层的这种特征被称为<strong>最大传输单元（MTU）</strong>。大多数的分组网络（例如以太网）都有固定的上限。大多数的流类型网络（串行链路）提供可设置的上限，它可被帧协议（例如 PPP）所使用。如果 IP 需要发送一个数据报，并且这个数据报比链路层 MTU大，则 IP 通过分片将数据报分解成较小的部分，使每个分片都小于 MTU。我们将在第 5 章和第 10 章讨论 IP 分片。</p>
<p>当同一网络中的两台主机之间通信时，本地链路的 MTU 在会话期间对数据报大小有直接影响。当两台主机之间跨越多个网络通信时，每条链路可能有不同大小的 MTU。在包含所有链路的整个网络路径上，最小的 MTU 称为<strong>路径 MTU</strong>。</p>
<p>任何两台主机之间的路径 MTU 不会永远不变，这取决于当时使用的路径。如果网络中的路由器或链路故障， MTU 可能改变。另外，路径通常不对称（主机 A 到 B 路径可能不是 B 到 A 的反向路径），路径 MTU 不需要在两个方向上相同。</p>
<p>[<a href="#RFC1191">RFC1191</a>] 规定了** IPv4 路径 MTU 发现（PMTUD）**机制， [<a href="#PMTUD">RFC1981</a>] 描述了用于 IPv6 的相应机制。 [<a href="#RFC4821">RFC4821</a>] 描述了一个补充方案，以解决这些机制中的一些问题。 PMTUD 用于确定某个时间的路径 MTU，它在 IPv6 实现中是需要的。在后面的章节中，针对前面描述的 ICMP 和 IP 分片，我们将观察这个机制如何运行。我们在讨论 TCP 和 UDP 时，也会讨论它对传输性能的影响。</p>
<hr>
<h2 id="39-隧道基础">3.9 隧道基础</h2>
<p>在某些情况下，两台计算机通过 Internet 或其他网络建立一条虚拟链路是有用的。虚拟专用网络（VpN）提供这种服务。实现这类服务的最常用方法称为<strong>隧道</strong>。一般来说，隧道是在高层（或同等层）分组中携带低层数据。例如，在一个 IPv4 或 IPv6 分组中携带 IPv4 数据，在一个 UDP、 IPv4 或 IPv6 分组中携带以太网数据。隧道转变了在头部中协议严格分层的思路，并允许形成<strong>覆盖网络</strong>（即这些“链路”实际是其他协议实现的虚拟链路，而不是物理连接的网络）。这是一个非常强大和有用的技术。这里，我们讨论了一些隧道方案的基础。</p>
<p>为某个协议层的分组或另一层的分组建立隧道有多种方法。用于建立隧道的 3 个常见协议包括：<strong>通用路由封装（GRE）</strong> [<a href="#RFC2784">RFC2784</a>] 、<strong>Microsoft 专用的点对点隧道协议（PPTP）</strong> [<a href="#RFC2637">RFC2637</a>] 和 <strong>第 2 层隧道协议（L2TP）</strong>  [<a href="#RFC3931">RFC3931</a>] 。其他协议包括早期非标准的 IP-in-IP 隧道协议 [<a href="#RFC1853">RFC1853</a>]。 GRE 和 IT2P 后来发展为标准，并分别代替了 IP-in-IP 和 PPTP （但这两种协议仍在使用）。我们将重点放在 GRE 和 PPTP，但更关注 PPTP，因为它是个人用户的常用协议，即使它并不是一个 IETF 标准。 L2TP 本身不提供安全保障，它常用于 IP 层安全（IPsec；见第 18 章）。由于 GRE 和 PPTP 有密切关系，我们现在看图 3-26 中的 GRE 头部，它们分别基于原来的标准和修订后的标准。</p>
<figure data-type="image" tabindex="26"><img src="https://wenbozhangw.github.io//post-images/1652968099400.png" alt="图 3-26" loading="lazy"></figure>
<p>图 3-26   基本的 GRE 头部只有 4 字节，包括一个 16 位的校验和选项（很多 Internet 协议中的典型选项）。后来，这个头部被扩展为包括一个标识符（密钥字段），该标识符是同一流中的多个分组共有的，还包括一个序列号（用于顺序混乱的分组重新排序）</p>
<p>从图 3-26 中的头部可以看出，基本 GRE 规范 [<a href="#RFC2784">RFC2784</a>] 是相当简单的，它只提供了对其他分组的最简化的封装。第一个位字段（C）指出是否存在<strong>校验和</strong>。如果是，<strong>校验和</strong>字段中包含相同类型的<strong>校验和</strong>，它在很多 Internet 相关协议中可看到（见 5.2.2 节）。如果<strong>校验和</strong>字段存在，<strong>保留 1 <strong>字段也存在，并被设置为 0。 [<a href="#RFC2890">RFC2890</a>] 扩展了基本格式，包括可选的</strong>密钥</strong>和<strong>序列号</strong>字段，如果有这两个字段的话，图 3-26 中的 K 和 S 位字段分别被设置为1。 密钥字段在多个分组中被分配了一个同样的值，表示它们是属于同一流中的分组。如果分组顺序被打乱（例如通过不同链路），可利用序列号字段对分组重新排序。</p>
<p>虽然 GRE 是 PPTP 的基础，并被 PPTP 使用，但这两个协议的目的不同。 GRE 隧道常用于网络基础设施内的流量传输，例如 ISP 之间或企业内部网与分支机构之间，虽然 GRE 隧道可与 IPsec 结合，但这个流量通常没必要加密。相反， PPTP 常用于用户和 ISP 或企业内部网之间，并需要加密（例如使用 MPPE）。 PPTP 本质上是 GRE 和 PPP 的结合，因此 GRE 可基于 PPP 提供虚拟的点到点链路。 GRE 使用 IPv4 或 IPv6 携带流量，因此它更像是一种第 3 层隧道技术。 PPTP 常用于携带第 2 层帧（例如以太网），因此需要模拟一条直接的局域网（链路层）连接。例如，它可用于对企业网络的远程访问。 PPTP 采用的是对标准 GRE 头部的改进方案（见图 3-27）。</p>
<figure data-type="image" tabindex="27"><img src="https://wenbozhangw.github.io//post-images/1652968427453.png" alt="图 3-27" loading="lazy"></figure>
<p>图 3-27   PPTP 头部基于一个旧的、非标准的 GRE 头部。它包括一个序列号、一个累积的分组确认号和一些标识信息。多数字段在第一次使用时设置为 0</p>
<p>我们可看到图 3-27 与标准 GRE 头部的一些差异，包括额外的 R、 S 和 A 位字段，以及<strong>标志</strong>字段和<strong>回溯（Recur）<strong>字段。它们中的多数设置为 0，并且没有使用（它们的分配是基于一个旧的、非标准的 GRE 版本）。 K、 S 和 A 位字段分别表示</strong>密钥</strong>、<strong>序列号</strong>和<strong>确认号</strong>字段是否存在。如果存在，<strong>序列号</strong>字段保存对方可看到的最大分组数。</p>
<p>我们现在建立一个 PPTP 会话，稍后对 PPTP 的其他功能进行简单讨论。下面的例子类似于前面给出的 PPP 链路建立的例子，区别在于现在不常使用拨号连接， PPTP 为 PPP 提供了一条“原始”链路。第二个客户端使用 Windows Vista 系统，服务器使用 Linux 系统。当调试选项启用时，这个输出保存在/ <code>var/log/messages</code> 文件中：</p>
<pre><code>pptpd: MGR: Manager process started
pptpd: MGR: Maximum of 100 connections available
pptpd: MGR: Launching /usr/sbin/pptpctrl to handle client
pptpd: CTRL: local address = 192.168.0.1
pptpd: CTRL: remote address = 192.168.1.1
pptpd: CTRL: pppd iptions file = /etc/ppp/options.pptpd
pptpd: CTRL: Client 71.141.227.30 control connection started
pptpd: CTRL: Received PPTP Control Message (type : 1)
pptpd: CTRL: Made a START CTRL CONN RPLY packet
pptpd: CTRL: I wrote 156 bytes to the client.
pptpd: CTRL: Sent packet to client
pptpd: CTRL: Received PPPTP Control Message (type : 7)

pptpd: CTRL: Set parameters to 100000000 maxbps， 64 window size
pptpd: CTRL: Made a OUT CALL RPLY packet
pptpd: CTRL: Starting call (launching ppd， opening GRE)
pptpd: CTRL: pty_fd = 6
pptpd: CTRL: tty_fd = 7
pptpd: CTRL (PPPD Launcher) : program binary = /usr/sbin/pppd 
pptpd: CTRL (PPPD Launcher) : local address = 192.168.0.1
pptpd: CTRL (PPPD Launcher) : remote address = 192.168.1.1
pppd: pppd 2.4.4 started by root， uid 0
pppd: using channel 60
pptpd: CTRL: I wrote 32 but4es to the client.
pptpd: CTRL: Sent packet to client
pppd: Using interface ppp0
pppd: Connect: ppp0 &lt;--&gt; /dev/pts/1
pppd:sent [LCP ConfReq id=0x1 &lt;asyncmap 0x0&gt; &lt;auth chap MS-v2&gt;
            &lt;magic 0x4e2ca200&gt; &lt;pcomp&gt; &lt;accomp&gt;]
pptpd: CTRL: Received PPTP Control Message (type : 15)
pptpd: CTRL: Got a SET LINK INFO packet with standard ACCMs
pptpd: GRE: accepting packet #0
pppd: rcvd [LCP ConfReq id=0x0 &lt;mru 1400&gt; &lt;magic 0x5e565505&gt;
            &lt;pcomp&gt; &lt;accomp&gt;]]
pppd: sent [LCP ConfAck id=0x0 &lt;mru 1400&gt; &lt;magic 0x5e565505&gt;
            &lt;pcomp&gt; &lt;accomp&gt;]]
pppd: sent [LCP ConfReq id=0x0 &lt;asyncmap 0x0&gt; &lt;auth chap MS-v2&gt; 
            &lt;magic 0x4e2ca200&gt; &lt;pcomp&gt; &lt;accomp&gt;]]
pptpd: GRE: accepting packet #1
pppd: rcvd [LCP ConfAck id=0x1 &lt;asyncmap 0x0&gt; &lt;auth chap MS-v2&gt;
            &lt;magic 0x4e2ca200&gt; &lt;pcomp&gt; &lt;accomp&gt;]
pppd: sent [CHAP Challenge id=0x3 
            &lt;eb88bfff67dlc239ef73e98ca32646a5&gt;， name = &quot;dialer&quot;]
pptpd: CTRL: Received PPTP Control Message (type = 15)
pptpd: CTRL: Ignored a SET LINK INFO packet with real ACCMs!
pptpd: GRE: accepting packet #2
pppd: rcvd [CHAP Response id=0x3 
            &lt;276f3678fofO3fa57f64b3c367529565000000
            00000000000fa2b2aeoad8db9d986f8e222a0217a620638a24
            3179160900&gt;， name = &quot;dialer&quot;]
pppd: sent [CHAP Success id=0x3
            &quot;S=C551119E0E1AAB68E86DED09A32D0346D7002E05
            M=Accessgranted&quot;]
pppd: sent [CCP ConfReq id=0x1 &lt;mppe +H -M +S +L -D -C&gt;]
pptpd: GRE: accepting packet #3
pppd: rcvd [ IPV6CP ConfReq id=0x1 &lt;addr fe80::1cfc:fddd:8e2c:e118&gt;]
pppd: sent [ IPV6CP TermAck id=0x1 ]
pptpd:GRE: accepting packet #4
pppd: rcvd [CCP confReq id=0x2 &lt;mppe +H -M -S -L -D -C&gt;]
pppd: sent [CCP confNak id=0x2&lt;mppe +H -M +S +L -D -C&gt;]
pptpd: GRE: accepting packet #5
pptpd: GRE: accepting packet #6
pppd: rcvd [ IPCP ConfReq id=0x3 &lt;addr 0.0.0.0&gt;&lt;ms-dns1 0.0.0.0&gt;
&lt;ms-wins 0.0.0.0&gt;&lt;ms-dns3 0.0.0.0&gt;&lt;ms-wins 0.0.0.0&gt;]
pptpd: GRE: accepting packet #7
pppd: sent [ IPCP TermAck id=0x3]
pppd: rcvd [CCP ConfNak id=0x1 &lt;mppe +H -M+S -L -D -C&gt;
pppd: sent [CCP ConfReq id=0x2 &lt;mppe +H -M +S -L -D -C&gt;
pppd: rcvd [CCP confReq id=0x4 &lt;mppe +H -M +S -L -D -C&gt;
pppd: sent [CCP ConfAck id=0x4 &lt;mppe +H -M +S -L -D -C&gt;
pptpd: GRE: accepting packet #8
pppd: rcvd [CCP ConfAck id=0x2 &lt;mppe +H -M +S -L -D -C&gt;
pppd: MPPE 128-bit stateless compression enabled
pppd: sent [ IPCP ConfReq id=0x1 &lt;addr 192.168.0.1&gt;]
pppd: sent [ IPV6CP ConfReq id=0x1 &lt;addr fe80::0206:5bff:fedd:c5c3&gt;]
pptpd: GRE: accepting packet #9
pppd: rcvd [ IPCP ConfAck id=0x1 &lt;addr 192.168.0.1&gt;]
pptpd: GRE: accepting packet #10
pppd: rcvd [ IPV6CP ConfAck id=0x1 &lt;addr fe80::0206:5bff:fedd:c5c3&gt;]
pptpd: GRE:accepting packet #11
pppd: rcvd [ IPCP ConfReq id=0x5 &lt;addr 0.0.0.0&gt;
            &lt;ms-dns1 0.0.0.0&gt;&lt;ms-wins 0.0.0.0&gt;
            &lt;ms-dns3 0.0.0.0&gt;&lt;ms-wins 0.0.0.0&gt;]
pppd: sent [ IPCP ConfRej id=0x5 &lt;ms-wins 0.0.0.0&gt;&lt;ms-wins 0.0.0.0&gt;]
pptpd: GRE: accepting packet #12
pppd: rcvd [ IPV6CP ConfReq id=0x6 &lt;addr fe80::1cfc:fddd:8e2c:e118&gt;]
pppd: sent [ IPV6CP ConfAck id=0x6 &lt;addr fe80::1cfc:fddd:8e2c:e118&gt;]
pppd: local LL address fe80::0206:5bff:fedd:c5c3
pppd: remote LL address fe80::1cfc:fddd:8e2c:e118
pptpd: GRE: accepting packet #13
pppd: rcvd [ IPCP ConfReq id=0x7 &lt;addr 0.0.0.0&gt;
            &lt;ms-dns1 0.0.0.0&gt;&lt;ms-dns3 0.0.0.0&gt;]
pppd: sent [ IPCP ConfNak id=0x7 &lt;addr 192.168.1.1&gt;
            &lt;ms-dns1 192.168.0.1&gt;&lt;ms-dns3 192.168.0.1&gt;]
pptpd: GRE: accepting packet #14
pppd: rcvd [ IPCP ConfReq id=0x8 &lt;addr 192.168.1.1&gt;
            &lt;ms-dns1 192.168.0.1&gt;&lt;ms-dns3 192.168.0.1&gt;]
pppd: sent [ IPCP confAck id=0x8 &lt;addr 192.168.1.1&gt;
            &lt;ms-dns1 192.168.0.1&gt;&lt;ms-dns3 192.168.0.1&gt;]
pppd: local IP address 192.168.0.1
pppd: remote IP address 192.168.1.1
pptpd: GRE:accepting packet #15
pptpd: CTRL: sending ECHO REQ id 1
pptpd: CTRL: Made a ECHO REQ packet
pptpd: CTRL: l wrote 16 bytes to the client.
pptpd: CTRL: sent packet to client
</code></pre>
<p>这个输出类似于前面看过的 PPP 的例子，区别在于一个 pppd 过程和一个 pptpd 过程。这些进程协同工作以建立到服务器的 PPTP 会话。整个建立过程开始于用 pptpd 接收 1 个类型为 1 的控制消息，表示客户机希望建立一个控制连接。 PPTP 使用分离的控制流和数据流，因此首先需要建立一个控制流。在响应这个请求之后，服务器接收到一个类型为 7 的控制消息（表示对方发送的呼叫请求）。最大速度（b/s）设置为一个很大的值 100000000，实际上意味着它是无限制的。<strong>窗口</strong>设置为 64，这是在传输协议例如 TCP （见第 15 章）中经常看到的一个概念。这里，窗口用于流量控制。也就是说， PPTP 使用自己的序列号和确认号来确定多少帧成功到达目的地。如果成功交付的帧太少，发送者需要减小发送速率。为了确定帧确认的等待时间， PPTP 使用一种自适应的超时机制，根据链路的往返时间进行估算。当我们学习 TCP 时将看到这种计算过程。</p>
<p>在设置窗口后不久， pppd 应用开始运行和处理 PPP 数据，就像我们之前在拨号例子中看到的那样。两者之间唯一的区别在于： pptpd 在分组到达和离开时转发给 pppd 过程，以及 pptpd 处理的少量特殊 PPTP 消息（例如 set link info 和 echo request）。这个例子说明了 PPTP 协议如何实际运行，就像一个针对 PPP 分组的 GRE 隧道。由于现有 PPP 实现（这里是 pppd）可处理封装的 PPP 分组，因此它是很方便的。注意，虽然 GRE 本身通常封装在 IPv4 分组中，但类似功能也可使用 IPv6 隧道分组 [<a href="#RFC2473">RFC2473</a>] 。</p>
<h3 id="391-单向链路">3.9.1 单向链路</h3>
<p>当链路仅在一个方向工作时出现一个有趣的问题。这种在一个方向工作的链路称为<strong>单向链路（UDL）</strong>，由于它们需要交换信息（例如 PPP 配置消息），因此前面介绍的很多协议在这种情况下不能正常运行。为了解决这种问题提出了一种标准，可在辅助 Internet 接口上创建隧道，它可与 UDL 操作相结合 [<a href="#RFC3077">RFC3077</a>] 。典型情况是由卫星提供下行流量（流向用户）而形成一条 Intenet 连接，或者是调制解调器提供上行流量而形成一条拨号链路。这在卫星连接的用户主要是下载而不是上传的情况下是有用的，并且通常用于早期的卫星 Internet 连接。它使用 GRE 将链路层的上行流量封装在 IP 分组中。</p>
<p>为了在接收方自动建立和维护隧道， [<a href="#RFC3077">RFC3077</a>] 规定了一种<strong>动态隧道配置协议（DTCP）</strong>。DTCP 涉及在下行链路中发送组播 <strong>Hello 消息</strong>，因此任何有兴趣的接收方都可知道已有 UDL 及其 MAC 和 IP 地址。另外， Hello 消息表示网络中一个隧道端点的接口，它可通过用户端的辅助接口到达。在用户选择隧道端点之后， DTCP 在 GRE 隧道中将同一 MAC 作为 UDL 封装返回流量。服务提供商接收由 GRE 封装的这些第 2 层帧（通常是以太网），将它们从隧道中提取并适当转发。因此，上游（提供商） UDL 需要手工配置隧道，下游（很多用户）自动配置隧道。注意，这种 UDL 处理方法实际上是为上层协议不对称地“隐藏”链路。因此，这条链路“两个”方向上的性能（延迟、带宽）可能非常不对称，并可能对高层协议产生不利影响 [<a href="#RFC3449">RFC3449</a>] 。</p>
<p>这个例子说明，隧道的一个重要问题是配置的工作量，这个工作从前一直由手工完成。在通常情况下，隧道配置涉及选择一个隧道端点，以及用对方的 IP 地址配置位于隧道端点的设备，也许还需要选择协议和提供认证信息。一些相关技术已经出现，以协助自动配置或使用隧道。一种从 IPv4 向 IPv6 的过渡方法称为6to4 [<a href="#RFC3056">RFC3056</a>] 。在 6to4 中， IPv6 分组在一个 IPv4 网络中通过隧道传输， [<a href="#RFC3056">RFC3056</a>] 中规定它采用的封装方式。当相应主机经过了网络地址转换（见第 7 章），采用这种方法就会出现一个问题。这在当前是常见的，特别是对于家庭用户。自动配置隧道的 IPv6 过渡处理方法规定在 Teredo 技术方案中 [<a href="#RFC4380">RFC4380</a>] 。 Teredo 在 UDP/IPv4 分组上形成 IPv6 分组的隧道。理解这种方法需要一些 IPv4、 IPv6 和 UDP 的背景知识，我们将在第 10 章详细讨论这种隧道自动配置选项。</p>
<hr>
<h2 id="310-与链路层相关的攻击">3.10 与链路层相关的攻击</h2>
<p>对 TCP/IP 以下的层进行攻击以影响 TCP/IP 网络运行一直是常见的做法，这是由于大部分链路层信息不被高层共享，因而难以检测。不过，现在大家已知道很多这种攻击，我们在这里提到其中一些，以更好地理解链路层问题如何影响高层运行。</p>
<p>在传统的有线以太网中，接口可被设置为<strong>混杂模式</strong>，这允许它接收目的地不是自己的流量。在早期的以太网中，当介质是名副其实的共享电缆时，该功能允许任何一台连接以太网电缆的计算机“嗅探”别人的帧并检查其内容。当时很多高层协议包含密码等敏感信息，仅通过查看一个分组并解码就能轻易获得密码。两个因素对这种方法的影响很大：交换机部署和高层协议加密部署。在使用交换机后，只有连接到交换机端口的站提供流量，流量的目的地也是其他站（或其他桥接的站），以及广播/组播流量。这种流量很少包含敏感信息（例如密码），可在很大程度上阻止攻击。但是，在更高层使用加密更有效，这在当前是常见的。在这种情况下，嗅探分组难以获得多少好处，因为基本无法直接获取内容。</p>
<p>另一种攻击的目标是交换机。交换机中有一个基于每个端口的站列表。如果这种表能被快速填充（例如被大量伪装的站快速填充），交换机可能被迫放弃合法条目，从而导致中断对合法站的服务。一个相关但可能更严重的攻击是使用 STP。在这种情况下，一个站可伪装成一个到根网桥拥有低成本路径的站，从而吸引流量直接导向它。</p>
<p>随着 Wi-Fi 网络的使用，有线以太网中存在的一些窃听和伪装问题变得更严重，这是由于任何站都可进入监控模式并嗅探分组（802.11 接口置于监控模式通常比以太网接口置于混杂模式更有挑战性，这样做依赖于一个适当的设备）。一些早期“攻击” （可能不是真的被攻击，依据相关的法律框架）涉及扫描中的简单漫游，寻找提供 Internet 连接的接入点（即<strong>驾驶攻击</strong>）。虽然很多接入点使用加密来限制授权用户的访问，但有些人却能打开或使用<strong>捕获门户</strong>技术访问注册网页，然后进行基于 MAC 地址的过滤访问。通过观察站注册以及冒充合法注册用户来“劫持”连接，捕获门户系统已被破坏。</p>
<p>一种更先进的 Wi-Fi 攻击涉及对加密保护的攻击，尤其是很多早期接入点使用的 WEP 加密。针对 WEP [<a href="#BHL06">BHL06</a>] 的攻击有显著的破坏性，它促使 IEEE 修订了自已的标准。新的WPA2 （和 WPA）加密体系明显更强，因此不再推荐使用 WEP。</p>
<p>如果攻击者可访问两个端点之间的信道，它可采用很多方式来攻击 PPP 链路。对于很简单的认证机制（例如 PAP），嗅探可用于捕获密码，以便后续的非法访问。通过 PPP 链路（例如路由流量）上的更高层流量，可导致系统的不可用。</p>
<p>从攻击的角度看，隧道经常是目标，有时也成为攻击工具。作为目标，隧道穿过一个网络（通常是 Internet），它是被截获和分析的目标。隧道端点配置也可被攻击，尝试由端点建立更多隧道（一个 DoS 攻击）或攻击配置自身。如果该配置被攻破，可能打开一个未授权的隧道端点。在这点上，隧道变成工具而不再是目标，有些协议（例如 L2TP）提供一种与协议无关的简便方法，以在链路层访问私有的内部网络。在一种 GRE 相关的攻击中，例如将流量简单地插入一个非加密隧道，它到达隧道端点并被注入“私有”网络，虽然它本来只应被送往端点本地。</p>
<hr>
<h2 id="311-总结">3.11 总结</h2>
<p>在本章中，我们探讨 Internet 协议族的低层，也就是我们关注的链路层。我们首先介绍以太网的演变，速度从 10Mb/s 增加到 10Gb/s 及以上，功能上的变化包括 VLAN、优先级、链路聚合和帧格式等方面。我们介绍了交换机如何通过网桥改善性能，这主要通过在多个独立站的集合之间提供直连电路来实现，以及由全双工操作取代早期半双工操作。我们还介绍了 IEEE 802.11 无线局域网 Wi-Fi 标准的一些细节，并说明它与以太网的相似点和区别。它已成为最流行的 IEEE 标准之一，并通过两个主要频段 2.4GHz 和 5GHz 提供无须许可的网络访问。我们还介绍了 Wi-Fi 安全方法的演变，从较弱的 WEP 到更强的 WPA 和 WPA2 框架。在 IEEE 标准的基础上，我们讨论了点到点链路和 PPP 协议。 PPP 实际上可封装任何类型的分组，可用于 TCP/IP 和非 TCP/IP 网络，采用一种类似 HDLC 的帧格式，并且可用于从低速拨号调制解调器到高速光纤线路。它本身是一整套协议，涉及压缩、加密、认证和链路聚合。它只支持两个参与者之间通信，无法处理对共享介质的访问控制，例如以太网或 Wi-Fi 的 MAC 协议。</p>
<p>大多数实现提供了环回接口。通过特殊的环回地址，通常为 <code>127.0.0.1</code> （IPv6 为 <code>::1</code>），或将 IP 数据报发送到主机自己的 IP 地址，都可访问该接口。环回数据可被传输层处理，并在网络层被 IP 处理。我们描述了链路层的一个重要特点，即 MTU 和路径 MTU 的相关概念。</p>
<p>我们也讨论了隧道的使用，涉及在更高层（或同等层）分组中携带低层协议。这种技术可形成覆盖网络，在 Internet 中将隧道作为网络基础设施的其他层中的链路。这项技术已变得非常流行，包括新功能的实验（例如在一个 IPv4 网络上运行的一个 IPv6 覆盖网络）和实际使用（例如 VPN）。</p>
<p>最后简要讨论了链路层涉及的各种攻击类型，它们既是目标又是工具。很多攻击涉及流量截取与分析（例如查找密码），但很多复杂攻击涉及伪造端点和修改传输中的流量。其他攻击涉及修改控制信息，例如隧道端点或 STP 信息，以将流量导向其他意想不到的位置。链路层访问也提供了一种执行 DoS 攻击的通用方式。这方面最著名的攻击是干扰通信信号，这种攻击几乎从无线电问世以来就有了。</p>
<p>本章仅涵盖了当前 TCP/IP 使用的一些常见链路技术。 TCP/IP 成功的原因之一在于它能工作在几乎任何一种链路技术之上。从本质上来说， IP 只要求发送方和接收方之间存在某条路径，它们可能经过一些级联的中间链路。这是一个相对适中的要求，很多研究的目标甚至延伸得更远，发送方和接收方之间可能永远没有一条端到端路径 [<a href="#RFC4838">RFC4838</a>]。</p>
<hr>
<h2 id="312-参考文献">3.12 参考文献</h2>
<p><span id="802.11-2007">[802.11-2007]</span></span> &quot;IEEE Standard for Local and Metropolitan Area Networks, Part 11: Wireless LAN Medium Access Control (MAC) and Physical Layer (PHY) Specifications,&quot; June 2007.</p>
<p><span id="802.11n-2009">[802.11n-2009]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks, Part 11: Wireless LAN Medium Access Control (MAC) and Physical Layer (PHY) Specifications Amendment 5: Enhancements for Higher Throughput,&quot; Oct. 2009.</p>
<p><span id="802.11y-2008">[802.11y-2008]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks, Part 11: Wireless LAN Medium Access Control (MAC) and Physical Layer (PHY) Specifications Amendment 3: 3650-3700 MHz Operation in USA,&quot; Nov. 2009.</p>
<p><span id="802.16-2009">[802.16-2009]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks, Part 16: Air Interface for Fixed Broadband Wireless Access Systems,&quot; May 2009.</p>
<p><span id="802.16h-2010">[802.16h-2010]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks, Part 16: Air Interface for Fixed Broadband Wireless Access Systems Amendment 2: Improved Coexistence Mechanisms for License-Exempt Operation,&quot; July 2010.</p>
<p><span id="802.16j-2009">[802.16j-2009]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks, Part 16: Air Interface for Fixed Broadband Wireless Access Systems Amendment 1: Multihop Relay Specification,&quot; June 2009.</p>
<p><span id="802.16k-2007">[802.16k-2007]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks, Part 16:Air Interface for Fixed Broadband Wireless Access Systems Amendment 5: Bridging of IEEE 802.16,&quot;Aug. 2010.</p>
<p><span id="802.1AK-2007">[802.1AK-2007]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks, Virtual Bridged Local Area Networks Amendment 7: Multiple RegistrationProtocol,&quot; June 2007.</p>
<p><span id="802.1AE-2006">[802.1AE-2006]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks Media Access Control (MAC) Security,&quot; Aug. 2006.</p>
<p><span id="802.1ak-2007">[802.1ak-2007]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks--—Virtual Bridged Local Area Networks--Amendment 7: Multiple Registration Protocol,&quot; June 2007.</p>
<p><span id="802.1AX-2008">[802.1AX-2008]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks—Link Aggregation,&quot; Nov. 2008.</p>
<p><span id="802.1D-2004">[802.1D-2004]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks Media Access Control (MAC) Bridges,&quot; June 2004.</p>
<p><span id="802.1Q-2005">[802.1Q-2005]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks Virtual Bridged Local Area Networks,&quot; May 2006.</p>
<p><span id="802.1X-2010">[802.1X-2010]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks Port-Based Network Access Control,&quot;Feb. 2010.</p>
<p><span id="802.2-1998">[802.2-1998]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks Logical Link Control&quot;(also ISO/IEC 8802-2:1998), May 1998.</p>
<p><span id="802.21-2008">[802.21-2008]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks, Part 21: Media Independent Handover Services&quot; Jan. 2009.</p>
<p><span id="802.3-2008">[802.3-2008]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks, Part 3:Carrier Sense Multiple Access with Collision Detection (CSMA/CD) Access Method and Physical Layer Specifications,&quot;Dec. 2008.</p>
<p><span id="802.3at-2009">[802.3at-2009]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks—Specific Requirements, Part 3: Carrier Sense Multiple Access with Collision Detection (CSMA/CD) Access Method and Physical Layer Specifications Amendment 3: Date Terminal Equipment (DTE) Power via the Media Dependent Interface (MDI) Enhancements,&quot; Oct. 2009.</p>
<p><span id="802.3ba-2010">[802.3ba-2010]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks, Part 3: Carrier Sense Multiple Access with Collision Detection (CSMA/CD) Access Method and Physical Layer Specifications, Amendment 4: Media Access Control Parameters, Physical Layers, and Management Parameters for 40Gb/s and 100Gb/s Operation,&quot; June 2010.</p>
<p><span id="802.11n-2009">[802.11n-2009]</span> &quot;IEEE Standard for Local and Metropolitan Area Networks, Part 11: Wireless LAN Medium Access Control (MAC) and Physical Layer (PHY) Specifications,Amendment 5: Enhancements for Higher Throughput,&quot; Oct. 2009.</p>
<p><span id="AESO1">[AESO1]</span> U.S. National Institute of Standards and Technology, FIPS PUB 197, &quot;Advanced Encryption Standard,&quot; Nov.2001.</p>
<p><span id="BHLO6">[BHLO6]</span> A.Bittau, M.Handley, and J.Lackey, &quot;The Final Nail in WEP's Coffin, &quot; Proc. IEEE Symposium on Security and Privacy, May 2006.</p>
<p><span id="BOND">[BOND]</span> http://bonding.sourceforge.net</p>
<p><span id="ETHERTYPES">[ETHERTYPES]</span> http://www.iana.org/assignments/ethernet-numbers</p>
<p><span id="ETX">[ETX]</span> D. De Couto, D.Aguayo, J. Bicket, and R. Morris,&quot;A High-Throughput Path Metric for Multi-Hop Wireless Routing,&quot; Proc. Mobicom, Sep. 2003.</p>
<p><span id="G704">[G704]</span> ITU, &quot;General Aspects of Digital Transmission Systems: Synchronous Frame Structures Used at 1544, 6312, 2048k, 8488, and 44736 kbit/s Hierarchical Levels,&quot; ITU-T Recommendation G.704, July 1995.</p>
<p><span id="IANA-CHARSET">[IANA-CHARSET]</span> &quot;Character Sets,&quot; http://www.iana.org/assignments/character-sets</p>
<p><span id="ISO3309">[ISO3309]</span> International Organization for Standardization, &quot;Information Processing Systems--Data Communication High-Level Data Link Control Procedure--Frame Structure,&quot; IS 3309,1984.</p>
<p><span id="ISO4335">[ISO4335]</span> International Organization for Standardization, &quot;Information Processing Systems-Data Communication High-Level Data Link Control Procedure—Elements of Procedure,&quot; IS 4335,1987.</p>
<p><span id="JF">[JF]</span> M.Mathis,&quot;Raising the Internet MTU,&quot; http://www.psc.edu/~mathis/MTU</p>
<p><span id="MWLD">[MWLD]</span> &quot;Long Distance Links with MadWiFi,&quot; http://madwifi-project.org/wiki/UserDocs/LongDistance</p>
<p><span id="PPPn">[PPPn]</span> http://www.iana.org/assignments/ppp-numbers</p>
<p><span id="RFC0894">[RFC0894]</span> C.Hornig, &quot;A Standard for the Transmission of IP Datagrams over Ethernet Networks,&quot; Internet RFC 0894/STD 0041, Apr. 1984.</p>
<p><span id="RFC1042">[RFC1042]</span> J. Postel and J. Reynolds,&quot;Standard for the Transmission of IP Datagrams over IEEE 802 Networks,&quot; Internet RFC 1042/STD 0043, Feb. 1988.</p>
<p><span id="RFC1144">[RFC1144]</span> V.Jacobson, &quot;Compressing TCP/IP Headers for Low-Speed Serial Links&quot; Internet RFC 1144, Feb. 1990.</p>
<p><span id="RFC1191">[RFC1191]</span> J. Mogul and S. Deering,&quot;Path MTU Discovery,&quot; Internet RFC 1191, Nov. 1990.</p>
<p><span id="RFC1332">[RFC1332]</span> G. McGregor, &quot;The PPP Internet Protocol Control Protocol,&quot; Internet RFC 1332, May 1992.</p>
<p><span id="RFC1570">[RFC1570]</span> W.Simpson, ed., &quot;PPP LCP Extensions,&quot; Internet RFC 1570, Jan. 1994.</p>
<p><span id="RFC1661">[RFC1661]</span> W. Simpson, &quot;The Point-to-Point Protocol (PPP),&quot; Internet RFC 1661/STD 0051, July 1994.</p>
<p><span id="RFC1662">[RFC1662]</span> W. Simpson, ed.,&quot;PPP in HDLC-like Framing,&quot; Internet RFC 1662/STD 0051, July 1994.</p>
<p><span id="RFC1663">[RFC1663]</span> D. Rand,&quot;PPP Reliable Transmission,&quot; Internet RFC 1663, July 1994.</p>
<p><span id="RFC1853">[RFC1853]</span> W. Simpson, &quot;IP in IP Tunneling,&quot; Internet RFC 1853 (informational), Oct. 1995.</p>
<p><span id="RFC1962">[RFC1962]</span> D. Rand, &quot;The PPP Compression Protocol (CCP),&quot; Internet RFC 1962, June 1996.</p>
<p><span id="RFC1977">[RFC1977]</span> V.Schryver, &quot;PPP BSD Compression Protocol,&quot; Internet RFC 1977 (informational), Aug. 1996.</p>
<p><span id="RFC1981">[RFC1981]</span> J. McCann and S. Deering ,&quot;Path MTU Discovery for IP Version 6,&quot; Internet RFC 1981,Aug. 1996.</p>
<p><span id="RFC1989">[RFC1989]</span> w. Simpson, &quot;PPP Link Quality Monitoring,&quot; Internet RFC 1989, Aug.1996.</p>
<p><span id="RFC1990">[RFC1990]</span> K. Sklower, B. Lloyd, G. McGregor, D. Carr, and T. Coradetti, &quot;The PPP Multilink Protocol (MP)&quot; Internet RFC 1990, Aug. 1996.</p>
<p><span id="RFC1994">[RFC1994]</span> W. Simpson, &quot;PPP Challenge Handshake Authentication Protocol (CHAP),&quot; Internet RFC 1994, Aug. 1996.</p>
<p><span id="RFC2118">[RFC2118]</span> G.Pall, &quot;Microsoft Point-to-Point (MPPC) Protocol,&quot; Internet RFC 2118 (informational), Mar. 1997.</p>
<p><span id="RFC2125">[RFC2125]</span> C.Richards and K. Smith, &quot;The PPP Bandwidth Allocation Protocol (BAP)/The PPP Bandwidth Allocation Control Protocol (BACP),&quot; Internet RFC 2125, Mar. 1997.</p>
<p><span id="RFC2153">[RFC2153]</span> W. Simpson,&quot;PPP Vendor Extensions,&quot; Internet RFC 2153(informational), May 1997.</p>
<p><span id="RFC2290">[RFC2290]</span> J. Solomon and S.Glass,&quot;Mobile-IPv4 Configuration Option for PPP IPCP,&quot; Internet RFC 2290, Feb. 1998.</p>
<p><span id="RFC2464">[RFC2464]</span> M.Crawford, &quot;Transmission of IPv6 Packets over Ethernet Networks,&quot; Internet RFC 2464, Dec. 1988.</p>
<p><span id="RFC2473">[RFC2473]</span> A.Conta and S. Deering ,&quot;Generic Packet Tuneling in IPv6 Specification,&quot; Internet RFC 2473, Dec. 1998.</p>
<p><span id="RFC2484">[RFC2484]</span> G.Zorn, &quot;PPP LCP Internationalization Configuration Option,&quot; Internet RFC 2484, Jan. 1999.</p>
<p><span id="RFC2507">[RFC2507]</span> M. Degermark, B. Nordgren, and S. Pink, &quot;IP Header Compression,&quot; Internet RFC 2507, Feb. 1999.</p>
<p><span id="RFC2615">[RFC2615]</span> A. Malis and W. Simpson, &quot;PPP over SONET/SDH,&quot; Internet RFC 2615, June 1999.</p>
<p><span id="RFC2637">[RFC2637]</span> K.Hamzeh, G. Pall, W. Verthein, J. Taarud, W. Little, and G.Zorn, &quot;Point-to-Point Tunneling Protocol (PPTP),&quot; Internet RFC 2637 (informational), July 1999.</p>
<p><span id="RFC2759">[RFC2759]</span> G.Zorn, &quot;Microsoft PPP CHAP Extensions, Version 2,&quot; Internet RFC 2759 (informational), Jan. 2000.</p>
<p><span id="RFC2784">[RFC2784]</span> D. Farinacci, T. Li, S. Hanks, D. Meyer, and P. Traina, &quot;Generic Routing Encapsulation (GRE),&quot;Internet RFC 2784, Mar. 2000.</p>
<p><span id="RFC2865">[RFC2865]</span> C.Rigney, S. Willens, A. Rubens, and W. Simpson, &quot;Remote Authentication Dial In User Service (RADIUS),&quot; Internet RFC 2865, June 2000.</p>
<p><span id="RFC2890">[RFC2890]</span> G. Dommety,&quot;Key and Sequence Number Extensions to GRE,&quot; Internet RFC 2890, Sept. 2000.</p>
<p><span id="RFC3056">[RFC3056]</span> B.Carpenter and K. Moore,&quot;Connection of IPv6 Domains via IPv4 Clouds,&quot; Internet RFC 3056, Feb. 2001.</p>
<p><span id="RFC3077">[RFC3077]</span> E. Duros, W. Dabbous, H.Izumiyama, N. Fujii, and Y.Zhang,&quot;A Link-Layer Tunneling Mechanism for Unidirectional Links,&quot; Internet RFC 3077, Mar. 2001.</p>
<p><span id="RFC3078">[RFC3078]</span> G.Pall and G.Zorn, &quot;Microsoft Point-to-Point Encryption (MPPE) Protocol,&quot; Internet RFC 3078 (informational), Mar. 2001.</p>
<p><span id="RFC3153">[RFC3153]</span> R.Pazhyannur, I. Ali, and C. Fox, &quot;PPP Multiplexing,&quot; Internet RFC 3153, Aug. 2001.</p>
<p><span id="RFC3366">[RFC3366]</span> G.Fairhurst and L. Wood,&quot;Advice to Link Designers on Link Automatic Repeat reQuest (ARQ),&quot;Internet RFC 3366/BCP 0062,Aug.2002.</p>
<p><span id="RFC3449">[RFC3449]</span> H. Balakrishnan, V.Padmanabhan, G. Fairhurst, and M. Sooriyabandara, &quot;TCP Performance Implications of Network Path Asymmetry,&quot; Internet RFC 3449/BCP 0069, Dec. 2002.</p>
<p><span id="RFC3544">[RFC3544]</span> T.Koren, S.Casner, and C. Bormann, &quot;IP Header Compression over PPP&quot; Internet RFC 3544, July 2003.</p>
<p><span id="RFC3561">[RFC3561]</span> C.Perkins,E. Belding-Royer, and S. Das,&quot;Ad Hoc On-Demand Distance Vector (AODV) Routing,&quot; Internet RFC 3561 (experimental), July 2003.</p>
<p><span id="RFC3610">[RFC3610]</span> D. Whiting,R.Housley, and N.Ferguson, &quot;Counter with CBC-MAC (CCM),&quot; Internet RFC 3610(informational), Sept. 2003.</p>
<p><span id="RFC3626">[RFC3626]</span> T. Clausen and P. Jacquet, eds.,&quot;Optimized Link State Routing Protocol (OLSR),&quot; Internet RFC 3626 (experimental), Oct. 2003.</p>
<p><span id="RFC3748">[RFC3748]</span> B. Aboba et al., &quot;Extensible Authentication Protocol (EAP),&quot; Internet RFC 3748, June 2004.</p>
<p><span id="RFC3931">[RFC3931]</span> J. Lau, M. Townsley, and L. Goyret, eds,&quot;Layer Two Tunneling Protocol--Version 3 (L2TPv3),&quot; Internet RFC 3931, Mar. 2005.</p>
<p><span id="RFC4017">[RFC4017]</span> D.Stanley, J. Walker, and B. Aboba,&quot;Extensible Authentication Protocol (EAP) Method Requirements for Wireless LANs,&quot; Internet RFC 4017 (informational), Mar. 2005.</p>
<p><span id="RFC4380">[RFC4380]</span>C. Huitema,&quot;Teredo: Tunneling IPv6 over UDP through Network Address Translations (NATs),&quot; Internet RFC 4380,Feb. 2006.</p>
<p><span id="RFC4647">[RFC4647]</span> A. Phillips and M. Davis, &quot;Matching of Language Tags,&quot; Internet RFC 4647/BCP 0047, Sept. 2006.</p>
<p><span id="RFC4821">[RFC4821]</span> M.Mathis and J. Heffner, &quot;Packetization Layer Path MTU Discovery,&quot; Internet RFC 4821, Mar. 2007.</p>
<p><span id="RFC4838">[RFC4838]</span> V.Cerf et al.,&quot;Delay-Tolerant Networking Architecture,&quot; Internet RFC 4838 (informational), Apr. 2007.</p>
<p><span id="RFC4840">[RFC4840]</span> B.Aboba, ed., E. Davies, and D. Thaler, &quot;Multiple Encapsulation Methods Considered Harmful,&quot; Internet RFC 4840 (informational), Apr. 2007.</p>
<p><span id="RFC5072">[RFC5072]</span> S. Varada, ed., D. Haskins, and E.Allen, &quot;IP Version 6 over PPP,&quot; Internet RFC 5072,Sept. 2007.</p>
<p><span id="RFC5225">[RFC5225]</span> G. Pelletier and K.Sandlund, &quot;RObust Header Compression Version 2 (ROHCv2): Profiles for RTP, UDP,IP, ESP, and UDP-Lite,&quot; Internet RFC 5225, Apr. 2008.</p>
<p><span id="RFC5646">[RFC5646]</span> A. Phillips and M. Davis, eds., &quot;Tags for Identifying Languages,&quot; Internet RFC 5646/BCP 0047,Sept. 2009.</p>
<p><span id="S08">[S08]</span> D. Skordoulis et al., &quot;IEEE 802.11n MAC Frame Aggregation Mechanisms for Next-Generation High-Throughput WLANs,” IEEE Wireless Communications, Feb. 2008.</p>
<p><span id="S96">[S96]</span> B. Schneier,Applied Cryptography, Second Edition (John Wiley &amp; Sons, 1996).</p>
<p><span id="SAE">[SAE]</span> D. Harkins, &quot;Simultaneous Authentication of Equals: A Secure, Password-Based Key Exchange for Mesh Networks,&quot; Proc. SENSORCOMM,Aug.2008.</p>
<p><span id="SC05">[SC05]</span> S. Shalunov and R.Carlson, &quot;Detecting Duplex Mismatch on Ethernet,&quot; Proc. Passive and Active Measurement Workshop, Mar. 2005.</p>
<p><span id="SHKO7">[SHKO7]</span> C.Sengul, A.Harris, and R. Kravets,&quot;Reconsidering Power Management,&quot; Invited Paper, Proc. IEEE Broadnets, 2007.</p>
<p><span id="WOL">[WOL]</span> http://wake-on-lan.sourceforge.net</p>
]]></content>
    </entry>
</feed>